{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbb88d4",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、Kaggleの「LLM 20 Questions」コンペティションに参加するための言語モデルの構築を目的としています。このコンペティションでは、参加者が「20の質問」ゲームをプレイし、推測者と回答者の役割を果たす2つの言語モデル（LLM）を使用して、秘密の単語をできるだけ少ない質問で特定しようとします。\n",
    "\n",
    "### 取り組んでいる問題\n",
    "ノートブックでは、質問と回答のプロセスを模倣し、秘密の単語を推測するために戦略的な質問を生成するための手法を探究しています。具体的には、モデルは「はい」または「いいえ」でしか答えられない質問を通じて、情報を絞り込んでいくことを目指します。\n",
    "\n",
    "### 使用されている手法やライブラリ\n",
    "1. **データ処理**:\n",
    "   - **Pandas**: データ操作のためのライブラリ。このノートブックではデータフレームの作成や操作に使用されています。\n",
    "   - **NumPy**: 数値計算のためのライブラリ。\n",
    "\n",
    "2. **自然言語処理**:\n",
    "   - **KerasとKeras NLP**: 深層学習のためのフレームワークとしてKerasを使用し、特に自然言語処理用の拡張機能であるKeras NLPを利用しています。\n",
    "   - **GemmaCausalLMモデル**: Keras NLPから事前に構成されたGemmaモデルを使用し、指定されたプロンプトに基づいてテキスト生成を行います。\n",
    "\n",
    "3. **エージェントの設計**:\n",
    "   - `Agent`クラスが定義されており、質問を生成し、回答を受け取って記録する機能を持っています。`ask_question`メソッドは質問をモデルに送り、`receive_answer`メソッドは受け取った回答を管理するための基礎を提供します。\n",
    "\n",
    "### まとめ\n",
    "このノートブックは、Kaggleの20の質問ゲームに挑むために、様々なライブラリと手法を使用して言語モデルを構築し、エージェントの設計や情報処理の実装に取り組んでいます。最終的な目標は、できるだけ少ない質問で秘密の単語を特定する能力を持ったエージェントを作成することです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf267c8",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "初心者がつまずきそうな専門用語の解説を以下に示します。これらの用語は、ノートブックの内容に特有であり、実務経験がないと馴染みが薄い可能性があります。\n",
    "\n",
    "1. **LLM (Large Language Model)**:\n",
    "   - 大規模な言語モデルの略で、膨大なデータセットから学習し、人間のような文を生成したり、質疑応答を行ったりできる機械学習モデルのこと。例えば、GPTやBERTがこれに該当します。\n",
    "\n",
    "2. **演繹的推論**:\n",
    "   - 具体的な事例から一般的な結論を導き出す推論方法。20の質問ゲームでは、最初の質問を一般的に設定し、それに対する回答から次の質問を絞り込む形式が演繹的推論の一例です。\n",
    "\n",
    "3. **Keras**:\n",
    "   - 高レベルなニューラルネットワークライブラリ。TensorFlowやTheanoをバックエンドとして利用し、モデルの構築や訓練を簡単に行えるように設計されています。\n",
    "\n",
    "4. **Keras_NLP**:\n",
    "   - Kerasを拡張した自然言語処理用のライブラリ。言語モデル、テキスト前処理、トークナイザーなど、自然言語処理に特化した機能を提供します。\n",
    "\n",
    "5. **GemmaCausalLM**:\n",
    "   - Keras_NLPで利用可能な特定の因果関係に基づく言語モデル。入力された情報に基づいて次に続くテキストを生成することができ、特に質問応答や文生成に使用されます。\n",
    "\n",
    "6. **プロンプト**:\n",
    "   - モデルに対する入力のこと。特に言語モデルにおいて、ユーザーがモデルに期待する応答を生成するための文やフレーズを指します。\n",
    "\n",
    "7. **トークン**:\n",
    "   - テキストの最小単位で、単語や部分的な単語を指すことが多い。言語モデルは、入力されたテキストをトークンに分割して処理します。\n",
    "\n",
    "8. **知識の蓄積 (knowledge)**:\n",
    "   - 質問や回答を記録するための情報の一覧。エージェントはゲームが進行する中でこの知識を利用して次の質問を戦略的に決定します。\n",
    "\n",
    "9. **エージェント (Agent)**:\n",
    "   - ゲーム内で特定の役割を果たすシステムやプログラムを指します。このノートブックでは、質問者の役割を果たすエージェントが定義されています。\n",
    "\n",
    "10. **環境変数 (Environment Variables)**:\n",
    "    - システムのオペレーティングシステムやソフトウェアの動作に影響を与える設定情報。ここではKerasのバックエンドを設定するために使用されています。\n",
    "\n",
    "これらの用語の理解が、ノートブック内のコードやコンペティションの文脈を把握する上で役に立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a6be96",
   "metadata": {},
   "source": [
    "## LLM 20 Questions\n",
    "\n",
    "# 説明\n",
    "\n",
    "それは人、場所、それとも物ですか？それはパン箱より小さいですか？それは70Bパラメータモデルより小さいですか？\n",
    "\n",
    "「20の質問」は古くからある推論ゲームであり、20問以内で秘密の単語を推測しようとします。このゲームでは、はい・いいえで答えられる質問のみを使用します。プレイヤーは、質問を一般的なものから具体的なものへと絞り込みながら、その単語を推測することを試みます。できるだけ少ない質問で単語を当てることを目指します。\n",
    "\n",
    "各チームは、質問をし推測を行う役割の「推測者LLM」と、「はい」または「いいえ」で応答する役割の「回答者LLM」の2つで構成されます。戦略的な質問と回答を通じて、推測者ができる限り少ないラウンドで秘密の単語を正確に特定することが目標です。\n",
    "\n",
    "このコンペティションでは、演繹的推論、的を絞った質問による効率的な情報収集、ペアエージェント間の連携といったLLMの重要なスキルが評価されます。また、限られた推測回数で創造性と戦略を駆使する必要がある制約のある環境を提供します。成功すれば、LLMは単に質問に答えるだけでなく、洞察に富んだ質問をし、論理的な推論を行い、可能性を迅速に絞り込む能力を示すことになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:05:08.613418Z",
     "iopub.status.busy": "2024-05-29T14:05:08.612529Z",
     "iopub.status.idle": "2024-05-29T14:05:20.214755Z",
     "shell.execute_reply": "2024-05-29T14:05:20.213962Z",
     "shell.execute_reply.started": "2024-05-29T14:05:08.613387Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # pandasライブラリをインポートしてデータ操作を行う\n",
    "import numpy as np  # numpyライブラリをインポートして数値計算を行う\n",
    "from llm_20_questions.keywords import KEYWORDS_JSON  # 独自モジュールからKEYWORDS_JSONをインポート\n",
    "import keras  # Kerasライブラリをインポートして深層学習モデルを構築する\n",
    "import keras_nlp  # Kerasの自然言語処理関連機能を提供するライブラリをインポート\n",
    "\n",
    "# pandasはデータ解析のためのライブラリで、特にデータフレームの作成・操作が得意です。\n",
    "# numpyは多次元配列を扱うためのライブラリで、高速な数値計算が可能です。\n",
    "# llm_20_questions.keywordsからKEYWORDS_JSONをインポートすることで、特定のキーワードデータにアクセスできます。\n",
    "# kerasは深層学習のためのフレームワークで、ニューラルネットワークの構築・訓練ができる。\n",
    "# keras_nlpは、自然言語処理に特化したKerasの拡張機能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:05:20.21719Z",
     "iopub.status.busy": "2024-05-29T14:05:20.216554Z",
     "iopub.status.idle": "2024-05-29T14:05:20.229709Z",
     "shell.execute_reply": "2024-05-29T14:05:20.228876Z",
     "shell.execute_reply.started": "2024-05-29T14:05:20.217158Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords = eval(KEYWORDS_JSON)  # KEYWORDS_JSONを評価してPythonのオブジェクトに変換し、keywords変数に格納する\n",
    "\n",
    "# eval関数を使用することで、KEYWORDS_JSONに格納されているデータを実際のデータ構造に変換します。\n",
    "# これにより、JSONフォーマットのキーワードデータをPythonの辞書形式として扱えるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:05:20.231042Z",
     "iopub.status.busy": "2024-05-29T14:05:20.230786Z",
     "iopub.status.idle": "2024-05-29T14:05:20.237859Z",
     "shell.execute_reply": "2024-05-29T14:05:20.237107Z",
     "shell.execute_reply.started": "2024-05-29T14:05:20.231021Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # osライブラリをインポートしてオペレーティングシステムとの対話を行う\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # 環境変数KERAS_BACKENDを'TensorFlow'に設定する\n",
    "\n",
    "# ここでは、KerasのバックエンドとしてTensorFlowを使用するように指定しています。\n",
    "# これにより、Kerasで構築したモデルがTensorFlowを利用して動作するようになります。\n",
    "# 複数のバックエンドが利用可能な場合、環境変数を設定することで選択を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:05:20.240535Z",
     "iopub.status.busy": "2024-05-29T14:05:20.239718Z",
     "iopub.status.idle": "2024-05-29T14:06:24.770656Z",
     "shell.execute_reply": "2024-05-29T14:06:24.769845Z",
     "shell.execute_reply.started": "2024-05-29T14:05:20.24051Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")  # GemmaCausalLMモデルをプリセットから読み込む\n",
    "\n",
    "# keras_nlp.models.GemmaCausalLMは、特定の自然言語処理タスクに特化したモデルです。\n",
    "# from_presetメソッドを使用することで、事前に定義された設定（ここでは\"gemma_2b_en\"）を持つモデルインスタンスを生成します。\n",
    "# このモデルは、与えられた情報を基に文を生成したり、テキストの解析を行うために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T13:36:04.272755Z",
     "iopub.status.busy": "2024-05-29T13:36:04.271756Z",
     "iopub.status.idle": "2024-05-29T13:36:04.314278Z",
     "shell.execute_reply": "2024-05-29T13:36:04.313375Z",
     "shell.execute_reply.started": "2024-05-29T13:36:04.272713Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.summary()  # GemmaCausalLMモデルの概要を出力する\n",
    "\n",
    "# summaryメソッドを使用することで、モデルの構造や層の詳細、パラメータ数などの情報が表示されます。\n",
    "# これにより、モデルのアーキテクチャを理解し、適切に使用するための手助けとなります。\n",
    "# モデルの性能や学習状況を把握するために重要なステップです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T13:42:58.626254Z",
     "iopub.status.busy": "2024-05-29T13:42:58.625349Z",
     "iopub.status.idle": "2024-05-29T13:42:58.752954Z",
     "shell.execute_reply": "2024-05-29T13:42:58.752047Z",
     "shell.execute_reply.started": "2024-05-29T13:42:58.626218Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.generate(KEYWORDS_JSON, max_length=20)  # KEYWORDS_JSONを入力として、最大20トークンの生成を行う\n",
    "\n",
    "# generateメソッドは、与えられた入力データ（ここではKEYWORDS_JSON）に基づいて新しいテキストを生成します。\n",
    "# max_length引数は生成されるテキストの最大長を指定し、ここでは20トークンまでの長さに制限しています。\n",
    "# この方法を使って、モデルがキーワードに関連する文を生成することが期待されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:34:06.227426Z",
     "iopub.status.busy": "2024-05-29T14:34:06.226825Z",
     "iopub.status.idle": "2024-05-29T14:34:06.231775Z",
     "shell.execute_reply": "2024-05-29T14:34:06.230651Z",
     "shell.execute_reply.started": "2024-05-29T14:34:06.227399Z"
    }
   },
   "outputs": [],
   "source": [
    "promt = \"\"\"\n",
    "    Hello. Now we play game 20 Questions. I have words and you must guess that. \n",
    "    I can answer you only \"Yes\" or \"No\". Please, ask me?\n",
    "    \"\"\"  # 「こんにちは。今から20の質問ゲームをプレイします。私は言葉を持っており、あなたはそれを推測しなければなりません。\n",
    "          # 私は「はい」または「いいえ」だけで答えることができます。どうぞ、私に質問してください？」\n",
    "          # というプロンプトを定義している。\n",
    "          \n",
    "# このプロンプトは、ゲームの開始を告げ、質問を促す内容で構成されています。\n",
    "# プレイヤーが質問を開始できるよう、ルールを簡潔に説明しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:34:06.538521Z",
     "iopub.status.busy": "2024-05-29T14:34:06.537748Z",
     "iopub.status.idle": "2024-05-29T14:34:27.902865Z",
     "shell.execute_reply": "2024-05-29T14:34:27.901999Z",
     "shell.execute_reply.started": "2024-05-29T14:34:06.538484Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.generate(promt, max_length=15)  # プロンプトを入力として、最大15トークンの生成を行う\n",
    "\n",
    "# generateメソッドを使用して、定義したプロンプト（ゲームの開始を告げる内容）に基づいて新しいテキストを生成します。\n",
    "# max_length引数は生成されるテキストの最大長を指定し、ここでは15トークンまでの長さに制限しています。\n",
    "# この処理は、ゲームの進行に必要な初回の応答を生成するために使用されることが期待されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-29T14:46:24.344754Z",
     "iopub.status.busy": "2024-05-29T14:46:24.34438Z",
     "iopub.status.idle": "2024-05-29T14:46:24.350577Z",
     "shell.execute_reply": "2024-05-29T14:46:24.349729Z",
     "shell.execute_reply.started": "2024-05-29T14:46:24.344724Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.gemma = gemma_lm  # GemmaCausalLMモデルのインスタンスを保持\n",
    "        self.knowledge = []  # 質問と回答を記録するためのリストを初期化\n",
    "\n",
    "    def ask_question(self, question):\n",
    "        self.knowledge.append(question)  # 提出された質問をknowledgeリストに追加\n",
    "        response = self.gemma.generate(question)  # Gemmaモデルを使用して質問に対する応答を生成\n",
    "        return response  # 生成された応答を返す\n",
    "\n",
    "    def receive_answer(self, answer):\n",
    "        self.knowledge.append(answer)  # 提出された回答をknowledgeリストに追加\n",
    "        # 必要に応じて回答を処理する\n",
    "        pass  # 将来的にこのメソッドを拡張するためのプレースホルダー\n",
    "\n",
    "# Agentクラスは、ゲームにおける質問者を定義しており、質問の記録と応答生成を行います。\n",
    "# ask_questionメソッドは質問を送信し、その応答を受け取る機能を提供します。\n",
    "# receive_answerメソッドは、受け取った回答を処理するための基礎を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
