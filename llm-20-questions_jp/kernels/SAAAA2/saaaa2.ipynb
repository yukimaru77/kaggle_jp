{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd75b138",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「20の質問」ゲームコンペティションにおいて、AIエージェントを開発するための実装を行っています。具体的には、質問を投げかける「質問者」と、YES/NO形式で回答する「回答者」による対戦形式のゲームをシミュレーションしています。\n",
    "\n",
    "### 問題の概要\n",
    "ノートブックは、言語モデルを使用して「20の質問」ゲームをプレイし、特定のキーワード（最初は「日本」と設定される）を推測するエージェントを構築することを目的としています。エージェントはターンごとに質問を生成し、それに対する回答を受け取り、その情報に基づいて推測を行います。\n",
    "\n",
    "### 使用している手法やライブラリ\n",
    "1. **PyTorch**: モデルのトレーニングおよび推論に使用されており、GPUを利用して効率的に計算を行います。\n",
    "2. **Transformers**: Hugging FaceのTransformersライブラリが使用され、様々な事前学習済みモデルを利用して質問や回答生成を行います。具体的には、`AutoTokenizer`および`AutoModelForCausalLM`を使用しています。\n",
    "3. **BitsAndBytes**: モデルの量子化のための設定を行い、メモリ使用量を削減しつつ推論を最適化しています。\n",
    "4. **Observationクラス**: ゲームの状態を管理するためのクラスで、質問、回答、推測を記録する属性を持っています。\n",
    "\n",
    "### ノートブックの主な機能\n",
    "- **モデルのロード**: 事前学習済みのモデルをGPUに最適化してロードします。\n",
    "- **質問・回答の生成**: `generate_answer`関数を用いて、質問者が入力する質問に対する回答を生成します。\n",
    "- **Robotクラス**: 質問者または回答者としての機能を持ち、各モードに応じた処理を行います。\n",
    "- **エージェントの実装**: エージェントの主要なロジックを含む`agent`関数があり、観察結果に基づいて質問、回答、推測を行います。\n",
    "- **ゲームのループ**: 最大20ラウンドのゲームを実装しており、各ターンで質問、回答、推測の結果を表示します。\n",
    "\n",
    "ノートブックの最後では、運が良ければ指定されたキーワードを推測し、勝利を収めることを目指しています。このプロセスには、実行するたびに動的に選ばれる質問が含まれ、エージェントの戦略を強化するための試行が行われます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd10b68",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、対象のJupyter Notebookに関連する専門用語の解説を列挙します。初心者がつまずきやすいマイナーな用語やドメイン特有のキーワードに焦点を当てています。\n",
    "\n",
    "1. **BitsAndBytes**:\n",
    "   - メモリ効率のよい重みの保存と読み込みを可能にするライブラリです。通常の浮動小数点数よりも8ビットの整数を使用して、モデルのサイズを圧縮し、計算リソースを節約します。特にGPUメモリの制限がある場合に役立ちます。\n",
    "\n",
    "2. **CUDAのメモリ効率的なSDP (Scalable Data Parallel)**:\n",
    "   - 複数のGPUでのデータ並列処理を効率的に行うための手法ですが、メモリ使用効率を高めるために通常とは異なる方法で動作します。特に大規模モデルを扱う際に、リソースを節約しながらトレーニングできます。\n",
    "\n",
    "3. **デバイスマッピング (device maps)**:\n",
    "   - モデルの各レイヤーを特定のデバイス（通常はGPU）に割り当てるための設定です。レイヤーごとに異なるGPUに分散配置することで、メモリ負荷を分散し、効率的な計算を実現します。\n",
    "\n",
    "4. **量子化 (quantization)**:\n",
    "   - モデルの重みや計算を低精度（例えば8ビット）で表現するプロセスです。これによりモデルのサイズが小さくなり、速度が向上します。量子化は特にリソース制約が厳しい環境やデバイスにおいて重要です。\n",
    "\n",
    "5. **勾配チェックポイント (gradient checkpointing)**:\n",
    "   - トレーニング中にメモリを節約し、計算グラフの一部を保存しながら逆伝播の際に必要な部分だけを再計算する手法です。これにより、より大きなモデルを小さいGPUメモリでトレーニング可能になります。\n",
    "\n",
    "6. **ターニングタイプ (turnType)**:\n",
    "   - ゲーム内でエージェントが行うアクションの種類を示す指標です。具体的には、質問する（ask）、回答する（answer）、推測する（guess）の3種類があります。この概念はゲームの進行において重要です。\n",
    "\n",
    "7. **エージェント (agent)**:\n",
    "   - 環境内での行動をコントロールするプログラムやAIのことです。この競技では、質問者と回答者の役割を持つエージェントが、それぞれのタスクを実行します。\n",
    "\n",
    "8. **観察クラス (Observation class)**:\n",
    "   - ゲームの進行状況や状態を保持するために使用されるクラスです。このクラスには現在のステップ、質問&回答履歴、ターゲットキーワードやそのカテゴリなどが含まれます。\n",
    "\n",
    "9. **キーワードデータフレーム (keywords DataFrame)**:\n",
    "   - ゲーム内で使用されるキーワードやそのカテゴリ、代替キーワードの情報を整理して保持するためのデータ構造です。これを使用することで、ゲームの進行に必要な情報を効率的に管理します。\n",
    "\n",
    "これらの用語を理解することで、ノートブック内のコードやその意図をより深く理解できるようになるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:04.588943Z",
     "iopub.status.busy": "2024-07-10T07:36:04.588675Z",
     "iopub.status.idle": "2024-07-10T07:36:44.507357Z",
     "shell.execute_reply": "2024-07-10T07:36:44.506539Z",
     "shell.execute_reply.started": "2024-07-10T07:36:04.588918Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# サブミッション用のディレクトリを作成します。-pオプションは、親ディレクトリが存在しない場合にそれも作成します。\n",
    "mkdir -p /kaggle/working/submission\n",
    "\n",
    "# bitsandbytesとaccelerateパッケージをインストールします。\n",
    "pip install bitsandbytes accelerate\n",
    "\n",
    "# transformersライブラリを最新のバージョンにアップグレードします。\n",
    "pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.509377Z",
     "iopub.status.busy": "2024-07-10T07:36:44.509069Z",
     "iopub.status.idle": "2024-07-10T07:36:44.521112Z",
     "shell.execute_reply": "2024-07-10T07:36:44.520307Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.50935Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a submission/main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "# CUDAのメモリ効率的なSDPを無効にします。\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "# Kaggleエージェントのパスが存在する場合、モデルIDを設定します。\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    model_id = os.path.join(KAGGLE_AGENT_PATH, \"model\")\n",
    "#else:\n",
    "# とりあえず別のモデルパスを指定します。\n",
    "model_id = \"/kaggle/input/gemma/transformers/7b-it/3\"\n",
    "\n",
    "# 各レイヤーに対するデバイスマッピングを定義します。\n",
    "device_maps = [('model.layers.0', 0),\n",
    " ('model.layers.1', 0),\n",
    " ('model.layers.2', 0),\n",
    " ('model.layers.3', 0),\n",
    " ('model.layers.4', 0),\n",
    " ('model.layers.5', 0),\n",
    " ('model.layers.6', 0),\n",
    " ('model.layers.7', 0),\n",
    " ('model.layers.8', 0),\n",
    " ('model.layers.9', 0),\n",
    " ('model.layers.10', 0),\n",
    " ('model.layers.11', 0),\n",
    " ('model.layers.12', 0),\n",
    " ('model.layers.13', 0),\n",
    " ('model.layers.14', 0),\n",
    " ('model.layers.15', 0),\n",
    " ('model.layers.16', 0),\n",
    " ('model.layers.17', 0),\n",
    " ('model.layers.18', 0),\n",
    " ('model.layers.19', 1),\n",
    " ('model.layers.20', 1),\n",
    " ('model.layers.21', 1),\n",
    " ('model.layers.22', 1),\n",
    " ('model.layers.23', 1),\n",
    " ('model.layers.24', 1),\n",
    " ('model.layers.25', 1),\n",
    " ('model.layers.26', 1),\n",
    " ('model.layers.27', 1),\n",
    " ('model.layers.28', 1),\n",
    " ('model.layers.29', 1),\n",
    " ('model.layers.30', 1),\n",
    " ('model.layers.31', 1),\n",
    " ('model.layers.32', 1),\n",
    " ('model.layers.33', 1),\n",
    " ('model.layers.34', 1),\n",
    " ('model.layers.35', 1),\n",
    " ('model.layers.36', 1),\n",
    " ('model.layers.37', 1),\n",
    " ('model.layers.38', 1),\n",
    " ('model.layers.39', 1),\n",
    " ('model.layers.40', 1),\n",
    " ('model.layers.41', 1),\n",
    " ('model.embed_tokens', 1),\n",
    " ('model.layers', 1)]\n",
    "\n",
    "# 量子化設定を8ビットで読み込むように設定します。\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "# トークナイザーを初期化します。\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\") \n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<eos>\"])[0]\n",
    "\n",
    "# デバイスマップを設定して、モデルを読み込みます。\n",
    "device = {layer: gpu_mem for (layer, gpu_mem) in device_maps}\n",
    "config = AutoConfig.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "# 勾配チェックポイントを有効にします。\n",
    "config.gradient_checkpointing = True\n",
    "# モデルを指定されたパスから読み込みます。\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\", torch_dtype=\"auto\", quantization_config=quantization_config,\n",
    "                                             device_map=\"auto\", trust_remote_code=True, config=config)\n",
    "\n",
    "# 回答生成関数\n",
    "def generate_answer(template):\n",
    "    # テンプレートからトークンIDを取得します。\n",
    "    input_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n",
    "    # モデルから出力トークンIDを生成します。\n",
    "    output_ids = model.generate(**input_ids, max_new_tokens=15).squeeze()\n",
    "    start_gen = input_ids.input_ids.shape[1]\n",
    "    output_ids = output_ids[start_gen:]\n",
    "    # 出力が終了トークンを含むか確認し、必要に応じてデコードします。\n",
    "    if id_eot in output_ids:\n",
    "        stop = output_ids.tolist().index(id_eot)\n",
    "        output = tokenizer.decode(output_ids[:stop])\n",
    "    else:\n",
    "        output = tokenizer.decode(output_ids)\n",
    "    # 不要な改行や末尾のトークンを削除します。\n",
    "    output = re.sub('\\n', '', output)\n",
    "    output = re.sub(' <end_of_turn>', '', output)\n",
    "    output = re.sub('<end_of_turn>', '', output)\n",
    "    return output\n",
    "\n",
    "# Robotクラスの定義\n",
    "class Robot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on(self, mode, obs):\n",
    "        # モードに応じて処理を分岐します。\n",
    "        assert mode in [\"asking\", \"guessing\", \"answering\"], \"mode can only take one of these values: asking, answering, guessing\"\n",
    "        if mode == \"asking\":\n",
    "            output = self.asker(obs)\n",
    "        if mode == \"answering\":\n",
    "            output = self.answerer(obs)\n",
    "            # 出力を「yes」または「no」に規定します。\n",
    "            if \"yes\" in output.lower() or \"Yes\" in output.lower():\n",
    "                output = \"yes\"\n",
    "            elif \"no\" in output.lower() or \"No\" in output.lower():\n",
    "                output = \"no\"\n",
    "            else:\n",
    "                output = \"yes\"\n",
    "        if mode == \"guessing\":\n",
    "            output = self.asker(obs)\n",
    "        return output\n",
    "\n",
    "    def asker(self, obs):\n",
    "        # 質問する際のシステムプロンプト\n",
    "        sys_prompt = \"\"\"\n",
    "        あなたは「20の質問」ゲームをプレイするために設計されたAIアシスタントです。 \n",
    "        このゲームでは、回答者がキーワードを考え、質問者がイエス/ノーで質問をしてそれに応えます。\n",
    "        キーワードは特定の国です。\n",
    "        \"\"\"\n",
    "        # 質問を投げかける場合の処理\n",
    "        if obs.turnType == \"ask\":\n",
    "            ask_prompt = sys_prompt + \"\"\"\n",
    "            では20の質問を始めましょう。あなたは質問者の役割を果たしています。\n",
    "            YesまたはNoで答えられる質問をしてください。\n",
    "            例として、キーワードがモロッコの場合、次のように流れます:\n",
    "            例:\n",
    "            <あなた: 国ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: ヨーロッパにありますか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: アフリカにありますか？\n",
    "            ユーザー: はい\n",
    "            あなた: その国に住む人は大半が肌の色が濃いですか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: 「m」で始まる国の名前ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: モロッコですか？\n",
    "            ユーザー: はい。>\n",
    "            ユーザーが選んだ言葉を考えて、最初の質問をしてください。\n",
    "            できるだけ短く、冗長にならないように、1つの質問だけをしてください。余計な言葉は不要です！\n",
    "            \"\"\"\n",
    "        \n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{ask_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "            if len(obs.questions) >= 1:\n",
    "                # 質問と回答の履歴を追加します。\n",
    "                for q, a in zip(obs.questions, obs.answers):\n",
    "                    chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                    chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        \n",
    "        # 残りのラウンドの推測処理\n",
    "        elif obs.turnType == \"guess\":\n",
    "            conv = \"\"\n",
    "            for q, a in zip(obs.questions, obs.answers):\n",
    "                conv += f\"\"\"Question: {q}\\nAnswer: {a}\\n\"\"\"\n",
    "            guess_prompt = sys_prompt + f\"\"\"\n",
    "            現在のゲームの状態は以下の通りです:\\n{conv}\n",
    "            この会話に基づいて、言葉を推測できますか？できるだけ簡潔に、言葉だけを提供してください。\n",
    "            \"\"\"\n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{guess_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "        output = generate_answer(chat_template)        \n",
    "        return output\n",
    "    \n",
    "    # 回答者の処理\n",
    "    def answerer(self, obs):\n",
    "        sys_prompt = f\"\"\"\n",
    "        あなたは「20の質問」ゲームをプレイするために設計されたAIアシスタントです。 \n",
    "        このゲームでは、回答者がキーワードを考え、質問者がイエス/ノーで質問をしてそれに応えます。\n",
    "        キーワードは特定の場所または物です。\\n\n",
    "        ユーザーの質問を理解し、推測されるキーワードを把握してください。\n",
    "        現在、ユーザーが推測すべき言葉は: \"{obs.keyword}\" で、カテゴリは \"{obs.category}\" です。\n",
    "        例として、キーワードがモロッコかつカテゴリが「場所」の場合、次のように流れます:\n",
    "        例:\n",
    "        <ユーザー: それは場所ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: ヨーロッパにありますか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: アフリカにありますか？\n",
    "        あなた: はい\n",
    "        ユーザー: その土地に住む人々は肌の色が暗いですか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: 「m」で始まる国名ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: モロッコですか？\n",
    "        あなた: はい。>\n",
    "        \"\"\"\n",
    "        chat_template = f\"\"\"<start_of_turn>system\\n{sys_prompt}<end_of_turn>\\n\"\"\"\n",
    "        chat_template += \"<start_of_turn>user\\n\"\n",
    "        chat_template += f\"{obs.questions[0]}\"\n",
    "        chat_template += \"<start_of_turn>model\\n\"\n",
    "        # 以前の質問と回答をテンプレートに追加します。\n",
    "        if len(obs.answers) >= 1:\n",
    "            for q, a in zip(obs.questions[1:], obs.answers):\n",
    "                chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        output = generate_answer(chat_template)\n",
    "        return output\n",
    "\n",
    "# Robotクラスのインスタンスを生成します。\n",
    "robot = Robot()\n",
    "\n",
    "# エージェントのメイン関数\n",
    "def agent(obs, cfg):\n",
    "    # 各ターンタイプに応じてロボットの処理を呼び出します。\n",
    "    if obs.turnType == \"ask\":\n",
    "        response = robot.on(mode=\"asking\", obs=obs)\n",
    "        \n",
    "    elif obs.turnType == \"guess\":\n",
    "        response = robot.on(mode=\"guessing\", obs=obs)\n",
    "        \n",
    "    elif obs.turnType == \"answer\":\n",
    "        response = robot.on(mode=\"answering\", obs=obs)\n",
    "        \n",
    "    # レスポンスが無効な場合、デフォルトとして「yes」を返します。\n",
    "    if response is None or len(response) <= 1:\n",
    "        response = \"yes\"\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.522628Z",
     "iopub.status.busy": "2024-07-10T07:36:44.522192Z",
     "iopub.status.idle": "2024-07-10T07:36:44.539285Z",
     "shell.execute_reply": "2024-07-10T07:36:44.538167Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.522593Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_agent1(obs, cfg):\n",
    "    # エージェントが推測者で、ターンタイプが「ask」の場合\n",
    "    if obs.turnType == \"ask\":\n",
    "        # 質問のリストを定義します。\n",
    "        response_list = [\n",
    "            'それはアフリカにありますか？',\n",
    "            'それはアメリカにありますか？',\n",
    "            'それはアジアにありますか？',\n",
    "            'それはオセアニアにありますか？',\n",
    "            'それは東ヨーロッパにありますか？',\n",
    "            'それは北ヨーロッパにありますか？',\n",
    "            'それは南ヨーロッパにありますか？',\n",
    "            'それは西ヨーロッパにありますか？',\n",
    "            'それは日本ですか？'\n",
    "        ]\n",
    "        # 現在の質問の数に基づいて、質問を選ぶ（コメントアウトされたが、長さに基づくロジックのサンプルあり）。\n",
    "#         response = response_list[len(obs.questions)]\n",
    "        # ランダムに質問を選びます。\n",
    "        response = random.choice(response_list)\n",
    "    elif obs.turnType == \"guess\":\n",
    "        # 推測する際のデフォルトの応答\n",
    "        response = \"duck\"  # 推測する単語が「アヒル」です。\n",
    "    elif obs.turnType == \"answer\":\n",
    "        # イエスまたはノーをランダムに選びます。\n",
    "        response = random.choices([\"yes\", \"no\"])[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.54247Z",
     "iopub.status.busy": "2024-07-10T07:36:44.542048Z",
     "iopub.status.idle": "2024-07-10T07:36:44.548992Z",
     "shell.execute_reply": "2024-07-10T07:36:44.547928Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.542435Z"
    }
   },
   "outputs": [],
   "source": [
    "#!apt install pigz pv > /dev/null\n",
    "# pigzとpvをインストールします。\n",
    "# pigzは圧縮ツールで、pvはデータの進捗状況を表示するためのコマンドラインツールです。\n",
    "# これらのインストール出力を非表示にします（> /dev/null）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.550865Z",
     "iopub.status.busy": "2024-07-10T07:36:44.550273Z",
     "iopub.status.idle": "2024-07-10T07:36:44.55715Z",
     "shell.execute_reply": "2024-07-10T07:36:44.556419Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.550839Z"
    }
   },
   "outputs": [],
   "source": [
    "#!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/transformers/2b-it/2\n",
    "# tarコマンドを使用して、指定したディレクトリを圧縮アーカイブにします。\n",
    "# pigzを使って圧縮し、pvを使って進捗状況を表示します。\n",
    "# submission.tar.gzという名前でアーカイブが作成されます。\n",
    "# -Cオプションは、アーカイブに追加する前に現在の作業ディレクトリを指定します。\n",
    "# 最初の -C は /kaggle/working/submission ディレクトリに移動し、その内容をアーカイブします。\n",
    "# 次の -C は /kaggle/input/gemma/transformers/2b-it/2 に移動し、このディレクトリもアーカイブに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.558489Z",
     "iopub.status.busy": "2024-07-10T07:36:44.558199Z",
     "iopub.status.idle": "2024-07-10T07:36:44.563596Z",
     "shell.execute_reply": "2024-07-10T07:36:44.562865Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.558448Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "# 実行時間を計測します。\n",
    "\n",
    "#import random  # randomモジュールをインポートします。\n",
    "#from kaggle_environments import make  # Kaggle環境を作成するためのmake関数をインポートします。\n",
    "# agent変数にエージェントのパスを指定します。\n",
    "#agent = \"/kaggle/working/submission/main.py\"\n",
    "# 環境を作成します。ここでは「llm_20_questions」ゲームをデバッグモードで生成します。\n",
    "#env = make(\"llm_20_questions\", debug=True)\n",
    "# 環境でエージェントを実行します。最初のエージェントは自作エージェント、その他はsimple_agent1です。\n",
    "#game_output = env.run(agents=[agent, simple_agent1, simple_agent1, simple_agent1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.565106Z",
     "iopub.status.busy": "2024-07-10T07:36:44.564745Z",
     "iopub.status.idle": "2024-07-10T07:36:44.571217Z",
     "shell.execute_reply": "2024-07-10T07:36:44.5704Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.565079Z"
    }
   },
   "outputs": [],
   "source": [
    "#env.render(mode=\"ipython\", width=600, height=500)\n",
    "# 環境の描画を行います。ここではIPythonモードで表示し、幅600ピクセル、高さ500ピクセルに設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.5725Z",
     "iopub.status.busy": "2024-07-10T07:36:44.572242Z",
     "iopub.status.idle": "2024-07-10T07:36:45.983895Z",
     "shell.execute_reply": "2024-07-10T07:36:45.982561Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.572478Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\n",
    "# 指定されたURLからkeywords.pyファイルをダウンロードし、keywords_local.pyという名前で保存します。\n",
    "# wgetコマンドを使用してインターネットからファイルを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:45.987033Z",
     "iopub.status.busy": "2024-07-10T07:36:45.98602Z",
     "iopub.status.idle": "2024-07-10T07:38:44.115779Z",
     "shell.execute_reply": "2024-07-10T07:38:44.114983Z",
     "shell.execute_reply.started": "2024-07-10T07:36:45.986989Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from submission.main import agent  # 作成したエージェントをインポートします。\n",
    "from keywords_local import KEYWORDS_JSON  # ダウンロードしたキーワードのJSONデータをインポートします。\n",
    "\n",
    "# 観察用クラスの定義\n",
    "class Observation:\n",
    "    def __init__(self):\n",
    "        self.step = 0  # 現在のステップ数を初期化します。\n",
    "        self.role = \"guesser\"  # 役割を「推測者」に設定します。\n",
    "        self.turnType = \"ask\"  # 現在のターンタイプを「質問」に設定します。\n",
    "        self.keyword = \"Japan\"  # キーワードを初期化します。「日本」をデフォルトとします。\n",
    "        self.category = \"country\"  # カテゴリーを「国」に設定します。\n",
    "        self.questions = []  # 質問のリストを初期化します。\n",
    "        self.answers = []  # 回答のリストを初期化します。\n",
    "        self.guesses = []  # 推測のリストを初期化します。\n",
    "        \n",
    "# JSONデータからキーワードのデータフレームを作成する関数\n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    json_data = json.loads(KEYWORDS_JSON)  # JSONをPythonの辞書に変換します。\n",
    "\n",
    "    keyword_list = []  # キーワードを格納するリスト\n",
    "    category_list = []  # カテゴリーを格納するリスト\n",
    "    alts_list = []  # 代替キーワードを格納するリスト\n",
    "\n",
    "    # JSONデータをループし、各キーワードを抽出します。\n",
    "    for i in range(len(json_data)):\n",
    "        for j in range(len(json_data[i]['words'])):\n",
    "            keyword = json_data[i]['words'][j]['keyword']  # キーワードを取得します。\n",
    "            keyword_list.append(keyword)  # キーワードリストに追加します。\n",
    "            category_list.append(json_data[i]['category'])  # カテゴリーリストに追加します。\n",
    "            alts_list.append(json_data[i]['words'][j]['alts'])  # 代替キーワードリストに追加します。\n",
    "\n",
    "    # データフレームを作成し、各リストをカラムに設定します。\n",
    "    data_pd = pd.DataFrame(columns=['keyword', 'category', 'alts'])\n",
    "    data_pd['keyword'] = keyword_list\n",
    "    data_pd['category'] = category_list\n",
    "    data_pd['alts'] = alts_list\n",
    "    \n",
    "    return data_pd  # 作成したデータフレームを返します。\n",
    "    \n",
    "# キーワードデータフレームを作成します。\n",
    "keywords_df = create_keyword_df(KEYWORDS_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:38:44.119151Z",
     "iopub.status.busy": "2024-07-10T07:38:44.118594Z",
     "iopub.status.idle": "2024-07-10T07:46:29.045452Z",
     "shell.execute_reply": "2024-07-10T07:46:29.044455Z",
     "shell.execute_reply.started": "2024-07-10T07:38:44.119123Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = Observation()  # 観察オブジェクトを作成します。\n",
    "cfg = \"_\"  # 設定用の変数（未使用）\n",
    "\n",
    "# キーワードデータフレームからランダムにサンプルを取得します。\n",
    "sample_df = keywords_df.sample()\n",
    "obs.keyword = sample_df[\"keyword\"].values[0]  # キーワードを設定します。\n",
    "obs.category = sample_df[\"category\"].values[0]  # カテゴリーを設定します。\n",
    "alts_list = sample_df[\"alts\"].values[0]  # 代替キーワードリストを取得します。\n",
    "alts_list.append(obs.keyword)  # 元のキーワードを代替キーワードリストに追加します。\n",
    "\n",
    "print(f\"keyword: {obs.keyword}\")  # 現在のキーワードを表示します。\n",
    "\n",
    "# 最大20ラウンドのゲームを開始します。\n",
    "for round in range(20):\n",
    "    obs.step = round + 1  # ステップ数を更新します。\n",
    "    \n",
    "    obs.role = \"guesser\"  # 現在の役割を「推測者」に設定します。\n",
    "    obs.turnType = \"ask\"  # 現在のターンタイプを「質問」に設定します。\n",
    "    question = agent(obs, cfg)  # エージェントに質問を投げます。\n",
    "    obs.questions.append(question)  # 質問を履歴に追加します。\n",
    "    \n",
    "    obs.role = \"answerer\"  # 役割を「回答者」に設定します。\n",
    "    obs.turnType = \"answer\"  # ターンタイプを「回答」に設定します。\n",
    "    answer = agent(obs, cfg)  # エージェントに回答を求めます。\n",
    "    obs.answers.append(answer)  # 回答を履歴に追加します。\n",
    "    \n",
    "    obs.role = \"guesser\"  # 役割を再度「推測者」に設定します。\n",
    "    obs.turnType = \"guess\"  # ターンタイプを「推測」に設定します。\n",
    "    guess = agent(obs, cfg)  # エージェントに推測を求めます。\n",
    "    obs.guesses.append(guess)  # 推測を履歴に追加します。\n",
    "    \n",
    "    # 現在のラウンド、質問、回答、推測を表示します。\n",
    "    print(f\"round: {round + 1}\")\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"answer: {answer}\")\n",
    "    print(f\"guess: {guess}\")\n",
    "    \n",
    "    # 推測が代替リストに含まれている場合、勝利を表示してループを終了します。\n",
    "    if guess in alts_list:\n",
    "        print(\"Win!!\")  # 勝利のメッセージを表示します。\n",
    "        break  # ゲームを終了します。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 58235,
     "sourceId": 69785,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
