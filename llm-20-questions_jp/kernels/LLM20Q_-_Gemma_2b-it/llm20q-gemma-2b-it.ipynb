{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f3f0c39",
   "metadata": {},
   "source": [
    "# è¦ç´„ \n",
    "ã“ã®Jupyter Notebookã¯ã€20ã®è³ªå•ã‚²ãƒ¼ãƒ ã«ãŠã„ã¦ã€äººç‰©ã€å ´æ‰€ã€ç‰©ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã‚’ä½¿ç”¨ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ææ¡ˆã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ã‚¿ãƒ¼ãƒ³ã”ã¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã€è³ªå•ã‚’é€šã˜ã¦ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¨æ¸¬ã™ã‚‹ã“ã¨ã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "### å•é¡Œå®šç¾©\n",
    "- **å•é¡Œ**: 20ã®è³ªå•ã‚²ãƒ¼ãƒ ã‚’é€šã˜ã¦ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‹ã‚‰ç‰¹å®šã®äººç‰©ã€å ´æ‰€ã€ç‰©ã‚’ç‰¹å®šã™ã‚‹ã€‚\n",
    "- **ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ç”¨ã„ã€GISåº§æ¨™ã‚„è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãªã©ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦ã€è³ªå•ã«å¯¾ã™ã‚‹é©åˆ‡ãªå¿œç­”ã‚’å°ãã€‚\n",
    "\n",
    "### è€ƒãˆã‚‰ã‚Œã‚‹è§£æ±ºç­–\n",
    "1. **ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®å†™çœŸã‚„GISåº§æ¨™ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šæ­£ç¢ºãªè³ªå•å¿œç­”ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚\n",
    "2. **ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨**: é›»è©±ã®ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚„ã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã®æƒ…å ±ã‚’Referã—ã€ç‰¹å®šã®è©±ã—æ–¹ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è­˜åˆ¥ã€‚\n",
    "3. **æ¤œç´¢ä¿¡å·ã®æœ€é©åŒ–**: ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ãã€è³ªå•ç¯„å›²å†…ã§ã®è¿…é€Ÿãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ã‚’å¯èƒ½ã«ã™ã‚‹éç›£è¦–ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã€‚\n",
    "\n",
    "### ã‚³ãƒ¼ãƒ‰ã®å®Ÿè£…\n",
    "- **ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿**: JSONå½¢å¼ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‚’èª­ã¿è¾¼ã¿ã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã«æ ¼ç´ã™ã‚‹ã€‚\n",
    "- **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­è¨ˆ**: è³ªå•è€…ï¼ˆQuestionerAgentï¼‰ã¨å›ç­”è€…ï¼ˆAnswererAgentï¼‰ã‚’å®šç¾©ã—ã€ãã‚Œãã‚Œã®å½¹å‰²ã«åŸºã¥ã„ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã™ã‚‹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã€‚\n",
    "- **ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–**: Gemmaã®ã‚«ã‚¸ãƒ¥ã‚¢ãƒ«LMãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒæ©Ÿèƒ½ã™ã‚‹ã‚ˆã†ã«æ§‹æˆã™ã‚‹ã€‚\n",
    "- **ç’°å¢ƒãƒ†ã‚¹ãƒˆ**: Kaggleã®ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€4ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¯¾æˆ¦ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã€‚\n",
    "\n",
    "### ä½¿ç”¨ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "- **Pandas**: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æ“ä½œã€‚\n",
    "- **Torch**: ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã€‚\n",
    "- **Kaggle Environments**: ã‚²ãƒ¼ãƒ ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å¯¾æˆ¦ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚\n",
    "\n",
    "ã“ã®Notebookã¯ã€20ã®è³ªå•ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é€šã˜ã¦ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®æ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æç¤ºã—ã¦ãŠã‚Šã€æˆ¦ç•¥çš„ãªè³ªå•å¿œç­”ã‚’é€šã˜ãŸæ¨è«–èƒ½åŠ›ã®è©•ä¾¡ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cc942",
   "metadata": {},
   "source": [
    "# ç”¨èªæ¦‚èª¬ \n",
    "ä»¥ä¸‹ã¯ã€æä¾›ã•ã‚ŒãŸJupyter Notebookã«å«ã¾ã‚Œã‚‹å°‚é–€ç”¨èªã‚„æ¦‚å¿µã®ç°¡å˜ãªè§£èª¬ã§ã™ã€‚ç‰¹ã«æ©Ÿæ¢°å­¦ç¿’ã‚„æ·±å±¤å­¦ç¿’ã®åˆå¿ƒè€…ãŒã¤ã¾ãšãã‚„ã™ã„ã€ã‚ã¾ã‚ŠçŸ¥ã‚‰ã‚Œã¦ã„ãªã„ç”¨èªã‚„ç‰¹å®šã®ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "1. **GISåº§æ¨™ (Geographic Information System Coordinates)**:\n",
    "   åœ°ç†æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ  (GIS) ã¨ã¯ã€åœ°ç†ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã€ä¿å­˜ã€è§£æã€è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚GISåº§æ¨™ã¯ã€ç‰¹å®šã®åœ°ç‚¹ã‚’åœ°çƒä¸Šã®ä½ç½®ã§è¡¨ç¾ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ç·¯åº¦ã¨çµŒåº¦ã®çµ„ã¿åˆã‚ã›ã§ã™ã€‚ç‰©ç†çš„ãªå ´æ‰€ã‚’ç‰¹å®šã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\n",
    "2. **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Fine-tuning)**:\n",
    "   æ—¢ã«å­¦ç¿’æ¸ˆã¿ã®ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã«é©å¿œã•ã›ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã•ã›ã¦ç²¾åº¦ã‚’å‘ä¸Šã•ã›ã‚‹æ–¹æ³•ã§ã€é€šå¸¸ã€å®Œå…¨ãªå†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚ˆã‚Šã‚‚æ—©ãã€å°‘ãªã„ãƒ‡ãƒ¼ã‚¿ã§è¡Œã‚ã‚Œã¾ã™ã€‚\n",
    "\n",
    "3. **æ¤œç´¢ä¿¡å· (Search Signal)**:\n",
    "   æ¤œç´¢ä¿¡å·ã¨ã¯ã€ç‰¹å®šã®æƒ…å ±ã‚’æ¢ã™éš›ã«å½¹ç«‹ã¤ãƒ‡ãƒ¼ã‚¿ã‚„ç‰¹å¾´ã®ã“ã¨ã§ã™ã€‚ã“ã“ã§ã¯ã€è³ªå•è€…ãŒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«å¿…è¦ãªæƒ…å ±ã‚’æŒ‡ã—ã¾ã™ã€‚\n",
    "\n",
    "4. **é€†å¼•ã (Reverse Lookup)**:\n",
    "   ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ãŠã„ã¦ã€ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦é–¢é€£ã™ã‚‹æƒ…å ±ã‚’è¦‹ã¤ã‘ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã§ã™ã€‚ã“ã“ã§ã¯ã€ç¾åœ¨ã®ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚„åŸ‹ã‚è¾¼ã¿ã‚’åˆ©ç”¨ã—ã¦ã€ç‰¹å®šã®è³ªå•ã«å¯¾ã™ã‚‹é©åˆ‡ãªå›ç­”ã‚’ç”Ÿæˆã™ã‚‹æ–¹æ³•ã‚’æŒ‡ã—ã¾ã™ã€‚\n",
    "\n",
    "5. **ãƒˆãƒ¼ã‚¯ãƒ³ (Token)**:\n",
    "   è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã„ã¦ã€ãƒˆãƒ¼ã‚¯ãƒ³ã¯æ–‡ç« ã‚’æ§‹æˆã™ã‚‹æœ€å°ã®å˜ä½ã§ã™ã€‚å˜èªã‚„å¥èª­ç‚¹ãªã©ãŒè©²å½“ã—ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ†ã‚­ã‚¹ãƒˆã‚’ç†è§£ã™ã‚‹ãŸã‚ã«ç”¨ã„ã¾ã™ã€‚\n",
    "\n",
    "6. **ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ (Model Weights)**:\n",
    "   ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®å„æ¥ç¶šã«ä»˜ä¸ã•ã‚Œã‚‹æ•°å€¤ã§ã€å­¦ç¿’ã«ã‚ˆã£ã¦æœ€é©åŒ–ã•ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ãŒç•°ãªã‚‹ã¨ã€åŒã˜å…¥åŠ›ã«å¯¾ã—ã¦ç•°ãªã‚‹å‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã¾ã™ã€‚\n",
    "\n",
    "7. **éç›£è¦–ãƒ¢ãƒ‡ãƒ« (Unsupervised Model)**:\n",
    "   ãƒ©ãƒ™ãƒ«ä»˜ã‘ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã›ãšã«ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„æ§‹é€ ã‚’å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ã‚„æ¬¡å…ƒå‰Šæ¸›ã®ã‚¿ã‚¹ã‚¯ã«ä¸€èˆ¬çš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "8. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Agent)**:\n",
    "   ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ã€Œè³ªå•è€…ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã€Œå›ç­”è€…ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒãã‚Œãã‚Œè³ªå•ã¨å›ç­”ã‚’æ‹…å½“ã—ã¾ã™ã€‚\n",
    "\n",
    "9. **æ¸©åº¦ (Temperature)**:\n",
    "   ç¢ºç‡åˆ†å¸ƒã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚’èª¿æ•´ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã€ã“ã®å€¤ãŒé«˜ã„ã»ã©å¤šæ§˜æ€§ã®ã‚ã‚‹å‡ºåŠ›ãŒå¾—ã‚‰ã‚Œã€ä½ã„ã»ã©æ±ºå®šè«–çš„ãªå‡ºåŠ›ã«ãªã‚‹å‚¾å‘ãŒã‚ã‚‹ã€‚ç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã§ã¯ã€å‰µé€ æ€§ã¨ä¸€è²«æ€§ã®ãƒãƒ©ãƒ³ã‚¹ã‚’å–ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "10. **å°‘æ•°ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’ (Few-shot Learning)**:\n",
    "    é™ã‚‰ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’å­¦ç¿’ã•ã›ã‚‹èƒ½åŠ›ã§ã™ã€‚ã‚ã¾ã‚Šãƒ‡ãƒ¼ã‚¿ãŒãªã„çŠ¶æ³ã§æœ‰ç”¨ã§ã‚ã‚Šã€ä¸€èˆ¬åŒ–èƒ½åŠ›ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ç”¨èªãŒåˆå¿ƒè€…ã«ã¨ã£ã¦å‚è€ƒã«ãªã‚Šã€Jupyter Notebookã¸ã®ç†è§£ã‚’æ·±ã‚ã‚‹åŠ©ã‘ã¨ãªã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f481c235",
   "metadata": {},
   "source": [
    "## å•é¡Œå®šç¾©:\n",
    "20ã®è³ªå•ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ãªãŒã‚‰ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‹ã‚‰äººç‰©ã€å ´æ‰€ã€ç‰©ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã‚¿ãƒ¼ãƒ³ã”ã¨ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¡ç”¨ã—ã¾ã™ã€‚  \n",
    "\n",
    "è€ƒãˆã‚‰ã‚Œã‚‹è§£æ±ºç­–:\n",
    "\n",
    "* å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¯ã€å›½ã€éƒ½å¸‚ã€å·ã€ãã—ã¦ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®è¿‘ä¼¼ã‚’è³ªå•ã«å¯¾ã—ã¦ã‚ˆã‚Šé©åˆ‡ã«èª¿æ•´ã™ã‚‹ãŸã‚ã«ã€å†™çœŸã‹ã‚‰ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚„éƒ½å¸‚ã®GISåº§æ¨™ã®ä¸­å¿ƒç‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "* é›»è©±ã®ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«GISåº§æ¨™ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã‚ã‚Šã€å¤‰æ›ã•ã‚ŒãŸå ´æ‰€ã‚’ç”¨ã„ã¦è¨€èªã®ãƒ­ãƒ¼ã‚«ãƒªã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ã€ç‰¹å®šã®è©±ã—æ–¹ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„å£èªã‚’ç‰¹å®šã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n",
    "\n",
    "* ç‰©ã«é–¢ã—ã¦ã¯ã€è£½å“èª¬æ˜ã‚„è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒã§ãã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚\n",
    "\n",
    "* äººã«é–¢ã—ã¦ã¯ã€ã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã‚„LinkedInã€ãƒ‡ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚µã‚¤ãƒˆãªã©ã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ã‚’å‚ç…§ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "* ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã®ä»–ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã¯ã€20ã®è³ªå•ç¯„å›²å†…ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ã™ãã«åˆ°é”ã§ãã‚‹ã‚ˆã†ã«ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã«å¯¾ã—ã¦å„ªã‚ŒãŸæ¤œç´¢ä¿¡å·ã‚’ç”Ÿã¿å‡ºã™ãƒˆãƒ¼ã‚¯ãƒ³ã‚’ç‰¹å®šã™ã‚‹ã“ã¨ãŒã§ãã€ç¾åœ¨ã®ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚„åŸ‹ã‚è¾¼ã¿ã«åŸºã¥ã„ã¦é€†å¼•ãã™ã‚‹éç›£è¦–ãƒ¢ãƒ‡ãƒ«ã«åˆ©ç”¨ã§ãã¾ã™ã€‚\n",
    "\n",
    "ä¾‹:\n",
    "* https://www.cia.gov/the-world-factbook/\n",
    "* https://public-nps.opendata.arcgis.com/datasets/nps::national-register-of-historic-places-points/explore\n",
    "\n",
    "\n",
    "## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.924486Z",
     "iopub.status.busy": "2024-06-08T05:46:22.924097Z",
     "iopub.status.idle": "2024-06-08T05:46:22.973208Z",
     "shell.execute_reply": "2024-06-08T05:46:22.972092Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.924455Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å‹•çš„ã«èª­ã¿è¾¼ã¿ã¾ã™\n",
    "from importlib.machinery import SourceFileLoader\n",
    "# keywords.pyã‹ã‚‰KEYWORDS_JSONã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™\n",
    "keywords = SourceFileLoader(\"keywords\",'/kaggle/input/llm-20-questions/llm_20_questions/keywords.py').load_module()\n",
    "# JSONå½¢å¼ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™\n",
    "df = json.loads(keywords.KEYWORDS_JSON)\n",
    "words = []\n",
    "\n",
    "# å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ã¤ã„ã¦ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚’è¡Œã„ã¾ã™\n",
    "for c in df:\n",
    "    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åã¨å˜èªæ•°ã‚’å‡ºåŠ›ã—ã¾ã™\n",
    "    print(c['category'], len(c['words']))\n",
    "    # ã‚«ãƒ†ã‚´ãƒªãƒ¼å†…ã®å„å˜èªã«ã¤ã„ã¦ã•ã‚‰ã«ãƒ«ãƒ¼ãƒ—å‡¦ç†ã‚’è¡Œã„ã¾ã™\n",
    "    for w in c['words']:\n",
    "        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ä»£æ›¿èªã€ç©ºã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã€ç·¯åº¦ã€çµŒåº¦ã‚’wordsãƒªã‚¹ãƒˆã«è¿½åŠ ã—ã¾ã™\n",
    "        words.append([c['category'], w[\"keyword\"], w[\"alts\"], \"\", \"\", 0.0, 0.0])\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã€ã‚«ãƒ©ãƒ åã‚’è¨­å®šã—ã¾ã™\n",
    "df = pd.DataFrame(words, columns=['Category','Word','Alternatives', \"Cat1\", \"Cat2\", \"Lat\", \"Lon\"])\n",
    "# ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®æœ€çµ‚5è¡Œã‚’è¡¨ç¤ºã—ã¾ã™\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecaafa9",
   "metadata": {},
   "source": [
    "## ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒ†ã‚£ãƒ³ã‚°\n",
    "* https://www.promptingguide.ai/models/gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.975677Z",
     "iopub.status.busy": "2024-06-08T05:46:22.975345Z",
     "iopub.status.idle": "2024-06-08T05:46:22.981114Z",
     "shell.execute_reply": "2024-06-08T05:46:22.980268Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.975647Z"
    }
   },
   "outputs": [],
   "source": [
    "template_special_tokens = ['<bos>','<start_of_turn>user','<start_of_turn>model','<end_of_turn>','<eos>']\n",
    "\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1 - æ¨æ¸¬è€… (ãƒ¢ãƒ‡ãƒ«ï¼Ÿ)\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2 - å›ç­”è€… (ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼Ÿ)\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ3 - æ¨æ¸¬è€… (ãƒ¢ãƒ‡ãƒ«ï¼Ÿ)\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ4 - å›ç­”è€… (ãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼Ÿ)\n",
    "\n",
    "def agentx(obs, cfg):\n",
    "    # è¦³å¯Ÿçµæœã®ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆã—ã¾ã™\n",
    "    if obs.turnType == \"ask\": \n",
    "        response = \"\"  # è³ªå•ã®ã‚¿ãƒ¼ãƒ³ã®å ´åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "    elif obs.turnType == \"guess\": \n",
    "        response = \"\"  # æ¨æ¸¬ã®ã‚¿ãƒ¼ãƒ³ã®å ´åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "    elif obs.turnType == \"answer\": \n",
    "        response = \"\"  # å›ç­”ã®ã‚¿ãƒ¼ãƒ³ã®å ´åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "    else: \n",
    "        response = \"Am I Halucinating?  **YES**\"  # ä»–ã®ä¸æ˜ãªã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã«å¯¾ã™ã‚‹ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "    return response  # ç”Ÿæˆã—ãŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bded1cd",
   "metadata": {},
   "source": [
    "## 20ã®è³ªå•æå‡ºãƒ¢ãƒ‡ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.982593Z",
     "iopub.status.busy": "2024-06-08T05:46:22.982319Z",
     "iopub.status.idle": "2024-06-08T05:46:34.844839Z",
     "shell.execute_reply": "2024-06-08T05:46:34.842919Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.982569Z"
    },
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’/kaggle/workingã«ç§»å‹•ã—ã¾ã™\n",
    "cd /kaggle/working\n",
    "# immutabledictã¨sentencepieceã®æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n",
    "# gemma_pytorchãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¾ã™\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null\n",
    "# gemmaç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™\n",
    "mkdir /kaggle/working/submission/lib/gemma/\n",
    "# ã‚¯ãƒ­ãƒ¼ãƒ³ã—ãŸgemmaã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•ã—ã¾ã™\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:50:54.946487Z",
     "iopub.status.busy": "2024-06-08T05:50:54.945851Z",
     "iopub.status.idle": "2024-06-08T05:50:54.9574Z",
     "shell.execute_reply": "2024-06-08T05:50:54.956464Z",
     "shell.execute_reply.started": "2024-06-08T05:50:54.946445Z"
    },
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile submission/main.py\n",
    "\n",
    "import torch, itertools, contextlib\n",
    "import os, sys, re, gc\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "gc.enable()\n",
    "\n",
    "# Kaggleã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/2b-it/2\")\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")\n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\"\n",
    "\n",
    "from gemma.config import get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "\n",
    "# ã“ã‚Œã¯çŸ­ç¸®ã•ã‚Œã€ã‚²ãƒ¼ãƒ ãƒ¡ãƒ¢ãƒªã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã§è£œå®Œã§ãã¾ã™ open('gamemaster.dat'), open('player.dat')\n",
    "class AgentFormatter:\n",
    "    def __init__(self, sp: str = None, fse: Iterable = None):\n",
    "        self._system_prompt = sp\n",
    "        self._few_shot_examples = fse\n",
    "        self._turn_user = f\"<start_of_turn>user\\n{{}}<end_of_turn>\\n\"\n",
    "        self._turn_model = f\"<start_of_turn>model\\n{{}}<end_of_turn>\\n\"\n",
    "        self.reset()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self._state\n",
    "    \n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)\n",
    "        return self\n",
    "    \n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)\n",
    "        return self\n",
    "    \n",
    "    def reset(self):\n",
    "        self._state = \"\"\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')\n",
    "        return self\n",
    "    \n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]\n",
    "        formatters = itertools.cycle(formatters)\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)\n",
    "        return self\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    torch.set_default_dtype(dtype)\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sp=None, fse=None):\n",
    "        self._device = torch.device('cuda:0')\n",
    "        self.formatter = AgentFormatter(sp=sp, fse=fse)\n",
    "        print(\"ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ä¸­\")\n",
    "        model_config = get_config_for_2b()\n",
    "        model_config.tokenizer = WEIGHTS_PATH + '/tokenizer.model'\n",
    "        with _set_default_tensor_type(model_config.get_dtype()):\n",
    "            model = GemmaForCausalLM(model_config)\n",
    "            model.load_weights(WEIGHTS_PATH + '/gemma-2b-it.ckpt')\n",
    "            self.model = model.to(self._device).eval()\n",
    "            \n",
    "    def __call__(self, obs, *args):\n",
    "        self._start_session(obs)\n",
    "        prompt = str(self.formatter)\n",
    "        response = self._call_llm(prompt)\n",
    "        response = self._parse_response(response, obs)\n",
    "        print(obs.turnType, response)\n",
    "        return response\n",
    "    \n",
    "    def _call_llm(self, prompt, max_nt=40, **sampler_kwargs):\n",
    "        if sampler_kwargs is None:\n",
    "            sampler_kwargs = {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50,}\n",
    "        response = self.model.generate(\n",
    "            prompt, device=self._device, output_len=max_nt, **sampler_kwargs,)\n",
    "        return response\n",
    "    \n",
    "    def _parse_keyword(self, response: str):\n",
    "        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response) #ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã§æœ€ã‚‚è¿‘ã„ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€æ­£è¦è¡¨ç¾ã‚’æ›´æ–°ã™ã‚‹\n",
    "        if match is None: keyword = ''\n",
    "        else: keyword = match.group().lower()\n",
    "        return keyword\n",
    "    \n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))\n",
    "            if match is None: question = \"Is it a place?\" #äººç‰©ã€å ´æ‰€ã€ç‰©ã®ãƒ©ãƒ³ãƒ€ãƒ ãªé¸æŠã‚’ã™ã‚‹\n",
    "            else: question = match.group()\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"no guess\" #ãƒ©ãƒ³ãƒ€ãƒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼Ÿ\n",
    "            else: \n",
    "                return guess\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)\n",
    "            return 'yes' if 'yes' in answer else 'no'\n",
    "        else: raise ValueError(\"ä¸æ˜ãªã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—:\", obs.turnType)\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    return [item for pair in itertools.zip_longest(x, y) for item in pair if item is not None]\n",
    "\n",
    "class QuestionerAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()\n",
    "        self.formatter.user(\"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã§è³ªå•è€…ã®å½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚\")\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)\n",
    "        self.formatter.apply_turns(turns, start_agent='model')\n",
    "        if obs.turnType == 'ask':\n",
    "            self.formatter.user(\"ã‚ãªãŸã®ã‚¿ãƒ¼ãƒ³ã¯ã€äººç‰©ã€å ´æ‰€ã€ç‰©ã‚’æ¢ã™ãŸã‚ã«ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã§å°‹ã­ã‚‹ã“ã¨ã§ã™ã€‚\")\n",
    "        elif obs.turnType == 'guess':\n",
    "            self.formatter.user(\"ã‚ãªãŸã®ã‚¿ãƒ¼ãƒ³ã¯ã€äººç‰©ã€å ´æ‰€ã€ç‰©ã‚’æ¨æ¸¬ã™ã‚‹ã“ã¨ã§ã™ã€‚æ¨æ¸¬ã‚’äºŒé‡ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã§å›²ã„ã€**yes**ã¾ãŸã¯**no**ã¨ã—ã¦ãã ã•ã„ã€‚\")\n",
    "\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))\n",
    "            if match is None: question = \"Is it a place?\" #äººç‰©ã€å ´æ‰€ã€ç‰©ã®ãƒ©ãƒ³ãƒ€ãƒ ãªé¸æŠã‚’ã™ã‚‹\n",
    "            else: question = match.group()\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"no guess\" \n",
    "            else: \n",
    "                return guess\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)\n",
    "            return 'yes' if 'yes' in answer else 'no'\n",
    "        else: raise ValueError(\"ä¸æ˜ãªã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—:\", obs.turnType)\n",
    "\n",
    "class AnswererAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()\n",
    "        self.formatter.user(f\"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã§å›ç­”è€…ã®å½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯{obs.keyword}ã§ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯{obs.category}ã§ã™ã€‚\")\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)\n",
    "        self.formatter.apply_turns(turns, start_agent='user')\n",
    "        self.formatter.user(f\"è³ªå•ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{obs.keyword}ã«ã¤ã„ã¦ã§ã€ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯{obs.category}ã§ã™ã€‚ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã¨ç­”ãˆã€äºŒé‡ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã§å›²ã‚“ã§ãã ã•ã„ï¼ˆä¾‹ï¼š**yes**ã¾ãŸã¯**no**ï¼‰.\")\n",
    "\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        answer = self._parse_keyword(response)\n",
    "        return 'yes' if 'yes' in answer else 'no'\n",
    "\n",
    "sp = \"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚²ãƒ¼ãƒ ã§ã¯ã€å›ç­”è€…ãŒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è€ƒãˆã€ãã®å¾Œè³ªå•è€…ã®ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã®è³ªå•ã«ç­”ãˆã¾ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ç‰¹å®šã®äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã§ã™ã€‚\"\n",
    "fse = [\n",
    "    \"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã§è³ªå•è€…ã®å½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚æœ€åˆã®è³ªå•ã‚’ã—ã¦ã€äººç‰©ã€å ´æ‰€ã€ç‰©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„ã€‚\",\n",
    "    \"ãã‚Œã¯äººç‰©ã§ã™ã‹ï¼Ÿ\", \"**no**\",\n",
    "    \"ãã‚Œã¯å ´æ‰€ã§ã™ã‹ï¼Ÿ\", \"**yes**\",\n",
    "    \"ãã‚Œã¯å›½ã§ã™ã‹ï¼Ÿ\", \"**yes** ã•ã¦ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ¨æ¸¬ã—ã¦ãã ã•ã„ã€‚\",\n",
    "    \"**ãƒ•ãƒ©ãƒ³ã‚¹**\", \"æ­£è§£!\",\n",
    "]\n",
    "agent = None\n",
    "\n",
    "def get_agent(name: str):\n",
    "    global agent\n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = QuestionerAgent(sp=sp, fse=fse,)\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = AnswererAgent(sp=sp, fse=fse,)\n",
    "    assert agent is not None, \"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\"\n",
    "    return agent\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = get_agent('questioner')(obs)\n",
    "    elif obs.turnType == \"guess\": response = get_agent('questioner')(obs)\n",
    "    elif obs.turnType == \"answer\": response = get_agent('answerer')(obs)\n",
    "    \n",
    "    if response is None or len(response) <= 1: return \"no\" #ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’å¤‰æ›´\n",
    "    else: return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa9e84b",
   "metadata": {},
   "source": [
    "# ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:59.550248Z",
     "iopub.status.busy": "2024-06-08T05:46:59.549885Z",
     "iopub.status.idle": "2024-06-08T05:47:27.472893Z",
     "shell.execute_reply": "2024-06-08T05:47:27.471795Z",
     "shell.execute_reply.started": "2024-06-08T05:46:59.550223Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pygame\n",
    "!pip install -q 'kaggle_environments>=1.14.8'  # æ–°ã—ã„ç’°å¢ƒå‘ã‘ã«Kaggleç’°å¢ƒã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:00.453764Z",
     "iopub.status.busy": "2024-06-08T05:51:00.453414Z",
     "iopub.status.idle": "2024-06-08T05:51:00.463462Z",
     "shell.execute_reply": "2024-06-08T05:51:00.462658Z",
     "shell.execute_reply.started": "2024-06-08T05:51:00.453736Z"
    }
   },
   "outputs": [],
   "source": [
    "# ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã™\n",
    "%run submission/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:03.119441Z",
     "iopub.status.busy": "2024-06-08T05:51:03.119068Z",
     "iopub.status.idle": "2024-06-08T05:51:53.374014Z",
     "shell.execute_reply": "2024-06-08T05:51:53.372967Z",
     "shell.execute_reply.started": "2024-06-08T05:51:03.119415Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "\n",
    "# Kaggleç’°å¢ƒã‚’ä½œæˆã—ã¾ã™\n",
    "env = make(\"llm_20_questions\", debug=True)\n",
    "agent = \"/kaggle/working/submission/main.py\"\n",
    "\n",
    "# ç’°å¢ƒã‚’ãƒªã‚»ãƒƒãƒˆã—ã¾ã™\n",
    "env.reset()\n",
    "# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½¿ã£ã¦ç’°å¢ƒã‚’å®Ÿè¡Œã—ã¾ã™\n",
    "logs = env.run([agent, agent, agent, agent])\n",
    "# while not env.done: # ãƒ†ã‚¹ãƒˆç”¨ã«è¿½åŠ ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã“ã“ã«å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã¾ã™\n",
    "# ç’°å¢ƒã®çµæœã‚’è¡¨ç¤ºã—ã¾ã™\n",
    "env.render(mode=\"ipython\", width=800, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12184e5",
   "metadata": {},
   "source": [
    "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.852949Z",
     "iopub.status.idle": "2024-06-08T05:46:34.85337Z",
     "shell.execute_reply": "2024-06-08T05:46:34.853168Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.85315Z"
    },
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv > /dev/null  # pigzã¨pvã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.854563Z",
     "iopub.status.idle": "2024-06-08T05:46:34.855024Z",
     "shell.execute_reply": "2024-06-08T05:46:34.854796Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.854777Z"
    },
    "papermill": {
     "duration": 148.240766,
     "end_time": "2024-04-17T13:50:23.136669",
     "exception": false,
     "start_time": "2024-04-17T13:47:54.895903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/2b-it/2  # submissionãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åœ§ç¸®ã—ã¦tar.gzãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6fbb1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ã‚³ãƒ¡ãƒ³ãƒˆ \n",
    "\n",
    "> ## DataDiva007\n",
    "> \n",
    "> ã“ã“ã§ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚€ã®ãŒã™ã”ãä¸­æ¯’çš„ã§ã™ã€‚ã¨ã¦ã‚‚æ¥½ã—ã„æ™‚é–“ã‚’éã”ã—ã¦ã„ã¾ã™ï¼\n",
    "> \n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## SuM\n",
    "> \n",
    "> ç´ æ™´ã‚‰ã—ã„ä»•äº‹ã§ã™ã­ [@jazivxt](https://www.kaggle.com/jazivxt)ğŸ‰\n",
    "> \n",
    "> å…±æœ‰ã—ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã€ã‚¹ã‚¿ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸ãˆã¦ãã‚Œã¾ã™ğŸ˜ƒ\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Neel Patel\n",
    "> \n",
    "> ã™ã”ã„ä»•äº‹ã§ã™ã­ã€æå‡ºå‰ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã®ã«éå¸¸ã«å½¹ç«‹ã¡ã¾ã™ã€‚ :)\n",
    "\n",
    "> \n",
    "---\n",
    "\n",
    "> ## Hassan shahidi\n",
    "> \n",
    "> å„ªã‚ŒãŸãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã™ [@jazivxt](https://www.kaggle.com/jazivxt)\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Prajwal Kanade\n",
    "> \n",
    "> ç´ æ™´ã‚‰ã—ãã€éå¸¸ã«æœ‰ç›Šã§ã™ã€\n",
    "> \n",
    "> å„ªã‚ŒãŸä»•äº‹ã§ã™ [@jazivxt](https://www.kaggle.com/jazivxt) \n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Utkarsh Jain\n",
    "> \n",
    "> èˆˆå‘³æ·±ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯!! ã¨ã¦ã‚‚æ´å¯Ÿã«æº€ã¡ã¦ã„ã¾ã™!!\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## huoyeqianxun\n",
    "> \n",
    "> CUDAã®ãƒ¡ãƒ¢ãƒªä¸è¶³ã®ã‚ˆã†ã§ã™â€¦\n",
    "> \n",
    "> ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§4ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã‹ï¼Ÿï¼Ÿï¼Ÿ\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 5383,
     "sourceId": 11358,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
