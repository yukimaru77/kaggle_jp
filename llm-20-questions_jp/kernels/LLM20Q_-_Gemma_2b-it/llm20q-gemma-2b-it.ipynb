{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80437c2a",
   "metadata": {},
   "source": [
    "# è¦ç´„ \n",
    "ã“ã®Jupyter Notebookã¯ã€ã€Œ20ã®è³ªå•ã€ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã™ã‚‹ãŸã‚ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é–‹ç™ºã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã—ã¦ã„ã¾ã™ã€‚ç‰¹ã«ã€ã‚¿ãƒ¼ãƒ³åˆ¶ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç”¨ã„ã¦ã€äººã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚„æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°æ‰‹æ³•ã‚’æ´»ç”¨ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "### å•é¡Œå®šç¾©\n",
    "- **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ç‰¹å®š**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‹ã‚‰ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒäººã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’ç‰¹å®šã—ã¾ã™ã€‚\n",
    "- **è€ƒãˆã‚‰ã‚Œã‚‹è§£æ±ºç­–**:\n",
    "  - å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’GISãƒ‡ãƒ¼ã‚¿ã‚„è£½å“æƒ…å ±ã¨ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã“ã¨ã§ã€æ­£ç¢ºãªæ¨æ¸¬ã‚’æ”¯æ´ã€‚\n",
    "  - åœ°ç†æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”¨ã„ãŸå ´æ‰€ã®è­˜åˆ¥ã€‚\n",
    "  - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ãŸæ–°ã—ã„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®ææ¡ˆã€‚\n",
    "\n",
    "### ä½¿ç”¨ã•ã‚Œã‚‹æ‰‹æ³•ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "- **Pandas**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç®¡ç†ã€‚\n",
    "- **JSON**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿ã¨ç®¡ç†ã€‚\n",
    "- **Torch**: Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®æ§‹ç¯‰ã€‚\n",
    "- **Kaggle Environments**: ã‚²ãƒ¼ãƒ ç’°å¢ƒã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€‚\n",
    "- **Gemma**: ç‰¹ã«è‡ªç„¶è¨€èªå‡¦ç†ã«ç‰¹åŒ–ã—ãŸå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦ä½¿ç”¨ã€‚\n",
    "\n",
    "### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®è¨­è¨ˆ\n",
    "- **è³ªå•è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®è³ªå•ã‚’ç”Ÿæˆã€‚\n",
    "- **å›ç­”è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**: è³ªå•ã«å¯¾ã—ã¦ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã§å¿œç­”ã€‚\n",
    "- å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯ã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚’è¡Œã„ã€ã‚²ãƒ¼ãƒ ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã«æ²¿ã£ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿç¾ã—ã¾ã™ã€‚\n",
    "\n",
    "### å®Ÿè¡Œã¨ç’°å¢ƒ\n",
    "- ç’°å¢ƒè¨­å®šã‚’è¡Œã„ã€è¤‡æ•°ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’åŒæ™‚ã«å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã‚²ãƒ¼ãƒ ã®é€²è¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã€å„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è¦³å¯Ÿã—ã¾ã™ã€‚\n",
    "\n",
    "ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºã‚„ã‚²ãƒ¼ãƒ AIã®ç ”ç©¶ãªã©ã«ãŠã„ã¦ã€èˆˆå‘³æ·±ã„å¿œç”¨ã‚’æŒã¤ã‚‚ã®ã§ã™ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687fb52",
   "metadata": {},
   "source": [
    "# ç”¨èªæ¦‚èª¬ \n",
    "ä»¥ä¸‹ã«ã€æå‡ºã•ã‚ŒãŸJupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«é–¢é€£ã™ã‚‹å°‚é–€ç”¨èªã«ã¤ã„ã¦ã€åˆå¿ƒè€…ãŒã¤ã¾ãšããã†ãªã‚‚ã®ã®ç°¡å˜ãªè§£èª¬ã‚’ç¤ºã—ã¾ã™ã€‚\n",
    "\n",
    "1. **ã‚¿ãƒ¼ãƒ³åˆ¶**:\n",
    "   - ã‚²ãƒ¼ãƒ ã‚„å¯¾è©±ã®ä¸­ã§ã€ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ãŒé †ç•ªã«è¡Œå‹•ã‚’è¡Œã†å½¢å¼ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€è³ªå•è€…ã¨å›ç­”è€…ãŒäº¤äº’ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¡Œã†ã€Œ20ã®è³ªå•ã€ã‚²ãƒ¼ãƒ ã®é€²è¡Œæ–¹æ³•ã‚’æŒ‡ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "2. **GISåº§æ¨™**:\n",
    "   - åœ°ç†æƒ…å ±ã‚·ã‚¹ãƒ†ãƒ ï¼ˆGISï¼‰ã§ä½¿ç”¨ã•ã‚Œã‚‹åº§æ¨™ã§ã€åœ°çƒä¸Šã®ä½ç½®ã‚’æ•°å€¤çš„ã«è¡¨ç¾ã™ã‚‹ãŸã‚ã®ã‚‚ã®ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€ç·¯åº¦ï¼ˆLatï¼‰ã¨çµŒåº¦ï¼ˆLonï¼‰ã‚’ç”¨ã„ã¦ä½ç½®ã‚’ç‰¹å®šã—ã¾ã™ã€‚\n",
    "\n",
    "3. **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**:\n",
    "   - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦å†èª¿æ•´ã™ã‚‹ã“ã¨ã§ã™ã€‚ç‰¹ã«ã€äº‹å‰å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ï¼ˆã“ã“ã§ã¯ã€è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸã‚²ãƒ¼ãƒ ï¼‰ã«é©å¿œã•ã›ã‚‹ãŸã‚ã«è¡Œã„ã¾ã™ã€‚\n",
    "\n",
    "4. **ãƒˆãƒ¼ã‚¯ãƒ³**:\n",
    "   - è‡ªç„¶è¨€èªå‡¦ç†ã«ãŠã„ã¦ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ„å‘³ã®ã‚ã‚‹å˜ä½ã«åˆ†å‰²ã—ãŸã‚‚ã®ã§ã™ã€‚å˜èªã‚„ã‚µãƒ–ãƒ¯ãƒ¼ãƒ‰ãªã©ãŒå«ã¾ã‚Œã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ãŒç†è§£å¯èƒ½ãªå½¢å¼ã«ã™ã‚‹ãŸã‚ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã§ã™ã€‚\n",
    "\n",
    "5. **é€†å¼•ãã®éç›£è¦–ãƒ¢ãƒ‡ãƒ«**:\n",
    "   - ãƒ©ãƒ™ãƒ«ãªã—ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦å­¦ç¿’ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã€ç‰¹å®šã®å‡ºåŠ›ã‚’ç¤ºã•ãªã„ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´ã‚„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡ºã—ã€æ¨æ¸¬ã‚’è¡Œã„ã¾ã™ã€‚é€†å¼•ãã¨ã¯ã€å…¥åŠ›ã‹ã‚‰å‡ºåŠ›ã‚’æ¨æ¸¬ã™ã‚‹ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚\n",
    "\n",
    "6. **Few-shot learning**:\n",
    "   - é™ã‚‰ã‚ŒãŸå­¦ç¿’ä¾‹ï¼ˆæ•°ä¾‹ï¼‰ã‹ã‚‰ä¸€èˆ¬åŒ–ã™ã‚‹èƒ½åŠ›ã‚’æŒã¤ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ä¸€éƒ¨ã®ä¾‹ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ¨è«–ã‚’åŠ©ã‘ã‚‹æ–¹æ³•ãŒç¤ºã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "7. **ã‚¤ã‚¨ã‚¹ã¾ãŸã¯ãƒãƒ¼ã®è³ªå•**:\n",
    "   - 2ã¤ã®é¸æŠè‚¢ï¼ˆã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ï¼‰ã‹ã‚‰ç­”ãˆã‚‹å½¢å¼ã®è³ªå•ã§ã€ã“ã®å½¢å¼ã¯æ¨æ¸¬ã‚²ãƒ¼ãƒ ã§ä¸€èˆ¬çš„ã§ã™ã€‚\n",
    "\n",
    "8. **ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:\n",
    "   - ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ç”Ÿæˆã•ã‚Œã‚‹å‡ºåŠ›ã®å¤šæ§˜æ€§ã‚„ç‰¹æ€§ã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®è¨­å®šã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€æ¸©åº¦ï¼ˆtemperatureï¼‰ã€ç¢ºç‡ï¼ˆtop_pï¼‰ã€ãŠã‚ˆã³ä¸Šä½kï¼ˆtop_kï¼‰ãŒå«ã¾ã‚Œã¾ã™ã€‚\n",
    "\n",
    "9. **ã‚¬ãƒ¼ãƒ™ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³**:\n",
    "   - ãƒ¡ãƒ¢ãƒªç®¡ç†ã®æ‰‹æ³•ã®ä¸€ã¤ã§ã€ä¸è¦ã«ãªã£ãŸã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è‡ªå‹•çš„ã«å‰Šé™¤ã™ã‚‹ã“ã¨ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã®å‡¦ç†ã«ã‚ˆã‚Šã€ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ã‚’é˜²ãã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "10. **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**:\n",
    "    - ç‰¹å®šã®ã‚¿ã‚¹ã‚¯ã‚„å½¹å‰²ã‚’æŒã£ã¦ã„ã‚‹ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ã‚’æŒ‡ã—ã¾ã™ã€‚ã“ã®å ´åˆã€è³ªå•è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨å›ç­”è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚²ãƒ¼ãƒ ã§ãã‚Œãã‚Œç•°ãªã‚‹å½¹å‰²ã‚’æœãŸã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "ã“ã‚Œã‚‰ã®è§£èª¬ã‚’é€šã˜ã¦ã€åˆå¿ƒè€…ã§ã‚‚ç†è§£ã—ã‚„ã™ãã™ã‚‹ã“ã¨ãŒæ„å›³ã•ã‚Œã¦ã„ã¾ã™ã€‚ã‚‚ã—ä»–ã«ç‰¹å®šã®ç”¨èªã«ã¤ã„ã¦ã®èª¬æ˜ãŒå¿…è¦ã§ã‚ã‚Œã°ã€ãŠçŸ¥ã‚‰ã›ãã ã•ã„ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc63c274",
   "metadata": {},
   "source": [
    "## å•é¡Œå®šç¾©:\n",
    "ã‚¿ãƒ¼ãƒ³åˆ¶ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¦ã€Œ20ã®è³ªå•ã€ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ãªãŒã‚‰ã€ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ãƒªã‚¹ãƒˆã‹ã‚‰äººã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ã€å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯æ–°ã—ã„ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "è€ƒãˆã‚‰ã‚Œã‚‹è§£æ±ºç­–:\n",
    "\n",
    "* å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’ã€å†™çœŸã‹ã‚‰ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚„éƒ½å¸‚ã®GISåº§æ¨™ä¸­å¿ƒç‚¹ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€å›½ã€éƒ½å¸‚ã€å·ã€ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®æ¨æ¸¬ã‚’ã‚ˆã‚Šé©åˆ‡ã«åˆã‚ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "* GISåº§æ¨™ã‚’ä½¿ç”¨ã—ãŸé›»è©±ã®ãƒ†ã‚­ã‚¹ãƒˆä¼šè©±ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ã€å ´æ‰€ã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã§ãã€è¨€èªã€ç‰¹å®šã®ä¼šè©±ãƒ‘ã‚¿ãƒ¼ãƒ³ã€ã¾ãŸã¯ä¿—èªã®åœ°åŸŸæ€§ã‚’è­˜åˆ¥ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "* ç‰©ã«ã¤ã„ã¦ã¯ã€è£½å“èª¬æ˜ã‚„è£½å“ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒä½¿ç”¨å¯èƒ½ã§ã™ã€‚\n",
    "\n",
    "* äººã«ã¤ã„ã¦ã¯ã€ã‚¦ã‚£ã‚­ãƒšãƒ‡ã‚£ã‚¢ã‚„LinkedInã€å‡ºä¼šã„ç³»ã‚µã‚¤ãƒˆãªã©ã®ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚­ãƒ³ã‚°ãŒåˆ©ç”¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "* ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãªã—ã®ä»–ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã—ã¦ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³ã‚’è­˜åˆ¥ã—ã¦ã€Œ20ã®è³ªå•ã€ã®ç¯„å›²å†…ã§ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«è¿…é€Ÿã«åˆ°é”ã™ã‚‹ãŸã‚ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’è¡Œã†å„ªã‚ŒãŸæ¤œç´¢ä¿¡å·ã‚’ç”Ÿã¿å‡ºã™ã“ã¨ãŒè€ƒãˆã‚‰ã‚Œã¾ã™ã€‚ã“ã‚Œã«åŸºã¥ã„ã¦ã€ç¾åœ¨ã®ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚„åŸ‹ã‚è¾¼ã¿ã‚’ä½¿ç”¨ã—ãŸé€†å¼•ãã®éç›£è¦–ãƒ¢ãƒ‡ãƒ«ãŒå¯èƒ½ã§ã™ã€‚\n",
    "\n",
    "ä¾‹:\n",
    "* https://www.cia.gov/the-world-factbook/\n",
    "* https://public-nps.opendata.arcgis.com/datasets/nps::national-register-of-historic-places-points/explore\n",
    "\n",
    "\n",
    "## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.924486Z",
     "iopub.status.busy": "2024-06-08T05:46:22.924097Z",
     "iopub.status.idle": "2024-06-08T05:46:22.973208Z",
     "shell.execute_reply": "2024-06-08T05:46:22.972092Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.924455Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "keywords = SourceFileLoader(\"keywords\",'/kaggle/input/llm-20-questions/llm_20_questions/keywords.py').load_module()\n",
    "df = json.loads(keywords.KEYWORDS_JSON)\n",
    "words = []\n",
    "for c in df:\n",
    "    print(c['category'], len(c['words']))\n",
    "    for w in c['words']:\n",
    "        words.append([c['category'], w[\"keyword\"], w[\"alts\"], \"\", \"\", 0.0, 0.0])\n",
    "df = pd.DataFrame(words, columns=['Category','Word','Alternatives', \"Cat1\", \"Cat2\", \"Lat\", \"Lon\"])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e6c33",
   "metadata": {},
   "source": [
    "## ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ\n",
    "* https://www.promptingguide.ai/models/gemma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.975677Z",
     "iopub.status.busy": "2024-06-08T05:46:22.975345Z",
     "iopub.status.idle": "2024-06-08T05:46:22.981114Z",
     "shell.execute_reply": "2024-06-08T05:46:22.980268Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.975647Z"
    }
   },
   "outputs": [],
   "source": [
    "template_special_tokens = ['<bos>','<start_of_turn>user','<start_of_turn>model','<end_of_turn>','<eos>']\n",
    "#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ1 - æ¨æ¸¬è€…ï¼ˆãƒ¢ãƒ‡ãƒ«ï¼Ÿï¼‰\n",
    "#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ2 - å›ç­”è€…ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼Ÿï¼‰\n",
    "#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ3 - æ¨æ¸¬è€…ï¼ˆãƒ¢ãƒ‡ãƒ«ï¼Ÿï¼‰\n",
    "#ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ4 - å›ç­”è€…ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ï¼Ÿï¼‰\n",
    "\n",
    "def agentx(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"\"  # è³ªå•ã®éš›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆæœŸåŒ–\n",
    "    elif obs.turnType == \"guess\": response = \"\"  # æ¨æ¸¬ã®éš›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆæœŸåŒ–\n",
    "    elif obs.turnType == \"answer\": response = \"\"  # å›ç­”ã®éš›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’åˆæœŸåŒ–\n",
    "    else: response = \"ç§ã¯å¹»è¦šã‚’è¦‹ã¦ã„ã¾ã™ã‹ï¼Ÿ **ã¯ã„**\"  # ä¸æ˜ãªã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã¸ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d9833",
   "metadata": {},
   "source": [
    "## 20ã®è³ªå•æå‡ºãƒ¢ãƒ‡ãƒ«\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.982593Z",
     "iopub.status.busy": "2024-06-08T05:46:22.982319Z",
     "iopub.status.idle": "2024-06-08T05:46:34.844839Z",
     "shell.execute_reply": "2024-06-08T05:46:34.842919Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.982569Z"
    },
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece  # å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null  # Gemmaã®PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³\n",
    "mkdir /kaggle/working/submission/lib/gemma/  # Gemmaç”¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/  # Gemmaã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:50:54.946487Z",
     "iopub.status.busy": "2024-06-08T05:50:54.945851Z",
     "iopub.status.idle": "2024-06-08T05:50:54.9574Z",
     "shell.execute_reply": "2024-06-08T05:50:54.956464Z",
     "shell.execute_reply.started": "2024-06-08T05:50:54.946445Z"
    },
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile submission/main.py\n",
    "\n",
    "import torch, itertools, contextlib\n",
    "import os, sys, re, gc\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "gc.enable()  # ã‚¬ãƒ¼ãƒ™ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’æœ‰åŠ¹ã«ã™ã‚‹\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"  # Kaggleã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ‘ã‚¹è¨­å®š\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))  # Kaggleã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/2b-it/2\")  # é‡ã¿ã®ãƒ‘ã‚¹è¨­å®š\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒ‘ã‚¹ã«è¿½åŠ \n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\"  # é‡ã¿ã®ãƒ‘ã‚¹è¨­å®š\n",
    "\n",
    "from gemma.config import get_config_for_2b  # Gemmaã®è¨­å®šã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "from gemma.model import GemmaForCausalLM  # Gemmaãƒ¢ãƒ‡ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "# ã‚²ãƒ¼ãƒ ã®å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã«ã€ã‚ªãƒ¼ãƒ—ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦å‡ç¸®ãƒ»è£œå®Œã™ã‚‹ã“ã¨ãŒã§ãã‚‹ï¼ˆopen('gamemaster.dat'), open('player.dat')ï¼‰\n",
    "class AgentFormatter:\n",
    "    def __init__(self, sp: str = None, fse: Iterable = None):\n",
    "        self._system_prompt = sp  # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®åˆæœŸåŒ–\n",
    "        self._few_shot_examples = fse  # Few-shotã®ä¾‹ã®åˆæœŸåŒ–\n",
    "        self._turn_user = f\"<start_of_turn>user\\n{{}}<end_of_turn>\\n\"  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¿ãƒ¼ãƒ³å½¢å¼\n",
    "        self._turn_model = f\"<start_of_turn>model\\n{{}}<end_of_turn>\\n\"  # ãƒ¢ãƒ‡ãƒ«ã®ã‚¿ãƒ¼ãƒ³å½¢å¼\n",
    "        self.reset()  # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
    "    def __repr__(self):\n",
    "        return self._state  # ç¾åœ¨ã®çŠ¶æ…‹ã‚’è¡¨ç¤º\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ›ã‚’è¿½åŠ \n",
    "        return self\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)  # ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®å…¥åŠ›ã‚’è¿½åŠ \n",
    "        return self\n",
    "    def reset(self):\n",
    "        self._state = \"\"  # çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)  # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒã‚ã‚‹å ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦è¿½åŠ \n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')  # Few-shotã®ä¾‹ã‚’è¿½åŠ \n",
    "        return self\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]  # ã‚¿ãƒ¼ãƒ³ã®é †ç•ªã‚’æ±ºå®š\n",
    "        formatters = itertools.cycle(formatters)  # é †ç•ªã«ã‚µã‚¤ã‚¯ãƒ«ã™ã‚‹\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)  # å„ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨\n",
    "        return self\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    torch.set_default_dtype(dtype)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ã‚½ãƒ«å‹ã‚’è¨­å®š\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’æˆ»ã™\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sp=None, fse=None):\n",
    "        self._device = torch.device('cuda:0')  # CUDAãƒ‡ãƒã‚¤ã‚¹ã‚’æŒ‡å®š\n",
    "        self.formatter = AgentFormatter(sp=sp, fse=fse)  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã®åˆæœŸåŒ–\n",
    "        print(\"ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ä¸­\")\n",
    "        model_config = get_config_for_2b()  # ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šã‚’å–å¾—\n",
    "        model_config.tokenizer = WEIGHTS_PATH + '/tokenizer.model'  # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ã®ãƒ‘ã‚¹ã‚’è¨­å®š\n",
    "        with _set_default_tensor_type(model_config.get_dtype()):  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ã‚½ãƒ«å‹ã‚’è¨­å®š\n",
    "            model = GemmaForCausalLM(model_config)  # Gemmaã®ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–\n",
    "            model.load_weights(WEIGHTS_PATH + '/gemma-2b-it.ckpt')  # é‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "            self.model = model.to(self._device).eval()  # ãƒ‡ãƒã‚¤ã‚¹ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®šã—è©•ä¾¡ãƒ¢ãƒ¼ãƒ‰ã«\n",
    "    def __call__(self, obs, *args):\n",
    "        self._start_session(obs)  # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹\n",
    "        prompt = str(self.formatter)  # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—\n",
    "        response = self._call_llm(prompt)  # LLMã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ¸¡ã—ã¦ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—\n",
    "        response = self._parse_response(response, obs)  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "        print(obs.turnType, response)  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¡¨ç¤º\n",
    "        return response\n",
    "    def _call_llm(self, prompt, max_nt=40, **sampler_kwargs):\n",
    "        if sampler_kwargs is None:\n",
    "            sampler_kwargs = {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50,}  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "        response = self.model.generate(\n",
    "            prompt, device=self._device, output_len=max_nt, **sampler_kwargs,)  # ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ\n",
    "        return response\n",
    "    def _parse_keyword(self, response: str):\n",
    "        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)  # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒªã‚¹ãƒˆã‹ã‚‰æœ€ã‚‚è¿‘ã„ä¸€è‡´ã‚’ãƒã‚§ãƒƒã‚¯\n",
    "        if match is None: keyword = ''\n",
    "        else: keyword = match.group().lower()  # ä¸€è‡´ã™ã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å°æ–‡å­—ã«å¤‰æ›\n",
    "        return keyword\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # è³ªå•å½¢å¼ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            if match is None: question = \"ãã‚Œã¯å ´æ‰€ã§ã™ã‹ï¼Ÿ\"  # è³ªå•ãŒãªã„å ´åˆ\n",
    "            else: question = match.group()  # è³ªå•ã‚’è¨­å®š\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # æ¨æ¸¬ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"æ¨æ¸¬ãªã—\"  # æ¨æ¸¬ã§ããªã„å ´åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹\n",
    "            else: \n",
    "                return guess  # æ¨æ¸¬ã‚’è¿”ã™\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # ç­”ãˆã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            return 'ã¯ã„' if 'ã¯ã„' in answer else 'ã„ã„ãˆ'  # ã€Œã¯ã„ã€ã¾ãŸã¯ã€Œã„ã„ãˆã€ã‚’è¿”ã™\n",
    "        else: raise ValueError(\"æœªçŸ¥ã®ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—:\", obs.turnType)  # ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    return [item for pair in itertools.zip_longest(x, y) for item in pair if item is not None]  # ä¸å‡ç­‰ãªãƒªã‚¹ãƒˆã‚’äº¤äº’ã«çµåˆã™ã‚‹é–¢æ•°\n",
    "\n",
    "class QuestionerAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
    "        self.formatter.user(\"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã®è³ªå•è€…ã¨ã—ã¦ãƒ—ãƒ¬ã‚¤ã—ã¦ã„ã¾ã™ã€‚\")  # è³ªå•è€…ã¨ã—ã¦ã®åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # è³ªå•ã¨å›ç­”ã‚’äº¤äº’ã«å–ã‚Šå‡ºã™\n",
    "        self.formatter.apply_turns(turns, start_agent='model')  # ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨\n",
    "        if obs.turnType == 'ask':\n",
    "            self.formatter.user(\"ã‚ãªãŸã¯ã€äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«ã‚¤ã‚¨ã‚¹ã¾ãŸã¯ãƒãƒ¼ã®è³ªå•ã‚’ã™ã‚‹ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚\")  # è³ªå•ã®ã‚¿ãƒ¼ãƒ³\n",
    "        elif obs.turnType == 'guess':\n",
    "            self.formatter.user(\"ã‚ãªãŸã¯äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã‚’æ¨æ¸¬ã™ã‚‹ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚æ¨æ¸¬ã‚’ã€Œ**ã‚‚ã®**ã€ã®ã‚ˆã†ã«äºŒé‡ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã§å›²ã‚“ã§ãã ã•ã„ã€‚\")  # æ¨æ¸¬ã®ã‚¿ãƒ¼ãƒ³\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # è³ªå•ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            if match is None: question = \"ãã‚Œã¯å ´æ‰€ã§ã™ã‹ï¼Ÿ\"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè³ªå•\n",
    "            else: question = match.group()  # è³ªå•ã‚’å–å¾—\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # æ¨æ¸¬ã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"æ¨æ¸¬ãªã—\" \n",
    "            else: \n",
    "                return guess  # æ¨æ¸¬ã‚’è¿”ã™\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # ç­”ãˆã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "            return 'ã¯ã„' if 'ã¯ã„' in answer else 'ã„ã„ãˆ'  # ç­”ãˆã‚’è¿”ã™\n",
    "        else: raise ValueError(\"æœªçŸ¥ã®ã‚¿ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—:\", obs.turnType)  # ã‚¨ãƒ©ãƒ¼å‡¦ç†\n",
    "\n",
    "class AnswererAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # è¦ªã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ã‚’ãƒªã‚»ãƒƒãƒˆ\n",
    "        self.formatter.user(f\"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã®å›ç­”è€…ã¨ã—ã¦ãƒ—ãƒ¬ã‚¤ã—ã¦ã„ã¾ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯{obs.keyword}ã§ã€ã‚«ãƒ†ã‚´ãƒªã¯{obs.category}ã§ã™ã€‚\")  # åˆæœŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # ã‚¿ãƒ¼ãƒ³ã‚’äº¤äº’ã«é©ç”¨\n",
    "        self.formatter.apply_turns(turns, start_agent='user')  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¿ãƒ¼ãƒ³ã‚’é©ç”¨\n",
    "        self.formatter.user(f\"è³ªå•ã¯ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰{obs.keyword}ã«ã¤ã„ã¦ã€ã‚«ãƒ†ã‚´ãƒªã¯{obs.category}ã§ã™ã€‚ã‚¤ã‚¨ã‚¹ã¾ãŸã¯ãƒãƒ¼ã§ç­”ãˆã€ç­”ãˆã‚’äºŒé‡ã‚¢ã‚¹ã‚¿ãƒªã‚¹ã‚¯ã§å›²ã‚“ã§ãã ã•ã„ã€‚\")  # è³ªå•ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        answer = self._parse_keyword(response)  # ç­”ãˆã‚’ãƒ‘ãƒ¼ã‚¹\n",
    "        return 'ã¯ã„' if 'ã¯ã„' in answer else 'ã„ã„ãˆ'  # ç­”ãˆã‚’è¿”ã™\n",
    "\n",
    "sp = \"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã‚’ãƒ—ãƒ¬ã‚¤ã—ã¦ã„ã¾ã™ã€‚ã“ã®ã‚²ãƒ¼ãƒ ã§ã¯ã€å›ç­”è€…ãŒã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è€ƒãˆã€è³ªå•è€…ãŒã‚¤ã‚¨ã‚¹ã¾ãŸã¯ãƒãƒ¼ã®è³ªå•ã‚’ã—ã¾ã™ã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯ç‰¹å®šã®äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã§ã™ã€‚\"\n",
    "fse = [\n",
    "    \"ã‚ãªãŸã¯20ã®è³ªå•ã‚²ãƒ¼ãƒ ã®è³ªå•è€…ã¨ã—ã¦ãƒ—ãƒ¬ã‚¤ã—ã¦ã„ã¾ã™ã€‚äººç‰©ã€å ´æ‰€ã€ã¾ãŸã¯ç‰©ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã«æœ€åˆã®è³ªå•ã‚’ã—ã¦ãã ã•ã„ã€‚\",\n",
    "    \"ã“ã‚Œã¯äººç‰©ã§ã™ã‹ï¼Ÿ\", \"**ã„ã„ãˆ**\",\n",
    "    \"ã“ã‚Œã¯å ´æ‰€ã§ã™ã‹ï¼Ÿ\", \"**ã¯ã„**\",\n",
    "    \"ã“ã‚Œã¯å›½ã§ã™ã‹ï¼Ÿ\", \"**ã¯ã„** æ¨æ¸¬ã—ã¦ã¿ã¦ãã ã•ã„ã€‚\",\n",
    "    \"**ãƒ•ãƒ©ãƒ³ã‚¹**\", \"æ­£è§£ã§ã™ï¼\",\n",
    "]\n",
    "agent = None\n",
    "\n",
    "def get_agent(name: str):\n",
    "    global agent\n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = QuestionerAgent(sp=sp, fse=fse,)  # è³ªå•è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = AnswererAgent(sp=sp, fse=fse,)  # å›ç­”è€…ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–\n",
    "    assert agent is not None, \"ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\"  # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®åˆæœŸåŒ–ç¢ºèª\n",
    "    return agent\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = get_agent('questioner')(obs)  # è³ªå•ã®ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–å¾—\n",
    "    elif obs.turnType == \"guess\": response = get_agent('questioner')(obs)  # æ¨æ¸¬ã®ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–å¾—\n",
    "    elif obs.turnType == \"answer\": response = get_agent('answerer')(obs)  # å›ç­”ã®ã‚¿ãƒ¼ãƒ³ã«å¿œã˜ãŸã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å–å¾—\n",
    "    \n",
    "    if response is None or len(response) <= 1: return \"ã„ã„ãˆ\"  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒä¸æ˜ã¾ãŸã¯çŸ­ã„å ´åˆ\n",
    "    else: return response  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb59094",
   "metadata": {},
   "source": [
    "# ãƒ†ã‚¹ãƒˆ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:59.550248Z",
     "iopub.status.busy": "2024-06-08T05:46:59.549885Z",
     "iopub.status.idle": "2024-06-08T05:47:27.472893Z",
     "shell.execute_reply": "2024-06-08T05:47:27.471795Z",
     "shell.execute_reply.started": "2024-06-08T05:46:59.550223Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pygame  # pygameã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "!pip install -q 'kaggle_environments>=1.14.8'  # Kaggleç’°å¢ƒã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:00.453764Z",
     "iopub.status.busy": "2024-06-08T05:51:00.453414Z",
     "iopub.status.idle": "2024-06-08T05:51:00.463462Z",
     "shell.execute_reply": "2024-06-08T05:51:00.462658Z",
     "shell.execute_reply.started": "2024-06-08T05:51:00.453736Z"
    }
   },
   "outputs": [],
   "source": [
    "#ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ\n",
    "%run submission/main.py  # ãƒ¡ã‚¤ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:03.119441Z",
     "iopub.status.busy": "2024-06-08T05:51:03.119068Z",
     "iopub.status.idle": "2024-06-08T05:51:53.374014Z",
     "shell.execute_reply": "2024-06-08T05:51:53.372967Z",
     "shell.execute_reply.started": "2024-06-08T05:51:03.119415Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make  # Kaggleç’°å¢ƒã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "env = make(\"llm_20_questions\", debug=True)  # ç’°å¢ƒã‚’ä½œæˆ\n",
    "agent = \"/kaggle/working/submission/main.py\"\n",
    "env.reset()  # ç’°å¢ƒã®ãƒªã‚»ãƒƒãƒˆ\n",
    "logs = env.run([agent, agent, agent, agent])  # 4ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œ\n",
    "#while not env.done: #ã“ã“ã«ãƒ†ã‚¹ãƒˆã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è¿½åŠ \n",
    "env.render(mode=\"ipython\", width=800, height=800)  # ç’°å¢ƒã‚’æç”»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ea098",
   "metadata": {},
   "source": [
    "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.852949Z",
     "iopub.status.idle": "2024-06-08T05:46:34.85337Z",
     "shell.execute_reply": "2024-06-08T05:46:34.853168Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.85315Z"
    },
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv > /dev/null  # pigzã¨pvã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.854563Z",
     "iopub.status.idle": "2024-06-08T05:46:34.855024Z",
     "shell.execute_reply": "2024-06-08T05:46:34.854796Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.854777Z"
    },
    "papermill": {
     "duration": 148.240766,
     "end_time": "2024-04-17T13:50:23.136669",
     "exception": false,
     "start_time": "2024-04-17T13:47:54.895903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/2b-it/2  # taråœ§ç¸®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b07104",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ã‚³ãƒ¡ãƒ³ãƒˆ \n",
    "\n",
    "> ## DataDiva007\n",
    "> \n",
    "> ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«å–ã‚Šçµ„ã‚€ã“ã¨ã¯ã¨ã¦ã‚‚ä¸­æ¯’æ€§ãŒã‚ã‚Šã€ã“ã“ã«æ¥ã¦ã¨ã¦ã‚‚æ¥½ã—ã„ã§ã™ï¼\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## SuM\n",
    "> \n",
    "> ã™ã°ã‚‰ã—ã„ä»•äº‹ [@jazivxt](https://www.kaggle.com/jazivxt)ğŸ‰\n",
    "> \n",
    "> å…±æœ‰ã—ã¦ãã‚Œã¦ã‚ã‚ŠãŒã¨ã†ã€ã“ã‚Œã¯åˆå¿ƒè€…ã«ã¨ã£ã¦é‡è¦ãªã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¸ãˆã¾ã™ğŸ˜ƒ\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Neel Patel\n",
    "> \n",
    "> ç´ æ™´ã‚‰ã—ã„ä½œæ¥­ã€æå‡ºå‰ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã®ã«éå¸¸ã«å½¹ç«‹ã¡ã¾ã™ã€‚ :)\n",
    "\n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Hassan shahidi\n",
    "> \n",
    "> ç´ æ™´ã‚‰ã—ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ [@jazivxt](https://www.kaggle.com/jazivxt)\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Prajwal Kanade\n",
    "> \n",
    "> ã™ã°ã‚‰ã—ã„æƒ…å ±ã§ã™ã€\n",
    "> \n",
    "> ç´ æ™´ã‚‰ã—ã„ä»•äº‹ [@jazivxt](https://www.kaggle.com/jazivxt) \n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Utkarsh Jain\n",
    "> \n",
    "> èˆˆå‘³æ·±ã„ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼ï¼éå¸¸ã«æ´å¯Ÿã«æº€ã¡ã¦ã„ã¾ã™ï¼ï¼\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## huoyeqianxun\n",
    "> \n",
    "> CUDAã®ãƒ¡ãƒ¢ãƒªä¸è¶³ã®ã‚ˆã†ã§ã™â€¦\n",
    "> \n",
    "> ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§4ã¤ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã‹ï¼Ÿï¼Ÿï¼Ÿ\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 5383,
     "sourceId": 11358,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
