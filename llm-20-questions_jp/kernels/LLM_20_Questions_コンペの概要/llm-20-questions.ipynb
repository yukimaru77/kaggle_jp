{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e742cb5a",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "## Jupyter Notebookの要約\n",
    "\n",
    "このJupyter Notebookは、Kaggleで開催されている「LLM 20 Questions」コンペに関する概要を説明しています。このコンペでは、言語モデル（LLM）を使用して「20の質問」という伝統的なゲームをプレイすることを目指しています。\n",
    "\n",
    "### 取り組む問題\n",
    "- コンペの目的は、プレイヤーがシークレットワードを20回以下の質問で当てるゲームを、LLMを使って実現することです。\n",
    "- プレイヤーはYes/No形式の質問を通じて情報を絞り込み、最終的にシークレットワードを特定することが求められます。\n",
    "\n",
    "### 手法・ライブラリ\n",
    "- コンペは、質問をする「Guesser LLM」と、回答する「Answerer LLM」の2種類のLLMで構成されます。Guesser LLMは質問をし、Answerer LLMは「Yes」または「No」で回答します。\n",
    "- 各チームは対戦形式で活動し、勝者がシークレットワードを先に当てたチームとなります。\n",
    "- ボットの評価は、ガウス分布N(μ,σ^2)を用いてモデル化され、勝敗に応じてスキルレーティングが更新されます。\n",
    "\n",
    "### 評価基準\n",
    "- 毎日最大5つのエージェントを提出可能で、リーダーボード上のスキルレーティングで評価されます。\n",
    "- ペア内で、GuesserとAnswererがランダムに割り当てられ、協力して勝利を目指す形式が取られます。\n",
    "\n",
    "### 終了と賞金\n",
    "- コンペ締切は2024年8月13日で、その後の期間に新しいシークレットワードに対して対戦が行われます。\n",
    "- 上位入賞者には賞金が提供され、1位には12,000ドルが贈られます。\n",
    "\n",
    "このコンペは、LLMの推論能力や効率的な情報収集、ペア間の協力が評価されるものであり、創造性と戦略性が求められる挑戦となっています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d74e4c3",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関連した、初心者がつまずきそうな専門用語の簡単な解説を示します。特に、マイナーな用語や実務経験が必要で馴染みのないものに焦点を当てています。\n",
    "\n",
    "1. **LLM (Large Language Model)**:\n",
    "   - 大規模なデータセットで訓練された自然言語処理モデルのこと。多くのパラメータを持ち、複雑な文脈理解や生成が可能。\n",
    "\n",
    "2. **Guesser LLM**:\n",
    "   - ゲームの中で質問を作成し、シークレットワードを推測する役割を持つ言語モデル。質問の内容が成功に大きく影響する。\n",
    "\n",
    "3. **Answerer LLM**:\n",
    "   - Guesserからの質問に「Yes」または「No」で答える役割を持つ言語モデル。正確で一貫した回答が重要となる。\n",
    "\n",
    "4. **スキルレーティング**:\n",
    "   - ボットのパフォーマンスを数値化したもの。対戦結果に基づき、勝利や敗北によって評価が変動する。\n",
    "\n",
    "5. **ガウス分布**:\n",
    "   - 平均と標準偏差で定義される対称的な確率分布。このコンペでは、ボットの推定スキルをモデル化するために使用される。\n",
    "\n",
    "6. **μ (ミュー) とσ (シグマ)**:\n",
    "   - μは平均値で、ボットの推定スキルを表す。一方、σはその評価の不確実性を示す。これらは、ボットのパフォーマンスに基づいて更新される。\n",
    "\n",
    "7. **引き分け**:\n",
    "   - 両方のチームが予想を当てられなかった場合、ゲームの結果を「引き分け」とする。これは、ビジネスやスポーツのルールとも似た概念。\n",
    "\n",
    "8. **非公開のシークレットワード**:\n",
    "   - 最終評価に使用される、新たに与えられる言葉で、通常のゲームで使われた言葉とは異なる。\n",
    "\n",
    "9. **制約された環境**:\n",
    "   - タイムアウトや質問制限など、GAME内でのルールや制限のこと。これにより戦略がさらに重要となる。\n",
    "\n",
    "10. **ペアエージェント**:\n",
    "    - 競技者同士が組になったボット。また、競技が2対2で行われるため、ペアの協力が鍵となる。\n",
    "\n",
    "このような用語は、特に実務を経験していない初心者には馴染みのない可能性があるため、理解しておくことが重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdd007",
   "metadata": {},
   "source": [
    "# LLM 20 Questions コンペの概要\n",
    "\n",
    "Kaggleで開催されている「LLM 20 Questions」コンペは、言語モデル（LLM）を使って伝統的なゲーム「20の質問」をプレイすることを目的としています。\n",
    "\n",
    "## ゲームの説明\n",
    "\n",
    "- 「20の質問」は、シークレットワードを20個以下の質問で当てるゲームです。\n",
    "- プレイヤーはYes/No形式の質問を使って、一般的な質問から具体的な質問へと絞り込んでいきます。\n",
    "- 最終的に、できるだけ少ない質問数でシークレットワードを当てることが目標です。\n",
    "\n",
    "## コンペの形式\n",
    "\n",
    "- 各チームは、質問をする「Guesser LLM」と答える「Answerer LLM」の2つのLLMで構成されます。\n",
    "- Guesser LLMは質問を投げかけ、シークレットワードを推測します。\n",
    "- Answerer LLMは「Yes」または「No」で回答します。\n",
    "- 2つのチームが対戦し、先にシークレットワードを当てたチームが勝利します。\n",
    "\n",
    "## 評価方法\n",
    "\n",
    "- 1日に最大5つのエージェント（ボット）をコンペに提出できます。\n",
    "- 各提出物は、リーダーボード上のスキルレーティングが似ているボットと対戦します。\n",
    "- 勝利でスキルレーティングが上がり、敗北で下がり、引き分けで均等になります。\n",
    "- コンペは協力形式（2対2）で行われ、同じスキルレベルのボットとペアを組みます。\n",
    "- ペア内で一方がGuesser、もう一方がAnswererにランダムに割り当てられます。\n",
    "- ペアで勝敗が決まるため、協力してプレイすることが重要です。\n",
    "\n",
    "## ランキングシステム\n",
    "\n",
    "- 各ボットのスキルレーティングは、ガウス分布N(μ,σ^2)でモデル化されます。\n",
    "- μは推定スキル、σは推定の不確実性を表します。\n",
    "- 対戦結果に基づいて、μとσが更新されます。\n",
    "- 勝利したペアのμは上がり、敗北したペアのμは下がります。\n",
    "- 引き分けの場合、μは平均値に近づきます。\n",
    "\n",
    "## 最終評価\n",
    "\n",
    "- 2024年8月13日の提出締切日に、提出物がロックされます。\n",
    "- 2024年8月13日から8月27日まで、新しい非公開のシークレットワードに対して対戦が行われます。\n",
    "- この期間の終了時に、リーダーボードが最終決定されます。\n",
    "\n",
    "## 賞金\n",
    "\n",
    "- 1位: $12,000\n",
    "- 2位: $10,000\n",
    "- 3位: $10,000\n",
    "- 4位: $10,000\n",
    "- 5位: $8,000\n",
    "\n",
    "このコンペを通じて、LLMの推論能力、効率的な情報収集、ペアエージェント間の協力などの重要なスキルが評価されます。限られた推測回数の中で、創造性と戦略性が求められる挑戦的なコンペとなっています。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
