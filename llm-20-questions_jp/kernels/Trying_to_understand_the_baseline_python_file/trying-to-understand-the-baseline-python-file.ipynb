{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e726322",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookでは、Kaggleの「20の質問」ゲームでのLLM（大規模言語モデル）を利用したエージェントの構築とその実行に関する問題に取り組んでいます。具体的には、ゲームの質問者（guesser agent）と回答者（answerer agent）をモデル化し、ゲームの流れを管理するための関数を定義しています。\n",
    "\n",
    "### 取り組んでいる問題\n",
    "「20の質問」ゲームでは、質問者が特定のキーワードを推測するために、相手に質問をし、得られた回答から推測を行います。このノートブックでは、LLMを用いてゲーム進行中の質問や推測の生成を行い、正確かつ効率的なプレイを目指しています。また、エージェント同士のフィードバックがどのようにゲームの結果に影響を与えるかを考慮することも重要です。\n",
    "\n",
    "### 使用されている手法とライブラリ\n",
    "1. **定数の定義**: ゲームの状態やアクションを表す定数が定義されています。\n",
    "2. **ライブラリのインポート**: \n",
    "   - `torch` - PyTorchライブラリを使用して、機械学習モデルを構築・管理します。\n",
    "   - `transformers` - Hugging Face TransformersライブラリからT5モデルを使用して、質問の生成や推測を行います。\n",
    "   - `pandas` - データ処理や管理に使います。\n",
    "   - `json`、`os`、`random`、`string`など - データの管理や操作のために標準ライブラリを使用しています。\n",
    "\n",
    "3. **エージェントの実装**:\n",
    "   - **guesser_agent**: ゲームの状態やターンに応じた質問や推測を生成する関数。\n",
    "   - **answerer_agent**: 質問に対して「はい」、「いいえ」、または「多分」で応答する関数。\n",
    "\n",
    "4. **ゲームの進行管理**:\n",
    "   - ゲーム状態を管理し、エージェントが交互に質問と回答を行うためのロジックが実装されています。\n",
    "   - 関数には、ターンのインクリメント、ゲームの終了処理、エラー管理などが含まれています。\n",
    "\n",
    "5. **モデルの呼び出し**: `call_llm`関数を通じて、生成モデルにプロンプトを渡し、その応答を受け取る機能を組み込んでいます。事前学習したT5モデルを使用し、GPUまたはCPUで動作します。\n",
    "\n",
    "このように、このノートブックは「20の質問」ゲームのプレイを自動化するLLMベースのエージェントの開発に焦点を当て、必要な技術とライブラリを活用して効率的に問題を解決していくプロセスを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685414c3",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの中で機械学習や深層学習の初心者がつまずきそうな専門用語の解説を列挙します。内容は特にマイナーなものや実務において馴染みが薄いものに焦点を当てています。\n",
    "\n",
    "1. **LLM (Large Language Model)**:\n",
    "   - 大規模言語モデルのことを指し、膨大な量のテキストデータで訓練され、言語理解や生成を行うことができるモデル。特にGPTやT5などが有名。これらのモデルは大量のパラメータを持ち、コンテクストに基づいた応答生成が可能。\n",
    "\n",
    "2. **T5 (Text-to-Text Transfer Transformer)**:\n",
    "   - Googleが開発したユニバーサルなテキストモデルであり、様々なNLPタスクを「テキストをテキストに変換する」問題として扱い、同じアーキテクチャを用いています。質問応答や翻訳、要約など多様な用途に対応しています。\n",
    "\n",
    "3. **トークナイザー (Tokenizer)**:\n",
    "   - テキストデータを数値的な形式に変換するプロセスを行うツール。モデルに入力するために単語や文をトークンという単位に分割し、対応する数値IDに変換します。言語モデルが理解可能な形に整形するための重要なステップ。\n",
    "\n",
    "4. **エピソード (Episode)**:\n",
    "   - ゲーム理論や強化学習において、環境内でエージェントが一連の行動を取る単位を指す。特定の初期状態からスタートして、最終的に終了状態に至るまでの一連のやり取りを含む。\n",
    "\n",
    "5. **状態 (State)**:\n",
    "   - ゲームや強化学習におけるエージェントや環境の現在の状況を指す。各ターンでエージェントが観測する情報を含み、その情報に基づいてアクションを選択します。\n",
    "\n",
    "6. **アクション (Action)**:\n",
    "   - エージェントが行う操作や意思決定を指す。例えば、質問をする、推測する、などの行動がこれに該当します。\n",
    "\n",
    "7. **観察データ (Observation Data)**:\n",
    "   - エージェントが環境から受け取る情報であり、現在の状態や過去の質問と回答から構成されます。エージェントはこのデータを基に次のアクションを選択します。\n",
    "\n",
    "8. **既存データ (Existing Data)**:\n",
    "   - モデルのトレーニングや評価に使用されるデータセットのこと。一般的に、モデルが学ぶための基盤となる参照データを指します。\n",
    "\n",
    "9. **エラートラッキング (Error Tracking)**:\n",
    "   - プログラムやシステムのエラーを特定し、記録するプロセス。特にテストやデバッグの段階で重要な役割を果たす。\n",
    "\n",
    "10. **デバイス (Device)**:\n",
    "    - 使用する計算資源を指し、CPUやGPU（グラフィックプロセッシングユニット）がこれに該当します。特に深層学習のモデルはGPUでの実行が一般的です。\n",
    "\n",
    "11. **タイムアウト (Timeout)**:\n",
    "    - 特定の操作が所定の時間内に完了しない場合に発生するエラー。ゲーム内の行動や応答に制限時間が設けられているシナリオを指します。\n",
    "\n",
    "これらの解説を通して、初心者が「20の質問」ゲームに関するモデルを理解する際の助けになることを目指します。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77392fe6",
   "metadata": {},
   "source": [
    "# ChatGPTの助けを借りてドキュメント化されたコード\n",
    "\n",
    "# 最初の設定\n",
    "実行環境の設定を行い、状態やアクションの定数を定義し、あらかじめ定義されたリストからキーワードとその代替案をランダムに選択することで、「20の質問」ゲームを開始する準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.684101Z",
     "iopub.status.busy": "2024-06-01T17:52:53.683668Z",
     "iopub.status.idle": "2024-06-01T17:52:53.691043Z",
     "shell.execute_reply": "2024-06-01T17:52:53.689454Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.68407Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys  # sysモジュールをインポートします。これは、Pythonインタプリタや環境に関する情報や機能を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.693538Z",
     "iopub.status.busy": "2024-06-01T17:52:53.693159Z",
     "iopub.status.idle": "2024-06-01T17:52:53.722318Z",
     "shell.execute_reply": "2024-06-01T17:52:53.721167Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.693505Z"
    }
   },
   "outputs": [],
   "source": [
    "import json  # JSONデータを扱うためのモジュールをインポートします。\n",
    "import os  # オペレーティングシステムの機能を利用するためのモジュールをインポートします。\n",
    "import pandas as pd  # データ操作と分析のためのpandasライブラリをインポートします。\n",
    "import random  # ランダムな値を生成するためのモジュールをインポートします。\n",
    "import string  # 文字列に関する便利な機能を提供するモジュールをインポートします。\n",
    "import torch  # PyTorchライブラリをインポートします。\n",
    "\n",
    "sys.path.append(\"/kaggle/input/llm-20-questions/llm_20_questions\")  # 特定のディレクトリをPythonパスに追加します。\n",
    "\n",
    "from keywords import KEYWORDS_JSON  # keywordsモジュールからKEYWORDS_JSONをインポートします。\n",
    "from os import path  # pathをosモジュールからインポートします。\n",
    "from pathlib import Path  # Pathをpathlibモジュールからインポートします。\n",
    "from random import choice  # choice関数をrandomモジュールからインポートします。\n",
    "from string import Template  # Templateクラスをstringモジュールからインポートします。\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration  # T5モデルに関連するトークナイザーと生成モデルをインポートします。\n",
    "\n",
    "# モデルやデバイスに関する初期設定\n",
    "llm_parent_dir = \"/kaggle/input/flan-t5/pytorch/large\"  # 使用するモデルの親ディレクトリを指定します。\n",
    "device = None  # デバイス変数を初期化します（後でGPUまたはCPUを選択するため）。\n",
    "model = None  # モデル変数を初期化します。\n",
    "tokenizer = None  # トークナイザー変数を初期化します。\n",
    "model_initialized = False  # モデルが初期化されたかどうかを示すフラグを初期化します。\n",
    "\n",
    "# 定数の定義\n",
    "ERROR = \"ERROR\"  # エラー状態を示す定数を定義します。\n",
    "DONE = \"DONE\"  # 完了状態を示す定数を定義します。\n",
    "INACTIVE = \"INACTIVE\"  # 非アクティブ状態を示す定数を定義します。\n",
    "ACTIVE = \"ACTIVE\"  # アクティブ状態を示す定数を定義します。\n",
    "TIMEOUT = \"TIMEOUT\"  # タイムアウト状態を示す定数を定義します。\n",
    "GUESS = \"guess\"  # 推測アクションを示す定数を定義します。\n",
    "ASK = \"ask\"  # 質問アクションを示す定数を定義します。\n",
    "GUESSER = \"guesser\"  # 推測者を示す定数を定義します。\n",
    "ANSWERER = \"guesser\"  # 回答者を示す定数を定義します。\n",
    "\n",
    "# キーワードリストの取得と選択\n",
    "keywords_list = json.loads(KEYWORDS_JSON)  # JSON形式のキーワードデータをパースしてリストに変換します。\n",
    "keyword_cat = random.choice(keywords_list)  # ランダムにキーワードカテゴリを選択します。\n",
    "category = keyword_cat[\"category\"]  # 選択したカテゴリを取得します。\n",
    "keyword_obj = random.choice(keyword_cat[\"words\"])  # ランダムにキーワードオブジェクトを選択します。\n",
    "keyword = keyword_obj[\"keyword\"]  # 選択したキーワードを取得します。\n",
    "alts = keyword_obj[\"alts\"]  # 選択したキーワードの代替案を取得します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae3e1c9",
   "metadata": {},
   "source": [
    "# 推測者エージェント\n",
    "\n",
    "<i>guesser_agent</i>関数は、現在のゲームの状態とターンの種類に基づいて動的なプロンプトを生成し、言語モデルを使用してゲーム内の次のアクションを生成します。具体的には、以下のような処理を行います。\n",
    "\n",
    "1. これまでの質問と回答の履歴を構築します。\n",
    "2. ターンの種類に基づいて適切なプロンプト（質問または推測）を選択します。\n",
    "3. 構築したプロンプトを使って言語モデルを呼び出し、次のアクションを生成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.724906Z",
     "iopub.status.busy": "2024-06-01T17:52:53.724494Z",
     "iopub.status.idle": "2024-06-01T17:52:53.735145Z",
     "shell.execute_reply": "2024-06-01T17:52:53.733533Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.724837Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_agent(obs):  # 推測者エージェントの関数を定義します。obsは現在の観察データを含む引数です。\n",
    "    info_prompt = \"\"\"あなたは20の質問ゲームをプレイしており、質問をしてキーワード（実在または架空の人物、場所、または物）を推測しようとしています。 \\nこれまでの情報は次のとおりです:\\n{q_a_thread}\"\"\"  # ゲームの進行状況に関する情報を含むプロンプトを定義します。\n",
    "    \n",
    "    questions_prompt = \"\"\"はいまたはいいえで答えられる質問を1つ聞いてください。\"\"\"  # 質問を促すプロンプトを定義します。\n",
    "    \n",
    "    guess_prompt = \"\"\"キーワードを推測してください。正確な単語/フレーズのみを返答してください。たとえば、キーワードが[paris]だと思う場合は、[私はキーワードがparisだと思います]や[キーワードはParisですか？]とは返答せず、単に[word]と返答してください。[paris]だけを返してください。\"\"\"  # キーワードの推測を促すプロンプトを定義します。\n",
    "    \n",
    "    q_a_thread = \"\"  # 質問と回答の履歴を保存するための変数を初期化します。\n",
    "    \n",
    "    # 質問と回答の履歴を構築します。\n",
    "    for i in range(0, len(obs.answers)):  # 現在の観察データの回答の数だけループします。\n",
    "        q_a_thread = \"{}Q: {} A: {}\\n\".format(  # Q&Aのスレッドを整形します。\n",
    "            q_a_thread,\n",
    "            obs.questions[i],  # 現在の質問を取得します。\n",
    "            obs.answers[i]  # 現在の回答を取得します。\n",
    "        )\n",
    "    \n",
    "    prompt = \"\"  # プロンプトを初期化します。\n",
    "    \n",
    "    # ターンの種類に応じてプロンプトを選択します。\n",
    "    if obs.turnType == ASK:  # ターンの種類が質問のとき\n",
    "        prompt = \"{}{}\".format(  # 情報プロンプトと質問プロンプトを結合します。\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "    elif obs.turnType == GUESS:  # ターンの種類が推測のとき\n",
    "        prompt = \"{}{}\".format(  # 情報プロンプトと推測プロンプトを結合します。\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "    else:\n",
    "        return \"\"  # ターンの種類が不明な場合は空の文字列を返します。\n",
    "    \n",
    "    return call_llm(prompt)  # 構築したプロンプトを使用してLLMを呼び出します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b47f1f",
   "metadata": {},
   "source": [
    "# 回答者エージェント\n",
    "answerer_agent関数は次のような処理を行います。\n",
    "\n",
    "1. ターンの種類が「回答」であるかどうかをチェックします。\n",
    "\n",
    "2. もし「回答」であれば、info_promptとanswer_question_promptを組み合わせてプロンプトを作成し、プレースホルダーを実際の値で置き換えます。\n",
    "\n",
    "3. 生成したプロンプトを使用してcall_llm関数を呼び出し、応答を取得します。\n",
    "\n",
    "4. ターンが「回答」でない場合は、空の文字列を返します。\n",
    "\n",
    "5. agents辞書は、エージェントの種類をゲーム内の行動を定義する役割にマッピングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.737143Z",
     "iopub.status.busy": "2024-06-01T17:52:53.736759Z",
     "iopub.status.idle": "2024-06-01T17:52:53.746596Z",
     "shell.execute_reply": "2024-06-01T17:52:53.745085Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.737114Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_agent(obs):  # 回答者エージェントの関数を定義します。obsは現在の観察データを含む引数です。\n",
    "    info_prompt = \"\"\"あなたは20の質問ゲームで非常に正確な回答者です。質問者が推測しようとしているキーワードは[the {category} {keyword}]です。\"\"\"  # ゲームの設定に関する情報を含むプロンプトを定義します。\n",
    "    \n",
    "    answer_question_prompt = \"\"\"次の質問には「はい」、「いいえ」、または不明な場合は「たぶん」のみで答えてください: {question}\"\"\"  # 質問への回答を促すプロンプトを定義します。\n",
    "    \n",
    "    if obs.turnType == \"answer\":  # ターンの種類が「回答」の場合\n",
    "        prompt = \"{}{}\".format(  # 情報プロンプトと質問回答プロンプトを結合します。\n",
    "            info_prompt.format(category=category, keyword=keyword),  # カテゴリとキーワードに実際の値を挿入します。\n",
    "            answer_question_prompt.format(question=obs.questions[-1])  # 最新の質問を挿入します。\n",
    "        )\n",
    "        return call_llm(prompt)  # 構築したプロンプトを使用してLLMを呼び出し、応答を取得します。\n",
    "    else: \n",
    "        return \"\"  # ターンが「回答」でない場合は空の文字列を返します。\n",
    "\n",
    "# エージェントの種類を役割にマッピングする辞書を定義します。\n",
    "agents = {GUESSER: guesser_agent, ANSWERER: answerer_agent}  # GUESSERは推測者エージェント、ANSWERERは回答者エージェントを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464c352",
   "metadata": {},
   "source": [
    "# 推測者アクション\n",
    "\n",
    "### 関数の構成要素\n",
    "1. **`guessed`変数の初期化**:\n",
    "   - 変数`guessed`は`False`として初期化され、キーワードが正しく推測されたかどうかを追跡します。\n",
    "   ```python\n",
    "   guessed = False\n",
    "   ```\n",
    "\n",
    "2. **アクションなしのチェック**:\n",
    "   - `active.action`が空（アクションが取られていない）場合、`active`のステータスを`ERROR`に設定します。\n",
    "   ```python\n",
    "   if not active.action:\n",
    "       active.status = ERROR\n",
    "   ```\n",
    "\n",
    "3. **質問ターンの処理**:\n",
    "   - 観察者のターンの種類（`turnType`）が`ASK`（質問する）である場合:\n",
    "     - アクション（`active.action`）は質問として扱われ、2000文字に制限されます。\n",
    "     - 質問はアクティブと非アクティブの両方の観察者の質問リストに追加されます。\n",
    "   ```python\n",
    "   elif active.observation.turnType == ASK:\n",
    "       question = active.action[:2000]\n",
    "       active.observation.questions.append(question)\n",
    "       inactive.observation.questions.append(question)\n",
    "   ```\n",
    "\n",
    "4. **推測ターンの処理**:\n",
    "   - 観察者のターンの種類が`GUESS`（推測する）である場合:\n",
    "     - アクション（`active.action`）は推測として扱われ、100文字に制限されます。\n",
    "     - 推測はアクティブと非アクティブの両方の観察者の推測リストに追加されます。\n",
    "   ```python\n",
    "   elif active.observation.turnType == GUESS:\n",
    "       guess = active.action[:100]\n",
    "       active.observation.guesses.append(guess)\n",
    "       inactive.observation.guesses.append(guess)\n",
    "   ```\n",
    "\n",
    "5. **キーワードが推測されたかのチェック**:\n",
    "   - アクション（`active.action`）があり、キーワードが正しく推測された場合（`keyword_guessed(active.action)`）:\n",
    "     - 変数`guessed`は`True`に設定されます。\n",
    "     - スコアは`20 - int(step / 3)`として計算され、ここで`step`はゲーム内で取られたステップ数を表します。\n",
    "     - `end_game`関数が呼び出され、アクティブと非アクティブの観察者を渡して、スコアと最終ステータス`DONE`でゲームを終了します。\n",
    "   ```python\n",
    "   if active.action and keyword_guessed(active.action):\n",
    "       guessed = True\n",
    "       score = 20 - int(step / 3)\n",
    "       end_game(active, inactive, score, DONE, DONE)\n",
    "   ```\n",
    "\n",
    "6. **`guessed`変数の返却**:\n",
    "   - 関数は`guessed`変数を返し、キーワードが正しく推測されたかどうかを示します。\n",
    "   ```python\n",
    "   return guessed\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.750303Z",
     "iopub.status.busy": "2024-06-01T17:52:53.749419Z",
     "iopub.status.idle": "2024-06-01T17:52:53.763111Z",
     "shell.execute_reply": "2024-06-01T17:52:53.761727Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.750264Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_action(active, inactive, step):  # 推測者アクションの関数を定義します。activeはアクティブな観察者、inactiveは非アクティブな観察者、stepはゲームの進行ステップ数を示します。\n",
    "    guessed = False  # キーワードが正しく推測されたかどうかを示す変数を初期化します。\n",
    "    \n",
    "    if not active.action:  # アクティブな観察者のアクションが空の場合\n",
    "        active.status = ERROR  # ステータスをERRORに設定します。\n",
    "        \n",
    "    elif active.observation.turnType == ASK:  # ターンの種類が質問の場合\n",
    "        question = active.action[:2000]  # アクション（質問）を2000文字に制限して取得します。\n",
    "        active.observation.questions.append(question)  # アクティブな観察者の質問リストに追加します。\n",
    "        inactive.observation.questions.append(question)  # 非アクティブな観察者の質問リストにも追加します。\n",
    "        \n",
    "    elif active.observation.turnType == GUESS:  # ターンの種類が推測の場合\n",
    "        guess = active.action[:100]  # アクション（推測）を100文字に制限して取得します。\n",
    "        active.observation.guesses.append(guess)  # アクティブな観察者の推測リストに追加します。\n",
    "        inactive.observation.guesses.append(guess)  # 非アクティブな観察者の推測リストにも追加します。\n",
    "        \n",
    "    if active.action and keyword_guessed(active.action):  # アクションがあり、キーワードが正しく推測された場合\n",
    "        guessed = True  # guessedをTrueに設定します。\n",
    "        score = 20 - int(step / 3)  # スコアを計算します。ステップ数に応じてスコアが減少します。\n",
    "        end_game(active, inactive, score, DONE, DONE)  # ゲームを終了する関数を呼び出します。\n",
    "        \n",
    "    return guessed  # 推測結果を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50352262",
   "metadata": {},
   "source": [
    "# ゲームの終了\n",
    "`end_game`関数はゲームを終了させるために次の処理を行います：\n",
    "- 両方の参加者に対してキーワードとカテゴリを設定します。\n",
    "- 両方の参加者に報酬を割り当てます。\n",
    "- 両方の参加者のステータスを更新します。\n",
    "\n",
    "これにより、すべての参加者がゲームの終了に関する正しい情報を持ち、彼らの状態がゲームの結論を反映するように適切に更新されることが保証されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.765011Z",
     "iopub.status.busy": "2024-06-01T17:52:53.764597Z",
     "iopub.status.idle": "2024-06-01T17:52:53.77889Z",
     "shell.execute_reply": "2024-06-01T17:52:53.776597Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.764979Z"
    }
   },
   "outputs": [],
   "source": [
    "def end_game(active, inactive, reward, status, inactive_status):  # ゲームを終了させる関数を定義します。activeはアクティブな参加者、inactiveは非アクティブな参加者、rewardは報酬、statusはアクティブな参加者のステータス、inactive_statusは非アクティブな参加者のステータスを示します。\n",
    "    active.observation.keyword = keyword  # アクティブな参加者の観察データにキーワードを設定します。\n",
    "    active.observation.category = category  # アクティブな参加者の観察データにカテゴリを設定します。\n",
    "    inactive.observation.keyword = keyword  # 非アクティブな参加者の観察データにキーワードを設定します。\n",
    "    inactive.observation.category = category  # 非アクティブな参加者の観察データにカテゴリを設定します。\n",
    "    \n",
    "    active.reward = reward  # アクティブな参加者に報酬を設定します。\n",
    "    inactive.reward = reward  # 非アクティブな参加者にも同じ報酬を設定します。\n",
    "    \n",
    "    active.status = status  # アクティブな参加者のステータスを設定します。\n",
    "    inactive.status = inactive_status  # 非アクティブな参加者のステータスを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c55da8",
   "metadata": {},
   "source": [
    "# 回答者アクション\n",
    "\n",
    "`answerer_action`関数は、回答者が質問に対する反応を処理します。具体的には次のような処理を行います：\n",
    "- アクティブな参加者にキーワードとカテゴリを設定します。\n",
    "- 反応が有効かどうかをチェックし、\"yes\"、\"no\"、または\"maybe\"に正規化します。\n",
    "- 反応が無効または空の場合は、エラーとしてゲームを終了します。\n",
    "- 両方の参加者の回答リストに反応を追加します。\n",
    "\n",
    "この関数は、回答者の反応に基づいてゲームの状態が適切に更新されることを保証し、エラーや無効な反応が発生した場合には、エラーステータスとしてゲームを終了します。\n",
    "\n",
    "**回答の更新**\n",
    "\n",
    "```python\n",
    "active.observation.answers.append(response)  # アクティブな参加者の回答リストに反応を追加します。\n",
    "inactive.observation.answers.append(response)  # 非アクティブな参加者の回答リストにも反応を追加します。\n",
    "```\n",
    "正規化された`response`は、両方の`active`と`inactive`の参加者の`answers`リストに追加されます。これにより、両方の参加者が回答者の反応の記録を持つことが保証されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.782277Z",
     "iopub.status.busy": "2024-06-01T17:52:53.780951Z",
     "iopub.status.idle": "2024-06-01T17:52:53.792029Z",
     "shell.execute_reply": "2024-06-01T17:52:53.790924Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.782226Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_action(active, inactive):  # 回答者アクションの関数を定義します。activeはアクティブな参加者、inactiveは非アクティブな参加者を示します。\n",
    "    active.observation.keyword = keyword  # アクティブな参加者の観察データにキーワードを設定します。\n",
    "    active.observation.category = category  # アクティブな参加者の観察データにカテゴリを設定します。\n",
    "    \n",
    "    response = active.action  # アクティブな参加者のアクション（応答）を取得します。\n",
    "    \n",
    "    if not response:  # 応答がない場合\n",
    "        response = \"none\"  # 応答を\"none\"に設定します。\n",
    "        end_game(active, inactive, -1, ERROR, DONE)  # エラーとしてゲームを終了します。\n",
    "        \n",
    "    elif \"yes\" in response.lower():  # 応答に\"yes\"が含まれる場合\n",
    "        response = \"yes\"  # 応答を\"yes\"に設定します。\n",
    "        \n",
    "    elif \"no\" in response.lower():  # 応答に\"no\"が含まれる場合\n",
    "        response = \"no\"  # 応答を\"no\"に設定します。\n",
    "        \n",
    "    else:  # それ以外の場合\n",
    "        response = \"maybe\"  # 応答を\"maybe\"に設定します。\n",
    "        end_game(active, inactive, -1, ERROR, DONE)  # エラーとしてゲームを終了します。\n",
    "        \n",
    "    active.observation.answers.append(response)  # アクティブな参加者の回答リストに応答を追加します。\n",
    "    inactive.observation.answers.append(response)  # 非アクティブな参加者の回答リストにも応答を追加します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf669c1",
   "metadata": {},
   "source": [
    "# ターンのインクリメント\n",
    "`increment_turn`関数は次のような処理を行います：\n",
    "1. キーワードが推測されていない場合、60ステップ後にゲームを終了します。\n",
    "2. ターンの種類を「質問」と「推測」間で切り替え、質問をする役割と推測をする役割を交互にします。\n",
    "3. アクティブな参加者と非アクティブな参加者のステータスを更新し、次のターンに正しい参加者がアクティブになるようにします。\n",
    "\n",
    "この関数は、ゲームがスムーズに進行し、参加者間で役割が交互に切り替わり、推測できなかった場合には適切にゲーム終了を処理することを保証します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.794871Z",
     "iopub.status.busy": "2024-06-01T17:52:53.794498Z",
     "iopub.status.idle": "2024-06-01T17:52:53.807073Z",
     "shell.execute_reply": "2024-06-01T17:52:53.805825Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.794827Z"
    }
   },
   "outputs": [],
   "source": [
    "def increment_turn(active, inactive, step, guessed):  # ターンをインクリメントする関数を定義します。activeはアクティブな参加者、inactiveは非アクティブな参加者、stepは現在のステップ数、guessedはキーワードが推測されたかを示します。\n",
    "    if step == 59 and not guessed:  # ステップが59で、キーワードが推測されていない場合\n",
    "        end_game(active, inactive, -1, DONE, DONE)  # エラーとしてゲームを終了します。\n",
    "        \n",
    "    elif active.observation.turnType == \"guess\":  # アクティブな参加者のターンの種類が「推測」の場合\n",
    "        active.observation.turnType = \"ask\"  # ターンの種類を「質問」に切り替えます。\n",
    "        \n",
    "    elif active.observation.turnType == \"ask\":  # アクティブな参加者のターンの種類が「質問」の場合\n",
    "        active.observation.turnType = \"guess\"  # ターンの種類を「推測」に切り替えます。\n",
    "        active.status = INACTIVE  # アクティブな参加者のステータスを非アクティブに設定します。\n",
    "        inactive.status = ACTIVE  # 非アクティブな参加者のステータスをアクティブに設定します。\n",
    "        \n",
    "    else:  # その他の場合\n",
    "        active.status = INACTIVE  # アクティブな参加者のステータスを非アクティブに設定します。\n",
    "        inactive.status = ACTIVE  # 非アクティブな参加者のステータスをアクティブに設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201477fa",
   "metadata": {},
   "source": [
    "# インタープリター\n",
    "\n",
    "### `interpreter`関数の目的\n",
    "\n",
    "`interpreter`関数は、2対のエージェントが関与するゲームの状態とアクションを管理します。各対はアクティブなエージェント（質問者）と非アクティブなエージェント（推測者）で構成されており、この関数はゲームの状態を更新し、各エージェントが取るべきアクションを決定し、遷移と終了条件を処理します。\n",
    "\n",
    "### コードの説明\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "```\n",
    "\n",
    "この行は、環境（ゲーム）が終わったかどうかをチェックします。終わっている場合、関数は現在の状態を変更せずに返します。\n",
    "\n",
    "### アクティブエージェントと非アクティブエージェントの分離\n",
    "\n",
    "```python\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "```\n",
    "\n",
    "これらの行は、各対のアクティブと非アクティブのエージェントを特定します。`state[0]`と`state[1]`は最初のエージェントのペア、`state[2]`と`state[3]`は二番目のエージェントのペアです。\n",
    "\n",
    "### 完了ステータスの処理\n",
    "\n",
    "```python\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "```\n",
    "\n",
    "これらの行は、もしペアの両方のエージェントが完了していれば、そのエージェントを`None`に設定します。すべてのエージェントが完了している場合、関数は現在の状態を返し、実質的に終了します。\n",
    "\n",
    "### ステップと終了条件の処理\n",
    "\n",
    "```python\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "```\n",
    "\n",
    "- `step`には、ゲームの現在のステップが格納されます。\n",
    "- `end_early`は、いずれかのアクティブエージェントが`TIMEOUT`または`ERROR`のステータスを持つ場合、早期終了の条件をチェックします。\n",
    "- `either_guessed`は、どのエージェントがキーワードを正しく推測したかをトラックするフラグです。\n",
    "\n",
    "### アクティブ1エージェントの処理\n",
    "\n",
    "```python\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "```\n",
    "\n",
    "- `active1`が`None`でない場合、関数はそのエージェントの役割をチェックします。\n",
    "- `active1`が推測者の場合、`guesser_action`を呼び出します。\n",
    "- `active1`が回答者の場合、`answerer_action`を呼び出します。\n",
    "- 次に、`TIMEOUT`や`ERROR`などの終了条件を処理し、`end_game`を呼び出します。\n",
    "- `end_early`が真の場合、ゲームを終了します。\n",
    "- そうでなければ、`increment_turn`を呼び出し、次のターンに進みます。\n",
    "\n",
    "### アクティブ2エージェントの処理\n",
    "\n",
    "```python\n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "```\n",
    "\n",
    "このブロックは`active1`の処理と似ていますが、`active2`と`inactive2`に対して操作を行います。\n",
    "\n",
    "### 状態の返却\n",
    "\n",
    "```python\n",
    "    return state\n",
    "```\n",
    "\n",
    "関数は、両方のペアのエージェントのアクションと遷移を処理した後、更新された状態を返します。\n",
    "\n",
    "### 概要\n",
    "\n",
    "`interpreter`関数は次の処理を行います：\n",
    "\n",
    "1. ゲームが完了しているかチェックし、完了している場合は状態を返します。\n",
    "2. 各ペアのアクティブと非アクティブのエージェントを特定します。\n",
    "3. 終了条件を処理し、質問と推測の役割を交互に切り替えます。\n",
    "4. エージェントの現在の役割とステータスに基づいて適切な関数（`guesser_action`、`answerer_action`、`end_game`、`increment_turn`）を呼び出します。\n",
    "5. ゲームの状態を更新し、返します。\n",
    "\n",
    "この関数はゲームの流れを管理するために重要であり、各エージェントが自分の役割に基づいて正しいアクションを取ることを保証し、さまざまな終了条件を適切に処理します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.809371Z",
     "iopub.status.busy": "2024-06-01T17:52:53.808999Z",
     "iopub.status.idle": "2024-06-01T17:52:53.825443Z",
     "shell.execute_reply": "2024-06-01T17:52:53.824102Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.809341Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpreter(state, env):  # ゲームの状態と環境を監視するインタープリター関数を定義します。\n",
    "    if env.done:  # 環境（ゲーム）が終了している場合\n",
    "        return state  # 現在の状態を返します。\n",
    "    \n",
    "    # アクティブおよび非アクティブエージェントを分離します。\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]  # 最初のペアのアクティブエージェントを選択します。\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]  # 最初のペアの非アクティブエージェントを選択します。\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]  # 二番目のペアのアクティブエージェントを選択します。\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]  # 二番目のペアの非アクティブエージェントを選択します。\n",
    "    \n",
    "    if active1.status == DONE and inactive1.status == DONE:  # 最初のペアの両方のエージェントがDONEの場合\n",
    "        active1 = None  # アクティブエージェントをNoneに設定します。\n",
    "        inactive1 = None  # 非アクティブエージェントをNoneに設定します。\n",
    "    \n",
    "    if active2.status == DONE or inactive2.status == DONE:  # 二番目のペアのいずれかのエージェントがDONEの場合\n",
    "        active2 = None  # アクティブエージェントをNoneに設定します。\n",
    "        inactive2 = None  # 非アクティブエージェントをNoneに設定します。\n",
    "    \n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:  # すべてのエージェントがNoneの場合\n",
    "        return state  # 現在の状態を返します。\n",
    "    \n",
    "    step = state[0].observation.step  # 現在のステップを取得します。\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))  # 早期終了の条件をチェックします。\n",
    "    either_guessed = False  # いずれかのエージェントが推測したかをトラックするフラグを初期化します。\n",
    "\n",
    "    if active1 is not None:  # アクティブな参加者が存在する場合\n",
    "        guessed = False  # 推測状況を初期化します。\n",
    "        if active1.observation.role == GUESSER:  # アクティブな参加者が推測者の場合\n",
    "            guessed = guesser_action(active1, inactive1, step)  # 推測者のアクションを実行します。\n",
    "            either_guessed = guessed  # 推測状況を更新します。\n",
    "        else:  # アクティブな参加者が回答者の場合\n",
    "            answerer_action(active1, inactive1)  # 回答者のアクションを実行します。\n",
    "        \n",
    "        if active1.status in (TIMEOUT, ERROR):  # タイムアウトまたはエラーの場合\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)  # ゲームを終了します。\n",
    "        elif end_early:  # 早期終了条件が成立する場合\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)  # ゲームを終了します。\n",
    "        else:  # それ以外の場合\n",
    "            increment_turn(active1, inactive1, step, guessed)  # ターンを進めます。\n",
    "    \n",
    "    if active2 is not None:  # アクティブな参加者が存在する場合\n",
    "        guessed = False  # 推測状況を初期化します。\n",
    "        if active2.observation.role == GUESSER:  # アクティブな参加者が推測者の場合\n",
    "            guessed = guesser_action(active2, inactive2, step)  # 推測者のアクションを実行します。\n",
    "            either_guessed = either_guessed or guessed  # 推測状況を更新します。\n",
    "        else:  # アクティブな参加者が回答者の場合\n",
    "            answerer_action(active2, inactive2)  # 回答者のアクションを実行します。\n",
    "        \n",
    "        if active2.status in (TIMEOUT, ERROR):  # タイムアウトまたはエラーの場合\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)  # ゲームを終了します。\n",
    "        elif end_early:  # 早期終了条件が成立する場合\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)  # ゲームを終了します。\n",
    "        else:  # それ以外の場合\n",
    "            increment_turn(active2, inactive2, step, guessed)  # ターンを進めます。\n",
    "    \n",
    "    return state  # 更新された状態を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdc13bf",
   "metadata": {},
   "source": [
    "# レンダラー\n",
    "\n",
    "- **`renderer`関数**:\n",
    "  - ゲームの状態を反復処理します。\n",
    "  - 各エージェントの役割、インタラクション、キーワード、およびスコアを出力します。\n",
    "  - `GUESSER`エージェントのためのトランスクリプトを構築し、彼らの質問、回答、および推測を表示します。\n",
    "  - エージェント間の可読性を向上させるために空行を印刷します。\n",
    "\n",
    "- **追加コード**:\n",
    "  - JSONファイルへのパスを構築します。\n",
    "  - JSONファイルを開き、変数`specification`にロードします。\n",
    "\n",
    "`renderer`関数は、ゲームの現在の状態を視覚化するのに役立ち、進行状況をデバッグしたり理解したりしやすくします。一方で、追加コードはJSONファイルからゲーム仕様をロードするためのものです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.827137Z",
     "iopub.status.busy": "2024-06-01T17:52:53.826659Z",
     "iopub.status.idle": "2024-06-01T17:52:53.844687Z",
     "shell.execute_reply": "2024-06-01T17:52:53.843323Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.827107Z"
    }
   },
   "outputs": [],
   "source": [
    "def renderer(state, env):  # ゲームの状態を表示する関数を定義します。\n",
    "    for s in state:  # ゲームの状態を逐次処理します。\n",
    "        print(\"role: \", s.observation.role)  # 各エージェントの役割を表示します。\n",
    "        \n",
    "        if s.observation.role == GUESSER:  # エージェントが推測者の場合\n",
    "            transcript = \"\"  # トランスクリプトの初期化\n",
    "            for i in range(0, len(s.observation.guesses)):  # 推測の数だけループします。\n",
    "                transcript = \"{}Q: {} A: {}\\nG: {}\\n\".format(  # 質問、回答、推測をトランスクリプトに追加します。\n",
    "                    transcript, s.observation.questions[i],  # 質問を追加\n",
    "                    s.observation.answers[i],  # 回答を追加\n",
    "                    s.observation.guesses[i]  # 推測を追加\n",
    "                )\n",
    "            print(transcript)  # 完成したトランスクリプトを表示します。\n",
    "        \n",
    "        print(\"keyword: \", s.observation.keyword)  # キーワードを表示します。\n",
    "        print(\"score: \", s.reward)  # スコアを表示します。\n",
    "        print(\"\")  # 可読性向上のために空行を挿入します。\n",
    "        print(\"\")  # 可読性向上のために空行を挿入します。\n",
    "        print(\"\")  # 可読性向上のために空行を挿入します。\n",
    "    \n",
    "    return \"\"  # 空の文字列を返します。\n",
    "\n",
    "# JSONファイルへのパスを構築します。\n",
    "jsonpath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.json\"))\n",
    "with open(jsonpath) as f:  # JSONファイルを開きます。\n",
    "    specification = json.load(f)  # JSONファイルの内容を読み込み、specificationに格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea30930",
   "metadata": {},
   "source": [
    "### `html_renderer`関数\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **JavaScriptのパスを構築**:\n",
    "    ```python\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    ```\n",
    "    - `path.abspath`を使用して`llm_20_questions.js`ファイルの絶対パスを取得します。\n",
    "    - `path.join`を使用して、現在のファイルのディレクトリ（`__file__`）と`llm_20_questions.js`を結合します。\n",
    "\n",
    "2. **JavaScriptファイルを開き、内容を読み込む**:\n",
    "    ```python\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "    ```\n",
    "    - `jspath`で指定されたパスにあるJavaScriptファイルを開きます。\n",
    "    - `f.read()`を使用してファイルの内容全体を読み込みます。\n",
    "    - 内容を文字列として返します。\n",
    "\n",
    "この関数は、`llm_20_questions.js`という名前のJavaScriptファイルを読み込み、その内容を文字列として返します。これは、HTMLページにJavaScriptを動的に埋め込む際に便利です。\n",
    "\n",
    "### `keyword_guessed`関数\n",
    "\n",
    "```python\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **`normalize`関数の定義**:\n",
    "    ```python\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    ```\n",
    "    - `normalize`は、比較のために文字列を標準化するヘルパー関数です。\n",
    "    - `str.maketrans`を使用して、文字列からすべての句読点を取り除きます。\n",
    "    - `s.lower()`を使用して、文字列を小文字に変換します。\n",
    "    - \"the\"と空白を空の文字列に置き換えることで、それらを取り除きます。\n",
    "    - `translate(t)`を使用して、句読点を削除します。\n",
    "\n",
    "2. **推測がキーワードと一致するかをチェック**:\n",
    "    ```python\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    ```\n",
    "    - `guess`と`keyword`の両方を標準化します。\n",
    "    - 標準化した文字列を比較します。\n",
    "    - 一致する場合は`True`を返します。\n",
    "\n",
    "3. **推測が代替キーワードのいずれかと一致するかをチェック**:\n",
    "    ```python\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    ```\n",
    "    - `alts`に含まれる各代替キーワードを反復処理します。\n",
    "    - 各代替キーワードを標準化し、標準化した`guess`と比較します。\n",
    "    - 一致する場合は`True`を返します。\n",
    "\n",
    "4. **一致しない場合は`False`を返す**:\n",
    "    ```python\n",
    "    return False\n",
    "    ```\n",
    "    - キーワードまたは任意の代替キーワードが推測と一致しない場合は`False`を返します。\n",
    "\n",
    "`keyword_guessed`関数は、与えられた推測がターゲットキーワードまたはその代替キーワードのいずれかと一致するかをチェックします。標準化された文字列を使用して、句読点を削除し、小文字に変換し、スペースや\"the\"を取り除くことで、比較がケースインセンシティブになり、句読点や余分なスペースを無視することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.847051Z",
     "iopub.status.busy": "2024-06-01T17:52:53.846554Z",
     "iopub.status.idle": "2024-06-01T17:52:53.855991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.854737Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.847018Z"
    }
   },
   "outputs": [],
   "source": [
    "def html_renderer():  # HTMLレンダラーの関数を定義します。\n",
    "    jspath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.js\"))  # JavaScriptファイルへの絶対パスを構築します。\n",
    "    with open(jspath) as f:  # JavaScriptファイルを開きます。\n",
    "        return f.read()  # ファイルの全内容を文字列として返します。\n",
    "\n",
    "def keyword_guessed(guess: str) -> bool:  # 与えられた推測がキーワードまたはその代替キーワードと一致するかをチェックする関数を定義します。\n",
    "    def normalize(s: str) -> str:  # 文字列を標準化するヘルパー関数を定義します。\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)  # 句読点を削除するための変換テーブルを作成します。\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)  # 文字列を小文字にし、\"the\"と空白を除去し、句読点を削除します。\n",
    "\n",
    "    if normalize(guess) == normalize(keyword):  # 推測とキーワードを標準化して比較します。\n",
    "        return True  # 一致する場合はTrueを返します。\n",
    "    \n",
    "    for s in alts:  # 代替キーワードをループ処理します。\n",
    "        if normalize(s) == normalize(guess):  # 各代替キーワードを推測と比較します。\n",
    "            return True  # 一致する場合はTrueを返します。\n",
    "\n",
    "    return False  # 一致しない場合はFalseを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd6fca8",
   "metadata": {},
   "source": [
    "### `call_llm`関数\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    \n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **グローバル変数**:\n",
    "    ```python\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    ```\n",
    "    - グローバル変数`model_initialized`、`device`、`model`、`tokenizer`を使用することを宣言します。\n",
    "\n",
    "2. **モデルの初期化チェック**:\n",
    "    ```python\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "    ```\n",
    "    - モデルがすでに初期化されているかを確認します。\n",
    "    - 初期化されていない場合、`llm_parent_dir`ディレクトリが存在し、ファイルが含まれているかをチェックします。\n",
    "\n",
    "3. **モデルとトークナイザーのロード**:\n",
    "    ```python\n",
    "    dirs = os.listdir(llm_parent_dir)\n",
    "    llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "    model_initialized = True\n",
    "    ```\n",
    "    - `llm_parent_dir`内のディレクトリを取得します。\n",
    "    - モデルディレクトリへのパスを構築します。\n",
    "    - GPUが利用可能であれば`cuda:0`、そうでなければCPUを使用するようデバイスを設定します。\n",
    "    - 指定されたディレクトリからT5モデルとトークナイザーをロードし、モデルを選択したデバイスに移動します。\n",
    "    - `model_initialized`を`True`に設定し、次回の呼び出しで再初期化しないようにします。\n",
    "\n",
    "4. **モデルディレクトリがない場合の処理**:\n",
    "    ```python\n",
    "    else:\n",
    "        print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "        print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "        raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    ```\n",
    "    - モデルディレクトリが存在しないか空である場合、エラーメッセージを表示し、例外を発生させます。\n",
    "\n",
    "5. **モデルの入力の準備**:\n",
    "    ```python\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    ```\n",
    "    - 入力`prompt`をトークナイズし、PyTorchのテンソルに変換します。\n",
    "    - テンソルを選択したデバイス（CPUまたはGPU）に移動させます。\n",
    "\n",
    "6. **出力を生成**:\n",
    "    ```python\n",
    "    outputs = model.generate(**inputs)\n",
    "    ```\n",
    "    - トークナイズした入力からモデルを使用して出力を生成します。\n",
    "\n",
    "7. **出力をデコード**:\n",
    "    ```python\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "    ```\n",
    "    - 生成された出力をテキストにデコードし、特別なトークンをスキップします。\n",
    "    - デコードされた出力の最初の要素を最終的な答えとして返します。\n",
    "\n",
    "### 概要\n",
    "\n",
    "`call_llm`関数は、与えられたプロンプトに基づいて応答を生成するために事前学習されたT5モデルと対話する役割を担っています。モデルとトークナイザーが一度だけロードされて初期化されることを保証します。モデルが初期化されていない場合は、指定されたディレクトリからモデルとトークナイザーをロードし、デバイス（CPU/GPU）をセットアップし、モデルを初期化済みとしてマークします。その後、入力プロンプトをトークナイズし、モデルを使用して応答を生成し、応答をデコードして文字列として返します。モデルファイルが見つからない場合は、例外を発生させ、必要なモデルファイルを追加するための指示を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.859146Z",
     "iopub.status.busy": "2024-06-01T17:52:53.858345Z",
     "iopub.status.idle": "2024-06-01T17:52:53.867991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.866918Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.859113Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_llm(prompt: str) -> str:  # プロンプトに基づいて応答を生成する関数を定義します。\n",
    "    global model_initialized  # グローバル変数を使用することを宣言します。\n",
    "    global device  # グローバル変数を使用することを宣言します。\n",
    "    global model  # グローバル変数を使用することを宣言します。\n",
    "    global tokenizer  # グローバル変数を使用することを宣言します。\n",
    "\n",
    "    if not model_initialized:  # モデルが初期化されていない場合\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:  # モデルディレクトリが存在し、ファイルが含まれている場合\n",
    "            dirs = os.listdir(llm_parent_dir)  # ディレクトリ内のファイルをリストします。\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])  # モデルディレクトリのパスを構築します。\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"  # GPUが使用可能であればGPU、それ以外はCPUを設定します。\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)  # 指定されたディレクトリからT5モデルをロードし、選択したデバイスに移動します。\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)  # 指定されたディレクトリからトークナイザーをロードします。\n",
    "            model_initialized = True  # モデルが初期化されたことを示すフラグを設定します。\n",
    "        else:  # モデルディレクトリが存在しないか空である場合\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")  # エラーメッセージを表示します。\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")  # 参考リンクを表示します。\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")  # 例外を発生させます。\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)  # プロンプトをトークナイズし、PyTorchのテンソルに変換してデバイスに移動します。\n",
    "    outputs = model.generate(**inputs)  # モデルを使用して生成された出力を取得します。\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)  # 出力をデコードしてテキストに変換します。\n",
    "    \n",
    "    print(prompt)  # プロンプトを出力します（デバッグ用）。\n",
    "    return answer[0]  # 最初の回答を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d7596",
   "metadata": {},
   "source": [
    "# 実行/デバッグ\n",
    "\n",
    "*参考文献:* \n",
    "1. [test_llm_20_questions.py](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/llm_20_questions/test_llm_20_questions.py)\n",
    "2. [ノートブックでのLLM 20 Questionsの実行/デバッグ](https://www.kaggle.com/code/rturley/run-debug-llm-20-questions-in-a-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.86985Z",
     "iopub.status.busy": "2024-06-01T17:52:53.869355Z",
     "iopub.status.idle": "2024-06-01T17:52:53.887698Z",
     "shell.execute_reply": "2024-06-01T17:52:53.886572Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.869817Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make  # kaggle_environmentsライブラリからmake関数をインポートします。\n",
    "\n",
    "def custom_questioner(obs):  # カスタム質問者の関数を定義します。\n",
    "    if obs.turnType == \"guess\":  # ターンの種類が「推測」の場合\n",
    "        return \"banana\"  # \"banana\"を返します。\n",
    "    return \"Is it a banana?\"  # それ以外の場合は質問を返します。\n",
    "\n",
    "def custom_answerer():  # カスタム回答者の関数を定義します。\n",
    "    return \"no\"  # \"no\"を返します。\n",
    "\n",
    "def bad_answerer():  # 悪い回答者の関数を定義します。\n",
    "    return \"maybe?\"  # \"maybe?\"を返します。\n",
    "\n",
    "def error_agent():  # エラーエージェントを定義します。\n",
    "    raise ValueError  # ValueErrorを発生させます。\n",
    "\n",
    "def test_llm_20_q_completes():  # LLM 20 Questionsが正常に終了するかをテストする関数を定義します。\n",
    "    env = make(\"llm_20_questions\", debug=True)  # 環境を作成します。\n",
    "    game_output = env.run([guesser_agent, answerer_agent, guesser_agent, answerer_agent])  # ゲームを実行します。\n",
    "    json = env.toJSON()  # 環境の状態をJSON形式に変換します。\n",
    "    env.render(mode=\"ipython\", width=400, height=400)  # 環境を表示します。\n",
    "    assert json[\"name\"] == \"llm_20_questions\"  # 環境名が正しいかを確認します。\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"DONE\"]  # ステータスがすべてDONEであることを確認します。\n",
    "\n",
    "def test_llm_20_q_errors_on_bad_answer():  # 悪い回答に対するエラーをテストする関数を定義します。\n",
    "    env = make(\"llm_20_questions\", debug=True)  # 環境を作成します。\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, bad_answerer])  # ゲームを実行します。\n",
    "    json = env.toJSON()  # 環境の状態をJSON形式に変換します。\n",
    "    assert json[\"name\"] == \"llm_20_questions\"  # 環境名が正しいかを確認します。\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]  # 報酬が期待通りであることを確認します。\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]  # ステータスが期待通りであることを確認します。\n",
    "    print(len(json[\"steps\"]))  # ステップ数を出力します。\n",
    "    assert len(json[\"steps\"]) == 3  # ステップ数が期待通りであることを確認します。\n",
    "\n",
    "def test_llm_20_q_errors_on_error_answer():  # 回答エラーをテストする関数を定義します。\n",
    "    env = make(\"llm_20_questions\", debug=True)  # 環境を作成します。\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, error_agent])  # ゲームを実行します。\n",
    "    json = env.toJSON()  # 環境の状態をJSON形式に変換します。\n",
    "    assert json[\"name\"] == \"llm_20_questions\"  # 環境名が正しいかを確認します。\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]  # 報酬が期待通りであることを確認します。\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]  # ステータスが期待通りであることを確認します。\n",
    "    print(len(json[\"steps\"]))  # ステップ数を出力します。\n",
    "    assert len(json[\"steps\"]) == 3  # ステップ数が期待通りであることを確認します。\n",
    "\n",
    "def test_llm_20_q_errors_on_error_question():  # 質問エラーをテストする関数を定義します。\n",
    "    env = make(\"llm_20_questions\", debug=True)  # 環境を作成します。\n",
    "    env.run([custom_questioner, custom_answerer, error_agent, custom_answerer])  # ゲームを実行します。\n",
    "    json = env.toJSON()  # 環境の状態をJSON形式に変換します。\n",
    "    assert json[\"name\"] == \"llm_20_questions\"  # 環境名が正しいかを確認します。\n",
    "    assert json[\"rewards\"] == [1, 1, None, 1]  # 報酬が期待通りであることを確認します。\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"ERROR\", \"DONE\"]  # ステータスが期待通りであることを確認します。\n",
    "    print(len(json[\"steps\"]))  # ステップ数を出力します。\n",
    "    assert len(json[\"steps\"]) == 2  # ステップ数が期待通りであることを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.889738Z",
     "iopub.status.busy": "2024-06-01T17:52:53.889163Z",
     "iopub.status.idle": "2024-06-01T17:55:15.400121Z",
     "shell.execute_reply": "2024-06-01T17:55:15.398007Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.889705Z"
    }
   },
   "outputs": [],
   "source": [
    "test_llm_20_q_completes()  # LLM 20 Questionsが正常に終了するかをテストする関数を実行します。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 3047,
     "sourceId": 4261,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
