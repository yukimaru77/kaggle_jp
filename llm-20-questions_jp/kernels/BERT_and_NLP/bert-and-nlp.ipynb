{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a05d98b",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LLM 20 Questions」コンペティションに関連するデータを処理するためのものであり、主にJSONファイルの読み込み、整形、およびCSVファイルへの書き込みを行っています。\n",
    "\n",
    "### 問題の主題\n",
    "ノートブックは、JSON形式で提供されたデータから「国」「都市」「名所」に関する情報を抽出し、これを整理してデータフレームに変換することに焦点を当てています。このデータ処理は、コンペティション内で使用される可能性のある関連情報の構造化された形式を提供することを目的としています。\n",
    "\n",
    "### 使用されている手法とライブラリ\n",
    "- **Pandas**: データフレームの作成、操作、最終的なCSVファイルへの保存を行うために使用されている。\n",
    "- **JSON**: JSONファイルを読み込み、データをPythonの辞書形式に変換し、その後データを抽出するために使用。\n",
    "- **TextBlob**: 自然言語処理に関連してインポートされているが、この特定のノートブックでは使用されていない。\n",
    "- **NumPy**: 数値計算に関連する処理のためにインポートされているが、具体的な使用は見られない。\n",
    "\n",
    "### 主な処理の流れ\n",
    "1. **JSONの読み込み**: 指定されたファイルからJSONデータを読み込む。\n",
    "2. **データの抽出と整形**: JSONから「国」「都市」「名所」の情報を抽出し、それぞれのデータをデータフレームに変換する。\n",
    "3. **データの表示と保存**: 各データフレームの内容を表示し、CSVファイルとして保存する。\n",
    "\n",
    "このノートブックは、Kaggleの競技データに対する初期のデータ前処理を実施し、今後の分析やモデル作成に向けた基盤を築く役割を果たしています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c7cae",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下はJupyter Notebookの内容に基づいて、機械学習・深層学習の初心者がつまずきそうな専門用語の解説です。\n",
    "\n",
    "1. **JSON (JavaScript Object Notation)**:\n",
    "   - 軽量なデータ交換フォーマットで、主に人間が読み書きしやすいテキスト形式でデータを表現します。主にAPIとのデータ通信や設定ファイルで使われます。辞書型（キーと値のペア）のデータ構造を持ちますが、Pythonではそのまま辞書として扱うことができます。\n",
    "\n",
    "2. **TextBlob**:\n",
    "   - 自然言語処理のためのPythonライブラリで、テキストの解析や処理を簡便に行うための機能を提供します。例えば、文を分割したり、感情分析を行ったりするための高水準なインターフェースを持っています。\n",
    "\n",
    "3. **pd.json_normalize**:\n",
    "   - Pandasの関数で、ネストされたJSONオブジェクトを平坦なデータフレームに変換するために使用されます。特に複雑な構造のJSONデータを分析可能な形に整理する際に便利です。\n",
    "\n",
    "4. **辞書のリスト**:\n",
    "   - Pythonにおけるデータ構造で、多数の辞書オブジェクトを含むリストのことです。それぞれの辞書は異なるデータフィールドを持っている場合があり、データ分析や操作に役立ちます。\n",
    "\n",
    "5. **キーワードモジュール (keywords.py)**:\n",
    "   - 特定のキーワードや重要なデータを収集・処理するために使用されるカスタムモジュール。Notebook内で定義される特有の機能やデータを持っているでしょうが、その詳細な内容はモジュールを確認しないと分かりません。\n",
    "\n",
    "6. **オペレーティングシステム関連の機能 (os)**:\n",
    "   - Pythonの標準ライブラリの一つで、ファイルシステムや環境変数の操作といったオペレーティングシステム特有の機能を提供します。ファイルのパスを操作したり、ディレクトリの走査（file walking）を行ったりするために使われます。\n",
    "\n",
    "7. **システムパラメータと関数 (sys)**:\n",
    "   - Pythonの標準ライブラリの一部で、Pythonインタプリタに関する情報を扱ったり、プログラムの実行環境に対する操作を行なうための関数や変数を提供します。スクリプトの引数や環境情報にアクセスするために使用されます。\n",
    "\n",
    "これらの用語は、初心者が理解するのに難しい場合があり、特に実務経験がないと馴染みが薄いことが予想されます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-19T15:17:16.671497Z",
     "iopub.status.busy": "2024-05-19T15:17:16.671077Z",
     "iopub.status.idle": "2024-05-19T15:17:16.677143Z",
     "shell.execute_reply": "2024-05-19T15:17:16.676092Z",
     "shell.execute_reply.started": "2024-05-19T15:17:16.671469Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # データ処理用のライブラリ\n",
    "import json  # JSON操作用のライブラリ\n",
    "from textblob import TextBlob  # 自然言語処理用のライブラリ\n",
    "\n",
    "# pandasはデータフレームの作成や操作に便利で、jsonはデータの読み書きに使用されます。\n",
    "# TextBlobはテキストデータの分析や処理を簡単に行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:17:31.824792Z",
     "iopub.status.busy": "2024-05-19T15:17:31.824351Z",
     "iopub.status.idle": "2024-05-19T15:17:31.832609Z",
     "shell.execute_reply": "2024-05-19T15:17:31.831069Z",
     "shell.execute_reply.started": "2024-05-19T15:17:31.824745Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSONデータを読み込んで検査します\n",
    "with open('/kaggle/input/llm-20-questions/llm_20_questions/llm_20_questions.json') as file:\n",
    "    raw_data = json.load(file)  # JSONファイルを読み込み、Pythonの辞書に変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:18:30.029068Z",
     "iopub.status.busy": "2024-05-19T15:18:30.028605Z",
     "iopub.status.idle": "2024-05-19T15:18:30.035645Z",
     "shell.execute_reply": "2024-05-19T15:18:30.034248Z",
     "shell.execute_reply.started": "2024-05-19T15:18:30.029036Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSONデータのキーを検査します\n",
    "print(raw_data.keys())  # 読み込んだデータのキーを出力して確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:19:56.039436Z",
     "iopub.status.busy": "2024-05-19T15:19:56.038923Z",
     "iopub.status.idle": "2024-05-19T15:19:56.045608Z",
     "shell.execute_reply": "2024-05-19T15:19:56.044353Z",
     "shell.execute_reply.started": "2024-05-19T15:19:56.039404Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'agents'キーの下のデータを抽出します\n",
    "data = raw_data['agents']  # 'agents'キーに関連付けられたデータを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:20:08.892517Z",
     "iopub.status.busy": "2024-05-19T15:20:08.892058Z",
     "iopub.status.idle": "2024-05-19T15:20:08.898945Z",
     "shell.execute_reply": "2024-05-19T15:20:08.897265Z",
     "shell.execute_reply.started": "2024-05-19T15:20:08.892485Z"
    }
   },
   "outputs": [],
   "source": [
    "# データをデータフレームに変換します（辞書のリストであると仮定）\n",
    "data = pd.DataFrame(data)  # 'agents'のデータをPandasのデータフレームに変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:20:33.877395Z",
     "iopub.status.busy": "2024-05-19T15:20:33.876959Z",
     "iopub.status.idle": "2024-05-19T15:20:33.885332Z",
     "shell.execute_reply": "2024-05-19T15:20:33.883708Z",
     "shell.execute_reply.started": "2024-05-19T15:20:33.877363Z"
    }
   },
   "outputs": [],
   "source": [
    "# 正しく読み込まれたか確認するために最初の数行を表示します\n",
    "print(data.head())  # データフレームの先頭の数行を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:39:30.643169Z",
     "iopub.status.busy": "2024-05-19T15:39:30.642707Z",
     "iopub.status.idle": "2024-05-19T15:39:30.823214Z",
     "shell.execute_reply": "2024-05-19T15:39:30.822047Z",
     "shell.execute_reply.started": "2024-05-19T15:39:30.643139Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import pandas as pd  # データ処理用のライブラリ\n",
    "import json  # JSON操作用のライブラリ\n",
    "import os  # オペレーティングシステム関連の機能を提供\n",
    "import sys  # Pythonのシステムパラメータと関数を提供\n",
    "\n",
    "# ファイルを表示\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))  # ファイルのパスを表示\n",
    "\n",
    "# keywords.pyをインポート\n",
    "sys.path.append('../input/llm-20-questions/llm_20_questions/')  # パスを追加\n",
    "import keywords  # キーワードモジュールをインポート\n",
    "\n",
    "# 設定\n",
    "pd.set_option('display.max_rows', None)  # データフレームのすべての行を表示\n",
    "pd.set_option('display.max_colwidth', None)  # 長いテキストも完全に表示\n",
    "\n",
    "# JSONに変換\n",
    "my_json = json.loads(keywords.KEYWORDS_JSON)  # キーワードJSONをロード\n",
    "\n",
    "# コンポーネントの抽出\n",
    "json_country = my_json[0]  # 国データ\n",
    "json_city = my_json[1]  # 都市データ\n",
    "json_landmark = my_json[2]  # 名所データ\n",
    "\n",
    "# 国データフレームの作成\n",
    "df_country = pd.json_normalize(json_country['words'])  # 国データを正規化\n",
    "print(\"国のデータフレーム:\")\n",
    "print(df_country)  # 国データフレームを表示\n",
    "\n",
    "# 都市データフレームの作成\n",
    "df_city = pd.json_normalize(json_city['words'])  # 都市データを正規化\n",
    "print(\"\\n都市のデータフレーム:\")\n",
    "print(df_city)  # 都市データフレームを表示\n",
    "\n",
    "# 名所データフレームの作成\n",
    "df_landmark = pd.json_normalize(json_landmark['words'])  # 名所データを正規化\n",
    "print(\"\\n名所のデータフレーム:\")\n",
    "print(df_landmark)  # 名所データフレームを表示\n",
    "\n",
    "print(\"\\nmy_jsonの長さ:\", len(my_json))  # my_jsonのリストの長さを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:43:33.33797Z",
     "iopub.status.busy": "2024-05-19T15:43:33.337378Z",
     "iopub.status.idle": "2024-05-19T15:43:33.48537Z",
     "shell.execute_reply": "2024-05-19T15:43:33.484154Z",
     "shell.execute_reply.started": "2024-05-19T15:43:33.337934Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import pandas as pd  # データ処理用のライブラリ\n",
    "import json  # JSON操作用のライブラリ\n",
    "import os  # オペレーティングシステム関連の機能を提供\n",
    "import sys  # Pythonのシステムパラメータと関数を提供\n",
    "\n",
    "# ファイルを表示\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))  # ファイルのパスを表示\n",
    "\n",
    "# keywords.pyをインポート\n",
    "sys.path.append('../input/llm-20-questions/llm_20_questions/')  # パスを追加\n",
    "import keywords  # キーワードモジュールをインポート\n",
    "\n",
    "# 設定\n",
    "pd.set_option('display.max_rows', None)  # データフレームのすべての行を表示\n",
    "pd.set_option('display.max_colwidth', None)  # 長いテキストも完全に表示\n",
    "\n",
    "# JSONに変換\n",
    "my_json = json.loads(keywords.KEYWORDS_JSON)  # キーワードJSONをロード\n",
    "\n",
    "# コンポーネントの抽出\n",
    "json_country = my_json[0]  # 国データ\n",
    "json_city = my_json[1]  # 都市データ\n",
    "json_landmark = my_json[2]  # 名所データ\n",
    "\n",
    "# 国データフレームの作成\n",
    "df_country = pd.json_normalize(json_country['words'])  # 国データを正規化\n",
    "print(\"国のデータフレーム:\")\n",
    "print(df_country)  # 国データフレームを表示\n",
    "df_country.to_csv('/kaggle/working/country.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "# 都市データフレームの作成\n",
    "df_city = pd.json_normalize(json_city['words'])  # 都市データを正規化\n",
    "print(\"\\n都市のデータフレーム:\")\n",
    "print(df_city)  # 都市データフレームを表示\n",
    "df_city.to_csv('/kaggle/working/city.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "# 名所データフレームの作成\n",
    "df_landmark = pd.json_normalize(json_landmark['words'])  # 名所データを正規化\n",
    "print(\"\\n名所のデータフレーム:\")\n",
    "print(df_landmark)  # 名所データフレームを表示\n",
    "df_landmark.to_csv('/kaggle/working/landmark.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "print(\"\\nmy_jsonの長さ:\", len(my_json))  # my_jsonのリストの長さを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T15:45:15.308119Z",
     "iopub.status.busy": "2024-05-19T15:45:15.307648Z",
     "iopub.status.idle": "2024-05-19T15:45:15.454376Z",
     "shell.execute_reply": "2024-05-19T15:45:15.453167Z",
     "shell.execute_reply.started": "2024-05-19T15:45:15.308086Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import pandas as pd  # データ処理用のライブラリ\n",
    "import json  # JSON操作用のライブラリ\n",
    "import os  # オペレーティングシステム関連の機能を提供\n",
    "import sys  # Pythonのシステムパラメータと関数を提供\n",
    "\n",
    "def main():\n",
    "    # ファイルを表示\n",
    "    for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "        for filename in filenames:\n",
    "            print(os.path.join(dirname, filename))  # ファイルのパスを表示\n",
    "\n",
    "    # keywords.pyをインポート\n",
    "    sys.path.append('../input/llm-20-questions/llm_20_questions/')  # パスを追加\n",
    "    import keywords  # キーワードモジュールをインポート\n",
    "\n",
    "    # 設定\n",
    "    pd.set_option('display.max_rows', None)  # データフレームのすべての行を表示\n",
    "    pd.set_option('display.max_colwidth', None)  # 長いテキストも完全に表示\n",
    "\n",
    "    # JSONに変換\n",
    "    my_json = json.loads(keywords.KEYWORDS_JSON)  # キーワードJSONをロード\n",
    "\n",
    "    # コンポーネントの抽出\n",
    "    json_country = my_json[0]  # 国データ\n",
    "    json_city = my_json[1]  # 都市データ\n",
    "    json_landmark = my_json[2]  # 名所データ\n",
    "\n",
    "    # 国データフレームの作成\n",
    "    df_country = pd.json_normalize(json_country['words'])  # 国データを正規化\n",
    "    print(\"国のデータフレーム:\")\n",
    "    print(df_country)  # 国データフレームを表示\n",
    "    df_country.to_csv('/kaggle/working/country.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "    # 都市データフレームの作成\n",
    "    df_city = pd.json_normalize(json_city['words'])  # 都市データを正規化\n",
    "    print(\"\\n都市のデータフレーム:\")\n",
    "    print(df_city)  # 都市データフレームを表示\n",
    "    df_city.to_csv('/kaggle/working/city.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "    # 名所データフレームの作成\n",
    "    df_landmark = pd.json_normalize(json_landmark['words'])  # 名所データを正規化\n",
    "    print(\"\\n名所のデータフレーム:\")\n",
    "    print(df_landmark)  # 名所データフレームを表示\n",
    "    df_landmark.to_csv('/kaggle/working/landmark.csv', index=False)  # CSVファイルとして保存\n",
    "\n",
    "    print(\"\\nmy_jsonの長さ:\", len(my_json))  # my_jsonのリストの長さを表示\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # メイン関数を実行"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
