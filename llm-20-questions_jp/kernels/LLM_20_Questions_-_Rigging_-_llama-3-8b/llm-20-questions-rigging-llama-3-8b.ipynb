{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30c6a845",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LLM 20 Questions」コンペティションに参加するためのエージェントを開発し、実装することに焦点を当てています。特に、質問応答ゲームである「20の質問」において、AI言語モデルを活用して効率的な質問と回答を生成し、ターゲットワードを推測するタスクに取り組みます。\n",
    "\n",
    "### 主な取り組み内容\n",
    "\n",
    "1. **ライブラリとモデルのセットアップ**:\n",
    "   - 必要なPythonパッケージ（`rigging`、`kaggle`、`transformers`、`accelerate`、`bitsandbytes`）をインストールし、KaggleのシークレットからHugging FaceトークンやKaggleのユーザー情報を取得しています。\n",
    "   - Hugging Face HubからOLM（Optimized Language Model）のモデルとして「Meta-Llama-3-8B-Instruct-bnb-8bit」をダウンロードし、動作確認を行います。\n",
    "\n",
    "2. **モデルの実装**:\n",
    "   - 主要なエージェント関数 `agent_fn` では、観察結果に基づいて質問、回答、推測を行うロジックが実装されています。\n",
    "   - 質問は情報を集めるように限られた回答の選択肢（「はい」、「いいえ」、「もしかしたら」）を考慮して生成され、観察内容をXML形式で追跡します。\n",
    "   - 各エージェントは、現在のターンに従って適切なアクションを取ります。\n",
    "\n",
    "3. **ファイルの圧縮と提出**:\n",
    "   - 完成したモデルやライブラリを含むアーカイブを作成し、Kaggleに提出するための準備をしています。`pigz`および`pv`といったツールを使用し、効率的な圧縮処理を行っています。\n",
    "\n",
    "### 使用ライブラリ\n",
    "- **Kaggle API**: コンペティションへのデータ提出をサポート。\n",
    "- **Hugging Face Hub**: モデルの取得と管理。\n",
    "- **Rigging**: モデル生成に関連する高度な操作を提供。\n",
    "\n",
    "### 結論\n",
    "このNotebookは、AIエージェントによる「20の質問」ゲームの最適化に重点を置いたものであり、戦略的かつ効率的な質問応答を通じてターゲットワードを素早く特定することが求められています。データの取り扱いやモデルの実装に専門的な手法とライブラリが利用されていることが特徴です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aa7ad5",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、与えられたJupyter Notebookの内容に基づいて、機械学習や深層学習の初心者がつまずきそうな専門用語の簡単な解説を列挙します。特にあまり馴染みのない用語や、このノートブック特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **rigging**:\n",
    "   - 特殊なライブラリで、特に大規模な言語モデルを操作するための機能を提供します。具体的には、モデルの生成やチャットインターフェースの構築に役立つツール群です。このコンテキストでは、言語モデルの性能を最大限に引き出すために使用されます。\n",
    "\n",
    "2. **Hugging Face Hub**:\n",
    "   - Hugging Faceのオンラインプラットフォームで、さまざまな事前学習されたモデルを共有・ダウンロードできるリポジトリです。特に自然言語処理(NLP)の分野で人気のモデルが多く公開されています。\n",
    "\n",
    "3. **snapshot_download**:\n",
    "   - Hugging Face Hubから特定のモデルのスナップショット（状態）をダウンロードするための関数。このメカニズムにより、モデルのバージョン管理や安定した環境での再現が可能になります。\n",
    "\n",
    "4. **CUDA**:\n",
    "   - NVIDIAの並列計算プラットフォームおよびAPIで、GPU（グラフィックス処理ユニット）を利用して計算処理を高速化する技術。深層学習モデルのトレーニングや推論を効率的に行うために使用されます。\n",
    "\n",
    "5. **iterators**:\n",
    "   - Pythonのコレクションやデータ構造に対して反復処理を行うためのオブジェクト。特に、ループ処理を行うための特別なメソッドを持ち、データを1つずつ取り出して操作する機能を提供します。\n",
    "\n",
    "6. **Pydantic**:\n",
    "   - Pythonのデータバリデーションと設定管理ライブラリ。型安全性を重視しており、データモデルの検証やシリアライズを簡単に行えるようにします。このノートブックでは、API入力の検証に使用されています。\n",
    "\n",
    "7. **field_validator**:\n",
    "   - Pydanticの機能の一部で、特定のフィールドに対してカスタムなバリデーションロジックを提供します。モデルが期待する値に適合しない場合にエラーを投げる役割を持ちます。\n",
    "\n",
    "8. **Annotated**:\n",
    "   - Pythonの型ヒント機能で、型に追加情報を付加するために使用されます。この情報は、例えば、データが持つべき制約（空白を削除するなど）の定義に用いられます。\n",
    "\n",
    "9. **xml_example**:\n",
    "   - XMLフォーマットの例を生成するメソッド。データをXML形式で表現する際に利用され、他のシステムとのデータのやり取りを容易にするための補助的な役割を果たします。\n",
    "\n",
    "10. **Contextualized Prompting**:\n",
    "   - モデルに対して文脈を考慮した質問をする技術。状態に応じて適切な情報を提供することで、モデルの応答を向上させるための手法です。このノートブックでは、特定の入力から有用な出力を得るために重要です。\n",
    "\n",
    "これらの専門用語は、初心者が理解するのに役立つ基本的な知識を深めるための出発点になるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 依存パッケージのインストール\n",
    "\n",
    "# 必要なパッケージを指定の場所にインストールします\n",
    "!pip install -U \\\n",
    "    -t /kaggle/tmp/lib \\  # インストール先のディレクトリ\n",
    "    rigging \\  # riggingパッケージをインストール\n",
    "    kaggle \\  # kaggleパッケージをインストール\n",
    "    transformers \\  # transformersライブラリをインストール\n",
    "    accelerate \\  # accelerateライブラリをインストール\n",
    "    -i https://pypi.org/simple/ bitsandbytes  # bitsandbytesを指定のリポジトリからインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シークレットの取得\n",
    "\n",
    "# Kaggleのシークレット機能を利用するために必要なライブラリをインポートします\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()  # UserSecretsClientのインスタンスを作成\n",
    "\n",
    "# Hugging Faceのトークンを取得します\n",
    "HF_TOKEN = secrets.get_secret(\"HF_TOKEN\")  # HF_TOKENという名前のシークレットを取得\n",
    "\n",
    "# Kaggleのキーとユーザー名を取得します\n",
    "KAGGLE_KEY = secrets.get_secret(\"KAGGLE_KEY\")  # KAGGLE_KEYという名前のシークレットを取得\n",
    "KAGGLE_USERNAME = secrets.get_secret(\"KAGGLE_USERNAME\")  # KAGGLE_USERNAMEという名前のシークレットを取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのダウンロード\n",
    "\n",
    "# Hugging Face Hubからモデルをダウンロードするために必要なライブラリをインポートします\n",
    "from huggingface_hub import snapshot_download  # モデルのスナップショットをダウンロードするための関数\n",
    "from pathlib import Path  # パス操作のためのライブラリ\n",
    "import shutil  # ファイル操作のためのライブラリ\n",
    "\n",
    "# モデル保存用のパスを定義\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "# 既にモデルのパスが存在する場合は削除します\n",
    "if g_model_path.exists():\n",
    "    shutil.rmtree(g_model_path)  # 既存のモデルディレクトリを削除\n",
    "# 新しいモデル用のディレクトリを作成します\n",
    "g_model_path.mkdir(parents=True)\n",
    "\n",
    "# モデルを指定したリポジトリからダウンロードします\n",
    "snapshot_download(\n",
    "    repo_id=\"alokabhishek/Meta-Llama-3-8B-Instruct-bnb-8bit\",  # ダウンロードするモデルのリポジトリID\n",
    "    local_dir=g_model_path,  # モデルを保存するローカルディレクトリ\n",
    "    local_dir_use_symlinks=False,  # シンボリックリンクを使用しない設定\n",
    "    token=HF_TOKEN  # Hugging Faceのトークンを使用して認証\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み確認\n",
    "\n",
    "# システムのパスにライブラリのディレクトリを追加します\n",
    "import sys\n",
    "sys.path.insert(0, \"/kaggle/tmp/lib\")  # カスタムライブラリのパスを最初に追加\n",
    "\n",
    "# riggingライブラリをインポートします\n",
    "import rigging as rg\n",
    "\n",
    "# モデルを生成するための関数を呼び出します\n",
    "generator = rg.get_generator(\"transformers!/kaggle/tmp/model,device_map=cuda:0\")  # CUDAデバイスを使用してモデルを取得\n",
    "\n",
    "# チャット機能を使用して「Hello!」と発言させます\n",
    "chat = generator.chat(\"Say Hello!\").run()\n",
    "\n",
    "# チャットの最後の返答を出力します\n",
    "print(chat.last)  # チャットの最後のメッセージを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "# モデルの実装\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "# パスの修正\n",
    "\n",
    "g_working_path = Path('/kaggle/working')  # 作業ディレクトリのパス\n",
    "g_input_path = Path('/kaggle/input')  # 入力データのパス\n",
    "g_temp_path = Path(\"/kaggle/tmp\")  # 一時ファイル用のパス\n",
    "g_agent_path = Path(\"/kaggle_simulations/agent/\")  # エージェント用のパス\n",
    "g_model_path = g_temp_path / \"model\"  # モデルのパス\n",
    "\n",
    "# エージェントのパスが存在する場合の処理\n",
    "if g_agent_path.exists():\n",
    "    sys.path.insert(0, str(g_agent_path / \"lib\"))  # エージェントのライブラリをパスに追加\n",
    "    g_model_path = g_agent_path / \"model\"  # モデルのパスを更新\n",
    "else:\n",
    "    sys.path.insert(0, str(g_temp_path / \"lib\"))  # 一時ファイルのライブラリをパスに追加\n",
    "\n",
    "import rigging as rg  # noqa\n",
    "from pydantic import BaseModel, field_validator, StringConstraints  # noqa\n",
    "\n",
    "# 定数\n",
    "\n",
    "g_generator_id = f\"transformers!{g_model_path},trust_remote_code=True,max_tokens=1024,temperature=1.0,top_k=256\"  # モデル生成のためのID設定\n",
    "\n",
    "# 型\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]  # 空白を削除するための型定義\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    step: int  # 現在のステップ\n",
    "    role: t.Literal[\"guesser\", \"answerer\"]  # 役割（予測者または回答者）\n",
    "    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]  # ターンタイプ（質問、回答、推測）\n",
    "    keyword: str  # キーワード\n",
    "    category: str  # カテゴリー\n",
    "    questions: list[str]  # 質問のリスト\n",
    "    answers: list[str]  # 回答のリスト\n",
    "    guesses: list[str]  # 推測のリスト\n",
    "    \n",
    "    @property\n",
    "    def empty(self) -> bool:\n",
    "        # すべての質問、回答、推測が空であればTrueを返す\n",
    "        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n",
    "    \n",
    "    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n",
    "        # 歴史（質問、回答、推測）を取得\n",
    "        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n",
    "\n",
    "    def get_history_as_xml(self, *, skip_guesses: bool = False) -> str:\n",
    "        # XML形式で歴史を取得\n",
    "        return \"\\n\".join(\n",
    "            f\"\"\"\\\n",
    "            <turn-{i}>\n",
    "            Question: {question}\n",
    "            Answer: {answer}\n",
    "            {'Guess: ' + guess if not skip_guesses else ''}\n",
    "            </turn-{i}>\n",
    "            \"\"\"\n",
    "            for i, (question, answer, guess) in enumerate(self.get_history())\n",
    "        ) if not self.empty else \"none yet.\"\n",
    "\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\", \"maybe\"]  # 回答の内容\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        # 回答が有効な値かどうかを検証\n",
    "        for valid in [\"yes\", \"no\", \"maybe\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"無効な回答です。有効な回答のいずれかでなければなりません：'yes', 'no', 'maybe'\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        # XML形式の例を返す\n",
    "        return f\"{Answer.xml_start_tag()}**yes/no/maybe**{Answer.xml_end_tag()}\"\n",
    "\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip  # 質問の内容\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        # XML形式の質問の例を返す\n",
    "        return Question(content=\"**question**\").to_pretty_xml()\n",
    "\n",
    "\n",
    "class Guess(rg.Model):\n",
    "    content: str_strip  # 推測の内容\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        # XML形式の推測の例を返す\n",
    "        return Guess(content=\"**thing/place/person**\").to_pretty_xml()\n",
    "\n",
    "\n",
    "# 関数群\n",
    "\n",
    "def ask(base: rg.PendingChat, observation: Observation) -> str:\n",
    "    # 次の質問を生成する関数\n",
    "    chat = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            あなたは現在次の質問をしています。\n",
    "\n",
    "            <game-history>\n",
    "            {observation.get_history_as_xml(skip_guesses=True)}\n",
    "            </game-history>\n",
    "\n",
    "            上記の歴史に基づいて、次に最も有用なはい/いいえの質問をし、以下の形式で記載してください：\n",
    "            {Question.xml_example()}\n",
    "\n",
    "            - あなたの回答は、最も情報を集められるような焦点を合わせた質問である必要があります\n",
    "            - 質問は一般的なもので始めてください\n",
    "            - 残りの検索空間を二分するように常に努力してください\n",
    "            - 順前の質問と回答に注意を払ってください\n",
    "\n",
    "            あなたの次の質問は何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Question, attempt_recovery=True)  # 質問がパースされるまで実行\n",
    "        .run()\n",
    "    )\n",
    "    return chat.last.parse(Question).content  # 質問の内容を返す\n",
    "\n",
    "\n",
    "def answer(base: rg.PendingChat, observation: Observation) -> t.Literal[\"yes\", \"no\", \"maybe\"]:\n",
    "    # 質問に回答する関数\n",
    "    last_question = observation.questions[-1]  # 最後の質問を取得\n",
    "    chat = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            このゲームの秘密の言葉は「{observation.keyword}」です。\n",
    "\n",
    "            あなたは現在上記の作業に関する質問に答えています。\n",
    "\n",
    "            次の質問は「{last_question}」です。\n",
    "\n",
    "            上記のはい/いいえの質問に答え、以下の形式で記載してください：\n",
    "            {Answer.xml_example()}\n",
    "\n",
    "            - あなたの回答は上記のキーワードに対して正確である必要があります\n",
    "            - 常に「yes」、「no」、「maybe」で答えてください\n",
    "\n",
    "            あなたの回答は何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Answer, attempt_recovery=True)  # 回答がパースされるまで実行\n",
    "        .run()\n",
    "    )\n",
    "    return chat.last.parse(Answer).content  # 回答の内容を返す\n",
    "\n",
    "\n",
    "def guess(base: rg.PendingChat, observation: Observation) -> str:\n",
    "    # キーワードの推測を行う関数\n",
    "    pending = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            あなたは現在キーワードの情報に基づいた推測を行っています。\n",
    "\n",
    "            <game-history>\n",
    "            {observation.get_history_as_xml()}\n",
    "            </game-history>\n",
    "\n",
    "            上記の歴史に基づいて、キーワードの次の最良の推測を生成し、以下の形式で記載してください：\n",
    "            {Guess.xml_example()}\n",
    "\n",
    "            - 上記の歴史に基づいて、同じ推測を避けてください\n",
    "            - 推測は具体的人、場所、または物でなければなりません\n",
    "\n",
    "            あなたの推測は何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Guess, attempt_recovery=True)  # 推測がパースされるまで実行\n",
    "        .run()\n",
    "    )\n",
    "        \n",
    "    return chat.last.parse(Guess).content  # 推測の内容を返す\n",
    "\n",
    "# モデル生成器の取得\n",
    "\n",
    "generator = rg.get_generator(g_generator_id)\n",
    "\n",
    "# エントリーポイント\n",
    "\n",
    "def agent_fn(obs: t.Any, _: t.Any) -> str:\n",
    "    # エージェントの主要な関数\n",
    "    observation = Observation(**obs.__dict__)  # 入力されたデータからObservationオブジェクトを作成\n",
    "    \n",
    "    try:\n",
    "        base = generator.chat(\"\"\"\\\n",
    "            あなたは20の質問ゲームの才能あるプレイヤーです。あなたは正確で、焦点を絞り、\n",
    "            構造化されたアプローチを取ります。役に立つ質問を作成し、推測を行い、\n",
    "            キーワードに関する質問に答えます。\n",
    "            \n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "        match observation.turnType:\n",
    "            case \"ask\":\n",
    "                return ask(base, observation)  # 質問を行う\n",
    "            case \"answer\":\n",
    "                if not observation.keyword:\n",
    "                    return \"maybe\"  # キーワードがない場合は「maybe」と返す\n",
    "                return answer(base, observation)  # 回答を行う\n",
    "            case \"guess\":\n",
    "                return guess(base, observation)  # 推測を行う\n",
    "            case _:\n",
    "                raise ValueError(\"未知のターンタイプです\")  # 不明なターンタイプのエラーを発生させる\n",
    "    except Exception as e:\n",
    "        print(str(e), file=sys.stderr)  # エラーを標準エラー出力に表示\n",
    "        raise  # エラーを再度発生させる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "# 必要なパッケージのインストール\n",
    "\n",
    "# pigzとpvをインストールします\n",
    "!apt install pigz pv  # pigzは並列圧縮ツール、pvはデータの視覚化ツールです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.tar.gzの作成\n",
    "\n",
    "# 提出用のtar.gzアーカイブを作成します\n",
    "!tar --use-compress-program='pigz --fast' \\  # pigzを利用して圧縮\n",
    "    -cf submission.tar.gz \\  # アーカイブファイルの名前\n",
    "    --dereference \\  # シンボリックリンクをたどって解凍する\n",
    "    -C /kaggle/tmp model lib \\  # /kaggle/tmp内のmodelとlibディレクトリを追加\n",
    "    -C /kaggle/working main.py  # /kaggle/working内のmain.pyを追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggleへの直接提出\n",
    "\n",
    "# Kaggleに競技会の提出を行います\n",
    "!KAGGLE_USERNAME={KAGGLE_USERNAME} \\  # Kaggleのユーザー名を設定\n",
    " KAGGLE_KEY={KAGGLE_KEY} \\  # KaggleのAPIキーを設定\n",
    " kaggle competitions submit -c llm-20-questions -f submission.tar.gz -m \"Updates\"  # 指定されたコンペティションに提出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac205eb6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント\n",
    "\n",
    "> ## Marília Prata\n",
    "> \n",
    "> Llama3とのRiggingの紹介をありがとう、Nick (Nicklanders)。\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
