{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327b5492",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LLM 20 Questions」コンペティションにおいて、言語モデルを製作し、一般的な言葉当てゲーム「20の質問」をプレイするためのロジックを実装しています。特に、モデルの状態の管理、質問と回答の生成、及び推測を行うエージェントを作成することに取り組んでいます。\n",
    "\n",
    "### 問題へのアプローチ\n",
    "- **依存関係のインストール**: Kaggle環境に必要なライブラリ（`rigging`、`transformers`、`Kaggle`など）をインストール。\n",
    "- **シークレット情報の取得**: Hugging Face及びKaggleのAPIトークンを取得します。\n",
    "- **モデルのダウンロード**: Hugging Face Hubから特定のモデル（`Meta-Llama-3-8B-Instruct-bnb-8bit`）をダウンロードしてローカルに保存します。\n",
    "- **モデルの読み込みと検証**: ダウンロードしたモデルを用いて簡単なチャットを実行し、正常に動作するか確認します。\n",
    "\n",
    "### 使用しているライブラリ\n",
    "- **Rigging**: モデルの質問生成や応答の管理を行うライブラリ。\n",
    "- **Hugging Face**: 事前トレーニングされたモデルをダウンロードし、使用するためのライブラリ。\n",
    "- **pydantic**: データの検証や設定の管理を行うためのライブラリ。\n",
    "\n",
    "### 実装の詳細\n",
    "- **クラス定義**: `Observation`や`Question`、`Answer`、`Guess`といったクラスを実装し、それぞれのデータ構造やバリデーションルールを定義しています。\n",
    "- **関数の実装**: `ask`、`answer`、`guess`といった関数を定義し、それぞれエージェントが質問を生成したり、回答したり、推測を行うロジックを組んでいます。\n",
    "- **メインエントリーポイント**: `agent_fn`関数にて、異なるターンの処理を行い、実際のゲームプレイに必要な動作を管理します。\n",
    "\n",
    "### 出力の整理\n",
    "最終的に、`submission.tar.gz`が生成され、Kaggleコンペティションへの提出が行われます。このスクリプトは、ゲームロジックを忠実に再現し、言語モデルが効果的に機能するための重要な構成要素を構築しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d9594a",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebook内の機械学習・深層学習の専門用語について、初心者がつまずきそうなポイントを解説したものです。\n",
    "\n",
    "1. **Hugging Faceのトークン (HF_TOKEN)**:\n",
    "   Hugging Faceが提供するモデルやデータセットにアクセスするための認証情報です。トークンを利用することで、特定のリソースに対する読み取りや書き込みが可能になります。\n",
    "\n",
    "2. **snapshot_download**:\n",
    "   Hugging Face Hubからモデルやデータをダウンロードする関数です。このライブラリでは、特定のリポジトリからモデルを簡単に取得できます。\n",
    "\n",
    "3. **Rigging**:\n",
    "   特定のフレームワークやライブラリ名で、機械学習モデルの操作を簡素化するために使用されます。このコンテキストでは、質問応答などの処理を行うためのインターフェースを提供しています。\n",
    "\n",
    "4. **PendingChat**:\n",
    "   これは、現在のチャットセッションの待機状態を表します。状態管理が含まれており、特定のコンテキストでの質問や回答を追跡します。\n",
    "\n",
    "5. **BaseModel**:\n",
    "   Pydanticライブラリが提供するクラスで、データモデルを作成する際に使用されます。データのバリデーションや型チェックを簡略化するための機能を持っています。\n",
    "\n",
    "6. **field_validator**:\n",
    "   Pydanticの機能で、特定のフィールドの値を検証するためのメソッドです。この仕組みを利用することで、カスタムバリデーションロジックを簡単に追加できます。\n",
    "\n",
    "7. **Literal**:\n",
    "   型ヒントにおいて、特定のリテラル値のリストを指定するためのものです。これにより、一部の特定の文字列や値のみが許可されることを示します。\n",
    "\n",
    "8. **str_strip**:\n",
    "   標準の文字列型にホワイトスペースを除去する制約を追加したカスタム型です。データの整合性を保つために使われることが多いです。\n",
    "\n",
    "9. **XML形式**:\n",
    "   データの構造を定義するためのマークアップ言語です。ここでは履歴データをXML形式で出力することによって、データの可読性を高め、他のシステムとインターフェースしやすくします。\n",
    "\n",
    "10. **ファイナリゼーション**:\n",
    "   クラスのメソッドの実装において、エラー処理やリカバリのオプションを用意する手法です。コードのロバスト性を高め、予期しない状況に対応するために重要です。\n",
    "\n",
    "11. **二分割探索**:\n",
    "   情報を効率的に得るために使用される戦略です。このプロセスは、質問を通じて探索空間を段階的に狭めていくことを意味し、情報収集を効果的に行う手法です。\n",
    "\n",
    "これらの用語は、特にこのノートブックの特定の文脈に関連しているため、初心者は理解しておくと役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 依存関係のインストール\n",
    "\n",
    "!pip install -U \\\n",
    "    -t /kaggle/tmp/lib \\\n",
    "    rigging \\\n",
    "    kaggle \\\n",
    "    transformers \\\n",
    "    accelerate \\\n",
    "    -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シークレット情報の取得\n",
    "\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()\n",
    "\n",
    "HF_TOKEN = secrets.get_secret(\"HF_TOKEN\")\n",
    "\n",
    "KAGGLE_KEY = secrets.get_secret(\"KAGGLE_KEY\")\n",
    "KAGGLE_USERNAME = secrets.get_secret(\"KAGGLE_USERNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのダウンロード\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "if g_model_path.exists():\n",
    "    shutil.rmtree(g_model_path)  # 既存のモデルパスがあれば削除\n",
    "g_model_path.mkdir(parents=True)  # 新しいモデルパスを作成\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"alokabhishek/Meta-Llama-3-8B-Instruct-bnb-8bit\",\n",
    "    local_dir=g_model_path,\n",
    "    local_dir_use_symlinks=False,\n",
    "    token=HF_TOKEN  # Hugging Faceのトークンを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの読み込み検証\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"/kaggle/tmp/lib\")  # ライブラリパスを追加\n",
    "\n",
    "import rigging as rg  # Riggingライブラリのインポート\n",
    "\n",
    "generator = rg.get_generator(\"transformers!/kaggle/tmp/model,device_map=cuda:0\")  # ジェネレーターの取得\n",
    "chat = generator.chat(\"Say Hello!\").run()  # チャットを実行\n",
    "\n",
    "print(chat.last)  # 最新のチャットメッセージを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "\n",
    "# パスの修正\n",
    "\n",
    "g_working_path = Path('/kaggle/working')\n",
    "g_input_path = Path('/kaggle/input')\n",
    "g_temp_path = Path(\"/kaggle/tmp\")\n",
    "g_agent_path = Path(\"/kaggle_simulations/agent/\")\n",
    "g_model_path = g_temp_path / \"model\"\n",
    "\n",
    "if g_agent_path.exists():\n",
    "    sys.path.insert(0, str(g_agent_path / \"lib\"))  # エージェントのライブラリパスを追加\n",
    "    g_model_path = g_agent_path / \"model\"\n",
    "else:\n",
    "    sys.path.insert(0, str(g_temp_path / \"lib\"))  # 一時的なライブラリパスを追加\n",
    "\n",
    "import rigging as rg  # noqa\n",
    "from pydantic import BaseModel, field_validator, StringConstraints  # noqa\n",
    "\n",
    "# 定数\n",
    "\n",
    "g_generator_id = f\"transformers!{g_model_path},trust_remote_code=True,max_tokens=1024,temperature=1.0,top_k=256\"\n",
    "\n",
    "# 型\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    step: int  # 現在のステップ\n",
    "    role: t.Literal[\"guesser\", \"answerer\"]  # 役割（推測者または回答者）\n",
    "    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]  # ターンの種類\n",
    "    keyword: str  # キーワード\n",
    "    category: str  # カテゴリー\n",
    "    questions: list[str]  # 質問のリスト\n",
    "    answers: list[str]  # 回答のリスト\n",
    "    guesses: list[str]  # 推測のリスト\n",
    "    \n",
    "    @property\n",
    "    def empty(self) -> bool:\n",
    "        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])  # すべてのリストが空か確認\n",
    "    \n",
    "    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n",
    "        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")  # 履歴を取得\n",
    "\n",
    "    def get_history_as_xml(self, *, skip_guesses: bool = False) -> str:\n",
    "        return \"\\n\".join(\n",
    "            f\"\"\"\\\n",
    "            <turn-{i}>\n",
    "            Question: {question}\n",
    "            Answer: {answer}\n",
    "            {'Guess: ' + guess if not skip_guesses else ''}\n",
    "            </turn-{i}>\n",
    "            \"\"\"\n",
    "            for i, (question, answer, guess) in enumerate(self.get_history())\n",
    "        ) if not self.empty else \"none yet.\"  # XML形式で履歴を取得\n",
    "\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\", \"maybe\"]  # 回答の内容\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:  # 回答の内容を検証\n",
    "        for valid in [\"yes\", \"no\", \"maybe\"]:  # 有効な回答を定義\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"Invalid answer, must be one of 'yes', 'no', 'maybe'\")  # 無効な回答の場合エラーを投げる\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}**yes/no/maybe**{Answer.xml_end_tag()}\"  # XML例を返す\n",
    "\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip  # 質問の内容\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"**question**\").to_pretty_xml()  # 質問のXML例\n",
    "\n",
    "\n",
    "class Guess(rg.Model):\n",
    "    content: str_strip  # 推測の内容\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Guess(content=\"**thing/place/person**\").to_pretty_xml()  # 推測のXML例\n",
    "\n",
    "\n",
    "# 関数\n",
    "\n",
    "\n",
    "def ask(base: rg.PendingChat, observation: Observation) -> str:\n",
    "    chat = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            あなたは現在、次の質問をしています。\n",
    "\n",
    "            <game-history>\n",
    "            {observation.get_history_as_xml(skip_guesses=True)}\n",
    "            </game-history>\n",
    "\n",
    "            上記の履歴に基づいて、次に最も有用なはい/いいえの質問を尋ね、以下の形式に置いてください:\n",
    "            {Question.xml_example()}\n",
    "\n",
    "            - あなたの応答は、最も情報を得るための集中した質問である必要があります\n",
    "            - 質問では一般的な内容から始めてください\n",
    "            - 残りの探索空間を常に二分割するようにしてください\n",
    "            - 前の質問と回答に注意を払ってください\n",
    "\n",
    "            次の質問は何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Question, attempt_recovery=True)\n",
    "        .run()\n",
    "    )\n",
    "    return chat.last.parse(Question).content\n",
    "\n",
    "\n",
    "def answer(base: rg.PendingChat, observation: Observation) -> t.Literal[\"yes\", \"no\", \"maybe\"]:\n",
    "    last_question = observation.questions[-1]  # 最後の質問を取得\n",
    "    chat = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            このゲームの秘密の言葉は \"{observation.keyword}\" です。\n",
    "\n",
    "            あなたは現在、上記の作業についての質問に回答しています。\n",
    "\n",
    "            次の質問は \"{last_question}\" です。\n",
    "\n",
    "            上記のはい/いいえの質問に回答し、以下の形式に置いてください:\n",
    "            {Answer.xml_example()}\n",
    "\n",
    "            - あなたの応答は、上記のキーワードに基づいて正確である必要があります\n",
    "            - 常に\"はい\"、\"いいえ\"、または\"多分\"で回答してください\n",
    "\n",
    "            答えは何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Answer, attempt_recovery=True)\n",
    "        .run()\n",
    "    )\n",
    "    return chat.last.parse(Answer).content\n",
    "\n",
    "\n",
    "def guess(base: rg.PendingChat, observation: Observation) -> str:\n",
    "    pending = (\n",
    "        base.fork(\n",
    "            f\"\"\"\\\n",
    "            あなたは現在、キーワードのインフォームド・ゲスを行っています。\n",
    "\n",
    "            <game-history>\n",
    "            {observation.get_history_as_xml()}\n",
    "            </game-history>\n",
    "\n",
    "            上記の履歴に基づいて、キーワードの次の最適な推測を生成し、以下の形式に置いてください:\n",
    "            {Guess.xml_example()}\n",
    "\n",
    "            - 上記の履歴に基づいて繰り返しの推測を避けてください\n",
    "            - 推測は具体的な人、場所、または物であるべきです\n",
    "\n",
    "            あなたの推測は何ですか？\n",
    "            \"\"\"\n",
    "        )\n",
    "        .until_parsed_as(Guess, attempt_recovery=True)\n",
    "        .run()\n",
    "    )\n",
    "        \n",
    "    return chat.last.parse(Guess).content\n",
    "\n",
    "# ジェネレーター\n",
    "\n",
    "generator = rg.get_generator(g_generator_id)\n",
    "\n",
    "# エントリーポイント\n",
    "\n",
    "def agent_fn(obs: t.Any, _: t.Any) -> str:\n",
    "    observation = Observation(**obs.__dict__)  # 観察データを生成\n",
    "    \n",
    "    try:\n",
    "        base = generator.chat(\"\"\"\\\n",
    "            あなたは20の質問ゲームの才能あるプレイヤーです。あなたは正確で、集中力があり、構造的なアプローチを持っています。あなたは有用な質問を作成し、推測を行い、キーワードに関する質問に回答します。\n",
    "            \n",
    "            \"\"\"\n",
    "        )\n",
    "    \n",
    "        match observation.turnType:  # ターンの種類によって処理を分ける\n",
    "            case \"ask\":\n",
    "                return ask(base, observation)  # 質問をする場合\n",
    "            case \"answer\":\n",
    "                if not observation.keyword:  # キーワードがない場合\n",
    "                    return \"maybe\"  # 多分を返す\n",
    "                return answer(base, observation)  # 回答をする場合\n",
    "            case \"guess\":\n",
    "                return guess(base, observation)  # 推測をする場合\n",
    "            case _:\n",
    "                raise ValueError(\"Unknown turn type\")  # 不明なターンタイプの場合エラーを投げる\n",
    "    except Exception as e:\n",
    "        print(str(e), file=sys.stderr)  # エラーを標準エラーに出力\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv  # pigzとpvをインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# submission.tar.gzを作成する\n",
    "\n",
    "!tar --use-compress-program='pigz --fast' \\\n",
    "    -cf submission.tar.gz \\\n",
    "    --dereference \\\n",
    "    -C /kaggle/tmp model lib \\\n",
    "    -C /kaggle/working main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggleに直接プッシュ\n",
    "\n",
    "!KAGGLE_USERNAME={KAGGLE_USERNAME} \\\n",
    " KAGGLE_KEY={KAGGLE_KEY} \\\n",
    " kaggle competitions submit -c llm-20-questions -f submission.tar.gz -m \"Updates\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c2284",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント \n",
    "\n",
    "> ## Marília Prata\n",
    "> \n",
    "> Rigging with Llama3を紹介してくれてありがとう Nick (Nicklanders)。\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
