{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cfeeba",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、2024年5月15日に公開され、コンペティション「LLM 20 Questions」に関連しています。著者はマリリア・プラタ（Marília Prata）とmpwolkeです。本ノートブックでは、言語モデルを用いて「20の質問」ゲームに取り組むための手法やデータの処理方法を示しています。\n",
    "\n",
    "### 主な内容と手法\n",
    "1. **データのインポートと準備**:\n",
    "   - NumPyおよびPandasライブラリを使用して、データの操作と分析に必要な環境を整えています。データセットはJSONファイル形式であり、`pd.read_json()`メソッドを使って読み込まれます。\n",
    "\n",
    "2. **強化学習の概念**:\n",
    "   - マルコフ決定過程（MDP）を用いたポリシーベースの強化学習手法に言及されており、質問選択の最適ポリシーを学ぶエージェントを設計しています。著者はRewardNetを導入し、適切な報酬を推定してエージェントの学習を支援しています。これは、ノイズの多い回答に対して頑健であり、オブジェクトの知識ベースに依存しないという利点を持っています。\n",
    "\n",
    "3. **モデルの実装**:\n",
    "   - KerasとKeras NLPライブラリを使用して、Gemmaという因果言語モデルを適用し、エージェントが質問に対して生成テキストを出力する様子を示しています。Gemmaモデルは、その能力を利用して、特定の質問に対する応答を生成します。\n",
    "\n",
    "4. **エラー処理とデータの正規化**:\n",
    "   - エラー処理に関する注意深い考慮があり、データのタイプの不一致を正規化することで解決できる可能性があります。このような問題を解決するために、データフレームの各部分を整然と処理しています。\n",
    "\n",
    "このNotebookは、強化学習を基にしたQ20ゲームの実装を展望しながら、データの読み込み、処理、モデルの利用までのプロセスを包括的に示しています。特に、これらの手法やライブラリがどのように言語モデルを最適化し、ユーザーとの対話を通してゲームを進行するかに焦点を当てています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e4744e",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関連する専門用語の簡単な解説を挙げます。この解説は、初心者がつまずきそうなマイナーな用語や、実務に馴染みのないものに特化しています。\n",
    "\n",
    "### 1. ポリシーベースの強化学習 (Policy-based Reinforcement Learning)\n",
    "強化学習の一種で、エージェントが行動を選択するための「ポリシー」を直接学習する方法です。これにより、エージェントは環境と相互作用しながら、最適な行動を決定するルールを生成します。特に対話システムやゲームなど、連続的なアクション選択が必要な状況で用いられます。\n",
    "\n",
    "### 2. 報酬ネットワーク (Reward Network)\n",
    "強化学習において、エージェントが行動を選択した結果得られる報酬を推定するためのネットワークです。このネットワークは、エージェントが最適なポリシーを学習するためのフィードバックを提供します。具体的には、エージェントが取った行動に対する「価値」を学習する役割があります。\n",
    "\n",
    "### 3. マルコフ決定過程 (Markov Decision Process; MDP)\n",
    "強化学習において、状態、行動、遷移確率、報酬を表す数学的モデルです。エージェントが環境内でどのように行動すべきかを定義するフレームワークで、状態が次の状態に影響を与えず、現在の状態のみが将来の決定に影響するという「マルコフ性」が特徴です。\n",
    "\n",
    "### 4. エントロピー基盤のエンジニアリング (Entropy-based Engineering)\n",
    "情報理論におけるエントロピーを利用して、システムの不確実性や情報の多様性を最大化しようとする手法です。特にDLモデルのパラメータ調整において、学習の探索性を高めたり、過剰適合を防いだりするために用いられます。\n",
    "\n",
    "### 5. JAX\n",
    "Googleが開発した数値計算ライブラリで、高速な数値計算のための自動微分機能やGPU対応を特徴とします。深層学習ライブラリ（KerasやTensorFlow）との連携も可能で、特に研究開発においてその性能を活かすことができます。\n",
    "\n",
    "### 6. トランスフォーマー (Transformer)\n",
    "自然言語処理や生成モデルで広く使用されるアーキテクチャです。自己注意機構を用いることで、入力シーケンス全体の情報を同時に処理し、長距離依存関係を捉える能力に優れています。BERTやGPTなど多くの強力なモデルの基盤になっていますが、その詳細な動作原理やチューニングが初心者には難解な場合があります。\n",
    "\n",
    "### 7. トークン\n",
    "自然言語処理において、テキストデータを処理する際の基本的な単位です。単語、文字、またはそれらの組み合わせで表現されます。モデルに供給するデータはトークンとして扱われ、モデルの出力や入力において有効に機能します。\n",
    "\n",
    "### 8. 知識ベース (Knowledge Base; KB)\n",
    "特定のドメインにおける情報を組織的に保存・管理するためのシステムやアーキテクチャです。一般的には、オブジェクトや概念に関する情報が含まれており、それを元に質問応答や推論を行う際に利用されます。特に深層学習モデルと組み合わせることで、より正確な情報提供を目指すことが可能です。\n",
    "\n",
    "### 9. 貪欲な選択 (Greedy Selection)\n",
    "最適化問題において、現時点で最も良いと思われる選択を行う手法です。この方式は、即座の報酬を最大化するが、全体の最適解を見逃すことがあるため、長期的な観点からの戦略が欠如することがあります。\n",
    "\n",
    "これらの用語は、機械学習や深層学習の実務に不慣れな初心者が理解する上で障害になる可能性が高いです。特に、強化学習や関連性の高い技術に関しては、理解を深めることが成功へのカギとなります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eedfbb5",
   "metadata": {},
   "source": [
    "2024年5月15日に公開されました。著者：マリリア・プラタ（Marília Prata）、mpwolke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T01:26:47.351907Z",
     "iopub.status.busy": "2024-05-16T01:26:47.351567Z",
     "iopub.status.idle": "2024-05-16T01:26:48.447237Z",
     "shell.execute_reply": "2024-05-16T01:26:48.446456Z",
     "shell.execute_reply.started": "2024-05-16T01:26:47.351879Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# この環境はkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、以下はロードするのに便利なパッケージのいくつかです\n",
    "\n",
    "import numpy as np # 線形代数を扱うライブラリ\n",
    "import pandas as pd # データ処理、CSVファイルの入出力（例：pd.read_csv）\n",
    "\n",
    "# 入力データファイルは、読み取り専用の \"../input/\" ディレクトリにあります\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするか、Shift+Enterを押すことで）入力ディレクトリ内のすべてのファイルがリスト表示されます\n",
    "\n",
    "import os\n",
    "# \"/kaggle/input\"ディレクトリを歩いてファイルを表示する\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        # 各ファイルへのパスをプリントする\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 最大20GBのデータを現在のディレクトリ（/kaggle/working/）に書き込むことができ、これは「すべてを保存して実行」したときに出力として保存されます\n",
    "# 一時ファイルは/kaggle/temp/に書き込むこともできますが、このセッションの外に保存されることはありません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072685f",
   "metadata": {},
   "source": [
    "# コンペティションの引用\n",
    "\n",
    "@misc{llm-20-questions,\n",
    "    author = {ゾーイ・モンガン, ルーク・サーナウ, ウィル・リファース, ボバード・ドアシュク-ティベリ, ライアン・ホルブルック, ウィル・クキエルスキー, アディソン・ハワード},\n",
    "    title = {LLM 20 Questions},\n",
    "    publisher = {Kaggle},\n",
    "    year = {2024},\n",
    "    url = {https://kaggle.com/competitions/llm-20-questions}\n",
    "}\n",
    "\n",
    "# 鳥ですか？飛行機ですか？いいえ、それはkagglerです！\n",
    "\n",
    "![](https://img1.picmix.com/output/pic/normal/5/6/8/3/11323865_2f559.gif) https://en.picmix.com/pic/bird-plane-bert-11323865\n",
    "\n",
    "# 強化学習を用いたQ20ゲーム\n",
    "\n",
    "ポリシーベースの強化学習を用いた20の質問ゲームのプレイ\n",
    "\n",
    "著者：黄虎1、呉進超、羅炳峰、陶崇陽、徐灿、呉威、陳展\n",
    "\n",
    "「本論文では、著者は独自のポリシーベースの強化学習（RL）手法を提案し、質問者エージェントがユーザーとの継続的な相互作用を通じて質問選択の最適ポリシーを学習できるようにします。トレーニングを円滑にするために、彼らは、より情報量の多い報酬を推定するための報酬ネットワークを使用することも提案しました。先行技術と比較して、彼らのRL手法はノイズの多い回答に対して堅牢であり、オブジェクトの知識ベースに依存しません。実験結果は、彼らのRL手法がエントロピー基盤のエンジニアリングシステムを明らかに上回り、ノイズのないシミュレーション環境で競争力のある性能を持っていることを示しています。」\n",
    "\n",
    "「Q20ゲームシステムを構築するアルゴリズムを設計することは簡単ではありません。決定木ベースの方法はQ20ゲームに自然に適合しているように見えますが、通常は、各オブジェクトに関する十分な情報を含む明確に定義された知識ベース（KB）が必要であり、実際には通常入手できません。オブジェクトと質問の選択のためのピボットとしてオブジェクト-質問関連性テーブルを使用し、既存のKB（知識ベース）に依存しない方法で質問を選択します。さらに、多くのエンジニアリングの工夫で関連性テーブルを改善しました。これらのテーブルベースの手法は質問を貪欲に選択し、モデルパラメータはルールによってのみ更新されるため、実際のQ20ゲームで一般的なユーザーからのノイズの多い回答に対して非常に敏感です。一般化能力を向上させるために値基盤の強化学習（RL）モデルを利用しましたが、依然として既存のKBに依存しています。」\n",
    "\n",
    "「本論文では、著者はゲームにおける質問選択のプロセスをマルコフ決定過程（MDP）として定式化し、Q20ゲームにおける質問選択の最適ポリシーを学習するための新しいポリシーベースのRLフレームワークを提案しました。彼らの質問者エージェントは、ターゲットオブジェクトの信頼度をモデル化するためにすべてのオブジェクトに対する確率分布を維持し、ユーザーからの回答に基づいて信頼度を更新します。」\n",
    "\n",
    "「各タイムステップで、エージェントはポリシーネットワークを使用して信頼度ベクトルを入力し、次の質問を選択するための質問分布を出力します。選択された各質問に即時的な報酬がない問題を解決するために、著者はRewardNetを導入して各タイムステップで適切な即時的な報酬を推定することを提案し、これを使用して長期的なリターンを計算しRLモデルをトレーニングします。」\n",
    "\n",
    "「彼らのRL（強化学習）フレームワークは、モデルパラメータが完全に学習可能であり、質問分布が質問をサンプリングするための原則的な方法を提供するため、エージェントをノイズの多い回答に対して堅牢にします。これにより、誤った回答によって引き起こされる局所的最適解からエージェントが脱出できるようにし、また、訓練中により多くのランダム性を導入してモデルの一般化能力を向上させます。さらに、質問をサンプリングする能力は、貪欲な選択と比較して、エージェントが尋ねる質問の多様性を向上させ、ユーザー体験にとって重要です。」\n",
    "\n",
    "https://www.researchgate.net/publication/327199595_Playing_20_Question_Game_with_Policy-Based_Reinforcement_Learning\n",
    "\n",
    "# llm_20_questions jsonファイル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:30.842511Z",
     "iopub.status.busy": "2024-05-16T00:56:30.841999Z",
     "iopub.status.idle": "2024-05-16T00:56:30.876504Z",
     "shell.execute_reply": "2024-05-16T00:56:30.875373Z",
     "shell.execute_reply.started": "2024-05-16T00:56:30.842476Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームをJSONファイルから読み込むためのコードです\n",
    "# df = pd.read_json(path_or_buf='/kaggle/input/llm-20-questions/llm_20_questions/llm_20_questions.json')\n",
    "\n",
    "# 行ごとにJSONを読み込むための別のコードです\n",
    "# df= pd.read_json('../input/llm-20-questions/llm_20_questions/llm_20_questions.json', lines=True)\n",
    "\n",
    "# JSONファイルをシリーズとして読み込みます\n",
    "df= pd.read_json('../input/llm-20-questions/llm_20_questions/llm_20_questions.json', typ=\"series\")\n",
    "\n",
    "# データフレームの最初の5行を表示します\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ff328",
   "metadata": {},
   "source": [
    "# 矢印の近くには：エージェント、設定、報酬、観察、アクション、ステータスがあります\n",
    "\n",
    "「辞書と非シリーズを混在させることは、あいまいな順序を引き起こす可能性があります」というエラーが発生しました。\n",
    "\n",
    "データ型がばらばらで、文字列やリスト、複数の{}などが存在するためです。このエラーは、データを正規化することで解決できるかもしれません。\n",
    "\n",
    "https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:35.970937Z",
     "iopub.status.busy": "2024-05-16T00:56:35.970288Z",
     "iopub.status.idle": "2024-05-16T00:56:35.977922Z",
     "shell.execute_reply": "2024-05-16T00:56:35.97699Z",
     "shell.execute_reply.started": "2024-05-16T00:56:35.970902Z"
    }
   },
   "outputs": [],
   "source": [
    "# MpwolkeのKaggleノートブックへのリンクです https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series\n",
    "\n",
    "# StackOverflowの質問へのリンクです: https://stackoverflow.com/questions/49505872/read-json-to-pandas-dataframe-valueerror-mixing-dicts-with-non-series-may-lea\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# JSONファイルを開いて読み込み、「observation」キーの内容を取得します\n",
    "ques = json.load(open('../input/llm-20-questions/llm_20_questions/llm_20_questions.json'))\n",
    "\n",
    "# 「observation」のデータをデータフレームに変換します\n",
    "df = pd.DataFrame(ques[\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:41.397293Z",
     "iopub.status.busy": "2024-05-16T00:56:41.396915Z",
     "iopub.status.idle": "2024-05-16T00:56:41.4194Z",
     "shell.execute_reply": "2024-05-16T00:56:41.418396Z",
     "shell.execute_reply.started": "2024-05-16T00:56:41.39726Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームの最初の5行を表示します\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:46.507035Z",
     "iopub.status.busy": "2024-05-16T00:56:46.506181Z",
     "iopub.status.idle": "2024-05-16T00:56:46.518447Z",
     "shell.execute_reply": "2024-05-16T00:56:46.517366Z",
     "shell.execute_reply.started": "2024-05-16T00:56:46.507001Z"
    }
   },
   "outputs": [],
   "source": [
    "# 「configuration」のデータをデータフレームに変換します\n",
    "df1 = pd.DataFrame(ques[\"configuration\"])\n",
    "\n",
    "# データフレームの最初の5行を表示します\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a1f92",
   "metadata": {},
   "source": [
    "# 設定を転置する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:51.44785Z",
     "iopub.status.busy": "2024-05-16T00:56:51.447108Z",
     "iopub.status.idle": "2024-05-16T00:56:51.459589Z",
     "shell.execute_reply": "2024-05-16T00:56:51.458641Z",
     "shell.execute_reply.started": "2024-05-16T00:56:51.447815Z"
    }
   },
   "outputs": [],
   "source": [
    "# 設定データフレームを転置します\n",
    "df1_transposed = df1.T\n",
    "\n",
    "# 転置したデータフレームの最初の5行を表示します\n",
    "df1_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:56.304742Z",
     "iopub.status.busy": "2024-05-16T00:56:56.303824Z",
     "iopub.status.idle": "2024-05-16T00:56:56.31415Z",
     "shell.execute_reply": "2024-05-16T00:56:56.313011Z",
     "shell.execute_reply.started": "2024-05-16T00:56:56.304705Z"
    }
   },
   "outputs": [],
   "source": [
    "# 「status」のデータをデータフレームに変換します\n",
    "df2 = pd.DataFrame(ques[\"status\"])\n",
    "\n",
    "# データフレームの最初の5行を表示します\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169218cb",
   "metadata": {},
   "source": [
    "# Kerasをインストールする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T01:27:27.888979Z",
     "iopub.status.busy": "2024-05-16T01:27:27.888524Z",
     "iopub.status.idle": "2024-05-16T01:28:12.99439Z",
     "shell.execute_reply": "2024-05-16T01:28:12.993421Z",
     "shell.execute_reply.started": "2024-05-16T01:27:27.888952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasをインストールします。最新バージョン3をインストールします。詳細についてはhttps://keras.io/getting_started/を参照してください。\n",
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "\n",
    "import os\n",
    "\n",
    "# Kerasのバックエンドを\"jax\"（または\"torch\"、\"tensorflow\"）に設定します。\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # または \"torch\" または \"tensorflow\" \n",
    "# JAXバックエンドでのメモリの断片化を避けるための設定です。\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\n",
    "\n",
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745280a1",
   "metadata": {},
   "source": [
    "# Gemma_2b_en\n",
    "\n",
    "最初のノートブックはGemma 7bを適用する予定でしたが、解決できない予期しないエラーが発生しました。それで、Gemma 2bを使用してみることにしました。ただし、意図していた質問のデータセットを持っていません。言い換えれば、それは運が悪くなりました。運が悪いコードのコレクションにまた一つ追加です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T01:28:15.748731Z",
     "iopub.status.busy": "2024-05-16T01:28:15.748018Z",
     "iopub.status.idle": "2024-05-16T01:30:02.607736Z",
     "shell.execute_reply": "2024-05-16T01:30:02.606631Z",
     "shell.execute_reply.started": "2024-05-16T01:28:15.748687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gemmaの因果言語モデルを指定のプレセットからロードします。\n",
    "# 実行時間を計測します。\n",
    "%%time\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b782452",
   "metadata": {},
   "source": [
    "# すべての答えは「はい」です。ただし、最後の答えを除いて。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T01:30:10.552435Z",
     "iopub.status.busy": "2024-05-16T01:30:10.551987Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Is Gemma, an open model based on Google's Gemini models?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Is Gemma a lightweight, text-to-text, decoder-only large language model?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Is Gemma a support low-latency generative AI used in cases such as streaming text?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Has Gemma 27 billion parameters?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Is LLaVA-Gemma, a MMFM that leverages the powerful Gemma language models for efficient multimodal interactions?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Is JAX a framework developed by Google?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Are you a model Gemma?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定した質問に対してGemmaモデルからの生成テキストを出力します。\n",
    "# 生成されるテキストの最大長は1024トークンです。\n",
    "print(gemma_lm.generate(\"Are you participating on this Q20 game Gemma?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04480364",
   "metadata": {},
   "source": [
    "![](https://www.wallyandosborne.com/wp-content/uploads/2006/02/2005-11-01.gif) https://www.wallyandosborne.com/wp-content/uploads/2006/02/2005-11-01.gif\n",
    "\n",
    "# 謝辞\n",
    "\n",
    "mpwolkeのノートブックへのリンクです: https://www.kaggle.com/code/mpwolke/eureka-gemma-1-1-instruct-7b-en\n",
    "\n",
    "また、こちらのノートブックも参考にしました: https://www.kaggle.com/code/mpwolke/thanks-for-delivering-my-writeup-order-gemma/notebook\n",
    "\n",
    "さらに、mpwolkeの他のノートブック: https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663d45e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント \n",
    "\n",
    "> ## SuM\n",
    "> \n",
    "> 興味深いゲームですね、共有してくれてありがとう😀\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## GODDiao\n",
    "> \n",
    "> 笑！それをエージェントにする方法は？\n",
    "> \n",
    "> > ## マリリア・プラタ（トピック著者）\n",
    "> > \n",
    "> > まったく手がかりがありません、GODDiao : )\n",
    "> > \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## アナ・ペドラ・ロペス\n",
    "> \n",
    "> 面白いタスクですね！\n",
    "> \n",
    "> > ## マリリア・プラタ（トピック著者）\n",
    "> > \n",
    "> > 確かに、アナ、ファイルを開いた後にこのタスクがどれほど難しいかを実感しました。私の知識ではとても手が届きません。\n",
    "> > \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## マルシオ・サントス\n",
    "> \n",
    "> 共有してくれてありがとう !!!\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## ムサ・カーン\n",
    "> \n",
    "> シンプルでユーモラスで、すべてはそうあるべきです！\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## マリリア・プラタ（トピック著者）\n",
    "> \n",
    "> あなたのサポートに感謝します、ファティフ。ありがとう。\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5388,
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
