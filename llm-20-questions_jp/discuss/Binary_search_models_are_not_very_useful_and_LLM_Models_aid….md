# バイナリサーチモデルはあまり役に立たず、LLMモデルがバイナリサーチモデルを支援しても利益はない

**OminousDude** *2024年5月31日 (金) 03:16:05 GMT+0900 (日本標準時)* (1票)
まず第一に、バイナリモデルはお勧めしません。なぜなら、コンペティションの制作者の一人が言っているように、
「提出締切後に単語リストを変更し、その後スコアが安定するのを待ちます。固定された単語リストを前提とするエージェントは、かなりの悪影響を受けるでしょう。」
次に、最近私のログで、多くの他の人と同様に、バイナリサーチ戦略を取っていることを見つけました。その主な方法は、文字を推測する戦略で、推測者がキーワードの最初の文字がa-gの間にあるか、g-mの間にあるかを尋ねるというものです。私のモデルを助けるために、私は暗黙的にキーワードの最初の文字を教えることにしました。つまり、プロンプトエンジニアリング/コンテキスト内で、モデルに次のように伝えました。
キーワードは「{keyword}」で、キーワードの最初の文字は「{keyword[0]}」
しかし、これがモデルを助けることはなく、むしろパフォーマンスとスコアをかなり低下させました。これはなぜ起こるのか想像できません。もし意見があれば、コメント欄にぜひお知らせください。
このディスカッションを設けたのは、バイナリサーチモデルを使うことに対するアドバイスのためであり、最終的にはほとんど役に立たなくなるでしょう。なぜなら、実際にほとんどのキーワードが変更されるからです。
このディスカッションが役に立ったと思ったら、ぜひ投票をお願いします。読んでいただき、ありがとうございました。皆さんの助けになれば幸いです！

---
# 他のユーザーからのコメント

> ## waechter
> 
> 共有してくれてありがとう！
> 
> 「しかし、これがモデルを助けることはなく、むしろパフォーマンスとスコアをかなり低下させました」
> 
> どのようにパフォーマンスを測定しましたか？ リーダーボードのスコアは今のところあまりにもランダムなので、それを考慮するよりも、質問が正しく答えられたかを確認する方が良いと思います。
> 
> 私のノートブックで確認したところ、あなたのエージェントは「キーワードの最後の文字がこのリストにあるか？」のような質問には正しく答えています。だから、もしかしたらあなたのモデルはその追加の助けを必要としないのかもしれません？

> ## OminousDude (トピック作成者)
> 
> モデルを同時に提出して、すべてのゲームからの動きを平均化しました。私は私のモデルがこれらのケースで失敗するのを見ましたが、古いバージョンだったかもしれません。

> > ## OminousDude (トピック作成者)
> > 
> これがあなたのモデルには役立つかもしれませんが、私のモデルには改善されませんでした。

---
> ## Lucas Fernandes
> 
> なぜバイナリサーチモデルがすべての単語にアクセスできないと考えるのですか？ LLMもバイナリサーチモデルと同じようにデータセットを使用して答えを見つける必要があります。

> ## Marek Przybyłowicz
> 
> まさに私の考えです。英単語の辞書（約50万語）はわずか5MB程度です。なぜすべての単語を読み込まないのですか？
> 
> 問題があるとすれば、それは答えを見つけるスピードだと思います。

> > ## Lucas Fernandes
> > 
> > 私が取り組んでいる方法は、検索が質問に対応しているので、実際には十分に速いです。課題は、すべての単語が20の質問以内で見つけられるユニークなパスを作ることです。
