# 要約 
このディスカッションは、Kaggleの「LLM 20 Questions」コンペティションにおけるバイナリサーチモデルの有効性について議論しています。

**OminousDude**は、バイナリサーチモデルはコンペティションのルール変更によって役に立たなくなり、LLMモデルを支援する試みも効果がないと主張しています。彼は、モデルにキーワードの最初の文字を明示的に伝えることでパフォーマンスが低下した経験を共有し、その理由を理解したいと考えています。

**waechter**は、OminousDudeのモデルがキーワードの最後の文字に関する質問に正しく答えていることを指摘し、追加の助けは必要ない可能性があると示唆しています。OminousDudeは、古いバージョンのモデルでは問題が発生していた可能性があると回答しています。

**Lucas Fernandes**と**Marek Przybyłowicz**は、バイナリサーチモデルがすべての単語にアクセスできないと仮定する理由が理解できないと述べています。彼らは、すべての英語の単語をロードして、質問に対応する検索を行う方法を提案しています。Lucas Fernandesは、ツリー構造を作成することで、すべての単語が20問以内で発見できる一意のパスを持つようにすることを目指しています。

**要約:**

このディスカッションは、コンペティションのルール変更によってバイナリサーチモデルの有効性が低下した可能性があることを示唆しています。また、LLMモデルを支援するための戦略が必ずしも効果的ではないことを示しています。参加者たちは、すべての単語をロードして検索を行う方法や、ツリー構造を作成する方法など、より効果的な戦略を探求しています。


---
# バイナリサーチモデルはあまり役に立たず、LLMモデルがバイナリサーチモデルを支援しても有益ではありません

**OminousDude** *2024年5月31日 金曜日 03:16:05 GMT+0900 (日本標準時)* (1票)

まず、バイナリモデルの使用は避けるべきです。なぜなら、コンペティションの主催者の一人が言っているように、

> 「提出期限後に単語リストを変更し、スコアが安定するまで待ちます。固定された単語リストを前提とするエージェントは、かなり低いパフォーマンスになります。」

第二に、最近自分のログで、自分自身（そして他の多くの人々）がバイナリサーチ戦略に対抗していることに気づきました。その主なタイプは、文字推測戦略であり、推測者はキーワードの最初の文字がa-gの間にあるか、g-mの間にあるかなどを尋ねます。モデルを助けるために、キーワードの最初の文字を暗黙的に伝えることにしました。そのため、プロンプトエンジニアリング/コンテキストの中で、モデルに次のように伝えました。

> キーワードは"{keyword}"で、キーワードの最初の文字は"{keyword[0]}"です。

しかし、これはモデルの助けにはならず、むしろパフォーマンスとスコアを大幅に低下させてしまいました。なぜこのようなことが起こるのか理解できず、もし誰かにアイデアがあれば、コメント欄で共有していただければ幸いです。

このディスカッションは、バイナリサーチモデルを支援（および使用）することの是非について議論するために作成しました。なぜなら、バイナリサーチモデルは、最終的にプライベートリーダーボードではほとんど役に立たなくなるからです。実際、ほとんどすべてのキーワードが変更されるからです。

このディスカッションが役に立てば幸いです。ぜひ upvote してください。読んでいただきありがとうございます。これがお役に立てば幸いです！

---
# 他のユーザーからのコメント

> ## waechter
> 
> ご意見を共有していただきありがとうございます！
> 
> しかし、これはモデルの助けにはならず、むしろパフォーマンスとスコアを大幅に低下させてしまいました。
> 
> パフォーマンスはどうやって測定しましたか？今のところリーダーボードのスコアはあまりにもランダムなので、質問が正しく回答されているかどうかを確認する方が良いと思います。
> 
> [自分のノートブック](https://www.kaggle.com/code/waechter/llm-20-questions-leaderbord-analyze-best-agents?scriptVersionId=180667811&cellId=30) で見たところ、あなたのエージェントは、キーワードの最後の文字がこのリストにあるかどうかといった質問に正しく答えています。そのため、あなたのモデルは追加の助けを必要としていないのかもしれません？
> 
> 
> 
> > ## OminousDudeトピック作成者
> > 
> > モデルを同時に提出して、すべてのゲームからのすべての移動の平均値を計算することにしました。そして、これは
> > 
> > [自分のノートブック](https://www.kaggle.com/code/waechter/llm-20-questions-leaderbord-analyze-best-agents?scriptVersionId=180667811&cellId=30) で見たところ、あなたのエージェントは、キーワードの最後の文字がこのリストにあるかどうかといった質問に正しく答えています。そのため、あなたのモデルは追加の助けを必要としていないのかもしれません？
> > 
> > おかしいことに、モデルがこれらのケースで失敗しているのを見ましたが、古いバージョンだったのかもしれません。
> > 
> > 
> > > ## OminousDudeトピック作成者
> > > 
> > > これはあなたのモデルには役立つかもしれませんが、私のモデルには改善が見られませんでした。
> > > 
> > > 
> > > 
---
> ## Lucas Fernandes
> 
> なぜバイナリサーチモデルがすべての単語にアクセスできないと仮定するのですか？そして、LLMもバイナリサーチモデルと同じように、答えを見つけるためにデータセットを使用する必要があるでしょう。
> 
> 
> 
> > ## Marek Przybyłowicz
> > 
> > 私の考えと同じです。すべての英語の単語（約50万語）の辞書は、わずか5MBです。なぜすべてをロードしないのですか？
> > 
> > 問題があるとすれば、答えを見つける速度です。
> > 
> > 
> > 
> > > ## Lucas Fernandes
> > > 
> > > 私が取り組んでいる方法は、検索が質問された質問に対応しているので、実際には十分な速度です。課題は、すべての単語が20問以内で発見できる一意のパスを持つように、ツリーを作成することです。
> > > 
> > > 
> > > 
---

