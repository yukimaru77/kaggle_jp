# 要約 
このディスカッションは、KaggleのLLM 20Qコンペティションの評価指標についてです。

OminousDudeは、自分のモデルをテストするために、コンペティションの評価指標について質問しました。Chris Deotteは、評価指標は、以前プレイしたゲームの数に基づいた式を使用して、全体的なリーダーボードがどのように増加するかであると説明しました。しかし、検証中は、この指標を使用できないと述べています。

Chris Deotteは、検証では、精度と勝利の速度だけを重視すべきだと提案しました。つまり、モデルを最適化して、20回の質問で単語を正しく推測し、できるだけ少ない推測回数で推測できるようにする必要があるということです。

OminousDudeは、Chris Deotteの回答に感謝しましたが、自分の質問は、圧縮されたモデルが互いにどのようにプレイされるかを知りたいということだったと説明しました。 


---
# LLM 20Q の評価指標はどこで見れますか？
**OminousDude** *2024年6月29日(土) 07:03:28 JST* (0 votes)

要するに、タイトル通り自分のモデルをテストしたかったんです。😁

---
# 他のユーザーからのコメント
> ## Chris Deotte
> 
> "評価指標" は、以前プレイしたゲームの数に基づいた式を使用して、全体的な LB がどのように増加するかです。しかし、検証中は、これを使用できないと思います。
> 
> 検証では、精度と勝利の速度だけを重視すべきだと思います。言い換えれば、モデルを最適化して、20回の質問で単語を正しく推測し、できるだけ少ない推測回数（つまり 20 回未満）で推測できるようにします。
> 
> 
> 
> > ## OminousDudeTopic Author
> > 
> > わかりました、ありがとうございます！
> > 
> > 
> > 
> > > ## OminousDudeTopic Author
> > > 
> > > すみません、私の言いたいことはそれではありませんでした。圧縮されたモデルが互いにどのようにプレイされるかを知りたかったのです。
> > > 
> > > 
> > > 
---

