# 新しいモデル (7B-14B) のリリース！
**Chris Deotte** *2024年7月29日 06:07:11 JST* (17票)
ここ1-2ヶ月で多くの新しいモデルがリリースされました。皆さんはこれらの新しいモデルを試しましたか？パフォーマンスはいかがですか？
- Gemma2-9B-IT [こちら](https://huggingface.co/google/gemma-2-9b-it)
- (Nvidia) Mistral-Nemo-Instruct-2407 (12B) [こちら](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407)
- (Nvidia) Minitron-8B-base [こちら](https://huggingface.co/nvidia/Minitron-8B-Base)
- Apple-DCLM-7B [こちら](https://huggingface.co/apple/DCLM-7B)
- Llama-3.1-8B-Instruct [こちら](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)
- Qwen2-7B-Instruct [こちら](https://huggingface.co/Qwen/Qwen2-7B-Instruct)
- Phi-3-Mini-4k-Instruct (4B) [こちら](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)
- Phi-3-Medium-4k-Instruct (14B) [こちら](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)
---
 # 他のユーザーからのコメント
> ## Matthew S Farmer
> 
> gemma 2 - マークダウン形式で答えるのが好きで、少し一般的な回答をするが、指示に従うのが得意のよう。カテゴリ語彙が少し向上すれば、このコンペでの優秀な候補になると思います。
> 
> mistralのバリエーション（nemo intとminitron） - 指示に従うのが難しいです。
> 
> llama 3.1 - kaggle環境でROPEエラーが発生します。
> 
> Qwen2 7b - 指示に従うのが得意で、キーワードに対する具体的な回答には失敗します。
> 
> Phi3 mini - 3つの役割において全体的に良いが、「もの」カテゴリの語彙が限られています。
> 
> Phi3 medium - 不思議なことにPhi3 miniよりも性能が劣る？質問者や推測者として、哲学的になってしまうのを防ぐのが非常に難しかったです。同様の論理的探求を持つAWQとして実装され、量子化が指示トレーニングに影響しているのかもしれません。
> 
> 私はコミュニティの微調整されたLLaMa 3に戻っています…そこで最良の結果が得られています。
> 
> MaziyarPanahi/Llama-3-8B-Instruct-v0.10
> 
> mlabonne/Daredevil-8B
> 
> openchat/openchat-3.6-8b-20240522
> 
> > ## Chris Deotte トピック作成者
> > 
> > 包括的な概要をありがとうございます。素晴らしい実験ですね。
> > 
> > > ## OminousDude
> > > 
> > > 私は上記のほとんどのモデルを試しており、使用するモデルとその理由についてより正確な説明ができます。
> > > 
> > > Gemma 2: このモデルは、huggingfaceがアップグレードされない限りエラーを出します（Kaggle環境は、"Gemma2ForCasualLM"がサポートされていない古いバージョンを使用していると思います）。さらに、このモデルは現在のパラメータ数でLLMリーダーボードで最高のスコアを持っている非常に良いモデルです。しかし、このモデルは最近リリースされたばかりで、微調整が不十分です。私が言いたいのは、ほとんどのモデル（例えばLlama 3）は、多くの微調整済みバリエーション（Smaugなど）を持っており、それぞれが異なる点で役立ち、他の点では劣ることです。私にとって完璧なモデルはGemma 2ではありません。なぜなら、まだそれらのバリエーションが存在しないからです。そのため、Gemma 2はLLM 20Q向けではなく、特定のタスクで微調整された他のモデルに順位を上げられる可能性があります。
> > > 
> > > Mistral + バリエーション: Matthewが言ったように、指示に従うのが難しく、洗練されたプロンプトを持つ人は運がないでしょう。しかし、Nemoは他のモデルとは異なり、現在の小型モデルの中で最も良いトークナイザーであるTekkenを持つため、異なると思います。[こちらに説明があります](https://mistral.ai/news/mistral-nemo/)
> > > 
> > > Llama 3.1: 非常に有望ですが、ロード時にエラーが発生します。ロードエラーが解決されれば、このコンペのトップにLlama 3.1だけになるかもしれません。しかし、時間が経てばわかることであり、誰かがこのモデルを機能させられれば、このコンペはLlama 3.1に支配されるかもしれません。
> > > > 
> > > Qwen2: Matthewとは異なる意見ですし、統計も私に味方しています。このモデルは私のテストによって、高度な指示に従うのが得意ではないと考えています。[LLMリーダーボード](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard)でも結果がそれを示しています。IFEvalスコア（指示に従う能力を示す）は31.49（指示済みバリエーションが56.79のスコア）ですが、Llama 3に比べるとかなり劣ります。Llama 3は74.08を得ます（三指示スコア）。さらに、Llama 3.1は77.40を得ており、20ポイント以上もリードしています。しかし、Qwenは良い回答者で良い質問をする（ただし指示に従う能力は劣ります）。
> > > > 
> > > Phi 3 mini & medium: Miniが優れた性能を示しますが、はるかに少ないデータで訓練されているため、あまり多くのオブジェクトを知りません。Mediumは、[これらの](https://www.kaggle.com/competitions/llm-20-questions/discussion/519297)平面地球に関する質問を出したボットかもしれません。Matthewが言ったように、時々質問する側で質問を出すことがあります。
> > > > 
> > > Mattの上記の発言を理解するのに役立つことを願っています。
> > > > 
> > > PS: 明らかに最良の戦略はアルファベットの二分探索です。なぜなら、公開リーダーボードで非常に高いスコアを持っているからです。
> > > 
> > > 
> > ## G R Shanker Sai
> > > 
> > こんにちは [@matthewsfarmer](https://www.kaggle.com/matthewsfarmer)、
> > > 
> > Matthewさんの意見に感謝しますが、"LLaMa 3のコミュニティ微調整"とは、Hugging Faceにある異なるフレーバーのことを指していますか？それとも自分のデータで微調整しているのですか？
> > > 
> > > 
> > > 
> > ## Matthew S Farmer
> > > > 
> > > はい、Hugging Faceのことです。私はコメントの下部にいくつかリストアップしました。また、モデルを微調整したこともありますが、HFのものがあまりにも優れています！
> > > 
> > > 
> > ## Matthew S Farmer
> > > 
> > RoPEエラー解決済み: [こちら](https://www.kaggle.com/competitions/llm-20-questions/discussion/523619)
> > >
---
> ## Muhammad Ehsan
> 
> (ChatGPT-4oによる執筆)
> 
> 各モデルについてもう少し詳しく述べます：
> 
> - Gemma2-9B-IT: 
> 
> このモデルは9億のパラメータを持ち、詳細な理解や複雑なタスクに最適化されています。コンテキストやニュアンスの深い理解を必要とするアプリケーションに役立ちます。
> 
> - Mistral-Nemo-Instruct-2407: 
> 
> 12億のパラメータを持つこのモデルは、指示に特化しており、与えられた具体的な指示に従い、実行するのが得意です。
> 
> - Minitron-8B-base: 
> 
> 8億のパラメータを持つ一般的なベースモデルです。多用途でさまざまなタスクに使用できますが、他のモデルと比べると特化した能力は持たないかもしれません。
> 
> - Apple-DCLM-7B: 
> 
> Appleが開発したこのモデルは、7億のパラメータを持っています。さまざまなアプリケーションを対象としており、Appleのエコシステムに特有の機能や最適化が含まれている可能性があります。
> 
> - Llama-3.1-8B-Instruct: 
> 
> 8億のパラメータを持つこのLlamaバージョンは、指示やガイドラインに従うタスクに合わせて調整されています。特定のコマンドを理解し、行動する能力を向上させています。
> 
> - Qwen2-7B-Instruct: 
> 
> 指示に焦点を当てた別のモデルで、7億のパラメータを持っています。詳細な指示を効果的に解釈し、応答することを目指しています。
> 
> - Phi-3-Mini-4k-Instruct: 
> 
> 4億のパラメータを持つこの小型モデルは、指示に従うことに特化しており、広範な処理能力は必要ありませんが、良好な命令追従能力を求めるタスクに適しています。
> 
> - Phi-3-Medium-4k-Instruct: 
> 
> 14億のパラメータを持つ中型モデルで、指示追従タスクにも対応しており、小型モデルと比べて処理能力や複雑さを提供します。
> 
> > ## OminousDude
> > 
> > この返信を書くためにどのモデルを使用しましたか？Llama 3でしょうか？AI生成のように見えます…
> > 
> > 
> > > ## fufu2022
> > > 
> > > ありがとうございます！Gemma2-9B-ITとLlama-3.1-8Bが私にとっては最高です。
> > > 
> > > 
> > > > ## torino
> > > > 
> > > > こんにちは[@fufu2022](https://www.kaggle.com/fufu2022)、
> > > > 
> > > > 提出環境でどのようにLlama3.1をロードしますか？秘密でないなら、共有していただけますか？
> > > > 
> > > > 
> > > > > ## OminousDude
> > > > > 
> > > > > 彼はそれを行っていないと思いますが、誰かがそれを成功させたかどうかはわかりません。彼は単に良い結果が出ると思っているだけでしょう。
> > > > 
> > > > > ## Matthew S Farmer
> > > > > 
> > > > > 今日、私は[解決策を開発しました。](https://www.kaggle.com/competitions/llm-20-questions/discussion/523619)
> > > > > 
> > > > 
---
> ## francesco fiamingo
> 
> すごい！いくつかは試しました（mistral, llama, qwen）が、他のものは聞いたことがなかったです！ありがとうございます！ところで、どれが私たちのゲームに最適だと思いますか？
> 
> ---
> ## Aadit Shukla
> 
> これらの新しいモデルを試す機会はまだありませんが、そのパフォーマンスにとても興味があります。聞いたところによると、印象的な能力を持っているようです。ここで体験したことがある方はいらっしゃいますか？あなたの意見をお聞きしたいです！ 
> 
>  更新ありがとうございます [@cdeotte](https://www.kaggle.com/cdeotte) 。
