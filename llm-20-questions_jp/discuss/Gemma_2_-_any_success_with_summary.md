# 要約 
このディスカッションは、Kaggleの「LLM 20 Questions」コンペティションにおいて、新しくリリースされたGemma 2モデルの使用に関するものです。

VassiliPhは、Gemma 2モデルを使ってコンペティションで成功した人がいるかどうか質問しています。

Kasaharaは、Gemma 2モデルをローカルにダウンロードしてテスト環境では動作させたものの、提出ファイルを作成すると出力ディレクトリの容量を超えてしまい、提出できなかったと報告しています。

Mitsutaniは、Gemma 2モデルを使って提出ファイルを作成し、圧縮して提出しましたが、検証にパスしなかったと報告しています。ログが空だったため、原因が分からず、main.pyが/submission内のファイルに対してのみ実行されるようにコードを変更する方法を質問しています。 


---
# Gemma 2 を使って成功した人はいますか？
**VassiliPh** *2024年6月28日 金曜日 03:36:25 日本標準時* (2 votes)

本日リリースされたばかりの新しい Gemma 2 をこのコンペティションで使用して成功した人はいますか？
[https://www.kaggle.com/models/google/gemma-2/keras](https://www.kaggle.com/models/google/gemma-2/keras)

---
# 他のユーザーからのコメント
> ## Kasahara
> 
> GPU メモリエラーのため、実行できませんでした。
> 
> そこで、[このコード](https://kaggle.com/code/kasafumi/gemma2-9b-it-llm20-questions) に示されているように、LLM をローカルにダウンロードしたところ、テスト環境では動作しました。
> 
> しかし、提出ファイルを作成すると出力ディレクトリの容量を超えてしまい、提出できませんでした。
> 
> 
> 
> > ## Mitsutani
> > 
> > Gemma 2 を使おうとしています。あなたのノートブックの出力ファイルをダウンロードして、自分のコンピューターで圧縮してから、圧縮ファイルを提出しましたが、検証にパスしませんでした（ログが空でした）。何か原因がわかるか、main.py が /submission 内のファイルに対してのみ実行されるようにコードを変更する方法を教えてください。初心者なので、どんな助けでも感謝します。
> > 
> > 
> > 
--- 

