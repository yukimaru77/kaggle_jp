# 要約 
このKaggleコンペティション「LLM 20 Questions」におけるモデル選択に関するディスカッションでは、参加者たちは、演繹的推論と明示的な指示への従順性が重要な要素であると認識しています。

Matthew S Farmerは、Hugging Face Open LLM Leaderboardで高いパフォーマンスを示すPhi 3、Qwen 2、Openchat 3.5、Yi、Hermes 2などのモデルを推奨しています。彼は、MUSRとIFEvalという2つのベンチマークを重視しており、これらのベンチマークで優れた成績を収めているモデルが適していると考えています。

一方、Azim Sonawallaは、演繹的推論に加えて、事実知識の重要性を指摘しています。彼は、より多くのトークンでトレーニングされたモデル（例：llama3）が、このコンペティションで優位に立てる可能性があると主張しています。

Matthew S Farmerは、Azim Sonawallaの意見に同意し、多言語モデルが英語のみのモデルよりも多くの語彙トレーニングを受けているため、このコンペティションに適している可能性があると示唆しています。

このディスカッションは、モデル選択において、演繹的推論、明示的な指示への従順性、事実知識の重要性を浮き彫りにしています。参加者たちは、これらの要素を考慮し、適切なモデルを選択する必要があることを認識しています。


---
# モデル選択
**Matthew S Farmer** *2024年6月29日土曜日 00:51:01 GMT+0900 (日本標準時)* (6票)

特定の20問ゲームのデータセットでモデルを微調整する以外に、このコンペティションに最適なモデルを選択する方法について考えてきました。そのため、[HF Open LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard) を確認し、さまざまなベンチマークを調べてみました。

パフォーマンスの鍵は、演繹的推論と、モデルが明示的な指示に従う能力（解析を支援するため）にあるはずです。そのため、次の2つのベンチマークを優先します。

MUSRとIFEval

MuSR（マルチステップソフト推論）（https://arxiv.org/abs/2310.16049） - MuSRは、アルゴリズム的に生成された複雑な問題からなる新しいデータセットで、それぞれ約1,000語の長さです。問題には、殺人ミステリー、オブジェクト配置問題、チーム割り当ての最適化などが含まれます。これらの問題を解決するには、モデルが長距離コンテキスト解析と推論を統合する必要があります。このデータセットでは、ランダムなパフォーマンスを上回るモデルはほとんどありません。

IFEval（https://arxiv.org/abs/2311.07911） - IFEvalは、モデルが「キーワードxを含める」や「フォーマットyを使用する」などの明示的な指示に従う能力をテストするために設計されたデータセットです。焦点は、生成されたコンテンツではなく、モデルのフォーマット指示への準拠であり、厳格で厳密な指標の使用を可能にします。

- Phi 3、Qwen 2、Openchat 3.5、Yi、Hermes 2… 上記のベンチマークを考慮すると、すべてがトップに位置しています。
- 対照的に：Gemma 2 7b it（スターターノートブックモデル）のMUSRは12.53であるのに対し、IntelのNeural ChatのMUSRは23.02です…

いくつかの考えられる点です。楽しいカグリングを！
---
# 他のユーザーからのコメント
> ## Azim Sonawalla
> 
> 
> パフォーマンスの鍵は、演繹的推論と、モデルが明示的な指示に従う能力（解析を支援するため）にあるはずです。
> 
> この仮定については、よくわかりません。ボットは、質問者/推測者として最大20個の同時条件を満たすキーワードを見つけることができる程度に推論する必要がありますが、最後の候補を絞り込むために、後半のゲームで質問を思いつくために、実際の事実の知識が必要です。
> 
> 私は、より高いトークン数でトレーニングされたモデル（例：llama3）がこの理由でうまくいくのではないかと考えてきましたが、そのように実験する時間はありませんでした。
> 
> 
> 
> > ## Matthew S Farmerトピック作成者
> > 
> > 面白い反論ですね！私の仮定に挑戦してくれてありがとうございます。あなたの考えに従うと、多言語モデルは、英語のみのモデルよりも多くの語彙トレーニングが必要なため、このコンペティションに最適かもしれませんか？
> > 
> > 
> > 
---
