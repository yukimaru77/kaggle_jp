# 要約 
ディスカッションでは、ユーザー*padeof*がvllmを使用してLLMクラスを実行しようとする中で、エラー「undefined symbol」に直面したことを共有しています。彼はこの問題を解決するために1週間奮闘しましたが、うまくいかなかったと述べています。また、vllmをサーバーとして実行する際にランダムに起動に失敗することもあると報告しています。この状況でノートブックの提出をデバッグするのが難しいと愚痴っています。

これに対して、ユーザー*Chris Deotte*がKaggleでのvLLMの使用例を提供し、必要なpipのアップグレードやファイルの修正が必要であることを指摘しています。*padeof*はその後、Chrisの投稿を読み、自身の試みが提出時に機能しないことを説明しました。具体的には、エージェントスクリプトでsysパスに変更を加える前にtorchモジュールが読み込まれてしまうため、vllmとtorchのバイナリに不一致が生じることが問題であると述べています。

---
# vllmの問題
**padeof** *2024年7月28日 18:41:08 (日本標準時)* (0票)
誰か、LLMクラスを使って直接vllmを実行できる人はいますか？
"/kaggle_simulations/agent/srvlib/vllm/_C.cpython-310-x86_64-linux-gnu.so: undefined symbol"というエラーを解決しようと1週間試みましたが、うまくいきませんでした…
vllmをサーバーとして実行すると、ランダムに起動に失敗することもあります。
ノートブックの提出でデバッグするのが非常に難しいです🤣
---
# 他のユーザーからのコメント
> ## Chris Deotte
> 
> ここにKaggleでvLLMを使ったコード例があります。vLLMはインストールされていますが、Kaggleで動作させるためにはpipのアップグレードやいくつかのファイルを変更する必要があります。[https://www.kaggle.com/code/cdeotte/infer-34b-with-vllm](https://www.kaggle.com/code/cdeotte/infer-34b-with-vllm)
> 
> 
> > ## padeof トピック作成者
> > 
> > ありがとうございます！あなたの投稿を読みました。しかし、この方法は提出時には機能しないようです。どうやら、エージェントスクリプト内でsysパスに変更を加える前にtorchモジュールが読み込まれてしまっているようです。そのため、vllmとtorchのバイナリが一致していません。 
> > 
> > 
> >
