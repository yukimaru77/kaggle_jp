# 要約 
コンペのディスカッションは、ポリシーベースの強化学習（RL）を用いて「20の質問ゲーム」をプレイする手法に焦点を当てています。著者らは、質問者エージェントがユーザーとのインタラクションを通じて質問選択の最適ポリシーを学ぶ方法を提案しており、報酬ネットワークを活用して情報に富んだ報酬の推定を行います。このアプローチはノイズのある回答に対して頑健で、既存の知識ベースに依存しないため、ゲームプレイの効率を向上させます。

ディスカッションでは、ゲーム内の質問選択プロセスをマルコフ決定過程（MDP）として定式化し、質問者エージェントが全オブジェクトに対する確率分布を維持しながら信頼度を更新する様子が詳述されています。また、RewardNetを使用して、即時報酬を推定し、長期的なリターンを計算することでモデルのトレーニングを支援します。

他のユーザーは、強化学習に関する関心を示し、エージェントが質問数を管理するのに苦労している体験を共有しました。また、ディスカッションの中で、著者のアルゴリズム設計の難しさが言及され、初心者にとっての挑戦が理解されました。

---
# Q20ゲームと強化学習。マルコフ決定過程（MDP）。
**マリリア・プラタ** *2024年5月16日 木曜日 11:02:24 GMT+0900 (日本標準時)* (23票)
# Q20ゲームと強化学習
ポリシーベースの強化学習を用いた「20の質問ゲーム」のプレイ
著者: 黄虎1、呉賢超、羅昇峰、陶崇陽、徐灿、伍韋、陳展
「本論文では、著者らは新しいポリシーベースの強化学習（RL）手法を提案しました。この手法により、質問者エージェントはユーザーとの継続的なインタラクションを通じて質問選択の最適ポリシーを学ぶことができます。トレーニングを容易にするために、より情報に富んだ報酬を推定するための報酬ネットワークの使用も提案されています。従来の手法と比較して、彼らのRL手法はノイズのある回答に対して頑健であり、オブジェクトの知識ベースに依存しません。実験結果は、彼らのRL手法がエントロピーに基づくエンジニアリングシステムを明確に上回り、ノイズのないシミュレーション環境では競争力のある性能を持つことを示しています。」
「Q20ゲームシステムを構築するためのアルゴリズムを設計するのは簡単ではありません。決定木ベースの方法はQ20ゲームに自然に適しているように見えますが、通常、各オブジェクトに関する十分な情報を含む明確に定義された知識ベース（KB）が必要であり、これは実際には一般的に入手できません。既存のKB（知識ベース）に依存しない質問とオブジェクトの選択のための参照として、オブジェクト-質問関連テーブルを使用しました。さらに、この関連テーブルは多くのエンジニアリングトリックで改善されました。これらのテーブルベースの手法は貪欲に質問を選択するため、モデルパラメータはルールによってのみ更新されるため、ユーザーからのノイズのある回答に非常に敏感です。これは現実のQ20ゲームでは一般的です。一般化能力を向上させるために、値ベースの強化学習（RL）モデルが利用されましたが、既存のKBにまだ依存しています。」

# マルコフ決定過程（MDP）
「本論文では著者らは、ゲームにおける質問選択のプロセスをマルコフ決定過程（MDP）として定式化し、さらにQ20ゲームにおける質問選択の最適ポリシーを学ぶための新しいポリシーベースのRLフレームワークを提案しました。彼らの質問者エージェントは、ターゲットオブジェクトの信頼度をモデル化するためにすべてのオブジェクトに対する確率分布を維持し、ユーザーからの回答に基づいてその信頼度を更新します。」

# RewardNet
「各タイムステップで、エージェントはポリシーネットワークを使用して信頼度ベクターを受け取り、次の質問を選択するための質問分布を出力します。選択した質問ごとに即時の報酬がないという問題を解決するために、著者らは各タイムステップで適切な即時報酬を推定するためにRewardNetを使用することを提案しました。この報酬は、長期的なリターンを計算するためにRLモデルのトレーニングに利用されます。」
「彼らのRL（強化学習）フレームワークは、エージェントをノイズのある回答に対して頑健にします。なぜなら、モデルパラメータは完全に学習可能であり、質問分布は質問をサンプリングするための原則的な方法を提供し、エージェントが不正確な回答によって引き起こされる局所最適から抜け出すことを可能にし、またトレーニング中により多くのランダム性を導入してモデルの一般化能力を向上させます。さらに、貪欲に選択することと比較して、質問をサンプリングする能力は、エージェントが尋ねる質問の多様性を改善し、ユーザー体験にとって非常に重要です。」
[https://www.researchgate.net/publication/327199595_Playing_20_Question_Game_with_Policy-Based_Reinforcement_Learning](https://www.researchgate.net/publication/327199595_Playing_20_Question_Game_with_Policy-Based_Reinforcement_Learning)

---
 # 他のユーザーからのコメント
> ## JDau
> 
> 面白いですね。強化学習の側面に興味があるので、今後の参考にこのリソースをブックマークしました。  
> 
> お遊びで、みんなのお気に入りのLLMを使ってこのゲームを試してみました。私の選んだジョン・メイナード・ケインズを特定できるか見たかったのです。チャットはそのカテゴリを特定するのに多くの質問を使っていましたが（経済学は標準の選択肢ではありませんでした）。以下は一例のやり取りです：
> 
> Copilot
> 
>   絞り込んでみましょう。この歴史的人物は科学的発見で知られていますか、それとも政治的または社会的な影響で有名ですか？🤔
> 
>   あなた
> 
>   明確な答えはありません。特に「科学的発見」というフレーズを広義に解釈すれば、彼らは3つすべてに関与していました。
> 
> ヒント（定期的なヒント）があったにも関わらず、有名な人物が一部の人が言うところの社会科学に関与していることがありましたが、それはカテゴリに絞り込まれることはありませんでした。絵文字は評価しましたが…
> 
> チャットは質問数を管理するのに苦労していることも明らかでした。（もしかしたら人間らしいですね？）
> 
> 質問12：この人は芸術、音楽、または文学の分野に重要な影響を及ぼしましたか？🤔
> 
>   あなた
> 
>   彼は本を書きました。しかし、この人物が文学の分野に重要な影響を及ぼしたとは思いません。
> 
>   Copilot
> 
>   追加のコンテキストをありがとうございます！この歴史的人物が本を書いたのは興味深いことですが、その文学の分野での影響は重要と見なされないかもしれません。それでは、探求を続けましょう：
> 
>   質問12：この人は芸術、音楽、または文学の分野に重要な影響を及ぼしましたか？🤔
> 
>   あなた
> 
>   あなたはもう質問13に到達しています。
> 
>   Copilot
> 
>   見落としについてお詫びします！次の質問を続けましょう：
> 
> > ## マリリア・プラタ トピック作成者
> > 
> > 素晴らしい例ですね、JDaustralia。  
> > 
> > Kaggleにはエージェントや強化学習に関する素晴らしいコンペもありますのでご紹介します：
> > 
> > [Connect X](https://www.kaggle.com/competitions/connectx)
> > 
> > [Lux AI Season 2](https://www.kaggle.com/competitions/lux-ai-season-2/overview)
> > 
> > [Kore 2022](https://www.kaggle.com/competitions/kore-2022/overview) 
> > 
> > [Halite by Two Sigma](https://www.kaggle.com/competitions/halite)
> > 
> > 
---
> ## エドウィン・サミュエル・ギフトソン
> 
> この20の質問ゲームのプレイ方法は本当にクールですね！彼らは強化学習と呼ばれるものを使って賢い質問をするエージェントを作っています。エージェントは人との対話を通じて、どの質問をするかを学びます。また、回答が良いかどうかを判断するのを助けるRewardNetというものもあります。従来の方法と比較して、大きな進展です。従来の方法は悪い回答や十分に設定された情報に依存することが多かったです。
> 
> 
> > ## マリリア・プラタ トピック作成者
> > 
> > 面白いことに、著者は「Q20ゲームシステムを構築するアルゴリズムを設計するのは簡単ではない」と書いています。
> > 
> > 彼らにとって簡単でないなら、私のような初心者にはいかに難しいか想像できます : ) ありがとう、ギフトソン！ 
> > 
> > 
---
