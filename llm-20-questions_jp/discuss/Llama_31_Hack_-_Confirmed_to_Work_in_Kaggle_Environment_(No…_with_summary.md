# 要約 
以下は、コンペのディスカッションに関する要約です。

---

**タイトル:** Llama 3.1 ハック - Kaggle 環境での動作確認

**発信者:** Matthew S Farmer (2024年8月2日)

要約:

Llama 3.1の最新リリースについて、Kaggleの「20の質問」コンペティションでの動作に関する問題が取り上げられています。特に、RoPEスケーリングに関するエラーが発生し、オンラインでは「transformersを更新しろ」との情報しか得られなかったとのこと。しかし、著者はtransformersを更新しなくても動作させるワークアラウンドを提供しました。

具体的な実装手順として、以下の内容が説明されています：
1. transformersの更新を解除する。
2. 使用するLlama 3.1モデルをインポートする。
3. config.jsonのパスを確認し、指定のコードで編集する。
4. 提出用のスクリプトを準備する。
5. モデルとスクリプトを正常に読み込む。
6. 設定ファイルを圧縮し、提出する。

最後に、他の参加者からの感謝のコメントが寄せられており、コンペティションの成功を祈る言葉で締めくくられています。

--- 

この要約は、ディスカッションの主旨や重要なポイントを簡潔にまとめたものです。

---
# Llama 3.1 ハック - Kaggle 環境（ノートブックおよびコンペティション）で動作確認済み
**Matthew S Farmer** *2024年8月2日金曜日 04:34:42 GMT+0900（日本標準時）* (21票)

# Llama 3.1
最新のLlama 3.1のリリースを見て、「これがLLM 20 Questionsコンペティションで使えそう」と思ったことでしょう。ノートブックを立ち上げてモデルをインポートし、読み込もうとすると、RoPEスケーリングに関するエラーが発生しました…。ディスカッションボードにアクセスしても助けを見つけられず、オンラインでは「transformersを更新しろ」としか書いていません。それを実行するとノートブックは動くようになりますが、今度は厄介なバリデーションエラーに直面します！どうすればいいのでしょう？いじくり回すことが好きな人なら、どこかにワークアラウンドがあることを知っています…

## 私たちにはワークアラウンドがあります！
私は、transformersを更新することなく、ノートブックおよびゲーム環境で動作することを確認しました。 
```
import json
with open("YOUR_LOCAL_MODEL_PATH/config.json", "r") as file:
    config = json.load(file)
config["rope_scaling"] = {"factor":8.0,"type":"dynamic"}
with open("YOUR_LOCAL_MODEL_PATH/config.json", "w") as file:
    json.dump(config, file)
```
## 実装手順
1. 試していたtransformersの更新をすべて取り消します。
2. 使用したいLlama 3.1モデルを作業フォルダにインポートします。
3. そのフォルダ内のconfig.jsonのパスを確認し、上記のコード内の全大文字のパスに置き換えます。
4. 提出用の.pyスクリプトおよびtarball提出の前に、コードブロック内にこのコードを追加します。
5. 通常通りモデルとスクリプトを読み込みます。
6. 必要に応じてノートブック内でテキスト生成を確認します。
7. 更新された設定ファイルをモデルと一緒に圧縮して提出用に準備します。
8. バリデーション後の緑のチェックマークを楽しんでください。

最終評価が迫る中、皆さんのコンペティションのレベルが上がることを願っています。最良のエージェントが勝ちますように！

## 要約
config.jsonを現在のtransformersバージョンが期待する辞書（2つのフィールド）に変更します。 
では、ハッピーカグリングを！

RoPEスケーリングについて質問がある場合は、[ドキュメントをチェックしてみてください！ ](https://huggingface.co/docs/text-generation-inference/en/basic_tutorials/preparing_model)

---

# 他のユーザーからのコメント
> ## VolodymyrBilyachat
> 
> 伝説ですね！このシンプルなハックに感謝します :)
