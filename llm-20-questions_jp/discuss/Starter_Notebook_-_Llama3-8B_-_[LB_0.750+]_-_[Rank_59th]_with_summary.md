# 要約 
このディスカッションは、Kaggleの「LLM 20 Questions」コンペティションにおけるLlama3-8Bモデルを使用したスターターノートブックについてです。投稿者はChris Deotte氏で、このノートブックはパブリックリーダーボードで0.750+のスコアを獲得し、59位にランクインしています。

ノートブックの主な利点は、質問の戦略、LLMモデルのダウンロードと使用、回答能力のEDA、エージェントコードの作成、Kaggle APIの実行など、コンペティションで役立つコードを提供していることです。

しかし、ノートブックにはいくつかの欠点も指摘されています。一つは、固定キーワードを使用しているため、プライベートリーダーボードで変更される可能性があることです。もう一つは、場所に関する質問しかしていないことです。

投稿者は、このノートブックを改善するために、Wikipediaから数千または数百万の単語を選択し、そのリストをすべての潜在的なキーワードのリストとして使用することを提案しています。また、データフレームに新しい列を作成し、すべての単語を記述する追加の機能を追加することを提案しています。

ディスカッションでは、他のユーザーからのコメントも含まれています。Rishit Jakharia氏は、GGUF量子化を試したかどうかを質問しています。Chris Deotte氏は、GGUF量子化は試していないが、AWQ量子化はfp4と比べて非常に遅かったため、GGUFを評価する際には速度も考慮する必要があると答えています。

torino氏は、オフラインでPythonパッケージをインストールしているが、提出環境に新しいpytorchをインストールできないという問題について質問しています。

このディスカッションは、コンペティション参加者にとって有益な情報源であり、Llama3-8Bモデルを使用したスターターノートブックの使用方法、改善方法、およびコンペティションで発生する可能性のある問題について理解を深めることができます。


---
# スターターノートブック - Llama3-8B - [LB 0.750+] - [ランク 59位]
**Chris Deotte** *2024年7月16日 火曜日 09:54:06 GMT+0900 (日本標準時)* (59票)

皆さん、こんにちは！現在、パブリックLBで0.750+、パブリックLBランクで59位を獲得している私の現在の提出物を共有します！（キーワードの更新前は、このノートブックはパブリックLBで1位を獲得していました🥇😀）。ノートブックはこちらです [https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750](https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750)。楽しんでください！

## 良い点
このノートブックにはいくつかの問題点がありますが（つまり、いくつかの固定キーワードを使用しています）、役に立つコードもたくさんあります。このノートブックで示されている役に立つ点は次のとおりです。

- 検索を絞り込むための質問の仕方の戦略（そして、裏側で機能のCSVを使用する）。
- 提出時に使用するpipライブラリをインストールする方法。
- Hugging Faceから任意のLLMモデルをダウンロードして使用する方法。
- LLMの回答能力に関するEDAを実行する方法。
- エージェントコードを作成し、提出用のtarballを作成する方法。
- KaggleのAPIを実行して、ローカルでエージェントを監視する方法。

## 悪い点
このノートブックのいくつかの問題点は次のとおりです。

- （古いリストの）固定キーワードを使用しており、プライベートLBで変更される可能性があります。（そして、パブリックLBで変更されました。）
- 場所に関する質問しかしていません（つまり、（1）どのサブカテゴリ？ （都市、国、ランドマーク）、（2）どの大陸？、（3）最初の文字は？ 物に関する質問はしていません）。

## 改善方法
プライベートLBのキーワードが変更されたとしても、このノートブックのテンプレートと戦略を使用して、Wikipediaから数千または数百万の単語を選択し、そのリストをすべての潜在的なキーワードのリストとして使用するノートブックを作成できます。
次に、そのデータフレームに新しい列を作成し、すべての単語を記述する追加の機能を追加し、キーワードがこれらの追加機能を持っているかどうかを尋ねる事前に決められた質問を作成します。最後に、作成したデータフレーム（追加の列機能付き）のキーワードと、機能に関する回答者の回答に基づいて推測を行います。

# スターターコード
スターターコードはこちらです [https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750](https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750)。

---
# 他のユーザーからのコメント
> ## mxmm2123
> 
> 素晴らしい仕事です!!!
> 
> 
> 
---
> ## Rishit Jakharia
> 
> こんにちは！ノートブックを共有してくれてありがとう。
> 
> Llama 3モデルの実装でfp4量子化を使用していることに気づきました。
> 
> GGUF量子化を試したかどうか、試した場合は現在の実装と比較してどのような結果が出たのか教えてください。
> 
> 
> 
> > ## Chris Deotteトピック作成者
> > 
> > こんにちは。GGUF量子化は試していません。別のプロジェクト（つまり、Kaggleの20問ゲームコンペではありません）で、Hugging FaceのAutoModelForCausalLMでAWQ量子化を試したことがありますが、fp4と比べて非常に遅かったです。そのため、GGUFを評価する際には、その速度も考慮する必要があります。
> > 
> > 
> > 
> > > ## Rishit Jakharia
> > > 
> > > わかりました、ありがとう！
> > > 
> > > 
> > > 
---
> ## Valentin Baltazar
> 
> これは私のような初心者にとって素晴らしいものです！ありがとう。
> 
> 
> 
---
> ## torino
> 
> [@cdeotte](https://www.kaggle.com/cdeotte) ノートブックを共有してくれてありがとう。オフラインでPythonパッケージをインストールしているのを見ましたが、私のノートブックでは、提出環境に新しいpytorchをインストールできません（通常のノートブックでは正常に動作しました）。何か提案はありますか？私の問題はこちらで見ることができます [https://www.kaggle.com/competitions/llm-20-questions/discussion/520207](https://www.kaggle.com/competitions/llm-20-questions/discussion/520207)
> 
> 
> 
---

