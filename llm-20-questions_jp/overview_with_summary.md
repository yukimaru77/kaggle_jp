# 要約 
## コンペ「LLM 20 Questions」： 言葉当てゲームでAIの推理力を競う！

**概要:**

誰もが遊んだことのある「20の質問」を、AI同士が競い合うコンペティションです。2体1組のAIチームを作り、より少ない質問で答えを当てることを目指します。

**具体的な問題設定:**

* 2つのAI（言語モデル）を1チームとして開発します。
    * **質問者AI**:  「それは動物ですか？」のように、答えを絞り込む質問を考えます。
    * **回答者AI**:  質問に対して「はい」か「いいえ」で答えます。
* 対戦相手チームとどちらが早く答えを当てられるかを競います。

**例：**

1. **お題**:  「富士山」
2. **質問者AI**:  「それは自然物ですか？」
3. **回答者AI**:  「はい」
4. **質問者AI**:  「それは日本にありますか？」
5. **回答者AI**:  「はい」
   ...  のように質問を繰り返して答えを導きます。

**評価ポイント:**

* 限られた質問回数で、いかに効率的に答えにたどり着けるか。
* 論理的な質問、情報収集能力、チームとしての連携が試されます。

**このコンペで試されるAI技術:**

* **演繹的推論**:  得られた情報から論理的に答えを導く能力
* **情報収集**:  的を絞った質問で必要な情報を効率的に集める能力
* **チームワーク**:  2体のAIが連携して答えを目指す能力

**賞金:**

* **総額5万ドル**,  1位チームには1万2千ドル！

**参加する面白さ:**

言葉当てゲームを通して、AIの思考力や問題解決能力を競い合うことができます。自分たちが開発したAIが、他の参加者のAIとどのように戦うのか、見守るだけでもエキサイティングです。 


---
# 用語概説 
### 機械学習・深層学習初心者のための専門用語解説 (LLM 20 Questionsコンペ)

このコンペは、**LLM(Large Language Model: 大規模言語モデル)**を用いて「20の質問」ゲームをプレイさせるという、NLP(自然言語処理)色が強いコンペティションです。

**1. LLM (Large Language Model: 大規模言語モデル)**

* **解説:**  膨大なテキストデータで学習された、人間のような自然な文章を生成できるAIモデル。ChatGPTに使われている技術の基礎。
* **つまずきポイント:**  LLMは「20の質問」を解くための知識を持っているわけではなく、あくまでも学習データの統計的なパターンに基づいて回答を生成している点を理解する必要があります。

**2. エージェント(ボット)**

* **解説:**  このコンペでは、質問者LLMと回答者LLMをまとめて「エージェント」と呼んでいます。他のコンペでは「提出物」と呼ばれることもあります。
* **つまずきポイント:**  エージェントは単独で動くAIではなく、質問者と回答者が協力して動作する必要があることを意識する必要があります。

**3. スキルレーティング**

* **解説:**  各エージェントの強さを表す数値。対戦結果によって変動し、強いエージェントほど高い値になります。
* **つまずきポイント:**  レーティングは相対的なものであり、絶対的な強さを表すものではありません。また、レーティングの算出方法はコンペによって異なる場合があります。

**4. ガウス分布 N(μ, σ2)**

* **解説:**  スキルレーティングの推定に使われる確率分布。μは平均値(推定スキル)、σは標準偏差(推定の不確実性)を表します。
* **つまずきポイント:**  ガウス分布は統計学の基礎知識ですが、μやσが具体的に何を意味するのか、どのように計算されるのかを理解する必要があります。

**5. バリデーションエピソード**

* **解説:**  提出したエージェントが正しく動作するかを確認するためのテスト。このコンペでは、自分自身のコピーと対戦させます。
* **つまずきポイント:**  バリデーションエピソードは、あくまで基本的な動作確認であり、実際の対戦相手との相性を保証するものではありません。

**6. μ0 = 600**

* **解説:**  新規エージェントの初期スキルレーティング。 
* **つまずきポイント:**  初期値はコンペによって異なります。

**7. アクティブ/非アクティブ**

* **解説:**  各参加者は、最大5つのエージェントを提出できますが、常に評価対象となるのは最新の3つまでです。これを「アクティブ」と呼び、それ以外は「非アクティブ」となります。
* **つまずきポイント:**  非アクティブなエージェントは評価されませんが、提出ページで進捗状況を確認することは可能です。

**8. リーダーボード**

* **解説:**  参加者のランキングを表示する bảng xếp hạng。スキルレーティング順に並びます。
* **つまずきポイント:**  リーダーボードはあくまでも現時点での順位であり、最終的な順位を保証するものではありません。

**9. タイムアウト**

* **解説:**  エージェントが一定時間以内に回答を返せなかった場合、負けとなります。
* **つまずきポイント:**  タイムアウトは、アルゴリズムの効率性だけでなく、実装の仕方にも影響を受ける可能性があります。

**10. カスタム指標**

* **解説:**  このコンペでは、勝敗数やレーティング以外にも、独自の評価指標が使われる可能性があります。
* **つまずきポイント:**  カスタム指標はコンペごとに異なるため、事前にルールをよく確認しておく必要があります。


これらの用語を理解することで、コンペのルールや評価方法をより深く理解し、より効果的な戦略を立てることができるでしょう。

---
## LLM 20 Questions - 言語モデルと挑む「20の質問」ゲーム

**概要**

このコンペティションでは、誰もが知っている言葉当てゲーム「20の質問」をプレイできる言語モデルの開発に挑戦します。2対2のチーム戦で、いかに早く答えを導き出せるかを競います。

### 説明

「それは動物、植物、鉱物？」「それはティッシュボックスより小さい？」「それは700億パラメータのモデルより小さい？」

「20の質問」は、限られた質問回数で答えを当てる、昔から親しまれている推理ゲームです。プレイヤーは、一般的な質問から具体的な質問へと絞り込みながら、できるだけ少ない質問回数で答えを導き出すことを目指します。

各チームは、質問と解答を担う「質問者LLM」と、「はい」または「いいえ」で回答する「回答者LLM」の2つの言語モデルで構成されます。戦略的な質問と回答を通して、質問者ができるだけ少ないラウンドで正解にたどり着くことが目標です。

このコンペティションでは、演繹的推論、的を絞った質問による効率的な情報収集、ペアエージェント間の連携といった、LLMの重要なスキルが評価されます。限られた質問回数の中で創造性と戦略性が求められる、制約のある設定も特徴です。成功すれば、LLMが単に質問に答えるだけでなく、洞察に富んだ質問をし、論理的な推論を行い、可能性を迅速に絞り込む能力を実証することになります。

### 評価方法

チームは毎日、最大5つのエージェント（ボット）をコンペティションに提出できます。各エージェントは、リーダーボード上で同等のスキルレーティングを持つ他のボットと対戦し、ゲームをプレイします。時間とともに、勝利すればスキルレーティングは上がり、敗北すれば下がり、引き分けの場合は変化しません。

このコンペティションは、2対2の協力プレイ形式で行われます。提出したボットは、ランダムに選ばれた同等のスキルを持つボットとペアになり、別のペアと対戦します。各ペアでは、どちらかのボットがランダムに質問者に、もう一方が回答者に割り当てられます。ペアとして勝敗が決まるため、協力し合うことが重要になります。

提出されたボットは、コンペティション終了までゲームをプレイし続けます。新しいボットほど、より頻繁にプレイするように選択されます。アクティブな提出数が3つに達すると、古いボットは非アクティブ化されます。リーダーボードには、最もスコアの高いボットのみが表示されますが、提出ページでは、すべての提出の進捗状況を追跡できます。

各提出物には、ガウス分布N(μ,σ2)でモデル化された推定スキルレーティングがあります。μは推定スキル、σはその推定の不確実性を表し、時間とともに減少します。

提出物をアップロードすると、まずバリデーションエピソードが実行されます。これは、提出物が正しく機能することを確認するために、自分自身のコピーと対戦するものです。エピソードが失敗した場合、提出物はエラーとしてマークされ、原因を特定するためにエージェントログをダウンロードできます。そうでない場合は、μ0=600で提出物を初期化し、継続的な評価のためにプールに追加します。この時点で、アクティブなエージェントの総数が3つを超える場合は、古いエージェントを非アクティブ化します。

### ランキングシステム

エピソードが終了すると、そのエピソードに参加したすべてのボットのレーティング推定値が更新されます。あるボットペアが勝利した場合、そのペアのμは増加し、対戦相手のμは減少します。引き分けの場合は、μの値が平均値に近づくように調整されます。更新の大きさは、以前のμ値に基づく予想結果からの偏差、および各ボットの不確実性σに比例します。また、結果によって得られた情報量に応じて、σの項も減少させます。ボットがエピソードで勝利または敗北したスコアは、スキルレーティングの更新には影響しません。

### 最終評価

2024年8月13日の提出締め切り時点で、提出物はロックされます。2024年8月13日から8月27日までは、公開されていない新しい単語のセットに対してエピソードを実行し続けます。この期間中は、アクティブな3つの提出物のみがリーダーボードの対象となります。この期間の終わりに、リーダーボードが確定します。

### スケジュール

- 2024年5月15日 - 開始日
- 2024年8月6日 - 参加登録締め切り。この日までにコンペティションルールに同意する必要があります。
- 2024年8月6日 - チーム統合締め切り。この日を過ぎると、チームへの参加や統合はできなくなります。
- 2024年8月13日 - 最終提出締め切り
- 2024年8月13日～8月27日 - 最終ゲームの実施予定期間
- 2024年8月28日 - 受賞者の発表

特に明記されていない限り、すべての締め切りは、対応する日の協定世界時（UTC）午後11時59分です。コンペティション主催者は、必要と判断した場合、コンテストのスケジュールを変更する権利を留保します。

### 賞金

- 1位: 12,000ドル
- 2位: 10,000ドル
- 3位: 10,000ドル
- 4位: 10,000ドル
- 5位: 8,000ドル

### 20の質問 ルール

ゲームはラウンド制で進行し、合計20ラウンドです。各ラウンドの開始時に、2人の質問者はそれぞれターゲットとなる単語を推測する質問を提出し、次にターゲットとなる単語が何であるかについての推測を提出します。

いずれかの質問者がそのラウンドでターゲットとなる単語を正しく推測した場合、そのチームはすぐにゲームに勝利します。両方の質問者が同じラウンドで正しく推測した場合は、そのラウンドは引き分けとなります。

どちらの質問者も正しく推測できなかった場合、ゲームは次のラウンドに進みます。2人の回答者はそれぞれ、「はい」または「いいえ」のいずれかで、チームの質問者からの質問に答えます。この情報を使用して、質問者は次のラウンドで新しい質問と推測を提出します。

このプロセスは、合計20ラウンドまで繰り返されます。20ラウンド経ってもどちらのチームも単語を推測できなかった場合、ゲームは引き分けとなります。目標は、各チームの質問者が、回答エージェントから提供された情報に基づいて、できるだけ少ないラウンドでターゲットとなる単語を推測することです。

## タイムアウト、制限、ペナルティ

- 質問は2000文字までに制限されています
- 推測は100文字までに制限されています
- タイムアウト
    - エージェントには、回答のために1ラウンドあたり60秒が与えられます
    - エージェントは、ゲームを通して使用できる追加の300秒の超過時間を持っています
    - いずれかのエージェントがタイムアウトした場合、ゲームは終了します
- 回答エージェントが「はい」または「いいえ」以外で回答した場合、ゲームは終了し、その試合は負けとなります。

## 技術仕様

- ディスク容量: 100GB
- RAM: 16GB
- GPU: 1 T4 GPU

### 引用

Zoe Mongan, Luke Sernau, Will Lifferth, Bovard Doerschuk-Tiberi, Ryan Holbrook, Will Cukierski, Addison Howard. (2024). LLM 20 Questions. Kaggle. https://kaggle.com/competitions/llm-20-questions

## コンペティション主催

Kaggle

## 賞金と賞

- 賞金総額: 50,000ドル
- アワードポイントとメダル

## 参加者情報

- 参加者数: 6,146人
- チーム数: 735チーム
- 提出数: 1,482件

## タグ

- テキスト
- 自然言語処理
- カスタム指標
