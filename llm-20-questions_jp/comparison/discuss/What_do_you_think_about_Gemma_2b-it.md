# 要約 
ディスカッションでは、ユーザーyamitomoがGemma 2b-itモデルについての不満を表明しています。具体的には、モデルに「あなたは質問者です」と指示しても、正しく認識せずに誤った応答をすることが原因でパフォーマンスが低いと感じているとのこと。他のユーザーCchristoCは、Gemma 2b-itの代わりにGemma 7bやLlama 3 8Bを使用することを提案しています。

---


<style>
.column-left{
  float: left;
  width: 47.5%;
  text-align: left;
}
.column-right{
  float: right;
  width: 47.5%;
  text-align: left;
}
.column-one{
  float: left;
  width: 100%;
  text-align: left;
}
</style>


<div class="column-left">

# original

# What do you think about Gemma 2b-it?

**yamitomo** *Mon Jul 08 2024 14:54:40 GMT+0900 (日本標準時)* (1 votes)

Even when I tell the model that you are a "questioner," it mistakes me for an "questioner" and asks questions that can't be answered with a yes/no, so I feel like its performance is low.

What do you think?



---

 # Comments from other users

> ## CchristoC
> 
> You should just use the Gemma 7b one or Llama 3 8B
> 
> 
> 


---



</div>
<div class="column-right">

# 日本語訳

# Gemma 2b-itについてどう思いますか？
**yamitomo** *2024年7月8日 14:54:40 JST* (1票)
モデルに「あなたは質問者です」と伝えても、「質問者」と間違えて認識し、はい/いえで答えられない質問をしてくるので、パフォーマンスが低いと感じています。みんなはどう思いますか？
---
 # 他のユーザーからのコメント
> ## CchristoC
> 
> Gemma 7bやLlama 3 8Bを使った方がいいと思いますよ。


</div>