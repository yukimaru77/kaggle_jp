{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc678443",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LLM 20 Questions」コンペティションに参加するためのAIアシスタントを構築するためのものです。主に、言葉当てゲーム「20の質問」をプレイできるモデルを開発し、質問者と回答者の役割を果たすことで、できるだけ少ない質問でターゲットを当てることを目指しています。\n",
    "\n",
    "### 問題\n",
    "このNotebookでは、20の質問ゲームにおいて、回答者が考えたキーワードに対して質問者が質問し、その質問に基づいて推測を行うというタスクに取り組んでいます。具体的には、与えられた質問に対する回答をモデルが生成し、適切にキーワードを推測する役割を果たす必要があります。\n",
    "\n",
    "### 手法\n",
    "1. **環境設定**: 必要なライブラリ（`immutabledict`、`sentencepiece`、`kaggle_environments`）をインストールし、GemmaのPyTorch実装をクローンして、作業ディレクトリに配置します。\n",
    "  \n",
    "2. **モデルの構成**: \n",
    "    - `GemmaFormatter`クラスを使用して、ユーザーとモデルのターンをフォーマットします。\n",
    "    - 構成情報に基づいてGemmaモデルをロードし、異なるバリエーション（例: \"2b\"、\"2b-it\"、\"7b-it-quant\"）でモデルを初期化します。\n",
    "\n",
    "3. **プロンプトの準備**: \n",
    "    - ゲームのシステムプロンプトや過去の例（few-shot examples）を用いて、質問と回答のターンを整列させるためのフォーマッターを使用します。\n",
    "\n",
    "4. **応答生成**: \n",
    "    - モデルを用いて生成されたプロンプトに基づいて、質問や推測の応答を生成します。\n",
    "\n",
    "5. **応答解析**: \n",
    "    - 抽出したキーワードや生成した質問を解析し、ゲームの流れに従って答えを導き出します。\n",
    "\n",
    "### 使用ライブラリ\n",
    "- `kaggle_environments`: Kaggleの競技環境を構築するために利用。\n",
    "- `torch`: PyTorchを利用して深層学習モデルを実装。\n",
    "- `gemma`: Googleが開発したGemmaモデルの実装を使用。\n",
    "\n",
    "このNotebookは、言語モデルが「20の質問」ゲームを通じて有用な質問を生成し、論理的に推論してキーワードを当てる能力を評価し、改善するための基盤を築いています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5f0957",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に関連する初心者がつまずく可能性のある専門用語の解説です。\n",
    "\n",
    "1. **GemmaForCausalLM**:\n",
    "   - Causal Language Model（因果言語モデル）の一種で、入力に基づいて次の単語を生成するために訓練されたモデルです。この種のモデルは、文脈に基づいて単語を予測するため、対話や物語生成などに使用されます。\n",
    "\n",
    "2. **Tokenizer**:\n",
    "   - テキストデータをモデルが理解できる形式（通常は数値のリスト）に変換するためのツールです。自然言語処理では、単語やトークンを分割して表現するために使用されます。\n",
    "\n",
    "3. **Few-shot Examples**:\n",
    "   - モデルに少数の例を与えることで、その後のタスクをより良く理解させる手法です。特に、言語モデルに対話の流れや形式を教える際に有用です。\n",
    "\n",
    "4. **Temperature**:\n",
    "   - モデルが生成する出力の多様性をコントロールするパラメータです。温度が高いと出力は多様になり、低いと出力が確定的になりやすいです。このパラメータを調整することで、生成される文章の創造性を操作できます。\n",
    "\n",
    "5. **Top-p Filtering (Nucleus Sampling)**:\n",
    "   - 確率が高い候補トークンを選択し、それらの合計確率が事前に指定された値（p）を超えるまでトークンを選ぶ方法です。これにより、出力がより自然で関連性のあるものになることが期待されます。\n",
    "\n",
    "6. **Top-k Filtering**:\n",
    "   - 出力候補としてk個の最も高い確率を持つトークンの中から新しいトークンを生成する方法です。これにより、無関係なトークンが選択される確率が減り、より洗練された結果が得られます。\n",
    "\n",
    "7. **Contextlib**:\n",
    "   - Pythonの標準ライブラリで、リソースの管理（例：ファイルの開閉）を簡単に行うためのツールです。このノートブックでは、コンテキストマネージャを使用して、デフォルトのデータ型を設定しています。\n",
    "\n",
    "8. **Quantization**:\n",
    "   - モデルのサイズを小さくし、計算速度を向上させるために、モデルの重みを圧縮して低精度の数値形式に変換する技術です。これにより、リソースの少ない環境でもモデルを実行できるようになります。\n",
    "\n",
    "9. **Interleave**:\n",
    "   - 二つのリストやシーケンスを交互に統合するプロセスです。このノートブックでは、質問と回答を一つのシーケンスにするために使われています。\n",
    "\n",
    "10. **Observation (`obs`)**:\n",
    "    - モデルが現在のゲームの状態を知るために使用する情報の集合です。この情報には、ターンの種類や以前の質問と回答が含まれます。\n",
    "\n",
    "これらの用語の理解は、このノートブックが持つ特有のドメイン知識や機能を理解するために重要となります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02489e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Setup the environment\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!pip install -q 'kaggle_environments>=1.14.8'\n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "!mkdir /kaggle/working/gemma/\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 環境を設定する\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!pip install -q 'kaggle_environments>=1.14.8'\n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "!mkdir /kaggle/working/gemma/\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:46:55.794817Z",
     "iopub.status.busy": "2024-06-28T13:46:55.794466Z",
     "iopub.status.idle": "2024-06-28T13:47:25.200385Z",
     "shell.execute_reply": "2024-06-28T13:47:25.199204Z",
     "shell.execute_reply.started": "2024-06-28T13:46:55.794784Z"
    }
   },
   "outputs": [],
   "source": [
    "# 環境を設定する\n",
    "!pip install -q -U immutabledict sentencepiece \n",
    "!pip install -q 'kaggle_environments>=1.14.8'\n",
    "!git clone https://github.com/google/gemma_pytorch.git\n",
    "!mkdir /kaggle/working/gemma/\n",
    "!mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/gemma/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1377aa5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import sys \n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "import contextlib\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import kaggle_environments\n",
    "import itertools\n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "from typing import Iterable\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import sys \n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "import contextlib\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import kaggle_environments\n",
    "import itertools\n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "from typing import Iterable\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:25.203258Z",
     "iopub.status.busy": "2024-06-28T13:47:25.202653Z",
     "iopub.status.idle": "2024-06-28T13:47:31.779874Z",
     "shell.execute_reply": "2024-06-28T13:47:31.779106Z",
     "shell.execute_reply.started": "2024-06-28T13:47:25.203217Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"/kaggle/working/gemma_pytorch/\") \n",
    "import contextlib\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "import kaggle_environments\n",
    "import itertools\n",
    "from gemma.config import GemmaConfig, get_config_for_7b, get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "from gemma.tokenizer import Tokenizer\n",
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a018e6b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class GemmaFormatter:\n",
    "    _start_token = '<start_of_turn>'\n",
    "    _end_token = '<end_of_turn>'\n",
    "\n",
    "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
    "        self._system_prompt = system_prompt\n",
    "        self._few_shot_examples = few_shot_examples\n",
    "        self._turn_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
    "        self._turn_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
    "        self.reset()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self._state\n",
    "\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)\n",
    "        return self\n",
    "\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)\n",
    "        return self\n",
    "\n",
    "    def start_user_turn(self):\n",
    "        self._state += f\"{self._start_token}user\\n\"\n",
    "        return self\n",
    "\n",
    "    def start_model_turn(self):\n",
    "        self._state += f\"{self._start_token}model\\n\"\n",
    "        return self\n",
    "\n",
    "    def end_turn(self):\n",
    "        self._state += f\"{self._end_token}\\n\"\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        self._state = \"\"\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')\n",
    "        return self\n",
    "\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]\n",
    "        formatters = itertools.cycle(formatters)\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)\n",
    "        return self\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class GemmaFormatter:\n",
    "    _start_token = '<start_of_turn>'\n",
    "    _end_token = '<end_of_turn>'\n",
    "\n",
    "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
    "        self._system_prompt = system_prompt  # システムプロンプトを保存\n",
    "        self._few_shot_examples = few_shot_examples  # 例を保存\n",
    "        # ユーザーとモデルのターンをフォーマットするためのテンプレート\n",
    "        self._turn_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
    "        self._turn_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
    "        self.reset()  # 初期状態にリセット\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self._state  # 現在の状態を返す\n",
    "\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)  # ユーザーのプロンプトを追加\n",
    "        return self\n",
    "\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)  # モデルのプロンプトを追加\n",
    "        return self\n",
    "\n",
    "    def start_user_turn(self):\n",
    "        self._state += f\"{self._start_token}user\\n\"  # ユーザーのターンを開始\n",
    "        return self\n",
    "\n",
    "    def start_model_turn(self):\n",
    "        self._state += f\"{self._start_token}model\\n\"  # モデルのターンを開始\n",
    "        return self\n",
    "\n",
    "    def end_turn(self):\n",
    "        self._state += f\"{self._end_token}\\n\"  # ターンを終了\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        self._state = \"\"  # 状態をクリア\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)  # システムプロンプトを使用\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')  # 例を適用\n",
    "        return self\n",
    "\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]\n",
    "        formatters = itertools.cycle(formatters)  # フォーマッターを交互に適用\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)  # 各ターンをフォーマット\n",
    "        return self\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.781426Z",
     "iopub.status.busy": "2024-06-28T13:47:31.781003Z",
     "iopub.status.idle": "2024-06-28T13:47:31.791789Z",
     "shell.execute_reply": "2024-06-28T13:47:31.790918Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.7814Z"
    }
   },
   "outputs": [],
   "source": [
    "class GemmaFormatter:\n",
    "    _start_token = '<start_of_turn>'\n",
    "    _end_token = '<end_of_turn>'\n",
    "\n",
    "    def __init__(self, system_prompt: str = None, few_shot_examples: Iterable = None):\n",
    "        self._system_prompt = system_prompt  # システムプロンプトを保存\n",
    "        self._few_shot_examples = few_shot_examples  # 例を保存\n",
    "        # ユーザーとモデルのターンをフォーマットするためのテンプレート\n",
    "        self._turn_user = f\"{self._start_token}user\\n{{}}{self._end_token}\\n\"\n",
    "        self._turn_model = f\"{self._start_token}model\\n{{}}{self._end_token}\\n\"\n",
    "        self.reset()  # 初期状態にリセット\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self._state  # 現在の状態を返す\n",
    "\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)  # ユーザーのプロンプトを追加\n",
    "        return self\n",
    "\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)  # モデルのプロンプトを追加\n",
    "        return self\n",
    "\n",
    "    def start_user_turn(self):\n",
    "        self._state += f\"{self._start_token}user\\n\"  # ユーザーのターンを開始\n",
    "        return self\n",
    "\n",
    "    def start_model_turn(self):\n",
    "        self._state += f\"{self._start_token}model\\n\"  # モデルのターンを開始\n",
    "        return self\n",
    "\n",
    "    def end_turn(self):\n",
    "        self._state += f\"{self._end_token}\\n\"  # ターンを終了\n",
    "        return self\n",
    "\n",
    "    def reset(self):\n",
    "        self._state = \"\"  # 状態をクリア\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)  # システムプロンプトを使用\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')  # 例を適用\n",
    "        return self\n",
    "\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]\n",
    "        formatters = itertools.cycle(formatters)  # フォーマッターを交互に適用\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)  # 各ターンをフォーマット\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e454fa0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def load_model(VARIANT, device):\n",
    "    WEIGHTS_PATH = f'/kaggle/input/gemma/pytorch/{VARIANT}/2' \n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _set_default_tensor_type(dtype: torch.dtype):\n",
    "        \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "        torch.set_default_dtype(dtype)\n",
    "        yield\n",
    "        torch.set_default_dtype(torch.float)\n",
    "\n",
    "    # Model Config.\n",
    "    model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()\n",
    "    model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")\n",
    "    model_config.quant = \"quant\" in VARIANT\n",
    "\n",
    "    # Model.\n",
    "    with _set_default_tensor_type(model_config.get_dtype()):\n",
    "        model = GemmaForCausalLM(model_config)\n",
    "        ckpt_path = os.path.join(WEIGHTS_PATH, f'gemma-{VARIANT}.ckpt')\n",
    "        model.load_weights(ckpt_path)\n",
    "        model = model.to(device).eval()\n",
    "        \n",
    "    return model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def load_model(VARIANT, device):\n",
    "    WEIGHTS_PATH = f'/kaggle/input/gemma/pytorch/{VARIANT}/2' \n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _set_default_tensor_type(dtype: torch.dtype):\n",
    "        \"\"\"与えられたdtypeを使用してデフォルトのtorchデータ型を設定します。\"\"\"\n",
    "        torch.set_default_dtype(dtype)  # デフォルトのdtypeを設定\n",
    "        yield\n",
    "        torch.set_default_dtype(torch.float)  # デフォルトdtypeをfloatに戻す\n",
    "\n",
    "    # モデルの設定\n",
    "    model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()  # VARIANTに応じた設定取得\n",
    "    model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")  # トークナイザーのパスを設定\n",
    "    model_config.quant = \"quant\" in VARIANT  # 量子化設定\n",
    "\n",
    "    # モデルをロード\n",
    "    with _set_default_tensor_type(model_config.get_dtype()):  # デフォルトのテンソル型を設定\n",
    "        model = GemmaForCausalLM(model_config)  # モデルを初期化\n",
    "        ckpt_path = os.path.join(WEIGHTS_PATH, f'gemma-{VARIANT}.ckpt')  # チェックポイントパス\n",
    "        model.load_weights(ckpt_path)  # 重みをロード\n",
    "        model = model.to(device).eval()  # デバイスに移動し評価モードに設定\n",
    "        \n",
    "    return model  # モデルを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.794995Z",
     "iopub.status.busy": "2024-06-28T13:47:31.794426Z",
     "iopub.status.idle": "2024-06-28T13:47:31.808707Z",
     "shell.execute_reply": "2024-06-28T13:47:31.80787Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.794963Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(VARIANT, device):\n",
    "    WEIGHTS_PATH = f'/kaggle/input/gemma/pytorch/{VARIANT}/2' \n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def _set_default_tensor_type(dtype: torch.dtype):\n",
    "        \"\"\"与えられたdtypeを使用してデフォルトのtorchデータ型を設定します。\"\"\"\n",
    "        torch.set_default_dtype(dtype)  # デフォルトのdtypeを設定\n",
    "        yield\n",
    "        torch.set_default_dtype(torch.float)  # デフォルトdtypeをfloatに戻す\n",
    "\n",
    "    # モデルの設定\n",
    "    model_config = get_config_for_2b() if \"2b\" in VARIANT else get_config_for_7b()  # VARIANTに応じた設定取得\n",
    "    model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")  # トークナイザーのパスを設定\n",
    "    model_config.quant = \"quant\" in VARIANT  # 量子化設定\n",
    "\n",
    "    # モデルをロード\n",
    "    with _set_default_tensor_type(model_config.get_dtype()):  # デフォルトのテンソル型を設定\n",
    "        model = GemmaForCausalLM(model_config)  # モデルを初期化\n",
    "        ckpt_path = os.path.join(WEIGHTS_PATH, f'gemma-{VARIANT}.ckpt')  # チェックポイントパス\n",
    "        model.load_weights(ckpt_path)  # 重みをロード\n",
    "        model = model.to(device).eval()  # デバイスに移動し評価モードに設定\n",
    "        \n",
    "    return model  # モデルを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbacdf05",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def _parse_keyword(response: str):\n",
    "    match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)\n",
    "    if match is None:\n",
    "        keyword = ''\n",
    "    else:\n",
    "        keyword = match.group().lower()\n",
    "    return keyword\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def _parse_keyword(response: str):\n",
    "    match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)  # キーワードの抽出\n",
    "    if match is None:\n",
    "        keyword = ''  # マッチしない場合は空文字\n",
    "    else:\n",
    "        keyword = match.group().lower()  # マッチした場合は小文字に変換\n",
    "    return keyword  # キーワードを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.809865Z",
     "iopub.status.busy": "2024-06-28T13:47:31.809558Z",
     "iopub.status.idle": "2024-06-28T13:47:31.821925Z",
     "shell.execute_reply": "2024-06-28T13:47:31.821138Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.809814Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_keyword(response: str):\n",
    "    match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)  # キーワードの抽出\n",
    "    if match is None:\n",
    "        keyword = ''  # マッチしない場合は空文字\n",
    "    else:\n",
    "        keyword = match.group().lower()  # マッチした場合は小文字に変換\n",
    "    return keyword  # キーワードを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc2850",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def _parse_response(response: str, obs: dict):\n",
    "    if obs['turnType'] == 'ask':\n",
    "        match = re.search(\".+?\\?\", response.replace('*', ''))\n",
    "        if match is None:\n",
    "            question = \"Is it a person?\"\n",
    "        else:\n",
    "            question = match.group()\n",
    "        return question\n",
    "    elif obs['turnType'] == 'guess':\n",
    "        guess = _parse_keyword(response)\n",
    "        return guess\n",
    "    else:\n",
    "        raise ValueError(\"Unknown turn type:\", obs['turnType'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def _parse_response(response: str, obs: dict):\n",
    "    if obs['turnType'] == 'ask':\n",
    "        match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問を抽出\n",
    "        if match is None:\n",
    "            question = \"人ですか？\"  # マッチしない場合のデフォルト質問\n",
    "        else:\n",
    "            question = match.group()  # 質問を返す\n",
    "        return question\n",
    "    elif obs['turnType'] == 'guess':\n",
    "        guess = _parse_keyword(response)  # キーワードを抽出\n",
    "        return guess\n",
    "    else:\n",
    "        raise ValueError(\"不明なターンタイプ:\", obs['turnType'])  # エラーを発生させる\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.823345Z",
     "iopub.status.busy": "2024-06-28T13:47:31.823021Z",
     "iopub.status.idle": "2024-06-28T13:47:31.832614Z",
     "shell.execute_reply": "2024-06-28T13:47:31.831874Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.823315Z"
    }
   },
   "outputs": [],
   "source": [
    "def _parse_response(response: str, obs: dict):\n",
    "    if obs['turnType'] == 'ask':\n",
    "        match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問を抽出\n",
    "        if match is None:\n",
    "            question = \"人ですか？\"  # マッチしない場合のデフォルト質問\n",
    "        else:\n",
    "            question = match.group()  # 質問を返す\n",
    "        return question\n",
    "    elif obs['turnType'] == 'guess':\n",
    "        guess = _parse_keyword(response)  # キーワードを抽出\n",
    "        return guess\n",
    "    else:\n",
    "        raise ValueError(\"不明なターンタイプ:\", obs['turnType'])  # エラーを発生させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cbd29e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def interleave_unequal(x, y):\n",
    "    return [\n",
    "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
    "    ]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def interleave_unequal(x, y):\n",
    "    return [\n",
    "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
    "    ]  # 長さの異なるリストを交互にマージ\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.834217Z",
     "iopub.status.busy": "2024-06-28T13:47:31.83377Z",
     "iopub.status.idle": "2024-06-28T13:47:31.842001Z",
     "shell.execute_reply": "2024-06-28T13:47:31.841138Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.834187Z"
    }
   },
   "outputs": [],
   "source": [
    "def interleave_unequal(x, y):\n",
    "    return [\n",
    "        item for pair in itertools.zip_longest(x, y) for item in pair if item is not None\n",
    "    ]  # 長さの異なるリストを交互にマージ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45b471",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "system_prompt = \"You are an AI assistant designed to play the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner. The keyword is a specific person, place, or thing.\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    \"Let's play 20 Questions. You are playing the role of the Questioner. Please ask your first question.\",\n",
    "    \"Is it a thing?\", \"**no**\",\n",
    "    \"Is is a country?\", \"**yes**\",\n",
    "    \"Is it Europe?\", \"**yes** Now guess the keyword.\",\n",
    "    \"**France**\", \"Correct!\",\n",
    "]\n",
    "\n",
    "formatter = GemmaFormatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "system_prompt = \"あなたは20の質問ゲームをプレイするために設計されたAIアシスタントです。このゲームでは、回答者がキーワードを考え、質問者がはいまたはいいえで質問に答えます。キーワードは特定の人、場所、または物です。\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    \"20の質問をプレイしましょう。あなたは質問者の役割を果たします。最初の質問をしてください。\",\n",
    "    \"それは物ですか？\", \"**いいえ**\",\n",
    "    \"それは国ですか？\", \"**はい**\",\n",
    "    \"それはヨーロッパですか？\", \"**はい** ではキーワードを推測してください。\",\n",
    "    \"**フランス**\", \"正解！\",\n",
    "]\n",
    "\n",
    "formatter = GemmaFormatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)  # フォーマッターを初期化\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.843806Z",
     "iopub.status.busy": "2024-06-28T13:47:31.843109Z",
     "iopub.status.idle": "2024-06-28T13:47:31.851451Z",
     "shell.execute_reply": "2024-06-28T13:47:31.850649Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.843774Z"
    }
   },
   "outputs": [],
   "source": [
    "system_prompt = \"あなたは20の質問ゲームをプレイするために設計されたAIアシスタントです。このゲームでは、回答者がキーワードを考え、質問者がはいまたはいいえで質問に答えます。キーワードは特定の人、場所、または物です。\"\n",
    "\n",
    "few_shot_examples = [\n",
    "    \"20の質問をプレイしましょう。あなたは質問者の役割を果たします。最初の質問をしてください。\",\n",
    "    \"それは物ですか？\", \"**いいえ**\",\n",
    "    \"それは国ですか？\", \"**はい**\",\n",
    "    \"それはヨーロッパですか？\", \"**はい** ではキーワードを推測してください。\",\n",
    "    \"**フランス**\", \"正解！\",\n",
    "]\n",
    "\n",
    "formatter = GemmaFormatter(system_prompt=system_prompt, few_shot_examples=few_shot_examples)  # フォーマッターを初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6f0b8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "obs = {\n",
    "    'turnType': 'ask',\n",
    "    'questions': [\n",
    "        'Is it a living entity?',\n",
    "        'Is it man-made?',\n",
    "        'Can it be held in a single hand?'\n",
    "    ],\n",
    "    'answers': [\n",
    "        'no',\n",
    "        'yes',\n",
    "        'yes'\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "obs = {\n",
    "    'turnType': 'ask',  # 現在のターンタイプ\n",
    "    'questions': [\n",
    "        'それは生きているものですか？',\n",
    "        '人工的なものでしょうか？',\n",
    "        '片手で持てるものですか？'\n",
    "    ],\n",
    "    'answers': [\n",
    "        'いいえ',\n",
    "        'はい',\n",
    "        'はい'\n",
    "    ]\n",
    "}  # 観察情報\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.852794Z",
     "iopub.status.busy": "2024-06-28T13:47:31.85249Z",
     "iopub.status.idle": "2024-06-28T13:47:31.864509Z",
     "shell.execute_reply": "2024-06-28T13:47:31.863739Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.852772Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = {\n",
    "    'turnType': 'ask',  # 現在のターンタイプ\n",
    "    'questions': [\n",
    "        'それは生きているものですか？',\n",
    "        '人工的なものでしょうか？',\n",
    "        '片手で持てるものですか？'\n",
    "    ],\n",
    "    'answers': [\n",
    "        'いいえ',\n",
    "        'はい',\n",
    "        'はい'\n",
    "    ]\n",
    "}  # 観察情報"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808e8449",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "formatter.reset()\n",
    "formatter.user(\"Let's play 20 Questions. You are playing the role of the Questioner.\")\n",
    "turns = interleave_unequal(obs['questions'], obs['answers'])\n",
    "formatter.apply_turns(turns, start_agent='model')\n",
    "if obs['turnType'] == 'ask':\n",
    "    formatter.user(\"Please ask a yes-or-no question.\")\n",
    "elif obs['turnType'] == 'guess':\n",
    "    formatter.user(\"Now guess the keyword. Surround your guess with double asterisks.\")\n",
    "formatter.start_model_turn()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "formatter.reset()  # フォーマッターをリセット\n",
    "formatter.user(\"20の質問をプレイしましょう。あなたは質問者の役割を果たします。\")  # ユーザーを初期化\n",
    "turns = interleave_unequal(obs['questions'], obs['answers'])  # 質問と回答を交互に整列\n",
    "formatter.apply_turns(turns, start_agent='model')  # ターンを適用\n",
    "if obs['turnType'] == 'ask':\n",
    "    formatter.user(\"はいまたはいいえで答えてください。\")  # 質問タイプがaskの時\n",
    "elif obs['turnType'] == 'guess':\n",
    "    formatter.user(\"今キーワードを推測してください。ダブルアスタリスクで囲んでください。\")  # 質問タイプがguessの時\n",
    "formatter.start_model_turn()  # モデルのターンを開始\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.868247Z",
     "iopub.status.busy": "2024-06-28T13:47:31.867968Z",
     "iopub.status.idle": "2024-06-28T13:47:31.877294Z",
     "shell.execute_reply": "2024-06-28T13:47:31.876427Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.868204Z"
    }
   },
   "outputs": [],
   "source": [
    "formatter.reset()  # フォーマッターをリセット\n",
    "formatter.user(\"20の質問をプレイしましょう。あなたは質問者の役割を果たします。\")  # ユーザーを初期化\n",
    "turns = interleave_unequal(obs['questions'], obs['answers'])  # 質問と回答を交互に整列\n",
    "formatter.apply_turns(turns, start_agent='model')  # ターンを適用\n",
    "if obs['turnType'] == 'ask':\n",
    "    formatter.user(\"はいまたはいいえで答えてください。\")  # 質問タイプがaskの時\n",
    "elif obs['turnType'] == 'guess':\n",
    "    formatter.user(\"今キーワードを推測してください。ダブルアスタリスクで囲んでください。\")  # 質問タイプがguessの時\n",
    "formatter.start_model_turn()  # モデルのターンを開始"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd96e5c1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "prompt = str(formatter)\n",
    "prompt\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "prompt = str(formatter)  # フォーマッターからプロンプトを生成\n",
    "prompt  # プロンプトを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.87862Z",
     "iopub.status.busy": "2024-06-28T13:47:31.878349Z",
     "iopub.status.idle": "2024-06-28T13:47:31.887707Z",
     "shell.execute_reply": "2024-06-28T13:47:31.886764Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.878596Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = str(formatter)  # フォーマッターからプロンプトを生成\n",
    "prompt  # プロンプトを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e326ad43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "MACHINE_TYPE = \"cuda\" \n",
    "device = torch.device(MACHINE_TYPE)\n",
    "max_new_tokens = 32\n",
    "sampler_kwargs = {\n",
    "'temperature': 0.01,\n",
    "'top_p': 0.1,\n",
    "'top_k': 1,\n",
    "}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "MACHINE_TYPE = \"cuda\"  # 使用する機械のタイプを指定\n",
    "device = torch.device(MACHINE_TYPE)  # デバイスを設定\n",
    "max_new_tokens = 32  # 最大生成トークン数\n",
    "sampler_kwargs = {\n",
    "'temperature': 0.01,  # 温度パラメータ\n",
    "'top_p': 0.1,  # 確率のトップpフィルタリング\n",
    "'top_k': 1,  # トップkフィルタリング\n",
    "}\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.890731Z",
     "iopub.status.busy": "2024-06-28T13:47:31.888869Z",
     "iopub.status.idle": "2024-06-28T13:47:31.895711Z",
     "shell.execute_reply": "2024-06-28T13:47:31.895002Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.890706Z"
    }
   },
   "outputs": [],
   "source": [
    "MACHINE_TYPE = \"cuda\"  # 使用する機械のタイプを指定\n",
    "device = torch.device(MACHINE_TYPE)  # デバイスを設定\n",
    "max_new_tokens = 32  # 最大生成トークン数\n",
    "sampler_kwargs = {\n",
    "'temperature': 0.01,  # 温度パラメータ\n",
    "'top_p': 0.1,  # 確率のトップpフィルタリング\n",
    "'top_k': 1,  # トップkフィルタリング\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a6332",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Gemma 2b V2\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Gemma 2b V2\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69d6e03",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = load_model(\"2b\", device)\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")\n",
    "response = _parse_response(response, obs)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = load_model(\"2b\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:47:31.897079Z",
     "iopub.status.busy": "2024-06-28T13:47:31.896743Z",
     "iopub.status.idle": "2024-06-28T13:48:09.346136Z",
     "shell.execute_reply": "2024-06-28T13:48:09.345216Z",
     "shell.execute_reply.started": "2024-06-28T13:47:31.897046Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"2b\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aeda71",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Gemma 2b-it V2\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Gemma 2b-it V2\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e78351",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = load_model(\"2b-it\", device)\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")\n",
    "response = _parse_response(response, obs)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = load_model(\"2b-it\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:48:09.347623Z",
     "iopub.status.busy": "2024-06-28T13:48:09.34733Z",
     "iopub.status.idle": "2024-06-28T13:48:44.807608Z",
     "shell.execute_reply": "2024-06-28T13:48:44.806732Z",
     "shell.execute_reply.started": "2024-06-28T13:48:09.347597Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"2b-it\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fdcb74",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Gemma 7b-it-quant V2\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Gemma 7b-it-quant V2\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d648210",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = load_model(\"7b-it-quant\", device)\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")\n",
    "response = _parse_response(response, obs)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = load_model(\"7b-it-quant\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T13:48:44.809002Z",
     "iopub.status.busy": "2024-06-28T13:48:44.808712Z",
     "iopub.status.idle": "2024-06-28T13:49:57.08955Z",
     "shell.execute_reply": "2024-06-28T13:49:57.08861Z",
     "shell.execute_reply.started": "2024-06-28T13:48:44.808978Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"7b-it-quant\", device)  # モデルをロード\n",
    "\n",
    "response = model.generate(\n",
    "    prompt,\n",
    "    device=device,\n",
    "    output_len=max_new_tokens,\n",
    "    **sampler_kwargs\n",
    ")  # モデルによる応答を生成\n",
    "response = _parse_response(response, obs)  # 応答を解析\n",
    "print(response)  # 応答を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86706e09",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント\n",
    "\n",
    "> ## dedq\n",
    "> \n",
    "> コードが明確で、迅速に実行されます。Kaggleのメンバーへの最高の仕事を共有してくれてありがとう！\n",
    "> \n",
    "> \n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8749,
     "sourceId": 11359,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5305,
     "sourceId": 11357,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5383,
     "sourceId": 11358,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
