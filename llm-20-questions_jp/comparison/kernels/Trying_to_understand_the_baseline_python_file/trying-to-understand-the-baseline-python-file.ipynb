{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ab0f39",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「20の質問」ゲームにおけるエージェントのロジックを実装し、実行するためのものであり、特に推測者（Guesser）および回答者（Answerer）エージェントのインタラクションを自動化しています。以下は、取り組まれている問題、使用されている手法やライブラリについての要約です。\n",
    "\n",
    "## 問題\n",
    "このNotebookは、2対2の協力プレイ形式で行われる「20の質問」ゲームにおいて、言語モデルがどのようにキーワードを推測し、質問をし、回答を行うかを実装しています。エージェントは、要求された情報を使用してできるだけ少ない質問で正解を導くことを目指しています。\n",
    "\n",
    "## 手法\n",
    "### エージェントのロジック\n",
    "- **推測者エージェント (`guesser_agent`)**: 現在のゲームの状態や過去の質問・回答履歴を元に、次に行う質問や推測を動的に生成します。これには、ゲームの状態に合わせたプロンプトを生成し、言語モデル（LLM）を呼び出して応答を得ます。\n",
    "  \n",
    "- **回答者エージェント (`answerer_agent`)**: 質問を受け取り、基づいて「はい」「いいえ」または「かもしれない」といった応答を返します。キーワードとそのカテゴリに基づいた正確な応答が求められます。\n",
    "\n",
    "### 使用するライブラリ\n",
    "- **Pandas**: データ管理や操作に使用。\n",
    "- **JSON**: ゲームの設定や観察結果の読み込みに使用。\n",
    "- **Torch** と **Transformers**: T5モデルを利用して自然言語の質問応答処理を行うために使用されます。\n",
    "- **Kaggle Environments**: ゲームの環境を生成し、エージェントのインタラクションを管理します。\n",
    "\n",
    "### ユーザーによる設定\n",
    "- **キーワードの選択**: あらかじめ定義されたリストからキーワードをランダムに選択し、ゲームの開始を準備します。\n",
    "  \n",
    "### ゲームのロジック\n",
    "- ゲームは、エージェントが遷移とアクションの制御を通じて進行し、終了条件が満たされるまで続きます。推測が成功するか、時間切れやエラーが発生するかでゲームが終了します。\n",
    "\n",
    "## 留意点\n",
    "- ゲームが進行する中で、エージェントはインタラクションとアクションを経て状態を更新し、結果に基づいた報酬を受けます。また、応答が無効または不正確な場合にはエラーとしてゲームを終了させることもあります。\n",
    "\n",
    "このNotebookは、AIを用いたゲームへの応用の一例を示し、エージェントの自律的な動作を通じて推理や戦略的思考を評価できる方法を提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7384c03",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下はJupyter Notebookに登場する専門用語や概念についての簡単な解説です。機械学習や深層学習に関する基礎的な知識を持つ初心者向けに、具体的なコンテキストや実務経験が必要になる可能性のある専門用語に焦点を当てています。\n",
    "\n",
    "1. **ロール（役割）**:\n",
    "   - ゲーム内でのエージェントの役割を指します。ここでは、質問と推測を行う「質問者（guesser）」と、その質問に回答する「回答者（answerer）」の2つのロールがあります。\n",
    "\n",
    "2. **プロンプト（prompt）**:\n",
    "   - 言語モデルに入力され、モデルから応答を得るためのテキスト。具体的には、質問や指示内容を含む文がここに該当します。\n",
    "\n",
    "3. **エージェント（agent）**:\n",
    "   - 環境内で行動を行う実体を指します。ここでは、質問をする役割のエージェントと、回答をする役割のエージェントが登場します。\n",
    "\n",
    "4. **呼び出し関数（call_llm）**:\n",
    "   - 言語モデルを呼び出してプロンプトに対する応答を得るための関数。モデルの初期化とプロンプトのトークナイズ、生成されたトークンをデコードする役割があります。\n",
    "\n",
    "5. **トークナイザー（tokenizer）**:\n",
    "   - テキストをトークンと呼ばれる小さな単位に変換するためのツール。トークンは通常、単語や句、あるいはそれを構成する部分を指します。\n",
    "\n",
    "6. **キーワード（keyword）**:\n",
    "   - このコンペティションにおける特定の単語やフレーズを指します。質問者が当てるべきターゲットとなる言葉です。\n",
    "\n",
    "7. **状態（state）**:\n",
    "   - ゲームやエージェントの現在の進行状況を表す情報の集合体。ゲームの進行や各エージェントのロール、アクションなどを含みます。\n",
    "\n",
    "8. **条件分岐（conditional statements）**:\n",
    "   - プログラムの流れを制御するために用いられる構文。特定の条件に基づいて異なる処理を実行するためのものです。\n",
    "\n",
    "9. **エピソード（episode）**:\n",
    "   - 環境内での一連の相互作用や行動の流れ。特定のゲームセッションを指すことがあります。\n",
    "\n",
    "10. **スコア（score）**:\n",
    "    - ゲーム内でのパフォーマンスを評価するための数値。成功した質問や推測の結果に基づいて計算され、チームの成績を決定します。\n",
    "\n",
    "11. **インタープリタ（interpreter）**:\n",
    "    - エージェントのアクションとゲームの状態を処理する関数。ゲームの進行を管理し、次に取るべきアクションを決定します。\n",
    "\n",
    "12. **エラー処理（error handling）**:\n",
    "    - プログラムが異常な状態やエラーが発生したときの動作を制御する技術。無効な入力やタイムアウトを管理し、ゲームを適切に終了します。\n",
    "\n",
    "これらの用語は、特にこのコンペティションの特定のコンテキストやアルゴリズムによる実装において理解が必要な概念です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ffdfa",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Code documented with the help of ChatGPT\n",
    "\n",
    "# First Settings\n",
    "Configuration of the execution environment, defines constants for states and actions, and randomly selects a keyword and its alternatives from a pre-defined list, thus preparing the 20-question game to start.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ChatGPTの助けを借りて文書化されたコード\n",
    "\n",
    "# 最初の設定\n",
    "実行環境の構成、状態とアクションの定数を定義し、あらかじめ定義されたリストからキーワードとその代替をランダムに選択します。これにより、「20の質問」ゲームの開始準備が整います。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf35c0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import sys\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import sys\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.684101Z",
     "iopub.status.busy": "2024-06-01T17:52:53.683668Z",
     "iopub.status.idle": "2024-06-01T17:52:53.691043Z",
     "shell.execute_reply": "2024-06-01T17:52:53.689454Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.68407Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5a3270",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "sys.path.append(\"/kaggle/input/llm-20-questions/llm_20_questions\")\n",
    "\n",
    "from  keywords import KEYWORDS_JSON\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "from string import Template\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "llm_parent_dir = \"/kaggle/input/flan-t5/pytorch/large\"\n",
    "device = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_initialized = False\n",
    "ERROR = \"ERROR\"\n",
    "DONE = \"DONE\"\n",
    "INACTIVE = \"INACTIVE\"\n",
    "ACTIVE = \"ACTIVE\"\n",
    "TIMEOUT = \"TIMEOUT\"\n",
    "GUESS = \"guess\"\n",
    "ASK = \"ask\"\n",
    "GUESSER = \"guesser\"\n",
    "ANSWERER = \"guesser\"\n",
    "keywords_list = json.loads(KEYWORDS_JSON)\n",
    "keyword_cat = random.choice(keywords_list)\n",
    "category = keyword_cat[\"category\"]\n",
    "keyword_obj = random.choice(keyword_cat[\"words\"])\n",
    "keyword = keyword_obj[\"keyword\"]\n",
    "alts = keyword_obj[\"alts\"]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "sys.path.append(\"/kaggle/input/llm-20-questions/llm_20_questions\")\n",
    "\n",
    "from  keywords import KEYWORDS_JSON\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "from string import Template\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "llm_parent_dir = \"/kaggle/input/flan-t5/pytorch/large\"\n",
    "device = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_initialized = False\n",
    "ERROR = \"ERROR\"\n",
    "DONE = \"DONE\"\n",
    "INACTIVE = \"INACTIVE\"\n",
    "ACTIVE = \"ACTIVE\"\n",
    "TIMEOUT = \"TIMEOUT\"\n",
    "GUESS = \"guess\"\n",
    "ASK = \"ask\"\n",
    "GUESSER = \"guesser\"\n",
    "ANSWERER = \"guesser\"\n",
    "keywords_list = json.loads(KEYWORDS_JSON)\n",
    "keyword_cat = random.choice(keywords_list)\n",
    "category = keyword_cat[\"category\"]\n",
    "keyword_obj = random.choice(keyword_cat[\"words\"])\n",
    "keyword = keyword_obj[\"keyword\"]\n",
    "alts = keyword_obj[\"alts\"]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.693538Z",
     "iopub.status.busy": "2024-06-01T17:52:53.693159Z",
     "iopub.status.idle": "2024-06-01T17:52:53.722318Z",
     "shell.execute_reply": "2024-06-01T17:52:53.721167Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.693505Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "sys.path.append(\"/kaggle/input/llm-20-questions/llm_20_questions\")\n",
    "\n",
    "from  keywords import KEYWORDS_JSON\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "from string import Template\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "llm_parent_dir = \"/kaggle/input/flan-t5/pytorch/large\"\n",
    "device = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_initialized = False\n",
    "ERROR = \"ERROR\"\n",
    "DONE = \"DONE\"\n",
    "INACTIVE = \"INACTIVE\"\n",
    "ACTIVE = \"ACTIVE\"\n",
    "TIMEOUT = \"TIMEOUT\"\n",
    "GUESS = \"guess\"\n",
    "ASK = \"ask\"\n",
    "GUESSER = \"guesser\"\n",
    "ANSWERER = \"guesser\"\n",
    "keywords_list = json.loads(KEYWORDS_JSON)\n",
    "keyword_cat = random.choice(keywords_list)\n",
    "category = keyword_cat[\"category\"]\n",
    "keyword_obj = random.choice(keyword_cat[\"words\"])\n",
    "keyword = keyword_obj[\"keyword\"]\n",
    "alts = keyword_obj[\"alts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce262e6a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Guesser Agent\n",
    "\n",
    "The <i>guesser_agent</i> function creates dynamic prompts based on the current game state and turn type, and then uses a language model to generate the next action in the game. Specifically:\n",
    "\n",
    "1. Builds a history of questions and answers so far.\n",
    "1. Choose the appropriate prompt (question or guess) based on the turn type.\n",
    "1. Generates the next action by calling a language model with the constructed prompt.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 推測者エージェント\n",
    "\n",
    "`guesser_agent`関数は、現在のゲームの状態とターンの種類に基づいて動的なプロンプトを生成し、次のアクションを決定するために言語モデルを使用します。具体的には：\n",
    "\n",
    "1. これまでの質問と回答の履歴を構築します。\n",
    "2. ターンの種類に基づいて適切なプロンプト（質問または推測）を選択します。\n",
    "3. 構築したプロンプトを使用して言語モデルを呼び出し、次のアクションを生成します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7101e18",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def guesser_agent(obs):\n",
    "    info_prompt = \"\"\"You are playing a game of 20 questions where you ask the questions and try to figure out the keyword, which will be a real or fictional person, place, or thing. \\nHere is what you know so far:\\n{q_a_thread}\"\"\"\n",
    "    questions_prompt = \"\"\"Ask one yes or no question.\"\"\"\n",
    "    guess_prompt = \"\"\"Guess the keyword. Only respond with the exact word/phrase. For example, if you think the keyword is [paris], don't respond with [I think the keyword is paris] or [Is the kewyord Paris?]. Respond only with the word [paris].\"\"\"\n",
    "    q_a_thread = \"\"\n",
    "    for i in range(0, len(obs.answers)):\n",
    "        q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "            q_a_thread,\n",
    "            obs.questions[i],\n",
    "            obs.answers[i]\n",
    "        )\n",
    "    prompt = \"\"\n",
    "    if obs.turnType == ASK:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "    elif obs.turnType == GUESS:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    return call_llm(prompt)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def guesser_agent(obs):\n",
    "    info_prompt = \"\"\"20の質問ゲームをプレイしており、質問をしながらキーワードを特定しようとしています。それまでの情報は以下の通りです:\\n{q_a_thread}\"\"\"\n",
    "    questions_prompt = \"\"\"はいまたはいいえで答えられる質問を1つしてください。\"\"\"\n",
    "    guess_prompt = \"\"\"キーワードを推測してください。正確な単語/フレーズだけで応答してください。たとえば、キーワードが[パリ]だと思うなら、[私はキーワードはパリだと思います]や[キーワードはパリですか？]とは応答せず、単に[パリ]と言ってください。\"\"\"\n",
    "    q_a_thread = \"\"\n",
    "    for i in range(0, len(obs.answers)):\n",
    "        q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "            q_a_thread,\n",
    "            obs.questions[i],\n",
    "            obs.answers[i]\n",
    "        )\n",
    "    prompt = \"\"\n",
    "    if obs.turnType == ASK:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "    elif obs.turnType == GUESS:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    return call_llm(prompt)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.724906Z",
     "iopub.status.busy": "2024-06-01T17:52:53.724494Z",
     "iopub.status.idle": "2024-06-01T17:52:53.735145Z",
     "shell.execute_reply": "2024-06-01T17:52:53.733533Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.724837Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_agent(obs):\n",
    "    info_prompt = \"\"\"20の質問ゲームをプレイしており、質問をしながらキーワードを特定しようとしています。それまでの情報は以下の通りです:\\n{q_a_thread}\"\"\"\n",
    "    questions_prompt = \"\"\"はいまたはいいえで答えられる質問を1つしてください。\"\"\"\n",
    "    guess_prompt = \"\"\"キーワードを推測してください。正確な単語/フレーズだけで応答してください。たとえば、キーワードが[パリ]だと思うなら、[私はキーワードはパリだと思います]や[キーワードはパリですか？]とは応答せず、単に[パリ]と言ってください。\"\"\"\n",
    "    q_a_thread = \"\"\n",
    "    for i in range(0, len(obs.answers)):\n",
    "        q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "            q_a_thread,\n",
    "            obs.questions[i],\n",
    "            obs.answers[i]\n",
    "        )\n",
    "    prompt = \"\"\n",
    "    if obs.turnType == ASK:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "    elif obs.turnType == GUESS:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    return call_llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb91180",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Answerer Agent\n",
    "The answerer_agent function:\n",
    "\n",
    "1. Checks if the turn type is \"answer\".\n",
    "\n",
    "1. If so, create a prompt by combining info_prompt and answer_question_prompt, replacing the placeholders with the actual values.\n",
    "\n",
    "1. Calls the call_llm function with the generated prompt to get the response.\n",
    "\n",
    "1. If the turn is not \"answer\", returns an empty string.\n",
    "\n",
    "1. The agents dictionary maps agent types to the respective roles that define their behavior in the game.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 回答者エージェント\n",
    "`answerer_agent`関数は：\n",
    "\n",
    "1. ターンのタイプが「answer」であるかを確認します。\n",
    "\n",
    "1. そうであれば、info_promptとanswer_question_promptを組み合わせたプロンプトを作成し、実際の値でプレースホルダを置き換えます。\n",
    "\n",
    "1. 生成されたプロンプトを使用してcall_llm関数を呼び出し、応答を取得します。\n",
    "\n",
    "1. ターンが「answer」でない場合は、空の文字列を返します。\n",
    "\n",
    "1. agents辞書は、エージェントタイプをゲーム内の振る舞いを定義する役割にマップします。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ac73e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def answerer_agent(obs):\n",
    "    info_prompt = \"\"\"You are a very precise answerer in a game of 20 questions. The keyword that the questioner is trying to guess is [the {category} {keyword}]. \"\"\"\n",
    "    answer_question_prompt = \"\"\"Answer the following question with only yes, no, or if unsure maybe: {question}\"\"\"\n",
    "    if obs.turnType == \"answer\":\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(category=category,keyword=keyword),\n",
    "            answer_question_prompt.format(question=obs.questions[-1])\n",
    "        )\n",
    "        return call_llm(prompt)\n",
    "    else: \n",
    "        return \"\"\n",
    "agents = {GUESSER: guesser_agent, ANSWERER: answerer_agent}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def answerer_agent(obs):\n",
    "    info_prompt = \"\"\"あなたは20の質問ゲームで非常に正確な回答者です。質問者が推測しようとしているキーワードは[the {category} {keyword}]です。\"\"\"\n",
    "    answer_question_prompt = \"\"\"次の質問に対して「はい」、「いいえ」または「もし不明なら「かもしれない」とだけ回答してください: {question}\"\"\"\n",
    "    if obs.turnType == \"answer\":\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(category=category,keyword=keyword),\n",
    "            answer_question_prompt.format(question=obs.questions[-1])\n",
    "        )\n",
    "        return call_llm(prompt)\n",
    "    else: \n",
    "        return \"\"\n",
    "agents = {GUESSER: guesser_agent, ANSWERER: answerer_agent}\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.737143Z",
     "iopub.status.busy": "2024-06-01T17:52:53.736759Z",
     "iopub.status.idle": "2024-06-01T17:52:53.746596Z",
     "shell.execute_reply": "2024-06-01T17:52:53.745085Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.737114Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_agent(obs):\n",
    "    info_prompt = \"\"\"あなたは20の質問ゲームで非常に正確な回答者です。質問者が推測しようとしているキーワードは[the {category} {keyword}]です。\"\"\"\n",
    "    answer_question_prompt = \"\"\"次の質問に対して「はい」、「いいえ」または「もし不明なら「かもしれない」とだけ回答してください: {question}\"\"\"\n",
    "    if obs.turnType == \"answer\":\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(category=category,keyword=keyword),\n",
    "            answer_question_prompt.format(question=obs.questions[-1])\n",
    "        )\n",
    "        return call_llm(prompt)\n",
    "    else: \n",
    "        return \"\"\n",
    "agents = {GUESSER: guesser_agent, ANSWERER: answerer_agent}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8598961e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Guesser Action\n",
    "\n",
    "### Components of the Function\n",
    "1. **Initialization of the `guessed` Variable**:\n",
    "   - The variable `guessed` is initialized as `False` to track whether the keyword has been correctly guessed.\n",
    "   ```python\n",
    "   guessed = False\n",
    "   ```\n",
    "2. **Checking for No Action**:\n",
    "   - If `active.action` is empty (no action was taken), the status of `active` is set to `ERROR`.\n",
    "   ```python\n",
    "   if not active.action:\n",
    "       active.status = ERROR\n",
    "   ```\n",
    "3. **Handling Question-Asking Turn**:\n",
    "   - If the observer’s turn type (`turnType`) is `ASK` (ask a question):\n",
    "     - The action (`active.action`) is treated as a question and is limited to 2000 characters.\n",
    "     - The question is appended to the lists of questions for both the active and inactive observers.\n",
    "   ```python\n",
    "   elif active.observation.turnType == ASK:\n",
    "       question = active.action[:2000]\n",
    "       active.observation.questions.append(question)\n",
    "       inactive.observation.questions.append(question)\n",
    "   ```\n",
    "4. **Handling Guessing Turn**:\n",
    "   - If the observer’s turn type is `GUESS` (make a guess):\n",
    "     - The action (`active.action`) is treated as a guess and is limited to 100 characters.\n",
    "     - The guess is appended to the lists of guesses for both the active and inactive observers.\n",
    "   ```python\n",
    "   elif active.observation.turnType == GUESS:\n",
    "       guess = active.action[:100]\n",
    "       active.observation.guesses.append(guess)\n",
    "       inactive.observation.guesses.append(guess)\n",
    "   ```\n",
    "5. **Checking if the Keyword is Guessed**:\n",
    "   - If there is an action (`active.action`) and the keyword is correctly guessed (`keyword_guessed(active.action)`):\n",
    "     - The variable `guessed` is set to `True`.\n",
    "     - The score is calculated as `20 - int(step / 3)`, where `step` represents the number of steps taken in the game.\n",
    "     - The `end_game` function is called to end the game with the active and inactive observers, passing the score and final states `DONE`.\n",
    "   ```python\n",
    "   if active.action and keyword_guessed(active.action):\n",
    "       guessed = True\n",
    "       score = 20 - int(step / 3)\n",
    "       end_game(active, inactive, score, DONE, DONE)\n",
    "   ```\n",
    "6. **Return the `guessed` Variable**:\n",
    "   - The function returns the `guessed` variable, indicating whether the keyword has been correctly guessed.\n",
    "   ```python\n",
    "   return guessed\n",
    "   ```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 推測者アクション\n",
    "\n",
    "### 関数のコンポーネント\n",
    "1. **`guessed`変数の初期化**:\n",
    "   - `guessed`変数は`False`として初期化され、キーワードが正しく推測されたかどうかを追跡します。\n",
    "   ```python\n",
    "   guessed = False\n",
    "   ```\n",
    "2. **アクションなしのチェック**:\n",
    "   - `active.action`が空である場合（アクションがなかった場合）、`active`の状態が`ERROR`に設定されます。\n",
    "   ```python\n",
    "   if not active.action:\n",
    "       active.status = ERROR\n",
    "   ```\n",
    "3. **質問をするターンの処理**:\n",
    "   - 観測者のターンタイプ（`turnType`）が`ASK`（質問をする）である場合：\n",
    "     - アクション（`active.action`）は質問として扱われ、2000文字に制限されます。\n",
    "     - 質問がアクティブおよび非アクティブの観測者リストに追加されます。\n",
    "   ```python\n",
    "   elif active.observation.turnType == ASK:\n",
    "       question = active.action[:2000]\n",
    "       active.observation.questions.append(question)\n",
    "       inactive.observation.questions.append(question)\n",
    "   ```\n",
    "4. **推測ターンの処理**:\n",
    "   - 観測者のターンタイプが`GUESS`（推測する）である場合：\n",
    "     - アクション（`active.action`）は推測として扱われ、100文字に制限されます。\n",
    "     - 推測がアクティブおよび非アクティブの観測者リストに追加されます。\n",
    "   ```python\n",
    "   elif active.observation.turnType == GUESS:\n",
    "       guess = active.action[:100]\n",
    "       active.observation.guesses.append(guess)\n",
    "       inactive.observation.guesses.append(guess)\n",
    "   ```\n",
    "5. **キーワードが推測されたかのチェック**:\n",
    "   - アクション（`active.action`）があり、キーワードが正しく推測された場合（`keyword_guessed(active.action)`）：\n",
    "     - `guessed`変数が`True`に設定されます。\n",
    "     - スコアが`20 - int(step / 3)`として計算され、`step`はゲーム内のステップ数を表します。\n",
    "     - ゲームを終了するために、`end_game`関数がアクティブおよび非アクティブの観測者を呼び出します。\n",
    "   ```python\n",
    "   if active.action and keyword_guessed(active.action):\n",
    "       guessed = True\n",
    "       score = 20 - int(step / 3)\n",
    "       end_game(active, inactive, score, DONE, DONE)\n",
    "   ```\n",
    "6. **`guessed`変数の返却**:\n",
    "   - 関数は`guessed`変数を返し、キーワードが正しく推測されたかどうかを示します。\n",
    "   ```python\n",
    "   return guessed\n",
    "   ```\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371088c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def guesser_action(active, inactive, step):\n",
    "    guessed = False\n",
    "    if not active.action:\n",
    "        active.status = ERROR\n",
    "    elif active.observation.turnType == ASK:\n",
    "        question = active.action[:2000]\n",
    "        active.observation.questions.append(question)\n",
    "        inactive.observation.questions.append(question)\n",
    "    elif active.observation.turnType == GUESS:\n",
    "        guess = active.action[:100]\n",
    "        active.observation.guesses.append(guess)\n",
    "        inactive.observation.guesses.append(guess)\n",
    "    if active.action and keyword_guessed(active.action):\n",
    "        guessed = True\n",
    "        score = 20 - int(step / 3)\n",
    "        end_game(active, inactive, score, DONE, DONE)\n",
    "    return guessed\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def guesser_action(active, inactive, step):\n",
    "    guessed = False\n",
    "    if not active.action:\n",
    "        active.status = ERROR\n",
    "    elif active.observation.turnType == ASK:\n",
    "        question = active.action[:2000]\n",
    "        active.observation.questions.append(question)\n",
    "        inactive.observation.questions.append(question)\n",
    "    elif active.observation.turnType == GUESS:\n",
    "        guess = active.action[:100]\n",
    "        active.observation.guesses.append(guess)\n",
    "        inactive.observation.guesses.append(guess)\n",
    "    if active.action and keyword_guessed(active.action):\n",
    "        guessed = True\n",
    "        score = 20 - int(step / 3)\n",
    "        end_game(active, inactive, score, DONE, DONE)\n",
    "    return guessed\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.750303Z",
     "iopub.status.busy": "2024-06-01T17:52:53.749419Z",
     "iopub.status.idle": "2024-06-01T17:52:53.763111Z",
     "shell.execute_reply": "2024-06-01T17:52:53.761727Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.750264Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_action(active, inactive, step):\n",
    "    guessed = False\n",
    "    if not active.action:\n",
    "        active.status = ERROR\n",
    "    elif active.observation.turnType == ASK:\n",
    "        question = active.action[:2000]\n",
    "        active.observation.questions.append(question)\n",
    "        inactive.observation.questions.append(question)\n",
    "    elif active.observation.turnType == GUESS:\n",
    "        guess = active.action[:100]\n",
    "        active.observation.guesses.append(guess)\n",
    "        inactive.observation.guesses.append(guess)\n",
    "    if active.action and keyword_guessed(active.action):\n",
    "        guessed = True\n",
    "        score = 20 - int(step / 3)\n",
    "        end_game(active, inactive, score, DONE, DONE)\n",
    "    return guessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f324b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# End Game\n",
    "The `end_game` function finalizes the game by:\n",
    "- Setting the keyword and category for both participants.\n",
    "- Assigning rewards to both participants.\n",
    "- Updating the status of both participants.\n",
    "\n",
    "This ensures that all participants have the correct end-of-game information and that their states are appropriately updated to reflect the conclusion of the game.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ゲームの終了\n",
    "`end_game`関数は、ゲームを終了させる役割を果たします：\n",
    "- 両参加者のキーワードとカテゴリーを設定します。\n",
    "- 両参加者に報酬を与えます。\n",
    "- 両参加者の状態を更新します。\n",
    "\n",
    "これにより、すべての参加者が正しいエンドゲーム情報を持ち、彼らの状態がゲームの結論を反映するように適切に更新されます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f6d81",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def end_game(active, inactive, reward, status, inactive_status):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    inactive.observation.keyword = keyword\n",
    "    inactive.observation.category = category\n",
    "    active.reward = reward\n",
    "    inactive.reward = reward\n",
    "    active.status = status\n",
    "    inactive.status = inactive_status\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def end_game(active, inactive, reward, status, inactive_status):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    inactive.observation.keyword = keyword\n",
    "    inactive.observation.category = category\n",
    "    active.reward = reward\n",
    "    inactive.reward = reward\n",
    "    active.status = status\n",
    "    inactive.status = inactive_status\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.765011Z",
     "iopub.status.busy": "2024-06-01T17:52:53.764597Z",
     "iopub.status.idle": "2024-06-01T17:52:53.77889Z",
     "shell.execute_reply": "2024-06-01T17:52:53.776597Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.764979Z"
    }
   },
   "outputs": [],
   "source": [
    "def end_game(active, inactive, reward, status, inactive_status):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    inactive.observation.keyword = keyword\n",
    "    inactive.observation.category = category\n",
    "    active.reward = reward\n",
    "    inactive.reward = reward\n",
    "    active.status = status\n",
    "    inactive.status = inactive_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e92ef91",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Answerer Action\n",
    "\n",
    "The `answerer_action` function processes the answerer's response to a question by:\n",
    "- Setting the keyword and category for the active participant.\n",
    "- Checking if the response is valid and normalizing it to \"yes\", \"no\", or \"maybe\".\n",
    "- Ending the game with an error if the response is invalid or empty.\n",
    "- Appending the response to the answers list of both participants.\n",
    "\n",
    "This function ensures that the game state is appropriately updated based on the answerer's response and handles any errors or invalid responses by ending the game with an error status.\n",
    "\n",
    "**Updating Answers**\n",
    "\n",
    "```python\n",
    "active.observation.answers.append(response)\n",
    "inactive.observation.answers.append(response)\n",
    "```\n",
    "The normalized `response` is appended to the `answers` list of both the `active` and `inactive` participants. This ensures that both participants have a record of the answerer's response.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 回答者アクション\n",
    "\n",
    "`answerer_action`関数は、回答者の質問に対する応答を処理します：\n",
    "- アクティブ参加者のキーワードとカテゴリーを設定します。\n",
    "- 応答が有効であるかを確認し、「はい」、「いいえ」または「かもしれない」に正規化します。\n",
    "- 応答が無効または空であれば、エラーを伴いゲームを終了します。\n",
    "- この応答を両参加者の回答リストに追加します。\n",
    "\n",
    "この関数により、回答者の応答に基づいてゲームの状態が適切に更新され、エラーや無効な応答を処理して、エラー状態でゲームを終了します。\n",
    "\n",
    "**回答の更新**\n",
    "\n",
    "```python\n",
    "active.observation.answers.append(response)\n",
    "inactive.observation.answers.append(response)\n",
    "```\n",
    "正規化された`response`は、`active`および`inactive`の両参加者の`answers`リストに追加されます。これにより、両参加者が回答者の応答を記録します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff4689",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def answerer_action(active, inactive):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    response = active.action\n",
    "    if not response:\n",
    "        response = \"none\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    elif \"yes\" in response.lower():\n",
    "        response = \"yes\"\n",
    "    elif \"no\" in response.lower():\n",
    "        response = \"no\"\n",
    "    else:\n",
    "        response = \"maybe\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    active.observation.answers.append(response)\n",
    "    inactive.observation.answers.append(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def answerer_action(active, inactive):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    response = active.action\n",
    "    if not response:\n",
    "        response = \"none\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    elif \"yes\" in response.lower():\n",
    "        response = \"yes\"\n",
    "    elif \"no\" in response.lower():\n",
    "        response = \"no\"\n",
    "    else:\n",
    "        response = \"maybe\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    active.observation.answers.append(response)\n",
    "    inactive.observation.answers.append(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.782277Z",
     "iopub.status.busy": "2024-06-01T17:52:53.780951Z",
     "iopub.status.idle": "2024-06-01T17:52:53.792029Z",
     "shell.execute_reply": "2024-06-01T17:52:53.790924Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.782226Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_action(active, inactive):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    response = active.action\n",
    "    if not response:\n",
    "        response = \"none\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    elif \"yes\" in response.lower():\n",
    "        response = \"yes\"\n",
    "    elif \"no\" in response.lower():\n",
    "        response = \"no\"\n",
    "    else:\n",
    "        response = \"maybe\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    active.observation.answers.append(response)\n",
    "    inactive.observation.answers.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51372e5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Increment turn\n",
    "The `increment_turn` function:\n",
    "1. Ends the game after 60 steps if the keyword has not been guessed.\n",
    "2. Switches the turn type between \"ask\" and \"guess\" to alternate the roles of asking questions and making guesses.\n",
    "3. Updates the statuses of the active and inactive participants to ensure the correct participant is active for the next turn.\n",
    "\n",
    "This function ensures that the game progresses smoothly, alternates roles between the participants, and properly handles the end of the game if the keyword is not guessed within the allotted turns.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ターンの増分\n",
    "`increment_turn`関数は：\n",
    "1. キーワードが推測されなかった場合、60ステップ後にゲームを終了します。\n",
    "2. 「ask」と「guess」の間でターンの種類を切り替え、質問と推測の役割を交代します。\n",
    "3. アクティブおよび非アクティブ参加者のステータスを更新し、次のターンにどの参加者がアクティブとなるかを正しく確保します。\n",
    "\n",
    "この関数により、ゲームがスムーズに進行し、参加者間で役割が交替し、キーワードが推測されなかった場合に適切にゲームが終了します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9dcac",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def increment_turn(active, inactive, step, guessed):\n",
    "    if step == 59 and not guessed:\n",
    "        end_game(active, inactive, -1, DONE, DONE)\n",
    "    elif active.observation.turnType == \"guess\":\n",
    "        active.observation.turnType = \"ask\"\n",
    "    elif active.observation.turnType == \"ask\":\n",
    "        active.observation.turnType = \"guess\"\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "    else:\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def increment_turn(active, inactive, step, guessed):\n",
    "    if step == 59 and not guessed:\n",
    "        end_game(active, inactive, -1, DONE, DONE)\n",
    "    elif active.observation.turnType == \"guess\":\n",
    "        active.observation.turnType = \"ask\"\n",
    "    elif active.observation.turnType == \"ask\":\n",
    "        active.observation.turnType = \"guess\"\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "    else:\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.794871Z",
     "iopub.status.busy": "2024-06-01T17:52:53.794498Z",
     "iopub.status.idle": "2024-06-01T17:52:53.807073Z",
     "shell.execute_reply": "2024-06-01T17:52:53.805825Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.794827Z"
    }
   },
   "outputs": [],
   "source": [
    "def increment_turn(active, inactive, step, guessed):\n",
    "    if step == 59 and not guessed:\n",
    "        end_game(active, inactive, -1, DONE, DONE)\n",
    "    elif active.observation.turnType == \"guess\":\n",
    "        active.observation.turnType = \"ask\"\n",
    "    elif active.observation.turnType == \"ask\":\n",
    "        active.observation.turnType = \"guess\"\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "    else:\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774055c4",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Interpreter\n",
    "\n",
    "### Purpose of the `interpreter` Function\n",
    "\n",
    "The `interpreter` function manages the state and actions of a game involving two pairs of agents. Each pair consists of an active and an inactive agent, where one agent is asking questions (the \"asker\") and the other is guessing (the \"guesser\"). The function updates the state of the game, determines the actions to be taken by each agent, and handles transitions and end conditions.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "```\n",
    "\n",
    "This line checks if the environment (the game) is done. If it is, the function returns the current state without making any changes.\n",
    "\n",
    "### Isolating Active and Inactive Agents\n",
    "\n",
    "```python\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "```\n",
    "\n",
    "These lines identify which agents are active and inactive for each pair. `state[0]` and `state[1]` are the first pair of agents, while `state[2]` and `state[3]` are the second pair.\n",
    "\n",
    "### Handling Done Status\n",
    "\n",
    "```python\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "```\n",
    "\n",
    "These lines set the agents to `None` if both agents in a pair are done. If all agents are done, the function returns the current state, effectively ending the function.\n",
    "\n",
    "### Processing Steps and End Conditions\n",
    "\n",
    "```python\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "```\n",
    "\n",
    "- `step` stores the current step of the game.\n",
    "- `end_early` checks if either active agent has a status of `TIMEOUT` or `ERROR`, indicating an early termination condition.\n",
    "- `either_guessed` is a flag to track if any agent has guessed the keyword correctly.\n",
    "\n",
    "### Handling Active1 Agent\n",
    "\n",
    "```python\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "```\n",
    "\n",
    "- If `active1` is not `None`, the function checks the agent's role.\n",
    "- If `active1` is the guesser, it calls `guesser_action`.\n",
    "- If `active1` is the answerer, it calls `answerer_action`.\n",
    "- It then handles end conditions such as `TIMEOUT` or `ERROR` by calling `end_game`.\n",
    "- If `end_early` is true, it ends the game.\n",
    "- Otherwise, it calls `increment_turn` to proceed to the next turn.\n",
    "\n",
    "### Handling Active2 Agent\n",
    "\n",
    "```python\n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "```\n",
    "\n",
    "This block is similar to the handling of `active1`, but it operates on `active2` and `inactive2`.\n",
    "\n",
    "### Returning the State\n",
    "\n",
    "```python\n",
    "    return state\n",
    "```\n",
    "\n",
    "The function returns the updated state after processing the actions and transitions for both pairs of agents.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `interpreter` function:\n",
    "\n",
    "1. Checks if the game is done and returns the state if it is.\n",
    "2. Identifies active and inactive agents in each pair.\n",
    "3. Handles end conditions and transitions between asking and guessing roles.\n",
    "4. Calls appropriate functions (`guesser_action`, `answerer_action`, `end_game`, `increment_turn`) based on the current role and status of the agents.\n",
    "5. Updates and returns the game state.\n",
    "\n",
    "This function is essential for managing the flow of the game, ensuring that each agent takes the correct action based on its role, and handling various end conditions appropriately.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# インタープリタ\n",
    "\n",
    "### `interpreter`関数の目的\n",
    "\n",
    "`interpreter`関数は、2対のエージェントのゲームの状態とアクションを管理します。各ペアはアクティブエージェントと非アクティブエージェントから構成されており、一方のエージェントが質問をし（「質問者」）、もう一方が推測を行います（「推測者」）。関数はゲームの状態を更新し、各エージェントが取るべきアクションを決定し、遷移と終了条件を処理します。\n",
    "\n",
    "### コードの説明\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "```\n",
    "\n",
    "この行は、環境（ゲーム）が完了しているかどうかをチェックします。完了している場合、関数は現在の状態を変更せずに返します。\n",
    "\n",
    "### アクティブおよび非アクティブエージェントの分離\n",
    "\n",
    "```python\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "```\n",
    "\n",
    "これらの行は、各ペアのアクティブエージェントと非アクティブエージェントを特定します。`state[0]`と`state[1]`は最初のペアのエージェントで、`state[2]`と`state[3]`は2番目のペアです。\n",
    "\n",
    "### 完了ステータスの処理\n",
    "\n",
    "```python\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "```\n",
    "\n",
    "これらの行は、ペアの両方のエージェントが完了した場合、エージェントを`None`に設定します。すべてのエージェントが完了している場合、関数は現在の状態を返して終了します。\n",
    "\n",
    "### ステップと終了条件の処理\n",
    "\n",
    "```python\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "```\n",
    "\n",
    "- `step`はゲームの現在のステップを保存します。\n",
    "- `end_early`は、いずれかのアクティブエージェントが`TIMEOUT`または`ERROR`のステータスを持っているかどうかをチェックして、早期終了条件を判定します。\n",
    "- `either_guessed`は、いずれかのエージェントがキーワードを正しく推測したかを追跡するためのフラグです。\n",
    "\n",
    "### Active1エージェントの処理\n",
    "\n",
    "```python\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "```\n",
    "\n",
    "- `active1`が`None`でない場合、エージェントの役割をチェックします。\n",
    "- `active1`が推測者であれば、`guesser_action`を呼び出します。\n",
    "- `active1`が回答者であれば、`answerer_action`を呼び出します。\n",
    "- `active1`のステータスが`TIMEOUT`または`ERROR`の場合、`end_game`を呼び出します。\n",
    "- `end_early`が真であれば、ゲームを終了します。\n",
    "- それ以外の場合、次のターンに進むために`increment_turn`を呼び出します。\n",
    "\n",
    "### Active2エージェントの処理\n",
    "\n",
    "```python\n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "```\n",
    "\n",
    "このブロックは、`active1`の処理と似ていますが、`active2`および`inactive2`に対して操作します。\n",
    "\n",
    "### 状態の返却\n",
    "\n",
    "```python\n",
    "    return state\n",
    "```\n",
    "\n",
    "関数は、両ペアのエージェントのアクションと遷移を処理した後の更新された状態を返します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "`interpreter`関数は：\n",
    "\n",
    "1. ゲームが完了しているかをチェックし、完了している場合は状態を返す。\n",
    "2. 各ペアのアクティブおよび非アクティブエージェントを特定する。\n",
    "3. 終了条件を処理し、質問と推測の役割を交替させる。\n",
    "4. エージェントの役割とステータスに基づいて適切な関数を呼び出す（`guesser_action`、`answerer_action`、`end_game`、`increment_turn`）。\n",
    "5. ゲームの状態を更新して返却する。\n",
    "\n",
    "この関数は、ゲームの流れを管理し、各エージェントが適切なアクションを取れるようにし、さまざまな終了条件を適切に処理するために重要です。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d83432",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "    # Isolate the active and inactive agents.\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "    \n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "    \n",
    "    return state\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "    # アクティブおよび非アクティブエージェントを分離します。\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "    \n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "    \n",
    "    return state\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.809371Z",
     "iopub.status.busy": "2024-06-01T17:52:53.808999Z",
     "iopub.status.idle": "2024-06-01T17:52:53.825443Z",
     "shell.execute_reply": "2024-06-01T17:52:53.824102Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.809341Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "    # アクティブおよび非アクティブエージェントを分離します。\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "    \n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d64b7b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Renderer\n",
    "\n",
    "- **`renderer` Function**:\n",
    "  - Iterates over the game state.\n",
    "  - Prints the role, interactions, keyword, and score for each agent.\n",
    "  - Constructs a transcript for `GUESSER` agents showing their questions, answers, and guesses.\n",
    "  - Prints blank lines for readability between agents.\n",
    "\n",
    "- **Additional Code**:\n",
    "  - Constructs the path to a JSON file.\n",
    "  - Opens and loads the JSON file into a variable named `specification`.\n",
    "\n",
    "The `renderer` function helps visualize the current state of the game, making it easier to debug or understand the progress, while the additional code is for loading a game specification from a JSON file.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# レンダラー\n",
    "\n",
    "- **`renderer`関数**:\n",
    "  - ゲームの状態を反復処理します。\n",
    "  - 各エージェントの役割、相互作用、キーワード、およびスコアを出力します。\n",
    "  - `GUESSER`エージェントの質問、回答、推測を表示するトランスクリプトを構築します。\n",
    "  - エージェント間に可読性のために空行を印刷します。\n",
    "\n",
    "- **追加コード**:\n",
    "  - JSONファイルへのパスを構築します。\n",
    "  - JSONファイルを開いて、`specification`という変数にロードします。\n",
    "\n",
    "`renderer`関数は、ゲームの現在の状態を可視化するのに役立ち、デバッグや進行状況の理解を容易にします。また、追加コードはJSONファイルからゲーム仕様を読み込むためのものです。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ac98f1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def renderer(state, env):\n",
    "    for s in state:\n",
    "        print(\"role: \", s.observation.role)\n",
    "        if s.observation.role == GUESSER:\n",
    "            transcript = \"\"\n",
    "            for i in range(0, len(s.observation.guesses)):\n",
    "                transcript = \"{}Q: {} A: {}\\nG: {}\\n\".format(\n",
    "                    transcript, s.observation.questions[i],\n",
    "                    s.observation.answers[i],\n",
    "                    s.observation.guesses[i]\n",
    "                )\n",
    "            print(transcript)\n",
    "        print(\"keyword: \", s.observation.keyword)\n",
    "        print(\"score: \", s.reward)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    return \"\"\n",
    "jsonpath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.json\"))\n",
    "with open(jsonpath) as f:\n",
    "    specification = json.load(f)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def renderer(state, env):\n",
    "    for s in state:\n",
    "        print(\"役割: \", s.observation.role)\n",
    "        if s.observation.role == GUESSER:\n",
    "            transcript = \"\"\n",
    "            for i in range(0, len(s.observation.guesses)):\n",
    "                transcript = \"{}Q: {} A: {}\\nG: {}\\n\".format(\n",
    "                    transcript, s.observation.questions[i],\n",
    "                    s.observation.answers[i],\n",
    "                    s.observation.guesses[i]\n",
    "                )\n",
    "            print(transcript)\n",
    "        print(\"キーワード: \", s.observation.keyword)\n",
    "        print(\"スコア: \", s.reward)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    return \"\"\n",
    "jsonpath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.json\"))\n",
    "with open(jsonpath) as f:\n",
    "    specification = json.load(f)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.827137Z",
     "iopub.status.busy": "2024-06-01T17:52:53.826659Z",
     "iopub.status.idle": "2024-06-01T17:52:53.844687Z",
     "shell.execute_reply": "2024-06-01T17:52:53.843323Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.827107Z"
    }
   },
   "outputs": [],
   "source": [
    "def renderer(state, env):\n",
    "    for s in state:\n",
    "        print(\"役割: \", s.observation.role)\n",
    "        if s.observation.role == GUESSER:\n",
    "            transcript = \"\"\n",
    "            for i in range(0, len(s.observation.guesses)):\n",
    "                transcript = \"{}Q: {} A: {}\\nG: {}\\n\".format(\n",
    "                    transcript, s.observation.questions[i],\n",
    "                    s.observation.answers[i],\n",
    "                    s.observation.guesses[i]\n",
    "                )\n",
    "            print(transcript)\n",
    "        print(\"キーワード: \", s.observation.keyword)\n",
    "        print(\"スコア: \", s.reward)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    return \"\"\n",
    "jsonpath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.json\"))\n",
    "with open(jsonpath) as f:\n",
    "    specification = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b368b0b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### `html_renderer` Function\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Construct JavaScript Path**:\n",
    "    ```python\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    ```\n",
    "    - Uses `path.abspath` to get the absolute path to the `llm_20_questions.js` file.\n",
    "    - Uses `path.join` to concatenate the directory of the current file (`__file__`) with `llm_20_questions.js`.\n",
    "\n",
    "2. **Open and Read JavaScript File**:\n",
    "    ```python\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "    ```\n",
    "    - Opens the JavaScript file located at the path `jspath`.\n",
    "    - Reads the entire content of the file using `f.read()`.\n",
    "    - Returns the content as a string.\n",
    "\n",
    "This function reads a JavaScript file named `llm_20_questions.js` and returns its content as a string. This can be useful for embedding JavaScript into an HTML page dynamically.\n",
    "\n",
    "### `keyword_guessed` Function\n",
    "\n",
    "```python\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Define `normalize` Function**:\n",
    "    ```python\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    ```\n",
    "    - `normalize` is a helper function to standardize strings for comparison.\n",
    "    - Removes all punctuation from the string using `str.maketrans`.\n",
    "    - Converts the string to lowercase with `s.lower()`.\n",
    "    - Removes occurrences of \"the\" and spaces by replacing them with an empty string.\n",
    "    - Uses `translate(t)` to remove punctuation.\n",
    "\n",
    "2. **Check If Guess Matches Keyword**:\n",
    "    ```python\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    ```\n",
    "    - Normalizes both `guess` and `keyword`.\n",
    "    - Compares the normalized strings.\n",
    "    - If they match, returns `True`.\n",
    "\n",
    "3. **Check If Guess Matches Any Alternate Keywords**:\n",
    "    ```python\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    ```\n",
    "    - Iterates over each alternate keyword in `alts`.\n",
    "    - Normalizes and compares each alternate keyword with the normalized `guess`.\n",
    "    - If any match, returns `True`.\n",
    "\n",
    "4. **Return False If No Match**:\n",
    "    ```python\n",
    "    return False\n",
    "    ```\n",
    "    - If neither the keyword nor any alternates match the guess, returns `False`.\n",
    "\n",
    "The `keyword_guessed` function checks if a given guess matches the target keyword or any of its alternate keywords. It uses the `normalize` function to standardize the strings by removing punctuation, converting to lowercase, and removing spaces and the word \"the\". This ensures that the comparison is case-insensitive and ignores common variations like punctuation and extra spaces.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### `html_renderer`関数\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **JavaScriptパスの構築**:\n",
    "    ```python\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    ```\n",
    "    - `path.abspath`を使用して`llm_20_questions.js`ファイルへの絶対パスを取得します。\n",
    "    - `path.join`を使用して、現在のファイルのディレクトリ（`__file__`）を`llm_20_questions.js`と結合します。\n",
    "\n",
    "2. **JavaScriptファイルを開いて読み取る**:\n",
    "    ```python\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "    ```\n",
    "    - `jspath`で指定された場所にあるJavaScriptファイルを開きます。\n",
    "    - `f.read()`を使用してファイルの全内容を読み取り、文字列として返します。\n",
    "\n",
    "この関数は、`llm_20_questions.js`という名前のJavaScriptファイルを読み込み、その内容を文字列として返します。これは、HTMLページにJavaScriptを動的に埋め込むのに便利です。\n",
    "\n",
    "### `keyword_guessed`関数\n",
    "\n",
    "```python\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **`normalize`関数の定義**:\n",
    "    ```python\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    ```\n",
    "    - `normalize`は、比較用に文字列を標準化するための補助関数です。\n",
    "    - 文字列からすべての句読点を削除します（`str.maketrans`を使用）。\n",
    "    - 文字列を小文字に変換します（`s.lower()`）。\n",
    "    - 「the」とスペースを削除します（空文字列に置き換え）。\n",
    "    - `translate(t)`を使用して、句読点を削除します。\n",
    "\n",
    "2. **推測がキーワードと一致するか確認**:\n",
    "    ```python\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    ```\n",
    "    - `guess`と`keyword`の両方を正規化します。\n",
    "    - 正規化された文字列を比較します。\n",
    "    - 一致する場合は、`True`を返します。\n",
    "\n",
    "3. **推測が代替キーワードのいずれかと一致するか確認**:\n",
    "    ```python\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    ```\n",
    "    - `alts`の各代替キーワードを反復処理します。\n",
    "    - 各代替キーワードを正規化し、`guess`と比較します。\n",
    "    - 一致する場合があれば、`True`を返します。\n",
    "\n",
    "4. **一致がない場合は`False`を返す**:\n",
    "    ```python\n",
    "    return False\n",
    "    ```\n",
    "    - キーワードやその代替が推測と一致しない場合は、`False`を返します。\n",
    "\n",
    "`keyword_guessed`関数は、与えられた推測がターゲットキーワードまたはその代替キーワードと一致するか確認します。`normalize`関数を使用して、句読点を削除し、大文字小文字を無視し、一般的なバリエーションを無視した上で比較を行います。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341f0e7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "      t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "      return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "      return True\n",
    "    for s in alts:\n",
    "      if normalize(s) == normalize(guess):\n",
    "        return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "      t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "      return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "      return True\n",
    "    for s in alts:\n",
    "      if normalize(s) == normalize(guess):\n",
    "        return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.847051Z",
     "iopub.status.busy": "2024-06-01T17:52:53.846554Z",
     "iopub.status.idle": "2024-06-01T17:52:53.855991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.854737Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.847018Z"
    }
   },
   "outputs": [],
   "source": [
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "      t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "      return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "      return True\n",
    "    for s in alts:\n",
    "      if normalize(s) == normalize(guess):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b48b30",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### `call_llm` Function\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    \n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Global Variables**:\n",
    "    ```python\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    ```\n",
    "    - Declares the use of global variables: `model_initialized`, `device`, `model`, and `tokenizer`.\n",
    "\n",
    "2. **Check Model Initialization**:\n",
    "    ```python\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "    ```\n",
    "    - Checks if the model has already been initialized.\n",
    "    - If not, it checks if the directory `llm_parent_dir` exists and contains files.\n",
    "\n",
    "3. **Load Model and Tokenizer**:\n",
    "    ```python\n",
    "    dirs = os.listdir(llm_parent_dir)\n",
    "    llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "    model_initialized = True\n",
    "    ```\n",
    "    - Lists the directories inside `llm_parent_dir`.\n",
    "    - Constructs the path to the model directory.\n",
    "    - Sets the device to GPU if available, otherwise uses CPU.\n",
    "    - Loads the T5 model and tokenizer from the specified directory and moves the model to the selected device.\n",
    "    - Sets `model_initialized` to `True` to avoid re-initialization in subsequent calls.\n",
    "\n",
    "4. **Handle Missing Model Directory**:\n",
    "    ```python\n",
    "    else:\n",
    "        print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "        print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "        raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    ```\n",
    "    - If the model directory does not exist or is empty, prints an error message and raises an exception.\n",
    "\n",
    "5. **Prepare Inputs for Model**:\n",
    "    ```python\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    ```\n",
    "    - Tokenizes the input `prompt` and converts it to PyTorch tensors.\n",
    "    - Moves the tensors to the selected device (CPU or GPU).\n",
    "\n",
    "6. **Generate Outputs**:\n",
    "    ```python\n",
    "    outputs = model.generate(**inputs)\n",
    "    ```\n",
    "    - Uses the model to generate outputs from the tokenized inputs.\n",
    "\n",
    "7. **Decode Outputs**:\n",
    "    ```python\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "    ```\n",
    "    - Decodes the generated outputs back into text, skipping special tokens.\n",
    "    - Returns the first element of the decoded outputs as the final answer.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `call_llm` function is responsible for interacting with a pre-trained T5 model for generating responses based on a given prompt. It ensures that the model and tokenizer are loaded and initialized only once. If the model is not initialized, it loads the model and tokenizer from the specified directory, sets up the device (CPU/GPU), and marks the model as initialized. Then, it tokenizes the input prompt, generates a response using the model, decodes the response, and returns it as a string. If the model files are not found, it raises an exception and provides instructions for adding the required model files.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### `call_llm`関数\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    \n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。大きなモデルのいずれかを追加してください。\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "#### 説明\n",
    "\n",
    "1. **グローバル変数**:\n",
    "    ```python\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    ```\n",
    "    - `model_initialized`、`device`、`model`、`tokenizer`のグローバル変数を宣言します。\n",
    "\n",
    "2. **モデルの初期化チェック**:\n",
    "    ```python\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "    ```\n",
    "    - モデルが既に初期化されているかをチェックします。\n",
    "    - 初期化されていない場合、`llm_parent_dir`が存在し、ファイルが含まれているかを確認します。\n",
    "\n",
    "3. **モデルとトークナイザーの読み込み**:\n",
    "    ```python\n",
    "    dirs = os.listdir(llm_parent_dir)\n",
    "    llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "    model_initialized = True\n",
    "    ```\n",
    "    - `llm_parent_dir`内のディレクトリをリストします。\n",
    "    - モデルディレクトリへのパスを構築します。\n",
    "    - GPUが使用可能であれば`cuda:0`を設定し、無ければCPUを使用します。\n",
    "    - 指定されたディレクトリからT5モデルとトークナイザーを読み込み、モデルを選択したデバイスに移動します。\n",
    "    - `model_initialized`を`True`に設定して、以降の初期化を避けます。\n",
    "\n",
    "4. **モデルディレクトリの欠如処理**:\n",
    "    ```python\n",
    "    else:\n",
    "        print(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。大きなモデルのいずれかを追加してください。\")\n",
    "        print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "        raise Exception(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。\")\n",
    "    ```\n",
    "    - モデルディレクトリが存在しない場合、エラーメッセージを表示し、例外を発生させます。\n",
    "\n",
    "5. **モデルへの入力準備**:\n",
    "    ```python\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    ```\n",
    "    - 入力`prompt`をトークナイザしてPyTorchテンソルに変換します。\n",
    "    - テンソルを選択したデバイス（CPUまたはGPU）に移動します。\n",
    "\n",
    "6. **出力の生成**:\n",
    "    ```python\n",
    "    outputs = model.generate(**inputs)\n",
    "    ```\n",
    "    - モデルを使用してトークン化された入力から出力を生成します。\n",
    "\n",
    "7. **出力のデコード**:\n",
    "    ```python\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "    ```\n",
    "    - 生成された出力をテキストにデコードし、特別なトークンをスキップします。\n",
    "    - デコードされた出力の最初の要素を最終的な回答として返します。\n",
    "\n",
    "### まとめ\n",
    "\n",
    "`call_llm`関数は、与えられたプロンプトに基づいて反応を生成するために事前学習済みのT5モデルとのインタラクションを担当します。この関数は、モデルとトークナイザーが一度だけ読み込まれて初期化されることを保証します。モデルが初期化されていない場合、有効なディレクトリからモデルとトークナイザーを読み込み、デバイス（CPU/GPU）を設定し、モデルを初期化済みとしてマークします。その後、入力プロンプトをトークナイズし、モデルを使用して応答を生成し、出力をデコードして文字列として返します。モデルファイルが見つからない場合、例外を発生させ、必要なモデルファイルを追加する手順を提供します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f58c5d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(prompt)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。大きなモデルのいずれかを追加してください。\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(prompt)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.859146Z",
     "iopub.status.busy": "2024-06-01T17:52:53.858345Z",
     "iopub.status.idle": "2024-06-01T17:52:53.867991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.866918Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.859113Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。大きなモデルのいずれかを追加してください。\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"デフォルトエージェントを使用するにはt5-flanモデルが必要です。\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(prompt)\n",
    "    return answer[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202e03e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Run/Debug\n",
    "\n",
    "*References:* \n",
    "1. [test_llm_20_questions.py](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/llm_20_questions/test_llm_20_questions.py)\n",
    "2. [Run/Debug LLM 20 Questions in a Notebook](https://www.kaggle.com/code/rturley/run-debug-llm-20-questions-in-a-notebook)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 実行/デバッグ\n",
    "\n",
    "*参考文献:* \n",
    "1. [test_llm_20_questions.py](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/llm_20_questions/test_llm_20_questions.py)\n",
    "2. [ノートブックでのLLM 20の質問の実行/デバッグ](https://www.kaggle.com/code/rturley/run-debug-llm-20-questions-in-a-notebook)\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145e59",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from kaggle_environments import make\n",
    "def custom_questioner(obs):\n",
    "    if obs.turnType == \"guess\":\n",
    "        return \"banana\"\n",
    "    return \"Is it a banana?\"\n",
    "def custom_answerer():\n",
    "    return \"no\"\n",
    "def bad_answerer():\n",
    "    return \"maybe?\"\n",
    "def error_agent():\n",
    "    raise ValueError\n",
    "def test_llm_20_q_completes():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    game_output = env.run([guesser_agent, answerer_agent, guesser_agent, answerer_agent])\n",
    "    json = env.toJSON()\n",
    "    env.render(mode=\"ipython\", width=400, height=400)\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"DONE\"]\n",
    "def test_llm_20_q_errors_on_bad_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, bad_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, error_agent])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_question():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, error_agent, custom_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, None, 1]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"ERROR\", \"DONE\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 2\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from kaggle_environments import make\n",
    "def custom_questioner(obs):\n",
    "    if obs.turnType == \"guess\":\n",
    "        return \"バナナ\"\n",
    "    return \"それはバナナですか？\"\n",
    "def custom_answerer():\n",
    "    return \"いいえ\"\n",
    "def bad_answerer():\n",
    "    return \"かもしれない？\"\n",
    "def error_agent():\n",
    "    raise ValueError\n",
    "def test_llm_20_q_completes():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    game_output = env.run([guesser_agent, answerer_agent, guesser_agent, answerer_agent])\n",
    "    json = env.toJSON()\n",
    "    env.render(mode=\"ipython\", width=400, height=400)\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"DONE\"]\n",
    "def test_llm_20_q_errors_on_bad_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, bad_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, error_agent])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_question():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, error_agent, custom_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, None, 1]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"ERROR\", \"DONE\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 2\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.86985Z",
     "iopub.status.busy": "2024-06-01T17:52:53.869355Z",
     "iopub.status.idle": "2024-06-01T17:52:53.887698Z",
     "shell.execute_reply": "2024-06-01T17:52:53.886572Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.869817Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "def custom_questioner(obs):\n",
    "    if obs.turnType == \"guess\":\n",
    "        return \"バナナ\"\n",
    "    return \"それはバナナですか？\"\n",
    "def custom_answerer():\n",
    "    return \"いいえ\"\n",
    "def bad_answerer():\n",
    "    return \"かもしれない？\"\n",
    "def error_agent():\n",
    "    raise ValueError\n",
    "def test_llm_20_q_completes():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    game_output = env.run([guesser_agent, answerer_agent, guesser_agent, answerer_agent])\n",
    "    json = env.toJSON()\n",
    "    env.render(mode=\"ipython\", width=400, height=400)\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"DONE\"]\n",
    "def test_llm_20_q_errors_on_bad_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, bad_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, error_agent])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_question():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, error_agent, custom_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, None, 1]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"ERROR\", \"DONE\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bbe5d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_llm_20_q_completes()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_llm_20_q_completes()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.889738Z",
     "iopub.status.busy": "2024-06-01T17:52:53.889163Z",
     "iopub.status.idle": "2024-06-01T17:55:15.400121Z",
     "shell.execute_reply": "2024-06-01T17:55:15.398007Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.889705Z"
    }
   },
   "outputs": [],
   "source": [
    "test_llm_20_q_completes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.889738Z",
     "iopub.status.busy": "2024-06-01T17:52:53.889163Z",
     "iopub.status.idle": "2024-06-01T17:55:15.400121Z",
     "shell.execute_reply": "2024-06-01T17:55:15.398007Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.889705Z"
    }
   },
   "outputs": [],
   "source": [
    "test_llm_20_q_completes()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 3047,
     "sourceId": 4261,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
