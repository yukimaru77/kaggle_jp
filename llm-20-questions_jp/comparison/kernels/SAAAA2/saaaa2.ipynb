{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9d58c2",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LLM 20 Questions」コンペティションにおいて、言語モデルを用いた「20の質問」ゲームをプレイするためのエージェントの作成に取り組んでいます。具体的には、以下の手法やライブラリを使用して問題を解決しています。\n",
    "\n",
    "### 取り組む問題\n",
    "ノートブックでは、特定のキーワード（国や物の名前など）を推測するゲームを自動化するAIエージェントを開発しています。エージェントは、質問を生成したり、はい・いいえの質問に対する回答を生成したり、最終的にキーワードを推測する役割を担います。\n",
    "\n",
    "### 使用しているライブラリ\n",
    "- **Transformers**: Hugging Faceのライブラリを使用して、事前訓練済みの言語モデル（Causal Language Model）を扱います。\n",
    "- **Torch**: PyTorchを使用して、GPUを活用しつつメモリ効率の良いモデルの操作を行います。\n",
    "- **BitsAndBytes**: モデルの量子化を行い、8ビットでの読み込みをサポートします。\n",
    "\n",
    "### 実装内容\n",
    "1. **環境の設定**: 必要なライブラリ（transformers, bitsandbytes）をインストールし、ファイルの準備を行います。\n",
    "2. **モデルの定義**: 事前訓練されたモデルを特定のGPUに配置してメモリ効率を最適化し、量子化の設定も行います。\n",
    "3. **質問および回答の生成**: ユーザーインターフェースを介して、質問と回答を生成するメソッド（asker、answerer）を持つ`Robot`クラスを実装します。\n",
    "4. **エージェントのメインロジック**: `agent`関数を通じて、推測、質問、および回答のターンを処理します。もし応答が不適切な場合はデフォルトで「yes」を返すロジックも含まれています。\n",
    "5. **キーワードの準備**: JSON形式のデータからキーワードとそのカテゴリを読み込み、データフレームに変換します。\n",
    "6. **ゲームの実行**: 20ラウンドにわたり、エージェントが質問を生成し、回答を受け取って推測を行う様子をシミュレーションします。\n",
    "\n",
    "このノートブックを通じて、特定のキーワードを推測するためのAIエージェントが、生成的な質問を通じて効率的に情報を引き出すことができるプロセスを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd28209",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、初心者がつまずきそうな専門用語について簡単に解説します。対象は、ノートブックの内容に関連する可能性があるマイナーな用語や、実務経験がないと馴染みが薄い用語です。\n",
    "\n",
    "1. **メモリ効率的なSDP (Mem Efficient SDP)**:\n",
    "   - SDP（Stochastic Dynamic Programming）は、強化学習などで使用される手法ですが、メモリ効率的なSDPは、特に大規模なモデルを扱う際にメモリ使用量を削減する手法です。これにより、より少ないリソースでモデルの学習や推論を実施できます。\n",
    "\n",
    "2. **BitsAndBytesConfig**:\n",
    "   - このクラスは、モデルの量子化（特に8ビット量子化など）を設定するためのものです。量子化は、モデルのサイズを縮小し、計算を高速化するために重みを圧縮する手法です。\n",
    "\n",
    "3. **Gradient Checkpointing (勾配チェックポイント)**:\n",
    "   - 大規模モデルの訓練でメモリを節約するためのテクニックです。全ての中間出力を保存するのではなく、効率的に再計算することでメモリを削減します。これにより、より大きなバッチサイズやより深いネットワークを扱うことが可能になります。\n",
    "\n",
    "4. **デバイスマップ (Device Map)**:\n",
    "   - テンソルをどのGPUに配置するかを定義するためのマッピングです。特に、複数のGPUを利用する際に、各レイヤーをどのGPUに配置するかを示します。\n",
    "\n",
    "5. **トークナイザー (Tokenizer)**:\n",
    "   - テキストをモデルが理解できる形式に変換するためのコンポーネントです。単語やサブワードをトークンと呼ばれる数値に変換します。通常、自然言語処理の前処理として重要です。\n",
    "\n",
    "6. **終了トークン (End Of Sentence Token, EOS)**:\n",
    "   - 生成されたテキストの文の終わりを示すために使用される特別なトークンです。生成モデルが出力を停止するタイミングを決定するのに用いられます。\n",
    "\n",
    "7. **観察オブジェクト (Observation Object)**:\n",
    "   - 現在のゲームの状態やターンセッティングなど、エージェントが行動を決定するために必要な情報を保持するためのクラスです。ゲームにおける状態情報を管理します。\n",
    "\n",
    "8. **代替キーワード (Alternative Keywords)**:\n",
    "   - 特定のキーワードに関連する、他の言葉やフレーズを指します。モデルが完全に同じ意味の異なる表現を理解できるようにするために用いられます。\n",
    "\n",
    "9. **ランダム選択 (Random Choice)**:\n",
    "   - プログラムがプレイヤーの質問や答える際に、あらかじめ設定した選択肢から無作為に選ぶ手法です。これは、自然かつ多様なインタラクションを生むために使われます。\n",
    "\n",
    "これらの用語は、ノートブックの内容を理解する際に初学者が直面しやすい概念でもありますので、あらかじめ知識を持っておくと良いでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58912689",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "mkdir -p /kaggle/working/submission\n",
    "pip install bitsandbytes accelerate\n",
    "pip install -U transformers\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "mkdir -p /kaggle/working/submission\n",
    "pip install bitsandbytes accelerate\n",
    "pip install -U transformers\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:04.588943Z",
     "iopub.status.busy": "2024-07-10T07:36:04.588675Z",
     "iopub.status.idle": "2024-07-10T07:36:44.507357Z",
     "shell.execute_reply": "2024-07-10T07:36:44.506539Z",
     "shell.execute_reply.started": "2024-07-10T07:36:04.588918Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p /kaggle/working/submission\n",
    "pip install bitsandbytes accelerate\n",
    "pip install -U transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fae215",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%writefile -a submission/main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    model_id = os.path.join(KAGGLE_AGENT_PATH, \"model\")\n",
    "#else:\n",
    "model_id = \"/kaggle/input/gemma/transformers/7b-it/3\"\n",
    "\n",
    "device_maps = [('model.layers.0', 0),\n",
    " ('model.layers.1', 0),\n",
    " ('model.layers.2', 0),\n",
    " ('model.layers.3', 0),\n",
    " ('model.layers.4', 0),\n",
    " ('model.layers.5', 0),\n",
    " ('model.layers.6', 0),\n",
    " ('model.layers.7', 0),\n",
    " ('model.layers.8', 0),\n",
    " ('model.layers.9', 0),\n",
    " ('model.layers.10', 0),\n",
    " ('model.layers.11', 0),\n",
    " ('model.layers.12', 0),\n",
    " ('model.layers.13', 0),\n",
    " ('model.layers.14', 0),\n",
    " ('model.layers.15', 0),\n",
    " ('model.layers.16', 0),\n",
    " ('model.layers.17', 0),\n",
    " ('model.layers.18', 0),\n",
    " ('model.layers.19', 1),\n",
    " ('model.layers.20', 1),\n",
    " ('model.layers.21', 1),\n",
    " ('model.layers.22', 1),\n",
    " ('model.layers.23', 1),\n",
    " ('model.layers.24', 1),\n",
    " ('model.layers.25', 1),\n",
    " ('model.layers.26', 1),\n",
    " ('model.layers.27', 1),\n",
    " ('model.layers.28', 1),\n",
    " ('model.layers.29', 1),\n",
    " ('model.layers.30', 1),\n",
    " ('model.layers.31', 1),\n",
    " ('model.layers.32', 1),\n",
    " ('model.layers.33', 1),\n",
    " ('model.layers.34', 1),\n",
    " ('model.layers.35', 1),\n",
    " ('model.layers.36', 1),\n",
    " ('model.layers.37', 1),\n",
    " ('model.layers.38', 1),\n",
    " ('model.layers.39', 1),\n",
    " ('model.layers.40', 1),\n",
    " ('model.layers.41', 1),\n",
    " ('model.embed_tokens', 1),\n",
    " ('model.layers', 1)]\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\") \n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<eos>\"])[0]\n",
    "\n",
    "device = {layer:gpu_mem for (layer,gpu_mem) in device_maps}\n",
    "config = AutoConfig.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "config.gradient_checkpointing = True\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\", torch_dtype=\"auto\", quantization_config=quantization_config,\n",
    "                                             device_map=\"auto\", trust_remote_code=True, config=config)\n",
    "\n",
    "def generate_answer(template):\n",
    "    input_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_ids = model.generate(**input_ids, max_new_tokens=15).squeeze()\n",
    "    start_gen = input_ids.input_ids.shape[1]\n",
    "    output_ids = output_ids[start_gen:]\n",
    "    if id_eot in output_ids:\n",
    "        stop = output_ids.tolist().index(id_eot)\n",
    "        output = tokenizer.decode(output_ids[:stop])\n",
    "    else:\n",
    "        output = tokenizer.decode(output_ids)\n",
    "    output = re.sub('\\n', '', output)\n",
    "    output = re.sub(' <end_of_turn>', '', output)\n",
    "    output = re.sub('<end_of_turn>', '', output)\n",
    "    return output\n",
    "\n",
    "class Robot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on(self, mode, obs):\n",
    "        assert mode in [\"asking\", \"guessing\", \"answering\"], \"mode can only take one of these values: asking, answering, guessing\"\n",
    "        if mode == \"asking\":\n",
    "            output = self.asker(obs)\n",
    "        if mode == \"answering\":\n",
    "            output = self.answerer(obs)\n",
    "            if \"yes\" in output.lower() or \"Yes\" in output.lower():\n",
    "                output = \"yes\"\n",
    "            elif \"no\" in output.lower() or \"No\" in output.lower():\n",
    "                output = \"no\"\n",
    "            else:\n",
    "                output = \"yes\"\n",
    "        if mode == \"guessing\":\n",
    "            output = self.asker(obs)\n",
    "        return output\n",
    "\n",
    "    def asker(self, obs):\n",
    "        sys_prompt = \"\"\"\n",
    "        You are an AI assistant designed to play the 20 Questions game. \n",
    "        In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner.\n",
    "        The keyword is a specific country.\n",
    "        \"\"\"\n",
    "        if obs.turnType ==\"ask\":\n",
    "            ask_prompt = sys_prompt + \"\"\"\n",
    "            Let's play 20 Questions. You are playing the role of the Questioner.\n",
    "            Please ask a yes-or-no question.\n",
    "            to help you, here's an example of how it should work assuming that the keyword is Morocco:\n",
    "            examle:\n",
    "            <you: is it a contry?\n",
    "            user: yes\n",
    "            you: is it in europe?\n",
    "            user: no\n",
    "            you: is it in africa?\n",
    "            user: yes\n",
    "            you: do most people living there have dark skin?\n",
    "            user: no\n",
    "            you: is it a country name starting by m ?\n",
    "            user: yes\n",
    "            you: is it Morocco?\n",
    "            user: yes.>\n",
    "            the user has chosen the word, ask your first question!\n",
    "            please be short and not verbose, give only one question, no extra word!\n",
    "            \"\"\"\n",
    "        \n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{ask_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "            if len(obs.questions)>=1:\n",
    "                    for q, a in zip(obs.questions, obs.answers):\n",
    "                        chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                        chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "                    \n",
    "        elif obs.turnType == \"guess\":\n",
    "                conv = \"\"\n",
    "                for q, a in zip(obs.questions, obs.answers):\n",
    "                    conv += f\"\"\"Question: {q}\\nAnswer: {a}\\n\"\"\"\n",
    "                guess_prompt =  sys_prompt + f\"\"\"\n",
    "                so far, the current state of the game is as following:\\n{conv}\n",
    "                based on the conversation, can you guess the word, please give only the word, no verbosity around\n",
    "                \"\"\"\n",
    "                chat_template = f\"\"\"<start_of_turn>system\\n{guess_prompt}<end_of_turn>\\n\"\"\"\n",
    "                chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "        output = generate_answer(chat_template)        \n",
    "        return output\n",
    "    \n",
    "    def answerer(self, obs):\n",
    "        sys_prompt = f\"\"\"\n",
    "        You are an AI assistant designed to play the 20 Questions game. \n",
    "        In this game, the Answerer thinks of a keyword and responds to yes-or-no questions by the Questioner.\n",
    "        The keyword is a specific place, or thing.\\n\n",
    "        so make sure you understand the user's question and you understand the keyword you're playig on.\n",
    "        for now the word that the user should guess is: \"{obs.keyword}\", it is of category \"{obs.category}\",\n",
    "        to help you, here's an example of how it should work assuming that the keyword is Morocco in the category \"place\":\n",
    "        examle:\n",
    "        <user: is it a place?\n",
    "        you: yes\n",
    "        user: is it in europe?\n",
    "        you: no\n",
    "        user: is it in africa?\n",
    "        you: yes\n",
    "        user: do most people living there have dark skin?\n",
    "        you: no\n",
    "        user: is it a country name starting by m ?\n",
    "        you: yes\n",
    "        user: is it Morocco?\n",
    "        you: yes.>\n",
    "        \"\"\"\n",
    "        chat_template = f\"\"\"<start_of_turn>system\\n{sys_prompt}<end_of_turn>\\n\"\"\"\n",
    "        chat_template += \"<start_of_turn>user\\n\"\n",
    "        chat_template += f\"{obs.questions[0]}\"\n",
    "        chat_template += \"<start_of_turn>model\\n\"\n",
    "        if len(obs.answers)>=1:\n",
    "            for q, a in zip(obs.questions[1:], obs.answers):\n",
    "                chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        output = generate_answer(chat_template)\n",
    "        return output\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "def agent(obs, cfg):\n",
    "    \n",
    "    if obs.turnType ==\"ask\":\n",
    "        response = robot.on(mode = \"asking\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType ==\"guess\":\n",
    "        response = robot.on(mode = \"guessing\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType ==\"answer\":\n",
    "        response = robot.on(mode = \"answering\", obs = obs)\n",
    "        \n",
    "    if response == None or len(response)<=1:\n",
    "        response = \"yes\"\n",
    "        \n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%writefile -a submission/main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    model_id = os.path.join(KAGGLE_AGENT_PATH, \"model\")\n",
    "#else:\n",
    "model_id = \"/kaggle/input/gemma/transformers/7b-it/3\"\n",
    "\n",
    "# 各レイヤーをどのGPUに配置するかを示すマッピング\n",
    "device_maps = [('model.layers.0', 0),\n",
    " ('model.layers.1', 0),\n",
    " ('model.layers.2', 0),\n",
    " ('model.layers.3', 0),\n",
    " ('model.layers.4', 0),\n",
    " ('model.layers.5', 0),\n",
    " ('model.layers.6', 0),\n",
    " ('model.layers.7', 0),\n",
    " ('model.layers.8', 0),\n",
    " ('model.layers.9', 0),\n",
    " ('model.layers.10', 0),\n",
    " ('model.layers.11', 0),\n",
    " ('model.layers.12', 0),\n",
    " ('model.layers.13', 0),\n",
    " ('model.layers.14', 0),\n",
    " ('model.layers.15', 0),\n",
    " ('model.layers.16', 0),\n",
    " ('model.layers.17', 0),\n",
    " ('model.layers.18', 0),\n",
    " ('model.layers.19', 1),\n",
    " ('model.layers.20', 1),\n",
    " ('model.layers.21', 1),\n",
    " ('model.layers.22', 1),\n",
    " ('model.layers.23', 1),\n",
    " ('model.layers.24', 1),\n",
    " ('model.layers.25', 1),\n",
    " ('model.layers.26', 1),\n",
    " ('model.layers.27', 1),\n",
    " ('model.layers.28', 1),\n",
    " ('model.layers.29', 1),\n",
    " ('model.layers.30', 1),\n",
    " ('model.layers.31', 1),\n",
    " ('model.layers.32', 1),\n",
    " ('model.layers.33', 1),\n",
    " ('model.layers.34', 1),\n",
    " ('model.layers.35', 1),\n",
    " ('model.layers.36', 1),\n",
    " ('model.layers.37', 1),\n",
    " ('model.layers.38', 1),\n",
    " ('model.layers.39', 1),\n",
    " ('model.layers.40', 1),\n",
    " ('model.layers.41', 1),\n",
    " ('model.embed_tokens', 1),\n",
    " ('model.layers', 1)]\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\") \n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<eos>\"])[0]\n",
    "\n",
    "# 各レイヤーを配置するGPUを辞書形式で定義\n",
    "device = {layer:gpu_mem for (layer,gpu_mem) in device_maps}\n",
    "config = AutoConfig.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "config.gradient_checkpointing = True\n",
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\", torch_dtype=\"auto\", quantization_config=quantization_config,\n",
    "                                             device_map=\"auto\", trust_remote_code=True, config=config)\n",
    "\n",
    "# 回答を生成する関数\n",
    "def generate_answer(template):\n",
    "    input_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_ids = model.generate(**input_ids, max_new_tokens=15).squeeze()\n",
    "    start_gen = input_ids.input_ids.shape[1]\n",
    "    output_ids = output_ids[start_gen:]\n",
    "    if id_eot in output_ids:  # 出力に終了トークンが含まれているか確認\n",
    "        stop = output_ids.tolist().index(id_eot)  # 終了トークンの位置を取得\n",
    "        output = tokenizer.decode(output_ids[:stop])  # トークンをデコードして出力を取得\n",
    "    else:\n",
    "        output = tokenizer.decode(output_ids)  # トークンをそのままデコード\n",
    "    output = re.sub('\\n', '', output)  # 改行を削除\n",
    "    output = re.sub(' <end_of_turn>', '', output)  # 特定のトークンを削除\n",
    "    output = re.sub('<end_of_turn>', '', output)  # 特定のトークンを削除\n",
    "    return output\n",
    "\n",
    "class Robot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on(self, mode, obs):\n",
    "        # モードに応じた処理を実行\n",
    "        assert mode in [\"asking\", \"guessing\", \"answering\"], \"mode can only take one of these values: asking, answering, guessing\"\n",
    "        if mode == \"asking\":\n",
    "            output = self.asker(obs)\n",
    "        if mode == \"answering\":\n",
    "            output = self.answerer(obs)\n",
    "            if \"yes\" in output.lower() or \"Yes\" in output.lower():  # 出力が「yes」の場合\n",
    "                output = \"yes\"\n",
    "            elif \"no\" in output.lower() or \"No\" in output.lower():  # 出力が「no」の場合\n",
    "                output = \"no\"\n",
    "            else:\n",
    "                output = \"yes\"  # それ以外はデフォルトで「yes」\n",
    "        if mode == \"guessing\":\n",
    "            output = self.asker(obs)  # モードが「guessing」の場合\n",
    "        return output\n",
    "\n",
    "    # 質問者の処理を行うメソッド\n",
    "    def asker(self, obs):\n",
    "        sys_prompt = \"\"\"\n",
    "        あなたは、20の質問ゲームをプレイするように設計されたAIアシスタントです。\n",
    "        このゲームでは、回答者がキーワードを考え、質問者がはい・いいえの質問に答えます。\n",
    "        キーワードは特定の国です。\n",
    "        \"\"\"\n",
    "        if obs.turnType == \"ask\":  # 質問するターンの場合\n",
    "            ask_prompt = sys_prompt + \"\"\"\n",
    "            20の質問をプレイしましょう。あなたは質問者の役割を果たします。\n",
    "            はい・いいえの質問をしてください。\n",
    "            キーワードがモロッコだとしたら、以下のように進行します:\n",
    "            例:\n",
    "            <あなた: それは国ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: ヨーロッパにありますか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: アフリカにありますか？\n",
    "            ユーザー: はい\n",
    "            あなた: そこに住んでいる人のほとんどは肌の色が暗いですか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: 名前がmで始まる国ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: モロッコですか？\n",
    "            ユーザー: はい。>\n",
    "            ユーザーが単語を選びました、あなたの最初の質問をしてください！\n",
    "            短く、冗長にならず一つの質問だけをしてください、余分な言葉はいりません！\n",
    "            \"\"\"\n",
    "        \n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{ask_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "            if len(obs.questions)>=1:  # 以前の質問がある場合\n",
    "                for q, a in zip(obs.questions, obs.answers):\n",
    "                    chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                    chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        \n",
    "        elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "            conv = \"\"\n",
    "            for q, a in zip(obs.questions, obs.answers):\n",
    "                conv += f\"\"\"質問: {q}\\n答え: {a}\\n\"\"\"\n",
    "            guess_prompt =  sys_prompt + f\"\"\"\n",
    "            現在のゲームの進行状況は次のようになっています:\\n{conv}\n",
    "            この会話に基づいて、単語を推測できますか、単語だけを回答してください、余計なことはいりません。\n",
    "            \"\"\"\n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{guess_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "        output = generate_answer(chat_template)        \n",
    "        return output\n",
    "    \n",
    "    # 回答者の処理を行うメソッド\n",
    "    def answerer(self, obs):\n",
    "        sys_prompt = f\"\"\"\n",
    "        あなたは、20の質問ゲームをプレイするように設計されたAIアシスタントです。 \n",
    "        このゲームでは、回答者がキーワードを考え、質問者がはい・いいえの質問に答えます。\n",
    "        キーワードは特定の場所や物です。\\n\n",
    "        ユーザーの質問を理解し、プレイしているキーワードを把握していることを確認してください。\n",
    "        現在、ユーザーが推測すべき単語は：「{obs.keyword}」、カテゴリは「{obs.category}」です。\n",
    "        もしキーワードがモロッコでカテゴリが「場所」の場合、以下のように進行します:\n",
    "        例:\n",
    "        <ユーザー: それは場所ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: ヨーロッパにありますか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: アフリカにありますか？\n",
    "        あなた: はい\n",
    "        ユーザー: そこに住んでいる人のほとんどは肌の色が暗いですか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: 名前がmで始まる国ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: モロッコですか？\n",
    "        あなた: はい。>\n",
    "        \"\"\"\n",
    "        chat_template = f\"\"\"<start_of_turn>system\\n{sys_prompt}<end_of_turn>\\n\"\"\"\n",
    "        chat_template += \"<start_of_turn>user\\n\"\n",
    "        chat_template += f\"{obs.questions[0]}\"\n",
    "        chat_template += \"<start_of_turn>model\\n\"\n",
    "        if len(obs.answers)>=1:  # 以前の回答がある場合\n",
    "            for q, a in zip(obs.questions[1:], obs.answers):\n",
    "                chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        output = generate_answer(chat_template)\n",
    "        return output\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "# エージェントのメイン処理\n",
    "def agent(obs, cfg):\n",
    "    \n",
    "    if obs.turnType == \"ask\":  # 質問をするターンの場合\n",
    "        response = robot.on(mode = \"asking\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "        response = robot.on(mode = \"guessing\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType == \"answer\":  # 答えるターンの場合\n",
    "        response = robot.on(mode = \"answering\", obs = obs)\n",
    "        \n",
    "    if response == None or len(response)<=1:  # レスポンスが空または短い場合\n",
    "        response = \"yes\"  # デフォルトで「yes」を返す\n",
    "        \n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.509377Z",
     "iopub.status.busy": "2024-07-10T07:36:44.509069Z",
     "iopub.status.idle": "2024-07-10T07:36:44.521112Z",
     "shell.execute_reply": "2024-07-10T07:36:44.520307Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.50935Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile -a submission/main.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    model_id = os.path.join(KAGGLE_AGENT_PATH, \"model\")\n",
    "#else:\n",
    "model_id = \"/kaggle/input/gemma/transformers/7b-it/3\"\n",
    "\n",
    "# 各レイヤーをどのGPUに配置するかを示すマッピング\n",
    "device_maps = [('model.layers.0', 0),\n",
    " ('model.layers.1', 0),\n",
    " ('model.layers.2', 0),\n",
    " ('model.layers.3', 0),\n",
    " ('model.layers.4', 0),\n",
    " ('model.layers.5', 0),\n",
    " ('model.layers.6', 0),\n",
    " ('model.layers.7', 0),\n",
    " ('model.layers.8', 0),\n",
    " ('model.layers.9', 0),\n",
    " ('model.layers.10', 0),\n",
    " ('model.layers.11', 0),\n",
    " ('model.layers.12', 0),\n",
    " ('model.layers.13', 0),\n",
    " ('model.layers.14', 0),\n",
    " ('model.layers.15', 0),\n",
    " ('model.layers.16', 0),\n",
    " ('model.layers.17', 0),\n",
    " ('model.layers.18', 0),\n",
    " ('model.layers.19', 1),\n",
    " ('model.layers.20', 1),\n",
    " ('model.layers.21', 1),\n",
    " ('model.layers.22', 1),\n",
    " ('model.layers.23', 1),\n",
    " ('model.layers.24', 1),\n",
    " ('model.layers.25', 1),\n",
    " ('model.layers.26', 1),\n",
    " ('model.layers.27', 1),\n",
    " ('model.layers.28', 1),\n",
    " ('model.layers.29', 1),\n",
    " ('model.layers.30', 1),\n",
    " ('model.layers.31', 1),\n",
    " ('model.layers.32', 1),\n",
    " ('model.layers.33', 1),\n",
    " ('model.layers.34', 1),\n",
    " ('model.layers.35', 1),\n",
    " ('model.layers.36', 1),\n",
    " ('model.layers.37', 1),\n",
    " ('model.layers.38', 1),\n",
    " ('model.layers.39', 1),\n",
    " ('model.layers.40', 1),\n",
    " ('model.layers.41', 1),\n",
    " ('model.embed_tokens', 1),\n",
    " ('model.layers', 1)]\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\") \n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<eos>\"])[0]\n",
    "\n",
    "# 各レイヤーを配置するGPUを辞書形式で定義\n",
    "device = {layer:gpu_mem for (layer,gpu_mem) in device_maps}\n",
    "config = AutoConfig.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\")\n",
    "config.gradient_checkpointing = True\n",
    "# モデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/kaggle/input/gemma/transformers/7b-it/3\", torch_dtype=\"auto\", quantization_config=quantization_config,\n",
    "                                             device_map=\"auto\", trust_remote_code=True, config=config)\n",
    "\n",
    "# 回答を生成する関数\n",
    "def generate_answer(template):\n",
    "    input_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_ids = model.generate(**input_ids, max_new_tokens=15).squeeze()\n",
    "    start_gen = input_ids.input_ids.shape[1]\n",
    "    output_ids = output_ids[start_gen:]\n",
    "    if id_eot in output_ids:  # 出力に終了トークンが含まれているか確認\n",
    "        stop = output_ids.tolist().index(id_eot)  # 終了トークンの位置を取得\n",
    "        output = tokenizer.decode(output_ids[:stop])  # トークンをデコードして出力を取得\n",
    "    else:\n",
    "        output = tokenizer.decode(output_ids)  # トークンをそのままデコード\n",
    "    output = re.sub('\\n', '', output)  # 改行を削除\n",
    "    output = re.sub(' <end_of_turn>', '', output)  # 特定のトークンを削除\n",
    "    output = re.sub('<end_of_turn>', '', output)  # 特定のトークンを削除\n",
    "    return output\n",
    "\n",
    "class Robot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def on(self, mode, obs):\n",
    "        # モードに応じた処理を実行\n",
    "        assert mode in [\"asking\", \"guessing\", \"answering\"], \"mode can only take one of these values: asking, answering, guessing\"\n",
    "        if mode == \"asking\":\n",
    "            output = self.asker(obs)\n",
    "        if mode == \"answering\":\n",
    "            output = self.answerer(obs)\n",
    "            if \"yes\" in output.lower() or \"Yes\" in output.lower():  # 出力が「yes」の場合\n",
    "                output = \"yes\"\n",
    "            elif \"no\" in output.lower() or \"No\" in output.lower():  # 出力が「no」の場合\n",
    "                output = \"no\"\n",
    "            else:\n",
    "                output = \"yes\"  # それ以外はデフォルトで「yes」\n",
    "        if mode == \"guessing\":\n",
    "            output = self.asker(obs)  # モードが「guessing」の場合\n",
    "        return output\n",
    "\n",
    "    # 質問者の処理を行うメソッド\n",
    "    def asker(self, obs):\n",
    "        sys_prompt = \"\"\"\n",
    "        あなたは、20の質問ゲームをプレイするように設計されたAIアシスタントです。\n",
    "        このゲームでは、回答者がキーワードを考え、質問者がはい・いいえの質問に答えます。\n",
    "        キーワードは特定の国です。\n",
    "        \"\"\"\n",
    "        if obs.turnType == \"ask\":  # 質問するターンの場合\n",
    "            ask_prompt = sys_prompt + \"\"\"\n",
    "            20の質問をプレイしましょう。あなたは質問者の役割を果たします。\n",
    "            はい・いいえの質問をしてください。\n",
    "            キーワードがモロッコだとしたら、以下のように進行します:\n",
    "            例:\n",
    "            <あなた: それは国ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: ヨーロッパにありますか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: アフリカにありますか？\n",
    "            ユーザー: はい\n",
    "            あなた: そこに住んでいる人のほとんどは肌の色が暗いですか？\n",
    "            ユーザー: いいえ\n",
    "            あなた: 名前がmで始まる国ですか？\n",
    "            ユーザー: はい\n",
    "            あなた: モロッコですか？\n",
    "            ユーザー: はい。>\n",
    "            ユーザーが単語を選びました、あなたの最初の質問をしてください！\n",
    "            短く、冗長にならず一つの質問だけをしてください、余分な言葉はいりません！\n",
    "            \"\"\"\n",
    "        \n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{ask_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "            if len(obs.questions)>=1:  # 以前の質問がある場合\n",
    "                for q, a in zip(obs.questions, obs.answers):\n",
    "                    chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                    chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        \n",
    "        elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "            conv = \"\"\n",
    "            for q, a in zip(obs.questions, obs.answers):\n",
    "                conv += f\"\"\"質問: {q}\\n答え: {a}\\n\"\"\"\n",
    "            guess_prompt =  sys_prompt + f\"\"\"\n",
    "            現在のゲームの進行状況は次のようになっています:\\n{conv}\n",
    "            この会話に基づいて、単語を推測できますか、単語だけを回答してください、余計なことはいりません。\n",
    "            \"\"\"\n",
    "            chat_template = f\"\"\"<start_of_turn>system\\n{guess_prompt}<end_of_turn>\\n\"\"\"\n",
    "            chat_template += \"<start_of_turn>model\\n\"\n",
    "\n",
    "        output = generate_answer(chat_template)        \n",
    "        return output\n",
    "    \n",
    "    # 回答者の処理を行うメソッド\n",
    "    def answerer(self, obs):\n",
    "        sys_prompt = f\"\"\"\n",
    "        あなたは、20の質問ゲームをプレイするように設計されたAIアシスタントです。 \n",
    "        このゲームでは、回答者がキーワードを考え、質問者がはい・いいえの質問に答えます。\n",
    "        キーワードは特定の場所や物です。\\n\n",
    "        ユーザーの質問を理解し、プレイしているキーワードを把握していることを確認してください。\n",
    "        現在、ユーザーが推測すべき単語は：「{obs.keyword}」、カテゴリは「{obs.category}」です。\n",
    "        もしキーワードがモロッコでカテゴリが「場所」の場合、以下のように進行します:\n",
    "        例:\n",
    "        <ユーザー: それは場所ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: ヨーロッパにありますか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: アフリカにありますか？\n",
    "        あなた: はい\n",
    "        ユーザー: そこに住んでいる人のほとんどは肌の色が暗いですか？\n",
    "        あなた: いいえ\n",
    "        ユーザー: 名前がmで始まる国ですか？\n",
    "        あなた: はい\n",
    "        ユーザー: モロッコですか？\n",
    "        あなた: はい。>\n",
    "        \"\"\"\n",
    "        chat_template = f\"\"\"<start_of_turn>system\\n{sys_prompt}<end_of_turn>\\n\"\"\"\n",
    "        chat_template += \"<start_of_turn>user\\n\"\n",
    "        chat_template += f\"{obs.questions[0]}\"\n",
    "        chat_template += \"<start_of_turn>model\\n\"\n",
    "        if len(obs.answers)>=1:  # 以前の回答がある場合\n",
    "            for q, a in zip(obs.questions[1:], obs.answers):\n",
    "                chat_template += f\"{q}<end_of_turn>\\n<start_of_turn>user\\n\"\n",
    "                chat_template += f\"{a}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        output = generate_answer(chat_template)\n",
    "        return output\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "# エージェントのメイン処理\n",
    "def agent(obs, cfg):\n",
    "    \n",
    "    if obs.turnType == \"ask\":  # 質問をするターンの場合\n",
    "        response = robot.on(mode = \"asking\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "        response = robot.on(mode = \"guessing\", obs = obs)\n",
    "        \n",
    "    elif obs.turnType == \"answer\":  # 答えるターンの場合\n",
    "        response = robot.on(mode = \"answering\", obs = obs)\n",
    "        \n",
    "    if response == None or len(response)<=1:  # レスポンスが空または短い場合\n",
    "        response = \"yes\"  # デフォルトで「yes」を返す\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a635857",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def simple_agent1(obs, cfg):\n",
    "    # if agent is guesser and turnType is \"ask\"\n",
    "    if obs.turnType == \"ask\":\n",
    "        response_list = [\n",
    "            'Is it in Africa?',\n",
    "            'Is it in America?',\n",
    "            'Is it in Asia?',\n",
    "            'Is it in Oceania?',\n",
    "            'Is it in Eastern Europe?',\n",
    "            'Is it in Northern Europe?',\n",
    "            'Is it in Southern Europe?',\n",
    "            'Is it in Western Europe?',\n",
    "            'Is it Japan?'\n",
    "        ]\n",
    "#         response = response_list[len(obs.questions)]\n",
    "        response = random.choice(response_list)\n",
    "    elif obs.turnType == \"guess\":\n",
    "        response = \"duck\"\n",
    "    elif obs.turnType == \"answer\":\n",
    "        response = random.choices([\"yes\", \"no\"])[0]\n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def simple_agent1(obs, cfg):\n",
    "    # エージェントが推測役でターンタイプが「ask」の場合\n",
    "    if obs.turnType == \"ask\":\n",
    "        response_list = [\n",
    "            'アフリカにありますか？',\n",
    "            'アメリカにありますか？',\n",
    "            'アジアにありますか？',\n",
    "            'オセアニアにありますか？',\n",
    "            '東ヨーロッパにありますか？',\n",
    "            '北ヨーロッパにありますか？',\n",
    "            '南ヨーロッパにありますか？',\n",
    "            '西ヨーロッパにありますか？',\n",
    "            '日本ですか？'\n",
    "        ]\n",
    "#         response = response_list[len(obs.questions)]\n",
    "        response = random.choice(response_list)  # レスポンスリストからランダムに選択\n",
    "    elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "        response = \"duck\"  # 固定で「duck」を返す\n",
    "    elif obs.turnType == \"answer\":  # 答えるターンの場合\n",
    "        response = random.choices([\"yes\", \"no\"])[0]  # 「yes」または「no」をランダムに選ぶ\n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.522628Z",
     "iopub.status.busy": "2024-07-10T07:36:44.522192Z",
     "iopub.status.idle": "2024-07-10T07:36:44.539285Z",
     "shell.execute_reply": "2024-07-10T07:36:44.538167Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.522593Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_agent1(obs, cfg):\n",
    "    # エージェントが推測役でターンタイプが「ask」の場合\n",
    "    if obs.turnType == \"ask\":\n",
    "        response_list = [\n",
    "            'アフリカにありますか？',\n",
    "            'アメリカにありますか？',\n",
    "            'アジアにありますか？',\n",
    "            'オセアニアにありますか？',\n",
    "            '東ヨーロッパにありますか？',\n",
    "            '北ヨーロッパにありますか？',\n",
    "            '南ヨーロッパにありますか？',\n",
    "            '西ヨーロッパにありますか？',\n",
    "            '日本ですか？'\n",
    "        ]\n",
    "#         response = response_list[len(obs.questions)]\n",
    "        response = random.choice(response_list)  # レスポンスリストからランダムに選択\n",
    "    elif obs.turnType == \"guess\":  # 推測するターンの場合\n",
    "        response = \"duck\"  # 固定で「duck」を返す\n",
    "    elif obs.turnType == \"answer\":  # 答えるターンの場合\n",
    "        response = random.choices([\"yes\", \"no\"])[0]  # 「yes」または「no」をランダムに選ぶ\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b85767",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#!apt install pigz pv > /dev/null\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#!apt install pigz pv > /dev/null\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.54247Z",
     "iopub.status.busy": "2024-07-10T07:36:44.542048Z",
     "iopub.status.idle": "2024-07-10T07:36:44.548992Z",
     "shell.execute_reply": "2024-07-10T07:36:44.547928Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.542435Z"
    }
   },
   "outputs": [],
   "source": [
    "#!apt install pigz pv > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5381b1a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/transformers/2b-it/2 \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/transformers/2b-it/2\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.550865Z",
     "iopub.status.busy": "2024-07-10T07:36:44.550273Z",
     "iopub.status.idle": "2024-07-10T07:36:44.55715Z",
     "shell.execute_reply": "2024-07-10T07:36:44.556419Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.550839Z"
    }
   },
   "outputs": [],
   "source": [
    "#!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/transformers/2b-it/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210ad340",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#%%time\n",
    "\n",
    "#import random\n",
    "#from kaggle_environments import make\n",
    "#agent = \"/kaggle/working/submission/main.py\"\n",
    "#env = make(\"llm_20_questions\", debug=True)\n",
    "#game_output = env.run(agents=[agent, simple_agent1, simple_agent1, simple_agent1])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#%%time\n",
    "\n",
    "#import random\n",
    "#from kaggle_environments import make\n",
    "#agent = \"/kaggle/working/submission/main.py\"\n",
    "#env = make(\"llm_20_questions\", debug=True)\n",
    "#game_output = env.run(agents=[agent, simple_agent1, simple_agent1, simple_agent1])\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.558489Z",
     "iopub.status.busy": "2024-07-10T07:36:44.558199Z",
     "iopub.status.idle": "2024-07-10T07:36:44.563596Z",
     "shell.execute_reply": "2024-07-10T07:36:44.562865Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.558448Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "#import random\n",
    "#from kaggle_environments import make\n",
    "#agent = \"/kaggle/working/submission/main.py\"\n",
    "#env = make(\"llm_20_questions\", debug=True)\n",
    "#game_output = env.run(agents=[agent, simple_agent1, simple_agent1, simple_agent1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a37ec2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#env.render(mode=\"ipython\", width=600, height=500)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#env.render(mode=\"ipython\", width=600, height=500)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.565106Z",
     "iopub.status.busy": "2024-07-10T07:36:44.564745Z",
     "iopub.status.idle": "2024-07-10T07:36:44.571217Z",
     "shell.execute_reply": "2024-07-10T07:36:44.5704Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.565079Z"
    }
   },
   "outputs": [],
   "source": [
    "#env.render(mode=\"ipython\", width=600, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d435e8df",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:44.5725Z",
     "iopub.status.busy": "2024-07-10T07:36:44.572242Z",
     "iopub.status.idle": "2024-07-10T07:36:45.983895Z",
     "shell.execute_reply": "2024-07-10T07:36:45.982561Z",
     "shell.execute_reply.started": "2024-07-10T07:36:44.572478Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472cbdc9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "from submission.main import agent\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "class Observation:\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "        self.role = \"guesser\"\n",
    "        self.turnType = \"ask\"\n",
    "        self.keyword = \"Japan\"\n",
    "        self.category = \"country\"\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        self.guesses = []\n",
    "        \n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    json_data = json.loads(KEYWORDS_JSON)\n",
    "\n",
    "    keyword_list = []\n",
    "    category_list = []\n",
    "    alts_list = []\n",
    "\n",
    "    for i in range(len(json_data)):\n",
    "        for j in range(len(json_data[i]['words'])):\n",
    "            keyword = json_data[i]['words'][j]['keyword']\n",
    "            keyword_list.append(keyword)\n",
    "            category_list.append(json_data[i]['category'])\n",
    "            alts_list.append(json_data[i]['words'][j]['alts'])\n",
    "\n",
    "    data_pd = pd.DataFrame(columns=['keyword', 'category', 'alts'])\n",
    "    data_pd['keyword'] = keyword_list\n",
    "    data_pd['category'] = category_list\n",
    "    data_pd['alts'] = alts_list\n",
    "    \n",
    "    return data_pd\n",
    "    \n",
    "keywords_df = create_keyword_df(KEYWORDS_JSON)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pandas as pd\n",
    "from submission.main import agent\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "class Observation:\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "        self.role = \"guesser\"\n",
    "        self.turnType = \"ask\"\n",
    "        self.keyword = \"Japan\"\n",
    "        self.category = \"country\"\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        self.guesses = []\n",
    "        \n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    json_data = json.loads(KEYWORDS_JSON)  # JSON形式のデータを読み込み\n",
    "\n",
    "    keyword_list = []\n",
    "    category_list = []\n",
    "    alts_list = []\n",
    "\n",
    "    for i in range(len(json_data)):\n",
    "        for j in range(len(json_data[i]['words'])):\n",
    "            keyword = json_data[i]['words'][j]['keyword']\n",
    "            keyword_list.append(keyword)\n",
    "            category_list.append(json_data[i]['category'])\n",
    "            alts_list.append(json_data[i]['words'][j]['alts'])  # 代替キーワードも追加\n",
    "\n",
    "    # データフレームを作成\n",
    "    data_pd = pd.DataFrame(columns=['keyword', 'category', 'alts'])\n",
    "    data_pd['keyword'] = keyword_list  # キーワードを追加\n",
    "    data_pd['category'] = category_list  # カテゴリを追加\n",
    "    data_pd['alts'] = alts_list  # 代替キーワードを追加\n",
    "    \n",
    "    return data_pd\n",
    "    \n",
    "keywords_df = create_keyword_df(KEYWORDS_JSON)  # キーワードデータフレームを作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:36:45.987033Z",
     "iopub.status.busy": "2024-07-10T07:36:45.98602Z",
     "iopub.status.idle": "2024-07-10T07:38:44.115779Z",
     "shell.execute_reply": "2024-07-10T07:38:44.114983Z",
     "shell.execute_reply.started": "2024-07-10T07:36:45.986989Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from submission.main import agent\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "class Observation:\n",
    "    def __init__(self):\n",
    "        self.step = 0\n",
    "        self.role = \"guesser\"\n",
    "        self.turnType = \"ask\"\n",
    "        self.keyword = \"Japan\"\n",
    "        self.category = \"country\"\n",
    "        self.questions = []\n",
    "        self.answers = []\n",
    "        self.guesses = []\n",
    "        \n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    json_data = json.loads(KEYWORDS_JSON)  # JSON形式のデータを読み込み\n",
    "\n",
    "    keyword_list = []\n",
    "    category_list = []\n",
    "    alts_list = []\n",
    "\n",
    "    for i in range(len(json_data)):\n",
    "        for j in range(len(json_data[i]['words'])):\n",
    "            keyword = json_data[i]['words'][j]['keyword']\n",
    "            keyword_list.append(keyword)\n",
    "            category_list.append(json_data[i]['category'])\n",
    "            alts_list.append(json_data[i]['words'][j]['alts'])  # 代替キーワードも追加\n",
    "\n",
    "    # データフレームを作成\n",
    "    data_pd = pd.DataFrame(columns=['keyword', 'category', 'alts'])\n",
    "    data_pd['keyword'] = keyword_list  # キーワードを追加\n",
    "    data_pd['category'] = category_list  # カテゴリを追加\n",
    "    data_pd['alts'] = alts_list  # 代替キーワードを追加\n",
    "    \n",
    "    return data_pd\n",
    "    \n",
    "keywords_df = create_keyword_df(KEYWORDS_JSON)  # キーワードデータフレームを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d6e2d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "obs = Observation()\n",
    "cfg = \"_\"\n",
    "\n",
    "sample_df = keywords_df.sample()\n",
    "obs.keyword = sample_df[\"keyword\"].values[0]\n",
    "obs.category = sample_df[\"category\"].values[0]\n",
    "alts_list = sample_df[\"alts\"].values[0]\n",
    "alts_list.append(obs.keyword)\n",
    "\n",
    "print(f\"keyword:{obs.keyword}\")\n",
    "\n",
    "for round in range(20):\n",
    "    obs.step = round+1\n",
    "    \n",
    "    obs.role = \"guesser\"\n",
    "    obs.turnType = \"ask\"\n",
    "    question = agent(obs, cfg)\n",
    "    obs.questions.append(question)\n",
    "    \n",
    "    obs.role = \"answerer\"\n",
    "    obs.turnType = \"answer\"\n",
    "    answer = agent(obs, cfg)\n",
    "    obs.answers.append(answer)\n",
    "    \n",
    "    obs.role = \"guesser\"\n",
    "    obs.turnType = \"guess\"\n",
    "    guess = agent(obs, cfg)\n",
    "    obs.guesses.append(guess)\n",
    "    \n",
    "    print(f\"round: {round+1}\")\n",
    "    print(f\"question: {question}\")\n",
    "    print(f\"answer: {answer}\")\n",
    "    print(f\"guess: {guess}\")\n",
    "    \n",
    "    if guess in alts_list:\n",
    "        print(\"Win!!\")\n",
    "        break\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "obs = Observation()  # 観察オブジェクトを作成\n",
    "cfg = \"_\"\n",
    "\n",
    "sample_df = keywords_df.sample()  # キーワードデータフレームからサンプルを抽出\n",
    "obs.keyword = sample_df[\"keyword\"].values[0]  # キーワードを設定\n",
    "obs.category = sample_df[\"category\"].values[0]  # カテゴリを設定\n",
    "alts_list = sample_df[\"alts\"].values[0]  # 代替キーワードを取得\n",
    "alts_list.append(obs.keyword)  # 代替キーワードリストに選ばれたキーワードを追加\n",
    "\n",
    "print(f\"キーワード: {obs.keyword}\")  # キーワードを表示\n",
    "\n",
    "for round in range(20):  # ゲームのラウンドを20まで繰り返す\n",
    "    obs.step = round + 1  # ラウンド数を設定\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"ask\"  # 質問するターン\n",
    "    question = agent(obs, cfg)  # 質問をエージェントに送信\n",
    "    obs.questions.append(question)  # 質問を記録\n",
    "    \n",
    "    obs.role = \"answerer\"  # 答える役の設定\n",
    "    obs.turnType = \"answer\"  # 答えるターン\n",
    "    answer = agent(obs, cfg)  # 答えをエージェントに送信\n",
    "    obs.answers.append(answer)  # 答えを記録\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"guess\"  # 推測するターン\n",
    "    guess = agent(obs, cfg)  # 推測をエージェントに送信\n",
    "    obs.guesses.append(guess)  # 推測を記録\n",
    "    \n",
    "    print(f\"ラウンド: {round + 1}\")  # ラウンド番号を表示\n",
    "    print(f\"質問: {question}\")  # 質問を表示\n",
    "    print(f\"答え: {answer}\")  # 答えを表示\n",
    "    print(f\"推測: {guess}\")  # 推測を表示\n",
    "    \n",
    "    if guess in alts_list:  # 推測が代替キーワードリストに含まれている場合\n",
    "        print(\"勝利!!\")  # 勝利のメッセージを表示\n",
    "        break\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:38:44.119151Z",
     "iopub.status.busy": "2024-07-10T07:38:44.118594Z",
     "iopub.status.idle": "2024-07-10T07:46:29.045452Z",
     "shell.execute_reply": "2024-07-10T07:46:29.044455Z",
     "shell.execute_reply.started": "2024-07-10T07:38:44.119123Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = Observation()  # 観察オブジェクトを作成\n",
    "cfg = \"_\"\n",
    "\n",
    "sample_df = keywords_df.sample()  # キーワードデータフレームからサンプルを抽出\n",
    "obs.keyword = sample_df[\"keyword\"].values[0]  # キーワードを設定\n",
    "obs.category = sample_df[\"category\"].values[0]  # カテゴリを設定\n",
    "alts_list = sample_df[\"alts\"].values[0]  # 代替キーワードを取得\n",
    "alts_list.append(obs.keyword)  # 代替キーワードリストに選ばれたキーワードを追加\n",
    "\n",
    "print(f\"キーワード: {obs.keyword}\")  # キーワードを表示\n",
    "\n",
    "for round in range(20):  # ゲームのラウンドを20まで繰り返す\n",
    "    obs.step = round + 1  # ラウンド数を設定\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"ask\"  # 質問するターン\n",
    "    question = agent(obs, cfg)  # 質問をエージェントに送信\n",
    "    obs.questions.append(question)  # 質問を記録\n",
    "    \n",
    "    obs.role = \"answerer\"  # 答える役の設定\n",
    "    obs.turnType = \"answer\"  # 答えるターン\n",
    "    answer = agent(obs, cfg)  # 答えをエージェントに送信\n",
    "    obs.answers.append(answer)  # 答えを記録\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"guess\"  # 推測するターン\n",
    "    guess = agent(obs, cfg)  # 推測をエージェントに送信\n",
    "    obs.guesses.append(guess)  # 推測を記録\n",
    "    \n",
    "    print(f\"ラウンド: {round + 1}\")  # ラウンド番号を表示\n",
    "    print(f\"質問: {question}\")  # 質問を表示\n",
    "    print(f\"答え: {answer}\")  # 答えを表示\n",
    "    print(f\"推測: {guess}\")  # 推測を表示\n",
    "    \n",
    "    if guess in alts_list:  # 推測が代替キーワードリストに含まれている場合\n",
    "        print(\"勝利!!\")  # 勝利のメッセージを表示\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T07:38:44.119151Z",
     "iopub.status.busy": "2024-07-10T07:38:44.118594Z",
     "iopub.status.idle": "2024-07-10T07:46:29.045452Z",
     "shell.execute_reply": "2024-07-10T07:46:29.044455Z",
     "shell.execute_reply.started": "2024-07-10T07:38:44.119123Z"
    }
   },
   "outputs": [],
   "source": [
    "obs = Observation()  # 観察オブジェクトを作成\n",
    "cfg = \"_\"\n",
    "\n",
    "sample_df = keywords_df.sample()  # キーワードデータフレームからサンプルを抽出\n",
    "obs.keyword = sample_df[\"keyword\"].values[0]  # キーワードを設定\n",
    "obs.category = sample_df[\"category\"].values[0]  # カテゴリを設定\n",
    "alts_list = sample_df[\"alts\"].values[0]  # 代替キーワードを取得\n",
    "alts_list.append(obs.keyword)  # 代替キーワードリストに選ばれたキーワードを追加\n",
    "\n",
    "print(f\"キーワード: {obs.keyword}\")  # キーワードを表示\n",
    "\n",
    "for round in range(20):  # ゲームのラウンドを20まで繰り返す\n",
    "    obs.step = round + 1  # ラウンド数を設定\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"ask\"  # 質問するターン\n",
    "    question = agent(obs, cfg)  # 質問をエージェントに送信\n",
    "    obs.questions.append(question)  # 質問を記録\n",
    "    \n",
    "    obs.role = \"answerer\"  # 答える役の設定\n",
    "    obs.turnType = \"answer\"  # 答えるターン\n",
    "    answer = agent(obs, cfg)  # 答えをエージェントに送信\n",
    "    obs.answers.append(answer)  # 答えを記録\n",
    "    \n",
    "    obs.role = \"guesser\"  # 推測役の設定\n",
    "    obs.turnType = \"guess\"  # 推測するターン\n",
    "    guess = agent(obs, cfg)  # 推測をエージェントに送信\n",
    "    obs.guesses.append(guess)  # 推測を記録\n",
    "    \n",
    "    print(f\"ラウンド: {round + 1}\")  # ラウンド番号を表示\n",
    "    print(f\"質問: {question}\")  # 質問を表示\n",
    "    print(f\"答え: {answer}\")  # 答えを表示\n",
    "    print(f\"推測: {guess}\")  # 推測を表示\n",
    "    \n",
    "    if guess in alts_list:  # 推測が代替キーワードリストに含まれている場合\n",
    "        print(\"勝利!!\")  # 勝利のメッセージを表示\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8318,
     "sourceId": 11382,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8332,
     "sourceId": 28808,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 58235,
     "sourceId": 69785,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
