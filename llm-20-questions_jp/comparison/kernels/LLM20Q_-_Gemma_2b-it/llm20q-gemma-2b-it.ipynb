{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80437c2a",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、「20の質問」ゲームをプレイするためのエージェントを開発することを目的としています。特に、ターン制のエージェントアプローチを用いて、人、場所、または物を特定するために、大規模言語モデルや新しいプログラミング手法を活用しています。\n",
    "\n",
    "### 問題定義\n",
    "- **ターゲットの特定**: キーワードのリストから、エージェントが人、場所、または物を特定します。\n",
    "- **考えられる解決策**:\n",
    "  - 大規模言語モデルをGISデータや製品情報とファインチューニングすることで、正確な推測を支援。\n",
    "  - 地理情報システムのデータセットを用いた場所の識別。\n",
    "  - キーワードのセグメンテーションを通じた新しいアプローチの提案。\n",
    "\n",
    "### 使用される手法とライブラリ\n",
    "- **Pandas**: キーワードのデータフレーム管理。\n",
    "- **JSON**: キーワードリストの読み込みと管理。\n",
    "- **Torch**: Gemmaモデルを使用したニューラルネットワークの構築。\n",
    "- **Kaggle Environments**: ゲーム環境のシミュレーション。\n",
    "- **Gemma**: 特に自然言語処理に特化した大規模言語モデルとして使用。\n",
    "\n",
    "### エージェントの設計\n",
    "- **質問者エージェント**: 人物、場所、または物を特定するための質問を生成。\n",
    "- **回答者エージェント**: 質問に対して「はい」または「いいえ」で応答。\n",
    "- 各エージェントは、セッション管理とレスポンス解析を行い、ゲームのラウンドに沿ったインタラクションを実現します。\n",
    "\n",
    "### 実行と環境\n",
    "- 環境設定を行い、複数のエージェントを同時に実行することでゲームの進行をシミュレーションし、各エージェントのパフォーマンスを観察します。\n",
    "\n",
    "このアプローチは、対話システムの開発やゲームAIの研究などにおいて、興味深い応用を持つものです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b687fb52",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、提出されたJupyterノートブックに関連する専門用語について、初心者がつまずきそうなものの簡単な解説を示します。\n",
    "\n",
    "1. **ターン制**:\n",
    "   - ゲームや対話の中で、プレイヤーが順番に行動を行う形式を指します。このノートブックでは、質問者と回答者が交互にアクションを行う「20の質問」ゲームの進行方法を指しています。\n",
    "\n",
    "2. **GIS座標**:\n",
    "   - 地理情報システム（GIS）で使用される座標で、地球上の位置を数値的に表現するためのものです。具体的には、緯度（Lat）と経度（Lon）を用いて位置を特定します。\n",
    "\n",
    "3. **ファインチューニング**:\n",
    "   - 学習済みモデルのパラメータを、新しいデータに合わせて再調整することです。特に、事前学習したモデルを特定のタスク（ここでは、言語モデルを使ったゲーム）に適応させるために行います。\n",
    "\n",
    "4. **トークン**:\n",
    "   - 自然言語処理において、テキストを意味のある単位に分割したものです。単語やサブワードなどが含まれます。モデルが理解可能な形式にするためのデータ構造です。\n",
    "\n",
    "5. **逆引きの非監視モデル**:\n",
    "   - ラベルなしのデータを使用して学習するモデルで、特定の出力を示さないデータから特徴やパターンを抽出し、推測を行います。逆引きとは、入力から出力を推測することを指します。\n",
    "\n",
    "6. **Few-shot learning**:\n",
    "   - 限られた学習例（数例）から一般化する能力を持つモデルを指します。このノートブックでは、一部の例を使用してモデルの推論を助ける方法が示されています。\n",
    "\n",
    "7. **イエスまたはノーの質問**:\n",
    "   - 2つの選択肢（「はい」または「いいえ」）から答える形式の質問で、この形式は推測ゲームで一般的です。\n",
    "\n",
    "8. **サンプリングパラメータ**:\n",
    "   - モデルから生成される出力の多様性や特性を調整するための設定です。具体的には、温度（temperature）、確率（top_p）、および上位k（top_k）が含まれます。\n",
    "\n",
    "9. **ガーベジコレクション**:\n",
    "   - メモリ管理の手法の一つで、不要になったオブジェクトを自動的に削除することを指します。この処理により、メモリリークを防ぐことができます。\n",
    "\n",
    "10. **エージェント**:\n",
    "    - 特定のタスクや役割を持っているプログラムまたはモデルを指します。この場合、質問者エージェントと回答者エージェントがゲームでそれぞれ異なる役割を果たしています。\n",
    "\n",
    "これらの解説を通じて、初心者でも理解しやすくすることが意図されています。もし他に特定の用語についての説明が必要であれば、お知らせください。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5dd20c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Problem Statement:\n",
    "Use Large Language Models or a new programming approach to identify a Person, Place or Thing from a list of keywords while playing a 20 Questions game using a turn by turn agent approach.  \n",
    "\n",
    "Possible Solutions:\n",
    "\n",
    "* Large Languate Models can be fine tuned with landmark and city GIS coordinates centerpoints from Photography to better align questioning to Country, City, State and Landmark approximation.\n",
    "\n",
    "* A phone Texts conversation datset with GIS coordinates could also potentially be used with converted locations to identify localization of languages, specific speach patterns or colloquialisms.\n",
    "\n",
    "* For Thigs, product descriptions or product reviews can be used possibly.\n",
    "\n",
    "* For Persons, Wikipedia can be used and any social networking like LinkedIn or Dating Sites.\n",
    "\n",
    "* Other approaches without fine tunning is to identify tokens that will yield great search signals to segmentations for quickly arriving at a keyword within a 20 question range that can be reverse lookup unsepervised model based on current use model weights or embeddings.\n",
    "\n",
    "Examples:\n",
    "* https://www.cia.gov/the-world-factbook/\n",
    "* https://public-nps.opendata.arcgis.com/datasets/nps::national-register-of-historic-places-points/explore\n",
    "\n",
    "\n",
    "## Keywords List\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 問題定義:\n",
    "ターン制のエージェントアプローチを使用して「20の質問」ゲームをプレイしながら、キーワードのリストから人、場所、または物を特定するために、大規模言語モデルまたは新しいプログラミングアプローチを使用します。\n",
    "\n",
    "考えられる解決策:\n",
    "\n",
    "* 大規模言語モデルを、写真からのランドマークや都市のGIS座標中心点でファインチューニングし、国、都市、州、ランドマークの推測をより適切に合わせることができます。\n",
    "\n",
    "* GIS座標を使用した電話のテキスト会話データセットも、場所を特定するために使用でき、言語、特定の会話パターン、または俗語の地域性を識別する可能性があります。\n",
    "\n",
    "* 物については、製品説明や製品レビューが使用可能です。\n",
    "\n",
    "* 人については、ウィキペディアやLinkedIn、出会い系サイトなどのソーシャルネットワーキングが利用されます。\n",
    "\n",
    "* ファインチューニングなしの他のアプローチとしては、トークンを識別して「20の質問」の範囲内でキーワードに迅速に到達するためのセグメンテーションを行う優れた検索信号を生み出すことが考えられます。これに基づいて、現在の使用モデルの重みや埋め込みを使用した逆引きの非監視モデルが可能です。\n",
    "\n",
    "例:\n",
    "* https://www.cia.gov/the-world-factbook/\n",
    "* https://public-nps.opendata.arcgis.com/datasets/nps::national-register-of-historic-places-points/explore\n",
    "\n",
    "\n",
    "## キーワードリスト\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f48919",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "keywords = SourceFileLoader(\"keywords\",'/kaggle/input/llm-20-questions/llm_20_questions/keywords.py').load_module()\n",
    "df = json.loads(keywords.KEYWORDS_JSON)\n",
    "words = []\n",
    "for c in df:\n",
    "    print(c['category'], len(c['words']))\n",
    "    for w in c['words']:\n",
    "        words.append([c['category'], w[\"keyword\"], w[\"alts\"], \"\", \"\", 0.0, 0.0])\n",
    "df = pd.DataFrame(words, columns=['Category','Word','Alternatives', \"Cat1\", \"Cat2\", \"Lat\", \"Lon\"])\n",
    "df.tail()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "keywords = SourceFileLoader(\"keywords\",'/kaggle/input/llm-20-questions/llm_20_questions/keywords.py').load_module()\n",
    "df = json.loads(keywords.KEYWORDS_JSON)\n",
    "words = []\n",
    "for c in df:\n",
    "    print(c['category'], len(c['words']))\n",
    "    for w in c['words']:\n",
    "        words.append([c['category'], w[\"keyword\"], w[\"alts\"], \"\", \"\", 0.0, 0.0])\n",
    "df = pd.DataFrame(words, columns=['Category','Word','Alternatives', \"Cat1\", \"Cat2\", \"Lat\", \"Lon\"])\n",
    "df.tail()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.924486Z",
     "iopub.status.busy": "2024-06-08T05:46:22.924097Z",
     "iopub.status.idle": "2024-06-08T05:46:22.973208Z",
     "shell.execute_reply": "2024-06-08T05:46:22.972092Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.924455Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from importlib.machinery import SourceFileLoader\n",
    "keywords = SourceFileLoader(\"keywords\",'/kaggle/input/llm-20-questions/llm_20_questions/keywords.py').load_module()\n",
    "df = json.loads(keywords.KEYWORDS_JSON)\n",
    "words = []\n",
    "for c in df:\n",
    "    print(c['category'], len(c['words']))\n",
    "    for w in c['words']:\n",
    "        words.append([c['category'], w[\"keyword\"], w[\"alts\"], \"\", \"\", 0.0, 0.0])\n",
    "df = pd.DataFrame(words, columns=['Category','Word','Alternatives', \"Cat1\", \"Cat2\", \"Lat\", \"Lon\"])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d779d4e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Template Formatting\n",
    "* https://www.promptingguide.ai/models/gemma\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## テンプレートフォーマット\n",
    "* https://www.promptingguide.ai/models/gemma\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ba1e13",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "template_special_tokens = ['<bos>','<start_of_turn>user','<start_of_turn>model','<end_of_turn>','<eos>']\n",
    "#Agent 1 - Guesser (Model?)\n",
    "#Agent 2 - Answerer (User?)\n",
    "#Agent 3 - Guesser (Model?)\n",
    "#Agent 4 - Answerer (User?)\n",
    "\n",
    "def agentx(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"\"\n",
    "    elif obs.turnType == \"guess\": response = \"\"\n",
    "    elif obs.turnType == \"answer\": response = \"\"\n",
    "    else: response = \"Am I Halucinating?  **YES**\"\n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "template_special_tokens = ['<bos>','<start_of_turn>user','<start_of_turn>model','<end_of_turn>','<eos>']\n",
    "#エージェント1 - 推測者（モデル？）\n",
    "#エージェント2 - 回答者（ユーザー？）\n",
    "#エージェント3 - 推測者（モデル？）\n",
    "#エージェント4 - 回答者（ユーザー？）\n",
    "\n",
    "def agentx(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"\"  # 質問の際のレスポンスを初期化\n",
    "    elif obs.turnType == \"guess\": response = \"\"  # 推測の際のレスポンスを初期化\n",
    "    elif obs.turnType == \"answer\": response = \"\"  # 回答の際のレスポンスを初期化\n",
    "    else: response = \"私は幻覚を見ていますか？ **はい**\"  # 不明なターンタイプへのレスポンス\n",
    "    return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.975677Z",
     "iopub.status.busy": "2024-06-08T05:46:22.975345Z",
     "iopub.status.idle": "2024-06-08T05:46:22.981114Z",
     "shell.execute_reply": "2024-06-08T05:46:22.980268Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.975647Z"
    }
   },
   "outputs": [],
   "source": [
    "template_special_tokens = ['<bos>','<start_of_turn>user','<start_of_turn>model','<end_of_turn>','<eos>']\n",
    "#エージェント1 - 推測者（モデル？）\n",
    "#エージェント2 - 回答者（ユーザー？）\n",
    "#エージェント3 - 推測者（モデル？）\n",
    "#エージェント4 - 回答者（ユーザー？）\n",
    "\n",
    "def agentx(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = \"\"  # 質問の際のレスポンスを初期化\n",
    "    elif obs.turnType == \"guess\": response = \"\"  # 推測の際のレスポンスを初期化\n",
    "    elif obs.turnType == \"answer\": response = \"\"  # 回答の際のレスポンスを初期化\n",
    "    else: response = \"私は幻覚を見ていますか？ **はい**\"  # 不明なターンタイプへのレスポンス\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8689739",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## 20 Questions Submission Model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 20の質問提出モデル\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b89ea",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null\n",
    "mkdir /kaggle/working/submission/lib/gemma/\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece  # 必要なパッケージのインストール\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null  # GemmaのPyTorchバージョンをクローン\n",
    "mkdir /kaggle/working/submission/lib/gemma/  # Gemma用のディレクトリを作成\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/  # Gemmaのファイルを移動\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:22.982593Z",
     "iopub.status.busy": "2024-06-08T05:46:22.982319Z",
     "iopub.status.idle": "2024-06-08T05:46:34.844839Z",
     "shell.execute_reply": "2024-06-08T05:46:34.842919Z",
     "shell.execute_reply.started": "2024-06-08T05:46:22.982569Z"
    },
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece  # 必要なパッケージのインストール\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null  # GemmaのPyTorchバージョンをクローン\n",
    "mkdir /kaggle/working/submission/lib/gemma/  # Gemma用のディレクトリを作成\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/  # Gemmaのファイルを移動"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974053a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%writefile submission/main.py\n",
    "\n",
    "import torch, itertools, contextlib\n",
    "import os, sys, re, gc\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "gc.enable()\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/2b-it/2\")\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")\n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\"\n",
    "\n",
    "from gemma.config import get_config_for_2b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "\n",
    "#This can be condensed and complimented with game memory storage open('gamemaster.dat'), open('player.dat')\n",
    "class AgentFormatter:\n",
    "    def __init__(self, sp: str = None, fse: Iterable = None):\n",
    "        self._system_prompt = sp\n",
    "        self._few_shot_examples = fse\n",
    "        self._turn_user = f\"<start_of_turn>user\\n{{}}<end_of_turn>\\n\"\n",
    "        self._turn_model = f\"<start_of_turn>model\\n{{}}<end_of_turn>\\n\"\n",
    "        self.reset()\n",
    "    def __repr__(self):\n",
    "        return self._state\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)\n",
    "        return self\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)\n",
    "        return self\n",
    "    def reset(self):\n",
    "        self._state = \"\"\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')\n",
    "        return self\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]\n",
    "        formatters = itertools.cycle(formatters)\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)\n",
    "        return self\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    torch.set_default_dtype(dtype)\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sp=None, fse=None):\n",
    "        self._device = torch.device('cuda:0')\n",
    "        self.formatter = AgentFormatter(sp=sp, fse=fse)\n",
    "        print(\"Initializing model\")\n",
    "        model_config = get_config_for_2b()\n",
    "        model_config.tokenizer = WEIGHTS_PATH + '/tokenizer.model'\n",
    "        with _set_default_tensor_type(model_config.get_dtype()):\n",
    "            model = GemmaForCausalLM(model_config)\n",
    "            model.load_weights(WEIGHTS_PATH + '/gemma-2b-it.ckpt')\n",
    "            self.model = model.to(self._device).eval()\n",
    "    def __call__(self, obs, *args):\n",
    "        self._start_session(obs)\n",
    "        prompt = str(self.formatter)\n",
    "        response = self._call_llm(prompt)\n",
    "        response = self._parse_response(response, obs)\n",
    "        print(obs.turnType, response)\n",
    "        return response\n",
    "    def _call_llm(self, prompt, max_nt=40, **sampler_kwargs):\n",
    "        if sampler_kwargs is None:\n",
    "            sampler_kwargs = {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50,}\n",
    "        response = self.model.generate(\n",
    "            prompt, device=self._device, output_len=max_nt, **sampler_kwargs,)\n",
    "        return response\n",
    "    def _parse_keyword(self, response: str):\n",
    "        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response) #Check keyword listing for closest match, update regex\n",
    "        if match is None: keyword = ''\n",
    "        else: keyword = match.group().lower()\n",
    "        return keyword\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))\n",
    "            if match is None: question = \"Is it a place?\" #make random choice for person, place, thing\n",
    "            else: question = match.group()\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"no guess\" #changed to random keyword?\n",
    "            else: \n",
    "                return guess\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)\n",
    "            return 'yes' if 'yes' in answer else 'no'\n",
    "        else: raise ValueError(\"Unknown turn type:\", obs.turnType)\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    return [item for pair in itertools.zip_longest(x, y) for item in pair if item is not None]\n",
    "\n",
    "class QuestionerAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()\n",
    "        self.formatter.user(\"You are playing the 20 Questions game in the role of the Questioner.\")\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)\n",
    "        self.formatter.apply_turns(turns, start_agent='model')\n",
    "        if obs.turnType == 'ask':\n",
    "            self.formatter.user(\"It is your turn to ask a yes or no question to find the person, place or thing.\")\n",
    "        elif obs.turnType == 'guess':\n",
    "            self.formatter.user(\"It is your turn to guess the person, place or thing. Surround your guess with double asterisks, like **yes** or **no**.\")\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))\n",
    "            if match is None: question = \"Is it a place?\" #make random choice for person, place, thing\n",
    "            else: question = match.group()\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"no guess\" \n",
    "            else: \n",
    "                return guess\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)\n",
    "            return 'yes' if 'yes' in answer else 'no'\n",
    "        else: raise ValueError(\"Unknown turn type:\", obs.turnType)\n",
    "\n",
    "class AnswererAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()\n",
    "        self.formatter.user(f\"You are playing the 20 Questions game in the role of the Answerer. The keyword is {obs.keyword} in the category {obs.category}.\")\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)\n",
    "        self.formatter.apply_turns(turns, start_agent='user')\n",
    "        self.formatter.user(f\"The question is about the keyword {obs.keyword} in the category {obs.category}. Give yes or no answer and surround your answer with double asterisks, like **yes** or **no**.\")\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        answer = self._parse_keyword(response)\n",
    "        return 'yes' if 'yes' in answer else 'no'\n",
    "\n",
    "sp = \"You are playing the 20 Questions game. In this game, the Answerer thinks of a keyword and responds to yes or no questions by the Questioner. The keyword is a specific person, place, or thing.\"\n",
    "fse = [\n",
    "    \"You are playing the 20 Questions game in the role of the Questioner. Please ask your first question to help guess a person, place or thing keyword.\",\n",
    "    \"Is it a person?\", \"**no**\",\n",
    "    \"Is is a place?\", \"**yes**\",\n",
    "    \"Is it a country?\", \"**yes** Now guess the keyword.\",\n",
    "    \"**France**\", \"Correct!\",\n",
    "]\n",
    "agent = None\n",
    "\n",
    "def get_agent(name: str):\n",
    "    global agent\n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = QuestionerAgent(sp=sp, fse=fse,)\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = AnswererAgent(sp=sp, fse=fse,)\n",
    "    assert agent is not None, \"Agent not initialized.\"\n",
    "    return agent\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = get_agent('questioner')(obs)\n",
    "    elif obs.turnType == \"guess\": response = get_agent('questioner')(obs)\n",
    "    elif obs.turnType == \"answer\": response = get_agent('answerer')(obs)\n",
    "    \n",
    "    if response is None or len(response) <= 1: return \"no\" #changed default\n",
    "    else: return response\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%writefile submission/main.py\n",
    "\n",
    "import torch, itertools, contextlib\n",
    "import os, sys, re, gc\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "gc.enable()  # ガーベジコレクションを有効にする\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"  # Kaggleエージェントのパス設定\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))  # Kaggleエージェントのライブラリをパスに追加\n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/2b-it/2\")  # 重みのパス設定\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")  # ローカルライブラリのパスに追加\n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\"  # 重みのパス設定\n",
    "\n",
    "from gemma.config import get_config_for_2b  # Gemmaの設定をインポート\n",
    "from gemma.model import GemmaForCausalLM  # Gemmaモデルをインポート\n",
    "\n",
    "# ゲームの履歴を保存するために、オープンファイルを使用して凝縮・補完することができる（open('gamemaster.dat'), open('player.dat')）\n",
    "class AgentFormatter:\n",
    "    def __init__(self, sp: str = None, fse: Iterable = None):\n",
    "        self._system_prompt = sp  # システムプロンプトの初期化\n",
    "        self._few_shot_examples = fse  # Few-shotの例の初期化\n",
    "        self._turn_user = f\"<start_of_turn>user\\n{{}}<end_of_turn>\\n\"  # ユーザーのターン形式\n",
    "        self._turn_model = f\"<start_of_turn>model\\n{{}}<end_of_turn>\\n\"  # モデルのターン形式\n",
    "        self.reset()  # フォーマッタをリセット\n",
    "    def __repr__(self):\n",
    "        return self._state  # 現在の状態を表示\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)  # ユーザーからの入力を追加\n",
    "        return self\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)  # モデルからの入力を追加\n",
    "        return self\n",
    "    def reset(self):\n",
    "        self._state = \"\"  # 状態をリセット\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)  # システムプロンプトがある場合、ユーザーターンとして追加\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')  # Few-shotの例を追加\n",
    "        return self\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]  # ターンの順番を決定\n",
    "        formatters = itertools.cycle(formatters)  # 順番にサイクルする\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)  # 各ターンを適用\n",
    "        return self\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    torch.set_default_dtype(dtype)  # デフォルトテンソル型を設定\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)  # デフォルトを戻す\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sp=None, fse=None):\n",
    "        self._device = torch.device('cuda:0')  # CUDAデバイスを指定\n",
    "        self.formatter = AgentFormatter(sp=sp, fse=fse)  # エージェントフォーマッタの初期化\n",
    "        print(\"モデルの初期化中\")\n",
    "        model_config = get_config_for_2b()  # モデルの設定を取得\n",
    "        model_config.tokenizer = WEIGHTS_PATH + '/tokenizer.model'  # トークナイザーのパスを設定\n",
    "        with _set_default_tensor_type(model_config.get_dtype()):  # デフォルトテンソル型を設定\n",
    "            model = GemmaForCausalLM(model_config)  # Gemmaのモデルを初期化\n",
    "            model.load_weights(WEIGHTS_PATH + '/gemma-2b-it.ckpt')  # 重みをロード\n",
    "            self.model = model.to(self._device).eval()  # デバイスにモデルを設定し評価モードに\n",
    "    def __call__(self, obs, *args):\n",
    "        self._start_session(obs)  # セッションを開始\n",
    "        prompt = str(self.formatter)  # フォーマットされたプロンプトを取得\n",
    "        response = self._call_llm(prompt)  # LLMにプロンプトを渡してレスポンスを取得\n",
    "        response = self._parse_response(response, obs)  # レスポンスをパース\n",
    "        print(obs.turnType, response)  # レスポンスを表示\n",
    "        return response\n",
    "    def _call_llm(self, prompt, max_nt=40, **sampler_kwargs):\n",
    "        if sampler_kwargs is None:\n",
    "            sampler_kwargs = {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50,}  # サンプリングパラメータ\n",
    "        response = self.model.generate(\n",
    "            prompt, device=self._device, output_len=max_nt, **sampler_kwargs,)  # モデルからレスポンスを生成\n",
    "        return response\n",
    "    def _parse_keyword(self, response: str):\n",
    "        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)  # キーワードリストから最も近い一致をチェック\n",
    "        if match is None: keyword = ''\n",
    "        else: keyword = match.group().lower()  # 一致するキーワードを小文字に変換\n",
    "        return keyword\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問形式のレスポンスをパース\n",
    "            if match is None: question = \"それは場所ですか？\"  # 質問がない場合\n",
    "            else: question = match.group()  # 質問を設定\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # 推測をパース\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"推測なし\"  # 推測できない場合のレスポンス\n",
    "            else: \n",
    "                return guess  # 推測を返す\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # 答えをパース\n",
    "            return 'はい' if 'はい' in answer else 'いいえ'  # 「はい」または「いいえ」を返す\n",
    "        else: raise ValueError(\"未知のターンタイプ:\", obs.turnType)  # エラー処理\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    return [item for pair in itertools.zip_longest(x, y) for item in pair if item is not None]  # 不均等なリストを交互に結合する関数\n",
    "\n",
    "class QuestionerAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # 親クラスの初期化\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # フォーマッタをリセット\n",
    "        self.formatter.user(\"あなたは20の質問ゲームの質問者としてプレイしています。\")  # 質問者としての初期プロンプト\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # 質問と回答を交互に取り出す\n",
    "        self.formatter.apply_turns(turns, start_agent='model')  # ターンを適用\n",
    "        if obs.turnType == 'ask':\n",
    "            self.formatter.user(\"あなたは、人物、場所、または物を見つけるためにイエスまたはノーの質問をするターンです。\")  # 質問のターン\n",
    "        elif obs.turnType == 'guess':\n",
    "            self.formatter.user(\"あなたは人物、場所、または物を推測するターンです。推測を「**もの**」のように二重アスタリスクで囲んでください。\")  # 推測のターン\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問をパース\n",
    "            if match is None: question = \"それは場所ですか？\"  # デフォルト質問\n",
    "            else: question = match.group()  # 質問を取得\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # 推測をパース\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"推測なし\" \n",
    "            else: \n",
    "                return guess  # 推測を返す\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # 答えをパース\n",
    "            return 'はい' if 'はい' in answer else 'いいえ'  # 答えを返す\n",
    "        else: raise ValueError(\"未知のターンタイプ:\", obs.turnType)  # エラー処理\n",
    "\n",
    "class AnswererAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # 親クラスの初期化\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # フォーマッタをリセット\n",
    "        self.formatter.user(f\"あなたは20の質問ゲームの回答者としてプレイしています。キーワードは{obs.keyword}で、カテゴリは{obs.category}です。\")  # 初期プロンプト\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # ターンを交互に適用\n",
    "        self.formatter.apply_turns(turns, start_agent='user')  # ユーザーのターンを適用\n",
    "        self.formatter.user(f\"質問はキーワード{obs.keyword}について、カテゴリは{obs.category}です。イエスまたはノーで答え、答えを二重アスタリスクで囲んでください。\")  # 質問プロンプト\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        answer = self._parse_keyword(response)  # 答えをパース\n",
    "        return 'はい' if 'はい' in answer else 'いいえ'  # 答えを返す\n",
    "\n",
    "sp = \"あなたは20の質問ゲームをプレイしています。このゲームでは、回答者がキーワードを考え、質問者がイエスまたはノーの質問をします。キーワードは特定の人物、場所、または物です。\"\n",
    "fse = [\n",
    "    \"あなたは20の質問ゲームの質問者としてプレイしています。人物、場所、または物のキーワードを見つけるために最初の質問をしてください。\",\n",
    "    \"これは人物ですか？\", \"**いいえ**\",\n",
    "    \"これは場所ですか？\", \"**はい**\",\n",
    "    \"これは国ですか？\", \"**はい** 推測してみてください。\",\n",
    "    \"**フランス**\", \"正解です！\",\n",
    "]\n",
    "agent = None\n",
    "\n",
    "def get_agent(name: str):\n",
    "    global agent\n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = QuestionerAgent(sp=sp, fse=fse,)  # 質問者エージェントの初期化\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = AnswererAgent(sp=sp, fse=fse,)  # 回答者エージェントの初期化\n",
    "    assert agent is not None, \"エージェントが初期化されていません。\"  # エージェントの初期化確認\n",
    "    return agent\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = get_agent('questioner')(obs)  # 質問のターンに応じたエージェントを取得\n",
    "    elif obs.turnType == \"guess\": response = get_agent('questioner')(obs)  # 推測のターンに応じたエージェントを取得\n",
    "    elif obs.turnType == \"answer\": response = get_agent('answerer')(obs)  # 回答のターンに応じたエージェントを取得\n",
    "    \n",
    "    if response is None or len(response) <= 1: return \"いいえ\"  # レスポンスが不明または短い場合\n",
    "    else: return response  # レスポンスを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:50:54.946487Z",
     "iopub.status.busy": "2024-06-08T05:50:54.945851Z",
     "iopub.status.idle": "2024-06-08T05:50:54.9574Z",
     "shell.execute_reply": "2024-06-08T05:50:54.956464Z",
     "shell.execute_reply.started": "2024-06-08T05:50:54.946445Z"
    },
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile submission/main.py\n",
    "\n",
    "import torch, itertools, contextlib\n",
    "import os, sys, re, gc\n",
    "from typing import Iterable\n",
    "from pathlib import Path\n",
    "gc.enable()  # ガーベジコレクションを有効にする\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"  # Kaggleエージェントのパス設定\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))  # Kaggleエージェントのライブラリをパスに追加\n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/2b-it/2\")  # 重みのパス設定\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")  # ローカルライブラリのパスに追加\n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/2b-it/2\"  # 重みのパス設定\n",
    "\n",
    "from gemma.config import get_config_for_2b  # Gemmaの設定をインポート\n",
    "from gemma.model import GemmaForCausalLM  # Gemmaモデルをインポート\n",
    "\n",
    "# ゲームの履歴を保存するために、オープンファイルを使用して凝縮・補完することができる（open('gamemaster.dat'), open('player.dat')）\n",
    "class AgentFormatter:\n",
    "    def __init__(self, sp: str = None, fse: Iterable = None):\n",
    "        self._system_prompt = sp  # システムプロンプトの初期化\n",
    "        self._few_shot_examples = fse  # Few-shotの例の初期化\n",
    "        self._turn_user = f\"<start_of_turn>user\\n{{}}<end_of_turn>\\n\"  # ユーザーのターン形式\n",
    "        self._turn_model = f\"<start_of_turn>model\\n{{}}<end_of_turn>\\n\"  # モデルのターン形式\n",
    "        self.reset()  # フォーマッタをリセット\n",
    "    def __repr__(self):\n",
    "        return self._state  # 現在の状態を表示\n",
    "    def user(self, prompt):\n",
    "        self._state += self._turn_user.format(prompt)  # ユーザーからの入力を追加\n",
    "        return self\n",
    "    def model(self, prompt):\n",
    "        self._state += self._turn_model.format(prompt)  # モデルからの入力を追加\n",
    "        return self\n",
    "    def reset(self):\n",
    "        self._state = \"\"  # 状態をリセット\n",
    "        if self._system_prompt is not None:\n",
    "            self.user(self._system_prompt)  # システムプロンプトがある場合、ユーザーターンとして追加\n",
    "        if self._few_shot_examples is not None:\n",
    "            self.apply_turns(self._few_shot_examples, start_agent='user')  # Few-shotの例を追加\n",
    "        return self\n",
    "    def apply_turns(self, turns: Iterable, start_agent: str):\n",
    "        formatters = [self.model, self.user] if start_agent == 'model' else [self.user, self.model]  # ターンの順番を決定\n",
    "        formatters = itertools.cycle(formatters)  # 順番にサイクルする\n",
    "        for fmt, turn in zip(formatters, turns):\n",
    "            fmt(turn)  # 各ターンを適用\n",
    "        return self\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    torch.set_default_dtype(dtype)  # デフォルトテンソル型を設定\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)  # デフォルトを戻す\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, sp=None, fse=None):\n",
    "        self._device = torch.device('cuda:0')  # CUDAデバイスを指定\n",
    "        self.formatter = AgentFormatter(sp=sp, fse=fse)  # エージェントフォーマッタの初期化\n",
    "        print(\"モデルの初期化中\")\n",
    "        model_config = get_config_for_2b()  # モデルの設定を取得\n",
    "        model_config.tokenizer = WEIGHTS_PATH + '/tokenizer.model'  # トークナイザーのパスを設定\n",
    "        with _set_default_tensor_type(model_config.get_dtype()):  # デフォルトテンソル型を設定\n",
    "            model = GemmaForCausalLM(model_config)  # Gemmaのモデルを初期化\n",
    "            model.load_weights(WEIGHTS_PATH + '/gemma-2b-it.ckpt')  # 重みをロード\n",
    "            self.model = model.to(self._device).eval()  # デバイスにモデルを設定し評価モードに\n",
    "    def __call__(self, obs, *args):\n",
    "        self._start_session(obs)  # セッションを開始\n",
    "        prompt = str(self.formatter)  # フォーマットされたプロンプトを取得\n",
    "        response = self._call_llm(prompt)  # LLMにプロンプトを渡してレスポンスを取得\n",
    "        response = self._parse_response(response, obs)  # レスポンスをパース\n",
    "        print(obs.turnType, response)  # レスポンスを表示\n",
    "        return response\n",
    "    def _call_llm(self, prompt, max_nt=40, **sampler_kwargs):\n",
    "        if sampler_kwargs is None:\n",
    "            sampler_kwargs = {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50,}  # サンプリングパラメータ\n",
    "        response = self.model.generate(\n",
    "            prompt, device=self._device, output_len=max_nt, **sampler_kwargs,)  # モデルからレスポンスを生成\n",
    "        return response\n",
    "    def _parse_keyword(self, response: str):\n",
    "        match = re.search(r\"(?<=\\*\\*)([^*]+)(?=\\*\\*)\", response)  # キーワードリストから最も近い一致をチェック\n",
    "        if match is None: keyword = ''\n",
    "        else: keyword = match.group().lower()  # 一致するキーワードを小文字に変換\n",
    "        return keyword\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問形式のレスポンスをパース\n",
    "            if match is None: question = \"それは場所ですか？\"  # 質問がない場合\n",
    "            else: question = match.group()  # 質問を設定\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # 推測をパース\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"推測なし\"  # 推測できない場合のレスポンス\n",
    "            else: \n",
    "                return guess  # 推測を返す\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # 答えをパース\n",
    "            return 'はい' if 'はい' in answer else 'いいえ'  # 「はい」または「いいえ」を返す\n",
    "        else: raise ValueError(\"未知のターンタイプ:\", obs.turnType)  # エラー処理\n",
    "\n",
    "def interleave_unequal(x, y):\n",
    "    return [item for pair in itertools.zip_longest(x, y) for item in pair if item is not None]  # 不均等なリストを交互に結合する関数\n",
    "\n",
    "class QuestionerAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # 親クラスの初期化\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # フォーマッタをリセット\n",
    "        self.formatter.user(\"あなたは20の質問ゲームの質問者としてプレイしています。\")  # 質問者としての初期プロンプト\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # 質問と回答を交互に取り出す\n",
    "        self.formatter.apply_turns(turns, start_agent='model')  # ターンを適用\n",
    "        if obs.turnType == 'ask':\n",
    "            self.formatter.user(\"あなたは、人物、場所、または物を見つけるためにイエスまたはノーの質問をするターンです。\")  # 質問のターン\n",
    "        elif obs.turnType == 'guess':\n",
    "            self.formatter.user(\"あなたは人物、場所、または物を推測するターンです。推測を「**もの**」のように二重アスタリスクで囲んでください。\")  # 推測のターン\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        if obs.turnType == 'ask':\n",
    "            match = re.search(\".+?\\?\", response.replace('*', ''))  # 質問をパース\n",
    "            if match is None: question = \"それは場所ですか？\"  # デフォルト質問\n",
    "            else: question = match.group()  # 質問を取得\n",
    "            return question\n",
    "        elif obs.turnType == 'guess':\n",
    "            guess = self._parse_keyword(response)  # 推測をパース\n",
    "            if guess is None or len(guess) <= 1: \n",
    "                return \"推測なし\" \n",
    "            else: \n",
    "                return guess  # 推測を返す\n",
    "        elif obs.turnType == 'answer':\n",
    "            answer = self._parse_keyword(response)  # 答えをパース\n",
    "            return 'はい' if 'はい' in answer else 'いいえ'  # 答えを返す\n",
    "        else: raise ValueError(\"未知のターンタイプ:\", obs.turnType)  # エラー処理\n",
    "\n",
    "class AnswererAgent(Agent):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)  # 親クラスの初期化\n",
    "    def _start_session(self, obs):\n",
    "        self.formatter.reset()  # フォーマッタをリセット\n",
    "        self.formatter.user(f\"あなたは20の質問ゲームの回答者としてプレイしています。キーワードは{obs.keyword}で、カテゴリは{obs.category}です。\")  # 初期プロンプト\n",
    "        turns = interleave_unequal(obs.questions, obs.answers)  # ターンを交互に適用\n",
    "        self.formatter.apply_turns(turns, start_agent='user')  # ユーザーのターンを適用\n",
    "        self.formatter.user(f\"質問はキーワード{obs.keyword}について、カテゴリは{obs.category}です。イエスまたはノーで答え、答えを二重アスタリスクで囲んでください。\")  # 質問プロンプト\n",
    "    def _parse_response(self, response: str, obs: dict):\n",
    "        answer = self._parse_keyword(response)  # 答えをパース\n",
    "        return 'はい' if 'はい' in answer else 'いいえ'  # 答えを返す\n",
    "\n",
    "sp = \"あなたは20の質問ゲームをプレイしています。このゲームでは、回答者がキーワードを考え、質問者がイエスまたはノーの質問をします。キーワードは特定の人物、場所、または物です。\"\n",
    "fse = [\n",
    "    \"あなたは20の質問ゲームの質問者としてプレイしています。人物、場所、または物のキーワードを見つけるために最初の質問をしてください。\",\n",
    "    \"これは人物ですか？\", \"**いいえ**\",\n",
    "    \"これは場所ですか？\", \"**はい**\",\n",
    "    \"これは国ですか？\", \"**はい** 推測してみてください。\",\n",
    "    \"**フランス**\", \"正解です！\",\n",
    "]\n",
    "agent = None\n",
    "\n",
    "def get_agent(name: str):\n",
    "    global agent\n",
    "    if agent is None and name == 'questioner':\n",
    "        agent = QuestionerAgent(sp=sp, fse=fse,)  # 質問者エージェントの初期化\n",
    "    elif agent is None and name == 'answerer':\n",
    "        agent = AnswererAgent(sp=sp, fse=fse,)  # 回答者エージェントの初期化\n",
    "    assert agent is not None, \"エージェントが初期化されていません。\"  # エージェントの初期化確認\n",
    "    return agent\n",
    "\n",
    "def agent_fn(obs, cfg):\n",
    "    if obs.turnType == \"ask\": response = get_agent('questioner')(obs)  # 質問のターンに応じたエージェントを取得\n",
    "    elif obs.turnType == \"guess\": response = get_agent('questioner')(obs)  # 推測のターンに応じたエージェントを取得\n",
    "    elif obs.turnType == \"answer\": response = get_agent('answerer')(obs)  # 回答のターンに応じたエージェントを取得\n",
    "    \n",
    "    if response is None or len(response) <= 1: return \"いいえ\"  # レスポンスが不明または短い場合\n",
    "    else: return response  # レスポンスを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a63d8a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Testing\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# テスト\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cabc0e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q pygame\n",
    "!pip install -q 'kaggle_environments>=1.14.8'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!pip install -q pygame  # pygameのインストール\n",
    "!pip install -q 'kaggle_environments>=1.14.8'  # Kaggle環境のインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:46:59.550248Z",
     "iopub.status.busy": "2024-06-08T05:46:59.549885Z",
     "iopub.status.idle": "2024-06-08T05:47:27.472893Z",
     "shell.execute_reply": "2024-06-08T05:47:27.471795Z",
     "shell.execute_reply.started": "2024-06-08T05:46:59.550223Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q pygame  # pygameのインストール\n",
    "!pip install -q 'kaggle_environments>=1.14.8'  # Kaggle環境のインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f284bf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#Run Code\n",
    "%run submission/main.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#コードを実行\n",
    "%run submission/main.py  # メインファイルを実行\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:00.453764Z",
     "iopub.status.busy": "2024-06-08T05:51:00.453414Z",
     "iopub.status.idle": "2024-06-08T05:51:00.463462Z",
     "shell.execute_reply": "2024-06-08T05:51:00.462658Z",
     "shell.execute_reply.started": "2024-06-08T05:51:00.453736Z"
    }
   },
   "outputs": [],
   "source": [
    "#コードを実行\n",
    "%run submission/main.py  # メインファイルを実行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bb3b30",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from kaggle_environments import make\n",
    "env = make(\"llm_20_questions\", debug=True)\n",
    "agent = \"/kaggle/working/submission/main.py\"\n",
    "env.reset()\n",
    "logs = env.run([agent, agent, agent, agent])\n",
    "#while not env.done: #add steps here for testing\n",
    "env.render(mode=\"ipython\", width=800, height=800)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from kaggle_environments import make  # Kaggle環境をインポート\n",
    "env = make(\"llm_20_questions\", debug=True)  # 環境を作成\n",
    "agent = \"/kaggle/working/submission/main.py\"\n",
    "env.reset()  # 環境のリセット\n",
    "logs = env.run([agent, agent, agent, agent])  # 4つのエージェントを実行\n",
    "#while not env.done: #ここにテストのステップを追加\n",
    "env.render(mode=\"ipython\", width=800, height=800)  # 環境を描画\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-08T05:51:03.119441Z",
     "iopub.status.busy": "2024-06-08T05:51:03.119068Z",
     "iopub.status.idle": "2024-06-08T05:51:53.374014Z",
     "shell.execute_reply": "2024-06-08T05:51:53.372967Z",
     "shell.execute_reply.started": "2024-06-08T05:51:03.119415Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make  # Kaggle環境をインポート\n",
    "env = make(\"llm_20_questions\", debug=True)  # 環境を作成\n",
    "agent = \"/kaggle/working/submission/main.py\"\n",
    "env.reset()  # 環境のリセット\n",
    "logs = env.run([agent, agent, agent, agent])  # 4つのエージェントを実行\n",
    "#while not env.done: #ここにテストのステップを追加\n",
    "env.render(mode=\"ipython\", width=800, height=800)  # 環境を描画"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c8c16b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Package\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# パッケージ\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280960c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!apt install pigz pv > /dev/null\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!apt install pigz pv > /dev/null  # pigzとpvのインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.852949Z",
     "iopub.status.idle": "2024-06-08T05:46:34.85337Z",
     "shell.execute_reply": "2024-06-08T05:46:34.853168Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.85315Z"
    },
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv > /dev/null  # pigzとpvのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1c532",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/2b-it/2\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/2b-it/2  # tar圧縮\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-08T05:46:34.854563Z",
     "iopub.status.idle": "2024-06-08T05:46:34.855024Z",
     "shell.execute_reply": "2024-06-08T05:46:34.854796Z",
     "shell.execute_reply.started": "2024-06-08T05:46:34.854777Z"
    },
    "papermill": {
     "duration": 148.240766,
     "end_time": "2024-04-17T13:50:23.136669",
     "exception": false,
     "start_time": "2024-04-17T13:47:54.895903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/working/submission . -C /kaggle/input/ gemma/pytorch/2b-it/2  # tar圧縮"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b07104",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント \n",
    "\n",
    "> ## DataDiva007\n",
    "> \n",
    "> データサイエンスプロジェクトに取り組むことはとても中毒性があり、ここに来てとても楽しいです！\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## SuM\n",
    "> \n",
    "> すばらしい仕事 [@jazivxt](https://www.kaggle.com/jazivxt)🎉\n",
    "> \n",
    "> 共有してくれてありがとう、これは初心者にとって重要なインスピレーションを与えます😃\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Neel Patel\n",
    "> \n",
    "> 素晴らしい作業、提出前にモデルをテストするのに非常に役立ちます。 :)\n",
    "\n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Hassan shahidi\n",
    "> \n",
    "> 素晴らしいノートブック [@jazivxt](https://www.kaggle.com/jazivxt)\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Prajwal Kanade\n",
    "> \n",
    "> すばらしい情報です、\n",
    "> \n",
    "> 素晴らしい仕事 [@jazivxt](https://www.kaggle.com/jazivxt) \n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Utkarsh Jain\n",
    "> \n",
    "> 興味深いノートブック！！非常に洞察に満ちています！！\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## huoyeqianxun\n",
    "> \n",
    "> CUDAのメモリ不足のようです…\n",
    "> \n",
    "> ノートブックで4つのエージェントを実行できませんか？？？\n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 5383,
     "sourceId": 11358,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
