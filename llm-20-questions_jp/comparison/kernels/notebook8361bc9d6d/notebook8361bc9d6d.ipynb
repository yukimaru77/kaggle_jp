{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfb5b79",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、「20の質問」ゲームに挑戦するための言語モデルの開発に関連しており、特定のキーワードを当てるための質問と推測を行うエージェントを構築しています。以下に、ノートブックの主な内容を要約します。\n",
    "\n",
    "### 問題の取り組み\n",
    "ノートブックは、言語モデルを使用して、質問応答形式で特定のキーワードを推測するAIエージェントを構築することを目的としています。特に、ユーザーが設定したカテゴリや特定の特徴に基づいて、質問を生成し、それに対する応答を取得して推測を行います。このプロジェクトは、Kaggleの「LLM 20 Questions」コンペティションに参加するために設計されています。\n",
    "\n",
    "### 使用されている手法とライブラリ\n",
    "1. **データ処理**:\n",
    "   - `pandas`: データ操作を行い、キーワードデータを管理します。\n",
    "   - JSON形式のキーワードデータを辞書として読み込み、DataFrame形式に変換しています。\n",
    "\n",
    "2. **ビジュアライゼーション**:\n",
    "   - `matplotlib`: クエスチョンやアンサーを視覚化するために使用され、描画機能を実装しています。\n",
    "\n",
    "3. **モデルの構築**:\n",
    "   - `transformers`: Hugging FaceのTransformersライブラリからT5モデルを用いることが考慮されています。また、別の言語モデル「Llama-3-Smaug-8B」を使用してYes/No質問の応答を生成しています。\n",
    "\n",
    "4. **対話システムの実装**:\n",
    "   - 多層的な質問生成や推測アルゴリズムを通じて、エージェントは、質問に対する応答を生成するほか、さらに次の質問を決定します。これには、質問の種類（例えば、地名や国名、文化財など）や特徴（大陸や文字の最初など）に基づく処理があります。\n",
    "\n",
    "5. **リソース管理**:\n",
    "   - `gc`および`torch.cuda`: メモリ管理を行い、GPUリソースのクリアを実施しています。\n",
    "\n",
    "### 結論\n",
    "このノートブックは「20の質問」ゲームのAIエージェントを開発するための基盤を提供しており、特定の対象を当てるための戦略的な質問を自動的に生成し、言語モデルによって得られた情報を効果的に利用します。また、モデルとトークナイザーの読み込み、応答処理のロジック、エラーハンドリングについても詳細に記載されており、実用的なプロジェクトとして集約されています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8adca7c",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に基づいて、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説です。初心者なレベルですが、少しマイナーな用語や特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **immutable_dict**: イミュータブル（不変）な辞書を提供するデータ構造で、作成後に内容を変更できません。この特性は、データ整合性を保つために役立ちます。\n",
    "\n",
    "2. **sentencepiece**: Googleが開発したオープンソースのトークン化ツールです。主に、ニューラルネットワークの入力としてテキストを効果的に処理するために使用されます。モデリングの際にサブワード単位での処理を支援します。\n",
    "\n",
    "3. **T5Tokenizer / T5ForConditionalGeneration**: T5（Text-to-Text Transfer Transformer）モデル用のトークナイザーおよび条件付き生成モデルです。テキストを生成や要約、翻訳など様々なタスクに利用できる柔軟性があります。\n",
    "\n",
    "4. **pip install -U -t**: Pythonのパッケージマネージャであるpipを使って、指定したフォルダにパッケージをインストールするコマンド。`-U`オプションは既存のパッケージをアップグレードすることを意味します。`-t`オプションはインストール先のディレクトリを指定します。\n",
    "\n",
    "5. **maximum new tokens**: モデルが生成する新しいトークンの最大数を指定するパラメータで、これにより生成された応答の長さを制限します。\n",
    "\n",
    "6. **torch.no_grad()**: PyTorchにおいて、勾配計算を無効にするための文脈マネージャです。推論時にメモリ使用量を削減し、計算時間を短縮します。\n",
    "\n",
    "7. **torch.cuda.amp.autocast()**: 自動混合精度（Automatic Mixed Precision）を有効にするための文脈マネージャで、計算を半精度で行うことにより性能を向上させることができます。リソースの効率を良くし、深層学習のトレーニングや推論を加速します。\n",
    "\n",
    "8. **get_yes_no()関数**: 与えられた質問に対して「はい」または「いいえ」で応答するための関数です。キーワードやその属性に基づいてプロンプトを組み立て、モデルに入力します。\n",
    "\n",
    "9. **Observationクラス**: エージェントのターンに関する情報（質問、回答、キーワードなど）を管理するデータ構造を定義するクラスで、システムの状態を保持します。\n",
    "\n",
    "10. **garbage collection (gc)**: 使用されなくなったメモリリソースを自動的に解放するプロセスです。メモリリークを防ぎ、アプリケーションのパフォーマンスを向上させます。\n",
    "\n",
    "11. **Assertions**: コード内の条件が本当に真であるかどうかを確認するためのテスト機能。エラーが発生した場合には、デバッグの助けとなります。\n",
    "\n",
    "これらの説明は、初心者がノートブックを理解するのに役立つ関連用語をより明確にするためのものです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba39bb66",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これは、kaggle/pythonのDockerイメージに基づいています: https://github.com/kaggle/docker-python\n",
    "# 例えば、いくつかの便利なパッケージを読み込むことができます\n",
    "\n",
    "import numpy as np # 線形代数を扱うためのライブラリ\n",
    "import pandas as pd # データ処理やCSVファイルの入出力を行うライブラリ（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の \"../input/\" ディレクトリにあります\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするかShift+Enterを押すと）入力ディレクトリ内のすべてのファイルが一覧表示されます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのパスを表示します\n",
    "\n",
    "# 現在のディレクトリ (/kaggle/working/) に最大20GBまで書き込むことができ、そのデータは \"Save & Run All\" を使用してバージョンを作成する際に出力として保存されます\n",
    "# また、一時ファイルを /kaggle/temp/ にも書き込むことができますが、現在のセッションの外には保存されません\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-04T17:22:06.807107Z",
     "iopub.status.busy": "2024-08-04T17:22:06.806802Z",
     "iopub.status.idle": "2024-08-04T17:22:07.79464Z",
     "shell.execute_reply": "2024-08-04T17:22:07.793304Z",
     "shell.execute_reply.started": "2024-08-04T17:22:06.807081Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これは、kaggle/pythonのDockerイメージに基づいています: https://github.com/kaggle/docker-python\n",
    "# 例えば、いくつかの便利なパッケージを読み込むことができます\n",
    "\n",
    "import numpy as np # 線形代数を扱うためのライブラリ\n",
    "import pandas as pd # データ処理やCSVファイルの入出力を行うライブラリ（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の \"../input/\" ディレクトリにあります\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするかShift+Enterを押すと）入力ディレクトリ内のすべてのファイルが一覧表示されます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのパスを表示します\n",
    "\n",
    "# 現在のディレクトリ (/kaggle/working/) に最大20GBまで書き込むことができ、そのデータは \"Save & Run All\" を使用してバージョンを作成する際に出力として保存されます\n",
    "# また、一時ファイルを /kaggle/temp/ にも書き込むことができますが、現在のセッションの外には保存されません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65afce41",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null\n",
    "mkdir /kaggle/working/submission/lib/gemma/\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%bash\n",
    "cd /kaggle/working # 作業ディレクトリに移動\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece # immutabledictとsentencepieceを作業ディレクトリ内の特定のライブラリフォルダにインストールします\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null # gemma_pytorchリポジトリをクローンします（出力は非表示）\n",
    "mkdir /kaggle/working/submission/lib/gemma/ # gemma用のディレクトリを作成します\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/ # クローンしたファイルを指定のディレクトリに移動します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:24:58.601352Z",
     "iopub.status.busy": "2024-08-04T17:24:58.60032Z",
     "iopub.status.idle": "2024-08-04T17:25:11.988458Z",
     "shell.execute_reply": "2024-08-04T17:25:11.987468Z",
     "shell.execute_reply.started": "2024-08-04T17:24:58.601316Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working # 作業ディレクトリに移動\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece # immutabledictとsentencepieceを作業ディレクトリ内の特定のライブラリフォルダにインストールします\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null # gemma_pytorchリポジトリをクローンします（出力は非表示）\n",
    "mkdir /kaggle/working/submission/lib/gemma/ # gemma用のディレクトリを作成します\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/ # クローンしたファイルを指定のディレクトリに移動します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f060561f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "from string import Template\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "KEYWORDS_JSON = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"category\": \"country\",\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"afghanistan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"albania\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"algeria\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"andorra\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"angola\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"antigua and barbuda\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"argentina\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"armenia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"australia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"austria\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"azerbaijan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bahrain\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bangladesh\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"barbados\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"belarus\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"belgium\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"belize\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"benin\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bhutan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bolivia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bosnia and herzegovina\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"botswana\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"brazil\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"brunei\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bulgaria\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"burkina faso\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"burundi\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cambodia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cameroon\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"canada\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cape verde\",\n",
    "        \"alts\": [\"cabo verde\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"central african republic\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"chad\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"chile\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"china\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"colombia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"comoros\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"congo\",\n",
    "        \"alts\": [\"republic of the congo\", \"congo brazzaville\", \"congo republic\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"costa rica\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"croatia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cuba\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cyprus\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"czech republic\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"democratic republic of the congo\",\n",
    "        \"alts\": [\"drc\", \"congo kinshasa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"denmark\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"djibouti\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dominica\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dominican republic\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ecuador\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"egypt\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"el salvador\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"england\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"equatorial guinea\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"eritrea\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"estonia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ethiopia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"federated states of micronesia\",\n",
    "        \"alts\": [\"micronesia\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"finland\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"france\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gabon\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gambia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"georgia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"germany\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ghana\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"greece\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"grenada\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guatemala\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guinea\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guinea bissau\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guyana\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"haiti\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"honduras\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hungary\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"iceland\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"india\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"indonesia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"iran\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"iraq\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ireland\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"israel\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"italy\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jamaica\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"japan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jordan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kazakhstan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kenya\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kiribati\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kosovo\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kuwait\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kyrgyzstan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"laos\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"latvia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lebanon\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lesotho\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"liberia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"libya\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"liechtenstein\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lithuania\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"luxembourg\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"madagascar\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"malawi\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"malaysia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"maldives\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mali\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"malta\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"marshall islands\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mauritania\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mauritius\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mexico\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"moldova\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"monaco\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mongolia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"montenegro\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"morocco\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mozambique\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"myanmar\",\n",
    "        \"alts\": [\"burma\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"namibia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nauru\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nepal\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"netherlands\",\n",
    "        \"alts\": [\"holland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"new zealand\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nicaragua\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"niger\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nigeria\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"north korea\",\n",
    "        \"alts\": [\"dprk\", \"democratic peoples republic of korea\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"norway\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oman\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"pakistan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"palau\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"palestine\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"panama\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"papua new guinea\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"paraguay\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"peru\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"philippines\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"poland\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"portugal\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"qatar\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"romania\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"russia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rwanda\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"saint kitts and nevis\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"saint lucia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"saint vincent and the grenadines\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"samoa\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"san marino\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sao tome and principe\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"saudi arabia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"senegal\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"serbia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"seychelles\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sierra leone\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"singapore\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"slovakia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"slovenia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"solomon islands\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"somalia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"south africa\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"south korea\",\n",
    "        \"alts\": [\"republic of korea\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"spain\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sudan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"suriname\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"swaziland\",\n",
    "        \"alts\": [\"eswatini\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sweden\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"switzerland\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"syria\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"taiwan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tajikistan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tanzania\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"thailand\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"togo\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tonga\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"trinidad and tobago\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tunisia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"turkey\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"turkmenistan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tuvalu\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"uganda\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ukraine\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"united arab emirates\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"united kingdom\",\n",
    "        \"alts\": [\"uk\", \"great britain\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"united states of america\",\n",
    "        \"alts\": [\"usa\", \"united states\", \"us\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"uruguay\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"uzbekistan\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vanuatu\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"venezuela\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vietnam\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yemen\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zambia\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zimbabwe\",\n",
    "        \"alts\": []\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"city\",\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"amsterdam netherlands\",\n",
    "        \"alts\": [\"amsterdam\", \"amsterdam holland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"anaheim california\",\n",
    "        \"alts\": [\"anaheim\", \"anaheim ca\", \"anaheim usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"austin texas\",\n",
    "        \"alts\": [\"austin\", \"austin tx\", \"austin usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"auckland new zealand\",\n",
    "        \"alts\": [\"auckland\", \"auckland nz\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"asheville north carolina\",\n",
    "        \"alts\": [\"asheville\", \"asheville nc\", \"asheville usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ashgabat turkmenistan\",\n",
    "        \"alts\": [\"ashgabat\", \"ashgabad turkmenistan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"athens greece\",\n",
    "        \"alts\": [\"athens\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"athens georgia\",\n",
    "        \"alts\": [\"athens\", \"athens ga\", \"athens usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"atlanta georgia\",\n",
    "        \"alts\": [\"atlanta\", \"atlanta ga\", \"atlanta usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"antwerp belgium\",\n",
    "        \"alts\": [\"antwerp\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"adelaide australia\",\n",
    "        \"alts\": [\"adelaide\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"astana kazakhstan\",\n",
    "        \"alts\": [\"astana\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"asuncion paraguay\",\n",
    "        \"alts\": [\"asuncion\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"algiers algeria\",\n",
    "        \"alts\": [\"algiers\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"acapulco mexico\",\n",
    "        \"alts\": [\"acapulco\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ankara turkey\",\n",
    "        \"alts\": [\"ankara\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"baghdad iraq\",\n",
    "        \"alts\": [\"baghdad\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bangkok thailand\",\n",
    "        \"alts\": [\"bangkok\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"beijing china\",\n",
    "        \"alts\": [\"beijing\", \"peking\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"berlin germany\",\n",
    "        \"alts\": [\"berlin\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"boston massachusetts\",\n",
    "        \"alts\": [\"boston\", \"boston ma\", \"boston usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"buenos aires argentina\",\n",
    "        \"alts\": [\"buenos aires\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bursa turkey\",\n",
    "        \"alts\": [\"bursa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bucharest romania\",\n",
    "        \"alts\": [\"bucharest\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"baltimore maryland\",\n",
    "        \"alts\": [\"baltimore\", \"baltimore md\", \"baltimore usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"beirut lebanon\",\n",
    "        \"alts\": [\"beirut\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"belfast northern ireland\",\n",
    "        \"alts\": [\"belfast\", \"belfast uk\", \"belfast united kingdom\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bratislava slovakia\",\n",
    "        \"alts\": [\"bratislava\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"belgrade serbia\",\n",
    "        \"alts\": [\"belgrade\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"budapest hungary\",\n",
    "        \"alts\": [\"budapest\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"baku azerbaijan\",\n",
    "        \"alts\": [\"baku\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bordeaux france\",\n",
    "        \"alts\": [\"bordeaux\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"busan south korea\",\n",
    "        \"alts\": [\"busan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"brussels belgium\",\n",
    "        \"alts\": [\"brussels\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"bangalore india\",\n",
    "        \"alts\": [\"bangalore\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"calgary canada\",\n",
    "        \"alts\": [\"calgary\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"chicago illinois\",\n",
    "        \"alts\": [\"chicago\", \"chi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"copenhagen denmark\",\n",
    "        \"alts\": [\"copenhagen\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"columbus ohio\",\n",
    "        \"alts\": [\"columbus\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cologne germany\",\n",
    "        \"alts\": [\"cologne\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cairo egypt\",\n",
    "        \"alts\": [\"cairo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cape town south africa\",\n",
    "        \"alts\": [\"cape town\", \"cape town sa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"caracas venezuela\",\n",
    "        \"alts\": [\"caracas\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cleveland ohio\",\n",
    "        \"alts\": [\"cleveland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cork ireland\",\n",
    "        \"alts\": [\"cork\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"christchurch new zealand\",\n",
    "        \"alts\": [\"christchurch\", \"christchurch nz\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"casablanca morocco\",\n",
    "        \"alts\": [\"casablanca\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"chengdu china\",\n",
    "        \"alts\": [\"chengdu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cannes france\",\n",
    "        \"alts\": [\"cannes\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"canberra australia\",\n",
    "        \"alts\": [\"canberra\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dallas texas\",\n",
    "        \"alts\": [\"dallas\", \"dallas tx\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dubai united arab emirates\",\n",
    "        \"alts\": [\"dubai\", \"dubai uae\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dhaka bangladesh\",\n",
    "        \"alts\": [\"dhaka\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dakar senegal\",\n",
    "        \"alts\": [\"dakar\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"delhi india\",\n",
    "        \"alts\": [\"delhi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"durban south africa\",\n",
    "        \"alts\": [\"durban\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dublin ireland\",\n",
    "        \"alts\": [\"dublin\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dalian china\",\n",
    "        \"alts\": [\"dalian\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"doha qatar\",\n",
    "        \"alts\": [\"doha\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"denver colorado\",\n",
    "        \"alts\": [\"denver\", \"denver co\", \"denver usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dusseldorf germany\",\n",
    "        \"alts\": [\"dusseldorf\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"davao city philippines\",\n",
    "        \"alts\": [\"davao city\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"darwin australia\",\n",
    "        \"alts\": [\"darwin\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dunfermline scotland\",\n",
    "        \"alts\": [\"dunfermline\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"daegu south korea\",\n",
    "        \"alts\": [\"daegu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"damascus syria\",\n",
    "        \"alts\": [\"damascus\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dar es salaam tanzania\",\n",
    "        \"alts\": [\"dar es salaam\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"edinburgh scotland\",\n",
    "        \"alts\": [\"edinburgh\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"edmonton canada\",\n",
    "        \"alts\": [\"edmonton\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"essen germany\",\n",
    "        \"alts\": [\"essen\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"evora portugal\",\n",
    "        \"alts\": [\"evora\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ensenada mexico\",\n",
    "        \"alts\": [\"ensenada\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"el paso texas\",\n",
    "        \"alts\": [\"el paso\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"enugu nigeria\",\n",
    "        \"alts\": [\"enugu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"enschede netherlands\",\n",
    "        \"alts\": [\"enschede\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"eureka california\",\n",
    "        \"alts\": [\"eureka\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"erie pennsylvania\",\n",
    "        \"alts\": [\"erie\", \"erie pa\", \"erie usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"eilat israel\",\n",
    "        \"alts\": [\"eilat\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"essentuki russia\",\n",
    "        \"alts\": [\"essentuki\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"esbjerg denmark\",\n",
    "        \"alts\": [\"esbjerg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fez morocco\",\n",
    "        \"alts\": [\"fez\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"florence italy\",\n",
    "        \"alts\": [\"florence\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"frankfurt germany\",\n",
    "        \"alts\": [\"frankfurt\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fort worth texas\",\n",
    "        \"alts\": [\"fort worth\", \"forth worth tx\", \"fort worth usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fukuoka japan\",\n",
    "        \"alts\": [\"fukuoka\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"faisalabad pakistan\",\n",
    "        \"alts\": [\"faisalabad\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fujairah united arab emirates\",\n",
    "        \"alts\": [\"fujairah\", \"fujairah uae\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"funafuti tuvalu\",\n",
    "        \"alts\": [\"funafuti\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"florianopolis brazil\",\n",
    "        \"alts\": [\"florianopolis\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"flinders australia\",\n",
    "        \"alts\": [\"flinders\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"faro portugal\",\n",
    "        \"alts\": [\"faro\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fujairah united arab emirates\",\n",
    "        \"alts\": [\"fujairah\", \"fujairah uae\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fort mcmurray canada\",\n",
    "        \"alts\": [\"fort mcmurray\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fortaleza brazil\",\n",
    "        \"alts\": [\"fortaleza\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"friesland netherlands\",\n",
    "        \"alts\": [\"friesland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"funchal portugal\",\n",
    "        \"alts\": [\"funchal\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fuzhou china\",\n",
    "        \"alts\": [\"fuzhou\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fresno california\",\n",
    "        \"alts\": [\"fresno\", \"fresno ca\", \"fresno usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fermoy ireland\",\n",
    "        \"alts\": [\"fermoy\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fukushima japan\",\n",
    "        \"alts\": [\"fukushima\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"glasgow scotland\",\n",
    "        \"alts\": [\"glasgow\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guangzhou china\",\n",
    "        \"alts\": [\"guangzhou\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gdansk poland\",\n",
    "        \"alts\": [\"gdansk\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guatemala city guatemala\",\n",
    "        \"alts\": [\"guatemala city\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guwahati india\",\n",
    "        \"alts\": [\"guwahati\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gyeongju south korea\",\n",
    "        \"alts\": [\"gyeongju\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"genoa italy\",\n",
    "        \"alts\": [\"genoa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"grahamstown south africa\",\n",
    "        \"alts\": [\"grahamstown\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"guadalajara mexico\",\n",
    "        \"alts\": [\"guadalajara\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"geneva switzerland\",\n",
    "        \"alts\": [\"geneva\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"graz austria\",\n",
    "        \"alts\": [\"graz\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gwangju south korea\",\n",
    "        \"alts\": [\"gwangju\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"houston texas\",\n",
    "        \"alts\": [\"houston\", \"houston tx\", \"houston usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hamburg germany\",\n",
    "        \"alts\": [\"hamburg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hanoi vietnam\",\n",
    "        \"alts\": [\"hanoi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"helsinki finland\",\n",
    "        \"alts\": [\"helsinki\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ho chi minh city vietnam\",\n",
    "        \"alts\": [\"ho chi minh city\", \"ho chi minh\", \"saigon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"haifa israel\",\n",
    "        \"alts\": [\"haifa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"havana cuba\",\n",
    "        \"alts\": [\"havana\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hong kong china\",\n",
    "        \"alts\": [\"hong kong\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hobart australia\",\n",
    "        \"alts\": [\"hobart\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hangzhou china\",\n",
    "        \"alts\": [\"hangzhou\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hilo hawaii\",\n",
    "        \"alts\": [\"hilo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hermosillo mexico\",\n",
    "        \"alts\": [\"hermosillo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"honolulu hawaii\",\n",
    "        \"alts\": [\"honolulu\", \"honolulu hi\", \"honolulu usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"helsingborg sweden\",\n",
    "        \"alts\": [\"helsingborg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"hiroshima japan\",\n",
    "        \"alts\": [\"hiroshima\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"harare zimbabwe\",\n",
    "        \"alts\": [\"harare\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"istanbul turkey\",\n",
    "        \"alts\": [\"istanbul\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"indianapolis indiana\",\n",
    "        \"alts\": [\"indianapolis\", \"indianapolis in\", \"indianapolis usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ibadan nigeria\",\n",
    "        \"alts\": [\"ibadan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"istanbul turkey\",\n",
    "        \"alts\": [\"istanbul\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"indore india\",\n",
    "        \"alts\": [\"indore\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"izmir turkey\",\n",
    "        \"alts\": [\"izmir\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"isafahan iran\",\n",
    "        \"alts\": [\"isafahan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"incheon south korea\",\n",
    "        \"alts\": [\"incheon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"innsbruck austria\",\n",
    "        \"alts\": [\"innsbruck\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"islamabad pakistan\",\n",
    "        \"alts\": [\"islamabad\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ingolstadt germany\",\n",
    "        \"alts\": [\"ingolstadt\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"irvine california\",\n",
    "        \"alts\": [\"irvine\", \"irvine ca\", \"irvine usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"irkutsk russia\",\n",
    "        \"alts\": [\"irkutsk\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jakarta indonesia\",\n",
    "        \"alts\": [\"jakarta\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jerusalem israel\",\n",
    "        \"alts\": [\"jerusalem\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jacksonville florida\",\n",
    "        \"alts\": [\"jacksonville\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"johannesburg south africa\",\n",
    "        \"alts\": [\"johannesburg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jabalpur india\",\n",
    "        \"alts\": [\"jabalpur\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jinan china\",\n",
    "        \"alts\": [\"jinan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jeddah saudi arabia\",\n",
    "        \"alts\": [\"jeddah\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jalapa guatemala\",\n",
    "        \"alts\": [\"jalapa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jackson mississippi\",\n",
    "        \"alts\": [\"jackson\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"juarez mexico\",\n",
    "        \"alts\": [\"juarez\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jabalpur india\",\n",
    "        \"alts\": [\"jabalpur\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"jining china\",\n",
    "        \"alts\": [\"jining\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kampala uganda\",\n",
    "        \"alts\": [\"kampala\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kathmandu nepal\",\n",
    "        \"alts\": [\"kathmandu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kaunas lithuania\",\n",
    "        \"alts\": [\"kaunas\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kuala lumpur malaysia\",\n",
    "        \"alts\": [\"kuala lumpur\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kyoto japan\",\n",
    "        \"alts\": [\"kyoto\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kagoshima japan\",\n",
    "        \"alts\": [\"kagoshima\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"karachi pakistan\",\n",
    "        \"alts\": [\"karachi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kiev ukraine\",\n",
    "        \"alts\": [\"kiev\", \"kyiv\", \"kyiv ukraine\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kingston jamaica\",\n",
    "        \"alts\": [\"kingston\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kolkata india\",\n",
    "        \"alts\": [\"kolkata\", \"calcutta\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kunming china\",\n",
    "        \"alts\": [\"kunming\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kabul afghanistan\",\n",
    "        \"alts\": [\"kabul\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kyiv ukraine\",\n",
    "        \"alts\": [\"kyiv\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kawasaki japan\",\n",
    "        \"alts\": [\"kawasaki\"]\n",
    "      },\n",
    "    \n",
    "      {\n",
    "        \"keyword\": \"london england\",\n",
    "        \"alts\": [\"london\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"la paz bolivia\",\n",
    "        \"alts\": [\"la paz\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"los angeles california\",\n",
    "        \"alts\": [\"los angeles\", \"los angeles ca\", \"los angeles usa\",  \"la\" , \"la ca\", \"la california\", \"la usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lima peru\",\n",
    "        \"alts\": [\"lima\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lyon france\",\n",
    "        \"alts\": [\"lyon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lisbon portugal\",\n",
    "        \"alts\": [\"lisbon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"luanda angola\",\n",
    "        \"alts\": [\"luanda\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"liverpool england\",\n",
    "        \"alts\": [\"liverpool\", \"liverpool uk\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lagos nigeria\",\n",
    "        \"alts\": [\"lagos\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"leeds england\",\n",
    "        \"alts\": [\"leeds\", \"leeds uk\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ljubljana slovenia\",\n",
    "        \"alts\": [\"ljubljana\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lyon france\",\n",
    "        \"alts\": [\"lyon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lima peru\",\n",
    "        \"alts\": [\"lima\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lviv ukraine\",\n",
    "        \"alts\": [\"lviv\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"leipzig germany\",\n",
    "        \"alts\": [\"leipzig\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lusaka zambia\",\n",
    "        \"alts\": [\"lusaka\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lausanne switzerland\",\n",
    "        \"alts\": [\"lausanne\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"madrid spain\",\n",
    "        \"alts\": [\"madrid\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"manchester england\",\n",
    "        \"alts\": [\"manchester\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mexico city mexico\",\n",
    "        \"alts\": [\"mexico city\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"manila philippines\",\n",
    "        \"alts\": [\"manila\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"montreal canada\",\n",
    "        \"alts\": [\"montreal\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"milan italy\",\n",
    "        \"alts\": [\"milan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"moscow russia\",\n",
    "        \"alts\": [\"moscow\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"madrid spain\",\n",
    "        \"alts\": [\"madrid\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mumbai india\",\n",
    "        \"alts\": [\"mumbai\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"managua nicaragua\",\n",
    "        \"alts\": [\"managua\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"melbourne australia\",\n",
    "        \"alts\": [\"melbourne\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"marrakech morocco\",\n",
    "        \"alts\": [\"marrakech\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"miami florida\",\n",
    "        \"alts\": [\"miami\", \"miami fl\", \"miami usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"minneapolis minnesota\",\n",
    "        \"alts\": [\"minneapolis\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mecca saudi arabia\",\n",
    "        \"alts\": [\"mecca\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"melbourne australia\",\n",
    "        \"alts\": [\"melbourne\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"makati philippines\",\n",
    "        \"alts\": [\"makati\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"monterrey mexico\",\n",
    "        \"alts\": [\"monterrey\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nagoya japan\",\n",
    "        \"alts\": [\"nagoya\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"new york city\",\n",
    "        \"alts\": [\"new york city\", \"nyc\", \"new york\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nanjing china\",\n",
    "        \"alts\": [\"nanjing\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"new delhi india\",\n",
    "        \"alts\": [\"new delhi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nantes france\",\n",
    "        \"alts\": [\"nantes\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"noida india\",\n",
    "        \"alts\": [\"noida\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"newcastle upon tyne england\",\n",
    "        \"alts\": [\"newcastle\", \"newcastle upon tyne\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nice france\",\n",
    "        \"alts\": [\"nice\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nurumberg germany\",\n",
    "        \"alts\": [\"nurumberg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"new orleans louisiana\",\n",
    "        \"alts\": [\"new orleans\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nairobi kenya\",\n",
    "        \"alts\": [\"nairobi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"naples italy\",\n",
    "        \"alts\": [\"naples\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"noosa australia\",\n",
    "        \"alts\": [\"noosa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"osaka japan\",\n",
    "        \"alts\": [\"osaka\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oklahoma city oklahoma\",\n",
    "        \"alts\": [\"oklahoma city\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oslo norway\",\n",
    "        \"alts\": [\"oslo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oxford england\",\n",
    "        \"alts\": [\"oxford\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ottawa canada\",\n",
    "        \"alts\": [\"ottawa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"orsay france\",\n",
    "        \"alts\": [\"orsay\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"odessa ukraine\",\n",
    "        \"alts\": [\"odessa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oranjestad aruba\",\n",
    "        \"alts\": [\"oranjestad\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"orlando florida\",\n",
    "        \"alts\": [\"orlando\", \"orlando fl\", \"orlando usa\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ostrava czech republic\",\n",
    "        \"alts\": [\"ostrava\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oaxaca mexico\",\n",
    "        \"alts\": [\"oaxaca\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"otago new zealand\",\n",
    "        \"alts\": [\"otago\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ouagadougou burkina faso\",\n",
    "        \"alts\": [\"ouagadougou\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"odense denmark\",\n",
    "        \"alts\": [\"odense\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"oulu finland\",\n",
    "        \"alts\": [\"oulu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"paris france\",\n",
    "        \"alts\": [\"paris\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"prague czech republic\",\n",
    "        \"alts\": [\"prague\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"porto portugal\",\n",
    "        \"alts\": [\"porto\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"philadelphia pennsylvania\",\n",
    "        \"alts\": [\"philadelphia\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"pyeongyang north korea\",\n",
    "        \"alts\": [\"pyeongyang\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"perth australia\",\n",
    "        \"alts\": [\"perth\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"plovdiv bulgaria\",\n",
    "        \"alts\": [\"plovdiv\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"pattaya thailand\",\n",
    "        \"alts\": [\"pattaya\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"portland oregon\",\n",
    "        \"alts\": [\"portland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"phoenix arizona\",\n",
    "        \"alts\": [\"phoenix\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"porto alegre brazil\",\n",
    "        \"alts\": [\"porto alegre\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"peshawar pakistan\",\n",
    "        \"alts\": [\"peshawar\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"panama city panama\",\n",
    "        \"alts\": [\"panama city\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rome italy\",\n",
    "        \"alts\": [\"rome\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rio de janeiro brazil\",\n",
    "        \"alts\": [\"rio de janeiro\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"riyadh saudi arabia\",\n",
    "        \"alts\": [\"riyadh\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"reykjavik iceland\",\n",
    "        \"alts\": [\"reykjavik\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rotterdam netherlands\",\n",
    "        \"alts\": [\"rotterdam\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ras al khaimah united arab emirates\",\n",
    "        \"alts\": [\"ras al khaimah\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"raleigh north carolina\",\n",
    "        \"alts\": [\"raleigh\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"riga latvia\",\n",
    "        \"alts\": [\"riga\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rochester new york\",\n",
    "        \"alts\": [\"rochester\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"recife brazil\",\n",
    "        \"alts\": [\"recife\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"san francisco california\",\n",
    "        \"alts\": [\"san francisco\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sydney australia\",\n",
    "        \"alts\": [\"sydney\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"singapore\",\n",
    "        \"alts\": [\"singapore\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"seoul south korea\",\n",
    "        \"alts\": [\"seoul\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"stockholm sweden\",\n",
    "        \"alts\": [\"stockholm\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"santiago chile\",\n",
    "        \"alts\": [\"santiago\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"san diego california\",\n",
    "        \"alts\": [\"san diego\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"shanghai china\",\n",
    "        \"alts\": [\"shanghai\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sao paulo brazil\",\n",
    "        \"alts\": [\"sao paulo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"stuttgart germany\",\n",
    "        \"alts\": [\"stuttgart\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sevilla spain\",\n",
    "        \"alts\": [\"sevilla\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"saskatoon canada\",\n",
    "        \"alts\": [\"saskatoon\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"san salvador el salvador\",\n",
    "        \"alts\": [\"san salvador\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sofia bulgaria\",\n",
    "        \"alts\": [\"sofia\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"seattle washington\",\n",
    "        \"alts\": [\"seattle\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tokyo japan\",\n",
    "        \"alts\": [\"tokyo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"torino italy\",\n",
    "        \"alts\": [\"torino\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tunis tunisia\",\n",
    "        \"alts\": [\"tunis\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tashkent uzbekistan\",\n",
    "        \"alts\": [\"tashkent\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"toronto canada\",\n",
    "        \"alts\": [\"toronto\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tirana albania\",\n",
    "        \"alts\": [\"tirana\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tijuana mexico\",\n",
    "        \"alts\": [\"tijuana\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"turin italy\",\n",
    "        \"alts\": [\"turin\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tokyo japan\",\n",
    "        \"alts\": [\"tokyo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"thessaloniki greece\",\n",
    "        \"alts\": [\"thessaloniki\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"taegu south korea\",\n",
    "        \"alts\": [\"taegu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"taksim turkey\",\n",
    "        \"alts\": [\"taksim\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"taipei taiwan\",\n",
    "        \"alts\": [\"taipei\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tripoli libya\",\n",
    "        \"alts\": [\"tripoli\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"tokyo japan\",\n",
    "        \"alts\": [\"tokyo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ulaanbaatar mongolia\",\n",
    "        \"alts\": [\"ulaanbaatar\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ubud indonesia\",\n",
    "        \"alts\": [\"ubud\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"uppsala sweden\",\n",
    "        \"alts\": [\"uppsala\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"urumqi china\",\n",
    "        \"alts\": [\"urumqi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vaduz liechtenstein\",\n",
    "        \"alts\": [\"vaduz\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vancouver canada\",\n",
    "        \"alts\": [\"vancouver\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"valencia spain\",\n",
    "        \"alts\": [\"valencia\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vigo spain\",\n",
    "        \"alts\": [\"vigo\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"valparaiso chile\",\n",
    "        \"alts\": [\"valparaiso\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vladivostok russia\",\n",
    "        \"alts\": [\"vladivostok\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vienna austria\",\n",
    "        \"alts\": [\"vienna\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"vilnius lithuania\",\n",
    "        \"alts\": [\"vilnius\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"villarreal spain\",\n",
    "        \"alts\": [\"villarreal\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"washington dc\",\n",
    "        \"alts\": [\"washington dc\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"westminster england\",\n",
    "        \"alts\": [\"westminster\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"wilmington delaware\",\n",
    "        \"alts\": [\"wilmington\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"wroclaw poland\",\n",
    "        \"alts\": [\"wroclaw\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"warsaw poland\",\n",
    "        \"alts\": [\"warsaw\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"wellington new zealand\",\n",
    "        \"alts\": [\"wellington\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"winnipeg manitoba\",\n",
    "        \"alts\": [\"winnipeg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"warsaw poland\",\n",
    "        \"alts\": [\"warsaw\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"wuhan china\",\n",
    "        \"alts\": [\"wuhan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yokohama japan\",\n",
    "        \"alts\": [\"yokohama\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"york england\",\n",
    "        \"alts\": [\"york\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yaounde cameroon\",\n",
    "        \"alts\": [\"yaounde\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yuma arizona\",\n",
    "        \"alts\": [\"yuma\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ypres belgium\",\n",
    "        \"alts\": [\"ypres\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yakutsk russia\",\n",
    "        \"alts\": [\"yakutsk\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yerevan armenia\",\n",
    "        \"alts\": [\"yerevan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yanbu saudi arabia\",\n",
    "        \"alts\": [\"yanbu\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yogyakarta indonesia\",\n",
    "        \"alts\": [\"yogyakarta\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yekaterinburg russia\",\n",
    "        \"alts\": [\"yekaterinburg\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zacatecas mexico\",\n",
    "        \"alts\": [\"zacatecas\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zunyi china\",\n",
    "        \"alts\": [\"zunyi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zincantan mexico\",\n",
    "        \"alts\": [\"zincantan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zagreb croatia\",\n",
    "        \"alts\": [\"zagreb\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zeeland netherlands\",\n",
    "        \"alts\": [\"zeeland\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zhongshan china\",\n",
    "        \"alts\": [\"zhongshan\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zanzibar tanzania\",\n",
    "        \"alts\": [\"zanzibar\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zurich switzerland\",\n",
    "        \"alts\": [\"zurich\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zaragoza spain\",\n",
    "        \"alts\": [\"zaragoza\"]\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"landmark\",\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"denali\",\n",
    "        \"alts\": [\"mount mckinley\", \"mt mckinley\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount saint lias\",\n",
    "        \"alts\": [\"mt st elias\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount whitney\",\n",
    "        \"alts\": [\"mt whitney\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount rainier\",\n",
    "        \"alts\": [\"mt rainier\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"iztaccihuatl\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"grand teton\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"gannett peak\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount adams\",\n",
    "        \"alts\": [\"mt adams\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount saint helens\",\n",
    "        \"alts\": [\"mt st helens\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount shasta\",\n",
    "        \"alts\": [\"mt shasta\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount saint helens\",\n",
    "        \"alts\": [\"mt st helens\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"pikes peak\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"aconcagua\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"fitz roy\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cotopaxi\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"chimborazo\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mont blanc\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zugspitze\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount elbrus\",\n",
    "        \"alts\": [\"mt elbrus\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount etna\",\n",
    "        \"alts\": [\"mt etna\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"everest\",\n",
    "        \"alts\": [\"mt everest\", \"mount everest\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"k2\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"lhotse\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"makalu\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"cho oyu\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"manaslu\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"annapurna\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dhaulagiri\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nanga parbat\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kangchenjunga\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mount fuji\",\n",
    "        \"alts\": [\"fuji\", \"mt fuji\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"kilimanjaro\",\n",
    "        \"alts\": [\"mount kilimanjaro\", \"mt kilimanjaro\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"meru\",\n",
    "        \"alts\": [\"mount meru\", \"mt meru\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"aoraki\",\n",
    "        \"alts\": [\"mount cook\", \"mt cook\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"haleakala\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"puncak jaya\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"sumantri\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"amazon\",\n",
    "        \"alts\": [\"amazonas\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"colorado river\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"dnieper\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"ganges\",\n",
    "        \"alts\": [\"ganga\", \"ganges river\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"illinois river\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"mississippi river\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"nile\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"rhine\",\n",
    "        \"alts\": []\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yangtze river\",\n",
    "        \"alts\": [\"changjiang\", \"yangtze\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yellow river\",\n",
    "        \"alts\": [\"huang he\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"zambezi river\",\n",
    "        \"alts\": [\"zambezi\"]\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"yenisei river\",\n",
    "        \"alts\": [\"yenisei\"]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import json # JSONデータを扱うためのライブラリをインポート\n",
    "import os # OSに関する機能を提供するライブラリをインポート\n",
    "import pandas as pd # データ操作のためのpandasライブラリをインポート\n",
    "import random # ランダムな値を生成するためのライブラリをインポート\n",
    "import string # 文字列操作のためのライブラリをインポート\n",
    "import torch # PyTorchライブラリをインポート（深層学習用）\n",
    "\n",
    "from os import path # OSのpath機能をインポート\n",
    "from pathlib import Path # パス操作のためのPathクラスをインポート\n",
    "from random import choice # ランダムに選択するためのchoice関数をインポート\n",
    "from string import Template # テンプレート文字列操作のためのTemplateクラスをインポート\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # T5モデル用のトークナイザーとモデルをインポート\n",
    "\n",
    "# キーワードのJSONデータを定義\n",
    "KEYWORDS_JSON = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"category\": \"country\", # カテゴリ: 国\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"afghanistan\", # キーワード: アフガニスタン\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"albania\", # キーワード: アルバニア\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"algeria\", # キーワード: アルジェリア\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      ...\n",
    "      {\n",
    "        \"keyword\": \"zimbabwe\", # キーワード: ジンバブエ\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"city\", # カテゴリ: 都市\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"amsterdam netherlands\", # キーワード: アムステルダム, オランダ\n",
    "        \"alts\": [\"amsterdam\", \"amsterdam holland\"] # 代替単語: アムステルダム, アムステルダム・ホラント\n",
    "      },\n",
    "      ...\n",
    "      {\n",
    "        \"keyword\": \"zurich switzerland\", # キーワード: チューリッヒ, スイス\n",
    "        \"alts\": [\"zurich\"] # 代替単語: なし\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "\"\"\" # JSONの内容の終わり\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:27:53.698669Z",
     "iopub.status.busy": "2024-08-04T17:27:53.698244Z",
     "iopub.status.idle": "2024-08-04T17:27:58.293566Z",
     "shell.execute_reply": "2024-08-04T17:27:58.292771Z",
     "shell.execute_reply.started": "2024-08-04T17:27:53.698638Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json # JSONデータを扱うためのライブラリをインポート\n",
    "import os # OSに関する機能を提供するライブラリをインポート\n",
    "import pandas as pd # データ操作のためのpandasライブラリをインポート\n",
    "import random # ランダムな値を生成するためのライブラリをインポート\n",
    "import string # 文字列操作のためのライブラリをインポート\n",
    "import torch # PyTorchライブラリをインポート（深層学習用）\n",
    "\n",
    "from os import path # OSのpath機能をインポート\n",
    "from pathlib import Path # パス操作のためのPathクラスをインポート\n",
    "from random import choice # ランダムに選択するためのchoice関数をインポート\n",
    "from string import Template # テンプレート文字列操作のためのTemplateクラスをインポート\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration # T5モデル用のトークナイザーとモデルをインポート\n",
    "\n",
    "# キーワードのJSONデータを定義\n",
    "KEYWORDS_JSON = \"\"\"\n",
    "[\n",
    "  {\n",
    "    \"category\": \"country\", # カテゴリ: 国\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"afghanistan\", # キーワード: アフガニスタン\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"albania\", # キーワード: アルバニア\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      {\n",
    "        \"keyword\": \"algeria\", # キーワード: アルジェリア\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      },\n",
    "      ...\n",
    "      {\n",
    "        \"keyword\": \"zimbabwe\", # キーワード: ジンバブエ\n",
    "        \"alts\": [] # 代替単語: なし\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"city\", # カテゴリ: 都市\n",
    "    \"words\": [\n",
    "      {\n",
    "        \"keyword\": \"amsterdam netherlands\", # キーワード: アムステルダム, オランダ\n",
    "        \"alts\": [\"amsterdam\", \"amsterdam holland\"] # 代替単語: アムステルダム, アムステルダム・ホラント\n",
    "      },\n",
    "      ...\n",
    "      {\n",
    "        \"keyword\": \"zurich switzerland\", # キーワード: チューリッヒ, スイス\n",
    "        \"alts\": [\"zurich\"] # 代替単語: なし\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  ...\n",
    "]\n",
    "\"\"\" # JSONの内容の終わり"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a5a2f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keywords_data = json.loads(KEYWORDS_JSON)\n",
    "\n",
    "# Create a list to hold rows for the DataFrame\n",
    "rows = []\n",
    "\n",
    "# Flatten the JSON structure into rows\n",
    "for item in keywords_data:\n",
    "    category = item[\"category\"]\n",
    "    for word in item[\"words\"]:\n",
    "        rows.append({\n",
    "            \"keyword\": word[\"keyword\"],\n",
    "            \"category\": category,\n",
    "            \"continent\": \"\",  # You can add continent data if available\n",
    "            \"first_letter\": word[\"keyword\"][0].upper()  # First letter in uppercase\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "keywords = pd.DataFrame(rows)\n",
    "keywords.head()\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "keywords_data = json.loads(KEYWORDS_JSON) # JSON形式のデータをPythonの辞書として読み込む\n",
    "\n",
    "# DataFrameの行を格納するリストを作成\n",
    "rows = []\n",
    "\n",
    "# JSONの構造を行にフラット化する\n",
    "for item in keywords_data:\n",
    "    category = item[\"category\"] # カテゴリを取得\n",
    "    for word in item[\"words\"]:\n",
    "        rows.append({\n",
    "            \"keyword\": word[\"keyword\"], # キーワードを取得\n",
    "            \"category\": category, # カテゴリを設定\n",
    "            \"continent\": \"\",  # 大陸データがあれば追加可能\n",
    "            \"first_letter\": word[\"keyword\"][0].upper()  # 最初の文字を大文字に変換\n",
    "        })\n",
    "\n",
    "# DataFrameを作成\n",
    "keywords = pd.DataFrame(rows) # フラット化したデータからDataFrameを作成\n",
    "keywords.head() # DataFrameの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:28:44.925238Z",
     "iopub.status.busy": "2024-08-04T17:28:44.92465Z",
     "iopub.status.idle": "2024-08-04T17:28:44.955705Z",
     "shell.execute_reply": "2024-08-04T17:28:44.954593Z",
     "shell.execute_reply.started": "2024-08-04T17:28:44.925192Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_data = json.loads(KEYWORDS_JSON) # JSON形式のデータをPythonの辞書として読み込む\n",
    "\n",
    "# DataFrameの行を格納するリストを作成\n",
    "rows = []\n",
    "\n",
    "# JSONの構造を行にフラット化する\n",
    "for item in keywords_data:\n",
    "    category = item[\"category\"] # カテゴリを取得\n",
    "    for word in item[\"words\"]:\n",
    "        rows.append({\n",
    "            \"keyword\": word[\"keyword\"], # キーワードを取得\n",
    "            \"category\": category, # カテゴリを設定\n",
    "            \"continent\": \"\",  # 大陸データがあれば追加可能\n",
    "            \"first_letter\": word[\"keyword\"][0].upper()  # 最初の文字を大文字に変換\n",
    "        })\n",
    "\n",
    "# DataFrameを作成\n",
    "keywords = pd.DataFrame(rows) # フラット化したデータからDataFrameを作成\n",
    "keywords.head() # DataFrameの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea14590",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def wrap_text(text, max_width, font_size):\n",
    "    words = text.split()\n",
    "    lines = []\n",
    "    line = \"\"\n",
    "    for word in words:\n",
    "        test_line = f\"{line} {word}\".strip()\n",
    "        if len(test_line) * font_size > max_width and line:\n",
    "            lines.append(line)\n",
    "            line = word\n",
    "        else:\n",
    "            line = test_line\n",
    "    if line:\n",
    "        lines.append(line)\n",
    "    return lines\n",
    "\n",
    "def renderer(context):\n",
    "    # Unpack context\n",
    "    act = context['act']\n",
    "    agents = context['agents']\n",
    "    environment = context['environment']\n",
    "    frame = context['frame']\n",
    "    height = context.get('height', 800)\n",
    "    interactive = context['interactive']\n",
    "    is_interactive = context['is_interactive']\n",
    "    parent = context['parent']\n",
    "    step = context['step']\n",
    "    update = context['update']\n",
    "    width = context.get('width', 1200)\n",
    "\n",
    "    # Common Dimensions\n",
    "    max_width = 1200\n",
    "    max_height = 800\n",
    "    canvas_size = min(height, width)\n",
    "    unit = 8\n",
    "    offset = canvas_size * 0.1 if canvas_size > 400 else unit / 2\n",
    "    cell_size = (canvas_size - offset * 2) / 3\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(width / 100, height / 100))\n",
    "    ax.set_xlim(0, width)\n",
    "    ax.set_ylim(0, height)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    # Get state for the current step\n",
    "    try:\n",
    "        steps = environment['steps']\n",
    "        state = steps[step]\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error accessing environment steps: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"State:\", state)\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        print(\"State is not properly defined.\")\n",
    "        return\n",
    "\n",
    "    # Extract information from state\n",
    "    try:\n",
    "        observation = state['observation']\n",
    "        team1_index = len(observation['questions']) - 1\n",
    "        team2_index = len(observation['questions']) - 1\n",
    "\n",
    "        team1_question = observation['questions'][team1_index] if team1_index >= 0 else \"\"\n",
    "        team2_question = observation['questions'][team2_index] if team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_answer = observation['answers'][team1_index] if len(observation['questions']) == len(observation['answers']) and team1_index >= 0 else \"\"\n",
    "        team2_answer = observation['answers'][team2_index] if len(observation['questions']) == len(observation['answers']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_guess = observation['guesses'][team1_index] if len(observation['questions']) == len(observation['guesses']) and team1_index >= 0 else \"\"\n",
    "        team2_guess = observation['guesses'][team2_index] if len(observation['questions']) == len(observation['guesses']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "        team2_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error extracting data from state: {e}\")\n",
    "        return\n",
    "\n",
    "    info = environment.get('info', {})\n",
    "    team1_text = info.get('TeamNames', ['Team 1'])[0]\n",
    "    team2_text = info.get('TeamNames', ['Team 2'])[1]\n",
    "\n",
    "    # Canvas parameters\n",
    "    padding = 20\n",
    "    row_width = (min(max_width, width) - padding * 3 - 100) / 2\n",
    "    label_x = padding\n",
    "    team1_x = padding + 100\n",
    "    team2_x = padding * 2 + row_width + 100\n",
    "    line_height = 40\n",
    "    label_y = 120\n",
    "    question_y = 160\n",
    "    answer_y = 200\n",
    "    guess_y = 240\n",
    "    score_y = 280\n",
    "\n",
    "    # Font size\n",
    "    font_size = 20\n",
    "\n",
    "    # Draw text\n",
    "    try:\n",
    "        # Keyword Row\n",
    "        ax.text(label_x, line_height, f\"Keyword: {observation['keyword']}\", fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        # Team Row\n",
    "        ax.text(team1_x, line_height, team1_text, fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team2_x, line_height, team2_text, fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        # Question Row\n",
    "        ax.text(label_x, question_y, \"Question:\", fontsize=font_size, color='#FFFFFF')\n",
    "        wrapped_text1 = wrap_text(team1_question, row_width, font_size)\n",
    "        wrapped_text2 = wrap_text(team2_question, row_width, font_size)\n",
    "        for i, line in enumerate(wrapped_text1):\n",
    "            ax.text(team1_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF')\n",
    "        for i, line in enumerate(wrapped_text2):\n",
    "            ax.text(team2_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        # Answer Row\n",
    "        ax.text(label_x, answer_y, \"Answer:\", fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team1_x, answer_y, team1_answer, fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team2_x, answer_y, team2_answer, fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        # Guess Row\n",
    "        ax.text(label_x, guess_y, \"Guess:\", fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team1_x, guess_y, team1_guess, fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team2_x, guess_y, team2_guess, fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        # Reward Row\n",
    "        ax.text(label_x, score_y, \"Reward:\", fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team1_x, score_y, team1_reward, fontsize=font_size, color='#FFFFFF')\n",
    "        ax.text(team2_x, score_y, team2_reward, fontsize=font_size, color='#FFFFFF')\n",
    "\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Error during rendering: {e}\")\n",
    "\n",
    "# Example context for testing\n",
    "context = {\n",
    "    'act': lambda x: print(f\"Action: {x}\"),\n",
    "    'agents': [],\n",
    "    'environment': {\n",
    "        'steps': [\n",
    "            {'observation': {'questions': ['What is AI?', 'Define ML.'], 'answers': ['Artificial Intelligence', 'Machine Learning'], 'guesses': ['AI', 'ML'], 'keyword': 'AI'}, 'reward': 10},\n",
    "        ],\n",
    "        'info': {'TeamNames': ['Team Alpha', 'Team Beta']}\n",
    "    },\n",
    "    'frame': None,\n",
    "    'height': 800,\n",
    "    'interactive': True,\n",
    "    'is_interactive': lambda: True,\n",
    "    'parent': None,\n",
    "    'step': 0,\n",
    "    'update': lambda: None,\n",
    "    'width': 1200\n",
    "}\n",
    "\n",
    "renderer(context)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def wrap_text(text, max_width, font_size):\n",
    "    words = text.split() # テキストを単語に分割\n",
    "    lines = [] # 行を格納するリスト\n",
    "    line = \"\" # 行の初期化\n",
    "    for word in words:\n",
    "        test_line = f\"{line} {word}\".strip() # 次の行をテスト\n",
    "        if len(test_line) * font_size > max_width and line: # 最大幅を超えたら\n",
    "            lines.append(line) # 現在の行を保存\n",
    "            line = word # 新しい行を開始\n",
    "        else:\n",
    "            line = test_line # 行を更新\n",
    "    if line:\n",
    "        lines.append(line) # 最後の行を保存\n",
    "    return lines # 行を返す\n",
    "\n",
    "def renderer(context):\n",
    "    # コンテキストから必要な情報を取得\n",
    "    act = context['act']\n",
    "    agents = context['agents']\n",
    "    environment = context['environment']\n",
    "    frame = context['frame']\n",
    "    height = context.get('height', 800) # 高さの取得\n",
    "    interactive = context['interactive']\n",
    "    is_interactive = context['is_interactive']\n",
    "    parent = context['parent']\n",
    "    step = context['step']\n",
    "    update = context['update']\n",
    "    width = context.get('width', 1200) # 幅の取得\n",
    "\n",
    "    # 共通の寸法\n",
    "    max_width = 1200\n",
    "    max_height = 800\n",
    "    canvas_size = min(height, width) # 最小のキャンバスサイズ\n",
    "    unit = 8\n",
    "    offset = canvas_size * 0.1 if canvas_size > 400 else unit / 2 # オフセットの計算\n",
    "    cell_size = (canvas_size - offset * 2) / 3 # セルサイズの計算\n",
    "\n",
    "    # 図と軸を作成\n",
    "    fig, ax = plt.subplots(figsize=(width / 100, height / 100)) # 図のサイズを設定\n",
    "    ax.set_xlim(0, width) # x軸の範囲を設定\n",
    "    ax.set_ylim(0, height) # y軸の範囲を設定\n",
    "    ax.invert_yaxis() # y軸の反転\n",
    "    ax.set_axis_off() # 軸を非表示\n",
    "\n",
    "    # 現在のステップの状態を取得\n",
    "    try:\n",
    "        steps = environment['steps']\n",
    "        state = steps[step] # 現在のステップを取得\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error accessing environment steps: {e}\") # エラーメッセージ\n",
    "        return\n",
    "\n",
    "    print(\"State:\", state) # ステート情報を表示\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        print(\"State is not properly defined.\") # ステートが不正な場合のエラーメッセージ\n",
    "        return\n",
    "\n",
    "    # ステートから情報を抽出\n",
    "    try:\n",
    "        observation = state['observation']\n",
    "        team1_index = len(observation['questions']) - 1\n",
    "        team2_index = len(observation['questions']) - 1\n",
    "\n",
    "        team1_question = observation['questions'][team1_index] if team1_index >= 0 else \"\"\n",
    "        team2_question = observation['questions'][team2_index] if team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_answer = observation['answers'][team1_index] if len(observation['questions']) == len(observation['answers']) and team1_index >= 0 else \"\"\n",
    "        team2_answer = observation['answers'][team2_index] if len(observation['questions']) == len(observation['answers']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_guess = observation['guesses'][team1_index] if len(observation['questions']) == len(observation['guesses']) and team1_index >= 0 else \"\"\n",
    "        team2_guess = observation['guesses'][team2_index] if len(observation['questions']) == len(observation['guesses']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "        team2_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error extracting data from state: {e}\") # エラーメッセージ\n",
    "        return\n",
    "\n",
    "    info = environment.get('info', {})\n",
    "    team1_text = info.get('TeamNames', ['Team 1'])[0] # チーム1の名前を取得\n",
    "    team2_text = info.get('TeamNames', ['Team 2'])[1] # チーム2の名前を取得\n",
    "\n",
    "    # キャンバスパラメータ\n",
    "    padding = 20\n",
    "    row_width = (min(max_width, width) - padding * 3 - 100) / 2 # 行の幅を計算\n",
    "    label_x = padding # ラベルのx座標\n",
    "    team1_x = padding + 100 # チーム1のx座標\n",
    "    team2_x = padding * 2 + row_width + 100 # チーム2のx座標\n",
    "    line_height = 40 # 行の高さ\n",
    "    label_y = 120 # ラベルのy座標\n",
    "    question_y = 160 # 質問のy座標\n",
    "    answer_y = 200 # 回答のy座標\n",
    "    guess_y = 240 # 推測のy座標\n",
    "    score_y = 280 # スコアのy座標\n",
    "\n",
    "    # フォントサイズ\n",
    "    font_size = 20 # フォントのサイズ\n",
    "\n",
    "    # テキストを描画\n",
    "    try:\n",
    "        # キーワード行\n",
    "        ax.text(label_x, line_height, f\"Keyword: {observation['keyword']}\", fontsize=font_size, color='#FFFFFF') # キーワードを描画\n",
    "\n",
    "        # チーム行\n",
    "        ax.text(team1_x, line_height, team1_text, fontsize=font_size, color='#FFFFFF') # チーム1の名前を描画\n",
    "        ax.text(team2_x, line_height, team2_text, fontsize=font_size, color='#FFFFFF') # チーム2の名前を描画\n",
    "\n",
    "        # 質問行\n",
    "        ax.text(label_x, question_y, \"Question:\", fontsize=font_size, color='#FFFFFF') # 質問ラベルを描画\n",
    "        wrapped_text1 = wrap_text(team1_question, row_width, font_size) # チーム1の質問をラップ\n",
    "        wrapped_text2 = wrap_text(team2_question, row_width, font_size) # チーム2の質問をラップ\n",
    "        for i, line in enumerate(wrapped_text1):\n",
    "            ax.text(team1_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF') # チーム1のラップされた質問を描画\n",
    "        for i, line in enumerate(wrapped_text2):\n",
    "            ax.text(team2_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF') # チーム2のラップされた質問を描画\n",
    "\n",
    "        # 回答行\n",
    "        ax.text(label_x, answer_y, \"Answer:\", fontsize=font_size, color='#FFFFFF') # 回答ラベルを描画\n",
    "        ax.text(team1_x, answer_y, team1_answer, fontsize=font_size, color='#FFFFFF') # チーム1の回答を描画\n",
    "        ax.text(team2_x, answer_y, team2_answer, fontsize=font_size, color='#FFFFFF') # チーム2の回答を描画\n",
    "\n",
    "        # 推測行\n",
    "        ax.text(label_x, guess_y, \"Guess:\", fontsize=font_size, color='#FFFFFF') # 推測ラベルを描画\n",
    "        ax.text(team1_x, guess_y, team1_guess, fontsize=font_size, color='#FFFFFF') # チーム1の推測を描画\n",
    "        ax.text(team2_x, guess_y, team2_guess, fontsize=font_size, color='#FFFFFF') # チーム2の推測を描画\n",
    "\n",
    "        # 報酬行\n",
    "        ax.text(label_x, score_y, \"Reward:\", fontsize=font_size, color='#FFFFFF') # 報酬ラベルを描画\n",
    "        ax.text(team1_x, score_y, team1_reward, fontsize=font_size, color='#FFFFFF') # チーム1の報酬を描画\n",
    "        ax.text(team2_x, score_y, team2_reward, fontsize=font_size, color='#FFFFFF') # チーム2の報酬を描画\n",
    "\n",
    "        plt.show() # グラフを表示\n",
    "    except Exception as e:\n",
    "        print(f\"Error during rendering: {e}\") # 描画中のエラーメッセージ\n",
    "\n",
    "# テスト用のコンテキストの例\n",
    "context = {\n",
    "    'act': lambda x: print(f\"Action: {x}\"), # アクションを処理するための関数\n",
    "    'agents': [],\n",
    "    'environment': {\n",
    "        'steps': [\n",
    "            {'observation': {'questions': ['What is AI?', 'Define ML.'], 'answers': ['Artificial Intelligence', 'Machine Learning'], 'guesses': ['AI', 'ML'], 'keyword': 'AI'}, 'reward': 10}, # ステップデータ\n",
    "        ],\n",
    "        'info': {'TeamNames': ['Team Alpha', 'Team Beta']} # チーム名情報\n",
    "    },\n",
    "    'frame': None,\n",
    "    'height': 800, # 高さ\n",
    "    'interactive': True,\n",
    "    'is_interactive': lambda: True,\n",
    "    'parent': None,\n",
    "    'step': 0,\n",
    "    'update': lambda: None,\n",
    "    'width': 1200 # 幅\n",
    "}\n",
    "\n",
    "renderer(context) # 描画関数を呼び出す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:28:59.064722Z",
     "iopub.status.busy": "2024-08-04T17:28:59.064326Z",
     "iopub.status.idle": "2024-08-04T17:28:59.381764Z",
     "shell.execute_reply": "2024-08-04T17:28:59.380555Z",
     "shell.execute_reply.started": "2024-08-04T17:28:59.06469Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "def wrap_text(text, max_width, font_size):\n",
    "    words = text.split() # テキストを単語に分割\n",
    "    lines = [] # 行を格納するリスト\n",
    "    line = \"\" # 行の初期化\n",
    "    for word in words:\n",
    "        test_line = f\"{line} {word}\".strip() # 次の行をテスト\n",
    "        if len(test_line) * font_size > max_width and line: # 最大幅を超えたら\n",
    "            lines.append(line) # 現在の行を保存\n",
    "            line = word # 新しい行を開始\n",
    "        else:\n",
    "            line = test_line # 行を更新\n",
    "    if line:\n",
    "        lines.append(line) # 最後の行を保存\n",
    "    return lines # 行を返す\n",
    "\n",
    "def renderer(context):\n",
    "    # コンテキストから必要な情報を取得\n",
    "    act = context['act']\n",
    "    agents = context['agents']\n",
    "    environment = context['environment']\n",
    "    frame = context['frame']\n",
    "    height = context.get('height', 800) # 高さの取得\n",
    "    interactive = context['interactive']\n",
    "    is_interactive = context['is_interactive']\n",
    "    parent = context['parent']\n",
    "    step = context['step']\n",
    "    update = context['update']\n",
    "    width = context.get('width', 1200) # 幅の取得\n",
    "\n",
    "    # 共通の寸法\n",
    "    max_width = 1200\n",
    "    max_height = 800\n",
    "    canvas_size = min(height, width) # 最小のキャンバスサイズ\n",
    "    unit = 8\n",
    "    offset = canvas_size * 0.1 if canvas_size > 400 else unit / 2 # オフセットの計算\n",
    "    cell_size = (canvas_size - offset * 2) / 3 # セルサイズの計算\n",
    "\n",
    "    # 図と軸を作成\n",
    "    fig, ax = plt.subplots(figsize=(width / 100, height / 100)) # 図のサイズを設定\n",
    "    ax.set_xlim(0, width) # x軸の範囲を設定\n",
    "    ax.set_ylim(0, height) # y軸の範囲を設定\n",
    "    ax.invert_yaxis() # y軸の反転\n",
    "    ax.set_axis_off() # 軸を非表示\n",
    "\n",
    "    # 現在のステップの状態を取得\n",
    "    try:\n",
    "        steps = environment['steps']\n",
    "        state = steps[step] # 現在のステップを取得\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error accessing environment steps: {e}\") # エラーメッセージ\n",
    "        return\n",
    "\n",
    "    print(\"State:\", state) # ステート情報を表示\n",
    "\n",
    "    if not isinstance(state, dict):\n",
    "        print(\"State is not properly defined.\") # ステートが不正な場合のエラーメッセージ\n",
    "        return\n",
    "\n",
    "    # ステートから情報を抽出\n",
    "    try:\n",
    "        observation = state['observation']\n",
    "        team1_index = len(observation['questions']) - 1\n",
    "        team2_index = len(observation['questions']) - 1\n",
    "\n",
    "        team1_question = observation['questions'][team1_index] if team1_index >= 0 else \"\"\n",
    "        team2_question = observation['questions'][team2_index] if team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_answer = observation['answers'][team1_index] if len(observation['questions']) == len(observation['answers']) and team1_index >= 0 else \"\"\n",
    "        team2_answer = observation['answers'][team2_index] if len(observation['questions']) == len(observation['answers']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_guess = observation['guesses'][team1_index] if len(observation['questions']) == len(observation['guesses']) and team1_index >= 0 else \"\"\n",
    "        team2_guess = observation['guesses'][team2_index] if len(observation['questions']) == len(observation['guesses']) and team2_index >= 0 else \"\"\n",
    "\n",
    "        team1_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "        team2_reward = str(state['reward']) if state['reward'] != 0 else \"\"\n",
    "    except (IndexError, KeyError) as e:\n",
    "        print(f\"Error extracting data from state: {e}\") # エラーメッセージ\n",
    "        return\n",
    "\n",
    "    info = environment.get('info', {})\n",
    "    team1_text = info.get('TeamNames', ['Team 1'])[0] # チーム1の名前を取得\n",
    "    team2_text = info.get('TeamNames', ['Team 2'])[1] # チーム2の名前を取得\n",
    "\n",
    "    # キャンバスパラメータ\n",
    "    padding = 20\n",
    "    row_width = (min(max_width, width) - padding * 3 - 100) / 2 # 行の幅を計算\n",
    "    label_x = padding # ラベルのx座標\n",
    "    team1_x = padding + 100 # チーム1のx座標\n",
    "    team2_x = padding * 2 + row_width + 100 # チーム2のx座標\n",
    "    line_height = 40 # 行の高さ\n",
    "    label_y = 120 # ラベルのy座標\n",
    "    question_y = 160 # 質問のy座標\n",
    "    answer_y = 200 # 回答のy座標\n",
    "    guess_y = 240 # 推測のy座標\n",
    "    score_y = 280 # スコアのy座標\n",
    "\n",
    "    # フォントサイズ\n",
    "    font_size = 20 # フォントのサイズ\n",
    "\n",
    "    # テキストを描画\n",
    "    try:\n",
    "        # キーワード行\n",
    "        ax.text(label_x, line_height, f\"Keyword: {observation['keyword']}\", fontsize=font_size, color='#FFFFFF') # キーワードを描画\n",
    "\n",
    "        # チーム行\n",
    "        ax.text(team1_x, line_height, team1_text, fontsize=font_size, color='#FFFFFF') # チーム1の名前を描画\n",
    "        ax.text(team2_x, line_height, team2_text, fontsize=font_size, color='#FFFFFF') # チーム2の名前を描画\n",
    "\n",
    "        # 質問行\n",
    "        ax.text(label_x, question_y, \"Question:\", fontsize=font_size, color='#FFFFFF') # 質問ラベルを描画\n",
    "        wrapped_text1 = wrap_text(team1_question, row_width, font_size) # チーム1の質問をラップ\n",
    "        wrapped_text2 = wrap_text(team2_question, row_width, font_size) # チーム2の質問をラップ\n",
    "        for i, line in enumerate(wrapped_text1):\n",
    "            ax.text(team1_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF') # チーム1のラップされた質問を描画\n",
    "        for i, line in enumerate(wrapped_text2):\n",
    "            ax.text(team2_x, question_y - i * line_height, line, fontsize=font_size, color='#FFFFFF') # チーム2のラップされた質問を描画\n",
    "\n",
    "        # 回答行\n",
    "        ax.text(label_x, answer_y, \"Answer:\", fontsize=font_size, color='#FFFFFF') # 回答ラベルを描画\n",
    "        ax.text(team1_x, answer_y, team1_answer, fontsize=font_size, color='#FFFFFF') # チーム1の回答を描画\n",
    "        ax.text(team2_x, answer_y, team2_answer, fontsize=font_size, color='#FFFFFF') # チーム2の回答を描画\n",
    "\n",
    "        # 推測行\n",
    "        ax.text(label_x, guess_y, \"Guess:\", fontsize=font_size, color='#FFFFFF') # 推測ラベルを描画\n",
    "        ax.text(team1_x, guess_y, team1_guess, fontsize=font_size, color='#FFFFFF') # チーム1の推測を描画\n",
    "        ax.text(team2_x, guess_y, team2_guess, fontsize=font_size, color='#FFFFFF') # チーム2の推測を描画\n",
    "\n",
    "        # 報酬行\n",
    "        ax.text(label_x, score_y, \"Reward:\", fontsize=font_size, color='#FFFFFF') # 報酬ラベルを描画\n",
    "        ax.text(team1_x, score_y, team1_reward, fontsize=font_size, color='#FFFFFF') # チーム1の報酬を描画\n",
    "        ax.text(team2_x, score_y, team2_reward, fontsize=font_size, color='#FFFFFF') # チーム2の報酬を描画\n",
    "\n",
    "        plt.show() # グラフを表示\n",
    "    except Exception as e:\n",
    "        print(f\"Error during rendering: {e}\") # 描画中のエラーメッセージ\n",
    "\n",
    "# テスト用のコンテキストの例\n",
    "context = {\n",
    "    'act': lambda x: print(f\"Action: {x}\"), # アクションを処理するための関数\n",
    "    'agents': [],\n",
    "    'environment': {\n",
    "        'steps': [\n",
    "            {'observation': {'questions': ['What is AI?', 'Define ML.'], 'answers': ['Artificial Intelligence', 'Machine Learning'], 'guesses': ['AI', 'ML'], 'keyword': 'AI'}, 'reward': 10}, # ステップデータ\n",
    "        ],\n",
    "        'info': {'TeamNames': ['Team Alpha', 'Team Beta']} # チーム名情報\n",
    "    },\n",
    "    'frame': None,\n",
    "    'height': 800, # 高さ\n",
    "    'interactive': True,\n",
    "    'is_interactive': lambda: True,\n",
    "    'parent': None,\n",
    "    'step': 0,\n",
    "    'update': lambda: None,\n",
    "    'width': 1200 # 幅\n",
    "}\n",
    "\n",
    "renderer(context) # 描画関数を呼び出す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051bd9fd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "\n",
    "# Global variables and configuration\n",
    "model_name = \"abacusai/Llama-3-Smaug-8B\"  # Consider a smaller model if memory issues persist\n",
    "VERBOSE = True  # Set to True for debugging output\n",
    "\n",
    "\n",
    "# Load model and tokenizer with GPU support\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            config=config,\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\"  # Load the model to the appropriate device\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "        return model, tokenizer\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "        return None, None\n",
    "\n",
    "\n",
    "# Function to interact with LLM for yes/no questions\n",
    "def get_yes_no(question, keyword, tokenizer, model):\n",
    "    try:\n",
    "        # Construct the prompt message\n",
    "        if keyword in keywords.keyword.values:\n",
    "            row = keywords.loc[keywords.keyword == keyword].iloc[0]\n",
    "            category = row.category\n",
    "            continent = row.continent\n",
    "            negate = {\n",
    "                \"city\": \"It is not a country. It is not a landmark.\",\n",
    "                \"country\": \"It is not a city. It is not a landmark.\",\n",
    "                \"landmark\": \"It is not a city. It is not a country.\",\n",
    "            }\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a {category}. {negate[category]} This word has first letter {keyword[0]}. This {category} is located in {continent}. {question}\"\n",
    "        else:\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a thing. It is not a city. It is not a country. It is not a landmark. This word has first letter {keyword[0]}. {question}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer yes or no to the following question and nothing else.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "\n",
    "        # Apply chat template and tokenize\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda')\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        if pad_token_id is None:\n",
    "            pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "        # Generate response using mixed precision\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            generated_ids = model.generate(\n",
    "                model_inputs.input_ids,\n",
    "                attention_mask=model_inputs.attention_mask,\n",
    "                pad_token_id=pad_token_id,\n",
    "                max_new_tokens=1\n",
    "            )\n",
    "        \n",
    "        generated_ids = [\n",
    "            output_ids[len(model_inputs.input_ids[0]):] for output_ids in generated_ids\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        if not \"yes\" in response.lower():\n",
    "            response = \"no\"\n",
    "        else:\n",
    "            response = \"yes\"\n",
    "\n",
    "        return response\n",
    "    \n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\")\n",
    "        return \"no\"\n",
    "    \n",
    "def agent_fn(obs, cfg):\n",
    "    global keywords\n",
    "\n",
    "   \n",
    "\n",
    "    # Initialize response variable\n",
    "    response = \"no\"  # Set a default value for response\n",
    "    \n",
    "    try:\n",
    "        # Ensure keywords are loaded correctly\n",
    "       # try:\n",
    "            #keywords = pd.read_csv(\"/kaggle/input/updated-kaggle-keywords/keywords_v2.csv\")\n",
    "        #except FileNotFoundError:\n",
    "            #if VERBOSE:\n",
    "               # print(\"Keywords file not found. Using an empty DataFrame.\")\n",
    "           # keywords = pd.DataFrame(columns=[\"keyword\", \"category\", \"continent\", \"first_letter\"])  # Create an empty DataFrame with expected columns\n",
    "\n",
    "        if keywords.empty:\n",
    "            response = \"Unable to process due to missing keywords.\"\n",
    "            return response\n",
    "\n",
    "        # Initialize necessary variables\n",
    "        cat_guess = 0\n",
    "        con_guess = 0\n",
    "        let_guess = 0\n",
    "        category_yes = []\n",
    "        category_no = []\n",
    "        continent_yes = []\n",
    "        continent_no = []\n",
    "        first_letter_yes = []\n",
    "        first_letter_no = []\n",
    "        extra_guess = None\n",
    "\n",
    "        categories = [\"city\", \"country\", \"landmark\"]\n",
    "        continents = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"]\n",
    "\n",
    "        if obs.turnType == \"ask\":\n",
    "            if (cat_guess < 3) and (len(category_yes) == 0):\n",
    "                response = f\"Is the keyword the name of a {categories[cat_guess]}?\"\n",
    "                cat_guess += 1\n",
    "            elif (con_guess < 6) and (len(continent_yes) == 0):\n",
    "                category = \"place\"\n",
    "                if len(category_yes) == 1: \n",
    "                    category = category_yes[0]\n",
    "                response = f\"Is the {category} located in {continents[con_guess]}?\"\n",
    "                con_guess += 1\n",
    "            else:\n",
    "                IDX = keywords.category.isin(category_yes)\n",
    "                IDX = IDX & (keywords.continent.isin(continent_yes))\n",
    "                first_letters = list(keywords.loc[IDX, \"first_letter\"].value_counts().index.values)\n",
    "                if let_guess < len(first_letters):\n",
    "                    response = f\"Does the keyword begin with the letter {first_letters[let_guess]}?\"\n",
    "                else:\n",
    "                    IDX = keywords.guess == 0\n",
    "                    if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes))\n",
    "                    if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no))\n",
    "                    if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes))\n",
    "                    if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no))\n",
    "                    if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n",
    "                    if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n",
    "\n",
    "                    try:\n",
    "                        guess = keywords.loc[IDX].sample(1).index.values[0]\n",
    "                        keywords.loc[guess, 'guess'] = 1\n",
    "                        response = keywords.loc[guess, \"keyword\"]\n",
    "                    except:\n",
    "                        response = np.random.choice(keywords.keyword.values)\n",
    "                    extra_guess = response\n",
    "                    response = f\"Is it {response}?\"\n",
    "                let_guess += 1\n",
    "\n",
    "        elif obs.turnType == \"guess\":\n",
    "            category_yes = []\n",
    "            category_no = []\n",
    "            for k in range(cat_guess):\n",
    "                if obs.answers[k] == \"yes\":\n",
    "                    category_yes.append(categories[k])\n",
    "                else:\n",
    "                    category_no.append(categories[k])\n",
    "            if (cat_guess == 3) and (len(category_yes) == 0):\n",
    "                category_yes = [\"city\", \"country\", \"landmark\"]\n",
    "                category_no = []\n",
    "\n",
    "            continent_yes = []\n",
    "            continent_no = []\n",
    "            for k in range(con_guess):\n",
    "                if obs.answers[k + cat_guess] == \"yes\":\n",
    "                    continent_yes.append(continents[k])\n",
    "                else:\n",
    "                    continent_no.append(continents[k])\n",
    "            if (con_guess == 6) and (len(continent_yes) == 0):\n",
    "                continent_yes = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"]\n",
    "                continent_no = []\n",
    "\n",
    "            first_letter_yes = []\n",
    "            first_letter_no = []\n",
    "            for k in range(let_guess):\n",
    "                if k >= len(first_letters): continue\n",
    "                if obs.answers[k + cat_guess + con_guess] == \"yes\":\n",
    "                    first_letter_yes.append(first_letters[k])    \n",
    "                else:\n",
    "                    first_letter_no.append(first_letters[k])\n",
    "\n",
    "            IDX = keywords.guess == 0\n",
    "            if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes))\n",
    "            if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no))\n",
    "            if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes))\n",
    "            if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no))\n",
    "            if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n",
    "            if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n",
    "\n",
    "            try:\n",
    "                guess = keywords.loc[IDX].sample(1).index.values[0]\n",
    "                keywords.loc[guess, 'guess'] = 1\n",
    "                response = keywords.loc[guess, \"keyword\"]\n",
    "            except:\n",
    "                response = np.random.choice(keywords.keyword.values)\n",
    "\n",
    "            if (let_guess > 0) and (let_guess >= len(first_letters)) and (obs.answers[-1] == \"yes\"):\n",
    "                response = extra_guess\n",
    "\n",
    "        elif obs.turnType == \"answer\":\n",
    "            if obs.keyword.lower() in obs.questions[-1].lower():\n",
    "                response = \"yes\"\n",
    "            else:\n",
    "                response = get_yes_no(obs.questions[-1], obs.keyword, tokenizer, model)\n",
    "\n",
    "        else:\n",
    "            response = \"yes\"  # Default response if all else fails\n",
    "\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\")\n",
    "\n",
    "    return response  # Always return response, even if it's the default value\n",
    "\n",
    "class Observation:\n",
    "    def __init__(self, turnType, answers=None, keyword=None, questions=None):\n",
    "        self.turnType = turnType\n",
    "        self.answers = answers or []\n",
    "        self.keyword = keyword\n",
    "        self.questions = questions or []\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name)\n",
    "    \n",
    "    observation_object = Observation(\n",
    "        turnType=\"ask\",\n",
    "        questions=[\"Is it a country?\"]  # Example question\n",
    "    )\n",
    "    configuration_object = {}  # Add necessary configuration parameters\n",
    "    \n",
    "    response = agent_fn(observation_object, configuration_object)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # Clean up resources\n",
    "    del model, tokenizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import pandas as pd # pandasをインポート\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig # Transformersライブラリから必要なクラスをインポート\n",
    "import torch # PyTorchライブラリをインポート\n",
    "import numpy as np # NumPyライブラリをインポート\n",
    "import gc # ガーベジコレクションを管理するためのライブラリをインポート\n",
    "import os # OSに関する機能を提供するライブラリをインポート\n",
    "\n",
    "# グローバル変数および設定\n",
    "model_name = \"abacusai/Llama-3-Smaug-8B\"  # メモリの問題が発生する場合は小さいモデルを検討\n",
    "VERBOSE = True  # デバッグ出力用にTrueに設定\n",
    "\n",
    "# GPUサポートでモデルとトークナイザーをロードする関数\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name) # モデルの設定をロード\n",
    "        model = AutoModelForCausalLM.from_pretrained( # 条件付き生成用のモデルをロード\n",
    "            model_name,\n",
    "            config=config,\n",
    "            trust_remote_code=True, # リモートコードを信頼\n",
    "            device_map=\"auto\"  # 適切なデバイスにモデルを配置\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name) # トークナイザーをロード\n",
    "        model.eval()  # モデルを評価モードに設定\n",
    "        return model, tokenizer # モデルとトークナイザーを返す\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error loading model: {e}\") # エラーメッセージ\n",
    "        return None, None # エラーが発生した場合はNoneを返す\n",
    "\n",
    "# Yes/No質問用にLLMと対話する関数\n",
    "def get_yes_no(question, keyword, tokenizer, model):\n",
    "    try:\n",
    "        # プロンプトメッセージを構築\n",
    "        if keyword in keywords.keyword.values: # キーワードが存在する場合\n",
    "            row = keywords.loc[keywords.keyword == keyword].iloc[0] # キーワードに対応する行を取得\n",
    "            category = row.category # カテゴリを取得\n",
    "            continent = row.continent # 大陸情報を取得\n",
    "            negate = { # 否定要素を定義\n",
    "                \"city\": \"It is not a country. It is not a landmark.\",\n",
    "                \"country\": \"It is not a city. It is not a landmark.\",\n",
    "                \"landmark\": \"It is not a city. It is not a country.\",\n",
    "            }\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a {category}. {negate[category]} This word has first letter {keyword[0]}. This {category} is located in {continent}. {question}\"\n",
    "        else:\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a thing. It is not a city. It is not a country. It is not a landmark. This word has first letter {keyword[0]}. {question}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer yes or no to the following question and nothing else.\"}, # システムメッセージ\n",
    "            {\"role\": \"user\", \"content\": prompt} # ユーザープロンプト\n",
    "        ]\n",
    "\n",
    "        # チャットテンプレートを適用し、トークン化\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda') # トークン化した入力をGPUに転送\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id # パディングトークンIDを取得\n",
    "        if pad_token_id is None:\n",
    "            pad_token_id = tokenizer.eos_token_id # Noneの場合はEOSトークンIDを使用\n",
    "\n",
    "        # 混合精度を使用して応答を生成\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            generated_ids = model.generate(\n",
    "                model_inputs.input_ids,\n",
    "                attention_mask=model_inputs.attention_mask,\n",
    "                pad_token_id=pad_token_id,\n",
    "                max_new_tokens=1 # 新しいトークンの最大数を設定\n",
    "            )\n",
    "        \n",
    "        generated_ids = [\n",
    "            output_ids[len(model_inputs.input_ids[0]):] for output_ids in generated_ids # 生成されたIDを抽出\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] # 応答をデコード\n",
    "        if not \"yes\" in response.lower(): # 応答が「yes」でなければ\n",
    "            response = \"no\" # 「no」と返す\n",
    "        else:\n",
    "            response = \"yes\" # 「yes」と返す\n",
    "\n",
    "        return response # 最終応答を返す\n",
    "    \n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\") # エラーメッセージ\n",
    "        return \"no\" # エラー時は「no」を返す\n",
    "    \n",
    "def agent_fn(obs, cfg): # エージェント関数\n",
    "    global keywords # グローバル変数としてキーワードを参照\n",
    "\n",
    "    # 応答変数の初期化\n",
    "    response = \"no\"  # 応答のデフォルト値を設定\n",
    "    \n",
    "    try:\n",
    "        # キーワードが正しくロードされていることを確認\n",
    "        if keywords.empty: # キーワードが空の場合\n",
    "            response = \"Unable to process due to missing keywords.\" # エラーメッセージを設定\n",
    "            return response\n",
    "\n",
    "        # 初期化が必要な変数\n",
    "        cat_guess = 0  # カテゴリ推測用カウンタ\n",
    "        con_guess = 0  # 大陸推測用カウンタ\n",
    "        let_guess = 0  # 最初の文字推測用カウンタ\n",
    "        category_yes = [] # 「はい」回答のカテゴリリスト\n",
    "        category_no = [] # 「いいえ」回答のカテゴリリスト\n",
    "        continent_yes = [] # 「はい」回答の大陸リスト\n",
    "        continent_no = [] # 「いいえ」回答の大陸リスト\n",
    "        first_letter_yes = [] # 「はい」回答の最初の文字リスト\n",
    "        first_letter_no = [] # 「いいえ」回答の最初の文字リスト\n",
    "        extra_guess = None # 追加の推測\n",
    "\n",
    "        categories = [\"city\", \"country\", \"landmark\"] # カテゴリのリスト\n",
    "        continents = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"] # 大陸のリスト\n",
    "\n",
    "        if obs.turnType == \"ask\": # 問いかけの場合\n",
    "            if (cat_guess < 3) and (len(category_yes) == 0): # カテゴリの推測\n",
    "                response = f\"Is the keyword the name of a {categories[cat_guess]}?\" # 質問の構築\n",
    "                cat_guess += 1 # カテゴリカウンタの増加\n",
    "            elif (con_guess < 6) and (len(continent_yes) == 0): # 大陸の推測\n",
    "                category = \"place\" # 場所として初期化\n",
    "                if len(category_yes) == 1: \n",
    "                    category = category_yes[0] # 既存のカテゴリをセット\n",
    "                response = f\"Is the {category} located in {continents[con_guess]}?\" # 質問の構築\n",
    "                con_guess += 1 # 大陸カウンタの増加\n",
    "            else:\n",
    "                IDX = keywords.category.isin(category_yes) # カテゴリのインデックス\n",
    "                IDX = IDX & (keywords.continent.isin(continent_yes)) # 大陸のインデックス\n",
    "                first_letters = list(keywords.loc[IDX, \"first_letter\"].value_counts().index.values) # 最初の文字のリスト\n",
    "                if let_guess < len(first_letters): # 最初の文字がリストにある場合\n",
    "                    response = f\"Does the keyword begin with the letter {first_letters[let_guess]}?\" # 質問の構築\n",
    "                else:\n",
    "                    IDX = keywords.guess == 0 # 推測が初めての場合\n",
    "                    if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes)) # 「はい」回答対象カテゴリをフィルタ\n",
    "                    if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no)) # 「いいえ」回答対象カテゴリをフィルタ\n",
    "                    if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes)) # 「はい」回答対象大陸をフィルタ\n",
    "                    if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no)) # 「いいえ」回答対象大陸をフィルタ\n",
    "                    if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes)) # 「はい」回答対象最初の文字をフィルタ\n",
    "                    if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no)) # 「いいえ」回答対象最初の文字をフィルタ\n",
    "\n",
    "                    try:\n",
    "                        guess = keywords.loc[IDX].sample(1).index.values[0] # 推測を抽出\n",
    "                        keywords.loc[guess, 'guess'] = 1 # 推測マーク\n",
    "                        response = keywords.loc[guess, \"keyword\"] # 推測結果を取得\n",
    "                    except:\n",
    "                        response = np.random.choice(keywords.keyword.values) # ランダムな推測を生成\n",
    "                    extra_guess = response # 追加推測にセット\n",
    "                    response = f\"Is it {response}?\" # 質問の構築\n",
    "                let_guess += 1 # 最初の文字カウンタの増加\n",
    "\n",
    "        elif obs.turnType == \"guess\": # 推測の場合\n",
    "            category_yes = [] # 「はい」回答のカテゴリリストを初期化\n",
    "            category_no = [] # 「いいえ」回答のカテゴリリストを初期化\n",
    "            for k in range(cat_guess): # カテゴリ推測に対する回答を取得\n",
    "                if obs.answers[k] == \"yes\":\n",
    "                    category_yes.append(categories[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    category_no.append(categories[k]) # 「いいえ」回答を追加\n",
    "            if (cat_guess == 3) and (len(category_yes) == 0): # 全てのカテゴリが「いいえ」だった場合\n",
    "                category_yes = [\"city\", \"country\", \"landmark\"] # すべてのカテゴリを対象にする\n",
    "                category_no = [] # 「いいえ」リストをクリア\n",
    "\n",
    "            continent_yes = [] # 大陸「はい」リストを初期化\n",
    "            continent_no = [] # 大陸「いいえ」リストを初期化\n",
    "            for k in range(con_guess): # 大陸推測に対する回答を取得\n",
    "                if obs.answers[k + cat_guess] == \"yes\":\n",
    "                    continent_yes.append(continents[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    continent_no.append(continents[k]) # 「いいえ」回答を追加\n",
    "            if (con_guess == 6) and (len(continent_yes) == 0): # 全ての大陸が「いいえ」だった場合\n",
    "                continent_yes = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"] # すべての大陸を対象にする\n",
    "                continent_no = [] # 「いいえ」リストをクリア\n",
    "\n",
    "            first_letter_yes = [] # 最初の文字「はい」リストを初期化\n",
    "            first_letter_no = [] # 最初の文字「いいえ」リストを初期化\n",
    "            for k in range(let_guess): # 最初の文字推測に対する回答を取得\n",
    "                if k >= len(first_letters): continue # 文字数がオーバーしている場合、スキップ\n",
    "                if obs.answers[k + cat_guess + con_guess] == \"yes\":\n",
    "                    first_letter_yes.append(first_letters[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    first_letter_no.append(first_letters[k]) # 「いいえ」回答を追加\n",
    "\n",
    "            # フィルタリング条件を適用\n",
    "            IDX = keywords.guess == 0\n",
    "            if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes))\n",
    "            if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no))\n",
    "            if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes))\n",
    "            if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no))\n",
    "            if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n",
    "            if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n",
    "\n",
    "            try:\n",
    "                guess = keywords.loc[IDX].sample(1).index.values[0] # 推測を抽出\n",
    "                keywords.loc[guess, 'guess'] = 1 # 推測マーク\n",
    "                response = keywords.loc[guess, \"keyword\"] # 推測結果を取得\n",
    "            except:\n",
    "                response = np.random.choice(keywords.keyword.values) # ランダムな推測を生成\n",
    "\n",
    "            if (let_guess > 0) and (let_guess >= len(first_letters)) and (obs.answers[-1] == \"yes\"): # 最後の回答が「はい」の場合\n",
    "                response = extra_guess # 追加の推測を応答\n",
    "\n",
    "        elif obs.turnType == \"answer\": # 回答の場合\n",
    "            if obs.keyword.lower() in obs.questions[-1].lower(): # キーワードが質問に含まれている場合\n",
    "                response = \"yes\" # 「はい」と応答\n",
    "            else:\n",
    "                response = get_yes_no(obs.questions[-1], obs.keyword, tokenizer, model) # LLMに問い合わせ\n",
    "\n",
    "        else:\n",
    "            response = \"yes\"  # すべて外れた場合のデフォルト応答\n",
    "\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\") # エラーメッセージ\n",
    "\n",
    "    return response  # 応答を常に返す\n",
    "\n",
    "class Observation: # 観察クラスの定義\n",
    "    def __init__(self, turnType, answers=None, keyword=None, questions=None):\n",
    "        self.turnType = turnType\n",
    "        self.answers = answers or [] # 回答リスト\n",
    "        self.keyword = keyword\n",
    "        self.questions = questions or [] # 質問リスト\n",
    "\n",
    "# 使用例\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name) # モデルとトークナイザーをロード\n",
    "    \n",
    "    observation_object = Observation( # 観察オブジェクトを作成\n",
    "        turnType=\"ask\",\n",
    "        questions=[\"Is it a country?\"]  # 質問の例\n",
    "    )\n",
    "    configuration_object = {}  # 必要な設定パラメータを追加\n",
    "    \n",
    "    response = agent_fn(observation_object, configuration_object) # エージェント関数を呼び出す\n",
    "    print(f\"Agent response: {response}\") # エージェントの応答を表示\n",
    "\n",
    "    # リソースをクリーンアップ\n",
    "    del model, tokenizer\n",
    "    gc.collect() # ガーベジコレクションを実行\n",
    "    torch.cuda.empty_cache() # CUDAキャッシュをクリア\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:29:07.156268Z",
     "iopub.status.busy": "2024-08-04T17:29:07.155923Z",
     "iopub.status.idle": "2024-08-04T17:31:35.139258Z",
     "shell.execute_reply": "2024-08-04T17:31:35.138294Z",
     "shell.execute_reply.started": "2024-08-04T17:29:07.156242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd # pandasをインポート\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig # Transformersライブラリから必要なクラスをインポート\n",
    "import torch # PyTorchライブラリをインポート\n",
    "import numpy as np # NumPyライブラリをインポート\n",
    "import gc # ガーベジコレクションを管理するためのライブラリをインポート\n",
    "import os # OSに関する機能を提供するライブラリをインポート\n",
    "\n",
    "# グローバル変数および設定\n",
    "model_name = \"abacusai/Llama-3-Smaug-8B\"  # メモリの問題が発生する場合は小さいモデルを検討\n",
    "VERBOSE = True  # デバッグ出力用にTrueに設定\n",
    "\n",
    "# GPUサポートでモデルとトークナイザーをロードする関数\n",
    "def load_model_and_tokenizer(model_name):\n",
    "    try:\n",
    "        config = AutoConfig.from_pretrained(model_name) # モデルの設定をロード\n",
    "        model = AutoModelForCausalLM.from_pretrained( # 条件付き生成用のモデルをロード\n",
    "            model_name,\n",
    "            config=config,\n",
    "            trust_remote_code=True, # リモートコードを信頼\n",
    "            device_map=\"auto\"  # 適切なデバイスにモデルを配置\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name) # トークナイザーをロード\n",
    "        model.eval()  # モデルを評価モードに設定\n",
    "        return model, tokenizer # モデルとトークナイザーを返す\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error loading model: {e}\") # エラーメッセージ\n",
    "        return None, None # エラーが発生した場合はNoneを返す\n",
    "\n",
    "# Yes/No質問用にLLMと対話する関数\n",
    "def get_yes_no(question, keyword, tokenizer, model):\n",
    "    try:\n",
    "        # プロンプトメッセージを構築\n",
    "        if keyword in keywords.keyword.values: # キーワードが存在する場合\n",
    "            row = keywords.loc[keywords.keyword == keyword].iloc[0] # キーワードに対応する行を取得\n",
    "            category = row.category # カテゴリを取得\n",
    "            continent = row.continent # 大陸情報を取得\n",
    "            negate = { # 否定要素を定義\n",
    "                \"city\": \"It is not a country. It is not a landmark.\",\n",
    "                \"country\": \"It is not a city. It is not a landmark.\",\n",
    "                \"landmark\": \"It is not a city. It is not a country.\",\n",
    "            }\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a {category}. {negate[category]} This word has first letter {keyword[0]}. This {category} is located in {continent}. {question}\"\n",
    "        else:\n",
    "            prompt = f\"We are playing 20 questions. The keyword is {keyword}. It is a thing. It is not a city. It is not a country. It is not a landmark. This word has first letter {keyword[0]}. {question}\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Answer yes or no to the following question and nothing else.\"}, # システムメッセージ\n",
    "            {\"role\": \"user\", \"content\": prompt} # ユーザープロンプト\n",
    "        ]\n",
    "\n",
    "        # チャットテンプレートを適用し、トークン化\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = tokenizer([text], return_tensors=\"pt\").to('cuda') # トークン化した入力をGPUに転送\n",
    "\n",
    "        pad_token_id = tokenizer.pad_token_id # パディングトークンIDを取得\n",
    "        if pad_token_id is None:\n",
    "            pad_token_id = tokenizer.eos_token_id # Noneの場合はEOSトークンIDを使用\n",
    "\n",
    "        # 混合精度を使用して応答を生成\n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            generated_ids = model.generate(\n",
    "                model_inputs.input_ids,\n",
    "                attention_mask=model_inputs.attention_mask,\n",
    "                pad_token_id=pad_token_id,\n",
    "                max_new_tokens=1 # 新しいトークンの最大数を設定\n",
    "            )\n",
    "        \n",
    "        generated_ids = [\n",
    "            output_ids[len(model_inputs.input_ids[0]):] for output_ids in generated_ids # 生成されたIDを抽出\n",
    "        ]\n",
    "\n",
    "        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] # 応答をデコード\n",
    "        if not \"yes\" in response.lower(): # 応答が「yes」でなければ\n",
    "            response = \"no\" # 「no」と返す\n",
    "        else:\n",
    "            response = \"yes\" # 「yes」と返す\n",
    "\n",
    "        return response # 最終応答を返す\n",
    "    \n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\") # エラーメッセージ\n",
    "        return \"no\" # エラー時は「no」を返す\n",
    "    \n",
    "def agent_fn(obs, cfg): # エージェント関数\n",
    "    global keywords # グローバル変数としてキーワードを参照\n",
    "\n",
    "    # 応答変数の初期化\n",
    "    response = \"no\"  # 応答のデフォルト値を設定\n",
    "    \n",
    "    try:\n",
    "        # キーワードが正しくロードされていることを確認\n",
    "        if keywords.empty: # キーワードが空の場合\n",
    "            response = \"Unable to process due to missing keywords.\" # エラーメッセージを設定\n",
    "            return response\n",
    "\n",
    "        # 初期化が必要な変数\n",
    "        cat_guess = 0  # カテゴリ推測用カウンタ\n",
    "        con_guess = 0  # 大陸推測用カウンタ\n",
    "        let_guess = 0  # 最初の文字推測用カウンタ\n",
    "        category_yes = [] # 「はい」回答のカテゴリリスト\n",
    "        category_no = [] # 「いいえ」回答のカテゴリリスト\n",
    "        continent_yes = [] # 「はい」回答の大陸リスト\n",
    "        continent_no = [] # 「いいえ」回答の大陸リスト\n",
    "        first_letter_yes = [] # 「はい」回答の最初の文字リスト\n",
    "        first_letter_no = [] # 「いいえ」回答の最初の文字リスト\n",
    "        extra_guess = None # 追加の推測\n",
    "\n",
    "        categories = [\"city\", \"country\", \"landmark\"] # カテゴリのリスト\n",
    "        continents = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"] # 大陸のリスト\n",
    "\n",
    "        if obs.turnType == \"ask\": # 問いかけの場合\n",
    "            if (cat_guess < 3) and (len(category_yes) == 0): # カテゴリの推測\n",
    "                response = f\"Is the keyword the name of a {categories[cat_guess]}?\" # 質問の構築\n",
    "                cat_guess += 1 # カテゴリカウンタの増加\n",
    "            elif (con_guess < 6) and (len(continent_yes) == 0): # 大陸の推測\n",
    "                category = \"place\" # 場所として初期化\n",
    "                if len(category_yes) == 1: \n",
    "                    category = category_yes[0] # 既存のカテゴリをセット\n",
    "                response = f\"Is the {category} located in {continents[con_guess]}?\" # 質問の構築\n",
    "                con_guess += 1 # 大陸カウンタの増加\n",
    "            else:\n",
    "                IDX = keywords.category.isin(category_yes) # カテゴリのインデックス\n",
    "                IDX = IDX & (keywords.continent.isin(continent_yes)) # 大陸のインデックス\n",
    "                first_letters = list(keywords.loc[IDX, \"first_letter\"].value_counts().index.values) # 最初の文字のリスト\n",
    "                if let_guess < len(first_letters): # 最初の文字がリストにある場合\n",
    "                    response = f\"Does the keyword begin with the letter {first_letters[let_guess]}?\" # 質問の構築\n",
    "                else:\n",
    "                    IDX = keywords.guess == 0 # 推測が初めての場合\n",
    "                    if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes)) # 「はい」回答対象カテゴリをフィルタ\n",
    "                    if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no)) # 「いいえ」回答対象カテゴリをフィルタ\n",
    "                    if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes)) # 「はい」回答対象大陸をフィルタ\n",
    "                    if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no)) # 「いいえ」回答対象大陸をフィルタ\n",
    "                    if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes)) # 「はい」回答対象最初の文字をフィルタ\n",
    "                    if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no)) # 「いいえ」回答対象最初の文字をフィルタ\n",
    "\n",
    "                    try:\n",
    "                        guess = keywords.loc[IDX].sample(1).index.values[0] # 推測を抽出\n",
    "                        keywords.loc[guess, 'guess'] = 1 # 推測マーク\n",
    "                        response = keywords.loc[guess, \"keyword\"] # 推測結果を取得\n",
    "                    except:\n",
    "                        response = np.random.choice(keywords.keyword.values) # ランダムな推測を生成\n",
    "                    extra_guess = response # 追加推測にセット\n",
    "                    response = f\"Is it {response}?\" # 質問の構築\n",
    "                let_guess += 1 # 最初の文字カウンタの増加\n",
    "\n",
    "        elif obs.turnType == \"guess\": # 推測の場合\n",
    "            category_yes = [] # 「はい」回答のカテゴリリストを初期化\n",
    "            category_no = [] # 「いいえ」回答のカテゴリリストを初期化\n",
    "            for k in range(cat_guess): # カテゴリ推測に対する回答を取得\n",
    "                if obs.answers[k] == \"yes\":\n",
    "                    category_yes.append(categories[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    category_no.append(categories[k]) # 「いいえ」回答を追加\n",
    "            if (cat_guess == 3) and (len(category_yes) == 0): # 全てのカテゴリが「いいえ」だった場合\n",
    "                category_yes = [\"city\", \"country\", \"landmark\"] # すべてのカテゴリを対象にする\n",
    "                category_no = [] # 「いいえ」リストをクリア\n",
    "\n",
    "            continent_yes = [] # 大陸「はい」リストを初期化\n",
    "            continent_no = [] # 大陸「いいえ」リストを初期化\n",
    "            for k in range(con_guess): # 大陸推測に対する回答を取得\n",
    "                if obs.answers[k + cat_guess] == \"yes\":\n",
    "                    continent_yes.append(continents[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    continent_no.append(continents[k]) # 「いいえ」回答を追加\n",
    "            if (con_guess == 6) and (len(continent_yes) == 0): # 全ての大陸が「いいえ」だった場合\n",
    "                continent_yes = [\"Europe\", \"Asia\", \"North America\", \"Africa\", \"South America\", \"Australia\"] # すべての大陸を対象にする\n",
    "                continent_no = [] # 「いいえ」リストをクリア\n",
    "\n",
    "            first_letter_yes = [] # 最初の文字「はい」リストを初期化\n",
    "            first_letter_no = [] # 最初の文字「いいえ」リストを初期化\n",
    "            for k in range(let_guess): # 最初の文字推測に対する回答を取得\n",
    "                if k >= len(first_letters): continue # 文字数がオーバーしている場合、スキップ\n",
    "                if obs.answers[k + cat_guess + con_guess] == \"yes\":\n",
    "                    first_letter_yes.append(first_letters[k]) # 「はい」回答を追加\n",
    "                else:\n",
    "                    first_letter_no.append(first_letters[k]) # 「いいえ」回答を追加\n",
    "\n",
    "            # フィルタリング条件を適用\n",
    "            IDX = keywords.guess == 0\n",
    "            if len(category_yes) > 0: IDX = IDX & (keywords.category.isin(category_yes))\n",
    "            if len(category_no) > 0: IDX = IDX & (~keywords.category.isin(category_no))\n",
    "            if len(continent_yes) > 0: IDX = IDX & (keywords.continent.isin(continent_yes))\n",
    "            if len(continent_no) > 0: IDX = IDX & (~keywords.continent.isin(continent_no))\n",
    "            if len(first_letter_yes) > 0: IDX = IDX & (keywords.first_letter.isin(first_letter_yes))\n",
    "            if len(first_letter_no) > 0: IDX = IDX & (~keywords.first_letter.isin(first_letter_no))\n",
    "\n",
    "            try:\n",
    "                guess = keywords.loc[IDX].sample(1).index.values[0] # 推測を抽出\n",
    "                keywords.loc[guess, 'guess'] = 1 # 推測マーク\n",
    "                response = keywords.loc[guess, \"keyword\"] # 推測結果を取得\n",
    "            except:\n",
    "                response = np.random.choice(keywords.keyword.values) # ランダムな推測を生成\n",
    "\n",
    "            if (let_guess > 0) and (let_guess >= len(first_letters)) and (obs.answers[-1] == \"yes\"): # 最後の回答が「はい」の場合\n",
    "                response = extra_guess # 追加の推測を応答\n",
    "\n",
    "        elif obs.turnType == \"answer\": # 回答の場合\n",
    "            if obs.keyword.lower() in obs.questions[-1].lower(): # キーワードが質問に含まれている場合\n",
    "                response = \"yes\" # 「はい」と応答\n",
    "            else:\n",
    "                response = get_yes_no(obs.questions[-1], obs.keyword, tokenizer, model) # LLMに問い合わせ\n",
    "\n",
    "        else:\n",
    "            response = \"yes\"  # すべて外れた場合のデフォルト応答\n",
    "\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Error during agent execution: {e}\") # エラーメッセージ\n",
    "\n",
    "    return response  # 応答を常に返す\n",
    "\n",
    "class Observation: # 観察クラスの定義\n",
    "    def __init__(self, turnType, answers=None, keyword=None, questions=None):\n",
    "        self.turnType = turnType\n",
    "        self.answers = answers or [] # 回答リスト\n",
    "        self.keyword = keyword\n",
    "        self.questions = questions or [] # 質問リスト\n",
    "\n",
    "# 使用例\n",
    "if __name__ == \"__main__\":\n",
    "    model, tokenizer = load_model_and_tokenizer(model_name) # モデルとトークナイザーをロード\n",
    "    \n",
    "    observation_object = Observation( # 観察オブジェクトを作成\n",
    "        turnType=\"ask\",\n",
    "        questions=[\"Is it a country?\"]  # 質問の例\n",
    "    )\n",
    "    configuration_object = {}  # 必要な設定パラメータを追加\n",
    "    \n",
    "    response = agent_fn(observation_object, configuration_object) # エージェント関数を呼び出す\n",
    "    print(f\"Agent response: {response}\") # エージェントの応答を表示\n",
    "\n",
    "    # リソースをクリーンアップ\n",
    "    del model, tokenizer\n",
    "    gc.collect() # ガーベジコレクションを実行\n",
    "    torch.cuda.empty_cache() # CUDAキャッシュをクリア"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3374053",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!apt install pigz pv > /dev/null\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!apt install pigz pv > /dev/null # pigzとpvパッケージをインストール（出力は非表示）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:33:05.171424Z",
     "iopub.status.busy": "2024-08-04T17:33:05.170704Z",
     "iopub.status.idle": "2024-08-04T17:33:11.672209Z",
     "shell.execute_reply": "2024-08-04T17:33:11.671121Z",
     "shell.execute_reply.started": "2024-08-04T17:33:05.17139Z"
    }
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv > /dev/null # pigzとpvパッケージをインストール（出力は非表示）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc23095",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf /kaggle/working/submission.tar.gz -C /kaggle/input/gemma-2/pytorch/gemma-2-2b-it/1 .\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf /kaggle/working/submission.tar.gz -C /kaggle/input/gemma-2/pytorch/gemma-2-2b-it/1 . # データを圧縮し、出力される圧縮ファイルを作成するコマンド\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-04T17:35:22.361678Z",
     "iopub.status.busy": "2024-08-04T17:35:22.361022Z",
     "iopub.status.idle": "2024-08-04T17:37:15.077861Z",
     "shell.execute_reply": "2024-08-04T17:37:15.076612Z",
     "shell.execute_reply.started": "2024-08-04T17:35:22.361638Z"
    }
   },
   "outputs": [],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf /kaggle/working/submission.tar.gz -C /kaggle/input/gemma-2/pytorch/gemma-2-2b-it/1 . # データを圧縮し、出力される圧縮ファイルを作成するコマンド"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 76277,
     "modelInstanceId": 72240,
     "sourceId": 85979,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
