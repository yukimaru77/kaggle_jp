{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63f2a2db",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、Kaggleの「LLM 20 Questions」コンペティションに向けた基盤モデルを構築するために、Pythonパッケージ「rigging」と「vLLM」を利用しているスタートノートブックです。\n",
    "\n",
    "### 問題:\n",
    "コンペティションは、言語モデル（LLM）が「20の質問」ゲームをプレイする能力を評価するもので、入力に基づいて効果的な質問を生成し、正確な答えを導き出すことが要求されます。このノートブックは、LLMがそのタスクを達成するための効率的なフレームワークを構築することを目的としています。\n",
    "\n",
    "### 解決手法:\n",
    "1. **riggingライブラリ**: LLMのインタラクションを簡単に行うためのフレームワークで、複数のバックエンドLLMモデルを扱えるように構築されています。このフレームワークを使用することで、期待される出力を確認し、成功するまで再試行するパイプラインを設計できます。\n",
    "   \n",
    "2. **vLLMライブラリ**: LLMモデルをローカルでホストするためのツールで、効率的にモデルを実行することが可能です。本ノートブックでは、`llama3`の量子化モデルを使用し、ローカルでの実行を強化します。\n",
    "\n",
    "### 手法の実装:\n",
    "- ノートブックには、初期設定で必要なパッケージのインストールが含まれています。これには、`rigging`や`vLLM`が含まれ、これらをKaggle環境にの中で適切に配置します。\n",
    "- モデルの重みをHugging Faceからダウンロードし、リギングフレームワークを使用してモデルをテストします。\n",
    "- 質問を生成するためのLLMの挙動を定義するクラス（`Answer`、`Question`等）が設計され、期待される出力形式も指定されています。\n",
    "- 質問者エージェントのフローを作成し、ストラテジックな質問を生成する機能を実装します。\n",
    "\n",
    "このノートブックは、リギングとvLLMを統合して、LLMが効果的に「20の質問」ゲームに参加できるように設計されたものです。ノートブックを通じて、参加者は自身のボットのための強固な基盤を築くことができ、ゲームでのパフォーマンスを向上させるための応答生成に関する知見を得ることができます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f065cba",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの中で機械学習・深層学習の初心者がつまずきそうな専門用語について簡単な解説を示します。これは、コンペティションや使用されている技術の特有の文脈を意識し、あまり知られていないまたは実務的な経験がないと分かりづらい用語に焦点を当てました。\n",
    "\n",
    "1. **vLLM**：\n",
    "   vLLMは、非常に大規模な言語モデルを効率的にホスティング・実行するためのフレームワークです。特に、GPUリソースを最大限に活用し、低レイテンシで応答できるように設計されています。これにより、モデルのパフォーマンスを向上させることができます。\n",
    "\n",
    "2. **量子化モデル**：\n",
    "   量子化は、モデルのサイズや計算リソースを削減するための技術です。モデルの重みを低ビット数（例えば、16ビットや8ビット）で表現することで、計算速度を向上させ、ストレージの使用を減らすことができます。これにより、より軽量で実行しやすいモデルが実現します。\n",
    "\n",
    "3. **Pydantic**：\n",
    "   Pydanticは、データのバリデーションや設定管理のためのPythonライブラリです。特に、型ヒントを用いてデータモデルを定義し、データが期待される形式であるかどうかを確認するために使用されます。このライブラリを使うことで、コードの安全性と可読性を高められます。\n",
    "\n",
    "4. **XMLタグ (xml_tags, xml_example)**：\n",
    "   XML（拡張可能なマークアップ言語）タグは、データを構造化するための手段です。このノートブックでは、LLM（大規模言語モデル）の出力を特定のフォーマットに従って返すために、XMLを使用しています。ここでは、LLMが期待される出力形式を示すための例として用いられています。\n",
    "\n",
    "5. **非同期サポート (async)**：\n",
    "   非同期プログラミングは、処理の効率を高めるために、タスクが完了するのを待たずに次の処理を進める方法です。特に、I/O操作が伴う場合（ネットワーク通信など）に有効です。このノートブックでは、非同期関数を介してエージェントがテンプレートを使いながら相互作用を行います。\n",
    "\n",
    "6. **バリデータ (field_validator)**：\n",
    "   バリデータは、データが特定の条件を満たすことを確認するための関数です。Pydanticを使用する際に、モデルのフィールドに対してカスタム検証を実行するために定義されます。これにより、データの一貫性を保証することができます。\n",
    "\n",
    "7. **キーワードデータフレーム**：\n",
    "   データフレームは、行と列から構成されるデータ構造で、特にpandasライブラリでよく使用されます。このノートブックでは、20の質問ゲームにおけるキーワードに関する情報を保持するためのデータフレームが作成されています。\n",
    "\n",
    "8. **自己対戦 (self-play)**：\n",
    "   自己対戦は、エージェントが自身と対戦することで、ゲームの戦略や能力を向上させる方法です。この手法を使用することで、エージェントは他のプレイヤーと対戦する前に、自らの能力を試すことができます。\n",
    "\n",
    "9. **エピソード**：\n",
    "   コンペティションのコンテキストでは、エピソードはゲームの1つの完全なサイクルを指すことが多いです。つまり、質問を行い、回答を受け取り、その結果に基づいて推測を行う一連のプロセスを意味します。\n",
    "\n",
    "10. **合計20ラウンド**：\n",
    "    20の質問ゲームのルールに関連した概念で、各ゲームは20回の質問と回答を通じて進行します。プレイヤーはできるだけ少ないラウンドで正しいキーワードを当てることを目指します。\n",
    "\n",
    "これらの用語に対する理解を深めることで、ノートブックの内容やその背後にある技術に対する理解が一層深まるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465243e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# LLM 20 Questions Starter with Rigging\n",
    "\n",
    "This starter notebook shows how the python package rigging can be used to create a baseline submission for the competition. This setup uses the `llama3` quantized model using vLLM.\n",
    "\n",
    "## Update **June 10, 2024**\n",
    "- Updated code to work with rigging 2.0\n",
    "- Including non-llm question asking agent that leverages the known keywords **note this won't work well on the private leaderboard**. Answer agent uses LLM via rigging.\n",
    "\n",
    "## What is Rigging?\n",
    "\n",
    "Rigging is a lightweight LLM interaction framework built on Pydantic XML. The goal is to make leveraging LLMs in production pipelines as simple and effictive as possible. Rigging is perfectly fit for the 20 questions tasks as it can:\n",
    "1. Easily handle swapping out different backend LLM models.\n",
    "2. Design LLM querying pipelines that check for expected outputs and retry until successful.\n",
    "3. Modern python with type hints, async support, pydantic validation, serialization, etc.\n",
    "\n",
    "Star the repo here: https://github.com/dreadnode/rigging\n",
    "Read the documentation here: https://rigging.dreadnode.io/\n",
    "\n",
    "Rigging is built and maintained by [dreadnode](https://www.dreadnode.io/) where we use it daily for our work.\n",
    "\n",
    "An example rigging pipeline might look like this:\n",
    "```{python}\n",
    "chat = rg.get_generator('gpt-4o') \\\n",
    "    .chat(f\"Provide me the names of all the countries in South America that start with the letter A {Answer.xml_tags()} tags.\") \\\n",
    "    .until_parsed_as(Answer) \\\n",
    "    .run() \n",
    "```\n",
    "\n",
    "Generators can be created seemlessly with most major LLM apis, so long as you have api keys saved as env variables.\n",
    "```\n",
    "export OPENAI_API_KEY=...\n",
    "export TOGETHER_API_KEY=...\n",
    "export TOGETHERAI_API_KEY=...\n",
    "export MISTRAL_API_KEY=...\n",
    "export ANTHROPIC_API_KEY=...\n",
    "```\n",
    "\n",
    "For this competition we must run our model locally, luckily rigging has support to run models using transformers on the back end.\n",
    "\n",
    "# Setup\n",
    "\n",
    "Below is some of the setup for this notebook. Where we will:\n",
    "- Load secret tokens for huggingface and kaggle (optional)\n",
    "- Install required packages\n",
    "- Create a helper utility script for testing our vLLM server\n",
    "\n",
    "This notebooks uses some hidden tokens using kaggle's secrets. This is optional and not required to run the code.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# LLM 20 Questions スタートノートブックとリギング\n",
    "\n",
    "このスタートノートブックでは、Pythonパッケージ「rigging」を使用して、コンペティション用のベースライン提出を作成する方法を示します。このセットアップでは、`llama3`の量子化モデルをvLLMを使用して使用します。\n",
    "\n",
    "## 更新 **2024年6月10日**\n",
    "- rigging 2.0で動作するようにコードを更新\n",
    "- プライベートリーダーボードではうまく機能しない**既知のキーワードを活用する非LLM質問エージェントを含む**。回答エージェントは、riggingを介してLLMを使用します。\n",
    "\n",
    "## リギングとは？\n",
    "\n",
    "リギングは、Pydantic XMLに基づく軽量のLLMインタラクションフレームワークです。目的は、LLMをプロダクションパイプラインでできるだけ簡単かつ効果的に活用できるようにすることです。リギングは、20の質問タスクに理想的で、以下を実現します。\n",
    "1. 異なるバックエンドLLMモデルを簡単に切り替えられる。\n",
    "2. 期待される出力を確認し、成功するまで再試行するLLMクエリパイプラインを設計できる。\n",
    "3. 型ヒント、非同期サポート、Pydanticバリデーション、シリアライゼーションなどを備えたモダンなPythonを活用。\n",
    "\n",
    "こちらでリポジトリをスターしてください: https://github.com/dreadnode/rigging\n",
    "ドキュメントはここで読むことができます: https://rigging.dreadnode.io/\n",
    "\n",
    "リギングは、[dreadnode](https://www.dreadnode.io/)によって構築・維持されており、私たちは日常的にこれを使用しています。\n",
    "\n",
    "リギングパイプラインの例は次のようになります。\n",
    "```{python}\n",
    "chat = rg.get_generator('gpt-4o') \\\n",
    "    .chat(f\"南アメリカのAで始まる国名を教えてください {Answer.xml_tags()} タグ.\") \\\n",
    "    .until_parsed_as(Answer) \\\n",
    "    .run() \n",
    "```\n",
    "\n",
    "ジェネレーターは、ほとんどの主要なLLM APIとシームレスに作成できます。APIキーが環境変数として保存されている限りです。\n",
    "```\n",
    "export OPENAI_API_KEY=...\n",
    "export TOGETHER_API_KEY=...\n",
    "export TOGETHERAI_API_KEY=...\n",
    "export MISTRAL_API_KEY=...\n",
    "export ANTHROPIC_API_KEY=...\n",
    "```\n",
    "\n",
    "このコンペティションでは、モデルをローカルで実行する必要があるため、リギングはバックエンドでtransformersを使用してモデルを実行するためのサポートを提供しています。\n",
    "\n",
    "# セットアップ\n",
    "\n",
    "以下は、このノートブックのためのセットアップの一部です。ここでは以下のことを行います。\n",
    "- Huggingfaceとkaggleのための秘密のトークンをロード（オプション）\n",
    "- 必要なパッケージをインストール\n",
    "- vLLMサーバーをテストするための補助ユーティリティスクリプトを作成\n",
    "\n",
    "このノートブックでは、kaggleのシークレットを使用した隠しトークンをいくつか使用します。これはオプションであり、コードを実行するために必ずしも必要ではありません。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3396802f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()\n",
    "\n",
    "HF_TOKEN: str | None  = None\n",
    "KAGGLE_KEY: str | None = None\n",
    "KAGGLE_USERNAME: str | None = None\n",
    "    \n",
    "try:\n",
    "    HF_TOKEN = secrets.get_secret(\"HF_TOKEN\")\n",
    "    KAGGLE_KEY = secrets.get_secret(\"KAGGLE_KEY\")\n",
    "    KAGGLE_USERNAME = secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "except:\n",
    "    pass\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()\n",
    "\n",
    "HF_TOKEN: str | None  = None\n",
    "KAGGLE_KEY: str | None = None\n",
    "KAGGLE_USERNAME: str | None = None\n",
    "    \n",
    "try:\n",
    "    HF_TOKEN = secrets.get_secret(\"HF_TOKEN\")\n",
    "    KAGGLE_KEY = secrets.get_secret(\"KAGGLE_KEY\")\n",
    "    KAGGLE_USERNAME = secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "except:\n",
    "    pass\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:44:41.417183Z",
     "iopub.status.busy": "2024-06-18T18:44:41.416506Z",
     "iopub.status.idle": "2024-06-18T18:44:41.516324Z",
     "shell.execute_reply": "2024-06-18T18:44:41.51541Z",
     "shell.execute_reply.started": "2024-06-18T18:44:41.417155Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "secrets = UserSecretsClient()\n",
    "\n",
    "HF_TOKEN: str | None  = None\n",
    "KAGGLE_KEY: str | None = None\n",
    "KAGGLE_USERNAME: str | None = None\n",
    "    \n",
    "try:\n",
    "    HF_TOKEN = secrets.get_secret(\"HF_TOKEN\")\n",
    "    KAGGLE_KEY = secrets.get_secret(\"KAGGLE_KEY\")\n",
    "    KAGGLE_USERNAME = secrets.get_secret(\"KAGGLE_USERNAME\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1198d8",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Pip install\n",
    "We will install:\n",
    "- [rigging](https://github.com/dreadnode/rigging) Used to created our LLM pipelines for the competition.\n",
    "- [vLLM](https://github.com/vllm-project/vllm) For hosting our model locally as an independent service.\n",
    "\n",
    "We also use [uv](https://github.com/astral-sh/uv) which allows us to install these packages much faster.\n",
    "\n",
    "**Note:** We are installing these packages to the `/kaggle/tmp/lib` directory. We only do this for the purposes of the competition setup, where we will later need to include the files from this path in our submission zip. We also install the vllm dependencies to `/kaggle/tmp/srvlib`.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## パッケージのインストール\n",
    "- [rigging](https://github.com/dreadnode/rigging): コンペティション用のLLMパイプラインを作成するために使用します。\n",
    "- [vLLM](https://github.com/vllm-project/vllm): モデルをローカルで独立したサービスとしてホスティングします。\n",
    "\n",
    "また、[uv](https://github.com/astral-sh/uv)を使用しており、これによりこれらのパッケージをより速くインストールできます。\n",
    "\n",
    "**注意:** これらのパッケージは`/kaggle/tmp/lib`ディレクトリにインストールしています。これはコンペティションセットアップの目的のためであり、後で提出zipにこのパスからファイルを含める必要があります。また、vllmの依存関係も`/kaggle/tmp/srvlib`にインストールします。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3120b66",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Dependencies (uv for speed)\n",
    "!pip install uv==0.1.45\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/lib \\\n",
    "    rigging==2.0.0 \\\n",
    "    kaggle\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/srvlib \\\n",
    "    vllm==0.4.2 \\\n",
    "    numpy==1.26.4\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 依存関係（高速化のためのuv）\n",
    "!pip install uv==0.1.45\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/lib \\\n",
    "    rigging==2.0.0 \\\n",
    "    kaggle\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/srvlib \\\n",
    "    vllm==0.4.2 \\\n",
    "    numpy==1.26.4\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-18T18:44:41.518147Z",
     "iopub.status.busy": "2024-06-18T18:44:41.517895Z",
     "iopub.status.idle": "2024-06-18T18:45:50.112765Z",
     "shell.execute_reply": "2024-06-18T18:45:50.111214Z",
     "shell.execute_reply.started": "2024-06-18T18:44:41.518124Z"
    },
    "papermill": {
     "duration": 13.257308,
     "end_time": "2024-04-17T13:47:49.310664",
     "exception": false,
     "start_time": "2024-04-17T13:47:36.053356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 依存関係（高速化のためのuv）\n",
    "!pip install uv==0.1.45\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/lib \\\n",
    "    rigging==2.0.0 \\\n",
    "    kaggle\n",
    "\n",
    "!uv pip install -U \\\n",
    "    --python $(which python) \\\n",
    "    --target /kaggle/tmp/srvlib \\\n",
    "    vllm==0.4.2 \\\n",
    "    numpy==1.26.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571f2d1",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Download the LLM Locally\n",
    "\n",
    "Because this competition requires us to submit our code with model weights, we will first download the model weights using `snapshot_download` from huggingface.\n",
    "\n",
    "We are going to download the `solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ`. This is a Activation-aware Weight Quantization version of the model that is small enough to run in the competition requirements.\n",
    "\n",
    "**Note**: When using rigging in a normal situation this step would not be necessary, but we are downloading the weights seperately so that we can include them in our submission zip for the competition.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# モデルをローカルにダウンロード\n",
    "\n",
    "このコンペティションでは、モデルの重みを含むコードを提出する必要があるため、まずHuggingfaceの`snapshot_download`を使用してモデルの重みをダウンロードします。\n",
    "\n",
    "`solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ`をダウンロードします。これは、コンペティションの要件を満たすのに十分小さいモデルの活性化意識型重み量子化バージョンです。\n",
    "\n",
    "**注意:** 通常の状況でリギングを使用する際、このステップは必要ありませんが、コンペティションのために提出zipに含めるために別々に重みをダウンロードしています。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aefd8c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Download the model\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "if g_model_path.exists():\n",
    "    shutil.rmtree(g_model_path)\n",
    "g_model_path.mkdir(parents=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ\",\n",
    "    ignore_patterns=\"original*\",\n",
    "    local_dir=g_model_path,\n",
    "    local_dir_use_symlinks=False,\n",
    "    token=globals().get(\"HF_TOKEN\", None)\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルをダウンロード\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "if g_model_path.exists():\n",
    "    shutil.rmtree(g_model_path)\n",
    "g_model_path.mkdir(parents=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ\",\n",
    "    ignore_patterns=\"original*\",\n",
    "    local_dir=g_model_path,\n",
    "    local_dir_use_symlinks=False,\n",
    "    token=globals().get(\"HF_TOKEN\", None)\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-06-18T18:45:50.119389Z",
     "iopub.status.busy": "2024-06-18T18:45:50.119071Z",
     "iopub.status.idle": "2024-06-18T18:46:23.55105Z",
     "shell.execute_reply": "2024-06-18T18:46:23.550098Z",
     "shell.execute_reply.started": "2024-06-18T18:45:50.11936Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルをダウンロード\n",
    "\n",
    "from huggingface_hub import snapshot_download\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "if g_model_path.exists():\n",
    "    shutil.rmtree(g_model_path)\n",
    "g_model_path.mkdir(parents=True)\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ\",\n",
    "    ignore_patterns=\"original*\",\n",
    "    local_dir=g_model_path,\n",
    "    local_dir_use_symlinks=False,\n",
    "    token=globals().get(\"HF_TOKEN\", None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff53e24f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "We can see the model weights are stored in `/kaggle/tmp/model/`\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "モデルの重みは`/kaggle/tmp/model/`に保存されています。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f0ac49",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!ls -l /kaggle/tmp/model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!ls -l /kaggle/tmp/model\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:46:26.312229Z",
     "iopub.status.busy": "2024-06-18T18:46:26.311603Z",
     "iopub.status.idle": "2024-06-18T18:46:27.343572Z",
     "shell.execute_reply": "2024-06-18T18:46:27.342399Z",
     "shell.execute_reply.started": "2024-06-18T18:46:26.312197Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l /kaggle/tmp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20aa9eb",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Helper Utilities File\n",
    "\n",
    "These are helper functions we will use for starting our vLLM server.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ヘルパーユーティリティファイル\n",
    "\n",
    "これは、vLLMサーバーを起動するために使用するヘルパー関数です。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e13bae",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%writefile util.py\n",
    "\n",
    "# Helpers for starting the vLLM server\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def check_port(port: int) -> bool:\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            sock.settimeout(1)\n",
    "            result = sock.connect_ex(('localhost', port))\n",
    "            if result == 0:\n",
    "                return True\n",
    "    except socket.error:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def run_and_wait_for_port(\n",
    "    cmd: list[str], port: int, env: dict[str, str] | None, timeout: int = 60, debug: bool = False\n",
    ") -> subprocess.Popen:\n",
    "    \n",
    "    if check_port(port):\n",
    "        raise ValueError(f\"Port {port} is already open\")\n",
    "        \n",
    "    popen = subprocess.Popen(\n",
    "        cmd,\n",
    "        env={**os.environ, **(env or {})},\n",
    "        stdout=subprocess.DEVNULL if not debug else None,\n",
    "        stderr=subprocess.DEVNULL if not debug else None,\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        if check_port(port):\n",
    "            return popen\n",
    "        time.sleep(1)\n",
    "    \n",
    "    popen.terminate()\n",
    "    raise Exception(f\"Process did not open port {port} within {timeout} seconds.\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%writefile util.py\n",
    "\n",
    "# vLLMサーバーを起動するためのヘルパー\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def check_port(port: int) -> bool:\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            sock.settimeout(1)\n",
    "            result = sock.connect_ex(('localhost', port))\n",
    "            if result == 0:\n",
    "                return True\n",
    "    except socket.error:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def run_and_wait_for_port(\n",
    "    cmd: list[str], port: int, env: dict[str, str] | None, timeout: int = 60, debug: bool = False\n",
    ") -> subprocess.Popen:\n",
    "    \n",
    "    if check_port(port):\n",
    "        raise ValueError(f\"ポート {port} はすでにオープンです\")\n",
    "        \n",
    "    popen = subprocess.Popen(\n",
    "        cmd,\n",
    "        env={**os.environ, **(env or {})},\n",
    "        stdout=subprocess.DEVNULL if not debug else None,\n",
    "        stderr=subprocess.DEVNULL if not debug else None,\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        if check_port(port):\n",
    "            return popen\n",
    "        time.sleep(1)\n",
    "    \n",
    "    popen.terminate()\n",
    "    raise Exception(f\"プロセスが {timeout}秒以内にポート {port} を開かなかった。\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:46:28.861984Z",
     "iopub.status.busy": "2024-06-18T18:46:28.861242Z",
     "iopub.status.idle": "2024-06-18T18:46:34.72919Z",
     "shell.execute_reply": "2024-06-18T18:46:34.728213Z",
     "shell.execute_reply.started": "2024-06-18T18:46:28.861946Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile util.py\n",
    "\n",
    "# vLLMサーバーを起動するためのヘルパー\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def check_port(port: int) -> bool:\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:\n",
    "            sock.settimeout(1)\n",
    "            result = sock.connect_ex(('localhost', port))\n",
    "            if result == 0:\n",
    "                return True\n",
    "    except socket.error:\n",
    "        pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "def run_and_wait_for_port(\n",
    "    cmd: list[str], port: int, env: dict[str, str] | None, timeout: int = 60, debug: bool = False\n",
    ") -> subprocess.Popen:\n",
    "    \n",
    "    if check_port(port):\n",
    "        raise ValueError(f\"ポート {port} はすでにオープンです\")\n",
    "        \n",
    "    popen = subprocess.Popen(\n",
    "        cmd,\n",
    "        env={**os.environ, **(env or {})},\n",
    "        stdout=subprocess.DEVNULL if not debug else None,\n",
    "        stderr=subprocess.DEVNULL if not debug else None,\n",
    "    )\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while time.time() - start_time < timeout:\n",
    "        if check_port(port):\n",
    "            return popen\n",
    "        time.sleep(1)\n",
    "    \n",
    "    popen.terminate()\n",
    "    raise Exception(f\"プロセスが {timeout}秒以内にポート {port} を開かなかった。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b0d83f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Starting up our vLLM server for testing\n",
    "\n",
    "Our model will be hosted using a vLLM server. Below we will start up the notebook so we can understand how it works in the kaggle environment.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# vLLMサーバーをテストのために起動\n",
    "\n",
    "私たちのモデルはvLLMサーバーを使用してホストされます。以下でノートブックを起動し、Kaggle環境での動作を理解します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a379a136",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# vLLM paths and settings.\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import util\n",
    "\n",
    "util = importlib.reload(util)\n",
    "\n",
    "g_srvlib_path = Path(\"/kaggle/tmp/srvlib\")\n",
    "assert g_srvlib_path.exists()\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "assert g_model_path.exists()\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# vLLMのパスと設定\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import util\n",
    "\n",
    "util = importlib.reload(util)\n",
    "\n",
    "g_srvlib_path = Path(\"/kaggle/tmp/srvlib\")\n",
    "assert g_srvlib_path.exists()\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "assert g_model_path.exists()\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:46:34.731502Z",
     "iopub.status.busy": "2024-06-18T18:46:34.731125Z",
     "iopub.status.idle": "2024-06-18T18:46:34.740817Z",
     "shell.execute_reply": "2024-06-18T18:46:34.739992Z",
     "shell.execute_reply.started": "2024-06-18T18:46:34.73147Z"
    }
   },
   "outputs": [],
   "source": [
    "# vLLMのパスと設定\n",
    "\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import util\n",
    "\n",
    "util = importlib.reload(util)\n",
    "\n",
    "g_srvlib_path = Path(\"/kaggle/tmp/srvlib\")\n",
    "assert g_srvlib_path.exists()\n",
    "\n",
    "g_model_path = Path(\"/kaggle/tmp/model\")\n",
    "assert g_model_path.exists()\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705092d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Run the vLLM server using subprocess\n",
    "vllm = util.run_and_wait_for_port([\n",
    "    \"python\", \"-m\",\n",
    "    \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--enforce-eager\",\n",
    "    \"--model\", str(g_model_path),\n",
    "    \"--port\", str(g_vllm_port),\n",
    "    \"--served-model-name\", g_vllm_model_name\n",
    "],\n",
    "    g_vllm_port,\n",
    "    {\"PYTHONPATH\": str(g_srvlib_path)},\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(\"vLLM Started\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# サブプロセスを使用してvLLMサーバーを実行\n",
    "vllm = util.run_and_wait_for_port([\n",
    "    \"python\", \"-m\",\n",
    "    \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--enforce-eager\",\n",
    "    \"--model\", str(g_model_path),\n",
    "    \"--port\", str(g_vllm_port),\n",
    "    \"--served-model-name\", g_vllm_model_name\n",
    "],\n",
    "    g_vllm_port,\n",
    "    {\"PYTHONPATH\": str(g_srvlib_path)},\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(\"vLLMが起動しました\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:46:36.925703Z",
     "iopub.status.busy": "2024-06-18T18:46:36.925325Z",
     "iopub.status.idle": "2024-06-18T18:47:02.966755Z",
     "shell.execute_reply": "2024-06-18T18:47:02.965667Z",
     "shell.execute_reply.started": "2024-06-18T18:46:36.925673Z"
    }
   },
   "outputs": [],
   "source": [
    "# サブプロセスを使用してvLLMサーバーを実行\n",
    "vllm = util.run_and_wait_for_port([\n",
    "    \"python\", \"-m\",\n",
    "    \"vllm.entrypoints.openai.api_server\",\n",
    "    \"--enforce-eager\",\n",
    "    \"--model\", str(g_model_path),\n",
    "    \"--port\", str(g_vllm_port),\n",
    "    \"--served-model-name\", g_vllm_model_name\n",
    "],\n",
    "    g_vllm_port,\n",
    "    {\"PYTHONPATH\": str(g_srvlib_path)},\n",
    "    debug=False\n",
    ")\n",
    "\n",
    "print(\"vLLMが起動しました\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e806c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "We can see that the llama3 model is loaded onto the 1st Tesla T4 GPU.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "私たちのllama3モデルは1台目のTesla T4 GPUにロードされていることが確認できます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9643ef0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:02.968876Z",
     "iopub.status.busy": "2024-06-18T18:47:02.968472Z",
     "iopub.status.idle": "2024-06-18T18:47:04.01652Z",
     "shell.execute_reply": "2024-06-18T18:47:04.01532Z",
     "shell.execute_reply.started": "2024-06-18T18:47:02.968842Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ded18be",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Validating the Model\n",
    "\n",
    "Lets create our first rigging generator. In rigging the generators are the foundation for creating powerful LLM pipelines.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルの検証\n",
    "\n",
    "初めてのリギングジェネレーターを作成しましょう。リギングでは、ジェネレーターが強力なLLMパイプラインを作成するための基盤です。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f98c3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Connect with Rigging\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "sys.path.insert(0, \"/kaggle/tmp/lib\")\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "import rigging as rg\n",
    "\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llama requires some hand holding\n",
    ")\n",
    "\n",
    "answer = await generator.chat(\"Say Hello!\").run()\n",
    "\n",
    "print()\n",
    "print('[Rigging Chat]')\n",
    "print(type(answer), answer)\n",
    "\n",
    "print()\n",
    "print('[LLM Response Only]')\n",
    "print(type(answer.last), answer.last)\n",
    "\n",
    "print()\n",
    "answer_string = answer.last.content\n",
    "print('[LLM Response as a String]')\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# リギングとの接続\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "sys.path.insert(0, \"/kaggle/tmp/lib\")\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "import rigging as rg\n",
    "\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "answer = await generator.chat(\"こんにちは！\").run()\n",
    "\n",
    "print()\n",
    "print('[リギングチャット]')\n",
    "print(type(answer), answer)\n",
    "\n",
    "print()\n",
    "print('[LLMの応答のみ]')\n",
    "print(type(answer.last), answer.last)\n",
    "\n",
    "print()\n",
    "answer_string = answer.last.content\n",
    "print('[LLMの応答を文字列として]')\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:07.297877Z",
     "iopub.status.busy": "2024-06-18T18:47:07.297084Z",
     "iopub.status.idle": "2024-06-18T18:47:15.064385Z",
     "shell.execute_reply": "2024-06-18T18:47:15.06343Z",
     "shell.execute_reply.started": "2024-06-18T18:47:07.297837Z"
    }
   },
   "outputs": [],
   "source": [
    "# リギングとの接続\n",
    "\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "sys.path.insert(0, \"/kaggle/tmp/lib\")\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "import rigging as rg\n",
    "\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "answer = await generator.chat(\"こんにちは！\").run()\n",
    "\n",
    "print()\n",
    "print('[リギングチャット]')\n",
    "print(type(answer), answer)\n",
    "\n",
    "print()\n",
    "print('[LLMの応答のみ]')\n",
    "print(type(answer.last), answer.last)\n",
    "\n",
    "print()\n",
    "answer_string = answer.last.content\n",
    "print('[LLMの応答を文字列として]')\n",
    "print(answer.last.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f4525",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Converting results to pandas dataframe\n",
    "\n",
    "Using the `to_df()` method we can easily convert the chat history to a pandas dataframe.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 結果をpandasデータフレームに変換\n",
    "\n",
    "`to_df()`メソッドを使用することで、チャット履歴を簡単にpandasデータフレームに変換できます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814ebb3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "answer.to_df()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "answer.to_df()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:15.065705Z",
     "iopub.status.busy": "2024-06-18T18:47:15.065434Z",
     "iopub.status.idle": "2024-06-18T18:47:15.110363Z",
     "shell.execute_reply": "2024-06-18T18:47:15.109471Z",
     "shell.execute_reply.started": "2024-06-18T18:47:15.065681Z"
    }
   },
   "outputs": [],
   "source": [
    "answer.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5c333d",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Changing Model Parameters\n",
    "\n",
    "Much like database connection strings, Rigging generators can be represented as strings which define what provider, model, API key, generation params, etc. should be used. They are formatted as follows:\n",
    "\n",
    "```\n",
    "<provider>!<model>,<**kwargs>\n",
    "```\n",
    "\n",
    "As an example, here we load the model with additional parameters:\n",
    "- temperature=0.9\n",
    "- max_tokens=512\n",
    "\n",
    "You can read more about these in the docs here: https://rigging.dreadnode.io/topics/generators/#overload-generation-params\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルパラメータの変更\n",
    "\n",
    "データベース接続文字列のように、リギングジェネレーターは、どのプロバイダー、モデル、APIキー、生成パラメータなどを使用するかを定義する文字列として表現できます。形式は次のとおりです。\n",
    "\n",
    "```\n",
    "<provider>!<model>,<**kwargs>\n",
    "```\n",
    "\n",
    "例えば、ここでは追加のパラメータでモデルをロードします：\n",
    "- temperature=0.9\n",
    "- max_tokens=512\n",
    "\n",
    "これらに関する詳細は、こちらのドキュメントでお読みいただけます: https://rigging.dreadnode.io/topics/generators/#overload-generation-params\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e534e431",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"temperature=0.9,max_tokens=512,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llama requires some hand holding,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"temperature=0.9,max_tokens=512,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:15.111849Z",
     "iopub.status.busy": "2024-06-18T18:47:15.111525Z",
     "iopub.status.idle": "2024-06-18T18:47:15.221209Z",
     "shell.execute_reply": "2024-06-18T18:47:15.220415Z",
     "shell.execute_reply.started": "2024-06-18T18:47:15.111825Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"temperature=0.9,max_tokens=512,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce00cf2",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Alternatively we can set these parameters using the `rg.GenerateParams` class. This class allows you to set various model parameters:\n",
    "\n",
    "```\n",
    "rg.GenerateParams(\n",
    "    *,\n",
    "    temperature: float | None = None,\n",
    "    max_tokens: int | None = None,\n",
    "    top_k: int | None = None,\n",
    "    top_p: float | None = None,\n",
    "    stop: list[str] | None = None,\n",
    "    presence_penalty: float | None = None,\n",
    "    frequency_penalty: float | None = None,\n",
    "    api_base: str | None = None,\n",
    "    timeout: int | None = None,\n",
    "    seed: int | None = None,\n",
    "    extra: dict[str, typing.Any] = None,\n",
    ")\n",
    "```\n",
    "\n",
    "https://rigging.dreadnode.io/api/generator/#rigging.generator.GenerateParams\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "または、`rg.GenerateParams`クラスを使用してこれらのパラメータを設定することができます。このクラスを使用すると、さまざまなモデルパラメータを設定できます：\n",
    "\n",
    "```\n",
    "rg.GenerateParams(\n",
    "    *,\n",
    "    temperature: float | None = None,\n",
    "    max_tokens: int | None = None,\n",
    "    top_k: int | None = None,\n",
    "    top_p: float | None = None,\n",
    "    stop: list[str] | None = None,\n",
    "    presence_penalty: float | None = None,\n",
    "    frequency_penalty: float | None = None,\n",
    "    api_base: str | None = None,\n",
    "    timeout: int | None = None,\n",
    "    seed: int | None = None,\n",
    "    extra: dict[str, typing.Any] = None,\n",
    ")\n",
    "```\n",
    "\n",
    "https://rigging.dreadnode.io/api/generator/#rigging.generator.GenerateParams\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7c687e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "rg_params = rg.GenerateParams(\n",
    "    temperature = 0.9,\n",
    "    max_tokens = 512,\n",
    ")\n",
    "base_chat = generator.chat(params=rg_params)\n",
    "answer = await base_chat.fork('How is it going?').run()\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "rg_params = rg.GenerateParams(\n",
    "    temperature = 0.9,\n",
    "    max_tokens = 512,\n",
    ")\n",
    "base_chat = generator.chat(params=rg_params)\n",
    "answer = await base_chat.fork('調子はどうですか？').run()\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:15.223081Z",
     "iopub.status.busy": "2024-06-18T18:47:15.222833Z",
     "iopub.status.idle": "2024-06-18T18:47:17.479867Z",
     "shell.execute_reply": "2024-06-18T18:47:17.478938Z",
     "shell.execute_reply.started": "2024-06-18T18:47:15.223059Z"
    }
   },
   "outputs": [],
   "source": [
    "rg_params = rg.GenerateParams(\n",
    "    temperature = 0.9,\n",
    "    max_tokens = 512,\n",
    ")\n",
    "base_chat = generator.chat(params=rg_params)\n",
    "answer = await base_chat.fork('調子はどうですか？').run()\n",
    "print(answer.last.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93789d30",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Or parameters can be set within the chain using params.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "また、params内でチェーンを使用してこれらのパラメータを設定できます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2468975d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "base_chat = generator.chat() # No params set\n",
    "answer = await base_chat.fork('How is it going?') \\\n",
    "    .with_(temperature = 0.9, max_tokens = 512) \\\n",
    "    .run()\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "base_chat = generator.chat() # paramsを設定していない\n",
    "answer = await base_chat.fork('調子はどうですか？') \\\n",
    "    .with_(temperature = 0.9, max_tokens = 512) \\\n",
    "    .run()\n",
    "print(answer.last.content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:17.481882Z",
     "iopub.status.busy": "2024-06-18T18:47:17.481227Z",
     "iopub.status.idle": "2024-06-18T18:47:19.65719Z",
     "shell.execute_reply": "2024-06-18T18:47:19.656339Z",
     "shell.execute_reply.started": "2024-06-18T18:47:17.481845Z"
    }
   },
   "outputs": [],
   "source": [
    "base_chat = generator.chat() # paramsを設定していない\n",
    "answer = await base_chat.fork('調子はどうですか？') \\\n",
    "    .with_(temperature = 0.9, max_tokens = 512) \\\n",
    "    .run()\n",
    "print(answer.last.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f40b9",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Parsed outputs example\n",
    "\n",
    "Next we will create a pipeline where we:\n",
    "1. Create a rigging Model called `Answer`. This explains the expected output that we will parse from the model results.\n",
    "    - We will add some validators to this that will ensure the output is either `yes` or `no`\n",
    "    - This is fully customizable.\n",
    "    - Here `validate_content` is ensuring that our response conforms to the expected output (lowercase and starts with \"yes\" or \"no\")\n",
    "2. We can use the `Answer.xml_example()` in our prompt to let the LLM know how we expect the output to look.\n",
    "3. Later on we will use `.until_parsed_as(Answer)` to ensure the LLM output is extracted as defined here.\n",
    "\n",
    "**Note** `until_parsed_as()` can take a `max_rounds` parameter, which by default is 5.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 解析された出力の例\n",
    "\n",
    "次に、以下を実行するパイプラインを作成します。\n",
    "1. `Answer`というリギングモデルを作成します。これにより、モデルの結果から解析される期待される出力が説明されます。\n",
    "    - 出力が`yes`または`no`のいずれかであることを確認するためのバリデータを追加します。\n",
    "    - これは完全にカスタマイズ可能です。\n",
    "    - ここで`validate_content`は、応答が期待される出力に準拠していること（小文字で「yes」または「no」で始まる）を確認します。\n",
    "2. プロンプト内で`.xml_example()`を使用して、LLMが出力の見た目を知ることができるようにします。\n",
    "3. 後で、`.until_parsed_as(Answer)`を使用して、LLMの出力がここで定義されたように抽出されることを確認します。\n",
    "\n",
    "**注意:** `until_parsed_as()`は、デフォルトで5の`max_rounds`パラメータを取ることができます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd02bb5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import typing as t\n",
    "from pydantic import field_validator\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"Invalid answer, must be 'yes' or 'no'\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}**yes/no**{Answer.xml_end_tag()}\"\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import typing as t\n",
    "from pydantic import field_validator\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"無効な回答、'yes'または'no'でなければなりません。\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}**yes/no**{Answer.xml_end_tag()}\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:19.659101Z",
     "iopub.status.busy": "2024-06-18T18:47:19.658668Z",
     "iopub.status.idle": "2024-06-18T18:47:19.668457Z",
     "shell.execute_reply": "2024-06-18T18:47:19.667558Z",
     "shell.execute_reply.started": "2024-06-18T18:47:19.659066Z"
    }
   },
   "outputs": [],
   "source": [
    "import typing as t\n",
    "from pydantic import field_validator\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"無効な回答、'yes'または'no'でなければなりません。\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}**yes/no**{Answer.xml_end_tag()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c9a01",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Lets see what the xml example looks like for this we can use this in our prompt\n",
    "Answer.xml_example()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# xmlの例がどのように見えるかを見てみましょう。これをプロンプトに使用できます。\n",
    "Answer.xml_example()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:19.669852Z",
     "iopub.status.busy": "2024-06-18T18:47:19.669536Z",
     "iopub.status.idle": "2024-06-18T18:47:19.752363Z",
     "shell.execute_reply": "2024-06-18T18:47:19.751366Z",
     "shell.execute_reply.started": "2024-06-18T18:47:19.669814Z"
    }
   },
   "outputs": [],
   "source": [
    "# xmlの例がどのように見えるかを見てみましょう。これをプロンプトに使用できます。\n",
    "Answer.xml_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9be279",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llama requires some hand holding,\n",
    ")\n",
    "\n",
    "keyword='Tom Hanks'\n",
    "category='Famous Person'\n",
    "last_question='Is it a famous person?'\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "            The secret word for this game is \"{keyword}\" [{category}]\n",
    "\n",
    "            You are currently answering a question about the word above.\n",
    "\n",
    "            The next question is \"{last_question}\".\n",
    "\n",
    "            Answer the yes/no question above and place it in the following format:\n",
    "            {Answer.xml_example()}\n",
    "\n",
    "            - Your response should be accurate given the keyword above\n",
    "            - Always answer with \"yes\" or \"no\"\n",
    "\n",
    "            What is the answer?\n",
    "\"\"\"\n",
    "\n",
    "chat = await (\n",
    "    generator\n",
    "    .chat(prompt)\n",
    "    .until_parsed_as(Answer, max_rounds=50)\n",
    "    .run()\n",
    ")\n",
    "\n",
    "print('=== Full Chat ===')\n",
    "print(chat)\n",
    "\n",
    "print()\n",
    "print('=== LLM Response Only ===')\n",
    "print(chat.last)\n",
    "\n",
    "print()\n",
    "print('=== Parsed Answer ===')\n",
    "print(chat.last.parse(Answer).content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "keyword='トム・ハンクス'\n",
    "category='有名人'\n",
    "last_question='これは有名な人物ですか？'\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "            このゲームの秘密の単語は \"{keyword}\" [{category}]です。\n",
    "\n",
    "            あなたは現在、上記の単語に関する質問に答えています。\n",
    "\n",
    "            次の質問は \"{last_question}\" です。\n",
    "\n",
    "            上記の質問に「yes」または「no」で答え、次の形式にしてください：\n",
    "            {Answer.xml_example()}\n",
    "\n",
    "            - あなたの応答は、上記のキーワードに基づいて正確でなければなりません\n",
    "            - 常に「yes」または「no」で答えてください\n",
    "\n",
    "            答えは何ですか？\n",
    "\"\"\"\n",
    "\n",
    "chat = await (\n",
    "    generator\n",
    "    .chat(prompt)\n",
    "    .until_parsed_as(Answer, max_rounds=50)\n",
    "    .run()\n",
    ")\n",
    "\n",
    "print('=== フルチャット ===')\n",
    "print(chat)\n",
    "\n",
    "print()\n",
    "print('=== LLMの応答のみ ===')\n",
    "print(chat.last)\n",
    "\n",
    "print()\n",
    "print('=== 解析された回答 ===')\n",
    "print(chat.last.parse(Answer).content)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:21.724128Z",
     "iopub.status.busy": "2024-06-18T18:47:21.723509Z",
     "iopub.status.idle": "2024-06-18T18:47:33.30668Z",
     "shell.execute_reply": "2024-06-18T18:47:33.305798Z",
     "shell.execute_reply.started": "2024-06-18T18:47:21.724097Z"
    }
   },
   "outputs": [],
   "source": [
    "generator = rg.get_generator(\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "keyword='トム・ハンクス'\n",
    "category='有名人'\n",
    "last_question='これは有名な人物ですか？'\n",
    "\n",
    "prompt = f\"\"\"\\\n",
    "            このゲームの秘密の単語は \"{keyword}\" [{category}]です。\n",
    "\n",
    "            あなたは現在、上記の単語に関する質問に答えています。\n",
    "\n",
    "            次の質問は \"{last_question}\" です。\n",
    "\n",
    "            上記の質問に「yes」または「no」で答え、次の形式にしてください：\n",
    "            {Answer.xml_example()}\n",
    "\n",
    "            - あなたの応答は、上記のキーワードに基づいて正確でなければなりません\n",
    "            - 常に「yes」または「no」で答えてください\n",
    "\n",
    "            答えは何ですか？\n",
    "\"\"\"\n",
    "\n",
    "chat = await (\n",
    "    generator\n",
    "    .chat(prompt)\n",
    "    .until_parsed_as(Answer, max_rounds=50)\n",
    "    .run()\n",
    ")\n",
    "\n",
    "print('=== フルチャット ===')\n",
    "print(chat)\n",
    "\n",
    "print()\n",
    "print('=== LLMの応答のみ ===')\n",
    "print(chat.last)\n",
    "\n",
    "print()\n",
    "print('=== 解析された回答 ===')\n",
    "print(chat.last.parse(Answer).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac4812",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Create an example Questioner Chat Pipeline with Rigging\n",
    "\n",
    "Next lets create the questioner pipeline that will attempt to help determine what the keyword might be.\n",
    "\n",
    "First lets create a `Question` object which we will use to parse our output.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Riggingを使用した質問者チャットパイプラインの作成\n",
    "\n",
    "次に、キーワードが何であるかを特定するのを助けるための質問者パイプラインを作成します。\n",
    "\n",
    "まず、出力を解析するために使用する`Question`オブジェクトを作成します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c992e958",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from pydantic import StringConstraints  # noqa\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"**question**\").to_pretty_xml()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from pydantic import StringConstraints  # noqa\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"**質問**\").to_pretty_xml()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:33.308069Z",
     "iopub.status.busy": "2024-06-18T18:47:33.307802Z",
     "iopub.status.idle": "2024-06-18T18:47:33.315461Z",
     "shell.execute_reply": "2024-06-18T18:47:33.314429Z",
     "shell.execute_reply.started": "2024-06-18T18:47:33.308044Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import StringConstraints  # noqa\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"**質問**\").to_pretty_xml()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75925f67",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "base =  generator.chat(\"\"\"\\\n",
    "You are a talented player of the 20 questions game. You are accurate, focused, and\n",
    "structured in your approach. You will create useful questions, make guesses, or answer\n",
    "questions about a keyword.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "question_chat = await (base.fork(\n",
    "    f\"\"\"\\\n",
    "    You are currently asking the next question.\n",
    "\n",
    "    question and place it in the following format:\n",
    "    {Question.xml_example()}\n",
    "\n",
    "    - Your response should be a focused question which will gather the most information\n",
    "    - Start general with your questions\n",
    "    - Always try to bisect the remaining search space\n",
    "    - Pay attention to previous questions and answers\n",
    "\n",
    "    What is your next question?\n",
    "    \"\"\"\n",
    ")\n",
    ".until_parsed_as(Question, attempt_recovery=True)\n",
    ".run()\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "base =  generator.chat(\"\"\"\\\n",
    "あなたは20の質問ゲームの才能あるプレイヤーです。正確で集中しており、\n",
    "構造的なアプローチを持っています。役に立つ質問を作成し、推測を行い、キーワードに関する質問に答えます。\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "question_chat = await (base.fork(\n",
    "    f\"\"\"\\\n",
    "    あなたは現在、次の質問をしています。\n",
    "\n",
    "    質問し、次の形式にしてください：\n",
    "    {Question.xml_example()}\n",
    "\n",
    "    - あなたの応答は、最も多くの情報を収集できる焦点を絞った質問でなければなりません\n",
    "    - 質問は一般的に始めてください\n",
    "    - 残りの検索空間を常に二分するようにしてください\n",
    "    - 以前の質問と回答に注意を払ってください\n",
    "\n",
    "    あなたの次の質問は何ですか？\n",
    "    \"\"\"\n",
    ")\n",
    ".until_parsed_as(Question, attempt_recovery=True)\n",
    ".run()\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:39.082592Z",
     "iopub.status.busy": "2024-06-18T18:47:39.082181Z",
     "iopub.status.idle": "2024-06-18T18:47:39.859978Z",
     "shell.execute_reply": "2024-06-18T18:47:39.859196Z",
     "shell.execute_reply.started": "2024-06-18T18:47:39.082562Z"
    }
   },
   "outputs": [],
   "source": [
    "base =  generator.chat(\"\"\"\\\n",
    "あなたは20の質問ゲームの才能あるプレイヤーです。正確で集中しており、\n",
    "構造的なアプローチを持っています。役に立つ質問を作成し、推測を行い、キーワードに関する質問に答えます。\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "question_chat = await (base.fork(\n",
    "    f\"\"\"\\\n",
    "    あなたは現在、次の質問をしています。\n",
    "\n",
    "    質問し、次の形式にしてください：\n",
    "    {Question.xml_example()}\n",
    "\n",
    "    - あなたの応答は、最も多くの情報を収集できる焦点を絞った質問でなければなりません\n",
    "    - 質問は一般的に始めてください\n",
    "    - 残りの検索空間を常に二分するようにしてください\n",
    "    - 以前の質問と回答に注意を払ってください\n",
    "\n",
    "    あなたの次の質問は何ですか？\n",
    "    \"\"\"\n",
    ")\n",
    ".until_parsed_as(Question, attempt_recovery=True)\n",
    ".run()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccaf6b2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Dataframe representation of the conversation\n",
    "question_chat.to_df()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 会話のデータフレーム表示\n",
    "question_chat.to_df()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:39.861319Z",
     "iopub.status.busy": "2024-06-18T18:47:39.861048Z",
     "iopub.status.idle": "2024-06-18T18:47:39.884675Z",
     "shell.execute_reply": "2024-06-18T18:47:39.883442Z",
     "shell.execute_reply.started": "2024-06-18T18:47:39.861295Z"
    }
   },
   "outputs": [],
   "source": [
    "# 会話のデータフレーム表示\n",
    "question_chat.to_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6df978",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "We now are confident that the LLM response contains the quesion and case parse the question like:\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "私たちは、LLMの応答が質問を含むことを確信しており、質問を解析して次のようにできます：\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd0e7f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "question = question_chat.last.parse(Question).content\n",
    "print(question)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "question = question_chat.last.parse(Question).content\n",
    "print(question)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T18:47:46.02397Z",
     "iopub.status.busy": "2024-06-18T18:47:46.023601Z",
     "iopub.status.idle": "2024-06-18T18:47:46.029781Z",
     "shell.execute_reply": "2024-06-18T18:47:46.028875Z",
     "shell.execute_reply.started": "2024-06-18T18:47:46.02394Z"
    }
   },
   "outputs": [],
   "source": [
    "question = question_chat.last.parse(Question).content\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b404c5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Create a keyword dataframe\n",
    "** Note this only works because we know the possible keywords in the public set. This will not work on the final leaderboard**\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# キーワードデータフレームの作成\n",
    "**注意:** これは、公開セットの可能なキーワードを知っているためにのみ機能します。最終的なリーダーボードでは機能しません。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb09ae1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:13:09.05161Z",
     "iopub.status.busy": "2024-06-18T19:13:09.050676Z",
     "iopub.status.idle": "2024-06-18T19:13:11.606383Z",
     "shell.execute_reply": "2024-06-18T19:13:11.605418Z",
     "shell.execute_reply.started": "2024-06-18T19:13:09.051574Z"
    }
   },
   "outputs": [],
   "source": [
    "!wget -O keywords_local.py https://raw.githubusercontent.com/Kaggle/kaggle-environments/master/kaggle_environments/envs/llm_20_questions/keywords.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f870d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!head keywords_local.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!head keywords_local.py\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:13:13.191677Z",
     "iopub.status.busy": "2024-06-18T19:13:13.190866Z",
     "iopub.status.idle": "2024-06-18T19:13:14.141544Z",
     "shell.execute_reply": "2024-06-18T19:13:14.140544Z",
     "shell.execute_reply.started": "2024-06-18T19:13:13.19164Z"
    }
   },
   "outputs": [],
   "source": [
    "!head keywords_local.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662c714",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append('./')\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "def capitalize_first_word(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    return text[0].upper() + text[1:].lower()\n",
    "\n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    keywords_dict = json.loads(KEYWORDS_JSON)\n",
    "\n",
    "    category_words_dict = {}\n",
    "    all_words = []\n",
    "    all_cat_words = []\n",
    "    for d in keywords_dict:\n",
    "        words = [w['keyword'] for w in d['words']]\n",
    "        cat_word = [(d['category'], w['keyword']) for w in d['words']]\n",
    "        category_words_dict[d['category']] = words\n",
    "        all_words += words\n",
    "        all_cat_words += cat_word\n",
    "\n",
    "    keyword_df = pd.DataFrame(all_cat_words, columns=['category','keyword'])\n",
    "    keyword_df['first_letter'] = keyword_df['keyword'].str[0]\n",
    "    keyword_df['second_letter'] = keyword_df['keyword'].str[1]\n",
    "    keyword_df.to_parquet('keywords.parquet')\n",
    "    \n",
    "create_keyword_df(KEYWORDS_JSON)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append('./')\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "def capitalize_first_word(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    return text[0].upper() + text[1:].lower()\n",
    "\n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    keywords_dict = json.loads(KEYWORDS_JSON)\n",
    "\n",
    "    category_words_dict = {}\n",
    "    all_words = []\n",
    "    all_cat_words = []\n",
    "    for d in keywords_dict:\n",
    "        words = [w['keyword'] for w in d['words']]\n",
    "        cat_word = [(d['category'], w['keyword']) for w in d['words']]\n",
    "        category_words_dict[d['category']] = words\n",
    "        all_words += words\n",
    "        all_cat_words += cat_word\n",
    "\n",
    "    keyword_df = pd.DataFrame(all_cat_words, columns=['category','keyword'])\n",
    "    keyword_df['first_letter'] = keyword_df['keyword'].str[0]\n",
    "    keyword_df['second_letter'] = keyword_df['keyword'].str[1]\n",
    "    keyword_df.to_parquet('keywords.parquet')\n",
    "    \n",
    "create_keyword_df(KEYWORDS_JSON)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:39:08.09623Z",
     "iopub.status.busy": "2024-06-18T19:39:08.095864Z",
     "iopub.status.idle": "2024-06-18T19:39:08.157802Z",
     "shell.execute_reply": "2024-06-18T19:39:08.156896Z",
     "shell.execute_reply.started": "2024-06-18T19:39:08.096204Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "sys.path.append('./')\n",
    "from keywords_local import KEYWORDS_JSON\n",
    "\n",
    "def capitalize_first_word(text):\n",
    "    if not text:\n",
    "        return text\n",
    "    return text[0].upper() + text[1:].lower()\n",
    "\n",
    "def create_keyword_df(KEYWORDS_JSON):\n",
    "    keywords_dict = json.loads(KEYWORDS_JSON)\n",
    "\n",
    "    category_words_dict = {}\n",
    "    all_words = []\n",
    "    all_cat_words = []\n",
    "    for d in keywords_dict:\n",
    "        words = [w['keyword'] for w in d['words']]\n",
    "        cat_word = [(d['category'], w['keyword']) for w in d['words']]\n",
    "        category_words_dict[d['category']] = words\n",
    "        all_words += words\n",
    "        all_cat_words += cat_word\n",
    "\n",
    "    keyword_df = pd.DataFrame(all_cat_words, columns=['category','keyword'])\n",
    "    keyword_df['first_letter'] = keyword_df['keyword'].str[0]\n",
    "    keyword_df['second_letter'] = keyword_df['keyword'].str[1]\n",
    "    keyword_df.to_parquet('keywords.parquet')\n",
    "    \n",
    "create_keyword_df(KEYWORDS_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccf86c0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keywords_df = pd.read_parquet('keywords.parquet')\n",
    "keywords_df.sample(10)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "keywords_df = pd.read_parquet('keywords.parquet')\n",
    "keywords_df.sample(10)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:39:08.568525Z",
     "iopub.status.busy": "2024-06-18T19:39:08.56792Z",
     "iopub.status.idle": "2024-06-18T19:39:08.621277Z",
     "shell.execute_reply": "2024-06-18T19:39:08.620385Z",
     "shell.execute_reply.started": "2024-06-18T19:39:08.568491Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df = pd.read_parquet('keywords.parquet')\n",
    "keywords_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e060265",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keywords_df['category'].value_counts()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "keywords_df['category'].value_counts()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:39:09.267519Z",
     "iopub.status.busy": "2024-06-18T19:39:09.267113Z",
     "iopub.status.idle": "2024-06-18T19:39:09.314644Z",
     "shell.execute_reply": "2024-06-18T19:39:09.313676Z",
     "shell.execute_reply.started": "2024-06-18T19:39:09.267487Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords_df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719112a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Create `main.py` Script for Final Submission.\n",
    "\n",
    "Our final submission will be a zipped directory with a `main` file. This file is below.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 最終提出のための`main.py`スクリプトを作成\n",
    "\n",
    "私たちの最終提出は、`main`ファイルを含むzipディレクトリになります。このファイルは以下の通りです。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d3d29",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%writefile main.py\n",
    "\n",
    "# Main agent file\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path fixups\n",
    "\n",
    "g_working_path = Path('/kaggle/working')\n",
    "g_input_path = Path('/kaggle/input')\n",
    "g_temp_path = Path(\"/kaggle/tmp\")\n",
    "g_agent_path = Path(\"/kaggle_simulations/agent/\")\n",
    "\n",
    "g_model_path = g_temp_path / \"model\"\n",
    "g_srvlib_path = g_temp_path / \"srvlib\"\n",
    "g_lib_path = g_temp_path / \"lib\"\n",
    "\n",
    "if g_agent_path.exists():\n",
    "    g_lib_path = g_agent_path / \"lib\"\n",
    "    g_model_path = g_agent_path / \"model\"\n",
    "    g_srvlib_path = g_agent_path / \"srvlib\"\n",
    "else:\n",
    "    g_agent_path = Path('/kaggle/working')\n",
    "    \n",
    "sys.path.insert(0, str(g_lib_path))\n",
    "\n",
    "# Logging noise\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "# Fixed imports\n",
    "\n",
    "import util # noqa\n",
    "import rigging as rg  # noqa\n",
    "from pydantic import BaseModel, field_validator, StringConstraints  # noqa\n",
    "\n",
    "# Constants\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\"\n",
    "\n",
    "g_generator_id = (\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llama requires some hand holding\n",
    ")\n",
    "\n",
    "# Types\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    step: int\n",
    "    role: t.Literal[\"guesser\", \"answerer\"]\n",
    "    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]\n",
    "    keyword: str\n",
    "    category: str\n",
    "    questions: list[str]\n",
    "    answers: list[str]\n",
    "    guesses: list[str]\n",
    "    \n",
    "    @property\n",
    "    def empty(self) -> bool:\n",
    "        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n",
    "    \n",
    "    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n",
    "        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n",
    "\n",
    "    def get_history_as_xml(self, *, skip_guesses: bool = False) -> str:\n",
    "        if not self.empty:\n",
    "            history = \"\\n\".join(\n",
    "            f\"\"\"\\\n",
    "            <turn-{i}>\n",
    "            Question: {question}\n",
    "            Answer: {answer}\n",
    "            {'Guess: ' + guess if not skip_guesses else ''}\n",
    "            </turn-{i}>\n",
    "            \"\"\"\n",
    "            for i, (question, answer, guess) in enumerate(self.get_history())\n",
    "            )\n",
    "            return history\n",
    "        return \"none yet.\"\n",
    "\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"Invalid answer, must be 'yes' or 'no'\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}yes/no{Answer.xml_end_tag()}\"\n",
    "\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"question\").to_pretty_xml()\n",
    "\n",
    "\n",
    "class Guess(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Guess(content=\"thing/place\").to_pretty_xml()\n",
    "\n",
    "\n",
    "# Functions\n",
    "\n",
    "async def ask(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    if observation.step == 0:\n",
    "        # override first question until keyword bug is fixed.\n",
    "        return \"Are we playing 20 questions?\"\n",
    "    \n",
    "    try:\n",
    "        chat = await (\n",
    "             base.fork(\n",
    "                f\"\"\"\\\n",
    "                You are currently asking the next question.\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml(skip_guesses=True)}\n",
    "                </game-history>\n",
    "\n",
    "                Based on the history above, ask the next most useful yes/no\n",
    "                question and place it in the following format:\n",
    "                {Question.xml_example()}\n",
    "\n",
    "                - Your response should be a focused question which will gather the most information\n",
    "                - Start general with your questions\n",
    "                - Always try to bisect the remaining search space\n",
    "                - Pay attention to previous questions and answers\n",
    "\n",
    "                What is your next question?\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Question, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "        return chat.last.parse(Question).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return 'Is it a person?'\n",
    "\n",
    "async def answer(base: rg.ChatPipeline, observation: Observation) -> t.Literal[\"yes\", \"no\"]:\n",
    "    if not observation.keyword:\n",
    "        print(\"Keyword wasn't provided to answerer\", file=sys.stderr)\n",
    "        return \"yes\" # override until keyword bug is fixed.\n",
    "            \n",
    "    last_question = observation.questions[-1]\n",
    "    \n",
    "#     print('=' * 10)\n",
    "#     print(f\"\"\"\\\n",
    "#                 Provide the best yes/no answer to the question about the keyword [{observation.keyword}] in the category [{observation.category}]\n",
    "\n",
    "#                 [QUESTION] \"{last_question}\" [/QUESTION]\n",
    "                \n",
    "#                 Remember they keyword is [{observation.keyword}]\n",
    "                \n",
    "#                 Answer the yes/no question above and place it in the following format:\n",
    "#                 {Answer.xml_example()}\n",
    "#                 \"\"\"\n",
    "#          )\n",
    "#     print('=' * 10)\n",
    "    try:\n",
    "        responses = []\n",
    "        for i in range(5):\n",
    "            # Loop 5 times and take the most frequent response\n",
    "            chat = await (\n",
    "                base.fork(\n",
    "                    f\"\"\"\\\n",
    "                    Provide the best yes/no answer to the question about the keyword [{observation.keyword}] in the category [{observation.category}]\n",
    "\n",
    "                    [QUESTION] \"{last_question}\" [/QUESTION]\n",
    "\n",
    "                    Remember they keyword is [{observation.keyword}]\n",
    "\n",
    "                    Answer the yes/no question above and place it in the following format:\n",
    "                    {Answer.xml_example()}\n",
    "                    \"\"\"\n",
    "                )\n",
    "                .until_parsed_as(Answer, attempt_recovery=True, max_rounds=20)\n",
    "                .run()\n",
    "            )\n",
    "            responses.append(chat.last.parse(Answer).content.strip('*'))\n",
    "            \n",
    "        print(f'Responses are {responses}')\n",
    "        return pd.Series(responses).value_counts().index[0]\n",
    "#         print('=' * 10)\n",
    "#         print('Response.....')\n",
    "#         print(chat.last)\n",
    "#         print('=' * 10)\n",
    "#         return chat.last.parse(Answer).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        print('%%%%%%%%%%%% Error so answering yes %%%%%%%%%%%% ')\n",
    "        return 'yes'\n",
    "\n",
    "async def guess(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    try:\n",
    "\n",
    "        chat = await (\n",
    "            base.fork(\n",
    "                f\"\"\"\\\n",
    "                You are currently making an informed guess of the keyword.\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml()}\n",
    "                </game-history>\n",
    "\n",
    "                Based on the history above, produce a single next best guess\n",
    "                for the keyword and place it in the following format:\n",
    "                {Guess.xml_example()}\n",
    "\n",
    "                - Avoid repeat guesses based on the history above\n",
    "                - The guess should be a specific person, place, or thing\n",
    "\n",
    "                What is your guess?\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Guess, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        return chat.last.parse(Guess).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return 'france'\n",
    "    \n",
    "# vLLM and Generator\n",
    "\n",
    "try:\n",
    "    vllm = util.run_and_wait_for_port([\n",
    "        \"python\", \"-m\",\n",
    "        \"vllm.entrypoints.openai.api_server\",\n",
    "        \"--enforce-eager\",\n",
    "        \"--model\", str(g_model_path),\n",
    "        \"--port\", str(g_vllm_port),\n",
    "        \"--served-model-name\", g_vllm_model_name\n",
    "    ], g_vllm_port, {\"PYTHONPATH\": str(g_srvlib_path)})\n",
    "\n",
    "    print(\"vLLM Started\")\n",
    "except ValueError:\n",
    "    print('vLLM Already Running')\n",
    "    \n",
    "    \n",
    "generator = rg.get_generator(g_generator_id)\n",
    "\n",
    "base =  generator.chat(\"\"\"\\\n",
    "You are a talented player of the 20 questions game. You are accurate, focused, and\n",
    "structured in your approach. You will create useful questions, make guesses, or answer\n",
    "questions about a keyword.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Entrypoint\n",
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"Does the keyword start with any letter?\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"Does the keyword start with the letter '{letters[0]}'\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" or '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"Does the keyword start with one of the letters {formatted_letters}?\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches\n",
    "\n",
    "# Simple question asker\n",
    "class SimpleQuestionerAgent():\n",
    "    def __init__(self, keyword_df: pd.DataFrame):\n",
    "        self.keyword_df = keyword_df\n",
    "        self.keyword_df_init = keyword_df.copy()\n",
    "        self.round = 0\n",
    "        self.category_questions = [\n",
    "            \"Are we playing 20 questions?\",\n",
    "            \"Is the keyword a thing that is not a place?\",\n",
    "            \"Is the keyword a place?\",\n",
    "        ]\n",
    "        self.found_category = False\n",
    "        \n",
    "    def filter_keywords(self, obs):\n",
    "        print(self.keyword_df.shape)\n",
    "        # Filter down keyword_df based on past answers\n",
    "        for i, answer in enumerate(obs.answers):\n",
    "            if obs.questions[i] in self.category_questions:\n",
    "                if answer == 'yes':\n",
    "                    if obs.questions[i] == \"Is the keyword a thing that is not a place?\":\n",
    "                        self.found_category = 'things'\n",
    "                    if obs.questions[i] == \"Is the keyword a place?\":\n",
    "                        self.found_category = 'place'\n",
    "                    fc = self.found_category\n",
    "                    self.keyword_df = self.keyword_df.query('category == @fc').reset_index(drop=True)\n",
    "    \n",
    "            if obs.questions[i].startswith('Does the keyword start '):\n",
    "                if self.keyword_df['first_letter'].nunique() <= 1:\n",
    "                    break\n",
    "                letter_question = obs.questions[i]\n",
    "#                 letters = letter_question.replace('Precisely evaluate the very first letter in the keyword. If the keyword is multiple words only evaluate the first word. Answer Yes/No if ANY of these letters are the first letter in the keyword: ','')\n",
    "#                 letters = letter_question.split(' (say yes if it does start with one of them, no if it doesnt) ')[-1]\n",
    "#                 letters = letters.replace('?','').replace(' ','').replace(':','').replace('[','').replace(']','').strip().split(',')\n",
    "                letters = extract_letters_from_question(letter_question)\n",
    "                self.keyword_df = self.keyword_df.reset_index(drop=True).copy()\n",
    "                if obs.answers[i] == 'yes':\n",
    "#                     print(f'Filtering down to letters {letters}')\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "                elif obs.answers[i] == 'no':\n",
    "#                     print(f'Excluding letters {letters}')\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        ~self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # Reset\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "            \n",
    "    def get_letters(self, obs, max_letters=20):\n",
    "        n_letters = self.keyword_df['first_letter'].nunique()\n",
    "        sample_letters = self.keyword_df['first_letter'].drop_duplicates().sample(n_letters // 2).values.tolist()\n",
    "        sample_letters = sample_letters[:max_letters]\n",
    "        print('sample letters', n_letters, sample_letters)\n",
    "        return sample_letters # ', '.join(sample_letters)\n",
    "    \n",
    "    def __call__(self, obs, *args):\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # Reset\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "        self.filter_keywords(obs)\n",
    "        if obs.turnType == 'ask':\n",
    "            self.round += 1\n",
    "            if (self.round <= 3 and not self.found_category):\n",
    "                response = self.category_questions[self.round - 1]\n",
    "            else:\n",
    "                sample_letters = self.get_letters(obs)\n",
    "                if len(sample_letters) == 0:\n",
    "                    n_sample = min(len(self.keyword_df), 10)\n",
    "                    possible_keywords = \", \".join(self.keyword_df['keyword'].sample(n_sample).values.tolist())\n",
    "                    response = f\"Is the keyword one of the following? {possible_keywords}\"\n",
    "                else:\n",
    "                    sample_letters_str = str(sample_letters).replace('[','').replace(']','')\n",
    "#                     response = f'Does the keyword start with one of the following letters : {sample_letters_str} ?'\n",
    "                    response = format_first_letter_question(sample_letters)\n",
    "        elif obs.turnType == 'guess':\n",
    "            response = self.keyword_df['keyword'].sample(1).values[0]\n",
    "            # Remove the guessed word\n",
    "            updated_df = self.keyword_df.loc[self.keyword_df['keyword'] != response].reset_index(drop=True).copy()\n",
    "            if len(updated_df) >= 1:\n",
    "                self.keyword_df = updated_df.copy()\n",
    "            else:\n",
    "                self.keyword_df = self.keyword_df_init.copy() # Reset the df\n",
    "#         print(f'Round {self.round}')\n",
    "#         print(f\"{response=}\")\n",
    "#         print(f'keyword_df size {self.keyword_df.shape}')\n",
    "        return response\n",
    "\n",
    "\n",
    "keyword_df = pd.read_parquet(f'{g_agent_path}/keywords.parquet')\n",
    "question_agent = None\n",
    "\n",
    "async def observe(obs: t.Any) -> str:\n",
    "    observation = Observation(**obs.__dict__)\n",
    "    global question_agent\n",
    "    if question_agent is None:\n",
    "        question_agent = SimpleQuestionerAgent(keyword_df)\n",
    "\n",
    "    try:\n",
    "        match observation.turnType:\n",
    "            case \"ask\":\n",
    "#                 return await ask(base, observation)\n",
    "                return question_agent(obs)\n",
    "            case \"answer\":\n",
    "                return await answer(base, observation)\n",
    "            case \"guess\":\n",
    "#                 return await guess(base, observation)\n",
    "                return question_agent(obs)\n",
    "\n",
    "            case _:\n",
    "                raise ValueError(\"Unknown turn type\")\n",
    "    except Exception as e:\n",
    "        print(str(e), file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "def agent_fn(obs: t.Any, _: t.Any) -> str:\n",
    "    # Async gate when executing in their framework\n",
    "    import asyncio\n",
    "    return asyncio.run(observe(obs))\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%writefile main.py\n",
    "\n",
    "# メインエージェントファイル\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# パスの修正\n",
    "\n",
    "g_working_path = Path('/kaggle/working')\n",
    "g_input_path = Path('/kaggle/input')\n",
    "g_temp_path = Path(\"/kaggle/tmp\")\n",
    "g_agent_path = Path(\"/kaggle_simulations/agent/\")\n",
    "\n",
    "g_model_path = g_temp_path / \"model\"\n",
    "g_srvlib_path = g_temp_path / \"srvlib\"\n",
    "g_lib_path = g_temp_path / \"lib\"\n",
    "\n",
    "if g_agent_path.exists():\n",
    "    g_lib_path = g_agent_path / \"lib\"\n",
    "    g_model_path = g_agent_path / \"model\"\n",
    "    g_srvlib_path = g_agent_path / \"srvlib\"\n",
    "else:\n",
    "    g_agent_path = Path('/kaggle/working')\n",
    "    \n",
    "sys.path.insert(0, str(g_lib_path))\n",
    "\n",
    "# ロギングのノイズ\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "# 固定インポート\n",
    "\n",
    "import util # noqa\n",
    "import rigging as rg  # noqa\n",
    "from pydantic import BaseModel, field_validator, StringConstraints  # noqa\n",
    "\n",
    "# 定数\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\"\n",
    "\n",
    "g_generator_id = (\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "# タイプ\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    step: int\n",
    "    role: t.Literal[\"guesser\", \"answerer\"]\n",
    "    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]\n",
    "    keyword: str\n",
    "    category: str\n",
    "    questions: list[str]\n",
    "    answers: list[str]\n",
    "    guesses: list[str]\n",
    "    \n",
    "    @property\n",
    "    def empty(self) -> bool:\n",
    "        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n",
    "    \n",
    "    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n",
    "        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n",
    "\n",
    "    def get_history_as_xml(self, *, skip_guesses: bool = False) -> str:\n",
    "        if not self.empty:\n",
    "            history = \"\\n\".join(\n",
    "            f\"\"\"\\\n",
    "            <turn-{i}>\n",
    "            質問: {question}\n",
    "            回答: {answer}\n",
    "            {'推測: ' + guess if not skip_guesses else ''}\n",
    "            </turn-{i}>\n",
    "            \"\"\"\n",
    "            for i, (question, answer, guess) in enumerate(self.get_history())\n",
    "            )\n",
    "            return history\n",
    "        return \"まだありません。\"\n",
    "\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"無効な回答、'yes'または'no'でなければなりません。\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}yes/no{Answer.xml_end_tag()}\"\n",
    "\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"質問\").to_pretty_xml()\n",
    "\n",
    "\n",
    "class Guess(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Guess(content=\"物や場所\").to_pretty_xml()\n",
    "\n",
    "\n",
    "# 関数\n",
    "\n",
    "async def ask(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    if observation.step == 0:\n",
    "        # 初回の質問を上書きし、キーワードのバグが修正されるまで処理します。\n",
    "        return \"20の質問をしていますか？\"\n",
    "    \n",
    "    try:\n",
    "        chat = await (\n",
    "             base.fork(\n",
    "                f\"\"\"\\\n",
    "                あなたは現在、次の質問をしています。\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml(skip_guesses=True)}\n",
    "                </game-history>\n",
    "\n",
    "                上記の履歴に基づいて、次の最も有用なyes/no質問を行い、次の形式にしてください:\n",
    "                {Question.xml_example()}\n",
    "\n",
    "                - あなたの応答は、最も多くの情報を収集できる焦点を絞った質問でなければなりません\n",
    "                - 質問は一般的に始めてください\n",
    "                - 残りの検索空間を常に二分してください\n",
    "                - 以前の質問と回答に注意を払ってください\n",
    "\n",
    "                あなたの次の質問は何ですか？\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Question, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "        return chat.last.parse(Question).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return '人物ですか？'\n",
    "\n",
    "async def answer(base: rg.ChatPipeline, observation: Observation) -> t.Literal[\"yes\", \"no\"]:\n",
    "    if not observation.keyword:\n",
    "        print(\"キーワードが回答者に提供されていません\", file=sys.stderr)\n",
    "        return \"yes\" # キーワードのバグが修正されるまで上書きします。\n",
    "            \n",
    "    last_question = observation.questions[-1]\n",
    "    \n",
    "#     print('=' * 10)\n",
    "#     print(f\"\"\"\\\n",
    "#                 提供する最良のyes/no回答を、キーワード [{observation.keyword}] に関する質問として回答してください。\n",
    "# \n",
    "#                 [質問] \"{last_question}\" [/質問]\n",
    "#                 \n",
    "#                 キーワードは [{observation.keyword}] です\n",
    "#                 \n",
    "#                 上記の質問に対する回答を次の形式で提供してください：\n",
    "#                 {Answer.xml_example()}\n",
    "#                 \"\"\"\n",
    "#          )\n",
    "#     print('=' * 10)\n",
    "    try:\n",
    "        responses = []\n",
    "        for i in range(5):\n",
    "            # 5回ループし、最も頻繁な応答を取得する\n",
    "            chat = await (\n",
    "                base.fork(\n",
    "                    f\"\"\"\\\n",
    "                    キーワード [{observation.keyword}] に関する質問に対する最良のyes/no回答を提供してください。\n",
    "\n",
    "                    [質問] \"{last_question}\" [/質問]\n",
    "\n",
    "                    キーワードは [{observation.keyword}] です\n",
    "\n",
    "                    上記の質問に対して最良の回答を次の形式で行ってください：\n",
    "                    {Answer.xml_example()}\n",
    "                    \"\"\"\n",
    "                )\n",
    "                .until_parsed_as(Answer, attempt_recovery=True, max_rounds=20)\n",
    "                .run()\n",
    "            )\n",
    "            responses.append(chat.last.parse(Answer).content.strip('*'))\n",
    "            \n",
    "        print(f'応答は {responses}')\n",
    "        return pd.Series(responses).value_counts().index[0]\n",
    "#         print('=' * 10)\n",
    "#         print('応答.....')\n",
    "#         print(chat.last)\n",
    "#         print('=' * 10)\n",
    "#         return chat.last.parse(Answer).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        print('%%%%%%%%%%%% エラーでyesと回答します %%%%%%%%%%%% ')\n",
    "        return 'yes'\n",
    "\n",
    "async def guess(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    try:\n",
    "\n",
    "        chat = await (\n",
    "            base.fork(\n",
    "                f\"\"\"\\\n",
    "                あなたは現在、キーワードについての推測を行なっています。\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml()}\n",
    "                </game-history>\n",
    "\n",
    "                上記の履歴に基づいて、単一の次の最良の推測を行い、次の形式にしてください：\n",
    "                {Guess.xml_example()}\n",
    "\n",
    "                - 上記の履歴に基づいた重複推測を避けてください\n",
    "                - 推測は特定の人、場所、物である必要があります\n",
    "\n",
    "                あなたの推測は何ですか？\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Guess, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        return chat.last.parse(Guess).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return 'フランス'\n",
    "    \n",
    "# vLLMとジェネレーターの設定\n",
    "\n",
    "try:\n",
    "    vllm = util.run_and_wait_for_port([\n",
    "        \"python\", \"-m\",\n",
    "        \"vllm.entrypoints.openai.api_server\",\n",
    "        \"--enforce-eager\",\n",
    "        \"--model\", str(g_model_path),\n",
    "        \"--port\", str(g_vllm_port),\n",
    "        \"--served-model-name\", g_vllm_model_name\n",
    "    ], g_vllm_port, {\"PYTHONPATH\": str(g_srvlib_path)})\n",
    "\n",
    "    print(\"vLLMが起動しました\")\n",
    "except ValueError:\n",
    "    print('vLLMはすでに実行中です')\n",
    "    \n",
    "    \n",
    "generator = rg.get_generator(g_generator_id)\n",
    "\n",
    "base =  generator.chat(\"\"\"\\\n",
    "あなたは20の質問ゲームの才能あるプレイヤーです。正確で集中しており、\n",
    "構造的なアプローチを持っています。役に立つ質問を作成し、推測を行い、キーワードに関する質問に答えます。\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# エントリーポイント\n",
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"キーワードはどの文字から始まりますか？\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"キーワードは '{letters[0]}' の文字で始まりますか？\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" または '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"キーワードは次の文字のいずれかで始まりますか {formatted_letters}？\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches\n",
    "\n",
    "# シンプルな質問者\n",
    "class SimpleQuestionerAgent():\n",
    "    def __init__(self, keyword_df: pd.DataFrame):\n",
    "        self.keyword_df = keyword_df\n",
    "        self.keyword_df_init = keyword_df.copy()\n",
    "        self.round = 0\n",
    "        self.category_questions = [\n",
    "            \"私たちは20の質問をしていますか？\",\n",
    "            \"キーワードは物で、場所ではないですか？\",\n",
    "            \"キーワードは場所ですか？\",\n",
    "        ]\n",
    "        self.found_category = False\n",
    "        \n",
    "    def filter_keywords(self, obs):\n",
    "        print(self.keyword_df.shape)\n",
    "        # 過去の回答に基づいてkeyword_dfをフィルタリング\n",
    "        for i, answer in enumerate(obs.answers):\n",
    "            if obs.questions[i] in self.category_questions:\n",
    "                if answer == 'yes':\n",
    "                    if obs.questions[i] == \"キーワードは物で、場所ではないですか？\":\n",
    "                        self.found_category = 'things'\n",
    "                    if obs.questions[i] == \"キーワードは場所ですか？\":\n",
    "                        self.found_category = 'place'\n",
    "                    fc = self.found_category\n",
    "                    self.keyword_df = self.keyword_df.query('category == @fc').reset_index(drop=True)\n",
    "    \n",
    "            if obs.questions[i].startswith('キーワードは次の文字で始まりますか'):\n",
    "                if self.keyword_df['first_letter'].nunique() <= 1:\n",
    "                    break\n",
    "                letter_question = obs.questions[i]\n",
    "                letters = extract_letters_from_question(letter_question)\n",
    "                self.keyword_df = self.keyword_df.reset_index(drop=True).copy()\n",
    "                if obs.answers[i] == 'yes':\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "                elif obs.answers[i] == 'no':\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        ~self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # リセット\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "            \n",
    "    def get_letters(self, obs, max_letters=20):\n",
    "        n_letters = self.keyword_df['first_letter'].nunique()\n",
    "        sample_letters = self.keyword_df['first_letter'].drop_duplicates().sample(n_letters // 2).values.tolist()\n",
    "        sample_letters = sample_letters[:max_letters]\n",
    "        print('サンプル文字', n_letters, sample_letters)\n",
    "        return sample_letters # ', '.join(sample_letters)\n",
    "    \n",
    "    def __call__(self, obs, *args):\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # リセット\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "        self.filter_keywords(obs)\n",
    "        if obs.turnType == 'ask':\n",
    "            self.round += 1\n",
    "            if (self.round <= 3 and not self.found_category):\n",
    "                response = self.category_questions[self.round - 1]\n",
    "            else:\n",
    "                sample_letters = self.get_letters(obs)\n",
    "                if len(sample_letters) == 0:\n",
    "                    n_sample = min(len(self.keyword_df), 10)\n",
    "                    possible_keywords = \", \".join(self.keyword_df['keyword'].sample(n_sample).values.tolist())\n",
    "                    response = f\"次の中にキーワードはありますか？ {possible_keywords}\"\n",
    "                else:\n",
    "                    sample_letters_str = str(sample_letters).replace('[','').replace(']','')\n",
    "                    response = format_first_letter_question(sample_letters)\n",
    "        elif obs.turnType == 'guess':\n",
    "            response = self.keyword_df['keyword'].sample(1).values[0]\n",
    "            # 推測された単語を削除\n",
    "            updated_df = self.keyword_df.loc[self.keyword_df['keyword'] != response].reset_index(drop=True).copy()\n",
    "            if len(updated_df) >= 1:\n",
    "                self.keyword_df = updated_df.copy()\n",
    "            else:\n",
    "                self.keyword_df = self.keyword_df_init.copy() # DFをリセット\n",
    "        return response\n",
    "\n",
    "\n",
    "keyword_df = pd.read_parquet(f'{g_agent_path}/keywords.parquet')\n",
    "question_agent = None\n",
    "\n",
    "async def observe(obs: t.Any) -> str:\n",
    "    observation = Observation(**obs.__dict__)\n",
    "    global question_agent\n",
    "    if question_agent is None:\n",
    "        question_agent = SimpleQuestionerAgent(keyword_df)\n",
    "\n",
    "    try:\n",
    "        match observation.turnType:\n",
    "            case \"ask\":\n",
    "                return question_agent(obs)\n",
    "            case \"answer\":\n",
    "                return await answer(base, observation)\n",
    "            case \"guess\":\n",
    "                return question_agent(obs)\n",
    "\n",
    "            case _:\n",
    "                raise ValueError(\"不明なターンタイプです\")\n",
    "    except Exception as e:\n",
    "        print(str(e), file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "def agent_fn(obs: t.Any, _: t.Any) -> str:\n",
    "    # 彼らのフレームワークで実行する際の非同期ゲート\n",
    "    import asyncio\n",
    "    return asyncio.run(observe(obs))\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:07:42.817674Z",
     "iopub.status.busy": "2024-06-18T20:07:42.817302Z",
     "iopub.status.idle": "2024-06-18T20:07:42.871384Z",
     "shell.execute_reply": "2024-06-18T20:07:42.870434Z",
     "shell.execute_reply.started": "2024-06-18T20:07:42.817645Z"
    },
    "papermill": {
     "duration": 0.016612,
     "end_time": "2024-04-17T13:47:49.33012",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.313508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "# メインエージェントファイル\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import typing as t\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# パスの修正\n",
    "\n",
    "g_working_path = Path('/kaggle/working')\n",
    "g_input_path = Path('/kaggle/input')\n",
    "g_temp_path = Path(\"/kaggle/tmp\")\n",
    "g_agent_path = Path(\"/kaggle_simulations/agent/\")\n",
    "\n",
    "g_model_path = g_temp_path / \"model\"\n",
    "g_srvlib_path = g_temp_path / \"srvlib\"\n",
    "g_lib_path = g_temp_path / \"lib\"\n",
    "\n",
    "if g_agent_path.exists():\n",
    "    g_lib_path = g_agent_path / \"lib\"\n",
    "    g_model_path = g_agent_path / \"model\"\n",
    "    g_srvlib_path = g_agent_path / \"srvlib\"\n",
    "else:\n",
    "    g_agent_path = Path('/kaggle/working')\n",
    "    \n",
    "sys.path.insert(0, str(g_lib_path))\n",
    "\n",
    "# ロギングのノイズ\n",
    "\n",
    "logging.getLogger(\"LiteLLM\").setLevel(logging.WARNING)\n",
    "\n",
    "# 固定インポート\n",
    "\n",
    "import util # noqa\n",
    "import rigging as rg  # noqa\n",
    "from pydantic import BaseModel, field_validator, StringConstraints  # noqa\n",
    "\n",
    "# 定数\n",
    "\n",
    "g_vllm_port = 9999\n",
    "g_vllm_model_name = \"custom\"\n",
    "\n",
    "g_generator_id = (\n",
    "    f\"openai/{g_vllm_model_name},\" \\\n",
    "    f\"api_base=http://localhost:{g_vllm_port}/v1,\" \\\n",
    "    \"api_key=sk-1234,\" \\\n",
    "    \"stop=<|eot_id|>\" # Llamaには少しの手助けが必要\n",
    ")\n",
    "\n",
    "# タイプ\n",
    "\n",
    "str_strip = t.Annotated[str, StringConstraints(strip_whitespace=True)]\n",
    "\n",
    "class Observation(BaseModel):\n",
    "    step: int\n",
    "    role: t.Literal[\"guesser\", \"answerer\"]\n",
    "    turnType: t.Literal[\"ask\", \"answer\", \"guess\"]\n",
    "    keyword: str\n",
    "    category: str\n",
    "    questions: list[str]\n",
    "    answers: list[str]\n",
    "    guesses: list[str]\n",
    "    \n",
    "    @property\n",
    "    def empty(self) -> bool:\n",
    "        return all(len(t) == 0 for t in [self.questions, self.answers, self.guesses])\n",
    "    \n",
    "    def get_history(self) -> t.Iterator[tuple[str, str, str]]:\n",
    "        return itertools.zip_longest(self.questions, self.answers, self.guesses, fillvalue=\"[none]\")\n",
    "\n",
    "    def get_history_as_xml(self, *, skip_guesses: bool = False) -> str:\n",
    "        if not self.empty:\n",
    "            history = \"\\n\".join(\n",
    "            f\"\"\"\\\n",
    "            <turn-{i}>\n",
    "            質問: {question}\n",
    "            回答: {answer}\n",
    "            {'推測: ' + guess if not skip_guesses else ''}\n",
    "            </turn-{i}>\n",
    "            \"\"\"\n",
    "            for i, (question, answer, guess) in enumerate(self.get_history())\n",
    "            )\n",
    "            return history\n",
    "        return \"まだありません。\"\n",
    "\n",
    "\n",
    "class Answer(rg.Model):\n",
    "    content: t.Literal[\"yes\", \"no\"]\n",
    "\n",
    "    @field_validator(\"content\", mode=\"before\")\n",
    "    def validate_content(cls, v: str) -> str:\n",
    "        for valid in [\"yes\", \"no\"]:\n",
    "            if v.lower().startswith(valid):\n",
    "                return valid\n",
    "        raise ValueError(\"無効な回答、'yes'または'no'でなければなりません。\")\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return f\"{Answer.xml_start_tag()}yes/no{Answer.xml_end_tag()}\"\n",
    "\n",
    "\n",
    "class Question(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Question(content=\"質問\").to_pretty_xml()\n",
    "\n",
    "\n",
    "class Guess(rg.Model):\n",
    "    content: str_strip\n",
    "\n",
    "    @classmethod\n",
    "    def xml_example(cls) -> str:\n",
    "        return Guess(content=\"物や場所\").to_pretty_xml()\n",
    "\n",
    "\n",
    "# 関数\n",
    "\n",
    "async def ask(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    if observation.step == 0:\n",
    "        # 初回の質問を上書きし、キーワードのバグが修正されるまで処理します。\n",
    "        return \"20の質問をしていますか？\"\n",
    "    \n",
    "    try:\n",
    "        chat = await (\n",
    "             base.fork(\n",
    "                f\"\"\"\\\n",
    "                あなたは現在、次の質問をしています。\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml(skip_guesses=True)}\n",
    "                </game-history>\n",
    "\n",
    "                上記の履歴に基づいて、次の最も有用なyes/no質問を行い、次の形式にしてください:\n",
    "                {Question.xml_example()}\n",
    "\n",
    "                - あなたの応答は、最も多くの情報を収集できる焦点を絞った質問でなければなりません\n",
    "                - 質問は一般的に始めてください\n",
    "                - 残りの検索空間を常に二分してください\n",
    "                - 以前の質問と回答に注意を払ってください\n",
    "\n",
    "                あなたの次の質問は何ですか？\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Question, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "        return chat.last.parse(Question).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return '人物ですか？'\n",
    "\n",
    "async def answer(base: rg.ChatPipeline, observation: Observation) -> t.Literal[\"yes\", \"no\"]:\n",
    "    if not observation.keyword:\n",
    "        print(\"キーワードが回答者に提供されていません\", file=sys.stderr)\n",
    "        return \"yes\" # キーワードのバグが修正されるまで上書きします。\n",
    "            \n",
    "    last_question = observation.questions[-1]\n",
    "    \n",
    "#     print('=' * 10)\n",
    "#     print(f\"\"\"\\\n",
    "#                 提供する最良のyes/no回答を、キーワード [{observation.keyword}] に関する質問として回答してください。\n",
    "# \n",
    "#                 [質問] \"{last_question}\" [/質問]\n",
    "#                 \n",
    "#                 キーワードは [{observation.keyword}] です\n",
    "#                 \n",
    "#                 上記の質問に対する回答を次の形式で提供してください：\n",
    "#                 {Answer.xml_example()}\n",
    "#                 \"\"\"\n",
    "#          )\n",
    "#     print('=' * 10)\n",
    "    try:\n",
    "        responses = []\n",
    "        for i in range(5):\n",
    "            # 5回ループし、最も頻繁な応答を取得する\n",
    "            chat = await (\n",
    "                base.fork(\n",
    "                    f\"\"\"\\\n",
    "                    キーワード [{observation.keyword}] に関する質問に対する最良のyes/no回答を提供してください。\n",
    "\n",
    "                    [質問] \"{last_question}\" [/質問]\n",
    "\n",
    "                    キーワードは [{observation.keyword}] です\n",
    "\n",
    "                    上記の質問に対して最良の回答を次の形式で行ってください：\n",
    "                    {Answer.xml_example()}\n",
    "                    \"\"\"\n",
    "                )\n",
    "                .until_parsed_as(Answer, attempt_recovery=True, max_rounds=20)\n",
    "                .run()\n",
    "            )\n",
    "            responses.append(chat.last.parse(Answer).content.strip('*'))\n",
    "            \n",
    "        print(f'応答は {responses}')\n",
    "        return pd.Series(responses).value_counts().index[0]\n",
    "#         print('=' * 10)\n",
    "#         print('応答.....')\n",
    "#         print(chat.last)\n",
    "#         print('=' * 10)\n",
    "#         return chat.last.parse(Answer).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        print('%%%%%%%%%%%% エラーでyesと回答します %%%%%%%%%%%% ')\n",
    "        return 'yes'\n",
    "\n",
    "async def guess(base: rg.ChatPipeline, observation: Observation) -> str:\n",
    "    try:\n",
    "\n",
    "        chat = await (\n",
    "            base.fork(\n",
    "                f\"\"\"\\\n",
    "                あなたは現在、キーワードについての推測を行なっています。\n",
    "\n",
    "                <game-history>\n",
    "                {observation.get_history_as_xml()}\n",
    "                </game-history>\n",
    "\n",
    "                上記の履歴に基づいて、単一の次の最良の推測を行い、次の形式にしてください：\n",
    "                {Guess.xml_example()}\n",
    "\n",
    "                - 上記の履歴に基づいた重複推測を避けてください\n",
    "                - 推測は特定の人、場所、物である必要があります\n",
    "\n",
    "                あなたの推測は何ですか？\n",
    "                \"\"\"\n",
    "            )\n",
    "            .until_parsed_as(Guess, attempt_recovery=True, max_rounds=20)\n",
    "            .run()\n",
    "        )\n",
    "\n",
    "        return chat.last.parse(Guess).content.strip('*')\n",
    "    except rg.error.MessagesExhaustedMaxRoundsError:\n",
    "        return 'フランス'\n",
    "    \n",
    "# vLLMとジェネレーターの設定\n",
    "\n",
    "try:\n",
    "    vllm = util.run_and_wait_for_port([\n",
    "        \"python\", \"-m\",\n",
    "        \"vllm.entrypoints.openai.api_server\",\n",
    "        \"--enforce-eager\",\n",
    "        \"--model\", str(g_model_path),\n",
    "        \"--port\", str(g_vllm_port),\n",
    "        \"--served-model-name\", g_vllm_model_name\n",
    "    ], g_vllm_port, {\"PYTHONPATH\": str(g_srvlib_path)})\n",
    "\n",
    "    print(\"vLLMが起動しました\")\n",
    "except ValueError:\n",
    "    print('vLLMはすでに実行中です')\n",
    "    \n",
    "    \n",
    "generator = rg.get_generator(g_generator_id)\n",
    "\n",
    "base =  generator.chat(\"\"\"\\\n",
    "あなたは20の質問ゲームの才能あるプレイヤーです。正確で集中しており、\n",
    "構造的なアプローチを持っています。役に立つ質問を作成し、推測を行い、キーワードに関する質問に答えます。\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# エントリーポイント\n",
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"キーワードはどの文字から始まりますか？\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"キーワードは '{letters[0]}' の文字で始まりますか？\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" または '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"キーワードは次の文字のいずれかで始まりますか {formatted_letters}？\"\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches\n",
    "\n",
    "# シンプルな質問者\n",
    "class SimpleQuestionerAgent():\n",
    "    def __init__(self, keyword_df: pd.DataFrame):\n",
    "        self.keyword_df = keyword_df\n",
    "        self.keyword_df_init = keyword_df.copy()\n",
    "        self.round = 0\n",
    "        self.category_questions = [\n",
    "            \"私たちは20の質問をしていますか？\",\n",
    "            \"キーワードは物で、場所ではないですか？\",\n",
    "            \"キーワードは場所ですか？\",\n",
    "        ]\n",
    "        self.found_category = False\n",
    "        \n",
    "    def filter_keywords(self, obs):\n",
    "        print(self.keyword_df.shape)\n",
    "        # 過去の回答に基づいてkeyword_dfをフィルタリング\n",
    "        for i, answer in enumerate(obs.answers):\n",
    "            if obs.questions[i] in self.category_questions:\n",
    "                if answer == 'yes':\n",
    "                    if obs.questions[i] == \"キーワードは物で、場所ではないですか？\":\n",
    "                        self.found_category = 'things'\n",
    "                    if obs.questions[i] == \"キーワードは場所ですか？\":\n",
    "                        self.found_category = 'place'\n",
    "                    fc = self.found_category\n",
    "                    self.keyword_df = self.keyword_df.query('category == @fc').reset_index(drop=True)\n",
    "    \n",
    "            if obs.questions[i].startswith('キーワードは次の文字で始まりますか'):\n",
    "                if self.keyword_df['first_letter'].nunique() <= 1:\n",
    "                    break\n",
    "                letter_question = obs.questions[i]\n",
    "                letters = extract_letters_from_question(letter_question)\n",
    "                self.keyword_df = self.keyword_df.reset_index(drop=True).copy()\n",
    "                if obs.answers[i] == 'yes':\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "                elif obs.answers[i] == 'no':\n",
    "                    self.keyword_df = self.keyword_df.loc[\n",
    "                        ~self.keyword_df['first_letter'].isin(letters)].reset_index(drop=True).copy()\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # リセット\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "            \n",
    "    def get_letters(self, obs, max_letters=20):\n",
    "        n_letters = self.keyword_df['first_letter'].nunique()\n",
    "        sample_letters = self.keyword_df['first_letter'].drop_duplicates().sample(n_letters // 2).values.tolist()\n",
    "        sample_letters = sample_letters[:max_letters]\n",
    "        print('サンプル文字', n_letters, sample_letters)\n",
    "        return sample_letters # ', '.join(sample_letters)\n",
    "    \n",
    "    def __call__(self, obs, *args):\n",
    "        if len(self.keyword_df) == 0:\n",
    "            # リセット\n",
    "            self.keyword_df = self.keyword_df_init.copy()\n",
    "        self.filter_keywords(obs)\n",
    "        if obs.turnType == 'ask':\n",
    "            self.round += 1\n",
    "            if (self.round <= 3 and not self.found_category):\n",
    "                response = self.category_questions[self.round - 1]\n",
    "            else:\n",
    "                sample_letters = self.get_letters(obs)\n",
    "                if len(sample_letters) == 0:\n",
    "                    n_sample = min(len(self.keyword_df), 10)\n",
    "                    possible_keywords = \", \".join(self.keyword_df['keyword'].sample(n_sample).values.tolist())\n",
    "                    response = f\"次の中にキーワードはありますか？ {possible_keywords}\"\n",
    "                else:\n",
    "                    sample_letters_str = str(sample_letters).replace('[','').replace(']','')\n",
    "                    response = format_first_letter_question(sample_letters)\n",
    "        elif obs.turnType == 'guess':\n",
    "            response = self.keyword_df['keyword'].sample(1).values[0]\n",
    "            # 推測された単語を削除\n",
    "            updated_df = self.keyword_df.loc[self.keyword_df['keyword'] != response].reset_index(drop=True).copy()\n",
    "            if len(updated_df) >= 1:\n",
    "                self.keyword_df = updated_df.copy()\n",
    "            else:\n",
    "                self.keyword_df = self.keyword_df_init.copy() # DFをリセット\n",
    "        return response\n",
    "\n",
    "\n",
    "keyword_df = pd.read_parquet(f'{g_agent_path}/keywords.parquet')\n",
    "question_agent = None\n",
    "\n",
    "async def observe(obs: t.Any) -> str:\n",
    "    observation = Observation(**obs.__dict__)\n",
    "    global question_agent\n",
    "    if question_agent is None:\n",
    "        question_agent = SimpleQuestionerAgent(keyword_df)\n",
    "\n",
    "    try:\n",
    "        match observation.turnType:\n",
    "            case \"ask\":\n",
    "                return question_agent(obs)\n",
    "            case \"answer\":\n",
    "                return await answer(base, observation)\n",
    "            case \"guess\":\n",
    "                return question_agent(obs)\n",
    "\n",
    "            case _:\n",
    "                raise ValueError(\"不明なターンタイプです\")\n",
    "    except Exception as e:\n",
    "        print(str(e), file=sys.stderr)\n",
    "        raise\n",
    "\n",
    "def agent_fn(obs: t.Any, _: t.Any) -> str:\n",
    "    # 彼らのフレームワークで実行する際の非同期ゲート\n",
    "    import asyncio\n",
    "    return asyncio.run(observe(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29180d",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Test the Agent Against Itself\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# エージェントを自己対戦してテスト\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1f6174",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"Does the keyword start with any letter?\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"Does the keyword start with the letter '{letters[0]}'\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" or '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"Does the keyword start with one of the letters {formatted_letters}?\"\n",
    "\n",
    "format_first_letter_question(['a','b','c'])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"キーワードはどの文字から始まりますか？\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"キーワードは '{letters[0]}' の文字で始まりますか？\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" または '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"キーワードは次の文字のいずれかで始まりますか {formatted_letters}？\"\n",
    "\n",
    "format_first_letter_question(['a','b','c'])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:07:44.085235Z",
     "iopub.status.busy": "2024-06-18T20:07:44.084879Z",
     "iopub.status.idle": "2024-06-18T20:07:45.842315Z",
     "shell.execute_reply": "2024-06-18T20:07:45.841352Z",
     "shell.execute_reply.started": "2024-06-18T20:07:44.085207Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_first_letter_question(letters):\n",
    "    if not letters:\n",
    "        return \"キーワードはどの文字から始まりますか？\"\n",
    "    \n",
    "    if len(letters) == 1:\n",
    "        return f\"キーワードは '{letters[0]}' の文字で始まりますか？\"\n",
    "    \n",
    "    formatted_letters = \", \".join(f\"'{letter}'\" for letter in letters[:-1])\n",
    "    formatted_letters += f\" または '{letters[-1]}'\"\n",
    "    \n",
    "    return f\"キーワードは次の文字のいずれかで始まりますか {formatted_letters}？\"\n",
    "\n",
    "format_first_letter_question(['a','b','c'])\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_letters_from_question(question):\n",
    "    pattern = r\"'([a-zA-Z])'\"\n",
    "    matches = re.findall(pattern, question)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a30025",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main import Observation, agent_fn, observe\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main import Observation, agent_fn, observe\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:07:45.84427Z",
     "iopub.status.busy": "2024-06-18T20:07:45.843989Z",
     "iopub.status.idle": "2024-06-18T20:07:45.888115Z",
     "shell.execute_reply": "2024-06-18T20:07:45.887152Z",
     "shell.execute_reply.started": "2024-06-18T20:07:45.844245Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from main import Observation, agent_fn, observe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c40951",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Check if vllm is running\n",
    "!ps -aef | grep vllm\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# vllmが実行中かどうか確認\n",
    "!ps -aef | grep vllm\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:07:46.655031Z",
     "iopub.status.busy": "2024-06-18T20:07:46.6543Z",
     "iopub.status.idle": "2024-06-18T20:07:47.652045Z",
     "shell.execute_reply": "2024-06-18T20:07:47.650877Z",
     "shell.execute_reply.started": "2024-06-18T20:07:46.655Z"
    }
   },
   "outputs": [],
   "source": [
    "# vllmが実行中かどうか確認\n",
    "!ps -aef | grep vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade106d9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "keyword_df = pd.read_parquet('keywords.parquet')\n",
    "sample = keyword_df.sample(1)\n",
    "\n",
    "obs = Observation(step = 0,\n",
    "    role = 'guesser',\n",
    "    turnType= \"ask\",\n",
    "    keyword= sample['keyword'].values[0],\n",
    "    category= sample['category'].values[0],\n",
    "    questions = [],\n",
    "    answers= [],\n",
    "    guesses= [],\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'ask'\n",
    "    question = await observe(obs)\n",
    "    print(f'[{i} Question]: {question}')\n",
    "    obs.questions.append(question)\n",
    "    obs.role = 'answerer'\n",
    "    obs.turnType = 'answer'\n",
    "    answer = await observe(obs)\n",
    "    obs.answers.append(answer)\n",
    "    \n",
    "    if obs.questions[-1].startswith('Are we playing 20 questions?'):\n",
    "        gt_answer = answer # whatever\n",
    "    elif obs.questions[-1].startswith('Is the keyword a thing that is not a place?'):\n",
    "        if sample['category'].values[0] == 'things':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword a place?'):\n",
    "        if sample['category'].values[0] == 'place':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Does the keyword start'):\n",
    "        letters_guess = extract_letters_from_question(obs.questions[-1])\n",
    "        gt_answer = obs.keyword[0] in letters_guess\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword one of the following?'):\n",
    "        possible_kw = obs.questions[-1].replace('Is the keyword one of the following? ','').split(',')\n",
    "        possible_kw = [c.strip(' ') for c in possible_kw]\n",
    "        print(possible_kw)\n",
    "        gt_answer = obs.keyword in possible_kw\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "\n",
    "    print(f'[{i} Answer]: {answer} [True Answer]: {gt_answer}')\n",
    "    if answer != gt_answer:\n",
    "        break\n",
    "\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'guess'\n",
    "    guess = await observe(obs)\n",
    "    print(f'[{i} Guess]: {guess} - [Keyword]: {obs.keyword}')\n",
    "    obs.guesses.append(guess)\n",
    "    if guess == obs.keyword:\n",
    "        print('GOT IT!')\n",
    "        break\n",
    "        \n",
    "    obs.step += 1\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "keyword_df = pd.read_parquet('keywords.parquet')\n",
    "sample = keyword_df.sample(1)\n",
    "\n",
    "obs = Observation(step = 0,\n",
    "    role = 'guesser',\n",
    "    turnType= \"ask\",\n",
    "    keyword= sample['keyword'].values[0],\n",
    "    category= sample['category'].values[0],\n",
    "    questions = [],\n",
    "    answers= [],\n",
    "    guesses= [],\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'ask'\n",
    "    question = await observe(obs)\n",
    "    print(f'[{i}の質問]: {question}')\n",
    "    obs.questions.append(question)\n",
    "    obs.role = 'answerer'\n",
    "    obs.turnType = 'answer'\n",
    "    answer = await observe(obs)\n",
    "    obs.answers.append(answer)\n",
    "    \n",
    "    if obs.questions[-1].startswith('Are we playing 20 questions?'):\n",
    "        gt_answer = answer # なんでも良い\n",
    "    elif obs.questions[-1].startswith('Is the keyword a thing that is not a place?'):\n",
    "        if sample['category'].values[0] == 'things':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword a place?'):\n",
    "        if sample['category'].values[0] == 'place':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Does the keyword start'):\n",
    "        letters_guess = extract_letters_from_question(obs.questions[-1])\n",
    "        gt_answer = obs.keyword[0] in letters_guess\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword one of the following?'):\n",
    "        possible_kw = obs.questions[-1].replace('Is the keyword one of the following? ','').split(',')\n",
    "        possible_kw = [c.strip(' ') for c in possible_kw]\n",
    "        print(possible_kw)\n",
    "        gt_answer = obs.keyword in possible_kw\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "\n",
    "    print(f'[{i}の回答]: {answer} [真の回答]: {gt_answer}')\n",
    "    if answer != gt_answer:\n",
    "        break\n",
    "\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'guess'\n",
    "    guess = await observe(obs)\n",
    "    print(f'[{i}の推測]: {guess} - [キーワード]: {obs.keyword}')\n",
    "    obs.guesses.append(guess)\n",
    "    if guess == obs.keyword:\n",
    "        print('当たり！')\n",
    "        break\n",
    "        \n",
    "    obs.step += 1\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T20:07:48.447833Z",
     "iopub.status.busy": "2024-06-18T20:07:48.447029Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "keyword_df = pd.read_parquet('keywords.parquet')\n",
    "sample = keyword_df.sample(1)\n",
    "\n",
    "obs = Observation(step = 0,\n",
    "    role = 'guesser',\n",
    "    turnType= \"ask\",\n",
    "    keyword= sample['keyword'].values[0],\n",
    "    category= sample['category'].values[0],\n",
    "    questions = [],\n",
    "    answers= [],\n",
    "    guesses= [],\n",
    ")\n",
    "\n",
    "\n",
    "for i in range(20):\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'ask'\n",
    "    question = await observe(obs)\n",
    "    print(f'[{i}の質問]: {question}')\n",
    "    obs.questions.append(question)\n",
    "    obs.role = 'answerer'\n",
    "    obs.turnType = 'answer'\n",
    "    answer = await observe(obs)\n",
    "    obs.answers.append(answer)\n",
    "    \n",
    "    if obs.questions[-1].startswith('Are we playing 20 questions?'):\n",
    "        gt_answer = answer # なんでも良い\n",
    "    elif obs.questions[-1].startswith('Is the keyword a thing that is not a place?'):\n",
    "        if sample['category'].values[0] == 'things':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword a place?'):\n",
    "        if sample['category'].values[0] == 'place':\n",
    "            gt_answer = 'yes'\n",
    "        else:\n",
    "            gt_answer = 'no'\n",
    "    elif obs.questions[-1].startswith('Does the keyword start'):\n",
    "        letters_guess = extract_letters_from_question(obs.questions[-1])\n",
    "        gt_answer = obs.keyword[0] in letters_guess\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "    elif obs.questions[-1].startswith('Is the keyword one of the following?'):\n",
    "        possible_kw = obs.questions[-1].replace('Is the keyword one of the following? ','').split(',')\n",
    "        possible_kw = [c.strip(' ') for c in possible_kw]\n",
    "        print(possible_kw)\n",
    "        gt_answer = obs.keyword in possible_kw\n",
    "        gt_answer = 'yes' if gt_answer else 'no'\n",
    "\n",
    "    print(f'[{i}の回答]: {answer} [真の回答]: {gt_answer}')\n",
    "    if answer != gt_answer:\n",
    "        break\n",
    "\n",
    "    obs.role = 'guesser'\n",
    "    obs.turnType = 'guess'\n",
    "    guess = await observe(obs)\n",
    "    print(f'[{i}の推測]: {guess} - [キーワード]: {obs.keyword}')\n",
    "    obs.guesses.append(guess)\n",
    "    if guess == obs.keyword:\n",
    "        print('当たり！')\n",
    "        break\n",
    "        \n",
    "    obs.step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59283b34",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Zipping Model and Code for Submission\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# モデルとコードの提出用圧縮\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2169cf70",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!apt install pigz pv\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!apt install pigz pv\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "execution": {
     "iopub.execute_input": "2024-06-18T20:05:09.682043Z",
     "iopub.status.busy": "2024-06-18T20:05:09.681791Z",
     "iopub.status.idle": "2024-06-18T20:05:12.711224Z",
     "shell.execute_reply": "2024-06-18T20:05:12.710045Z",
     "shell.execute_reply.started": "2024-06-18T20:05:09.682021Z"
    }
   },
   "outputs": [],
   "source": [
    "!apt install pigz pv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fac1b9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast' \\\n",
    "    -cf submission.tar.gz \\\n",
    "    --dereference \\\n",
    "    -C /kaggle/tmp model lib srvlib \\\n",
    "    -C /kaggle/working main.py util.py \\\n",
    "    -C /kaggle/working keywords.parquet\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!tar --use-compress-program='pigz --fast' \\\n",
    "    -cf submission.tar.gz \\\n",
    "    --dereference \\\n",
    "    -C /kaggle/tmp model lib srvlib \\\n",
    "    -C /kaggle/working main.py util.py \\\n",
    "    -C /kaggle/working keywords.parquet\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:16:49.684667Z",
     "iopub.status.busy": "2024-06-18T19:16:49.684329Z",
     "iopub.status.idle": "2024-06-18T19:19:49.999133Z",
     "shell.execute_reply": "2024-06-18T19:19:49.997937Z",
     "shell.execute_reply.started": "2024-06-18T19:16:49.684638Z"
    },
    "papermill": {
     "duration": 5.560311,
     "end_time": "2024-04-17T13:47:54.892856",
     "exception": false,
     "start_time": "2024-04-17T13:47:49.332545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar --use-compress-program='pigz --fast' \\\n",
    "    -cf submission.tar.gz \\\n",
    "    --dereference \\\n",
    "    -C /kaggle/tmp model lib srvlib \\\n",
    "    -C /kaggle/working main.py util.py \\\n",
    "    -C /kaggle/working keywords.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c58523",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!ls -GFlash --color\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!ls -GFlash --color\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:19:50.002318Z",
     "iopub.status.busy": "2024-06-18T19:19:50.001899Z",
     "iopub.status.idle": "2024-06-18T19:19:51.037256Z",
     "shell.execute_reply": "2024-06-18T19:19:51.036303Z",
     "shell.execute_reply.started": "2024-06-18T19:19:50.002277Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -GFlash --color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491fa535",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Submitting using Kaggle CLI\n",
    "\n",
    "Optionally you can submit using the kaggle cli interface without needing to re-run commit the notebook.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Kaggle CLIを使用した提出\n",
    "\n",
    "オプションで、ノートブックを再実行することなく、kaggle CLIインターフェースを使用して提出できます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17963c6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# !KAGGLE_USERNAME={KAGGLE_USERNAME} \\\n",
    "#  KAGGLE_KEY={KAGGLE_KEY} \\\n",
    "#  kaggle competitions submit -c llm-20-questions -f submission.tar.gz -m \"submit from notebook\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# !KAGGLE_USERNAME={KAGGLE_USERNAME} \\\n",
    "#  KAGGLE_KEY={KAGGLE_KEY} \\\n",
    "#  kaggle competitions submit -c llm-20-questions -f submission.tar.gz -m \"ノートブックから提出\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T19:19:51.040706Z",
     "iopub.status.busy": "2024-06-18T19:19:51.040378Z",
     "iopub.status.idle": "2024-06-18T19:19:51.086269Z",
     "shell.execute_reply": "2024-06-18T19:19:51.085134Z",
     "shell.execute_reply.started": "2024-06-18T19:19:51.040676Z"
    }
   },
   "outputs": [],
   "source": [
    "# !KAGGLE_USERNAME={KAGGLE_USERNAME} \\\n",
    "#  KAGGLE_KEY={KAGGLE_KEY} \\\n",
    "#  kaggle competitions submit -c llm-20-questions -f submission.tar.gz -m \"ノートブックから提出\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037d300",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント\n",
    "\n",
    "> ## Bhanu Prakash M\n",
    "> \n",
    "> こんにちは [@robikscube](https://www.kaggle.com/robikscube)、\n",
    "> \n",
    "> vLLMサーバーを実行する方法を教えていただけますか？デバッグを有効にすると、次のようなエラーが表示されます。\n",
    "> \n",
    "> INFO 06-18 21:44:58 selector.py:69] VoltaおよびTuring GPU用にFlashAttention-2バックエンドを使用できません。\n",
    "> \n",
    "> INFO 06-18 21:44:58 selector.py:32] XFormersバックエンドを使用しています。\n",
    "> \n",
    "> エラーの長いトレースバックが続き、最終的な文は\n",
    "> \n",
    "> ValueError: Bfloat16は、計算能力が少なくとも8.0のGPUでのみサポートされています。あなたのTesla P100-PCIE-16GB GPUは、計算能力が6.0です。CLIのdtypeフラグを明示的に設定することでfloat16を使用できます。例えば、--dtype=halfのように。\n",
    "\n",
    "> ## Rob Mulla トピック作成者\n",
    "> \n",
    "> 実行しようとしているモデルは何ですか？\n",
    "> \n",
    "> > ## Bhanu Prakash M\n",
    "> > \n",
    "> > phi-3モデルで、その重み層をllama形式に変換しました\n",
    "> > > [https://huggingface.co/rhysjones/Phi-3-mini-mango-1-llamafied](https://huggingface.co/rhysjones/Phi-3-mini-mango-1-llamafied)\n",
    "> > > これが正確なモデルです\n",
    "> > > \n",
    "> > > > ## Bhanu Prakash M\n",
    "> > > > [@robikscube](https://www.kaggle.com/robikscube) 進展はありますか？\n",
    "> > > > \n",
    "> > > > > ## Rob Mulla トピック作成者\n",
    "> > > > > ここで動作させることができました: [https://www.kaggle.com/code/robikscube/phi3-intro-to-rigging-for-llm-20-questions/](https://www.kaggle.com/code/robikscube/phi3-intro-to-rigging-for-llm-20-questions/)\n",
    "> > > > \n",
    "\n",
    "---\n",
    "\n",
    "> ## OminousDude\n",
    "> \n",
    "> \"プロセスが120秒以内にポート9999を開かなかった\"というエラーが発生するのはなぜですか？ [@robikscube](https://www.kaggle.com/robikscube)\n",
    "> \n",
    "> \n",
    "> > ## Rob Mulla トピック作成者\n",
    "> > \n",
    "> > 見てみます！ヘッドアップをありがとう。\n",
    "> > \n",
    "> > \n",
    "> > > ## OminousDude\n",
    "> > > \n",
    "> > > ありがとうございます！私はriggingの実験をしているのですが、時間配分に合わなくて、このコードは本当に助かります！\n",
    "> > > \n",
    "> > > \n",
    "\n",
    "---\n",
    "\n",
    "> ## OminousDude\n",
    "> \n",
    "> こんにちは、あなたのコードをテストしていたのですが、実行したところ、\"AttributeError: 'coroutine' object has no attribute 'last'\"という例外で失敗しました。このエラーに遭遇したことはありますか？\n",
    "\n",
    "> ## Rob Mulla トピック作成者\n",
    "> \n",
    "> 教えてくれてありがとう。このエラーも出ているのを確認しています。私たちは現在、riggingを積極的に開発しており、これは最新リリースからの変更のようです。ノートブックを更新してこの変更を修正するか、古いバージョンのriggingをピン留めして問題を解決するかもしれません。\n",
    "\n",
    "> > ## OminousDude\n",
    "> > > ありがとうございます！\n",
    "> > > \n",
    "> > > > ## OminousDude\n",
    "> > > > バージョン7は動作しますか？\n",
    "> > > \n",
    "\n",
    "---\n",
    "\n",
    "> ## OminousDude\n",
    "> \n",
    "> 私は自分のローカルマシンでこれを試しているのですが、動作しません。なぜか分かりますか？ [@robikscube](https://www.kaggle.com/robikscube) \n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## OminousDude\n",
    "> \n",
    "> これはバグかもしれませんが、このコードは\"solidrust/Meta-Llama-3-8B-Instruct-hf-AWQ\"でのみ動作します。これを元にして、Llamaの大きいバージョンを使おうとしているときにこれに気づきました。\n",
    "> \n",
    "> "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.923583,
   "end_time": "2024-04-17T13:50:23.369773",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-17T13:47:33.44619",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
