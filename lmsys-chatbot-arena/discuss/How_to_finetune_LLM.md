# How to finetune LLM? 

**bao** *Tue Jun 25 2024 18:26:28 GMT+0900 (æ—¥æœ¬æ¨™æº–æ™‚)* (0 votes)

I am a beginner in LLM and would like to get started. Could you please explain how to fine-tune the model for this scenario? Is it done using methods like DPO with LLama-Factory?



---

 # Comments from other users

> ## Staru09
> 
> You can check this [https://dassum.medium.com/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07](https://dassum.medium.com/fine-tune-large-language-model-llm-on-a-custom-dataset-with-qlora-fb60abdeba07)
> 
> 
> 
> > ## Nikhil Narayan
> > 
> > Well do you have resources about any other way to do this
> > 
> > 
> > 
> > > ## Staru09
> > > 
> > > Resources as in computation or something else. If computation is an issue then you can try using tools like llamaedge or wasmedge. They are very good frameworks to work with but you should know Rust otherwise you can use PEFT, or converting into lower bit like 8 or 16 to fine-tune along with LORA, QLORA etc.
> > > 
> > > 
> > > 


---

> ## Lorry Zou
> 
> There are plenty of great videos on YouTube teaching you how to fine-tune LLM and Llama 3 specifically.
> 
> 
> 
> > ## YingxiZhang
> > 
> > Indeed, there are a lot of resources on YouTube and I've learned a lot.ðŸ˜€
> > 
> > 
> > 


---

