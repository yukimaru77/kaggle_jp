{
    "main_topic": {
        "author": "Darek K≈Çeczek",
        "title": "External data - additional 157k human preference ratings üî•üî•üî•",
        "content": "I'm super excited to see if smaller models (Kaggle GPU compatible) can effectively rate responses from much larger LLMs. To help you improve your models, I published a dataset with external data:\n\n[https://www.kaggle.com/datasets/thedrcat/llm-human-preference-data-ultrafeedback/data](https://www.kaggle.com/datasets/thedrcat/llm-human-preference-data-ultrafeedback/data)\n\nThis is based on Ultrafeedback dataset published on HF by Argilla. I additionally converted it into the competition train data format. \n\nEDIT: Note that Ultrafeedback uses GPT4 as a judge as a proxy for human raters. I also added ties between models in version 2 that were previously filtered out. See original dataset paper [here](https://arxiv.org/pdf/2310.01377). Thanks [@nbroad](https://www.kaggle.com/nbroad) for catching this. \n\nEnjoy ‚ù§Ô∏èüôèüëç\n\n",
        "date": "Fri May 03 2024 07:09:30 GMT+0900 (Êó•Êú¨Ê®ôÊ∫ñÊôÇ)",
        "votes": "96"
    },
    "comments": [
        {
            "author": "Dlond Mike",
            "content": "no use‚Ä¶but just for my notebook\n\n",
            "date": "Posted 21 days ago  ¬∑  173rd in this Competition",
            "votes": "1",
            "reply": []
        },
        {
            "author": "Rich Olson",
            "content": "I added 50k of the items from this to my \"Deberta + TF-IDF + Word2Vec + Length\" notebook (it's public - I'd post a link - but Kaggle thinks I'm spamming).\n\ngot an identical 1.011 on the LB.  Had same experience with [this dataset](https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500973).\n\nI take this as indication the data is probably good (or at least not bad) - it's just my notebook isn't able to benefit from the extra data.\n\n",
            "date": "Posted 3 months ago  ¬∑  1199th in this Competition",
            "votes": "5",
            "reply": []
        },
        {
            "author": "Nicholas Broad",
            "content": "How do you think the tie should be handled? If the scores are equal, it should be a tie? (Your dataset only has \"model a\" winning)\n\nUpdate:\n\nI read more into how they processed the dataset and I noticed a few things:\n\nI don't think this is human preferences. I think this is using [GPT-4 to rate the responses](https://github.com/OpenBMB/UltraFeedback/tree/main?tab=readme-ov-file#introduction)\n[Ultrafeedback intentionally filters out ties](https://huggingface.co/datasets/argilla/ultrafeedback-binarized-preferences/blob/main/README.md#dataset-processing), whereas the LMSYS dataset has roughly even split between model a winning, b winning, and ties.  \n",
            "date": "Posted 3 months ago  ¬∑  18th in this Competition",
            "votes": "8",
            "reply": [
                {
                    "author": "Darek K≈ÇeczekTopic Author",
                    "content": "Great catch, thanks! I'll update the thread. I think this can be still useful for pretraining or pseudolabeling. Also found the paper here: [https://arxiv.org/pdf/2310.01377](https://arxiv.org/pdf/2310.01377)\n\n",
                    "date": "Posted 3 months ago",
                    "votes": "1",
                    "reply": [
                        {
                            "author": "Darek K≈ÇeczekTopic Author",
                            "content": "I'll see if I can reproduce the binarization while keeping ties too. \n\n",
                            "date": "Posted 3 months ago",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "Darek K≈ÇeczekTopic Author",
                            "content": "Version 2 of the [dataset](https://www.kaggle.com/datasets/thedrcat/llm-human-preference-data-ultrafeedback) has ties between models added now. \n\n",
                            "date": "Posted 3 months ago",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "Turbo",
                            "content": "Intersting dataset.\n\nDid you use this dataset and boost your score?\n\n",
                            "date": "Posted 10 days ago  ¬∑  162nd in this Competition",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "eli plutchok",
            "content": "Wouldn't you expect gpt-4 rankings to be very different than human rankings? \n\n",
            "date": "Posted 3 months ago  ¬∑  1077th in this Competition",
            "votes": "2",
            "reply": [
                {
                    "author": "Darek K≈ÇeczekTopic Author",
                    "content": "There's research pointing that GPT-4 correlates well with human ratings, for example [here](https://arxiv.org/pdf/2306.05685):\n\nThe agreement [‚Ä¶] between GPT-4 and humans reaches 85%, which is even higher than the agreement among humans (81%). This means GPT-4‚Äôs judgments closely align with the majority of humans.\n\n",
                    "date": "Posted 3 months ago",
                    "votes": "9",
                    "reply": [
                        {
                            "author": "eli plutchok",
                            "content": "Wow. Have you tested GPT4 on the training examples to see how well it scores?\n\n",
                            "date": "Posted 3 months ago  ¬∑  1077th in this Competition",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "justin1357",
            "content": "Is any data from kaggle covered in this dataset?\n\n",
            "date": "Posted a month ago  ¬∑  19th in this Competition",
            "votes": "0",
            "reply": []
        }
    ]
}