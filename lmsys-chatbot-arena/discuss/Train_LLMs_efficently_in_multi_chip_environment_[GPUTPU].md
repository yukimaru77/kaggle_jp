# Train LLMs efficently in multi chip environment [GPU/TPU]

**Simon Veitner** *Wed May 29 2024 16:24:01 GMT+0900 (日本標準時)* (4 votes)

Hello guys,

I shared a customizable notebook that let's you train LLMs with FSDP and potentially TP technique on multiple GPU/TPU chips.

The architecture was inspired by [first place solution in LLM science exam.](https://www.kaggle.com/competitions/kaggle-llm-science-exam/discussion/446422)

Note that the score of the notebook is rather bad but can be easily improved by adjusting preproccesing/modelling etc etc.

[See the notebook here](https://www.kaggle.com/code/simonveitner/fsdp-with-scalax)



