{
    "main_topic": {
        "author": "suri@7",
        "title": "How to avoid wights and bias logging, when I try train the model, it was asking wights and bias token id",
        "content": "when I try train the model, it was asking wights and bias token id. I don't want to wights and bias to my model.\n\n```\ntraining_args = TrainingArguments(\n  output_dir=\"./kaggle/input/lmsys-chatbot-arena/bert_model\",\n  learning_rate=2e-5,\n  per_device_train_batch_size=3,\n  per_device_eval_batch_size=3,\n  num_train_epochs=2,\n  weight_decay=0.01,\n  evaluation_strategy=\"epoch\",\n  save_strategy=\"epoch\",\n  load_best_model_at_end=True,\n)\ntrainer = Trainer(\n  model=model,\n  args=training_args,\n  train_dataset=train_dataset,\n  eval_dataset=test_dataset,\n  tokenizer=tokenizer,\n  data_collator=data_collator,\n  #compute_metrics=compute_metrics,\n)\ntrainer.train()\n\n```\n\n",
        "date": "Wed Jul 10 2024 18:24:36 GMT+0900 (日本標準時)",
        "votes": "0"
    },
    "comments": [
        {
            "author": "waechter",
            "content": "Set report_to='none' in TrainingArguments if you don't want to use remote logging\n\nreport_to (str or List[str], optional, defaults to \"all\") — The list of integrations to report the results and logs to. Supported platforms are \"azure_ml\", \"clearml\", \"codecarbon\", \"comet_ml\", \"dagshub\", \"dvclive\", \"flyte\", \"mlflow\", \"neptune\", \"tensorboard\", and \"wandb\". Use \"all\" to report to all integrations installed, \"none\" for no integrations. \n\n  From [https://huggingface.co/docs/transformers/en/main_classes/trainer](https://huggingface.co/docs/transformers/en/main_classes/trainer)\n\n",
            "date": "Posted 25 days ago  ·  654th in this Competition",
            "votes": "1",
            "reply": [
                {
                    "author": "suri@7Topic Author",
                    "content": "Thanks for your help [@waechter](https://www.kaggle.com/waechter) ,, I would like to know after training my model how, can I can submit the prediction offline, When saving the model Kaggle input path, It does not load when submitted to p predictions.\n\n",
                    "date": "Posted 24 days ago",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "waechter",
                            "content": "output_dir=\"./kaggle/input/lmsys-chatbot-arena/bert_model\",\n\nI think this is wrong because you trying to write to the kaggle/input directory (which is read only)\n\nYou should save the pretrained model to kaggle/working dir : output_dir=\"kaggle/working/bert_model\"\n\n",
                            "date": "Posted 24 days ago  ·  654th in this Competition",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "suri@7Topic Author",
                            "content": "ok, Thanks\n\n",
                            "date": "Posted 24 days ago",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        }
    ]
}