{
    "main_topic": {
        "author": "KeShuang Liu",
        "title": "Why I did not get the corresponding checkpoint when I continued training from the checkpoint and reset save_steps? My save_steps=5000 before, and now I changed it to 200, but after 200 steps, I did not get the corresponding checkpoint.",
        "content": "training_args = TrainingArguments(\n\n    output_dir=config.output_dir,\n\n    overwrite_output_dir=True,\n\n    report_to=\"none\",\n\n    num_train_epochs=config.n_epochs,\n\n    per_device_train_batch_size=config.per_device_train_batch_size,\n\n    gradient_accumulation_steps=config.gradient_accumulation_steps,\n\n    per_device_eval_batch_size=config.per_device_eval_batch_size,\n\n    logging_steps=10,\n\n    eval_strategy=\"epoch\",\n\n    save_strategy=\"steps\", \n\n    save_steps=200,        # 每5000步保存一次\n\n    # eval_steps=2000, \n\n    optim=config.optim_type,\n\n    fp16=True,\n\n    learning_rate=config.lr,\n\n    warmup_steps=config.warmup_steps,\n\n    resume_from_checkpoint=\"/liukeshuang/lora_model/gemma_bnb_4_g8/checkpoint-2873\"\n\n)\n\n",
        "date": "Sun Jul 28 2024 21:09:52 GMT+0900 (日本標準時)",
        "votes": "2"
    },
    "comments": [
        {
            "author": "Piotr Gabrys",
            "content": "[EDIT] It's uncertain whether this code solves the problem.\n\nHi! You can do it like this:\n\n```\ntraining_args = TrainingArguments(\noutput_dir=config.output_dir,\noverwrite_output_dir=True,\nreport_to=\"none\",\nnum_train_epochs=config.n_epochs,\nper_device_train_batch_size=config.per_device_train_batch_size,\ngradient_accumulation_steps=config.gradient_accumulation_steps,\nper_device_eval_batch_size=config.per_device_eval_batch_size,\nlogging_steps=10,\neval_strategy=\"epoch\",\nsave_strategy=\"steps\",\nsave_steps=200, # 每5000步保存一次\n# eval_steps=2000,\noptim=config.optim_type,\nfp16=True,\nlearning_rate=config.lr,\nwarmup_steps=config.warmup_steps\n\ntrainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=dataset['train'],\n        eval_dataset=dataset['test'],\n        tokenizer=tokenizer,\n    )\n\ntrainer.train(\"/liukeshuang/lora_model/gemma_bnb_4_g8/checkpoint-2873\")\n\n```\n\nreference: [https://github.com/huggingface/transformers/issues/7198](https://github.com/huggingface/transformers/issues/7198)\n\nHope that helps!\n\n",
            "date": "Posted 7 days ago",
            "votes": "3",
            "reply": [
                {
                    "author": "KeShuang LiuTopic Author",
                    "content": "Thanks for your reply, I will try\n\n",
                    "date": "Posted 7 days ago  ·  312th in this Competition",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "Piotr Gabrys",
                            "content": "Has it worked?\n\n",
                            "date": "Posted 6 days ago",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "KeShuang LiuTopic Author",
                            "content": "I used [@nbroad](https://www.kaggle.com/nbroad) method and it works fine.\n\n",
                            "date": "Posted 6 days ago  ·  312th in this Competition",
                            "votes": "1",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Nicholas Broad",
            "content": "It's because you are resuming from checkpoint. It will use your old value when you resume. I think you can overwrite training_args.bin in your checkpoint to have the new values and it should work\n\n",
            "date": "Posted 7 days ago  ·  18th in this Competition",
            "votes": "2",
            "reply": []
        },
        {
            "author": "Dlond Mike",
            "content": "same issue\n\n",
            "date": "Posted 7 days ago  ·  173rd in this Competition",
            "votes": "0",
            "reply": []
        }
    ]
}