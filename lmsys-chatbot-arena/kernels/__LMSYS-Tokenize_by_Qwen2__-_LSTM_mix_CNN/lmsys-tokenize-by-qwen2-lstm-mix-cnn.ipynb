{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb946d67",
   "metadata": {},
   "source": [
    "# Import libs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:16.158729Z",
     "iopub.status.busy": "2024-07-21T15:14:16.15847Z",
     "iopub.status.idle": "2024-07-21T15:14:24.595436Z",
     "shell.execute_reply": "2024-07-21T15:14:24.594472Z",
     "shell.execute_reply.started": "2024-07-21T15:14:16.158705Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, AutoModel\n",
    "import torch.nn.functional as F\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fe358",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:24.598181Z",
     "iopub.status.busy": "2024-07-21T15:14:24.597373Z",
     "iopub.status.idle": "2024-07-21T15:14:31.080351Z",
     "shell.execute_reply": "2024-07-21T15:14:31.079306Z",
     "shell.execute_reply.started": "2024-07-21T15:14:24.598145Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen2-7B-Instruct\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.add_eos_token = True\n",
    "\n",
    "# save tokenizer to load offline during inference\n",
    "tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:31.082086Z",
     "iopub.status.busy": "2024-07-21T15:14:31.081766Z",
     "iopub.status.idle": "2024-07-21T15:14:31.087211Z",
     "shell.execute_reply": "2024-07-21T15:14:31.086151Z",
     "shell.execute_reply.started": "2024-07-21T15:14:31.082061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility function giving token length\n",
    "def get_token_lengths(texts):\n",
    "    # tokenize and receive input_ids for reach text\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # return length of inputs_ids for each text\n",
    "    return [len(t) for t in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835efcc6",
   "metadata": {},
   "source": [
    "# Prepare train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:31.090449Z",
     "iopub.status.busy": "2024-07-21T15:14:31.08983Z",
     "iopub.status.idle": "2024-07-21T15:14:34.574896Z",
     "shell.execute_reply": "2024-07-21T15:14:34.57383Z",
     "shell.execute_reply.started": "2024-07-21T15:14:31.090424Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.576524Z",
     "iopub.status.busy": "2024-07-21T15:14:34.576147Z",
     "iopub.status.idle": "2024-07-21T15:14:34.594077Z",
     "shell.execute_reply": "2024-07-21T15:14:34.593208Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.576491Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.595496Z",
     "iopub.status.busy": "2024-07-21T15:14:34.595223Z",
     "iopub.status.idle": "2024-07-21T15:14:34.863738Z",
     "shell.execute_reply": "2024-07-21T15:14:34.862784Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.595473Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(train['text'][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.865029Z",
     "iopub.status.busy": "2024-07-21T15:14:34.864747Z",
     "iopub.status.idle": "2024-07-21T15:15:42.052187Z",
     "shell.execute_reply": "2024-07-21T15:15:42.051287Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.865005Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train with only take 50% train dataset\n",
    "train = train[:int(len(train) * 1)]\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])\n",
    "\n",
    "# prepare label for model\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n",
    "\n",
    "# Display data\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.053765Z",
     "iopub.status.busy": "2024-07-21T15:15:42.05349Z",
     "iopub.status.idle": "2024-07-21T15:15:42.066714Z",
     "shell.execute_reply": "2024-07-21T15:15:42.065847Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.05374Z"
    }
   },
   "outputs": [],
   "source": [
    "train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.068273Z",
     "iopub.status.busy": "2024-07-21T15:15:42.067931Z",
     "iopub.status.idle": "2024-07-21T15:15:42.090686Z",
     "shell.execute_reply": "2024-07-21T15:15:42.089936Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.06825Z"
    }
   },
   "outputs": [],
   "source": [
    "# token Count\n",
    "display(train['token_count'].describe().to_frame().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.091911Z",
     "iopub.status.busy": "2024-07-21T15:15:42.091646Z",
     "iopub.status.idle": "2024-07-21T15:15:42.098523Z",
     "shell.execute_reply": "2024-07-21T15:15:42.097554Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.091869Z"
    }
   },
   "outputs": [],
   "source": [
    "# get length of tokens which covers 90% of data, we'll still take 1024 length!\n",
    "np.percentile(train['token_count'], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc441ed9",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.102475Z",
     "iopub.status.busy": "2024-07-21T15:15:42.102219Z",
     "iopub.status.idle": "2024-07-21T15:16:44.236123Z",
     "shell.execute_reply": "2024-07-21T15:16:44.235128Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.102454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize Data\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')\n",
    "\n",
    "# Input IDs are the token IDs\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "# Attention Masks to Ignore Padding Tokens\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "# Label of Texts\n",
    "LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "print(f'LABELS shape: {LABELS.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:44.237864Z",
     "iopub.status.busy": "2024-07-21T15:16:44.237471Z",
     "iopub.status.idle": "2024-07-21T15:16:44.243414Z",
     "shell.execute_reply": "2024-07-21T15:16:44.242354Z",
     "shell.execute_reply.started": "2024-07-21T15:16:44.237829Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 14300\n",
    "maxlen = 1024\n",
    "batch_size = 16\n",
    "embedding_dims = 100\n",
    "nb_filter = 150\n",
    "filter_length = 3\n",
    "hidden_dims = 100\n",
    "nb_epoch = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:44.244999Z",
     "iopub.status.busy": "2024-07-21T15:16:44.244645Z",
     "iopub.status.idle": "2024-07-21T15:16:54.727089Z",
     "shell.execute_reply": "2024-07-21T15:16:54.726245Z",
     "shell.execute_reply.started": "2024-07-21T15:16:44.244975Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta,Adamax\n",
    "from keras.preprocessing import sequence as sq\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda,Input,TimeDistributed,Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session as K\n",
    "num_samples = INPUT_IDS.shape[0]\n",
    "\n",
    "# Số lượng mẫu cho X_valid (20% của X_train)\n",
    "num_valid_samples = int(num_samples * 0.2)\n",
    "\n",
    "# Xáo trộn các chỉ số của X_train\n",
    "indices = np.random.permutation(num_samples)\n",
    "\n",
    "# Chọn 20% chỉ số đầu tiên làm chỉ số cho X_valid\n",
    "valid_indices = indices[:num_valid_samples]\n",
    "\n",
    "# Các chỉ số còn lại làm chỉ số cho X_train\n",
    "train_indices = indices[num_valid_samples:]\n",
    "\n",
    "# Tạo X_valid và X_train mới từ các chỉ số đã chọn\n",
    "X_train = sq.pad_sequences(INPUT_IDS[train_indices], maxlen=maxlen)\n",
    "X_train_attention = sq.pad_sequences(ATTENTION_MASKS[train_indices], maxlen=maxlen)\n",
    "y_train = LABELS[train_indices]\n",
    "\n",
    "X_valid = sq.pad_sequences(INPUT_IDS[valid_indices], maxlen=maxlen)\n",
    "X_valid_attention = sq.pad_sequences(ATTENTION_MASKS[valid_indices], maxlen=maxlen)\n",
    "y_valid = LABELS[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:54.728506Z",
     "iopub.status.busy": "2024-07-21T15:16:54.728212Z",
     "iopub.status.idle": "2024-07-21T15:16:54.820841Z",
     "shell.execute_reply": "2024-07-21T15:16:54.820075Z",
     "shell.execute_reply.started": "2024-07-21T15:16:54.728481Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062651a",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:54.822449Z",
     "iopub.status.busy": "2024-07-21T15:16:54.822147Z",
     "iopub.status.idle": "2024-07-21T15:16:56.077159Z",
     "shell.execute_reply": "2024-07-21T15:16:56.076243Z",
     "shell.execute_reply.started": "2024-07-21T15:16:54.822425Z"
    }
   },
   "outputs": [],
   "source": [
    "'''This example demonstrates the use of Convolution1D for text classification.\n",
    "Gets to 0.88 test accuracy after 2 epochs.\n",
    "90s/epoch on Intel i5 2.4Ghz CPU.\n",
    "10s/epoch on Tesla K40 GPU.\n",
    "'''\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import  GlobalMaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "#config = K.tf.ConfigProto(intra_op_parallelism_threads=16, inter_op_parallelism_threads=16, \\\n",
    "#                        allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "\n",
    "\n",
    "# tf_config = K.tf.ConfigProto()\n",
    "# tf_config.gpu_options.allow_growth = True\n",
    "# session = K.tf.Session(config=tf_config)\n",
    "# K.set_session(session)\n",
    "\n",
    "# config = K.tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4, \\\n",
    "#                         allow_soft_placement=True, device_count = {'CPU': 4})\n",
    "# session = K.tf.Session(config=config)\n",
    "# K.set_session(session)\n",
    "\n",
    "class ApplyAttentionMask(Layer):\n",
    "    def call(self, inputs):\n",
    "        embeddings, attention_mask = inputs\n",
    "        return embeddings * tf.expand_dims(attention_mask, -1)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')\n",
    "attention_masks = Input(shape=(maxlen,), dtype='float32', name=\"attention_masks\")\n",
    "\n",
    "emb_layer = Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=maxlen\n",
    "                      )(input_layer)\n",
    "\n",
    "masked_embeddings = ApplyAttentionMask(name='apply_attention_mask')([emb_layer, attention_masks])\n",
    "def max_1d(X):\n",
    "    return K.max(X, axis=1)\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size 3:\n",
    "\n",
    "con3_layer = Convolution1D(filters=nb_filter,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    kernel_size =3,\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con3_layer = GlobalMaxPooling1D()(con3_layer)\n",
    "\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size 4:\n",
    "\n",
    "con4_layer = Convolution1D(filters=nb_filter,\n",
    "                    kernel_size=5,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con4_layer = GlobalMaxPooling1D()(con4_layer)\n",
    "\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size 5:\n",
    "\n",
    "con5_layer = Convolution1D(filters=nb_filter,\n",
    "                    kernel_size=7,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con5_layer = GlobalMaxPooling1D()(con5_layer)\n",
    "\n",
    "\n",
    "cnn_layer =Concatenate()([pool_con3_layer, pool_con5_layer, pool_con4_layer])\n",
    "\n",
    "\n",
    "#LSTM\n",
    "\n",
    "\n",
    "x = masked_embeddings\n",
    "lstm_layer = LSTM(128)(x)\n",
    "\n",
    "cnn_lstm_layer = Concatenate()([lstm_layer, cnn_layer])\n",
    "\n",
    "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)\n",
    "output_layer= Dropout(0.2)(dense_layer)\n",
    "output_layer = Dense(3, trainable=True,activation='softmax')(output_layer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=[input_layer, attention_masks], outputs=[output_layer])\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.75, epsilon=1e-06)\n",
    "adamax = Adamax(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7aeec",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:56.078492Z",
     "iopub.status.busy": "2024-07-21T15:16:56.078221Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint('CNN-LSTM-weights/weights.keras',\n",
    "                                 monitor='val_acc', verbose=0, save_best_only=True,\n",
    "                                 mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "model.fit([X_train,X_train_attention], y_train,\n",
    "          batch_size=16,\n",
    "          epochs=nb_epoch,\n",
    "          callbacks=[checkpoint, early_stopping],\n",
    "          validation_data=([X_valid,X_valid_attention], y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "model.save('model_LSTM_mix_CNN.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59412f6",
   "metadata": {},
   "source": [
    "# Test Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Null' for training\n",
    "indexes = test[(test.response_a == 'null') & (test.response_b == 'null')].index\n",
    "test.drop(indexes, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")\n",
    "print('Total train samples: ', len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize Data\n",
    "tokens_test = tokenizer(\n",
    "    test['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')\n",
    "\n",
    "# Input IDs are the token IDs\n",
    "INPUT_test = tokens_test['input_ids']\n",
    "# Attention Masks to Ignore Padding Tokens\n",
    "ATTENTION_MASKS2 = tokens_test['attention_mask']\n",
    "\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_test.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sq.pad_sequences(INPUT_test, maxlen=maxlen)\n",
    "X_test_attention = sq.pad_sequences(ATTENTION_MASKS2, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict([X_test,X_test_attention])\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df = pd.DataFrame(y_predict, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "result_df = pd.concat([test['id'], winner_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4146046",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "\n",
    "There is still alot of room to speed up and optimize training! Try out more data, different batch size, lr... All the best!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 3863727,
     "sourceId": 6703755,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 71342,
     "modelInstanceId": 51944,
     "sourceId": 62188,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
