{
    "comments": [
        {
            "author": "Songling",
            "content": "Can't find this file, can someone help me?\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nERROR: Could not find a version that satisfies the requirement bitsandbytes (from versions: none)\n\nERROR: No matching distribution found for bitsandbytes\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nERROR: Could not find a version that satisfies the requirement peft (from versions: none)\n\nERROR: No matching distribution found for peft\n\n",
            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "2",
            "reply": []
        },
        {
            "author": "Shimei",
            "content": "Hi,thank you for sharing this wonderful notebook!\n\nbut after fine tuning your training notebook, i get the following error when inference\n\nOSError: /kaggle/input/llama3-sft/checkpoint-2800 does not appear to have a file named config.json. Checkout 'https://huggingface.co//kaggle/input/llama3-sft/checkpoint-2800/tree/None' for available files.\n\n",
            "date": "Posted 7 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "4",
            "reply": [
                {
                    "author": "Romanov_Alex",
                    "content": "Same there, have you tried how to fix it?\n\n",
                    "date": "Posted 5 days ago  ·  Posted on Version 11 of \n        14",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "duncangao",
                            "content": "sam here. I wonder how to fix it\n\n",
                            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Huang Jing Stark",
            "content": "Any specifig reason to set MAX_LENGTH = 2400?\n\n",
            "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "1",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "Just to give the model more information.\n\n",
                    "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "3",
                    "reply": []
                }
            ]
        },
        {
            "author": "Rabbit",
            "content": "I would like to ask how your model loads from huggingface to kaggle?\n\n",
            "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "Create a new notebook, open the Internet, download the model using snapshot download, and use this notebook as the new dataset\n\n",
                    "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "5",
                    "reply": [
                        {
                            "author": "Rabbit",
                            "content": "Thank you\n\n",
                            "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
                            "votes": "-1",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Dlond Mike",
            "content": "but you,my friend,you are truly hero.\n\n",
            "date": "Posted 13 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "1",
            "reply": []
        },
        {
            "author": "PaulRRR",
            "content": "I use llama3.1 but I get the error:ValueError: rope_scaling must be a dictionary with with two fields, type and factor, got {'factor': 8.0, 'high_freq_factor': 4.0, 'low_freq_factor': 1.0, 'original_max_position_embeddings': 8192, 'rope_type': 'llama3'}\n\n",
            "date": "Posted 2 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "zhudong1949",
                    "content": "update transformers version\n\n",
                    "date": "Posted a day ago  ·  Posted on Version 14 of \n        14",
                    "votes": "0",
                    "reply": []
                }
            ]
        },
        {
            "author": "Aaryan Gupta",
            "content": "Hey, are the datasets for this notebook private? Since the code is throwing error on paths not found.\n\n",
            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "0",
            "reply": []
        },
        {
            "author": "박민욱peterminpark",
            "content": "WAIT\n\nIs the model /kaggle/input/sft-llama3-lora-9231 public?\n\nAlso i trained models from using the training code to get fold0-fold4 models and tested them but they are stuck in the 0.94 - 0.95 range\n\n",
            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "PaulRRR",
                    "content": "Hello, can you run this inference code？\n\n",
                    "date": "Posted 2 days ago  ·  Posted on Version 11 of \n        14",
                    "votes": "0",
                    "reply": []
                }
            ]
        },
        {
            "author": "Lorry Zou",
            "content": "I downloaded the whole repository from Huggingface and made a dataset for inference, but I got this error when loading:\n\nError no file named pytorch_model.bin, model.safetensors, tf_model.h5, model.ckpt.index or flax_model.msgpack found in directory /kaggle/input/llama-3-8b-instruct-bnb-4bit-1.\n\nAnyone encountered the same problem and know how to deal with it?\n\n",
            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "Lorry Zou",
                    "content": "Now I got another error:\n\nIncorrect path_or_model_id: '/kaggle/input/llama-3-8b-instruct-bnb-4bit'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\n\nCan anyone help me please.\n\n",
                    "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
                    "votes": "0",
                    "reply": []
                }
            ]
        },
        {
            "author": "OHIRA",
            "content": "Hi thanks for great work !!!\n\nif you use 8bit LoRA, then can you do inference within the time limit ?\n\nhow much time ?\n\nif you know please tell me.\n\n",
            "date": "Posted 5 days ago  ·  Posted on Version 11 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "as well as 4bits\n\n",
                    "date": "Posted 5 days ago  ·  Posted on Version 11 of \n        14",
                    "votes": "1",
                    "reply": [
                        {
                            "author": "OHIRA",
                            "content": "Thank you!\n\n",
                            "date": "Posted 4 days ago  ·  Posted on Version 11 of \n        14",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "hn",
                            "content": "hello, I tried to use gemma2-9b, but somehow always get exception if I use 8 bits and a total length of say [256+640+640] = [1536] and above. Have you experienced it before? I reduced to 4 bits and [256+512+512] and the inference ran. hmm\n\n",
                            "date": "Posted 2 days ago  ·  Posted on Version 11 of \n        14",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Qihang Wang",
            "content": "Hi , I would like to ask why you set \n\nlabel_token_id = [128250]\n\n",
            "date": "Posted 6 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "[128250] is llama3 special token, doesn't make any sense, just take the label position and avoid other normal tokens.\n\n",
                    "date": "Posted 6 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "0",
                    "reply": []
                }
            ]
        },
        {
            "author": "Dlond Mike",
            "content": "Hi,can you give a simple conclusion about what's new in this new notebook?\n\n",
            "date": "Posted 7 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": []
        },
        {
            "author": "YEI0907",
            "content": "How long did it take for your inferencing time? I also used an autoregressive architecture, but the inference time increased significantly\n\n",
            "date": "Posted 7 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": []
        },
        {
            "author": "YEI0907",
            "content": "老哥，你的这个架构推理时间花了多久呀？我也用了自回归模型进行推理，但是推理时间比直接分类长了很多\n\n",
            "date": "Posted 7 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "max_len=2400 -> 6h -> 0.935\n\nmax_len=1024 -> 3h -> 0.938\n\n",
                    "date": "Posted 7 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "1",
                    "reply": []
                }
            ]
        },
        {
            "author": "Rabbit",
            "content": "I have tried your method, why do I cv0.927 but lb only 0.960\n\n",
            "date": "Posted 8 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "sad, could be overfitting？\n\n",
                    "date": "Posted 8 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "0",
                    "reply": []
                },
                {
                    "author": "PaulRRR",
                    "content": "Hello, may I ask if you can run this inference code？\n\n",
                    "date": "Posted 2 days ago  ·  Posted on Version 11 of \n        14",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "Rabbit",
                            "content": "I finetune the code\n\n",
                            "date": "Posted 2 days ago  ·  Posted on Version 11 of \n        14",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "lllleeeo",
            "content": "That‘s a really great work！Have you compared the score with classifier head？\n\n",
            "date": "Posted 9 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "Of course, this method works better with almost the same parameters\n\n",
                    "date": "Posted 9 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "0",
                    "reply": []
                }
            ]
        },
        {
            "author": "Octavio Grau",
            "content": "This notebook throws an error for me (0.935 version). Any hint guys? [@shelterw](https://www.kaggle.com/shelterw) thanks for publishing!\n\n",
            "date": "Posted 10 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "what error ?\n\n",
                    "date": "Posted 9 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "1",
                    "reply": [
                        {
                            "author": "Songling",
                            "content": "[@shelterw](https://www.kaggle.com/shelterw) \n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nERROR: Could not find a version that satisfies the requirement bitsandbytes (from versions: none)\n\nERROR: No matching distribution found for bitsandbytes\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nWARNING: Location '../input/llm-pip-2024-7-4/' is ignored: it is either a non-existing path or lacks a specific scheme.\n\nERROR: Could not find a version that satisfies the requirement peft (from versions: none)\n\nERROR: No matching distribution found for peft\n\n",
                            "date": "Posted 6 days ago  ·  Posted on Version 10 of \n        14",
                            "votes": "1",
                            "reply": []
                        },
                        {
                            "author": "ShelterWTopic Author",
                            "content": "sorry, man, updated.\n\n",
                            "date": "Posted 6 days ago  ·  Posted on Version 11 of \n        14",
                            "votes": "2",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Nikhil Tumbde",
            "content": "Thanks for the notebook! I was trying to implement unsloth versions of LLMs but couldn't. This is really helpful. \n\nCan you tell me how long it takes for scoring?\n\n",
            "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
            "votes": "0",
            "reply": [
                {
                    "author": "ShelterWTopic Author",
                    "content": "~6h\n\nWhen set max_len =1024 , It's going to take 3h  and score 0.938\n\n",
                    "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
                    "votes": "2",
                    "reply": [
                        {
                            "author": "Nikhil Tumbde",
                            "content": "Thanks!\n\nI have one last question (can be open ended, sorry for that). I am a new to NLP space, faced too many errors while trying to convert unsloth to seq classification from its causal LM version. Is there a way to find out what are the expected outputs and inputs for each function, I tried chatgpt but it wasn't that helpful? for eg\n\nLlama3ForSFT should return - CausalLMOutputWithPast(\n\n        loss=loss,\n\n        logits=true_logits,\n\n    )\n\n2.tokenize should return - {\n\n    \"input_ids\": input_ids,\n\n    \"attention_mask\": attention_mask,\n\n    \"labels\": labels\n\n} \n\nThanks for your time!\n",
                            "date": "Posted 12 days ago  ·  Posted on Version 10 of \n        14",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        }
    ]
}