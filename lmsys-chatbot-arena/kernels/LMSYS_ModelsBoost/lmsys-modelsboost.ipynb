{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4118b70f",
   "metadata": {},
   "source": [
    "# LMSys Chatbot Arena\n",
    "\n",
    "Propose, document and defend a solution that can determine which answer is better, or if there is a tie, based on criteria you define..  \n",
    "\n",
    "\n",
    "**Proposal**: Boosting is a machine learning technique that combines the results of several weak model trainings to create a strong model. The process uses a sequence of interactions, where weights are used for the errors obtained in each training session.\n",
    "\n",
    "**Example**: XGBoost is a machine learning algorithm based on gradient boosting and using decision trees, where each tree tries to correct the errors of the previous tree.\n",
    "\n",
    "**Features**: For this problem, we will use features extracted from the texts in our dataset.\n",
    "\n",
    "In this case, we can use exploratory analysis to establish features add to our classification, such as:\n",
    "- Size of the texts;\n",
    "- Words present in the question and answears;\n",
    "- Difference between answears, etc.\n",
    "\n",
    "## 1 - Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:55:36.054866Z",
     "iopub.status.busy": "2024-07-28T12:55:36.054427Z",
     "iopub.status.idle": "2024-07-28T12:56:06.798802Z",
     "shell.execute_reply": "2024-07-28T12:56:06.79741Z",
     "shell.execute_reply.started": "2024-07-28T12:55:36.054829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Librarys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 14,5\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style = 'whitegrid'\n",
    "\n",
    "import plotly.express as px\n",
    "px.defaults.template = \"plotly_dark\"\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classification models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:06.805284Z",
     "iopub.status.busy": "2024-07-28T12:56:06.804818Z",
     "iopub.status.idle": "2024-07-28T12:56:11.030445Z",
     "shell.execute_reply": "2024-07-28T12:56:11.029073Z",
     "shell.execute_reply.started": "2024-07-28T12:56:06.805244Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading datasets\n",
    "df_train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "df_submission = df_test.copy()\n",
    "sample_example = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.033741Z",
     "iopub.status.busy": "2024-07-28T12:56:11.033235Z",
     "iopub.status.idle": "2024-07-28T12:56:11.049732Z",
     "shell.execute_reply": "2024-07-28T12:56:11.048347Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.033706Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sample example visualization\n",
    "sample_example.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.051844Z",
     "iopub.status.busy": "2024-07-28T12:56:11.051464Z",
     "iopub.status.idle": "2024-07-28T12:56:11.070692Z",
     "shell.execute_reply": "2024-07-28T12:56:11.069451Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.051813Z"
    }
   },
   "outputs": [],
   "source": [
    "# train dataset\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.073115Z",
     "iopub.status.busy": "2024-07-28T12:56:11.072499Z",
     "iopub.status.idle": "2024-07-28T12:56:11.084323Z",
     "shell.execute_reply": "2024-07-28T12:56:11.08299Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.073074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset's shape\n",
    "print(f'Train dataset shape: {df_train.shape}')\n",
    "print(f'Test dataset shape: {df_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.086155Z",
     "iopub.status.busy": "2024-07-28T12:56:11.085747Z",
     "iopub.status.idle": "2024-07-28T12:56:11.15365Z",
     "shell.execute_reply": "2024-07-28T12:56:11.152264Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.086121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.155667Z",
     "iopub.status.busy": "2024-07-28T12:56:11.15529Z",
     "iopub.status.idle": "2024-07-28T12:56:11.204561Z",
     "shell.execute_reply": "2024-07-28T12:56:11.203288Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.155633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Null values train\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.206559Z",
     "iopub.status.busy": "2024-07-28T12:56:11.206165Z",
     "iopub.status.idle": "2024-07-28T12:56:11.219704Z",
     "shell.execute_reply": "2024-07-28T12:56:11.218387Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.206529Z"
    }
   },
   "outputs": [],
   "source": [
    "# Null values test\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.224008Z",
     "iopub.status.busy": "2024-07-28T12:56:11.223574Z",
     "iopub.status.idle": "2024-07-28T12:56:11.870179Z",
     "shell.execute_reply": "2024-07-28T12:56:11.868854Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.223965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Text Preprocessing \n",
    "def preprocess(string):\n",
    "    strip = string.strip('[]')\n",
    "    parts = [x.strip('\"') for x in strip.split('\",\"')]\n",
    "    return ''.join(parts)\n",
    "columns = ['prompt','response_a','response_b']\n",
    "\n",
    "for colum in df_train[columns]:\n",
    "    df_train[colum] = df_train[colum].apply(preprocess)\n",
    "    \n",
    "for colum in df_test[columns]:\n",
    "    df_test[colum] = df_test[colum].apply(preprocess)\n",
    "    \n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:17.434164Z",
     "iopub.status.busy": "2024-07-28T12:56:17.433724Z",
     "iopub.status.idle": "2024-07-28T12:56:22.891657Z",
     "shell.execute_reply": "2024-07-28T12:56:22.890224Z",
     "shell.execute_reply.started": "2024-07-28T12:56:17.43413Z"
    }
   },
   "outputs": [],
   "source": [
    "# create new columns for data exploration\n",
    "columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "def class_label(df):\n",
    "    df['class_label'] = None\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for col in columns:\n",
    "            if row[col] == 1:\n",
    "                df.at[index, 'class_label'] = col\n",
    "                break\n",
    "\n",
    "# Call the function on your DataFrame\n",
    "class_label(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:22.893926Z",
     "iopub.status.busy": "2024-07-28T12:56:22.893458Z",
     "iopub.status.idle": "2024-07-28T12:56:22.919076Z",
     "shell.execute_reply": "2024-07-28T12:56:22.917946Z",
     "shell.execute_reply.started": "2024-07-28T12:56:22.893871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define class number\n",
    "class_number = {'winner_model_a':0 ,'winner_model_b':1,'winner_tie':2}\n",
    "\n",
    "df_train['class'] = df_train['class_label'].map(class_number)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:22.923358Z",
     "iopub.status.busy": "2024-07-28T12:56:22.92233Z",
     "iopub.status.idle": "2024-07-28T12:56:24.054951Z",
     "shell.execute_reply": "2024-07-28T12:56:24.053692Z",
     "shell.execute_reply.started": "2024-07-28T12:56:22.923307Z"
    }
   },
   "outputs": [],
   "source": [
    "# Which model was chosen\n",
    "def chose_model(row):\n",
    "    if row['class'] == 0:\n",
    "        return row['model_a']\n",
    "    elif row['class'] == 1:\n",
    "        return row['model_b']\n",
    "    else:\n",
    "        return 'tie'\n",
    "\n",
    "df_train['chose_model'] = df_train.apply(chose_model, axis=1)\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3841224",
   "metadata": {},
   "source": [
    "## 2 - Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:33.64687Z",
     "iopub.status.busy": "2024-07-28T12:56:33.646323Z",
     "iopub.status.idle": "2024-07-28T12:56:33.664827Z",
     "shell.execute_reply": "2024-07-28T12:56:33.663305Z",
     "shell.execute_reply.started": "2024-07-28T12:56:33.646827Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[['winner_model_a','winner_model_b','winner_tie']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:41.218562Z",
     "iopub.status.busy": "2024-07-28T12:56:41.217723Z",
     "iopub.status.idle": "2024-07-28T12:56:43.699012Z",
     "shell.execute_reply": "2024-07-28T12:56:43.697638Z",
     "shell.execute_reply.started": "2024-07-28T12:56:41.218522Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analysing class distribuitions\n",
    "# Objective: is the base balanced?\n",
    "fig = px.pie(df_train[['winner_model_a','winner_model_b','winner_tie']].mean(), names=df_train['class_label'], title='Class distribuition')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:44.567146Z",
     "iopub.status.busy": "2024-07-28T12:56:44.566669Z",
     "iopub.status.idle": "2024-07-28T12:56:44.70399Z",
     "shell.execute_reply": "2024-07-28T12:56:44.702698Z",
     "shell.execute_reply.started": "2024-07-28T12:56:44.56711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models distribuitions\n",
    "# Objective: The winningest models in the comparison\n",
    "df_models = df_train.groupby('chose_model')['class'].count().reset_index().sort_values(by='class',ascending=False)\n",
    "df_models.rename(columns={'chose_model':'model'}, inplace=True)\n",
    "\n",
    "# Results Graphs\n",
    "fig = px.bar(df_models[1:11].sort_values(by='class'), y='model', x='class', title='Top 10 Most Chosen Models', text_auto='.3s')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:46.249769Z",
     "iopub.status.busy": "2024-07-28T12:56:46.249328Z",
     "iopub.status.idle": "2024-07-28T12:56:46.303936Z",
     "shell.execute_reply": "2024-07-28T12:56:46.302641Z",
     "shell.execute_reply.started": "2024-07-28T12:56:46.249732Z"
    }
   },
   "outputs": [],
   "source": [
    "# Models chosen from those mentioned\n",
    "# Objective: The most of these models\n",
    "df_uni1 = df_train.groupby('model_a')['id'].count().reset_index().sort_values('id', ascending=False)\n",
    "df_uni1.rename(columns={'model_a':'model'}, inplace=True)\n",
    "df_uni2 = df_train.groupby('model_b')['id'].count().reset_index().sort_values('id', ascending=False)\n",
    "df_uni2.rename(columns={'model_b':'model'}, inplace=True)\n",
    "\n",
    "df_uni = df_uni1.merge(df_uni2, how='left', on = 'model')\n",
    "df_uni['total_mentions'] = df_uni['id_x'] + df_uni['id_y']\n",
    "mentions = df_uni['total_mentions'].sum()\n",
    "df_uni['%mentions'] = (df_uni['total_mentions'] / mentions) * 100\n",
    "\n",
    "df_uni = df_uni.merge(df_models, how='left', on = 'model')\n",
    "df_uni['chose_in_mentions'] = (df_uni['class'] / df_uni['total_mentions']) * 100\n",
    "df_uni = df_uni.sort_values(by = 'chose_in_mentions', ascending=False)[:10]\n",
    "df_uni.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:47.41905Z",
     "iopub.status.busy": "2024-07-28T12:56:47.418581Z",
     "iopub.status.idle": "2024-07-28T12:56:47.497398Z",
     "shell.execute_reply": "2024-07-28T12:56:47.496226Z",
     "shell.execute_reply.started": "2024-07-28T12:56:47.419015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Results - Graphs\n",
    "fig = px.bar(df_uni.sort_values('chose_in_mentions'), y='model', x='chose_in_mentions', title='% Top 10 Most Chosen Models',\n",
    "             text_auto='.3s')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa209e5",
   "metadata": {},
   "source": [
    "## 3 Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:57:15.523984Z",
     "iopub.status.busy": "2024-07-28T12:57:15.523553Z",
     "iopub.status.idle": "2024-07-28T15:29:38.126535Z",
     "shell.execute_reply": "2024-07-28T15:29:38.125267Z",
     "shell.execute_reply.started": "2024-07-28T12:57:15.523951Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# Word Processing\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def word_processing(text):\n",
    "    '''Process text: remove special characters, convert to lowercase, tokenize, and remove stopwords'''\n",
    "    text = re.sub(r'[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_list]  # Remove stopwords\n",
    "    return filtered_tokens\n",
    "\n",
    "# Features engineering\n",
    "def count_token(tokens):\n",
    "    '''Count number of tokens'''\n",
    "    return len(tokens)\n",
    "\n",
    "def diff_response(tokens1, tokens2):\n",
    "    '''Difference in token count between responses'''\n",
    "    len_1 = len(tokens1)\n",
    "    len_2 = len(tokens2)\n",
    "    diff = abs(len_1 - len_2)\n",
    "    return len_1, len_2, diff\n",
    "\n",
    "def prompt_u_response(text1, text2):\n",
    "    '''Common words between the prompt and the responses'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)\n",
    "    return len(intersec)\n",
    "\n",
    "def aUb(text1, text2):\n",
    "    '''Common words between the responses'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)\n",
    "    return len(intersec)\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    '''Proportion of unique words'''\n",
    "    return len(set(text)) / len(text) if text else 0\n",
    "\n",
    "def avg_words_per_sentence(text):\n",
    "    '''Calculate average number of words per sentence'''\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_count = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    return word_count / len(sentences) if sentences else 0\n",
    "\n",
    "def sentence_diversity(text):\n",
    "    '''Calculate sentence diversity (variety in sentence length)'''\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sentence)) for sentence in sentences]\n",
    "    return len(set(lengths)) / len(lengths) if lengths else 0\n",
    "\n",
    "def Simylarity(text1, text2):\n",
    "    '''Calculate the similaty between prompt and responses'''\n",
    "    tokenA = nlp(text1)\n",
    "    tokenB = nlp(text2)\n",
    "    return tokenA.similarity(tokenB)\n",
    "\n",
    "df['similaty_promptUresponse_a'] = df.apply(lambda row: Simylarity(row['prompt'],row['response_a']), axis=1)\n",
    "df['similaty_promptUresponse_b'] = df.apply(lambda row: Simylarity(row['prompt'],row['response_b']), axis=1)\n",
    "\n",
    "\n",
    "# Applying word processing to columns\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df[col] = df[col].apply(word_processing)\n",
    "    df[f'{col}_count_token'] = df[col].apply(count_token)\n",
    "\n",
    "# Applying additional features\n",
    "for index, row in df.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)\n",
    "        \n",
    "        df.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)\n",
    "        df.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)\n",
    "        df.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)\n",
    "        \n",
    "        # Existing features\n",
    "        df.at[index, f'{col}_count_token'] = count_token(tokens)\n",
    "\n",
    "# Applying diferences functions in the train dataframe \n",
    "for index, row in df.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)\n",
    "    response_b_text = ' '.join(response_b_tokens)\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)\n",
    "    df.at[index, 'response_len_a'] = len_a\n",
    "    df.at[index, 'response_len_b'] = len_b\n",
    "    df.at[index, 'response_diff'] = diff\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)\n",
    "    df.at[index, 'common_words_ab'] = common_words_ab\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)\n",
    "    df.at[index, 'common_words_prompt_a'] = common_words_prompt_a\n",
    "    df.at[index, 'common_words_prompt_b'] = common_words_prompt_b\n",
    "    \n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:31:36.353796Z",
     "iopub.status.busy": "2024-07-28T15:31:36.35334Z",
     "iopub.status.idle": "2024-07-28T15:31:36.388101Z",
     "shell.execute_reply": "2024-07-28T15:31:36.386931Z",
     "shell.execute_reply.started": "2024-07-28T15:31:36.353761Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['similaty_promptUresponse_a','similaty_promptUresponse_b']].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:32:15.79069Z",
     "iopub.status.busy": "2024-07-28T15:32:15.789718Z",
     "iopub.status.idle": "2024-07-28T15:39:33.148986Z",
     "shell.execute_reply": "2024-07-28T15:39:33.147634Z",
     "shell.execute_reply.started": "2024-07-28T15:32:15.790649Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# features and target selection\n",
    "X = df.drop(['id','model_a','model_b','prompt','response_a','response_b','winner_model_a','winner_model_b','winner_tie',\n",
    "            'class_label','chose_model','class'], axis=1).values\n",
    "y = df['class'].values\n",
    "\n",
    "# Split train and valid\n",
    "X_train,X_valid,y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Models use\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42,verbose=False)\n",
    "}\n",
    "\n",
    "# Trainning the models\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "result_loss = []\n",
    "result_models = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    i = 0\n",
    "    print(f'Model {model_name}')\n",
    "\n",
    "    model_losses = []  # Loss Models List\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        X_train_fold, X_test_fold = X[train_index], X[valid_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[valid_index]\n",
    "        \n",
    "        # Training the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Metrics evaluation\n",
    "        y_test_pred_proba = model.predict_proba(X_test_fold)\n",
    "        loss = metrics.log_loss(y_test_fold, y_test_pred_proba)\n",
    "        model_losses.append(loss)  # Add loss in list\n",
    "        \n",
    "        # Display the results\n",
    "        print(f'Fold {i} | Log Loss: {loss}')\n",
    "        i += 1\n",
    "        \n",
    "        mean_loss = np.mean(model_losses)\n",
    "        result_loss.append(model_losses)\n",
    "        result_models.append((model_name, model_losses))\n",
    "\n",
    "    print(f'Mean Loss for model {model_name} is {mean_loss}')\n",
    "    print('---' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:40:20.886693Z",
     "iopub.status.busy": "2024-07-28T15:40:20.886267Z",
     "iopub.status.idle": "2024-07-28T15:40:21.030166Z",
     "shell.execute_reply": "2024-07-28T15:40:21.028702Z",
     "shell.execute_reply.started": "2024-07-28T15:40:20.886662Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "data_dict = {'CV': list(range(0, 5))}\n",
    "\n",
    "for model, values in result_models:\n",
    "    data_dict[model] = values\n",
    "\n",
    "results_df = pd.DataFrame(data_dict)\n",
    "\n",
    "fig = px.line(results_df, x='CV', y=['XGBoost','GradientBoosting','CatBoost'], title='Loss Models')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:40:59.332186Z",
     "iopub.status.busy": "2024-07-28T15:40:59.33173Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# The best model are GradientBoosting\n",
    "# Now, we'll use the gridsearch for tunning hyperparametros\n",
    "model_grad = GradientBoostingClassifier()\n",
    "params = {\n",
    "    'n_estimators':[100, 150, 170],\n",
    "    'max_depth': [1, 3, 5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model_grad, params, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=False)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:01:45.541169Z",
     "iopub.status.busy": "2024-07-19T13:01:45.540725Z",
     "iopub.status.idle": "2024-07-19T13:01:45.547128Z",
     "shell.execute_reply": "2024-07-19T13:01:45.546118Z",
     "shell.execute_reply.started": "2024-07-19T13:01:45.541129Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'The best params {grid.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:01:51.323862Z",
     "iopub.status.busy": "2024-07-19T13:01:51.323434Z",
     "iopub.status.idle": "2024-07-19T13:01:51.3287Z",
     "shell.execute_reply": "2024-07-19T13:01:51.327547Z",
     "shell.execute_reply.started": "2024-07-19T13:01:51.323828Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selection the best model\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:03:01.162878Z",
     "iopub.status.busy": "2024-07-19T13:03:01.162415Z",
     "iopub.status.idle": "2024-07-19T13:03:01.260652Z",
     "shell.execute_reply": "2024-07-19T13:03:01.2595Z",
     "shell.execute_reply.started": "2024-07-19T13:03:01.162843Z"
    }
   },
   "outputs": [],
   "source": [
    "# Avaluation the best model\n",
    "y_predict_valid_prob = best_model.predict_proba(X_valid)\n",
    "\n",
    "logloss = metrics.log_loss(y_valid, y_predict_valid_prob)\n",
    "\n",
    "print(f'LogLoss the Best Models with GridSearch: {logloss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544f5a4",
   "metadata": {},
   "source": [
    "There was no significant improvement with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:20:47.24073Z",
     "iopub.status.busy": "2024-07-19T13:20:47.240315Z",
     "iopub.status.idle": "2024-07-19T13:20:47.310384Z",
     "shell.execute_reply": "2024-07-19T13:20:47.309207Z",
     "shell.execute_reply.started": "2024-07-19T13:20:47.240683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Features importance\n",
    "features_importance = best_model.feature_importances_\n",
    "features_names = ['prompt_count_token', 'response_a_count_token',\n",
    "       'response_b_count_token', 'response_a_lexical_diversity',\n",
    "       'response_a_avg_words_per_sentence', 'response_a_sentence_diversity',\n",
    "       'response_b_lexical_diversity', 'response_b_avg_words_per_sentence',\n",
    "       'response_b_sentence_diversity', 'response_len_a', 'response_len_b',\n",
    "       'response_diff', 'common_words_ab', 'common_words_prompt_a',\n",
    "       'common_words_prompt_b','similaty_promptUresponse_a', 'similaty_promptUresponse_b']\n",
    "\n",
    "fig = px.bar(y=features_names, x=features_importance, color=features_importance, title='Features Importance')\n",
    "scale = px.colors.sequential.BuGn\n",
    "fig.update_traces(marker=dict(colorscale=scale))\n",
    "fig.update_layout(width=800, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7cf5c",
   "metadata": {},
   "source": [
    "Above we can see the most important features for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:05.820087Z",
     "iopub.status.busy": "2024-07-19T13:04:05.81966Z",
     "iopub.status.idle": "2024-07-19T13:04:06.117529Z",
     "shell.execute_reply": "2024-07-19T13:04:06.11641Z",
     "shell.execute_reply.started": "2024-07-19T13:04:05.820054Z"
    }
   },
   "outputs": [],
   "source": [
    "# Preparing the test data to predict\n",
    "df_test['similaty_promptUresponse_a'] = df_test.apply(lambda row: Simylarity(row['prompt'],row['response_a']), axis=1)\n",
    "df_test['similaty_promptUresponse_b'] = df_test.apply(lambda row: Simylarity(row['prompt'],row['response_b']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Applying word processing to columns\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df_test[col] = df_test[col].apply(word_processing)\n",
    "    df_test[f'{col}_count_token'] = df_test[col].apply(count_token)\n",
    "\n",
    "# Applying additional features\n",
    "for index, row in df_test.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)\n",
    "        \n",
    "        df_test.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)\n",
    "        df_test.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)\n",
    "        df_test.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)\n",
    "        \n",
    "        # Existing features\n",
    "        df_test.at[index, f'{col}_count_token'] = count_token(tokens)\n",
    "\n",
    "\n",
    "# Applying diferences functions in the test dataframe \n",
    "for index, row in df_test.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)\n",
    "    response_b_text = ' '.join(response_b_tokens)\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)\n",
    "    df_test.at[index, 'response_len_a'] = len_a\n",
    "    df_test.at[index, 'response_len_b'] = len_b\n",
    "    df_test.at[index, 'response_diff'] = diff\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)\n",
    "    df_test.at[index, 'common_words_ab'] = common_words_ab\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)\n",
    "    df_test.at[index, 'common_words_prompt_a'] = common_words_prompt_a\n",
    "    df_test.at[index, 'common_words_prompt_b'] = common_words_prompt_b\n",
    "\n",
    "df_test.drop(columns = ['id','prompt','response_a','response_b'], axis=1, inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:10.15887Z",
     "iopub.status.busy": "2024-07-19T13:04:10.158443Z",
     "iopub.status.idle": "2024-07-19T13:04:10.169863Z",
     "shell.execute_reply": "2024-07-19T13:04:10.168724Z",
     "shell.execute_reply.started": "2024-07-19T13:04:10.158835Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predict proba in test\n",
    "y_sub_proba = best_model.predict_proba(df_test)\n",
    "y_sub_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:14.135325Z",
     "iopub.status.busy": "2024-07-19T13:04:14.134831Z",
     "iopub.status.idle": "2024-07-19T13:04:14.151783Z",
     "shell.execute_reply": "2024-07-19T13:04:14.150521Z",
     "shell.execute_reply.started": "2024-07-19T13:04:14.135288Z"
    }
   },
   "outputs": [],
   "source": [
    "# Submission df\n",
    "submission = pd.DataFrame({\n",
    "    'id':df_submission['id'],\n",
    "    'winner_model_a': y_sub_proba[:, 0],\n",
    "    'winner_model_b': y_sub_proba[:, 1],\n",
    "    'winner_tie': y_sub_proba[:, 2]\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:17.05701Z",
     "iopub.status.busy": "2024-07-19T13:04:17.056603Z",
     "iopub.status.idle": "2024-07-19T13:04:17.065393Z",
     "shell.execute_reply": "2024-07-19T13:04:17.064351Z",
     "shell.execute_reply.started": "2024-07-19T13:04:17.056978Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
