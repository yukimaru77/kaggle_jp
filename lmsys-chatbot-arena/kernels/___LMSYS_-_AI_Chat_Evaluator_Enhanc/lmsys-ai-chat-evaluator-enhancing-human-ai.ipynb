{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b145f11a",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Arial', sans-serif; \n",
    "    padding: 30px; \n",
    "    border-radius: 15px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 6px 12px rgba(0, 0, 0, 0.4);\n",
    "    margin-bottom: 30px;\n",
    "\">\n",
    "    <h1 style=\"font-size: 2.5em;\">üß† LMSYS - AI Chat Evaluator: Enhancing Human-AI</h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 20px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
    "    margin-bottom: 20px;\n",
    "\">\n",
    "    <h1>Welcome to my Notebook! üôè</h1>\n",
    "    <p> This notebook is dedicated to the <strong>Chatbot Arena Competition</strong>, where we explore and innovate in the realm of conversational AI.</p>\n",
    "    <p><strong>Competition Overview:</strong> The goal is to develop a chatbot that excels in understanding and engaging users through natural and relevant conversations. You'll find data, techniques, and insights here to help you craft the best chatbot possible.</p>\n",
    "    <p>Thank you for joining this journey. Dive in, explore, and let‚Äôs make some magic with chatbots!</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    " 1. Setup the Environment\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T09:09:58.963626Z",
     "iopub.status.busy": "2024-07-22T09:09:58.963177Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow pandas numpy scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ce939",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "2. Importing Libraries\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42474e3f",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "3. Loading.. Data\n",
    "</h1>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b5880",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "4. Preprocessing Text Data\n",
    "</h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate responses and prompts for tokenization\n",
    "texts = train_df['prompt'] + ' ' + train_df['response_a'] + ' ' + train_df['response_b']\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Convert text to sequences\n",
    "def text_to_sequences(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    return pad_sequences(sequences, maxlen=500)  # Adjust maxlen based on your needs\n",
    "\n",
    "# Process training data\n",
    "X_prompt_a = text_to_sequences(train_df['prompt'])\n",
    "X_response_a = text_to_sequences(train_df['response_a'])\n",
    "X_response_b = text_to_sequences(train_df['response_b'])\n",
    "\n",
    "# Labels\n",
    "y_a = train_df['winner_model_a']\n",
    "y_b = train_df['winner_model_b']\n",
    "y_tie = train_df['winner_tie']\n",
    "\n",
    "# Split data for training\n",
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X_prompt_a, y_a, test_size=0.2, random_state=42)\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(X_prompt_a, y_b, test_size=0.2, random_state=42)\n",
    "X_train_tie, X_val_tie, y_train_tie, y_val_tie = train_test_split(X_prompt_a, y_tie, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e92e3",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "5. Building the Model\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 100\n",
    "max_len = 500\n",
    "\n",
    "# Define inputs\n",
    "input_prompt = Input(shape=(max_len,))\n",
    "input_response_a = Input(shape=(max_len,))\n",
    "input_response_b = Input(shape=(max_len,))\n",
    "\n",
    "# Embedding layers\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_len)\n",
    "\n",
    "embedded_prompt = embedding_layer(input_prompt)\n",
    "embedded_response_a = embedding_layer(input_response_a)\n",
    "embedded_response_b = embedding_layer(input_response_b)\n",
    "\n",
    "# LSTM layers\n",
    "lstm_layer = LSTM(64)\n",
    "\n",
    "encoded_prompt = lstm_layer(embedded_prompt)\n",
    "encoded_response_a = lstm_layer(embedded_response_a)\n",
    "encoded_response_b = lstm_layer(embedded_response_b)\n",
    "\n",
    "# Concatenate encoded responses with prompt\n",
    "concat_a = Concatenate()([encoded_prompt, encoded_response_a])\n",
    "concat_b = Concatenate()([encoded_prompt, encoded_response_b])\n",
    "\n",
    "# Dense layers for classification\n",
    "dense_layer = Dense(64, activation='relu')\n",
    "\n",
    "output_a = Dense(1, activation='sigmoid')(dense_layer(concat_a))\n",
    "output_b = Dense(1, activation='sigmoid')(dense_layer(concat_b))\n",
    "output_tie = Dense(1, activation='sigmoid')(dense_layer(concat_a))\n",
    "\n",
    "# Model\n",
    "model = Model(inputs=[input_prompt, input_response_a, input_response_b], \n",
    "              outputs=[output_a, output_b, output_tie])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617cc87",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "6. Training the Model\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compilation\n",
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'], \n",
    "    metrics=[['accuracy'], ['accuracy'], ['accuracy']]\n",
    ")\n",
    "\n",
    "# Model Training\n",
    "history = model.fit(\n",
    "    [X_train_a, X_train_b, X_train_b],\n",
    "    [y_train_a, y_train_b, y_train_tie],\n",
    "    validation_data=([X_val_a, X_val_b, X_val_b], [y_val_a, y_val_b, y_val_tie]),\n",
    "    epochs=5,  # Adjust epochs as needed\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba528102",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "7. Evaluateing the Model\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "eval_results = model.evaluate([X_val_a, X_val_b, X_val_b], [y_val_a, y_val_b, y_val_tie])\n",
    "\n",
    "# Unpack the results\n",
    "val_loss = eval_results[0]\n",
    "loss_a = eval_results[1]\n",
    "loss_b = eval_results[2]\n",
    "loss_tie = eval_results[3]\n",
    "acc_a = eval_results[4]\n",
    "acc_b = eval_results[5]\n",
    "acc_tie = eval_results[6]\n",
    "\n",
    "print(f'Validation Loss: {val_loss}')\n",
    "print(f'Loss for model_a predictions: {loss_a}')\n",
    "print(f'Loss for model_b predictions: {loss_b}')\n",
    "print(f'Loss for tie predictions: {loss_tie}')\n",
    "print(f'Accuracy for model_a predictions: {acc_a}')\n",
    "print(f'Accuracy for model_b predictions: {acc_b}')\n",
    "print(f'Accuracy for tie predictions: {acc_tie}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f8caa",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "8. Makeing Predictions\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess test data\n",
    "X_test_prompt = text_to_sequences(test_df['prompt'])\n",
    "X_test_response_a = text_to_sequences(test_df['response_a'])\n",
    "X_test_response_b = text_to_sequences(test_df['response_b'])\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict([X_test_prompt, X_test_response_a, X_test_response_b])\n",
    "\n",
    "# Unpack predictions\n",
    "predicted_a = predictions[0].flatten()\n",
    "predicted_b = predictions[1].flatten()\n",
    "predicted_tie = predictions[2].flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5ce35",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "9. Prepareing the Submission File\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions for submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'winner_model_a': predicted_a,\n",
    "    'winner_model_b': predicted_b,\n",
    "    'winner_tie': predicted_tie\n",
    "})\n",
    "\n",
    "\n",
    "# Save to CSV\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6433d6",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Arial', sans-serif; \n",
    "    padding: 20px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
    "    margin-top: 30px;\n",
    "\">\n",
    "    <h2><strong>Thank You for Exploring My Notebook! üôè<strong></h2>\n",
    "    <p>I hope you found the content and insights valuable as we journeyed through the <strong>LMSYS - AI Chat Evaluator</strong> project together.</p>\n",
    "    <p>Your feedback and support mean a lot to me. If you enjoyed this notebook and found it helpful, please consider giving it an <span style=\"background-color: #dde9f4; color: #3777ac; padding: 5px 10px; border-radius: 5px;\"> <strong>upvote ‚¨ÜÔ∏è</strong></span>. Your encouragement helps me continue improving and sharing useful content.</p>\n",
    "    <p><span style=\"background-color: #dde9f4; color: #3777ac; padding: 5px 10px; border-radius: 5px;\"><strong> Thank you once again for your time and support!</strong></span></p>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
