{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6eeded61",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:33:52.921668Z",
     "iopub.status.busy": "2024-07-17T12:33:52.921015Z",
     "iopub.status.idle": "2024-07-17T12:34:30.56459Z",
     "shell.execute_reply": "2024-07-17T12:34:30.562952Z",
     "shell.execute_reply.started": "2024-07-17T12:33:52.921604Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:52:01.743052Z",
     "iopub.status.busy": "2024-07-17T12:52:01.742554Z",
     "iopub.status.idle": "2024-07-17T12:52:18.661461Z",
     "shell.execute_reply": "2024-07-17T12:52:18.659919Z",
     "shell.execute_reply.started": "2024-07-17T12:52:01.743013Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:50:26.327198Z",
     "iopub.status.busy": "2024-07-17T12:50:26.324366Z",
     "iopub.status.idle": "2024-07-17T12:50:26.343563Z",
     "shell.execute_reply": "2024-07-17T12:50:26.341069Z",
     "shell.execute_reply.started": "2024-07-17T12:50:26.327108Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7893b78",
   "metadata": {},
   "source": [
    "**Before we start, here is a summary derived from the excellent EDA done in this notebook :**https://www.kaggle.com/code/abaojiang/lmsys-detailed-eda\n",
    "\n",
    "**General findings**\n",
    "\n",
    "- There are 64 different models in the training set.\n",
    "- For each prompt, there are 3 responses, each from different model and ranked according to the human preference.\n",
    "- The most common (frequent models) in the training data are as follows :\n",
    "\n",
    "    - gpt-4-1106-preview \n",
    "    - gpt-3.5-turbo-0613\n",
    "    - gpt-4-0613 \n",
    "    - claude-2.1 \n",
    "    - (gpt-4-0314,claude-instant-1)\n",
    "    \n",
    "    \n",
    "- Number of Turns : The number of prompt/response pairs in the training data.\n",
    "\n",
    "    - Around 86.88% of conversations are single-turn.\n",
    "    - Over 99.19% of conversations are less than 6 turns.\n",
    "    - The maximum number of turns is 36.\n",
    "    \n",
    "    \n",
    "\n",
    "**Model response preferences**\n",
    "\n",
    "- Three LLMs have win rate over 50%, including gpt-3.5-turbo-0314, gpt-4-0125-preview and gpt-4-1106-preview.\n",
    "- A lower tie rate means that a winner can be judged more deterministically\n",
    "\n",
    "\n",
    "**Biases and correlations in response/prompts**\n",
    "\n",
    "\n",
    "- No position bias for human judges. i.e , the positions A,B,C in the training data have no such positional bias in them in context of preference of annotators.\n",
    " \n",
    "- Correlation between response lenghts of models for the same prompt: There exist a strong correlation between response length for the same prompt.\n",
    " \n",
    "- Correlation between prompt length and response length : the linear relationship between prompt length and response length, the correlation seems much weaker.\n",
    "\n",
    "- Verbosity Bias (how the verbosity of the answer affects human preference) : \n",
    "    - There is a clear verbosity bias with the data.\n",
    "    - Correlation of \"Mean response length\" vs \"win rate\"  =  0.488\n",
    "    - gpt-4-0125-preview and gpt-4-1106-preview are models with the top-2 longest average response length.\n",
    "    \n",
    "\n",
    "**null/empty responses or prompts**\n",
    "\n",
    "- There exists 5 samples with empty prompts.\n",
    "- All of the empty prompts are a single space \" \" and appear at the last prompt during conversation.\n",
    "- Models can still continue to respond even if an empty prompt is sent.\n",
    "- Missing responses can be empty or None.\n",
    "\n",
    "- efffect on judges\n",
    "    - We can see that the tie rate drops to around 0.15, which is quite reasonble.\n",
    "    - If only one model has missing responses, judges might tend to vote the other responding normally or tie.\n",
    "    \n",
    "\n",
    "**checking train and test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.422896Z",
     "iopub.status.idle": "2024-07-17T12:35:41.423383Z",
     "shell.execute_reply": "2024-07-17T12:35:41.423167Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.423149Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_response(response_object:str)->[str,]:\n",
    "    try:\n",
    "        resp = literal_eval(response_object)\n",
    "        \n",
    "    except Exception as e:\n",
    "        try:\n",
    "            response_object = response_object.replace('null',None)\n",
    "            resp = literal_eval(response_object)\n",
    "        except Exception as e:\n",
    "#             print(type(response_object),response_object)\n",
    "            resp = []\n",
    "\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.425537Z",
     "iopub.status.idle": "2024-07-17T12:35:41.42595Z",
     "shell.execute_reply": "2024-07-17T12:35:41.425775Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.42576Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "train['prompt'] = train['prompt'].apply(literal_eval)\n",
    "train['response_a'] = train['response_a'].apply(parse_response)\n",
    "train['response_b'] = train['response_b'].apply(parse_response)\n",
    "\n",
    "test = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "\n",
    "_ = print(train.shape),print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.42975Z",
     "iopub.status.idle": "2024-07-17T12:35:41.430249Z",
     "shell.execute_reply": "2024-07-17T12:35:41.430054Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.430031Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.432483Z",
     "iopub.status.idle": "2024-07-17T12:35:41.432953Z",
     "shell.execute_reply": "2024-07-17T12:35:41.432746Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.432729Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping empty responses\n",
    "train_ss = train[(train.response_a.apply(len)>0) & (train.response_b.apply(len)>0)]\n",
    "\n",
    "train_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.435804Z",
     "iopub.status.idle": "2024-07-17T12:35:41.436558Z",
     "shell.execute_reply": "2024-07-17T12:35:41.436222Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.436195Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b272b",
   "metadata": {},
   "source": [
    "# Topic Modelling \n",
    "\n",
    "**How it works (from: https://maartengr.github.io/BERTopic/algorithm/algorithm.html)**\n",
    "\n",
    "![image.png](attachment:60ac0df8-5866-4948-9240-7e6453976a10.png)\n",
    "\n",
    "1. Embed documents : We start by converting our documents to numerical representations using a tranformer based model embedding.\n",
    "\n",
    "2. Dimensionality reduction : After having created our numerical representations of the documents we have to reduce the dimensionality of these representations. Cluster models typically have difficulty handling high dimensional data due to the curse of dimensionality.\n",
    "\n",
    "3. Cluster Documents : After having reduced our embeddings, we can start clustering our data. For that, we leverage a density-based clustering technique, HDBSCAN. It can find clusters of different shapes and has the nice feature of identifying outliers where possible.\n",
    "\n",
    "4. Bag-of-words : To create topic representations in BERTopic's algorithm while allowing for modularity, HDBSCAN is used as a clustering model because it accommodates clusters with varying densities and shapes. Instead of using a centroid-based method, all documents in a cluster are combined into a single document, and the frequency of each word is counted to form a bag-of-words representation. This representation, normalized for cluster size differences, focuses on words at the cluster level without assuming a specific cluster structure.\n",
    "\n",
    "5. Topic representation : From the generated bag-of-words representation, we want to know what makes one cluster different from another. Which words are typical for cluster 1 and not so much for all other clusters? To solve this, we need to modify TF-IDF such that it considers topics (i.e., clusters) instead of documents.\n",
    "\n",
    "6. Fine-tune Topic representation : we can consider the c-TF-IDF generated topics to be candidate topics. They each contain a set of keywords and representative documents that we can use to further fine-tune the topic representations. Having a set of representative documents for each topic is huge advantage as it allows for fine-tuning on a reduced number of documents. This reduces computation for large models as they only need to operate on that small set of representative documents for each topic. \n",
    "\n",
    "\n",
    "\n",
    "    Let us try to find the underlying patterns in the prompt, using a unsupervised topic modelling approach. This will give an high level idea of what the constituent topics in the prompts are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.438765Z",
     "iopub.status.idle": "2024-07-17T12:35:41.439466Z",
     "shell.execute_reply": "2024-07-17T12:35:41.439139Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.439114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup modules\n",
    "\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=20, \n",
    "    n_components=5,\n",
    "    min_dist=0.0, \n",
    "    metric=\"cosine\",\n",
    "    random_state=7,\n",
    ")\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=32, \n",
    "    min_samples=1,\n",
    "    metric=\"euclidean\", \n",
    "    cluster_selection_method=\"eom\",\n",
    "    prediction_data=True\n",
    ")\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True,)\n",
    "\n",
    "# Fine-tune topic representations with  a `bertopic.representation` model\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.4,\n",
    "                                                top_n_words=15\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.440938Z",
     "iopub.status.idle": "2024-07-17T12:35:41.441681Z",
     "shell.execute_reply": "2024-07-17T12:35:41.441311Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.441285Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build topic modeling pipeline\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    representation_model=representation_model,\n",
    "    n_gram_range=(1,5),\n",
    "    language=\"english\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.443865Z",
     "iopub.status.idle": "2024-07-17T12:35:41.444604Z",
     "shell.execute_reply": "2024-07-17T12:35:41.444286Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.44426Z"
    }
   },
   "outputs": [],
   "source": [
    "train_prompt_concatenated = train.prompt.apply(lambda x: \"\\n\\n\".join(x)).to_list()\n",
    "len(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.447172Z",
     "iopub.status.idle": "2024-07-17T12:35:41.447834Z",
     "shell.execute_reply": "2024-07-17T12:35:41.447546Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.447523Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "topics,topic_proba = topic_model.fit_transform(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"topic_model_unguided\", serialization=\"safetensors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.449705Z",
     "iopub.status.idle": "2024-07-17T12:35:41.450401Z",
     "shell.execute_reply": "2024-07-17T12:35:41.450079Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.450053Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\" number of unique topics: {len(np.unique(topics))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.452791Z",
     "iopub.status.idle": "2024-07-17T12:35:41.453477Z",
     "shell.execute_reply": "2024-07-17T12:35:41.453171Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.453147Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_info = topic_model.get_topic_info()\n",
    "topic_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a specific topic repr \n",
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.455888Z",
     "iopub.status.idle": "2024-07-17T12:35:41.456404Z",
     "shell.execute_reply": "2024-07-17T12:35:41.456197Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.456181Z"
    }
   },
   "outputs": [],
   "source": [
    "#visualize topic repr\n",
    "topic_model.visualize_barchart(top_n_topics=30,n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.457709Z",
     "iopub.status.idle": "2024-07-17T12:35:41.458136Z",
     "shell.execute_reply": "2024-07-17T12:35:41.45795Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.457933Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_term_rank()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.460194Z",
     "iopub.status.idle": "2024-07-17T12:35:41.460659Z",
     "shell.execute_reply": "2024-07-17T12:35:41.460456Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.460439Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(top_n_topics=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e195a",
   "metadata": {},
   "source": [
    "# Guided topic modelling \n",
    "\n",
    "    The following illustration gives a idea behind guided topic modelling (from: https://maartengr.github.io/BERTopic/getting_started/guided)\n",
    "\n",
    "![image.png](attachment:e350c127-4025-4b0a-9942-3768abb34873.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.463165Z",
     "iopub.status.idle": "2024-07-17T12:35:41.464666Z",
     "shell.execute_reply": "2024-07-17T12:35:41.464416Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.464386Z"
    }
   },
   "outputs": [],
   "source": [
    "task_topics = \"Code to text,,text to code,Named entity recognition,Sentiment Analysis,Translation,Question Answering,Program Execution, Miscallenous tasks,Text Categorization,Language Identification, Information Extraction,Text Quality,Summarization,text completion,essay writing,poem writing,creative writing,fact verification,reasoning,mathematical,grammer task,rephrasing,style transfer,paraphrasing,natural language inference,question generation,text matching,dialogue generation,harmfullness detection,toxic language detection,fact verification,keyword tagging\".split(\",\")\n",
    "\n",
    "print(task_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d160833",
   "metadata": {},
   "source": [
    "**Modified task keywords using CHATGPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.466159Z",
     "iopub.status.idle": "2024-07-17T12:35:41.466607Z",
     "shell.execute_reply": "2024-07-17T12:35:41.46641Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.466392Z"
    }
   },
   "outputs": [],
   "source": [
    "#define seed topics \n",
    "task_topics_modified = [\n",
    "    ['Code to text', 'source code', 'comments', 'explanation', 'description', 'documentation'],\n",
    "    ['Text to code', 'programming', 'syntax', 'function', 'script', 'automation'],\n",
    "    ['Named entity recognition', 'NER', 'entities', 'classification', 'annotation', 'identification'],\n",
    "    ['Sentiment Analysis', 'emotion', 'opinion', 'polarity', 'attitude', 'mood'],\n",
    "    ['Translation', 'bilingual', 'language pair', 'conversion', 'interpretation', 'localization'],\n",
    "    ['Question Answering', 'QA', 'response', 'inquiry', 'knowledge', 'retrieval'],\n",
    "    ['Program Execution', 'run', 'execute', 'compile', 'script', 'process'],\n",
    "    ['Miscellaneous tasks', 'varied', 'general', 'diverse', 'assorted', 'multiple'],\n",
    "    ['Text Categorization', 'classification', 'labeling', 'sorting', 'grouping', 'organization'],\n",
    "    ['Language Identification', 'detection', 'recognition', 'classification', 'language', 'dialect'],\n",
    "    ['Information Extraction', 'data mining', 'retrieval', 'extraction', 'parsing', 'harvesting'],\n",
    "    ['Text Quality', 'clarity', 'readability', 'coherence', 'accuracy', 'precision'],\n",
    "    ['Summarization', 'abstract', 'condense', 'overview', 'digest', 'outline'],\n",
    "    ['Text completion', 'autocomplete', 'fill-in', 'predictive', 'continuation', 'suggestion'],\n",
    "    ['Essay writing', 'composition', 'argument', 'thesis', 'structure', 'drafting'],\n",
    "    ['Poem writing', 'verse', 'rhyme', 'stanza', 'meter', 'lyric'],\n",
    "    ['Creative writing', 'story', 'imagination', 'narrative', 'fiction', 'expression'],\n",
    "    ['Fact verification', 'truth', 'validation', 'accuracy', 'confirmation', 'authenticity'],\n",
    "    ['Reasoning', 'logic', 'deduction', 'inference', 'rationale', 'analysis'],\n",
    "    ['Mathematical', 'calculation', 'formula', 'equation', 'computation', 'arithmetic'],\n",
    "    ['Grammar task', 'syntax', 'rules', 'correction', 'structure', 'editing'],\n",
    "    ['Rephrasing', 'paraphrase', 'reword', 'rewrite', 'restatement', 'alteration'],\n",
    "    ['Style transfer', 'transformation', 'conversion', 'adaptation', 'modification', 'recasting'],\n",
    "    ['Paraphrasing', 'rewording', 'restating', 'rephrasing', 'altering', 'modifying'],\n",
    "    ['Natural language inference', 'NLI', 'hypothesis', 'entailment', 'contradiction', 'inference'],\n",
    "    ['Question generation', 'inquiry', 'query', 'interrogative', 'ask', 'question'],\n",
    "    ['Text matching', 'similarity', 'comparison', 'alignment', 'correlation', 'matching'],\n",
    "    ['Dialogue generation', 'conversation', 'interaction', 'exchange', 'communication', 'chatbot'],\n",
    "    ['Harmfulness detection', 'toxicity', 'abuse', 'malice', 'danger', 'risk'],\n",
    "    ['Toxic language detection', 'abusive', 'offensive', 'harmful', 'inappropriate', 'insulting'],\n",
    "    ['Fact verification', 'validation', 'authenticity', 'accuracy', 'truth', 'confirmation'],\n",
    "    ['Keyword tagging', 'labeling', 'annotation', 'classification', 'indexing', 'tagging'],\n",
    "    ['Topic modeling', 'themes', 'topics', 'clustering', 'segmentation', 'grouping'],\n",
    "    ['Contextual embedding', 'context', 'representation', 'vectors', 'embeddings', 'contextualization'],\n",
    "    ['Coreference resolution', 'pronouns', 'anaphora', 'antecedents', 'referents', 'binding'],\n",
    "    ['Semantic similarity', 'meaning', 'relation', 'comparison', 'equivalence', 'likeness'],\n",
    "    ['Document summarization', 'overview', 'digest', 'abstract', 'compendium', 'condensation'],\n",
    "    ['Speech recognition', 'transcription', 'audio', 'voice', 'ASR', 'spoken'],\n",
    "    ['Optical character recognition', 'OCR', 'text', 'image', 'scanning', 'extraction'],\n",
    "    ['Text generation', 'creation', 'synthesis', 'generation', 'writing', 'production'],\n",
    "    ['Dialogue summarization', 'conversation', 'overview', 'recap', 'condensation', 'summary'],\n",
    "    ['Data anonymization', 'privacy', 'masking', 'obfuscation', 'anonymity', 'de-identification']\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "len(task_topics_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.469022Z",
     "iopub.status.idle": "2024-07-17T12:35:41.469718Z",
     "shell.execute_reply": "2024-07-17T12:35:41.469424Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.469395Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model_guided = BERTopic(\n",
    "    embedding_model=embedding_model,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=hdbscan_model,\n",
    "    vectorizer_model=vectorizer_model,\n",
    "    ctfidf_model=ctfidf_model,\n",
    "    representation_model=representation_model,\n",
    "    n_gram_range=(1,5),\n",
    "    language=\"english\",\n",
    "    seed_topic_list=task_topics_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.472249Z",
     "iopub.status.idle": "2024-07-17T12:35:41.472912Z",
     "shell.execute_reply": "2024-07-17T12:35:41.47262Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.472596Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "topics,topic_proba = topic_model_guided.fit_transform(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.474916Z",
     "iopub.status.idle": "2024-07-17T12:35:41.475573Z",
     "shell.execute_reply": "2024-07-17T12:35:41.475266Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.475241Z"
    }
   },
   "outputs": [],
   "source": [
    "topic_model_guided.visualize_barchart(top_n_topics=30,n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_guided.save(\"topic_model_guided\", serialization=\"safetensors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99a6d0",
   "metadata": {},
   "source": [
    "# Resources \n",
    "\n",
    "\n",
    "\n",
    "* https://research.google/pubs/large-language-models-are-effective-text-rankers-with-pairwise-ranking-prompting/\n",
    "* https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms\n",
    "* https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\n",
    "* https://www.kaggle.com/code/abaojiang/lmsys-detailed-eda\n",
    "* https://www.kaggle.com/code/robikscube/lmsys-chatbot-arena-data-anaylsis#Response-Length-Baseline\n",
    "* https://medium.com/data-reply-it-datatech/bertopic-topic-modeling-as-you-have-never-seen-it-before-abb48bbab2b2"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
