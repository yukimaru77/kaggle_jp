{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":78911,"sourceType":"modelInstanceVersion","modelInstanceId":66305,"modelId":91224}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-23T12:14:11.610675Z","iopub.execute_input":"2024-07-23T12:14:11.61132Z","iopub.status.idle":"2024-07-23T12:14:12.713362Z","shell.execute_reply.started":"2024-07-23T12:14:11.611289Z","shell.execute_reply":"2024-07-23T12:14:12.712364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:12.71552Z","iopub.execute_input":"2024-07-23T12:14:12.716446Z","iopub.status.idle":"2024-07-23T12:14:16.340081Z","shell.execute_reply.started":"2024-07-23T12:14:12.716387Z","shell.execute_reply":"2024-07-23T12:14:16.338541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.341799Z","iopub.execute_input":"2024-07-23T12:14:16.34214Z","iopub.status.idle":"2024-07-23T12:14:16.353114Z","shell.execute_reply.started":"2024-07-23T12:14:16.342108Z","shell.execute_reply":"2024-07-23T12:14:16.351547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.356502Z","iopub.execute_input":"2024-07-23T12:14:16.357126Z","iopub.status.idle":"2024-07-23T12:14:16.386243Z","shell.execute_reply.started":"2024-07-23T12:14:16.357089Z","shell.execute_reply":"2024-07-23T12:14:16.38542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed = train_data.drop('id', axis = 1)\ntest_data_processed = test_data.drop('id', axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.387909Z","iopub.execute_input":"2024-07-23T12:14:16.388567Z","iopub.status.idle":"2024-07-23T12:14:16.404489Z","shell.execute_reply.started":"2024-07-23T12:14:16.388523Z","shell.execute_reply":"2024-07-23T12:14:16.403373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed = train_data_processed.drop(['model_a', 'model_b'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.40625Z","iopub.execute_input":"2024-07-23T12:14:16.407019Z","iopub.status.idle":"2024-07-23T12:14:16.422356Z","shell.execute_reply.started":"2024-07-23T12:14:16.406979Z","shell.execute_reply":"2024-07-23T12:14:16.421527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed['winner'] = train_data_processed[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1).apply(lambda x: {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}[x])\ntrain_data_processed.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.423991Z","iopub.execute_input":"2024-07-23T12:14:16.424393Z","iopub.status.idle":"2024-07-23T12:14:16.514678Z","shell.execute_reply.started":"2024-07-23T12:14:16.424357Z","shell.execute_reply":"2024-07-23T12:14:16.513538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.5159Z","iopub.execute_input":"2024-07-23T12:14:16.516196Z","iopub.status.idle":"2024-07-23T12:14:16.530556Z","shell.execute_reply.started":"2024-07-23T12:14:16.51617Z","shell.execute_reply":"2024-07-23T12:14:16.529315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers\n!pip install torch","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:14:16.53195Z","iopub.execute_input":"2024-07-23T12:14:16.532315Z","iopub.status.idle":"2024-07-23T12:15:23.626554Z","shell.execute_reply.started":"2024-07-23T12:14:16.532283Z","shell.execute_reply":"2024-07-23T12:15:23.625465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:23.631471Z","iopub.execute_input":"2024-07-23T12:15:23.631818Z","iopub.status.idle":"2024-07-23T12:15:27.227161Z","shell.execute_reply.started":"2024-07-23T12:15:23.631785Z","shell.execute_reply":"2024-07-23T12:15:27.226331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:27.228634Z","iopub.execute_input":"2024-07-23T12:15:27.229195Z","iopub.status.idle":"2024-07-23T12:15:27.266679Z","shell.execute_reply.started":"2024-07-23T12:15:27.229158Z","shell.execute_reply":"2024-07-23T12:15:27.265551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:27.267986Z","iopub.execute_input":"2024-07-23T12:15:27.268365Z","iopub.status.idle":"2024-07-23T12:15:28.873329Z","shell.execute_reply.started":"2024-07-23T12:15:27.268332Z","shell.execute_reply":"2024-07-23T12:15:28.872529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n# model = BertModel.from_pretrained('bert-base-uncased')\n\n# tokenizer.save_pretrained('./bert-base-uncased')\n# model.save_pretrained('./bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:28.874417Z","iopub.execute_input":"2024-07-23T12:15:28.874843Z","iopub.status.idle":"2024-07-23T12:15:28.879071Z","shell.execute_reply.started":"2024-07-23T12:15:28.874816Z","shell.execute_reply":"2024-07-23T12:15:28.878237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased/pytorch/uncased/1')\nmodel = BertModel.from_pretrained('/kaggle/input/bert-base-uncased/pytorch/uncased/1')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:28.880091Z","iopub.execute_input":"2024-07-23T12:15:28.880345Z","iopub.status.idle":"2024-07-23T12:15:32.913515Z","shell.execute_reply.started":"2024-07-23T12:15:28.880324Z","shell.execute_reply":"2024-07-23T12:15:32.912464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bert_embeddings_batch(text_list, batch_size=32):\n    embeddings = []\n    for i in tqdm(range(0, len(text_list), batch_size)):\n        batch_texts = text_list[i:i+batch_size]\n        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n        inputs = {key: value.to(device) for key, value in inputs.items()}  # Move inputs to GPU if available\n        with torch.no_grad():\n            outputs = model(**inputs)\n        batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Move embeddings back to CPU\n        embeddings.append(batch_embeddings)\n    return np.vstack(embeddings)","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:32.914862Z","iopub.execute_input":"2024-07-23T12:15:32.91518Z","iopub.status.idle":"2024-07-23T12:15:32.923194Z","shell.execute_reply.started":"2024-07-23T12:15:32.915153Z","shell.execute_reply":"2024-07-23T12:15:32.922114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_prompt_embeddings = get_bert_embeddings_batch(train_data_processed['prompt'].tolist())\ntrain_response_a_embeddings = get_bert_embeddings_batch(train_data_processed['response_a'].tolist())\ntrain_response_b_embeddings = get_bert_embeddings_batch(train_data_processed['response_b'].tolist())","metadata":{"execution":{"iopub.status.busy":"2024-07-23T12:15:32.924304Z","iopub.execute_input":"2024-07-23T12:15:32.924623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prompt_embeddings = get_bert_embeddings_batch(test_data_processed['prompt'].tolist())\ntest_response_a_embeddings = get_bert_embeddings_batch(test_data_processed['response_a'].tolist())\ntest_response_b_embeddings = get_bert_embeddings_batch(test_data_processed['response_b'].tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings = np.hstack([train_prompt_embeddings, train_response_a_embeddings, train_response_b_embeddings])\ntest_embeddings = np.hstack([test_prompt_embeddings, test_response_a_embeddings, test_response_b_embeddings])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed['prompt_embedding'] = list(train_embeddings[:, :768])\ntrain_data_processed['response_a_embedding'] = list(train_embeddings[:, 768:1536])\ntrain_data_processed['response_b_embedding'] = list(train_embeddings[:, 1536:2304])\n\ntest_data_processed['prompt_embedding'] = list(test_embeddings[:, :768])\ntest_data_processed['response_a_embedding'] = list(test_embeddings[:, 768:1536])\ntest_data_processed['response_b_embedding'] = list(test_embeddings[:, 1536:2304])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_processed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train_embeddings\ny = train_data_processed['winner']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install catboost","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = CatBoostClassifier(\n    iterations = 1460,\n    learning_rate = 0.01,\n    depth = 7,\n    loss_function = 'MultiClass',\n    eval_metric = 'Accuracy',\n    random_seed = 0,\n    task_type = 'GPU',\n    verbose = 100\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, eval_set=(X_val, y_val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = model.predict(X_val)\nval_preds_class = val_preds.argmax(axis=1)\n\naccuracy = accuracy_score(y_val, val_preds_class)\nprint(f'Validation Accuracy: {accuracy:.4f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test_embeddings","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds_prob = model.predict_proba(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'id': test_data['id'],\n    'prob_winner_model_a': test_preds_prob[:, 0],\n    'prob_winner_model_b': test_preds_prob[:, 1],\n    'prob_winner_tie': test_preds_prob[:, 2]\n})\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}