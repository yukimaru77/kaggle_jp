{"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8377405,"sourceType":"datasetVersion","datasetId":4959805}],"dockerImageVersionId":30715,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2593.627859,"end_time":"2024-06-06T20:41:57.399746","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-06-06T19:58:43.771887","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction üìú","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":0.006471,"end_time":"2024-06-06T19:58:46.762326","exception":false,"start_time":"2024-06-06T19:58:46.755855","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"‚úîÔ∏è What is the objective of this notebook?\n\nThe goal is to create a robust and efficient solution to predict users' preference of LLM responses using LightGBM and TF-IDF vectorization.\n\n---\n\n‚úîÔ∏è What does this notebook cover?\n\n- `Data Loading & EDA`\n\n- `Theory behind TF-IDF`\n\n- `Data Preprocessing`\n\n- `Model Training`\n       \n- `Model Inference`\n     ","metadata":{"papermill":{"duration":0.005699,"end_time":"2024-06-06T19:58:46.774185","exception":false,"start_time":"2024-06-06T19:58:46.768486","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Imports üì¶","metadata":{}},{"cell_type":"code","source":"# Handle warning messages\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:31:51.269196Z","iopub.execute_input":"2024-06-17T17:31:51.269648Z","iopub.status.idle":"2024-06-17T17:31:51.319543Z","shell.execute_reply.started":"2024-06-17T17:31:51.269611Z","shell.execute_reply":"2024-06-17T17:31:51.318188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data preprocessing\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\n# Data visualization\nimport plotly.graph_objects as go\nfrom sklearn.metrics import confusion_matrix\n\n# Model development\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\n\n# TF-IDF Vectorization\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Similarity/distance features for TF-IDF vectors\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, laplacian_kernel","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:32:20.757965Z","iopub.execute_input":"2024-06-17T17:32:20.758585Z","iopub.status.idle":"2024-06-17T17:32:20.766174Z","shell.execute_reply.started":"2024-06-17T17:32:20.758551Z","shell.execute_reply":"2024-06-17T17:32:20.764803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration ‚öôÔ∏è","metadata":{}},{"cell_type":"code","source":"class CFG:\n    # Paths to competition data\n    train_data = Path(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n    test_data = Path(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n    subm_data = Path(\"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\")\n    \n    # Colorscale for confusion matrix\n    colorscale = \"peach\"\n    \n    # TF-IDF Vectorization parameters\n    components = 32\n    ngrams = (1, 7) \n    max_freq = 0.95 # Words that occur in more than 95% of the documents are omitted\n    min_freq = 10   # Words that occur in less than 10 documents are omitted\n    \n    # Training arguments\n    num_classes = 3\n    early_stop = 50\n    log_steps = 100\n    \n    # LightGBM parameters\n    params = {\n        \"objective\": \"multiclass\",\n        \"colsample_bytree\": 0.8,\n        \"colsample_bynode\": 0.8,\n        \"metric\": \"multiclass\",\n        \"learning_rate\": 0.02,\n        \"extra_trees\": True,\n        \"num_rounds\": 3000,\n        \"reg_lambda\": 1.3,\n        \"num_classes\": 3,\n        \"num_leaves\": 64,\n        \"reg_alpha\": 0.1,\n        \"device\": \"cpu\",\n        \"max_depth\": 6,\n        \"max_bin\": 128,\n        \"verbose\": -1,\n        \"seed\": 42\n    }","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:33:16.958249Z","iopub.execute_input":"2024-06-17T17:33:16.95883Z","iopub.status.idle":"2024-06-17T17:33:16.970032Z","shell.execute_reply.started":"2024-06-17T17:33:16.95869Z","shell.execute_reply":"2024-06-17T17:33:16.968747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA) üóÉÔ∏è","metadata":{"papermill":{"duration":0.00575,"end_time":"2024-06-06T19:58:50.463546","exception":false,"start_time":"2024-06-06T19:58:50.457796","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class EDA:\n    def read_data(self, path):\n        # Read dataframe from path\n        df = pd.read_csv(path)\n        \n        # Display the shape of the dataframe and the first 3 rows\n        print(f\"The shape of the dataframe is: {df.shape}\")\n        display(df.head(3))\n        \n        return df\n    \n    def pie_chart(self, data):\n        # Calculate the counts for each winner column\n        counts = {\n            'winner_model_a': data['winner_model_a'].sum(),\n            'winner_model_b': data['winner_model_b'].sum(),\n            'winner_tie': data['winner_tie'].sum()\n        }\n\n        # Define the colors\n        colors = ['#a89192', '#8083a8', '#a8c28c']  # creme, light blue, mint\n        identifiers = ['Creme', 'Light Blue', 'Mint']\n        \n        # Create the pie chart\n        fig = go.Figure(data=[go.Pie(labels=identifiers, \n                                     values=list(counts.values()), \n                                     textinfo='percent', \n                                     hole=0.1,\n                                     marker=dict(colors=colors, line=dict(color='#FFFFFF')))])\n        \n        # Update layout for a transparent background and move the pie to the left\n        fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', \n                          paper_bgcolor='rgba(0,0,0,0)', \n                          margin=dict(l=0, r=0, t=0, b=0))\n        \n        # Hide the legend\n        fig.update_layout(showlegend=False)\n        \n        # Show the plot\n        fig.show()\n\n        # Display the counts as a table\n        counts_df = pd.DataFrame(list(counts.items()), columns=['Class', 'Count'])\n        counts_df['Identifier'] = identifiers\n        display(counts_df)\n        \n    def response_length(self, data):\n        # Create a copy of the dataframe to avoid modifying the original data\n        data_copy = data.copy()\n        \n        # Calculate the number of words in each response\n        data_copy['word_count_a'] = data_copy['response_a'].apply(lambda x: len(str(x).split()))\n        data_copy['word_count_b'] = data_copy['response_b'].apply(lambda x: len(str(x).split()))\n        \n        # Calculate the average word count for each winner class\n        word_counts = {\n            'winner_model_a': int(\n                data_copy[data_copy['winner_model_a'] == 1][\n                    ['word_count_a', \n                     'word_count_b']\n                ].mean().mean()\n            ),\n            \n            'winner_model_b': int(\n                data_copy[data_copy['winner_model_b'] == 1][\n                    ['word_count_a', \n                     'word_count_b']\n                ].mean().mean()\n            ),\n            \n            'winner_tie': int(\n                data_copy[data_copy['winner_tie'] == 1][\n                    ['word_count_a', \n                     'word_count_b']\n                ].mean().mean()\n            )\n        }\n        \n        # Create custom hover text\n        hover_texts = [f\"Word Count: {value}<br>{key}\" for key, value in word_counts.items()]\n        \n        # Create the bar chart\n        fig = go.Figure(data=[go.Bar(\n            x=list(word_counts.keys()),  # Winner class labels on x-axis\n            y=list(word_counts.values()),\n            marker=dict(color=['#a89192', '#8083a8', '#a8c28c']),\n            hovertext=hover_texts,\n            hoverinfo='text',\n            orientation='v'  # Ensure bars are vertical\n        )])\n        \n        # Update layout\n        fig.update_layout(\n            title='Average Response Word Count by Winner Class',\n            xaxis_title='',\n            yaxis_title='Average Response Word Count',\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            xaxis=dict(showticklabels=False)  # Hide x-axis labels\n        )\n        \n        # Show the plot\n        fig.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:20.288118Z","iopub.execute_input":"2024-06-17T17:38:20.288524Z","iopub.status.idle":"2024-06-17T17:38:20.308922Z","shell.execute_reply.started":"2024-06-17T17:38:20.288494Z","shell.execute_reply":"2024-06-17T17:38:20.307347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda = EDA()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:21.695297Z","iopub.execute_input":"2024-06-17T17:38:21.695756Z","iopub.status.idle":"2024-06-17T17:38:21.702409Z","shell.execute_reply.started":"2024-06-17T17:38:21.695695Z","shell.execute_reply":"2024-06-17T17:38:21.701089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = eda.read_data(CFG.train_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:25.550913Z","iopub.execute_input":"2024-06-17T17:38:25.551342Z","iopub.status.idle":"2024-06-17T17:38:30.501504Z","shell.execute_reply.started":"2024-06-17T17:38:25.551312Z","shell.execute_reply":"2024-06-17T17:38:30.500243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data = eda.read_data(CFG.test_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:36.652917Z","iopub.execute_input":"2024-06-17T17:38:36.653436Z","iopub.status.idle":"2024-06-17T17:38:36.672035Z","shell.execute_reply.started":"2024-06-17T17:38:36.653398Z","shell.execute_reply":"2024-06-17T17:38:36.670511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm_data = eda.read_data(CFG.subm_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:43.898369Z","iopub.execute_input":"2024-06-17T17:38:43.898851Z","iopub.status.idle":"2024-06-17T17:38:43.922869Z","shell.execute_reply.started":"2024-06-17T17:38:43.898813Z","shell.execute_reply":"2024-06-17T17:38:43.921453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Distribution of classes (winners):\")\neda.pie_chart(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:48.961789Z","iopub.execute_input":"2024-06-17T17:38:48.962237Z","iopub.status.idle":"2024-06-17T17:38:49.482496Z","shell.execute_reply.started":"2024-06-17T17:38:48.962204Z","shell.execute_reply":"2024-06-17T17:38:49.481275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot average response word count per winner model\neda.response_length(train_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T17:38:59.134924Z","iopub.execute_input":"2024-06-17T17:38:59.135398Z","iopub.status.idle":"2024-06-17T17:39:01.210285Z","shell.execute_reply.started":"2024-06-17T17:38:59.13536Z","shell.execute_reply":"2024-06-17T17:39:01.208513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Theory üìí","metadata":{}},{"cell_type":"markdown","source":"‚úîÔ∏è **Term Frequency - Inverse Document Frequency** or **TF-IDF** vectorization is used in text mining and information retrieval to assess the importance of words in a document relative to a corpus. This technique transforms text data into a numerical format suitable for machine learning algorithms.\n\n---\n\n‚úîÔ∏è **Components of TF-IDF**\n\n1. Term Frequency (TF):\n\n   - *Definition:* Measures the frequency of a term in a document.\n   \n   - *Formula:* $ \\text{TF}(t,d) = \\frac{f_{t,d}}{\\sum\\limits_{t' \\in d} f_{t',d}} $ , where $ f_{t,d} $ is the frequency of term $ t $ in document $ d $.\n\n2. Inverse Document Frequency (IDF):\n\n   - *Definition:* Measures the importance of a term across the entire corpus.\n   \n   - *Formula:* $ \\text{IDF}(t) = \\log \\left( \\frac{N}{1 + n_t} \\right) $ , where $ N $ is the total number of documents, and $ n_t $ is the number of documents containing term $ t $.\n\n3. TF-IDF Score:\n\n   - *Definition:* Product of TF and IDF scores.\n   \n   - *Formula:* $ \\text{TF-IDF}(t,d) = \\text{TF}(t,d) \\times \\text{IDF}(t) $\n   \n---\n\n‚úîÔ∏è ***N-grams* explained**\n\n*N-grams* are contiguous sequences of $ n $ items (tokens) extracted from a text document. They provide a more comprehensive representation of the language structure and context compared to individual words.\n\n*Formula:* $ N\\text{-grams} = [t_1, t_2, ..., t_n] $\n\n*Example:* For `ngrams = (1, 3)`, it means we are considering all possible combinations of tokens within a sliding window of length 3 in the text document. Each combination of 3 tokens represents a trigram. \n\nFor instance, consider the sentence: \"I love coding.\"\n\nWith `ngrams = (1, 3)`, the n-grams extracted from this sentence would include:\n\n   * Unigrams (1-grams): [\"I\"], [\"love\"], [\"coding\"]\n    \n   * Bigrams (2-grams): [\"I love\"], [\"love coding\"]\n    \n   * Trigrams (3-grams): [\"I love coding\"]\n\nThis way, $ N-grams $ capture not only individual words but also phrases and contextual information within the text.\n  \n---\n   \n‚úîÔ∏è **Steps of TF-IDF**\n\n1. Tokenization:\n\n   - *Definition:* Breaks text into tokens.\n   \n   - *Example:* \"I love coding\" -> [\"I\", \"love\", \"coding\"]\n\n2. Document Frequency Calculation:\n\n   - *Definition:* Counts the number of documents containing each term.\n   \n   - *Example:* \"love\" appears in 1 document out of 1.\n\n3. TF-IDF Calculation:\n\n   - *Definition:* Computes the TF-IDF score for each term in each document.\n   \n   - *Example:* For ngrams = (1, 3), \"love\" appears in Document 1, the TF-IDF score for \"love\" would be calculated based on its TF and IDF.\n\n4. Vectorization:\n\n   - *Definition:* Represents each document as a vector of TF-IDF scores.\n   \n   - *Example:* Each document becomes a high-dimensional vector where each dimension corresponds to a unique term or n-gram.\n","metadata":{}},{"cell_type":"markdown","source":"# Data Preprocessing üõ†Ô∏è","metadata":{"papermill":{"duration":0.007328,"end_time":"2024-06-06T19:58:54.698795","exception":false,"start_time":"2024-06-06T19:58:54.691467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class DataPreprocessing:\n    # Check if any value in the input list is None\n    @staticmethod\n    def retrieve_none(vals):\n        return int(any(val is None for val in vals))\n\n    # Calculate the total length of strings in the input list\n    @staticmethod\n    def retrieve_length(vals):\n        length = 0\n        for val in vals:\n            if isinstance(val, str):\n                length += len(val)\n        return length\n    \n    # Calculate the count of unique works in the input list\n    @staticmethod\n    def retrieve_nuniques(vals):\n        if isinstance(vals, str):\n            return len(set(vals.split()))\n        return 0\n    \n    # Replace 'None' in the list with the string 'NONE', and join elements with a space\n    @staticmethod\n    def clean_response(text):\n        if isinstance(text, list):\n            cleaned_text = ' '.join([str(item) if item is not None else 'NONE' for item in text])\n            return cleaned_text\n\n        return text\n\n    def add_features(self, data):\n        # Add features related to the length and presence of None values in response columns.\n        data[f\"response_a_len\"] = data[f\"response_a\"].apply(self.retrieve_length)\n        data[f\"response_b_len\"] = data[f\"response_b\"].apply(self.retrieve_length)\n\n        # Calculate unique word count for responses\n        data[f\"response_a_unique\"] = data[f\"response_a\"].apply(self.retrieve_nuniques)\n        data[f\"response_b_unique\"] = data[f\"response_b\"].apply(self.retrieve_nuniques)\n\n        # Calculate length difference, mean length, and length difference ratio.\n        data[\"response_len_diff\"] = data[\"response_a_len\"] - data[\"response_b_len\"]\n        data[\"response_len_mean\"] = (data[\"response_a_len\"] + data[\"response_b_len\"]) / 2\n        data[\"response_diff_ratio\"] = data[\"response_len_diff\"] / data[\"response_len_mean\"]\n\n        # Calculate unique word count difference, mean, and ratio.\n        data[\"response_unique_diff\"] = data[\"response_a_unique\"] - data[\"response_b_unique\"]\n        data[\"response_unique_mean\"] = (data[\"response_a_unique\"] + \n                                        data[\"response_b_unique\"]) / 2\n        data[\"response_unique_ratio\"] = (data[\"response_unique_diff\"] / \n                                         data[\"response_unique_mean\"])\n\n        # Check if any value in response columns is None.\n        data[\"a_has_none\"] = data[\"response_a\"].apply(self.retrieve_none)\n        data[\"b_has_none\"] = data[\"response_b\"].apply(self.retrieve_none)\n        data[\"has_none_diff\"] = data[\"a_has_none\"] - data[\"b_has_none\"]\n\n        return data\n    \n    # Calculate cosine similarity between prompt and responses\n    @staticmethod\n    def calculate_cosine_similarity(tfidf_matrix, \n                                    prompt_idx, \n                                    response_a_idx, \n                                    response_b_idx):\n        \n        # Cosine similarity between prompt (p) and response_a (a)\n        similarity_pa = cosine_similarity(\n                tfidf_matrix[prompt_idx].reshape(1, -1), \n                tfidf_matrix[response_a_idx].reshape(1, -1)\n        )[0][0]\n\n        # Cosine similarity between prompt (p) and response_b (b)\n        similarity_pb = cosine_similarity(\n                tfidf_matrix[prompt_idx].reshape(1, -1), \n                tfidf_matrix[response_b_idx].reshape(1, -1)\n        )[0][0]\n\n        return similarity_pa, similarity_pb\n\n    # Calculate distances (Euclidean/Laplacian) between prompt and responses\n    @staticmethod\n    def calculate_distances(tfidf_matrix, \n                            prompt_idx, \n                            response_a_idx, \n                            response_b_idx, \n                            distance_metric):\n        \n        # Distance between prompt (p) and response_a (a)\n        distance_pa = distance_metric(\n                tfidf_matrix[prompt_idx].reshape(1, -1), \n                tfidf_matrix[response_a_idx].reshape(1, -1)\n        )[0][0]\n        \n        # Distance between prompt (p) and response_b (b)\n        distance_pb = distance_metric(\n                tfidf_matrix[prompt_idx].reshape(1, -1),\n                tfidf_matrix[response_b_idx].reshape(1, -1)\n        )[0][0]\n        \n        return distance_pa, distance_pb\n\n    def create_tfidf_features(self, train, test, ngrams, min_freq, max_freq, components):\n        # Initialize TF-IDF Vectorizer\n        tfidf_vectorizer = TfidfVectorizer(analyzer='char', \n                                           ngram_range=ngrams, \n                                           min_df=min_freq, \n                                           max_df=max_freq,\n                                           lowercase=False,\n                                           sublinear_tf=True)\n\n        # Combine train and test data into a single DataFrame\n        full_data = pd.concat([train, test], ignore_index=True)\n\n        # Clean and prepare the text columns\n        for col in ['prompt', 'response_a', 'response_b']:\n            full_data[col] = full_data[col].apply(self.clean_response)\n\n        # Combine all text columns into a single corpus for TF-IDF vectorization\n        full_corpus = pd.concat([full_data['prompt'], \n                                 full_data['response_a'], \n                                 full_data['response_b']], \n                                 ignore_index=True)\n\n        # Compute the TF-IDF matrix\n        tfidf_matrix = tfidf_vectorizer.fit_transform(full_corpus)\n\n        # Perform dimensionality reduction with TruncatedSVD\n        svd = TruncatedSVD(n_components=components, random_state=42)\n        reduced_matrix = svd.fit_transform(tfidf_matrix)\n\n        # Calculate split indices for separating different parts of the corpus\n        len_full = len(full_data)\n        split_index_01 = len_full\n        split_index_02 = len_full * 2\n\n        # Split the reduced matrix into prompts, response_a, and response_b parts\n        full_tfidf_prompts = reduced_matrix[:split_index_01]\n        full_tfidf_response_a = reduced_matrix[split_index_01:split_index_02]\n        full_tfidf_response_b = reduced_matrix[split_index_02:]\n\n        # Separate the reduced matrix into training and testing sets\n        len_train = len(train)\n        train_tfidf_prompts = full_tfidf_prompts[:len_train]\n        train_tfidf_response_a = full_tfidf_response_a[:len_train]\n        train_tfidf_response_b = full_tfidf_response_b[:len_train]\n        test_tfidf_prompts = full_tfidf_prompts[len_train:]\n        test_tfidf_response_a = full_tfidf_response_a[len_train:]\n        test_tfidf_response_b = full_tfidf_response_b[len_train:]\n\n        # Create DataFrames to hold the SVD features for train and test sets\n        feature_names = [f'svd_feature_{i}' for i in range(components)]\n        train_features = pd.DataFrame(index=train.index)\n        test_features = pd.DataFrame(index=test.index)\n\n        # Assign SVD features to the respective columns in the feature DataFrames\n        for i in range(components):\n            train_features[f'svd_prompts_{i}'] = train_tfidf_prompts[:, i]\n            train_features[f'svd_response_a_{i}'] = train_tfidf_response_a[:, i]\n            train_features[f'svd_response_b_{i}'] = train_tfidf_response_b[:, i]\n            test_features[f'svd_prompts_{i}'] = test_tfidf_prompts[:, i]\n            test_features[f'svd_response_a_{i}'] = test_tfidf_response_a[:, i]\n            test_features[f'svd_response_b_{i}'] = test_tfidf_response_b[:, i]\n\n        # Concatenate the new features with the original train and test DataFrames\n        train = pd.concat([train, train_features], axis=1)\n        test = pd.concat([test, test_features], axis=1)\n\n        # Calculate similarity and distance features\n        for df, len_df in zip([train, test], [len(train), len(test)]):\n            prompt_indices = df.index\n\n            # Calculate cosine similarity features\n            df['similarity_pa'], df['similarity_pb'] = zip(*[\n                self.calculate_cosine_similarity(reduced_matrix, i, i + len_df, i + 2 * len_df)\n                for i in prompt_indices\n            ])\n\n            # Calculate Euclidean distance features\n            df['euclidean_pa'], df['euclidean_pb'] = zip(*[\n                self.calculate_distances(reduced_matrix, i, i + len_df, i + 2 * len_df, \n                                         euclidean_distances)\n                for i in prompt_indices\n            ])\n\n            # Calculate Laplacian kernel distance features\n            df['laplacian_pa'], df['laplacian_pb']= zip(*[\n                self.calculate_distances(reduced_matrix, i, i + len_df, i + 2 * len_df, \n                                         laplacian_kernel)\n                for i in prompt_indices\n            ])\n\n        return train, test\n    \n    # Merges multiple labels into a single label\n    def merge_label(self, row):\n        if row[\"winner_model_a\"] == 1:\n            return 0\n        if row[\"winner_model_b\"] == 1:\n            return 1\n        if row[\"winner_tie\"] == 1:\n            return 2\n        raise ValueError(\"The value is invalid.\")","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:16:09.084595Z","iopub.execute_input":"2024-06-17T18:16:09.085037Z","iopub.status.idle":"2024-06-17T18:16:09.127941Z","shell.execute_reply.started":"2024-06-17T18:16:09.085004Z","shell.execute_reply":"2024-06-17T18:16:09.126578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dp = DataPreprocessing()","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:16:11.276207Z","iopub.execute_input":"2024-06-17T18:16:11.276607Z","iopub.status.idle":"2024-06-17T18:16:11.282244Z","shell.execute_reply.started":"2024-06-17T18:16:11.276577Z","shell.execute_reply":"2024-06-17T18:16:11.280811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add length, similarity and distance features\ntrain_data = dp.add_features(train_data)\ntest_data = dp.add_features(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:16:12.766348Z","iopub.execute_input":"2024-06-17T18:16:12.76684Z","iopub.status.idle":"2024-06-17T18:17:12.04567Z","shell.execute_reply.started":"2024-06-17T18:16:12.766804Z","shell.execute_reply":"2024-06-17T18:17:12.044262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extract TF-IDF features and perform dimensionality reduction\ntrain_data, test_data = dp.create_tfidf_features(train_data, \n                                                 test_data, \n                                                 CFG.ngrams,\n                                                 CFG.min_freq, \n                                                 CFG.max_freq, \n                                                 CFG.components)","metadata":{"execution":{"iopub.status.busy":"2024-06-17T18:17:12.047755Z","iopub.execute_input":"2024-06-17T18:17:12.048154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge multiple labels into a single label\ntrain_data[\"target\"] = train_data[\n    [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n                                 ].apply(lambda x: dp.merge_label(x), axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Development üß†","metadata":{"papermill":{"duration":0.007905,"end_time":"2024-06-06T20:37:34.001646","exception":false,"start_time":"2024-06-06T20:37:33.993741","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class ModelDevelopment:\n    def train_lgb(self, train_data, test_data, feature_cols, params, early_stop, log_steps):\n        # Extract feature values and target labels from the training and testing data\n        X_train = train_data[feature_cols].values\n        X_test = test_data[feature_cols].values\n        Y_train = train_data[\"target\"]\n\n        # List to store predictions\n        train_preds_list = []\n        test_preds_list = []\n\n        # Initialize StratifiedKFold\n        cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n        for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, Y_train)):\n            # Split the training data into training and validation sets for the current fold\n            x_train, x_valid = X_train[train_index], X_train[valid_index]\n            y_train, y_valid = Y_train[train_index], Y_train[valid_index]\n\n            # Create LightGBM dataset objects for training and validation\n            train = lgb.Dataset(x_train, y_train)\n            valid = lgb.Dataset(x_valid, y_valid, reference=train)\n\n            # Train the model on the current fold\n            model = lgb.train(\n                params,\n                train,\n                valid_sets=[train, valid],\n                feature_name=feature_cols,\n                callbacks=[lgb.early_stopping(early_stop),\n                           lgb.log_evaluation(log_steps)])\n\n            # Make predictions on the train and test sets\n            train_preds = model.predict(X_train)\n            test_preds = model.predict(X_test)\n\n            train_preds_list.append(train_preds)\n            test_preds_list.append(test_preds)\n\n        # Average predictions\n        train_preds = np.mean(train_preds_list, axis=0)\n        test_preds = np.mean(test_preds_list, axis=0)\n\n        return train_preds, test_preds\n    \n    # Confusion matrix for train data predictions\n    def plot_cm(self, y_true, y_pred, labels, colorscale):\n        cm = confusion_matrix(y_true, y_pred, labels=labels)\n\n        # Create a custom hover text formatter\n        def format_hover_text(value):\n            if value >= 10000:\n                return str(int(value))  # Convert to integer without commas or \"k\"\n            else:\n                return str(value)\n\n        # Create the heatmap\n        fig = go.Figure(data=go.Heatmap(\n            z=cm,\n            x=labels,\n            y=labels,\n            colorscale=colorscale,\n            zmin=0,\n            zmax=20000,\n            text=cm,\n            texttemplate=\"%{text:.0f}\",\n            hovertemplate=\"True: %{y}<br>Predicted: %{x}<br>Count: %{z:,.0f}<extra></extra>\",\n            customdata=[format_hover_text(value) for value in cm.flatten()]\n        ))\n\n        # Update layout for a transparent background and square aspect ratio\n        fig.update_layout(\n            plot_bgcolor='rgba(0,0,0,0)',\n            paper_bgcolor='rgba(0,0,0,0)',\n            xaxis_title=\"Predicted Labels\",\n            yaxis_title=\"True Labels\",\n            xaxis=dict(constrain='domain'),\n            yaxis=dict(constrain='domain', scaleanchor='x'),\n            width=650,  \n            height=650,  \n            margin=dict(t=65, b=65, l=65, r=65) \n        )\n\n        # Show the plot\n        fig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"md = ModelDevelopment()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define label columns\nlabel_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n\n# Define the list of features to exclude from the training data\nexcluded_features = ['id', \n                     'model_a', \n                     'model_b', \n                     'prompt', \n                     'response_a', \n                     'response_b',\n                     'winner_model_a', \n                     'winner_model_b', \n                     'winner_tie', \n                     'target', \n                     'fold_id']\n\nfeatures = [col for col in train_data.columns if col not in excluded_features]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train LightGBM\ntrain_preds, test_preds = md.train_lgb(train_data, \n                                       test_data, \n                                       features,\n                                       CFG.params, \n                                       CFG.early_stop, \n                                       CFG.log_steps)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Confusion matrix for (mean) predictions on train data\nmd.plot_cm(train_data['target'], np.argmax(train_preds, axis=1), [0, 1, 2], CFG.colorscale)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit Predictions üí°","metadata":{"papermill":{"duration":0.010083,"end_time":"2024-06-06T20:41:56.314735","exception":false,"start_time":"2024-06-06T20:41:56.304652","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Assign the predicted test labels to the submission dataframe\nsubm_data[label_cols] = test_preds\n\n# Save the submission dataframe and display the first 3 rows\nsubm_data.to_csv(\"submission.csv\", index=False)\ndisplay(subm_data.head(3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}