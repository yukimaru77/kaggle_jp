{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:45:46.411366Z",
     "iopub.status.busy": "2024-07-06T12:45:46.410517Z",
     "iopub.status.idle": "2024-07-06T12:46:56.122877Z",
     "shell.execute_reply": "2024-07-06T12:46:56.121632Z",
     "shell.execute_reply.started": "2024-07-06T12:45:46.41132Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n",
    "!pip install -U /kaggle/input/peft-wheel/pytorch/version1/1/peft-0.10.0-py3-none-any.whl -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-06T12:46:56.125204Z",
     "iopub.status.busy": "2024-07-06T12:46:56.124907Z",
     "iopub.status.idle": "2024-07-06T12:47:04.022214Z",
     "shell.execute_reply": "2024-07-06T12:47:04.021448Z",
     "shell.execute_reply.started": "2024-07-06T12:46:56.125174Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from datasets import Dataset\n",
    "import torch.nn.functional as F\n",
    "from threading import Thread\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.023805Z",
     "iopub.status.busy": "2024-07-06T12:47:04.023314Z",
     "iopub.status.idle": "2024-07-06T12:47:04.028508Z",
     "shell.execute_reply": "2024-07-06T12:47:04.027708Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.023778Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "MODEL_NAME = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n",
    "MAX_LENGTH = 1284\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.030963Z",
     "iopub.status.busy": "2024-07-06T12:47:04.030677Z",
     "iopub.status.idle": "2024-07-06T12:47:04.067682Z",
     "shell.execute_reply": "2024-07-06T12:47:04.066813Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.03094Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.068823Z",
     "iopub.status.busy": "2024-07-06T12:47:04.068588Z",
     "iopub.status.idle": "2024-07-06T12:47:04.073019Z",
     "shell.execute_reply": "2024-07-06T12:47:04.072044Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.068802Z"
    }
   },
   "outputs": [],
   "source": [
    "def transform(row):\n",
    "    return row.strip('[]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.074433Z",
     "iopub.status.busy": "2024-07-06T12:47:04.07411Z",
     "iopub.status.idle": "2024-07-06T12:47:04.085064Z",
     "shell.execute_reply": "2024-07-06T12:47:04.084026Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.074401Z"
    }
   },
   "outputs": [],
   "source": [
    "df['prompt'] = df['prompt'].apply(transform)\n",
    "df['response_a'] = df['response_a'].apply(transform)\n",
    "df['response_b'] = df['response_b'].apply(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.086628Z",
     "iopub.status.busy": "2024-07-06T12:47:04.086266Z",
     "iopub.status.idle": "2024-07-06T12:47:04.096075Z",
     "shell.execute_reply": "2024-07-06T12:47:04.095197Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.086597Z"
    }
   },
   "outputs": [],
   "source": [
    "df['text'] = 'User prompt: ' + df['prompt'] +  '\\n\\nModel A :\\n' + df['response_a'] +'\\n\\n----------\\n\\nModel B:\\n'  + df['response_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.097488Z",
     "iopub.status.busy": "2024-07-06T12:47:04.097234Z",
     "iopub.status.idle": "2024-07-06T12:47:04.609309Z",
     "shell.execute_reply": "2024-07-06T12:47:04.608535Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.097466Z"
    }
   },
   "outputs": [],
   "source": [
    "# peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "# peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.610679Z",
     "iopub.status.busy": "2024-07-06T12:47:04.610405Z",
     "iopub.status.idle": "2024-07-06T12:47:04.616589Z",
     "shell.execute_reply": "2024-07-06T12:47:04.615856Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.610654Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_function(df):\n",
    "    result = tokenizer(df, padding=\"max_length\", truncation=True, max_length = MAX_LENGTH)\n",
    "    return result['input_ids'], result['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:00.067958Z",
     "iopub.status.busy": "2024-07-06T12:48:00.067048Z",
     "iopub.status.idle": "2024-07-06T12:48:00.081557Z",
     "shell.execute_reply": "2024-07-06T12:48:00.080565Z",
     "shell.execute_reply.started": "2024-07-06T12:48:00.067923Z"
    }
   },
   "outputs": [],
   "source": [
    "temp = df['text'].apply(tokenize_function)\n",
    "df['input_ids'] = temp.apply(lambda x: x[0])\n",
    "df['attention_mask'] = temp.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:07.377336Z",
     "iopub.status.busy": "2024-07-06T12:48:07.37698Z",
     "iopub.status.idle": "2024-07-06T12:48:07.39649Z",
     "shell.execute_reply": "2024-07-06T12:48:07.395322Z",
     "shell.execute_reply.started": "2024-07-06T12:48:07.377302Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.332502Z",
     "iopub.status.busy": "2024-07-06T12:48:20.331635Z",
     "iopub.status.idle": "2024-07-06T12:48:20.33626Z",
     "shell.execute_reply": "2024-07-06T12:48:20.335287Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.332467Z"
    }
   },
   "outputs": [],
   "source": [
    "# data = Dataset.from_pandas(df[['text']])\n",
    "# data = data.map(tokenize_function, batched=True)\n",
    "# data.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.365693Z",
     "iopub.status.busy": "2024-07-06T12:48:20.365434Z",
     "iopub.status.idle": "2024-07-06T12:48:20.36919Z",
     "shell.execute_reply": "2024-07-06T12:48:20.368292Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.36567Z"
    }
   },
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.397825Z",
     "iopub.status.busy": "2024-07-06T12:48:20.397573Z",
     "iopub.status.idle": "2024-07-06T12:48:20.403307Z",
     "shell.execute_reply": "2024-07-06T12:48:20.402289Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.397804Z"
    }
   },
   "outputs": [],
   "source": [
    "device0 = torch.device('cuda:0')\n",
    "device1 = torch.device('cuda:1')\n",
    "\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.435991Z",
     "iopub.status.busy": "2024-07-06T12:48:20.435696Z",
     "iopub.status.idle": "2024-07-06T12:48:20.439876Z",
     "shell.execute_reply": "2024-07-06T12:48:20.438794Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.435966Z"
    }
   },
   "outputs": [],
   "source": [
    "peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.463942Z",
     "iopub.status.busy": "2024-07-06T12:48:20.463438Z",
     "iopub.status.idle": "2024-07-06T12:50:04.287314Z",
     "shell.execute_reply": "2024-07-06T12:50:04.286249Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.463918Z"
    }
   },
   "outputs": [],
   "source": [
    "model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model_0 = PeftModel.from_pretrained(model_0, peft_model_id).to(device0)\n",
    "model_0 = model_0.merge_and_unload()\n",
    "model_0.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:04.289854Z",
     "iopub.status.busy": "2024-07-06T12:50:04.289473Z",
     "iopub.status.idle": "2024-07-06T12:50:34.168108Z",
     "shell.execute_reply": "2024-07-06T12:50:34.16704Z",
     "shell.execute_reply.started": "2024-07-06T12:50:04.289805Z"
    }
   },
   "outputs": [],
   "source": [
    "model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model_1 = PeftModel.from_pretrained(model_1, peft_model_id).to(device1)\n",
    "model_1 = model_1.merge_and_unload()\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.169604Z",
     "iopub.status.busy": "2024-07-06T12:50:34.169313Z",
     "iopub.status.idle": "2024-07-06T12:50:34.341422Z",
     "shell.execute_reply": "2024-07-06T12:50:34.340328Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.169579Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.34401Z",
     "iopub.status.busy": "2024-07-06T12:50:34.343704Z",
     "iopub.status.idle": "2024-07-06T12:50:34.352783Z",
     "shell.execute_reply": "2024-07-06T12:50:34.35189Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.343984Z"
    }
   },
   "outputs": [],
   "source": [
    "def inference(df,model,device,batch_size=BATCH_SIZE):\n",
    "    \n",
    "    all_probabilities = []\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        \n",
    "        batch_input_ids = torch.tensor(df['input_ids'][start_idx:end_idx].tolist()).to(device)\n",
    "        batch_attention_mask = torch.tensor(df['attention_mask'][start_idx:end_idx].tolist()).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    del batch_input_ids, batch_attention_mask, outputs\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    df['winner_model_a'] = all_probabilities[:, 0]\n",
    "    df['winner_model_b'] = all_probabilities[:, 1]\n",
    "    df['winner_tie'] = all_probabilities[:, 2]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.354286Z",
     "iopub.status.busy": "2024-07-06T12:50:34.353996Z",
     "iopub.status.idle": "2024-07-06T12:50:34.372055Z",
     "shell.execute_reply": "2024-07-06T12:50:34.371265Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.354262Z"
    }
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = len(df)\n",
    "\n",
    "half = round(N_SAMPLES / 2)\n",
    "sub1 = df.iloc[0:half].copy()\n",
    "sub2 = df.iloc[half:N_SAMPLES].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.373496Z",
     "iopub.status.busy": "2024-07-06T12:50:34.37319Z",
     "iopub.status.idle": "2024-07-06T12:50:34.377873Z",
     "shell.execute_reply": "2024-07-06T12:50:34.376906Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.373472Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.379363Z",
     "iopub.status.busy": "2024-07-06T12:50:34.379101Z",
     "iopub.status.idle": "2024-07-06T12:50:34.388717Z",
     "shell.execute_reply": "2024-07-06T12:50:34.387884Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.379339Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.390058Z",
     "iopub.status.busy": "2024-07-06T12:50:34.389766Z",
     "iopub.status.idle": "2024-07-06T12:50:49.752074Z",
     "shell.execute_reply": "2024-07-06T12:50:49.751267Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.390026Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0,results, 0))\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1,results, 1))\n",
    "\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "data = pd.concat([results[0], results[1]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:49.753862Z",
     "iopub.status.busy": "2024-07-06T12:50:49.753229Z",
     "iopub.status.idle": "2024-07-06T12:50:49.764639Z",
     "shell.execute_reply": "2024-07-06T12:50:49.763794Z",
     "shell.execute_reply.started": "2024-07-06T12:50:49.753807Z"
    }
   },
   "outputs": [],
   "source": [
    "data.drop(columns=['prompt','response_a','response_b','text','input_ids','attention_mask'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:51:10.982061Z",
     "iopub.status.busy": "2024-07-06T12:51:10.981323Z",
     "iopub.status.idle": "2024-07-06T12:51:10.99276Z",
     "shell.execute_reply": "2024-07-06T12:51:10.991895Z",
     "shell.execute_reply.started": "2024-07-06T12:51:10.982017Z"
    }
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:49.767486Z",
     "iopub.status.busy": "2024-07-06T12:50:49.767222Z",
     "iopub.status.idle": "2024-07-06T12:50:49.836704Z",
     "shell.execute_reply": "2024-07-06T12:50:49.835875Z",
     "shell.execute_reply.started": "2024-07-06T12:50:49.767463Z"
    }
   },
   "outputs": [],
   "source": [
    "data.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28071,
     "sourceId": 33534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 28079,
     "sourceId": 33547,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 62824,
     "sourceId": 74803,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
