{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:08.3611Z",
     "iopub.status.busy": "2024-07-10T18:14:08.360659Z",
     "iopub.status.idle": "2024-07-10T18:14:08.929677Z",
     "shell.execute_reply": "2024-07-10T18:14:08.928456Z",
     "shell.execute_reply.started": "2024-07-10T18:14:08.361064Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:10.223858Z",
     "iopub.status.busy": "2024-07-10T18:14:10.223246Z",
     "iopub.status.idle": "2024-07-10T18:14:46.242631Z",
     "shell.execute_reply": "2024-07-10T18:14:46.241363Z",
     "shell.execute_reply.started": "2024-07-10T18:14:10.223819Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:46.245461Z",
     "iopub.status.busy": "2024-07-10T18:14:46.245087Z",
     "iopub.status.idle": "2024-07-10T18:15:21.470406Z",
     "shell.execute_reply": "2024-07-10T18:15:21.469016Z",
     "shell.execute_reply.started": "2024-07-10T18:14:46.245428Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:15:21.472389Z",
     "iopub.status.busy": "2024-07-10T18:15:21.472024Z",
     "iopub.status.idle": "2024-07-10T18:15:56.372185Z",
     "shell.execute_reply": "2024-07-10T18:15:56.370713Z",
     "shell.execute_reply.started": "2024-07-10T18:15:21.472355Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:15:56.376712Z",
     "iopub.status.busy": "2024-07-10T18:15:56.376166Z",
     "iopub.status.idle": "2024-07-10T18:16:05.593946Z",
     "shell.execute_reply": "2024-07-10T18:16:05.592679Z",
     "shell.execute_reply.started": "2024-07-10T18:15:56.376663Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import textstat\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import concurrent.futures\n",
    "import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:44.314554Z",
     "iopub.status.busy": "2024-07-10T18:19:44.314074Z",
     "iopub.status.idle": "2024-07-10T18:19:44.333118Z",
     "shell.execute_reply": "2024-07-10T18:19:44.331702Z",
     "shell.execute_reply.started": "2024-07-10T18:19:44.31452Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_readability_scores(text):\n",
    "    # This function calculates various readability scores\n",
    "    return {\n",
    "        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(text),\n",
    "        \"gunning_fog\": textstat.gunning_fog(text),\n",
    "        \"smog_index\": textstat.smog_index(text),\n",
    "        \"ari\": textstat.automated_readability_index(text),\n",
    "        \"coleman_liau_index\": textstat.coleman_liau_index(text)\n",
    "    }\n",
    "\n",
    "def count_noun_phrases(text):\n",
    "    blob = TextBlob(text)\n",
    "    return len(blob.noun_phrases)\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "\n",
    "def count_passive_voice(text):\n",
    "    doc = nlp(text)\n",
    "    return sum(1 for token in doc if token.dep_ == 'auxpass')\n",
    "\n",
    "def pos_tag_frequencies(text):\n",
    "    words = word_tokenize(text)\n",
    "    tags = nltk.pos_tag(words)\n",
    "    freq_dist = nltk.FreqDist(tag for (word, tag) in tags)\n",
    "    # Ensure all frequencies are stored in a consistent dictionary format\n",
    "    return {tag: freq for tag, freq in freq_dist.items()}\n",
    "\n",
    "def text_statistics(text):\n",
    "    stats = calculate_readability_scores(text)\n",
    "    stats.update({\n",
    "        \"word_count\": len(word_tokenize(text)),\n",
    "        \"char_count\": len(text),\n",
    "        \"sentence_count\": len(sent_tokenize(text)),\n",
    "        \"avg_word_length\": sum(len(word) for word in word_tokenize(text)) / len(word_tokenize(text)),\n",
    "        \"avg_sentence_length\": sum(len(sent) for sent in sent_tokenize(text)) / len(sent_tokenize(text)),\n",
    "        \"lexical_diversity\": len(set(word_tokenize(text))) / len(word_tokenize(text)),\n",
    "        \"noun_phrases_count\": count_noun_phrases(text),\n",
    "        \"sentiment\": analyze_sentiment(text),\n",
    "        \"passive_voice_count\": count_passive_voice(text),\n",
    "    })\n",
    "    # Merge POS tag frequencies into the main stats dictionary\n",
    "    pos_tags = pos_tag_frequencies(text)\n",
    "    for tag, count in pos_tags.items():\n",
    "        stats[f'pos_tag_{tag}'] = count\n",
    "    return stats\n",
    "\n",
    "def parallel_apply(df, column):\n",
    "    # Drop NaN values to avoid errors during text processing\n",
    "    texts = df[column].dropna()\n",
    "\n",
    "    # Use ProcessPoolExecutor to apply the function in parallel\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(text_statistics, texts))\n",
    "\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Automatically handles missing POS tags by filling with 0 and converts data types appropriately\n",
    "    # Filling missing POS tags handled by DataFrame initialization from dict\n",
    "    results_df.fillna(0, inplace=True)\n",
    "    for col in results_df.columns:\n",
    "        if results_df[col].dtype == float:\n",
    "            results_df[col] = results_df[col].astype(int)\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:47.314726Z",
     "iopub.status.busy": "2024-07-10T18:19:47.314284Z",
     "iopub.status.idle": "2024-07-10T18:19:49.521817Z",
     "shell.execute_reply": "2024-07-10T18:19:49.52068Z",
     "shell.execute_reply.started": "2024-07-10T18:19:47.314695Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "print('Data has been imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:51.505083Z",
     "iopub.status.busy": "2024-07-10T18:19:51.504656Z",
     "iopub.status.idle": "2024-07-10T18:19:51.512762Z",
     "shell.execute_reply": "2024-07-10T18:19:51.511538Z",
     "shell.execute_reply.started": "2024-07-10T18:19:51.50505Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T11:21:50.392346Z",
     "iopub.status.busy": "2024-07-10T11:21:50.391912Z",
     "iopub.status.idle": "2024-07-10T11:21:50.398948Z",
     "shell.execute_reply": "2024-07-10T11:21:50.397465Z",
     "shell.execute_reply.started": "2024-07-10T11:21:50.392314Z"
    }
   },
   "outputs": [],
   "source": [
    "# def parallel_apply(df, column):\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         results = list(executor.map(text_statistics, df[column].dropna()))  # Use dropna to handle NaNs gracefully\n",
    "#     return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:57.96877Z",
     "iopub.status.busy": "2024-07-10T18:19:57.968198Z",
     "iopub.status.idle": "2024-07-10T18:20:17.15232Z",
     "shell.execute_reply": "2024-07-10T18:20:17.150766Z",
     "shell.execute_reply.started": "2024-07-10T18:19:57.968726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying parallel_apply to 'prompt' and 'response' columns\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "prompt_stats_df = parallel_apply(train, 'prompt')\n",
    "response_a_stats_df = parallel_apply(train, 'response_a')\n",
    "response_b_stats_df = parallel_apply(train, 'response_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:27.584464Z",
     "iopub.status.busy": "2024-07-10T18:20:27.583673Z",
     "iopub.status.idle": "2024-07-10T18:20:27.686498Z",
     "shell.execute_reply": "2024-07-10T18:20:27.685326Z",
     "shell.execute_reply.started": "2024-07-10T18:20:27.584421Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.join(prompt_stats_df.add_suffix('_prompt'))\n",
    "train = train.join(response_a_stats_df.add_suffix('_response_a'))\n",
    "train = train.join(response_b_stats_df.add_suffix('_response_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:49.736783Z",
     "iopub.status.busy": "2024-07-10T18:20:49.73633Z",
     "iopub.status.idle": "2024-07-10T18:20:49.744679Z",
     "shell.execute_reply": "2024-07-10T18:20:49.7434Z",
     "shell.execute_reply.started": "2024-07-10T18:20:49.736746Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:30.29828Z",
     "iopub.status.busy": "2024-07-10T18:20:30.297834Z",
     "iopub.status.idle": "2024-07-10T18:20:30.325713Z",
     "shell.execute_reply": "2024-07-10T18:20:30.324552Z",
     "shell.execute_reply.started": "2024-07-10T18:20:30.298248Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:02:58.054824Z",
     "iopub.status.busy": "2024-07-08T12:02:58.054395Z",
     "iopub.status.idle": "2024-07-08T12:02:58.477477Z",
     "shell.execute_reply": "2024-07-08T12:02:58.476116Z",
     "shell.execute_reply.started": "2024-07-08T12:02:58.05479Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Convert the target into a single column with categorical labels\n",
    "train['winner'] = (train['winner_model_a'] * 1 + train['winner_model_b'] * 2 + train['winner_tie'] * 3).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "columns_to_remove = {'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', \n",
    "                     'winner_model_a', 'winner_model_b', 'winner_tie', 'winner'}\n",
    "\n",
    "features = [col for col in train.columns if col not in columns_to_remove]\n",
    "\n",
    "X = train[features]\n",
    "y = train['winner'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:04:40.502718Z",
     "iopub.status.busy": "2024-07-08T12:04:40.501238Z",
     "iopub.status.idle": "2024-07-08T12:06:05.549672Z",
     "shell.execute_reply": "2024-07-08T12:06:05.548464Z",
     "shell.execute_reply.started": "2024-07-08T12:04:40.502676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the Optimization Function\n",
    "def objective(trial):\n",
    "    # Data splitting inside the trial\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Define model and hyperparameters to optimize\n",
    "    model_type = trial.suggest_categorical('model_type', ['XGBClassifier', 'LGBMClassifier', 'CatBoostClassifier'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 0.1)\n",
    "\n",
    "    if model_type == 'XGBClassifier':\n",
    "        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    elif model_type == 'LGBMClassifier':\n",
    "        model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, random_state=42)\n",
    "    elif model_type == 'CatBoostClassifier':\n",
    "        model = CatBoostClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, verbose=0, random_state=42)\n",
    "\n",
    "    # Training and evaluating the model\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict_proba(X_val)\n",
    "    return log_loss(y_val, y_val_pred)\n",
    "\n",
    "# Run Optuna Optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "# Train the Best Model on Full Data\n",
    "best_params = study.best_trial.params\n",
    "model_type = best_params.pop('model_type')\n",
    "\n",
    "if model_type == 'XGBClassifier':\n",
    "    final_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "elif model_type == 'LGBMClassifier':\n",
    "    final_model = LGBMClassifier(**best_params, random_state=42)\n",
    "elif model_type == 'CatBoostClassifier':\n",
    "    final_model = CatBoostClassifier(**best_params, verbose=0, random_state=42)\n",
    "\n",
    "final_model.fit(X, y)  # Training on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:10:55.670111Z",
     "iopub.status.busy": "2024-07-08T12:10:55.669593Z",
     "iopub.status.idle": "2024-07-08T12:10:55.681442Z",
     "shell.execute_reply": "2024-07-08T12:10:55.680161Z",
     "shell.execute_reply.started": "2024-07-08T12:10:55.670072Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:16:41.428065Z",
     "iopub.status.busy": "2024-07-08T12:16:41.42756Z",
     "iopub.status.idle": "2024-07-08T12:16:42.661732Z",
     "shell.execute_reply": "2024-07-08T12:16:42.660111Z",
     "shell.execute_reply.started": "2024-07-08T12:16:41.42803Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying parallel_apply to 'prompt' and 'response' columns\n",
    "prompt_stats_df_test = parallel_apply(test, 'prompt')\n",
    "response_a_stats_df_test = parallel_apply(test, 'response_a')\n",
    "response_b_stats_df_test = parallel_apply(test, 'response_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:17:18.052752Z",
     "iopub.status.busy": "2024-07-08T12:17:18.052149Z",
     "iopub.status.idle": "2024-07-08T12:17:18.072001Z",
     "shell.execute_reply": "2024-07-08T12:17:18.07058Z",
     "shell.execute_reply.started": "2024-07-08T12:17:18.052709Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.join(prompt_stats_df_test.add_suffix('_prompt'))\n",
    "test = test.join(response_a_stats_df_test.add_suffix('_response_a'))\n",
    "test = test.join(response_b_stats_df_test.add_suffix('_response_b'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:12.279293Z",
     "iopub.status.busy": "2024-07-08T12:19:12.278703Z",
     "iopub.status.idle": "2024-07-08T12:19:12.312519Z",
     "shell.execute_reply": "2024-07-08T12:19:12.311113Z",
     "shell.execute_reply.started": "2024-07-08T12:19:12.279252Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test[features]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:20.608873Z",
     "iopub.status.busy": "2024-07-08T12:19:20.608382Z",
     "iopub.status.idle": "2024-07-08T12:19:20.645067Z",
     "shell.execute_reply": "2024-07-08T12:19:20.643825Z",
     "shell.execute_reply.started": "2024-07-08T12:19:20.608837Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:29.014605Z",
     "iopub.status.busy": "2024-07-08T12:19:29.01409Z",
     "iopub.status.idle": "2024-07-08T12:19:29.026851Z",
     "shell.execute_reply": "2024-07-08T12:19:29.025562Z",
     "shell.execute_reply.started": "2024-07-08T12:19:29.014565Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "test_predictions = final_model.predict_proba(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:35.206668Z",
     "iopub.status.busy": "2024-07-08T12:19:35.205839Z",
     "iopub.status.idle": "2024-07-08T12:19:35.218775Z",
     "shell.execute_reply": "2024-07-08T12:19:35.217583Z",
     "shell.execute_reply.started": "2024-07-08T12:19:35.206626Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:22:54.02283Z",
     "iopub.status.busy": "2024-07-08T12:22:54.021496Z",
     "iopub.status.idle": "2024-07-08T12:22:54.032338Z",
     "shell.execute_reply": "2024-07-08T12:22:54.031145Z",
     "shell.execute_reply.started": "2024-07-08T12:22:54.022787Z"
    }
   },
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv', usecols=['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:23:00.262804Z",
     "iopub.status.busy": "2024-07-08T12:23:00.261927Z",
     "iopub.status.idle": "2024-07-08T12:23:00.27939Z",
     "shell.execute_reply": "2024-07-08T12:23:00.278202Z",
     "shell.execute_reply.started": "2024-07-08T12:23:00.262753Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare the submission file\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],\n",
    "    'winner_model_a': test_predictions[:, 0],\n",
    "    'winner_model_b': test_predictions[:, 1],\n",
    "    'winner_tie': test_predictions[:, 2]\n",
    "})\n",
    "\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index= False)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 1332972,
     "sourceId": 2220985,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
