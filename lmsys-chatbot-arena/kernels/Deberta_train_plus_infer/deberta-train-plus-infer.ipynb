{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8859017,"sourceType":"datasetVersion","datasetId":5333407},{"sourceId":8875732,"sourceType":"datasetVersion","datasetId":5342754},{"sourceId":8882976,"sourceType":"datasetVersion","datasetId":5345416},{"sourceId":8857082,"sourceType":"datasetVersion","datasetId":5331941},{"sourceId":8898264,"sourceType":"datasetVersion","datasetId":5349810},{"sourceId":8898258,"sourceType":"datasetVersion","datasetId":5349807},{"sourceId":8898272,"sourceType":"datasetVersion","datasetId":5349814},{"sourceId":8902791,"sourceType":"datasetVersion","datasetId":5352224},{"sourceId":8902994,"sourceType":"datasetVersion","datasetId":5352375},{"sourceId":8918757,"sourceType":"datasetVersion","datasetId":5363851},{"sourceId":8926669,"sourceType":"datasetVersion","datasetId":5369514},{"sourceId":8976237,"sourceType":"datasetVersion","datasetId":5404689},{"sourceId":177816615,"sourceType":"kernelVersion"}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport logging\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\nfrom transformers import TrainingArguments, Trainer, DataCollatorWithPadding\nfrom datasets import Dataset\nfrom sklearn.metrics import log_loss\nimport torch\nfrom functools import partial\nimport warnings\nfrom transformers import logging as transformers_logging\nfrom transformers import EarlyStoppingCallback\nimport json\nfrom pprint import pformat\nfrom tqdm import trange\nwarnings.simplefilter('ignore')\n\nTYPE = \"large\"\nVER= 14\nDATE = \"0717\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n\n# Set up logging\ntransformers_logging.set_verbosity_error()\nlogging.basicConfig(level=logging.INFO, filename=f'logs_v{VER}.log', filemode='a',\n                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nclass PATHS:\n    train_path = '/kaggle/input/lmsys-chatbot-arena/train.csv'\n    test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n    sub_path = '/kaggle/input/lmsys-chatbot-arena/sample_submission.csv'\n    model_name = f\"deberta-v3-{TYPE}\"\n    model_path = f\"/root/autodl-tmp/ase2/huggingfacedebertav3variants/{model_name}\"\n    tokenizer_path = f\"/kaggle/input/lmsys-{TYPE}{VER}-{DATE}/fold_0/tokenizer\"\n    general_tokenizer = \"/kaggle/input/lmsys-base4-0704/fold_0/tokenizer\"\n\nclass CFG:\n    seed = 42\n    max_length = 512\n    lr = 5e-5  # 学习率\n    weight_decay = 0.01  # 权重衰减\n    warmup_ratio = 0 # 学习率预热比例\n    max_grad_norm = 1000  # 梯度裁剪最大范数\n    lr_scheduler_type = 'linear'  # 学习率调度类型\n    frozen_embedding = False # 冻结前面的层\n    frozen_num = 6\n    train_batch_size = 32  # 训练批量大小\n    eval_batch_size = 64  # 评估批量大小\n    evaluation_strategy = 'steps'  # 更改为 steps 评估策略\n    metric_for_best_model = \"eval_log_loss\"  # 用于选择最佳模型的度量标准\n    save_strategy = 'steps'  # 更改为 steps 保存策略\n    save_steps = 200  # 每 步保存一次模型\n    save_total_limit = 1  # 保存检查点总数限制\n    train_epochs = 5  # 训练周期数\n    num_labels = 6\n    output_dir = f'/kaggle/input/lmsys-{TYPE}{VER}-{DATE}'  # 输出目录\n    fp16 = True  # 使用混合精度训练\n    load_best_model_at_end = True  # 训练结束时加载最佳模型\n    report_to = 'none'  # 不报告训练日志到外部工具\n    optim = 'adamw_torch'  # 优化器类型\n    logging_first_step = True  # 记录第一步的日志\n    logging_steps = 200  # 每 步记录一次日志\n    logging_dir =f'logs_v{VER}'  # 日志保存目录\n    n_splits = 5\n    model_name = PATHS.model_name\n    greater_is_better = False\n    early_stop = False\n    early_stopping_patience = 3  # Number of evaluation calls with no improvement after which training will be stopped\n    early_stopping_threshold = 0.001  # Minimum change to qualify as an improvement\n\ndef seed_everything(seed):\n    import random\n    import os\n    import numpy as np\n    import torch\n    \n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=CFG.seed)\n\n# tokenizer = AutoTokenizer.from_pretrained(PATHS.tokenizer_path)\ntokenizer = AutoTokenizer.from_pretrained(PATHS.general_tokenizer)\nsep_token = tokenizer.sep_token_id\n\ndef log_parameters(logger):\n    \"\"\"Log all parameters from PATHS and CFG classes.\"\"\"\n    logger.info(\"=== Parameter Settings ===\")\n    \n    logger.info(\"PATHS:\")\n    for key, value in PATHS.__dict__.items():\n        if not key.startswith('__'):\n            logger.info(f\"  {key}: {value}\")\n    \n    logger.info(\"CFG:\")\n    for key, value in CFG.__dict__.items():\n        if not key.startswith('__'):\n            logger.info(f\"  {key}: {value}\")\n    \n    logger.info(\"=*100\")\n\ndef tokenize_function(row, tokenizer):\n    max_len = CFG.max_length - 2 # We need 2 separator tokens\n    tokens_prompt = tokenizer(row['prompt'], truncation=True, max_length=max_len//4, add_special_tokens=False)['input_ids']\n    remaining_length = max_len - len(tokens_prompt)\n    \n    tokens_response_a = tokenizer(row['response_a'], truncation=True, max_length=remaining_length//2, add_special_tokens=False)['input_ids']\n    remaining_length -= len(tokens_response_a)\n    tokens_response_b = tokenizer(row['response_b'], truncation=True, max_length=remaining_length, add_special_tokens=False)['input_ids']\n    \n    input_ids = [tokenizer.cls_token_id] + tokens_prompt + [sep_token] + tokens_response_a + [sep_token] + tokens_response_b\n    token_type_ids = [0] * (len(tokens_prompt) + 2) + [1] * (len(tokens_response_a) + 1) + [2] * len(tokens_response_b)\n    attention_mask = [1] * len(input_ids)\n    \n    padding_length = CFG.max_length - len(input_ids)\n    if padding_length > 0:\n        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n        token_type_ids = token_type_ids + [0] * padding_length\n        attention_mask = attention_mask + [0] * padding_length\n    \n    return {\n        'input_ids': input_ids[:CFG.max_length],\n        'token_type_ids': token_type_ids[:CFG.max_length],\n        'attention_mask': attention_mask[:CFG.max_length],\n    }\n\ndef add_label(df):\n    labels = np.zeros(len(df), dtype=np.int32)\n    labels[df['winner_model_a'] == 1] = 0\n    labels[df['winner_model_b'] == 1] = 1\n    labels[df['winner_tie'] == 1] = 2\n    df['labels'] = labels\n    return df\n\ndef process_data(df, mode='train'):\n    dataset = Dataset.from_pandas(df)\n    tokenized_dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=False)\n    remove_cols = ['id', 'prompt', 'response_a', 'response_b']\n    if mode == 'train':\n        remove_cols += ['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie']\n    tokenized_dataset = tokenized_dataset.remove_columns(remove_cols)\n    return tokenized_dataset\n\ndef split_train_val(dataset, train_fraction):\n    np.random.seed(0)\n    ixs = np.arange(len(dataset))\n    cutoff = int(len(ixs) * train_fraction)\n    np.random.shuffle(ixs)\n    ixs_train = ixs[:cutoff]\n    ixs_val = ixs[cutoff:]\n    fit_train = dataset.select(ixs_train)\n    fit_val = dataset.select(ixs_val)\n    return fit_train, fit_val\n\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n    return {\n        'eval_log_loss': log_loss(labels, probabilities),\n        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()\n    }\n    \ndef train_model():\n    log_parameters(logger)\n    train_df = pd.read_csv(PATHS.train_path)\n    train_df = add_label(train_df)\n    train_tokenized = process_data(train_df, mode='train')\n    \n    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n    \n    for fold, (train_idx, val_idx) in enumerate(skf.split(train_tokenized, train_tokenized['labels'])):\n        print(f\"Training fold {fold + 1}\")\n        logger.info(f\"Training fold {fold + 1}\")\n        \n        fit_train = train_tokenized.select(train_idx)\n        fit_val = train_tokenized.select(val_idx)\n        \n        model = AutoModelForSequenceClassification.from_pretrained(\n            PATHS.model_path,\n            num_labels=3,\n            problem_type=\"single_label_classification\"\n        )\n        \n        training_args = TrainingArguments(\n            output_dir=f\"{CFG.output_dir}/fold_{fold}\",  # 模型和检查点的输出目录\n            fp16=CFG.fp16,  # 使用混合精度训练\n            learning_rate=CFG.lr,  # 学习率\n            per_device_train_batch_size=CFG.train_batch_size,  # 每个设备上的训练批量大小\n            per_device_eval_batch_size=CFG.eval_batch_size,  # 每个设备上的评估批量大小\n            num_train_epochs=CFG.train_epochs,  # 训练的总周期数\n            weight_decay=CFG.weight_decay,  # 权重衰减（L2正则化）\n            evaluation_strategy=CFG.evaluation_strategy,  # 评估策略\n            metric_for_best_model=CFG.metric_for_best_model,  # 用于选择最佳模型的度量标准\n            save_strategy=CFG.save_strategy,  # 保存策略\n            save_total_limit=CFG.save_total_limit,  # 保存的检查点总数限制\n            load_best_model_at_end=CFG.load_best_model_at_end,  # 在训练结束时加载最佳模型\n            report_to=CFG.report_to,  # 不报告训练日志到外部工具\n            warmup_ratio=CFG.warmup_ratio,  # 学习率预热比例\n            lr_scheduler_type=CFG.lr_scheduler_type,  # 学习率调度类型\n            optim=CFG.optim,  # 使用的优化器类型\n            logging_first_step=CFG.logging_first_step,  # 记录第一步的日志\n            greater_is_better=CFG.greater_is_better,\n            \n            # max_grad_norm=CFG.max_grad_norm,  # 设置梯度裁剪\n            \n            logging_steps=CFG.logging_steps,  # 每 500 步记录一次日志\n            logging_dir=CFG.logging_dir,  # 日志保存目录\n        \n            save_steps=CFG.save_steps,  # 每  步保存一次模型\n            eval_steps=CFG.save_steps,  # 添加 eval_steps 参数,与 save_steps 保持一致\n        )\n\n         # Log training arguments\n        logger.info(\"Training arguments:\")\n        logger.info(pformat(training_args.to_dict()))\n\n        if CFG.frozen_embedding:\n            n = CFG.frozen_num\n            # 冻结嵌入层\n            for i, layer in enumerate(model.deberta.encoder.layer[:n]):\n                for param in layer.parameters():\n                    param.requires_grad = False # True False\n            for param in model.deberta.embeddings.parameters():\n                param.requires_grad = False\n\n        # 初始化 tokenizer\n        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n        # Create EarlyStoppingCallback\n        if CFG.early_stop:\n            early_stopping_callback = EarlyStoppingCallback(\n                early_stopping_patience=CFG.early_stopping_patience,\n                early_stopping_threshold=CFG.early_stopping_threshold,\n            )\n        \n            trainer = Trainer(\n                model=model,\n                args=training_args,\n                train_dataset=fit_train,\n                data_collator=data_collator,\n                eval_dataset=fit_val,\n                compute_metrics=compute_metrics,\n                callbacks=[early_stopping_callback],  # Add the early stopping callback\n            )\n        else:\n            trainer = Trainer(\n                model=model,\n                args=training_args,\n                train_dataset=fit_train,\n                data_collator=data_collator,\n                eval_dataset=fit_val,\n                compute_metrics=compute_metrics,\n            )\n        \n        trainer.train()\n        \n        # Save the model\n        trainer.save_model(f\"{CFG.output_dir}/fold_{fold}/best_model\")\n        tokenizer.save_pretrained(f\"{CFG.output_dir}/fold_{fold}/tokenizer\")\n        \n        # Log the results\n        eval_result = trainer.evaluate()\n        logger.info(f\"Fold {fold + 1} - Evaluation result: {eval_result}\")\n        logger.info(\"=*100\")\n\ndef predict_test():\n    test_df = pd.read_csv(PATHS.test_path)\n    test_tokenized = process_data(test_df, mode='test')\n    \n    predictions = []\n    \n    for fold in trange(CFG.n_splits):\n        model = AutoModelForSequenceClassification.from_pretrained(f\"{CFG.output_dir}/fold_{fold}/best_model\")\n        model.eval()\n        \n        trainer = Trainer(model=model)\n        fold_preds = trainer.predict(test_tokenized).predictions\n        fold_preds = np.exp(fold_preds) / np.sum(np.exp(fold_preds), axis=1, keepdims=True)\n        predictions.append(fold_preds)\n    \n    # Average predictions across folds\n    final_preds = np.mean(predictions, axis=0)\n    display(predictions)\n    logger.info(f\"Final_preds: {final_preds}\")\n    \n    # Create submission file\n    submission = pd.DataFrame({\n        'id': test_df['id'],\n        'winner_model_a': final_preds[:, 0],\n        'winner_model_b': final_preds[:, 1],\n        'winner_tie': final_preds[:, 2]\n    })\n    \n    submission.to_csv('submission.csv', index=False)\n    display(submission)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-06T16:45:31.260005Z","iopub.execute_input":"2024-07-06T16:45:31.260392Z","iopub.status.idle":"2024-07-06T16:45:31.582586Z","shell.execute_reply.started":"2024-07-06T16:45:31.26036Z","shell.execute_reply":"2024-07-06T16:45:31.581769Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\nif __name__ == \"__main__\":\n#     train_model()\n    predict_test()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T16:45:31.584158Z","iopub.execute_input":"2024-07-06T16:45:31.584644Z","iopub.status.idle":"2024-07-06T16:45:35.020468Z","shell.execute_reply.started":"2024-07-06T16:45:31.584608Z","shell.execute_reply":"2024-07-06T16:45:35.019751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tokenizers\n# print(tokenizers.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T14:28:38.541923Z","iopub.execute_input":"2024-07-04T14:28:38.542344Z","iopub.status.idle":"2024-07-04T14:28:38.547292Z","shell.execute_reply.started":"2024-07-04T14:28:38.542313Z","shell.execute_reply":"2024-07-04T14:28:38.546354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}