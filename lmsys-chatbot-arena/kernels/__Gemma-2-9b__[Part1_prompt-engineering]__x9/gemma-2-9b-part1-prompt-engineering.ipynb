{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:06.677065Z",
     "iopub.status.busy": "2024-07-15T06:48:06.676325Z",
     "iopub.status.idle": "2024-07-15T06:48:07.827666Z",
     "shell.execute_reply": "2024-07-15T06:48:07.826627Z",
     "shell.execute_reply.started": "2024-07-15T06:48:06.677019Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T07:59:57.252098Z",
     "iopub.status.busy": "2024-07-15T07:59:57.25174Z",
     "iopub.status.idle": "2024-07-15T07:59:57.256785Z",
     "shell.execute_reply": "2024-07-15T07:59:57.255788Z",
     "shell.execute_reply.started": "2024-07-15T07:59:57.25207Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:11.113603Z",
     "iopub.status.busy": "2024-07-15T06:48:11.11297Z",
     "iopub.status.idle": "2024-07-15T06:48:11.118344Z",
     "shell.execute_reply": "2024-07-15T06:48:11.117441Z",
     "shell.execute_reply.started": "2024-07-15T06:48:11.113569Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:48:01.813641Z",
     "iopub.status.busy": "2024-07-15T07:48:01.813261Z",
     "iopub.status.idle": "2024-07-15T07:48:01.822292Z",
     "shell.execute_reply": "2024-07-15T07:48:01.821373Z",
     "shell.execute_reply.started": "2024-07-15T07:48:01.813612Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    sentences = ' '.join(sentences)\n",
    "    return sentences\n",
    "\n",
    "def get_data(path, system_prompt=None):\n",
    "    df = pd.read_csv(path)\n",
    "    df['prompt'] = df['prompt'].apply(process_data)\n",
    "    df['response_a'] = df['response_a'].apply(process_data)\n",
    "    df['response_b'] = df['response_b'].apply(process_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:48:02.367062Z",
     "iopub.status.busy": "2024-07-15T07:48:02.366648Z",
     "iopub.status.idle": "2024-07-15T07:48:02.382044Z",
     "shell.execute_reply": "2024-07-15T07:48:02.381191Z",
     "shell.execute_reply.started": "2024-07-15T07:48:02.367032Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n",
    "test_df = get_data(test_path)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ca329",
   "metadata": {},
   "source": [
    "## Load Gemma-2-9B model\n",
    "> google/gemma-2-9b-it \n",
    "\n",
    "I have already downloaded and stored bfloat16 weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:14.572235Z",
     "iopub.status.busy": "2024-07-15T06:48:14.571879Z",
     "iopub.status.idle": "2024-07-15T06:48:15.465156Z",
     "shell.execute_reply": "2024-07-15T06:48:15.464383Z",
     "shell.execute_reply.started": "2024-07-15T06:48:14.572207Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:15.467426Z",
     "iopub.status.busy": "2024-07-15T06:48:15.466814Z",
     "iopub.status.idle": "2024-07-15T06:48:15.471513Z",
     "shell.execute_reply": "2024-07-15T06:48:15.470542Z",
     "shell.execute_reply.started": "2024-07-15T06:48:15.467393Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-tokenizer'\n",
    "model_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:15.517944Z",
     "iopub.status.busy": "2024-07-15T06:48:15.517688Z",
     "iopub.status.idle": "2024-07-15T06:48:16.445695Z",
     "shell.execute_reply": "2024-07-15T06:48:16.444823Z",
     "shell.execute_reply.started": "2024-07-15T06:48:15.517922Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:22.429128Z",
     "iopub.status.busy": "2024-07-15T06:48:22.428103Z",
     "iopub.status.idle": "2024-07-15T06:51:09.409078Z",
     "shell.execute_reply": "2024-07-15T06:51:09.40808Z",
     "shell.execute_reply.started": "2024-07-15T06:48:22.429097Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:51:09.411816Z",
     "iopub.status.busy": "2024-07-15T06:51:09.410924Z",
     "iopub.status.idle": "2024-07-15T06:51:09.421473Z",
     "shell.execute_reply": "2024-07-15T06:51:09.420593Z",
     "shell.execute_reply.started": "2024-07-15T06:51:09.41178Z"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa34207",
   "metadata": {},
   "source": [
    "## Let's do a simple inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:51:09.42281Z",
     "iopub.status.busy": "2024-07-15T06:51:09.422507Z",
     "iopub.status.idle": "2024-07-15T06:51:42.214722Z",
     "shell.execute_reply": "2024-07-15T06:51:42.213751Z",
     "shell.execute_reply.started": "2024-07-15T06:51:09.422785Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = 'Write a conversation between gemma and llama llm models'\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=200)\n",
    "response = tokenizer.decode(outputs[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2063b99",
   "metadata": {},
   "source": [
    "## Let's do inference on test set with some prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:09:50.637151Z",
     "iopub.status.busy": "2024-07-15T08:09:50.636469Z",
     "iopub.status.idle": "2024-07-15T08:09:50.646948Z",
     "shell.execute_reply": "2024-07-15T08:09:50.64597Z",
     "shell.execute_reply.started": "2024-07-15T08:09:50.637121Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:37:15.073395Z",
     "iopub.status.busy": "2024-07-15T07:37:15.072935Z",
     "iopub.status.idle": "2024-07-15T07:37:15.078959Z",
     "shell.execute_reply": "2024-07-15T07:37:15.078025Z",
     "shell.execute_reply.started": "2024-07-15T07:37:15.073366Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prompt(query, response_a, response_b):\n",
    "    prompt = f\"\"\"\n",
    "You are tasked with evaluating two responses generated by different models to determine which one is better. Given a query and two responses (RESPONSE_A from MODEL_A and RESPONSE_B from MODEL_B), you will assess the quality of each response based on relevance, accuracy, completeness, and overall coherence. If both responses are equally good or equally poor, you may declare a tie.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Query: {query}\n",
    "RESPONSE_A (MODEL_A): {response_a}\n",
    "RESPONSE_B (MODEL_B): {response_b}\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Relevance: How well does the response address the query?\n",
    "Accuracy: Is the information provided correct and reliable?\n",
    "Completeness: Does the response provide a comprehensive answer?\n",
    "Coherence: Is the response logically structured and easy to understand?\n",
    "Output:\n",
    "\n",
    "If RESPONSE_A is better, output: RESPONSE_A\n",
    "If RESPONSE_B is better, output: RESPONSE_B\n",
    "If both responses are equally good or poor, output: TIE\n",
    "\n",
    "You have to output a single line having either of these words - RESPONSE_A or RESPONSE_B or TIE \\n\n",
    "OUTPUT: \n",
    "\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:01:15.237464Z",
     "iopub.status.busy": "2024-07-15T08:01:15.236745Z",
     "iopub.status.idle": "2024-07-15T08:01:15.243954Z",
     "shell.execute_reply": "2024-07-15T08:01:15.243011Z",
     "shell.execute_reply.started": "2024-07-15T08:01:15.237431Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(query, response_a, response_b, max_new_tokens=50, do_sample=False, temperature=1.0):\n",
    "    prompt = get_prompt(query=query, response_a=response_a, response_b=response_b)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=do_sample, temperature=temperature)\n",
    "    response = tokenizer.decode(outputs[0])\n",
    "\n",
    "    pattern = r\"OUTPUT:\\s*(RESPONSE_A|RESPONSE_B|TIE)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        pred = match.group(1)\n",
    "    else:\n",
    "        pred = None\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:07:33.054676Z",
     "iopub.status.busy": "2024-07-15T08:07:33.054312Z",
     "iopub.status.idle": "2024-07-15T08:08:01.168403Z",
     "shell.execute_reply": "2024-07-15T08:08:01.167462Z",
     "shell.execute_reply.started": "2024-07-15T08:07:33.054648Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "id_list = []\n",
    "winner_model_a_list = []\n",
    "winner_model_b_list = []\n",
    "winner_tie_list = []\n",
    "for idx in tqdm(range(0, len(test_df))):\n",
    "    query_id = test_df.iloc[idx]['id']\n",
    "    query = test_df.iloc[idx]['prompt']\n",
    "    response_a = test_df.iloc[idx]['response_a']\n",
    "    response_b = test_df.iloc[idx]['response_b']\n",
    "    pred = predict(query, response_a, response_b, max_new_tokens=20, do_sample=True, temperature=0.7)\n",
    "    id_list.append(query_id)\n",
    "    if pred is not None:\n",
    "        if 'A' in pred or 'a' in pred:\n",
    "            winner_model_a_list.append(1)\n",
    "            winner_model_b_list.append(0)                    \n",
    "            winner_tie_list.append(0)\n",
    "        if 'B' in pred or 'b' in pred:\n",
    "            winner_model_a_list.append(0)\n",
    "            winner_model_b_list.append(1)        \n",
    "            winner_tie_list.append(0)            \n",
    "    else:\n",
    "        winner_model_a_list.append(0)\n",
    "        winner_model_b_list.append(0)        \n",
    "        winner_tie_list.append(1)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:08:32.901906Z",
     "iopub.status.busy": "2024-07-15T08:08:32.901214Z",
     "iopub.status.idle": "2024-07-15T08:08:32.906789Z",
     "shell.execute_reply": "2024-07-15T08:08:32.905883Z",
     "shell.execute_reply.started": "2024-07-15T08:08:32.901875Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'id': id_list, 'winner_model_a': winner_model_a_list, 'winner_model_b': winner_model_b_list, 'winner_tie': winner_tie_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:08:36.702362Z",
     "iopub.status.busy": "2024-07-15T08:08:36.701617Z",
     "iopub.status.idle": "2024-07-15T08:08:36.711417Z",
     "shell.execute_reply": "2024-07-15T08:08:36.71021Z",
     "shell.execute_reply.started": "2024-07-15T08:08:36.70233Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:10:31.19526Z",
     "iopub.status.busy": "2024-07-15T08:10:31.19451Z",
     "iopub.status.idle": "2024-07-15T08:10:31.202885Z",
     "shell.execute_reply": "2024-07-15T08:10:31.201907Z",
     "shell.execute_reply.started": "2024-07-15T08:10:31.195228Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5390170,
     "sourceId": 8956282,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
