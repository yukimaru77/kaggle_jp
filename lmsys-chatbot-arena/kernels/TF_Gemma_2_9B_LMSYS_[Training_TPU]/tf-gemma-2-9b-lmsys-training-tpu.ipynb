{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971467db",
   "metadata": {},
   "source": [
    "1 epoch takes ~3hrs \n",
    "\n",
    "Just save lora weights and load them in the following notebook for Inference on 2xT4s:\n",
    "\n",
    "Note: Training on bfloat16 causes model to overfit, so training should be on float32 and inference on float16\n",
    "\n",
    "\n",
    "https://www.kaggle.com/code/pranshubahadur/inference-tf-gemma-2-9b-lmsys\n",
    "\n",
    "Inspiration:\n",
    "\n",
    "https://www.kaggle.com/code/matthewdwatson/gemma-2-fine-tuning-and-inference\n",
    "\n",
    "https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb#scrollTo=_Peq7TnLtHse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:15.769561Z",
     "iopub.status.busy": "2024-07-27T04:04:15.768765Z",
     "iopub.status.idle": "2024-07-27T04:04:23.367166Z",
     "shell.execute_reply": "2024-07-27T04:04:23.366072Z",
     "shell.execute_reply.started": "2024-07-27T04:04:15.76953Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp tensorflow-text\n",
    "# Install tensorflow-cpu so tensorflow does not attempt to access the TPU.\n",
    "!pip install -q -U tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:23.369577Z",
     "iopub.status.busy": "2024-07-27T04:04:23.369172Z",
     "iopub.status.idle": "2024-07-27T04:04:26.510795Z",
     "shell.execute_reply": "2024-07-27T04:04:26.509939Z",
     "shell.execute_reply.started": "2024-07-27T04:04:23.369542Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:26.512189Z",
     "iopub.status.busy": "2024-07-27T04:04:26.511813Z",
     "iopub.status.idle": "2024-07-27T04:04:26.516278Z",
     "shell.execute_reply": "2024-07-27T04:04:26.51551Z",
     "shell.execute_reply.started": "2024-07-27T04:04:26.51214Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Pre-allocate all TPU memory to minimize memory fragmentation and allocation overhead.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:26.517527Z",
     "iopub.status.busy": "2024-07-27T04:04:26.517204Z",
     "iopub.status.idle": "2024-07-27T04:04:29.404347Z",
     "shell.execute_reply": "2024-07-27T04:04:29.403479Z",
     "shell.execute_reply.started": "2024-07-27T04:04:26.517495Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:29.40678Z",
     "iopub.status.busy": "2024-07-27T04:04:29.406293Z",
     "iopub.status.idle": "2024-07-27T04:04:29.411026Z",
     "shell.execute_reply": "2024-07-27T04:04:29.410235Z",
     "shell.execute_reply.started": "2024-07-27T04:04:29.40674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a device mesh with (1, 8) shape so that the weights are sharded across\n",
    "# all 8 TPUs.\n",
    "device_mesh = keras.distribution.DeviceMesh(\n",
    "    (1, 8),\n",
    "    [\"batch\", \"model\"],\n",
    "    devices=keras.distribution.list_devices(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:29.412201Z",
     "iopub.status.busy": "2024-07-27T04:04:29.411945Z",
     "iopub.status.idle": "2024-07-27T04:04:29.429592Z",
     "shell.execute_reply": "2024-07-27T04:04:29.428903Z",
     "shell.execute_reply.started": "2024-07-27T04:04:29.412174Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dim = \"model\"\n",
    "\n",
    "layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "\n",
    "# Weights that match 'token_embedding/embeddings' will be sharded on 8 TPUs\n",
    "layout_map[\"token_embedding/embeddings\"] = (model_dim, None)\n",
    "# Regex to match against the query, key and value matrices in attention layers\n",
    "layout_map[\"decoder_block.*attention.*(query|key|value)/kernel\"] = (model_dim, None, None)\n",
    "layout_map[\"decoder_block.*attention_output/kernel\"] = (model_dim, None, None)\n",
    "layout_map[\"decoder_block.*ffw_gating.*/kernel\"] = (None, model_dim)\n",
    "layout_map[\"decoder_block.*ffw_linear/kernel\"] = (model_dim, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:29.430592Z",
     "iopub.status.busy": "2024-07-27T04:04:29.430349Z",
     "iopub.status.idle": "2024-07-27T04:04:29.440359Z",
     "shell.execute_reply": "2024-07-27T04:04:29.439674Z",
     "shell.execute_reply.started": "2024-07-27T04:04:29.430567Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_surrogates(text):\n",
    "    return ''.join(char for char in text if not (0xD800 <= ord(char) <= 0xDFFF))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:29.441429Z",
     "iopub.status.busy": "2024-07-27T04:04:29.441191Z",
     "iopub.status.idle": "2024-07-27T04:04:52.03838Z",
     "shell.execute_reply": "2024-07-27T04:04:52.037521Z",
     "shell.execute_reply.started": "2024-07-27T04:04:29.441403Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "input_columns = ['prompt', 'response_a', 'response_b']\n",
    "label_columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "raw_train_dataset = read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "#raw_train_dataset[input_columns] = raw_train_dataset[input_columns].map(lambda x: eval(x)[0])\n",
    "\n",
    "raw_train_dataset = raw_train_dataset.dropna().drop(['model_a', 'model_b'], axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataset = DataFrame({\n",
    "    'text' : raw_train_dataset[input_columns].agg('\\n\\nRESPONSE:\\n\\n'.join, axis=1).apply(lambda x: '\\n\\nPROMPT\\n\\n' + x).apply(lambda x: remove_surrogates(x)),\n",
    "    'label' : raw_train_dataset[label_columns].apply(lambda x: x.values.tolist(), axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:52.039529Z",
     "iopub.status.busy": "2024-07-27T04:04:52.039292Z",
     "iopub.status.idle": "2024-07-27T04:04:52.043277Z",
     "shell.execute_reply": "2024-07-27T04:04:52.042543Z",
     "shell.execute_reply.started": "2024-07-27T04:04:52.039505Z"
    }
   },
   "outputs": [],
   "source": [
    "model_parallel = keras.distribution.ModelParallel(\n",
    "    layout_map=layout_map,\n",
    "    batch_dim_name=\"batch\",\n",
    ")\n",
    "\n",
    "keras.distribution.set_distribution(model_parallel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.config.set_floatx(\"bfloat16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:04:52.044474Z",
     "iopub.status.busy": "2024-07-27T04:04:52.044206Z",
     "iopub.status.idle": "2024-07-27T04:07:17.610825Z",
     "shell.execute_reply": "2024-07-27T04:07:17.610039Z",
     "shell.execute_reply.started": "2024-07-27T04:04:52.044447Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma2/keras/gemma2_instruct_9b_en/1\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:17.612026Z",
     "iopub.status.busy": "2024-07-27T04:07:17.611775Z",
     "iopub.status.idle": "2024-07-27T04:07:18.398538Z",
     "shell.execute_reply": "2024-07-27T04:07:18.397688Z",
     "shell.execute_reply.started": "2024-07-27T04:07:17.612001Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.backbone.enable_lora(rank=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.399766Z",
     "iopub.status.busy": "2024-07-27T04:07:18.399506Z",
     "iopub.status.idle": "2024-07-27T04:07:18.404759Z",
     "shell.execute_reply": "2024-07-27T04:07:18.404095Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.39974Z"
    }
   },
   "outputs": [],
   "source": [
    "for layer in gemma_lm._backbone.layers[:16]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.405872Z",
     "iopub.status.busy": "2024-07-27T04:07:18.405572Z",
     "iopub.status.idle": "2024-07-27T04:07:18.438794Z",
     "shell.execute_reply": "2024-07-27T04:07:18.438138Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.405844Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.441284Z",
     "iopub.status.busy": "2024-07-27T04:07:18.441038Z",
     "iopub.status.idle": "2024-07-27T04:07:18.445386Z",
     "shell.execute_reply": "2024-07-27T04:07:18.444669Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.44126Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    preprocessed = gemma_lm._preprocessor(text, sequence_length=1024)[0]\n",
    "    # Ensure the preprocess function returns only the necessary inputs\n",
    "    return {'token_ids' : preprocessed['token_ids'], 'padding_mask' : preprocessed['padding_mask']}, label if label is not None else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.446656Z",
     "iopub.status.busy": "2024-07-27T04:07:18.446319Z",
     "iopub.status.idle": "2024-07-27T04:07:18.747228Z",
     "shell.execute_reply": "2024-07-27T04:07:18.746211Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.446614Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling1D\n",
    "from keras import Model\n",
    "\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "x = gemma_lm.backbone(inputs)\n",
    "print(x.shape)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "print(x.shape)\n",
    "\n",
    "outputs = Dense(3, 'softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.748578Z",
     "iopub.status.busy": "2024-07-27T04:07:18.748242Z",
     "iopub.status.idle": "2024-07-27T04:07:18.754139Z",
     "shell.execute_reply": "2024-07-27T04:07:18.753415Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.74855Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.AdamW(\n",
    "                learning_rate=5e-5,\n",
    "                weight_decay=0.01,)\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.75531Z",
     "iopub.status.busy": "2024-07-27T04:07:18.755045Z",
     "iopub.status.idle": "2024-07-27T04:07:18.768823Z",
     "shell.execute_reply": "2024-07-27T04:07:18.768097Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.755284Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:18.76989Z",
     "iopub.status.busy": "2024-07-27T04:07:18.769643Z",
     "iopub.status.idle": "2024-07-27T04:07:19.247006Z",
     "shell.execute_reply": "2024-07-27T04:07:19.246007Z",
     "shell.execute_reply.started": "2024-07-27T04:07:18.769864Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_dataset.text.values, raw_train_dataset[label_columns].values)).batch(4).map(preprocess_fn)\n",
    "ds = ds.shuffle(ds.cardinality())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T04:07:19.248245Z",
     "iopub.status.busy": "2024-07-27T04:07:19.248003Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split = ds.take(int(len(ds)*0.9))\n",
    "val_split = ds.skip(int(len(ds)*0.9)).take(int(len(ds)*0.1))\n",
    "histories = model.fit(train_split, validation_data=[val_split], epochs=1, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "layer = model.get_layer(name='dense')\n",
    "weights = layer.get_weights()\n",
    "kernel, bias = weights\n",
    "\n",
    "# Save the kernel and bias separately\n",
    "np.save('dense_1_kernel.npy', kernel)\n",
    "np.save('dense_1_bias.npy', bias)\n",
    "model.layers[2].save_lora_weights(\"model.lora.h5\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 57466,
     "sourceId": 69834,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
