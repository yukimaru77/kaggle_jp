{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982c8ecc",
   "metadata": {},
   "source": [
    "# LMSYS | XGB Baseline\n",
    "\n",
    "# 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-06T22:53:47.250349Z",
     "iopub.status.busy": "2024-07-06T22:53:47.249376Z",
     "iopub.status.idle": "2024-07-06T22:53:47.259892Z",
     "shell.execute_reply": "2024-07-06T22:53:47.258305Z",
     "shell.execute_reply.started": "2024-07-06T22:53:47.250304Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f8c7ad",
   "metadata": {},
   "source": [
    "# 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:53:47.266784Z",
     "iopub.status.busy": "2024-07-06T22:53:47.265928Z",
     "iopub.status.idle": "2024-07-06T22:53:47.281569Z",
     "shell.execute_reply": "2024-07-06T22:53:47.280051Z",
     "shell.execute_reply.started": "2024-07-06T22:53:47.26674Z"
    }
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    root = \"/kaggle/input/lmsys-chatbot-arena/\"\n",
    "    train_path = os.path.join(root, \"train.csv\")\n",
    "    test_path = os.path.join(root, \"test.csv\")\n",
    "    sample_submission_path = os.path.join(root, \"sample_submission.csv\")\n",
    "    seed = 42\n",
    "    n_splits = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d43931",
   "metadata": {},
   "source": [
    "# 3. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:53:47.294082Z",
     "iopub.status.busy": "2024-07-06T22:53:47.293054Z",
     "iopub.status.idle": "2024-07-06T22:53:49.593844Z",
     "shell.execute_reply": "2024-07-06T22:53:49.592669Z",
     "shell.execute_reply.started": "2024-07-06T22:53:47.294044Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(config.train_path)\n",
    "test = pd.read_csv(config.test_path)\n",
    "sample_submission = pd.read_csv(config.sample_submission_path)\n",
    "\n",
    "if test.shape[0] < 10:\n",
    "    train = train.iloc[:10000]\n",
    "    \n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "train[\"prompt\"] = train[\"prompt\"].apply(process)\n",
    "train[\"response_a\"] = train[\"response_a\"].apply(process)\n",
    "train[\"response_b\"] = train[\"response_b\"].apply(process)\n",
    "\n",
    "test[\"prompt\"] = test[\"prompt\"].apply(process)\n",
    "test[\"response_a\"] = test[\"response_a\"].apply(process)\n",
    "test[\"response_b\"] = test[\"response_b\"].apply(process)\n",
    "\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(\"-\"*90)\n",
    "print(f\"train missing values: {train.isnull().sum().sum()}\")\n",
    "print(f\"test missing values: {test.isnull().sum().sum()}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb02024f",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:53:49.597014Z",
     "iopub.status.busy": "2024-07-06T22:53:49.596633Z",
     "iopub.status.idle": "2024-07-06T22:53:49.62899Z",
     "shell.execute_reply": "2024-07-06T22:53:49.627576Z",
     "shell.execute_reply.started": "2024-07-06T22:53:49.596974Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "\n",
    "    def cosine_sim(self, text1: str, text2: str):\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "            vectorizer.fit([text1, text2])\n",
    "            output = vectorizer.transform([text1, text2]).toarray()\n",
    "            cos_sim = cosine_similarity(output)\n",
    "            return cos_sim[0][1]\n",
    "        except:\n",
    "            return np.nan\n",
    "\n",
    "    def jaccard_sim(self, text1: str, text2: str):\n",
    "        set1 = set(text1.split())\n",
    "        set2 = set(text2.split())\n",
    "        intersection = set1.intersection(set2)\n",
    "        union = set1.union(set2)\n",
    "        return len(intersection) / len(union)\n",
    "    \n",
    "    def count_new_lines(self, text: str) -> int:\n",
    "        return text.count('\\\\n') \n",
    "    \n",
    "    def count_quotes(self, text: str) -> int:\n",
    "        single_quote_pattern = r\"'(.*?)'\"\n",
    "        double_quote_pattern = r'\"(.*?)\"'\n",
    "        single_quotes = re.findall(single_quote_pattern, text)\n",
    "        double_quotes = re.findall(double_quote_pattern, text)\n",
    "        total_quotes = len(single_quotes) + len(double_quotes)\n",
    "        return len(single_quotes) + len(double_quotes)\n",
    "\n",
    "    def tokenize(self, text: str):\n",
    "        return nltk.word_tokenize(text.lower())\n",
    "\n",
    "    def generate_ngrams(self, text: str, n: int):\n",
    "        tokens = self.tokenize(text)\n",
    "        return list(ngrams(tokens, n))\n",
    "\n",
    "    def count_ngram_overlaps(self, text1: str, text2: str, n: int) -> int:\n",
    "        try:\n",
    "            ngrams1 = self.generate_ngrams(text1, n)\n",
    "            ngrams2 = self.generate_ngrams(text2, n)\n",
    "            counter1 = Counter(ngrams1)\n",
    "            counter2 = Counter(ngrams2)\n",
    "            overlap = counter1 & counter2\n",
    "            overlap_count = sum(overlap.values())\n",
    "            return overlap_count\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        data[\"respa_respb_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 1), axis=1)\n",
    "        data[\"respa_respb_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 2), axis=1)\n",
    "        data[\"respa_respb_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 3), axis=1)\n",
    "\n",
    "        data[\"respa_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respa_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respa_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 3), axis=1)\n",
    "\n",
    "        data[\"respb_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respb_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respb_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 3), axis=1)\n",
    "        \n",
    "        data[\"respa_len\"] = data[\"response_a\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        data[\"respb_len\"] = data[\"response_b\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        data[\"prompt_len\"] = data[\"prompt\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        \n",
    "        data[\"respa_new_lines\"] = data[\"response_a\"].apply(lambda x: self.count_new_lines(x))\n",
    "        data[\"respb_new_lines\"] = data[\"response_b\"].apply(lambda x: self.count_new_lines(x))\n",
    "        data[\"prompt_new_lines\"] = data[\"prompt\"].apply(lambda x: self.count_new_lines(x))\n",
    "        \n",
    "        data[\"respa_prompt_len_ratio\"] = data[\"respa_len\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_len_ratio\"] = data[\"respb_len\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_respb_len_ratio\"] = data[\"respa_len\"] / data[\"respb_len\"]\n",
    "        \n",
    "        data[\"respa_respb_len_diff\"] = data[\"respa_len\"] - data[\"respb_len\"]\n",
    "        data[\"respa_prompt_len_diff\"] = data[\"respa_len\"] - data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_len_diff\"] = data[\"respb_len\"] - data[\"prompt_len\"]\n",
    "        \n",
    "        data[\"respa_prompt_overlap_unigram_len_ratio\"] = data[\"respa_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_prompt_overlap_bigram_len_ratio\"] = data[\"respa_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_prompt_overlap_trigram_len_ratio\"] = data[\"respa_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
    "\n",
    "        data[\"respb_prompt_overlap_unigram_len_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_overlap_bigram_len_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_overlap_trigram_len_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
    "        \n",
    "        data[\"overlap_unigram_diff\"] = data[\"respa_prompt_overlap_unigram\"] - data[\"respb_prompt_overlap_unigram\"]\n",
    "        data[\"overlap_bigram_diff\"] = data[\"respa_prompt_overlap_bigram\"] - data[\"respb_prompt_overlap_bigram\"]\n",
    "        data[\"overlap_trigram_diff\"] = data[\"respa_prompt_overlap_trigram\"] - data[\"respb_prompt_overlap_trigram\"]\n",
    "        \n",
    "        data[\"overlap_unigram_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"respa_prompt_overlap_unigram\"] \n",
    "        data[\"overlap_bigram_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"respa_prompt_overlap_bigram\"] \n",
    "        data[\"overlap_trigram_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"respa_prompt_overlap_trigram\"] \n",
    "        \n",
    "        data[\"respa_quotes\"] = data[\"response_a\"].apply(lambda x: self.count_quotes(x))\n",
    "        data[\"respb_quotes\"] = data[\"response_b\"].apply(lambda x: self.count_quotes(x))\n",
    "        data[\"prompt_quotes\"] = data[\"prompt\"].apply(lambda x: self.count_quotes(x))\n",
    "        \n",
    "        data[\"respa_respb_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)\n",
    "        data[\"respa_respb_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)\n",
    "        \n",
    "        data[\"respa_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)\n",
    "        data[\"respa_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)\n",
    "        \n",
    "        data[\"respb_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)\n",
    "        data[\"respb_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)\n",
    "        \n",
    "        data[\"jaccard_sim_diff\"] = data[\"respa_prompt_jaccard_sim\"] - data[\"respb_prompt_jaccard_sim\"]\n",
    "        data[\"jaccard_sim_ratio\"] = data[\"respb_prompt_jaccard_sim\"] / data[\"respa_prompt_jaccard_sim\"]\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T22:53:49.631559Z",
     "iopub.status.busy": "2024-07-06T22:53:49.631147Z",
     "iopub.status.idle": "2024-07-06T23:04:32.599122Z",
     "shell.execute_reply": "2024-07-06T23:04:32.597677Z",
     "shell.execute_reply.started": "2024-07-06T22:53:49.631529Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preprocessor = Preprocessor()\n",
    "train = preprocessor.run(train)\n",
    "test = preprocessor.run(test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T23:08:34.442062Z",
     "iopub.status.busy": "2024-07-06T23:08:34.441571Z",
     "iopub.status.idle": "2024-07-06T23:08:34.488055Z",
     "shell.execute_reply": "2024-07-06T23:08:34.486837Z",
     "shell.execute_reply.started": "2024-07-06T23:08:34.44202Z"
    }
   },
   "outputs": [],
   "source": [
    "drop_cols = [\"id\", \"response_a\", \"response_b\", \"prompt\"]\n",
    "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "target = \"target\"\n",
    "\n",
    "train[target] = np.nan\n",
    "for idx, t in enumerate(target_cols):\n",
    "    train.loc[train[t] == 1, target] = idx\n",
    "train[target] = train[target].astype(\"int32\")\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e1ecc",
   "metadata": {},
   "source": [
    "# 5. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T23:08:34.490712Z",
     "iopub.status.busy": "2024-07-06T23:08:34.490159Z",
     "iopub.status.idle": "2024-07-06T23:08:38.142354Z",
     "shell.execute_reply": "2024-07-06T23:08:38.140954Z",
     "shell.execute_reply.started": "2024-07-06T23:08:34.490671Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train.drop(columns=target_cols+drop_cols+[target]+[\"model_a\", \"model_b\"], axis=1)\n",
    "y = train[target]\n",
    "X_test = test.drop(columns=drop_cols, axis=1)\n",
    "\n",
    "X = X.replace([-np.inf, np.inf], np.nan)\n",
    "X_test = X_test.replace([-np.inf, np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T23:08:38.143948Z",
     "iopub.status.busy": "2024-07-06T23:08:38.143572Z"
    }
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)\n",
    "test_preds = np.zeros(shape=(X_test.shape[0], y.nunique()))\n",
    "cv_scores = list()\n",
    "\n",
    "features = X.columns.tolist()\n",
    "feat_imp_df = pd.DataFrame({\"feature\": features})\n",
    "\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"| Fold {idx+1} |\".center(90, \"=\"))\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n",
    "\n",
    "    print(f'train: {X_train.shape}')\n",
    "    print(f'val: {X_val.shape}')\n",
    "    \n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        eval_metric='mlogloss',\n",
    "        subsample=0.8,\n",
    "        n_estimators=650,\n",
    "        learning_rate=0.045,\n",
    "        max_depth=5,\n",
    "        random_state=config.seed\n",
    "    )\n",
    "    \n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        early_stopping_rounds=75,\n",
    "        verbose=75\n",
    "    )\n",
    "    \n",
    "    val_preds = model.predict_proba(X_val)\n",
    "    val_log_loss = log_loss(y_val, val_preds, eps=\"auto\")\n",
    "    print(f\"val log loss: {val_log_loss:.5f}\")\n",
    "    cv_scores.append(val_log_loss)\n",
    "    \n",
    "    test_preds += model.predict_proba(X_test) / cv.get_n_splits()\n",
    "    \n",
    "    feat_imp_df = feat_imp_df.merge(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": features,\n",
    "                f\"fold_{idx+1}_feat_imp\": model.feature_importances_,\n",
    "            }\n",
    "        ),\n",
    "        on=[\"feature\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "print(\"=\"*90)\n",
    "print(f\"CV: {np.mean(cv_scores):.5f}\")\n",
    "\n",
    "feat_imp_df[\"avg_importance\"] = feat_imp_df.iloc[:, 1:].mean(axis=1)\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(\n",
    "    data=feat_imp_df.sort_values(by=\"avg_importance\", ascending=False).iloc[\n",
    "        :50\n",
    "    ],\n",
    "    x=\"avg_importance\",\n",
    "    y=\"feature\",\n",
    "    color=\"royalblue\",\n",
    "    width=0.75,\n",
    ")\n",
    "plt.title(\"Average Feature Importances of All Folds\", size=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73592411",
   "metadata": {},
   "source": [
    "# 6. Saving Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, t in enumerate(target_cols):\n",
    "    sample_submission[t] = test_preds[:, idx]\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
