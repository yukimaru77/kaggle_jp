{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8811121,"sourceType":"datasetVersion","datasetId":5299906},{"sourceId":8984506,"sourceType":"datasetVersion","datasetId":5410481},{"sourceId":8998271,"sourceType":"datasetVersion","datasetId":5419932},{"sourceId":148861315,"sourceType":"kernelVersion"},{"sourceId":186671053,"sourceType":"kernelVersion"}],"dockerImageVersionId":30746,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U bitsandbytes --no-index --find-links ../input/libs-install\n!pip install -q -U transformers --no-index --find-links ../input/libs-install","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:55:50.628382Z","iopub.execute_input":"2024-07-20T15:55:50.628675Z","iopub.status.idle":"2024-07-20T15:56:17.87735Z","shell.execute_reply.started":"2024-07-20T15:55:50.628646Z","shell.execute_reply":"2024-07-20T15:56:17.876038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nfrom time import time\n\nimport torch\nimport transformers\nimport sklearn\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom transformers import Gemma2ForCausalLM, GemmaTokenizer, BitsAndBytesConfig\n\nimport time\nfrom catboost import CatBoostClassifier, Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, log_loss\n\nfrom torch.cuda.amp import autocast\nfrom threading import Thread\n\ntorch.backends.cuda.enable_mem_efficient_sdp(False)\ntorch.backends.cuda.enable_flash_sdp(False)\n\nif (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:56:27.053454Z","iopub.execute_input":"2024-07-20T15:56:27.053843Z","iopub.status.idle":"2024-07-20T15:56:30.488833Z","shell.execute_reply.started":"2024-07-20T15:56:27.053806Z","shell.execute_reply":"2024-07-20T15:56:30.487809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/embedding/train_embed.csv')\ntrain_embed = np.load('/kaggle/input/embedding/gemma2_train_embed.npy')\n\ntrain_df.loc[:, 'label'] = np.argmax(train_df[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:56:38.209404Z","iopub.execute_input":"2024-07-20T15:56:38.21034Z","iopub.status.idle":"2024-07-20T15:56:45.353822Z","shell.execute_reply.started":"2024-07-20T15:56:38.210303Z","shell.execute_reply":"2024-07-20T15:56:45.352979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splits\nTargets = ['winner_model_a','winner_model_b','winner_tie']\n\ny = train_df['label'].values\ntrain_idx, test_idx = train_test_split(train_df.index, test_size=0.1, random_state=42, stratify=y)\n\nX_train, y_train = train_embed[train_idx], train_df.iloc[train_idx]['label'].values\nX_test, y_test = train_embed[test_idx], train_df.iloc[test_idx]['label'].values\n\nprint(X_train.shape, y_train.shape)\nprint(X_test.shape, y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T16:04:14.67469Z","iopub.execute_input":"2024-07-20T16:04:14.675515Z","iopub.status.idle":"2024-07-20T16:04:14.825208Z","shell.execute_reply.started":"2024-07-20T16:04:14.675478Z","shell.execute_reply":"2024-07-20T16:04:14.824135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cb = CatBoostClassifier()\nmodel_cb.load_model('/kaggle/input/catboost-mike/catboost.cbm')","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:56:48.004578Z","iopub.execute_input":"2024-07-20T15:56:48.004951Z","iopub.status.idle":"2024-07-20T15:56:48.03876Z","shell.execute_reply.started":"2024-07-20T15:56:48.004921Z","shell.execute_reply":"2024-07-20T15:56:48.037854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_cb","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:56:49.886015Z","iopub.execute_input":"2024-07-20T15:56:49.887004Z","iopub.status.idle":"2024-07-20T15:56:49.893266Z","shell.execute_reply.started":"2024-07-20T15:56:49.886956Z","shell.execute_reply":"2024-07-20T15:56:49.892301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_PATH = '/kaggle/input/gemma-2-9b-hf'\nMAX_LENGTH = 1024\nBATCH_SIZE = 2\n    \ndevice0 = torch.device('cuda:0')\ndevice1 = torch.device('cuda:1')\n\ntokenizer = GemmaTokenizer.from_pretrained(MODEL_PATH)\n\nbnb_config_4bit = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=False)\n\nmodel_0 = Gemma2ForCausalLM.from_pretrained(MODEL_PATH,\n                                        revision=\"float16\",\n                                        device_map='cuda:0',\n                                        quantization_config=bnb_config_4bit)        \n\nmodel_1 = Gemma2ForCausalLM.from_pretrained(MODEL_PATH,\n                                        revision=\"float16\",\n                                        device_map='cuda:1',\n                                        quantization_config=bnb_config_4bit)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:56:51.256391Z","iopub.execute_input":"2024-07-20T15:56:51.256772Z","iopub.status.idle":"2024-07-20T15:57:42.262798Z","shell.execute_reply.started":"2024-07-20T15:56:51.256742Z","shell.execute_reply":"2024-07-20T15:57:42.261799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process(input_str):\n    stripped_str = input_str.strip('[]')\n    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n    return sentences[-1] if sentences else ''\n  \ntest = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n\ntest.loc[:, 'prompt'] = test['prompt'].apply(process)\ntest.loc[:, 'response_a'] = test['response_a'].apply(process)\ntest.loc[:, 'response_b'] = test['response_b'].apply(process)\n\ntest['text'] = '<start_of_turn>User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n----\\n\\nModel B:\\n'  + test['response_b'] + '<end_of_turn><eos>'\nprint(test['text'][0])","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:58:36.584451Z","iopub.execute_input":"2024-07-20T15:58:36.584863Z","iopub.status.idle":"2024-07-20T15:58:36.601027Z","shell.execute_reply.started":"2024-07-20T15:58:36.584831Z","shell.execute_reply":"2024-07-20T15:58:36.599962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokens = tokenizer(test['text'].tolist(),\n                   padding='max_length',\n                   max_length=MAX_LENGTH,\n                   truncation=True,\n                   return_tensors='pt')\n\n\ndata = pd.DataFrame()\ndata['INPUT_IDS'] = [tensor.tolist() for tensor in tokens['input_ids']]\ndata['ATTENTION_MASKS'] = [tensor.tolist() for tensor in  tokens['attention_mask']]\ndata[:2]","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:58:39.90304Z","iopub.execute_input":"2024-07-20T15:58:39.903906Z","iopub.status.idle":"2024-07-20T15:58:39.948433Z","shell.execute_reply.started":"2024-07-20T15:58:39.903875Z","shell.execute_reply":"2024-07-20T15:58:39.947544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df, model, device, batch_size=BATCH_SIZE):  \n    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n\n    embed_list = []\n\n    for start_idx in range(0, len(df), batch_size):\n        end_idx = min(start_idx + batch_size, len(df))\n        batch_input_ids = input_ids[start_idx:end_idx].to(device)\n        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)\n        gc.collect()\n        torch.cuda.empty_cache()\n        with torch.no_grad():\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, output_hidden_states=True)\n            embed = outputs.hidden_states[-1]\n            embed_mean = torch.mean(embed, dim=1).cpu() #mean pool\n            embed_list.append(embed_mean) \n            \n            torch.cuda.empty_cache()\n        \n    embeddings = torch.cat(embed_list, dim=0)\n    return embeddings\n\ndef compute_embed(df, model, device, results, index):\n    results[index] = get_embeddings(df, model, device)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:58:42.254534Z","iopub.execute_input":"2024-07-20T15:58:42.255269Z","iopub.status.idle":"2024-07-20T15:58:42.264111Z","shell.execute_reply.started":"2024-07-20T15:58:42.255234Z","shell.execute_reply":"2024-07-20T15:58:42.263201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"st = time.time()\n\nN_SAMPLES = len(data)\nhalf = round(N_SAMPLES / 2)\nsub1 = data.iloc[0:half].copy()\nsub2 = data.iloc[half:N_SAMPLES].copy()\n\nresults = {}\n\nt0 = Thread(target=compute_embed, args=(sub1, model_0, device0, results, 0))\nt1 = Thread(target=compute_embed, args=(sub2, model_1, device1, results, 1))\n\nt0.start()\nt1.start()\n\nt0.join()\nt1.join()\n\nprint(f\"Processing complete. Total time: {time.time() - st:.2f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:58:45.72315Z","iopub.execute_input":"2024-07-20T15:58:45.72353Z","iopub.status.idle":"2024-07-20T15:59:00.986464Z","shell.execute_reply.started":"2024-07-20T15:58:45.723499Z","shell.execute_reply":"2024-07-20T15:59:00.985477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_embeddings = torch.cat([results[0], results[1]], dim=0)\ntest_embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:59:28.51497Z","iopub.execute_input":"2024-07-20T15:59:28.51597Z","iopub.status.idle":"2024-07-20T15:59:28.522786Z","shell.execute_reply.started":"2024-07-20T15:59:28.515935Z","shell.execute_reply":"2024-07-20T15:59:28.521713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()\ndel model_1\ndel  model_0\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model_cb.predict_proba(test_embeddings.numpy())\npreds","metadata":{"execution":{"iopub.status.busy":"2024-07-20T15:59:34.530054Z","iopub.execute_input":"2024-07-20T15:59:34.530916Z","iopub.status.idle":"2024-07-20T15:59:34.642592Z","shell.execute_reply.started":"2024-07-20T15:59:34.530884Z","shell.execute_reply":"2024-07-20T15:59:34.641713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\nsample_sub[Targets] =  preds\n\ndisplay(sample_sub)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T16:04:20.252401Z","iopub.execute_input":"2024-07-20T16:04:20.252748Z","iopub.status.idle":"2024-07-20T16:04:20.269829Z","shell.execute_reply.started":"2024-07-20T16:04:20.252723Z","shell.execute_reply":"2024-07-20T16:04:20.268956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-20T16:04:21.65216Z","iopub.execute_input":"2024-07-20T16:04:21.652541Z","iopub.status.idle":"2024-07-20T16:04:21.662648Z","shell.execute_reply.started":"2024-07-20T16:04:21.652511Z","shell.execute_reply":"2024-07-20T16:04:21.661766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}