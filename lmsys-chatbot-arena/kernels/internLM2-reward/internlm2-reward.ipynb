{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8290453,"sourceType":"datasetVersion","datasetId":4924785},{"sourceId":8897601,"sourceType":"datasetVersion","datasetId":5297895},{"sourceId":188190593,"sourceType":"kernelVersion"},{"sourceId":82087,"sourceType":"modelInstanceVersion","modelInstanceId":68973,"modelId":94105},{"sourceId":82656,"sourceType":"modelInstanceVersion","modelInstanceId":69432,"modelId":94570},{"sourceId":84069,"sourceType":"modelInstanceVersion","modelInstanceId":70610,"modelId":95660},{"sourceId":84495,"sourceType":"modelInstanceVersion","modelInstanceId":70978,"modelId":95971}],"dockerImageVersionId":30747,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U transformers peft bitsandbytes accelerate --no-index --find-links /kaggle/input/lmsys-wheel-files\n!pip install -q -U einops --no-index --find-links /kaggle/input/einops-v0-8-0","metadata":{"execution":{"iopub.status.busy":"2024-07-29T11:45:59.106818Z","iopub.execute_input":"2024-07-29T11:45:59.107778Z","iopub.status.idle":"2024-07-29T11:46:23.200683Z","shell.execute_reply.started":"2024-07-29T11:45:59.107744Z","shell.execute_reply":"2024-07-29T11:46:23.199339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModel, AutoTokenizer\nfrom transformers import BitsAndBytesConfig\n","metadata":{"execution":{"iopub.status.busy":"2024-07-29T11:47:26.243449Z","iopub.execute_input":"2024-07-29T11:47:26.243859Z","iopub.status.idle":"2024-07-29T11:47:26.254891Z","shell.execute_reply.started":"2024-07-29T11:47:26.243824Z","shell.execute_reply":"2024-07-29T11:47:26.254079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel_path = \"/kaggle/input/internlm2-1.8b-reward/transformers/default/1/internlm_internlm2-1_8b-reward\"\nmodel_path = \"/kaggle/input/internlm-2-7b/transformers/default/1/internlm_internlm2-7b-reward\"\nmodel_path = \"/kaggle/input/iternlm2-20b-reward/transformers/default/1/internlm_internlm2-20b-reward\"\ntokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type='nf4',\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nmodel_0 = AutoModel.from_pretrained(\n    model_path, \n    device_map=\"cuda:0\", \n    torch_dtype=torch.float16, \n    trust_remote_code=True,\n    quantization_config=bnb_config,\n)\n\nmodel_1 = AutoModel.from_pretrained(\n    model_path, \n    device_map=\"cuda:1\", \n    torch_dtype=torch.float16, \n    trust_remote_code=True,\n    quantization_config=bnb_config,\n)\n\n# model_0 = AutoModel.from_pretrained(\n#     model_path, \n#     device_map=\"cuda:0\", \n#     torch_dtype=torch.float16, \n#     trust_remote_code=True,\n# )\n# model_1 = AutoModel.from_pretrained(\n#     model_path, \n#     device_map=\"cuda:1\", \n#     torch_dtype=torch.float16, \n#     trust_remote_code=True,\n# )","metadata":{"execution":{"iopub.status.busy":"2024-07-29T11:50:06.217365Z","iopub.execute_input":"2024-07-29T11:50:06.217983Z","iopub.status.idle":"2024-07-29T11:56:18.97818Z","shell.execute_reply.started":"2024-07-29T11:50:06.217953Z","shell.execute_reply":"2024-07-29T11:56:18.977391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bnb_4bit_path = \"internlm2-20b-rm-bnb-4bit\"\n# model_0.save_pretrained(bnb_4bit_path)\n# tokenizer.save_pretrained(bnb_4bit_path)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T11:56:50.789519Z","iopub.execute_input":"2024-07-29T11:56:50.790183Z","iopub.status.idle":"2024-07-29T11:57:24.122377Z","shell.execute_reply.started":"2024-07-29T11:56:50.790153Z","shell.execute_reply":"2024-07-29T11:57:24.121263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink, display\n# display(FileLink(\"/kaggle/working/internlm2-20b-rm-bnb-4bit/model-00001-of-00003.safetensors\"))","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:43:12.081999Z","iopub.execute_input":"2024-07-29T12:43:12.08275Z","iopub.status.idle":"2024-07-29T12:43:12.088672Z","shell.execute_reply.started":"2024-07-29T12:43:12.082717Z","shell.execute_reply":"2024-07-29T12:43:12.087675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_0","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:06:23.313989Z","iopub.execute_input":"2024-07-29T12:06:23.314271Z","iopub.status.idle":"2024-07-29T12:06:23.329576Z","shell.execute_reply.started":"2024-07-29T12:06:23.314248Z","shell.execute_reply":"2024-07-29T12:06:23.328678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# DEBUG = False\ndf = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n# if len(df) == 3:\n#     DEBUG = True\n#     df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n#     df = df.head(1000)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:42:53.645694Z","iopub.execute_input":"2024-07-29T12:42:53.646581Z","iopub.status.idle":"2024-07-29T12:42:53.67154Z","shell.execute_reply.started":"2024-07-29T12:42:53.646547Z","shell.execute_reply":"2024-07-29T12:42:53.670676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef cut_off(example, max_length=7200):\n    \n    def _count(example, idx):\n        _len = 0    \n        for s in example['prompt'][:idx] + example['response_a'][:idx] + example['response_b'][:idx]:\n            _len += len(s)\n        return _len\n\n    def _recusive_cut(idx):\n        if idx == 0:\n            example['prompt'] = [example['prompt'][0][:1000]]\n            example['response_a'] = [example['response_a'][0][:3000]]\n            example['response_b'] = [example['response_b'][0][:3000]]\n            return example\n            \n        if _count(example, idx) > max_length:\n            return _recusive_cut(idx-1)\n        else:\n            example['prompt'] = example['prompt'][:idx]\n            example['response_a'] = example['response_a'][:idx]\n            example['response_b'] = example['response_b'][:idx]\n            return example\n    return _recusive_cut(len(example['prompt']))\n        \n\n\ndef process_fn(example):\n    example['prompt'] = eval(example['prompt'], {\"null\": \"\"})\n    example['response_a'] = eval(example['response_a'], {\"null\": \"\"})\n    example['response_b'] = eval(example['response_b'], {\"null\": \"\"})\n    return cut_off(example)\n\nnew_df = df.apply(lambda x: process_fn(x), axis=1)\nnew_df","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:20:28.432133Z","iopub.execute_input":"2024-07-29T12:20:28.432868Z","iopub.status.idle":"2024-07-29T12:20:28.761143Z","shell.execute_reply.started":"2024-07-29T12:20:28.432838Z","shell.execute_reply":"2024-07-29T12:20:28.760142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport math\nimport numpy as np\ndef inference(df, model):\n\n    error_cnt = 0\n    y_pred = []\n    for idx, row in df.iterrows():\n        chat_a = []\n        chat_b = []\n        for i in range(len(row['prompt'])):\n            chat_a.append({\"role\": \"user\", \"content\": row['prompt'][i]})\n            chat_a.append({\"role\": \"assistant\", \"content\": row['response_a'][i]})\n\n            chat_b.append({\"role\": \"user\", \"content\": row['prompt'][i]})\n            chat_b.append({\"role\": \"assistant\", \"content\": row['response_b'][i]})\n            \n        try:\n            score1, score2 = model.get_scores(tokenizer, [chat_a, chat_b])\n            if abs(score1 - score2) < 0.08:\n                y_pred.append([0.00005, 0.00005, 0.9999])\n            else:\n                score1, score2 = math.exp(score1), math.exp(score2)\n                sum_ = score1 + score2\n                y_pred.append([score1/sum_ - 0.0001, score2/sum_ -0.0001, 0.0002])\n        except:\n            y_pred.append([0.33334, 0.33333, 0.33333])\n            error_cnt += 1\n        \n    y_pred = np.array(y_pred)\n    df['winner_model_a_pred'] = y_pred[:, 0]\n    df['winner_model_b_pred'] = y_pred[:, 1]\n    df['winner_tie_pred'] = y_pred[:, 2]\n    print(error_cnt)\n    return df","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:20:33.770795Z","iopub.execute_input":"2024-07-29T12:20:33.77159Z","iopub.status.idle":"2024-07-29T12:20:33.782691Z","shell.execute_reply.started":"2024-07-29T12:20:33.771557Z","shell.execute_reply":"2024-07-29T12:20:33.781561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test\n# inference(new_df[:20], model_0)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:19:14.030237Z","iopub.execute_input":"2024-07-29T12:19:14.031198Z","iopub.status.idle":"2024-07-29T12:19:19.783271Z","shell.execute_reply.started":"2024-07-29T12:19:14.031168Z","shell.execute_reply":"2024-07-29T12:19:19.782357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsub_0 = new_df.iloc[0::2].copy()\nsub_1 = new_df.iloc[1::2].copy()\n\nfrom concurrent.futures import ThreadPoolExecutor \n\nwith ThreadPoolExecutor(max_workers=2) as executor:\n    results = executor.map(inference, (sub_0, sub_1), (model_0, model_1))\n\nresult_df = pd.concat(list(results), axis=0)\nresult_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:20:39.017063Z","iopub.execute_input":"2024-07-29T12:20:39.017836Z","iopub.status.idle":"2024-07-29T12:40:17.219023Z","shell.execute_reply.started":"2024-07-29T12:20:39.017802Z","shell.execute_reply":"2024-07-29T12:40:17.218066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df = result_df.rename(columns={'winner_model_a_pred' : 'winner_model_a', 'winner_model_b_pred' : 'winner_model_b', 'winner_tie_pred' : 'winner_tie'})\nresult_df","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:40:17.221299Z","iopub.execute_input":"2024-07-29T12:40:17.222011Z","iopub.status.idle":"2024-07-29T12:40:17.261673Z","shell.execute_reply.started":"2024-07-29T12:40:17.221973Z","shell.execute_reply":"2024-07-29T12:40:17.260528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']].to_csv('submission.csv', index=False)\npd.read_csv('submission.csv').head(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:40:17.263498Z","iopub.execute_input":"2024-07-29T12:40:17.263889Z","iopub.status.idle":"2024-07-29T12:40:17.289937Z","shell.execute_reply.started":"2024-07-29T12:40:17.263839Z","shell.execute_reply":"2024-07-29T12:40:17.289073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import log_loss, accuracy_score\n\n# if DEBUG:\n#     y_true = result_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values.tolist()\n#     y_pred = result_df[['winner_model_a_pred', 'winner_model_b_pred', 'winner_tie_pred']].values.tolist()\n#     print(log_loss(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-07-29T12:19:07.130804Z","iopub.execute_input":"2024-07-29T12:19:07.131134Z","iopub.status.idle":"2024-07-29T12:19:07.135459Z","shell.execute_reply.started":"2024-07-29T12:19:07.131103Z","shell.execute_reply":"2024-07-29T12:19:07.134671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if not DEBUG:\n#     result_df = result_df.rename({'winner_model_a_pred' : 'winner_model_a', 'winner_model_b_pred' : 'winner_model_b', 'winner_tie_pred' : 'winner_tie'})\n#     result_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']].to_csv('submission.csv', index=False)\n#     pd.read_csv('submission.csv').head(5)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T16:44:02.07137Z","iopub.execute_input":"2024-07-25T16:44:02.07165Z","iopub.status.idle":"2024-07-25T16:44:02.077642Z","shell.execute_reply.started":"2024-07-25T16:44:02.071627Z","shell.execute_reply":"2024-07-25T16:44:02.076635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}