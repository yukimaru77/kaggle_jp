{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-11T09:31:16.066182Z","iopub.execute_input":"2024-07-11T09:31:16.06664Z","iopub.status.idle":"2024-07-11T09:31:17.822835Z","shell.execute_reply.started":"2024-07-11T09:31:16.066602Z","shell.execute_reply":"2024-07-11T09:31:17.820993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, log_loss, confusion_matrix, roc_curve, auc\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint('All libraries has been imported')","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:34:46.154388Z","iopub.execute_input":"2024-07-11T09:34:46.155601Z","iopub.status.idle":"2024-07-11T09:34:46.163657Z","shell.execute_reply.started":"2024-07-11T09:34:46.155552Z","shell.execute_reply":"2024-07-11T09:34:46.162306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Collection\ntrain_file = '/kaggle/input/lmsys-chatbot-arena/train.csv'\ntest_file = '/kaggle/input/lmsys-chatbot-arena/test.csv'\ntrain_data = pd.read_csv(train_file)\ntest_data = pd.read_csv(test_file)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:34:54.455786Z","iopub.execute_input":"2024-07-11T09:34:54.45723Z","iopub.status.idle":"2024-07-11T09:34:58.404044Z","shell.execute_reply.started":"2024-07-11T09:34:54.457178Z","shell.execute_reply":"2024-07-11T09:34:58.402866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Understanding\nprint(\"Training Dataset Info:\")\nprint(train_data.info())\nprint(\"\\nFirst few rows:\")\nprint(train_data.head())\n\nprint(\"\\nTest Dataset Info:\")\nprint(test_data.info())\nprint(\"\\nFirst few rows:\")\nprint(test_data.head())\n\n# Visualize class distribution before resampling\nplt.figure(figsize=(12, 6))\nsns.countplot(x=train_data['winner_model_a'])\nplt.title(\"Class Distribution Before Resampling\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:35:08.079216Z","iopub.execute_input":"2024-07-11T09:35:08.07966Z","iopub.status.idle":"2024-07-11T09:35:08.445124Z","shell.execute_reply.started":"2024-07-11T09:35:08.079625Z","shell.execute_reply":"2024-07-11T09:35:08.443929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Preparation\ndef clean_text(text, stop_words):\n    text = re.sub(r'\\[.*?\\]', '', text)\n    text = re.sub(r'http\\S+|www.\\S+', '', text)\n    text = re.sub(r'<.*?>+', '', text)\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    text = text.lower()\n    text = ' '.join(word for word in text.split() if word not in stop_words)\n    return text\n\nstop_words = set()\n\n# Clean text data\ntrain_data['prompt'] = train_data['prompt'].apply(lambda x: clean_text(x, stop_words))\ntrain_data['response_a'] = train_data['response_a'].apply(lambda x: clean_text(x, stop_words))\ntrain_data['response_b'] = train_data['response_b'].apply(lambda x: clean_text(x, stop_words))\n\ntest_data['prompt'] = test_data['prompt'].apply(lambda x: clean_text(x, stop_words))\ntest_data['response_a'] = test_data['response_a'].apply(lambda x: clean_text(x, stop_words))\ntest_data['response_b'] = test_data['response_b'].apply(lambda x: clean_text(x, stop_words))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:35:16.895836Z","iopub.execute_input":"2024-07-11T09:35:16.89655Z","iopub.status.idle":"2024-07-11T09:35:22.952786Z","shell.execute_reply.started":"2024-07-11T09:35:16.896495Z","shell.execute_reply":"2024-07-11T09:35:22.951303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Vectorize text data\nvectorizer = TfidfVectorizer(max_features=1000)\ntrain_text = train_data['prompt'] + ' ' + train_data['response_a'] + ' ' + train_data['response_b']\ntest_text = test_data['prompt'] + ' ' + test_data['response_a'] + ' ' + test_data['response_b']\n\nX_train_text = vectorizer.fit_transform(train_text)\nX_test_text = vectorizer.transform(test_text)\n\n# Verbosity Bias - Add response lengths and length differences\ntrain_data['response_a_length'] = train_data['response_a'].apply(len)\ntrain_data['response_b_length'] = train_data['response_b'].apply(len)\ntest_data['response_a_length'] = test_data['response_a'].apply(len)\ntest_data['response_b_length'] = test_data['response_b'].apply(len)\ntrain_data['length_diff'] = train_data['response_a_length'] - train_data['response_b_length']\ntest_data['length_diff'] = test_data['response_a_length'] - test_data['response_b_length']\n\n# Position Bias - Add position bias feature\ntrain_data['position_bias_a'] = 0  # Assuming response_a is always the first\ntrain_data['position_bias_b'] = 1  # Assuming response_b is always the second\ntest_data['position_bias_a'] = 0\ntest_data['position_bias_b'] = 1\n\n# Self-Enhancement Bias - Add self-enhancement detection feature\ndef detect_self_enhancement(text):\n    keywords = ['best', 'better', 'excellent', 'superior', 'number one']\n    for keyword in keywords:\n        if keyword in text:\n            return 1\n    return 0\n\ntrain_data['self_enhancement_a'] = train_data['response_a'].apply(detect_self_enhancement)\ntrain_data['self_enhancement_b'] = train_data['response_b'].apply(detect_self_enhancement)\ntest_data['self_enhancement_a'] = test_data['response_a'].apply(detect_self_enhancement)\ntest_data['self_enhancement_b'] = test_data['response_b'].apply(detect_self_enhancement)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:35:31.208024Z","iopub.execute_input":"2024-07-11T09:35:31.208589Z","iopub.status.idle":"2024-07-11T09:35:34.26134Z","shell.execute_reply.started":"2024-07-11T09:35:31.208544Z","shell.execute_reply":"2024-07-11T09:35:34.260045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoding Categorical Features\ncategorical_columns = ['model_a', 'model_b']\nfor column in categorical_columns:\n    if column not in test_data.columns:\n        test_data[column] = 'missing'\ntrain_data_encoded = pd.get_dummies(train_data, columns=categorical_columns)\ntest_data_encoded = pd.get_dummies(test_data, columns=categorical_columns)\ntrain_data_encoded, test_data_encoded = train_data_encoded.align(test_data_encoded, join='left', axis=1, fill_value=0)\n\n# Handle Missing Columns\ntest_data_encoded.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie'], errors='ignore', inplace=True)\n\n# Remove non-numeric columns\nnon_numeric_columns = train_data_encoded.select_dtypes(exclude=[np.number]).columns\ntrain_data_encoded.drop(columns=non_numeric_columns, inplace=True)\ntest_data_encoded.drop(columns=non_numeric_columns, inplace=True)\n\n# Combine all features into training and testing sets\nX_train_combined = np.hstack((X_train_text.toarray(), train_data_encoded.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie']).values))\nX_test_combined = np.hstack((X_test_text.toarray(), test_data_encoded.values))\nX = X_train_combined\ny = train_data_encoded['winner_model_a']\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:36:01.535916Z","iopub.execute_input":"2024-07-11T09:36:01.536381Z","iopub.status.idle":"2024-07-11T09:36:02.104743Z","shell.execute_reply.started":"2024-07-11T09:36:01.536331Z","shell.execute_reply":"2024-07-11T09:36:02.103381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeling\n# Resample Data\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Visualize class distribution after resampling\nplt.figure(figsize=(12, 6))\nsns.countplot(x=y_resampled)\nplt.title(\"Class Distribution After Resampling\")\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:36:16.126148Z","iopub.execute_input":"2024-07-11T09:36:16.126603Z","iopub.status.idle":"2024-07-11T09:36:32.788713Z","shell.execute_reply.started":"2024-07-11T09:36:16.126566Z","shell.execute_reply":"2024-07-11T09:36:32.787375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the resampled data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:36:37.574799Z","iopub.execute_input":"2024-07-11T09:36:37.575501Z","iopub.status.idle":"2024-07-11T09:36:37.793416Z","shell.execute_reply.started":"2024-07-11T09:36:37.57546Z","shell.execute_reply":"2024-07-11T09:36:37.792022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning and model selection\nmodels = {\n    'Logistic Regression': {\n        'model': LogisticRegression(random_state=42, max_iter=1000),\n        'params': {'C': [0.01, 0.1, 1, 10, 100]}\n    },\n    'Random Forest': {\n        'model': RandomForestClassifier(random_state=42),\n        'params': {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30]}\n    },\n    'Gradient Boosting': {\n        'model': GradientBoostingClassifier(random_state=42),\n        'params': {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200]}\n    }\n}\n\nbest_models = {}\n\nfor model_name, config in models.items():\n    grid_search = GridSearchCV(estimator=config['model'], param_grid=config['params'], cv=5, scoring='neg_log_loss', verbose=2, n_jobs=-1)\n    grid_search.fit(X_train, y_train)\n    best_models[model_name] = grid_search.best_estimator_\n    print(f\"Best {model_name} Model: {grid_search.best_params_}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T09:36:46.73429Z","iopub.execute_input":"2024-07-11T09:36:46.735141Z","iopub.status.idle":"2024-07-11T11:09:25.315774Z","shell.execute_reply.started":"2024-07-11T09:36:46.735105Z","shell.execute_reply":"2024-07-11T11:09:25.314176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation\nfor model_name, model in best_models.items():\n    y_val_pred = model.predict(X_val)\n    y_val_pred_proba = model.predict_proba(X_val)\n    print(f\"Classification Report on Validation Set ({model_name}):\")\n    print(classification_report(y_val, y_val_pred, zero_division=1))\n    print(f\"Log Loss ({model_name}): {log_loss(y_val, y_val_pred_proba)}\")\n\n    # Confusion Matrix\n    cm = confusion_matrix(y_val, y_val_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f'Confusion Matrix ({model_name})')\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.show()\n\n    # ROC Curve\n    fpr, tpr, _ = roc_curve(y_val, y_val_pred_proba[:, 1])\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title(f'Receiver Operating Characteristic ({model_name})')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T11:10:04.344728Z","iopub.execute_input":"2024-07-11T11:10:04.345155Z","iopub.status.idle":"2024-07-11T11:10:08.986953Z","shell.execute_reply.started":"2024-07-11T11:10:04.345116Z","shell.execute_reply":"2024-07-11T11:10:08.98556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Deployment with the best model (example: Logistic Regression)\nbest_lr_model = best_models['Logistic Regression']\ntest_predictions_proba = best_lr_model.predict_proba(X_test_combined)\nsubmission_df = pd.DataFrame({\n    'id': test_data['id'],\n    'winner_model_a': test_predictions_proba[:, 0],\n    'winner_model_b': test_predictions_proba[:, 1],\n    'winner_tie': 0.0  # Assuming binary classification\n})\nsubmission_df.to_csv('submission.csv', index=False)\nprint(submission_df.head())\nprint(\"Submission file saved successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-11T11:10:31.160802Z","iopub.execute_input":"2024-07-11T11:10:31.161289Z","iopub.status.idle":"2024-07-11T11:10:31.184943Z","shell.execute_reply.started":"2024-07-11T11:10:31.16125Z","shell.execute_reply":"2024-07-11T11:10:31.18274Z"},"trusted":true},"execution_count":null,"outputs":[]}]}