{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8984365,"sourceType":"datasetVersion","datasetId":5410613}],"dockerImageVersionId":30734,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-18T15:36:00.626869Z","iopub.execute_input":"2024-07-18T15:36:00.627567Z","iopub.status.idle":"2024-07-18T15:36:01.029683Z","shell.execute_reply.started":"2024-07-18T15:36:00.627534Z","shell.execute_reply":"2024-07-18T15:36:01.028708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\ntest=pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:04.537978Z","iopub.execute_input":"2024-07-18T15:36:04.538447Z","iopub.status.idle":"2024-07-18T15:36:07.960915Z","shell.execute_reply.started":"2024-07-18T15:36:04.538415Z","shell.execute_reply":"2024-07-18T15:36:07.960028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# detect and init the TPU\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:22.341255Z","iopub.execute_input":"2024-07-18T15:36:22.341626Z","iopub.status.idle":"2024-07-18T15:36:25.864079Z","shell.execute_reply.started":"2024-07-18T15:36:22.341593Z","shell.execute_reply":"2024-07-18T15:36:25.86332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nimport transformers \nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:32.529963Z","iopub.execute_input":"2024-07-18T15:36:32.53128Z","iopub.status.idle":"2024-07-18T15:36:35.3523Z","shell.execute_reply.started":"2024-07-18T15:36:32.531231Z","shell.execute_reply":"2024-07-18T15:36:35.3513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('/kaggle/input/bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:37:46.270334Z","iopub.execute_input":"2024-07-18T15:37:46.271364Z","iopub.status.idle":"2024-07-18T15:37:46.347287Z","shell.execute_reply.started":"2024-07-18T15:37:46.271324Z","shell.execute_reply":"2024-07-18T15:37:46.346335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel\n\n# Load BERT model\nbert_model = TFBertModel.from_pretrained('/kaggle/input/bert-base-uncased')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:37:49.1906Z","iopub.execute_input":"2024-07-18T15:37:49.191476Z","iopub.status.idle":"2024-07-18T15:37:54.176855Z","shell.execute_reply.started":"2024-07-18T15:37:49.191438Z","shell.execute_reply":"2024-07-18T15:37:54.17583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train.index:\n    if train.loc[i,'winner_model_a']==1:\n        train.loc[i,'winner']=0\n    elif train.loc[i,'winner_model_b']==1:\n        train.loc[i,'winner']=1\n    else :\n        train.loc[i,'winner']=2","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:37:57.83605Z","iopub.execute_input":"2024-07-18T15:37:57.836924Z","iopub.status.idle":"2024-07-18T15:38:11.664979Z","shell.execute_reply.started":"2024-07-18T15:37:57.83689Z","shell.execute_reply":"2024-07-18T15:38:11.664148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features=['prompt','response_a','response_b','winner']","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:40:16.062404Z","iopub.execute_input":"2024-07-18T15:40:16.063333Z","iopub.status.idle":"2024-07-18T15:40:16.067503Z","shell.execute_reply.started":"2024-07-18T15:40:16.063296Z","shell.execute_reply":"2024-07-18T15:40:16.066597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data=train[features]","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:40:20.681566Z","iopub.execute_input":"2024-07-18T15:40:20.681929Z","iopub.status.idle":"2024-07-18T15:40:20.697557Z","shell.execute_reply.started":"2024-07-18T15:40:20.681899Z","shell.execute_reply":"2024-07-18T15:40:20.696645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train,X_val=train_test_split(train_data,test_size=0.2,random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:40:21.758073Z","iopub.execute_input":"2024-07-18T15:40:21.759047Z","iopub.status.idle":"2024-07-18T15:40:21.776955Z","shell.execute_reply.started":"2024-07-18T15:40:21.759009Z","shell.execute_reply":"2024-07-18T15:40:21.775942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenize function\ndef tokenize_function(df):\n    prompt_encodings = tokenizer(\n        df['prompt'].tolist(),\n        padding='max_length',\n        truncation=True,\n        max_length=128,\n        return_tensors='tf'\n    )\n    response_a_encodings = tokenizer(\n        df['response_a'].tolist(),\n        padding='max_length',\n        truncation=True,\n        max_length=128,\n        return_tensors='tf'\n    )\n    response_b_encodings = tokenizer(\n        df['response_b'].tolist(),\n        padding='max_length',\n        truncation=True,\n        max_length=128,\n        return_tensors='tf'\n    )\n    return prompt_encodings, response_a_encodings, response_b_encodings \n\n\ntrain_prompt_encodings, train_response_a_encodings, train_response_b_encodings = tokenize_function(X_train)\nval_prompt_encodings, val_response_a_encodings, val_response_b_encodings = tokenize_function(X_val)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:40:45.103011Z","iopub.execute_input":"2024-07-18T15:40:45.103893Z","iopub.status.idle":"2024-07-18T15:45:03.65788Z","shell.execute_reply.started":"2024-07-18T15:40:45.103857Z","shell.execute_reply":"2024-07-18T15:45:03.655548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.utils import to_categorical \n\n# Prepare input features and labels\ntrain_labels = to_categorical(X_train['winner'].tolist(), num_classes=3)\nval_labels = to_categorical(X_val['winner'].tolist(), num_classes=3)\n\n# Create TensorFlow datasets\ntrain_dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids_prompt': train_prompt_encodings['input_ids'],\n        'attention_mask_prompt': train_prompt_encodings['attention_mask'],\n        'input_ids_response_a': train_response_a_encodings['input_ids'],\n        'attention_mask_response_a': train_response_a_encodings['attention_mask'],\n        'input_ids_response_b': train_response_b_encodings['input_ids'],\n        'attention_mask_response_b': train_response_b_encodings['attention_mask'],\n    },\n    train_labels\n)).shuffle(1000).batch(1)\n\nval_dataset = tf.data.Dataset.from_tensor_slices((\n    {\n        'input_ids_prompt': val_prompt_encodings['input_ids'],\n        'attention_mask_prompt': val_prompt_encodings['attention_mask'],\n        'input_ids_response_a': val_response_a_encodings['input_ids'],\n        'attention_mask_response_a': val_response_a_encodings['attention_mask'],\n        'input_ids_response_b': val_response_b_encodings['input_ids'],\n        'attention_mask_response_b': val_response_b_encodings['attention_mask'],\n    },\n    val_labels\n)).batch(1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define inputs\ninput_ids_prompt = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids_prompt\")\nattention_mask_prompt = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask_prompt\")\n\ninput_ids_response_a = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids_response_a\")\nattention_mask_response_a = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask_response_a\")\n\ninput_ids_response_b = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"input_ids_response_b\")\nattention_mask_response_b = tf.keras.layers.Input(shape=(128,), dtype=tf.int32, name=\"attention_mask_response_b\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFBertModel\n\nclass BertEmbeddingLayer(tf.keras.layers.Layer):\n    def __init__(self, bert_model_name='bert-base-uncased', **kwargs):\n        super(BertEmbeddingLayer, self).__init__(**kwargs)\n        self.bert = bert_model\n        \n    def call(self, inputs):\n        input_ids, attention_mask = inputs\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        return outputs.last_hidden_state[:, 0, :]  # CLS token embedding\n\n# Initialize the custom BERT layer\nbert_layer = BertEmbeddingLayer()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:45:20.906328Z","iopub.execute_input":"2024-07-18T15:45:20.906713Z","iopub.status.idle":"2024-07-18T15:45:20.932362Z","shell.execute_reply.started":"2024-07-18T15:45:20.90668Z","shell.execute_reply":"2024-07-18T15:45:20.931598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprompt_embeddings = bert_layer([input_ids_prompt, attention_mask_prompt])\nresponse_a_embeddings = bert_layer([input_ids_response_a, attention_mask_response_a])\nresponse_b_embeddings = bert_layer([input_ids_response_b, attention_mask_response_b])\n\n# Concatenate embeddings\ncombined_embeddings = tf.keras.layers.Concatenate()([prompt_embeddings, response_a_embeddings, response_b_embeddings])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndense_layer = tf.keras.layers.Dense(256, activation='relu')(combined_embeddings)\ndropout_layer = tf.keras.layers.Dropout(0.2)(dense_layer)\noutput_layer = tf.keras.layers.Dense(3, activation='softmax')(dropout_layer)\n\n# Build and compile the model\nmodel = tf.keras.Model(inputs=[\n    input_ids_prompt, attention_mask_prompt,\n    input_ids_response_a, attention_mask_response_a,\n    input_ids_response_b, attention_mask_response_b\n], outputs=output_layer)\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    epochs=1\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_text(texts, max_length):\n    return tokenizer(\n        texts,\n        truncation=True,\n        padding='max_length',\n        max_length=max_length,\n        return_tensors='tf'\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length = 128  # Adjust according to your model's max sequence length\ninput_ids_prompt = encode_text(test['prompt'].tolist(), max_length)\ninput_ids_response_a = encode_text(test['response_a'].tolist(), max_length)\ninput_ids_response_b = encode_text(test['response_b'].tolist(), max_length)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict({\n    'input_ids_prompt': input_ids_prompt['input_ids'],\n    'attention_mask_prompt': input_ids_prompt['attention_mask'],\n    'input_ids_response_a': input_ids_response_a['input_ids'],\n    'attention_mask_response_a': input_ids_response_a['attention_mask'],\n    'input_ids_response_b': input_ids_response_b['input_ids'],\n    'attention_mask_response_b': input_ids_response_b['attention_mask']\n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"done till here\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results=pd.DataFrame({\n    'ID':test['id'],\n    'winner_model_a':predictions[0],\n    'winner_model_b':predictions[1],\n    'winner_tie':predictions[2],\n    \n})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results.to_csv('/kaggle/working/submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}