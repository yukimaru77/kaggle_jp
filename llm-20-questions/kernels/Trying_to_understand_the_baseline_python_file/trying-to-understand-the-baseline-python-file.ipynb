{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f10f1346",
   "metadata": {},
   "source": [
    "# Code documented with the help of ChatGPT\n",
    "\n",
    "# First Settings\n",
    "Configuration of the execution environment, defines constants for states and actions, and randomly selects a keyword and its alternatives from a pre-defined list, thus preparing the 20-question game to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.684101Z",
     "iopub.status.busy": "2024-06-01T17:52:53.683668Z",
     "iopub.status.idle": "2024-06-01T17:52:53.691043Z",
     "shell.execute_reply": "2024-06-01T17:52:53.689454Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.68407Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.693538Z",
     "iopub.status.busy": "2024-06-01T17:52:53.693159Z",
     "iopub.status.idle": "2024-06-01T17:52:53.722318Z",
     "shell.execute_reply": "2024-06-01T17:52:53.721167Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.693505Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import string\n",
    "import torch\n",
    "sys.path.append(\"/kaggle/input/llm-20-questions/llm_20_questions\")\n",
    "\n",
    "from  keywords import KEYWORDS_JSON\n",
    "from os import path\n",
    "from pathlib import Path\n",
    "from random import choice\n",
    "from string import Template\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "llm_parent_dir = \"/kaggle/input/flan-t5/pytorch/large\"\n",
    "device = None\n",
    "model = None\n",
    "tokenizer = None\n",
    "model_initialized = False\n",
    "ERROR = \"ERROR\"\n",
    "DONE = \"DONE\"\n",
    "INACTIVE = \"INACTIVE\"\n",
    "ACTIVE = \"ACTIVE\"\n",
    "TIMEOUT = \"TIMEOUT\"\n",
    "GUESS = \"guess\"\n",
    "ASK = \"ask\"\n",
    "GUESSER = \"guesser\"\n",
    "ANSWERER = \"guesser\"\n",
    "keywords_list = json.loads(KEYWORDS_JSON)\n",
    "keyword_cat = random.choice(keywords_list)\n",
    "category = keyword_cat[\"category\"]\n",
    "keyword_obj = random.choice(keyword_cat[\"words\"])\n",
    "keyword = keyword_obj[\"keyword\"]\n",
    "alts = keyword_obj[\"alts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6798afe9",
   "metadata": {},
   "source": [
    "# Guesser Agent\n",
    "\n",
    "The <i>guesser_agent</i> function creates dynamic prompts based on the current game state and turn type, and then uses a language model to generate the next action in the game. Specifically:\n",
    "\n",
    "1. Builds a history of questions and answers so far.\n",
    "1. Choose the appropriate prompt (question or guess) based on the turn type.\n",
    "1. Generates the next action by calling a language model with the constructed prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.724906Z",
     "iopub.status.busy": "2024-06-01T17:52:53.724494Z",
     "iopub.status.idle": "2024-06-01T17:52:53.735145Z",
     "shell.execute_reply": "2024-06-01T17:52:53.733533Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.724837Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_agent(obs):\n",
    "    info_prompt = \"\"\"You are playing a game of 20 questions where you ask the questions and try to figure out the keyword, which will be a real or fictional person, place, or thing. \\nHere is what you know so far:\\n{q_a_thread}\"\"\"\n",
    "    questions_prompt = \"\"\"Ask one yes or no question.\"\"\"\n",
    "    guess_prompt = \"\"\"Guess the keyword. Only respond with the exact word/phrase. For example, if you think the keyword is [paris], don't respond with [I think the keyword is paris] or [Is the kewyord Paris?]. Respond only with the word [paris].\"\"\"\n",
    "    q_a_thread = \"\"\n",
    "    for i in range(0, len(obs.answers)):\n",
    "        q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "            q_a_thread,\n",
    "            obs.questions[i],\n",
    "            obs.answers[i]\n",
    "        )\n",
    "    prompt = \"\"\n",
    "    if obs.turnType == ASK:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "    elif obs.turnType == GUESS:\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "    return call_llm(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca9c666",
   "metadata": {},
   "source": [
    "# Answerer Agent\n",
    "The answerer_agent function:\n",
    "\n",
    "1. Checks if the turn type is \"answer\".\n",
    "\n",
    "1. If so, create a prompt by combining info_prompt and answer_question_prompt, replacing the placeholders with the actual values.\n",
    "\n",
    "1. Calls the call_llm function with the generated prompt to get the response.\n",
    "\n",
    "1. If the turn is not \"answer\", returns an empty string.\n",
    "\n",
    "1. The agents dictionary maps agent types to the respective roles that define their behavior in the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.737143Z",
     "iopub.status.busy": "2024-06-01T17:52:53.736759Z",
     "iopub.status.idle": "2024-06-01T17:52:53.746596Z",
     "shell.execute_reply": "2024-06-01T17:52:53.745085Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.737114Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_agent(obs):\n",
    "    info_prompt = \"\"\"You are a very precise answerer in a game of 20 questions. The keyword that the questioner is trying to guess is [the {category} {keyword}]. \"\"\"\n",
    "    answer_question_prompt = \"\"\"Answer the following question with only yes, no, or if unsure maybe: {question}\"\"\"\n",
    "    if obs.turnType == \"answer\":\n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(category=category,keyword=keyword),\n",
    "            answer_question_prompt.format(question=obs.questions[-1])\n",
    "        )\n",
    "        return call_llm(prompt)\n",
    "    else: \n",
    "        return \"\"\n",
    "agents = {GUESSER: guesser_agent, ANSWERER: answerer_agent}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb918708",
   "metadata": {},
   "source": [
    "# Guesser Action\n",
    "\n",
    "### Components of the Function\n",
    "1. **Initialization of the `guessed` Variable**:\n",
    "   - The variable `guessed` is initialized as `False` to track whether the keyword has been correctly guessed.\n",
    "   ```python\n",
    "   guessed = False\n",
    "   ```\n",
    "2. **Checking for No Action**:\n",
    "   - If `active.action` is empty (no action was taken), the status of `active` is set to `ERROR`.\n",
    "   ```python\n",
    "   if not active.action:\n",
    "       active.status = ERROR\n",
    "   ```\n",
    "3. **Handling Question-Asking Turn**:\n",
    "   - If the observer’s turn type (`turnType`) is `ASK` (ask a question):\n",
    "     - The action (`active.action`) is treated as a question and is limited to 2000 characters.\n",
    "     - The question is appended to the lists of questions for both the active and inactive observers.\n",
    "   ```python\n",
    "   elif active.observation.turnType == ASK:\n",
    "       question = active.action[:2000]\n",
    "       active.observation.questions.append(question)\n",
    "       inactive.observation.questions.append(question)\n",
    "   ```\n",
    "4. **Handling Guessing Turn**:\n",
    "   - If the observer’s turn type is `GUESS` (make a guess):\n",
    "     - The action (`active.action`) is treated as a guess and is limited to 100 characters.\n",
    "     - The guess is appended to the lists of guesses for both the active and inactive observers.\n",
    "   ```python\n",
    "   elif active.observation.turnType == GUESS:\n",
    "       guess = active.action[:100]\n",
    "       active.observation.guesses.append(guess)\n",
    "       inactive.observation.guesses.append(guess)\n",
    "   ```\n",
    "5. **Checking if the Keyword is Guessed**:\n",
    "   - If there is an action (`active.action`) and the keyword is correctly guessed (`keyword_guessed(active.action)`):\n",
    "     - The variable `guessed` is set to `True`.\n",
    "     - The score is calculated as `20 - int(step / 3)`, where `step` represents the number of steps taken in the game.\n",
    "     - The `end_game` function is called to end the game with the active and inactive observers, passing the score and final states `DONE`.\n",
    "   ```python\n",
    "   if active.action and keyword_guessed(active.action):\n",
    "       guessed = True\n",
    "       score = 20 - int(step / 3)\n",
    "       end_game(active, inactive, score, DONE, DONE)\n",
    "   ```\n",
    "6. **Return the `guessed` Variable**:\n",
    "   - The function returns the `guessed` variable, indicating whether the keyword has been correctly guessed.\n",
    "   ```python\n",
    "   return guessed\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.750303Z",
     "iopub.status.busy": "2024-06-01T17:52:53.749419Z",
     "iopub.status.idle": "2024-06-01T17:52:53.763111Z",
     "shell.execute_reply": "2024-06-01T17:52:53.761727Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.750264Z"
    }
   },
   "outputs": [],
   "source": [
    "def guesser_action(active, inactive, step):\n",
    "    guessed = False\n",
    "    if not active.action:\n",
    "        active.status = ERROR\n",
    "    elif active.observation.turnType == ASK:\n",
    "        question = active.action[:2000]\n",
    "        active.observation.questions.append(question)\n",
    "        inactive.observation.questions.append(question)\n",
    "    elif active.observation.turnType == GUESS:\n",
    "        guess = active.action[:100]\n",
    "        active.observation.guesses.append(guess)\n",
    "        inactive.observation.guesses.append(guess)\n",
    "    if active.action and keyword_guessed(active.action):\n",
    "        guessed = True\n",
    "        score = 20 - int(step / 3)\n",
    "        end_game(active, inactive, score, DONE, DONE)\n",
    "    return guessed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552fe38",
   "metadata": {},
   "source": [
    "# End Game\n",
    "The `end_game` function finalizes the game by:\n",
    "- Setting the keyword and category for both participants.\n",
    "- Assigning rewards to both participants.\n",
    "- Updating the status of both participants.\n",
    "\n",
    "This ensures that all participants have the correct end-of-game information and that their states are appropriately updated to reflect the conclusion of the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.765011Z",
     "iopub.status.busy": "2024-06-01T17:52:53.764597Z",
     "iopub.status.idle": "2024-06-01T17:52:53.77889Z",
     "shell.execute_reply": "2024-06-01T17:52:53.776597Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.764979Z"
    }
   },
   "outputs": [],
   "source": [
    "def end_game(active, inactive, reward, status, inactive_status):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    inactive.observation.keyword = keyword\n",
    "    inactive.observation.category = category\n",
    "    active.reward = reward\n",
    "    inactive.reward = reward\n",
    "    active.status = status\n",
    "    inactive.status = inactive_status"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9dda55",
   "metadata": {},
   "source": [
    "# Answerer Action\n",
    "\n",
    "The `answerer_action` function processes the answerer's response to a question by:\n",
    "- Setting the keyword and category for the active participant.\n",
    "- Checking if the response is valid and normalizing it to \"yes\", \"no\", or \"maybe\".\n",
    "- Ending the game with an error if the response is invalid or empty.\n",
    "- Appending the response to the answers list of both participants.\n",
    "\n",
    "This function ensures that the game state is appropriately updated based on the answerer's response and handles any errors or invalid responses by ending the game with an error status.\n",
    "\n",
    "**Updating Answers**\n",
    "\n",
    "```python\n",
    "active.observation.answers.append(response)\n",
    "inactive.observation.answers.append(response)\n",
    "```\n",
    "The normalized `response` is appended to the `answers` list of both the `active` and `inactive` participants. This ensures that both participants have a record of the answerer's response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.782277Z",
     "iopub.status.busy": "2024-06-01T17:52:53.780951Z",
     "iopub.status.idle": "2024-06-01T17:52:53.792029Z",
     "shell.execute_reply": "2024-06-01T17:52:53.790924Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.782226Z"
    }
   },
   "outputs": [],
   "source": [
    "def answerer_action(active, inactive):\n",
    "    active.observation.keyword = keyword\n",
    "    active.observation.category = category\n",
    "    response = active.action\n",
    "    if not response:\n",
    "        response = \"none\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    elif \"yes\" in response.lower():\n",
    "        response = \"yes\"\n",
    "    elif \"no\" in response.lower():\n",
    "        response = \"no\"\n",
    "    else:\n",
    "        response = \"maybe\"\n",
    "        end_game(active, inactive, -1, ERROR, DONE)\n",
    "    active.observation.answers.append(response)\n",
    "    inactive.observation.answers.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4393c6",
   "metadata": {},
   "source": [
    "# Increment turn\n",
    "The `increment_turn` function:\n",
    "1. Ends the game after 60 steps if the keyword has not been guessed.\n",
    "2. Switches the turn type between \"ask\" and \"guess\" to alternate the roles of asking questions and making guesses.\n",
    "3. Updates the statuses of the active and inactive participants to ensure the correct participant is active for the next turn.\n",
    "\n",
    "This function ensures that the game progresses smoothly, alternates roles between the participants, and properly handles the end of the game if the keyword is not guessed within the allotted turns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.794871Z",
     "iopub.status.busy": "2024-06-01T17:52:53.794498Z",
     "iopub.status.idle": "2024-06-01T17:52:53.807073Z",
     "shell.execute_reply": "2024-06-01T17:52:53.805825Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.794827Z"
    }
   },
   "outputs": [],
   "source": [
    "def increment_turn(active, inactive, step, guessed):\n",
    "    if step == 59 and not guessed:\n",
    "        end_game(active, inactive, -1, DONE, DONE)\n",
    "    elif active.observation.turnType == \"guess\":\n",
    "        active.observation.turnType = \"ask\"\n",
    "    elif active.observation.turnType == \"ask\":\n",
    "        active.observation.turnType = \"guess\"\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE\n",
    "    else:\n",
    "        active.status = INACTIVE\n",
    "        inactive.status = ACTIVE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c702965f",
   "metadata": {},
   "source": [
    "# Interpreter\n",
    "\n",
    "### Purpose of the `interpreter` Function\n",
    "\n",
    "The `interpreter` function manages the state and actions of a game involving two pairs of agents. Each pair consists of an active and an inactive agent, where one agent is asking questions (the \"asker\") and the other is guessing (the \"guesser\"). The function updates the state of the game, determines the actions to be taken by each agent, and handles transitions and end conditions.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "```python\n",
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "```\n",
    "\n",
    "This line checks if the environment (the game) is done. If it is, the function returns the current state without making any changes.\n",
    "\n",
    "### Isolating Active and Inactive Agents\n",
    "\n",
    "```python\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "```\n",
    "\n",
    "These lines identify which agents are active and inactive for each pair. `state[0]` and `state[1]` are the first pair of agents, while `state[2]` and `state[3]` are the second pair.\n",
    "\n",
    "### Handling Done Status\n",
    "\n",
    "```python\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "```\n",
    "\n",
    "These lines set the agents to `None` if both agents in a pair are done. If all agents are done, the function returns the current state, effectively ending the function.\n",
    "\n",
    "### Processing Steps and End Conditions\n",
    "\n",
    "```python\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "```\n",
    "\n",
    "- `step` stores the current step of the game.\n",
    "- `end_early` checks if either active agent has a status of `TIMEOUT` or `ERROR`, indicating an early termination condition.\n",
    "- `either_guessed` is a flag to track if any agent has guessed the keyword correctly.\n",
    "\n",
    "### Handling Active1 Agent\n",
    "\n",
    "```python\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "```\n",
    "\n",
    "- If `active1` is not `None`, the function checks the agent's role.\n",
    "- If `active1` is the guesser, it calls `guesser_action`.\n",
    "- If `active1` is the answerer, it calls `answerer_action`.\n",
    "- It then handles end conditions such as `TIMEOUT` or `ERROR` by calling `end_game`.\n",
    "- If `end_early` is true, it ends the game.\n",
    "- Otherwise, it calls `increment_turn` to proceed to the next turn.\n",
    "\n",
    "### Handling Active2 Agent\n",
    "\n",
    "```python\n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "```\n",
    "\n",
    "This block is similar to the handling of `active1`, but it operates on `active2` and `inactive2`.\n",
    "\n",
    "### Returning the State\n",
    "\n",
    "```python\n",
    "    return state\n",
    "```\n",
    "\n",
    "The function returns the updated state after processing the actions and transitions for both pairs of agents.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `interpreter` function:\n",
    "\n",
    "1. Checks if the game is done and returns the state if it is.\n",
    "2. Identifies active and inactive agents in each pair.\n",
    "3. Handles end conditions and transitions between asking and guessing roles.\n",
    "4. Calls appropriate functions (`guesser_action`, `answerer_action`, `end_game`, `increment_turn`) based on the current role and status of the agents.\n",
    "5. Updates and returns the game state.\n",
    "\n",
    "This function is essential for managing the flow of the game, ensuring that each agent takes the correct action based on its role, and handling various end conditions appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.809371Z",
     "iopub.status.busy": "2024-06-01T17:52:53.808999Z",
     "iopub.status.idle": "2024-06-01T17:52:53.825443Z",
     "shell.execute_reply": "2024-06-01T17:52:53.824102Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.809341Z"
    }
   },
   "outputs": [],
   "source": [
    "def interpreter(state, env):\n",
    "    if env.done:\n",
    "        return state\n",
    "    # Isolate the active and inactive agents.\n",
    "    active1 = state[0] if state[0].status == ACTIVE else state[1]\n",
    "    inactive1 = state[0] if state[0].status == INACTIVE else state[1]\n",
    "    active2 = state[2] if state[2].status == ACTIVE else state[3]\n",
    "    inactive2 = state[2] if state[2].status == INACTIVE else state[3]\n",
    "    if active1.status == DONE and inactive1.status == DONE:\n",
    "        active1 = None\n",
    "        inactive1 = None\n",
    "    if active2.status == DONE or inactive2.status == DONE:\n",
    "        active2 = None\n",
    "        inactive2 = None\n",
    "    if active1 is None and inactive1 is None and active2 is None and inactive2 is None:\n",
    "        return state\n",
    "    step = state[0].observation.step\n",
    "    end_early = (active1 and active1.status) in (TIMEOUT, ERROR) or (active2 and active2.status in (TIMEOUT, ERROR))\n",
    "    either_guessed = False\n",
    "    if active1 is not None:\n",
    "        guessed = False\n",
    "        if active1.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active1, inactive1, step)\n",
    "            either_guessed = guessed\n",
    "        else:\n",
    "            answerer_action(active1, inactive1)\n",
    "        if active1.status in (TIMEOUT, ERROR):\n",
    "            end_game(active1, inactive1, 0, active1.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active1, inactive1, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active1, inactive1, step, guessed)\n",
    "    \n",
    "    if active2 is not None:\n",
    "        guessed = False\n",
    "        if active2.observation.role == GUESSER:\n",
    "            guessed = guesser_action(active2, inactive2, step)\n",
    "            either_guessed = either_guessed or guessed\n",
    "        else:\n",
    "            answerer_action(active2, inactive2)\n",
    "        if active2.status in (TIMEOUT, ERROR):\n",
    "            end_game(active2, inactive2, 0, active2.status, DONE)\n",
    "        elif end_early:\n",
    "            end_game(active2, inactive2, 0, DONE, DONE)\n",
    "        else:\n",
    "            increment_turn(active2, inactive2, step, guessed)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1fbdce",
   "metadata": {},
   "source": [
    "# Renderer\n",
    "\n",
    "- **`renderer` Function**:\n",
    "  - Iterates over the game state.\n",
    "  - Prints the role, interactions, keyword, and score for each agent.\n",
    "  - Constructs a transcript for `GUESSER` agents showing their questions, answers, and guesses.\n",
    "  - Prints blank lines for readability between agents.\n",
    "\n",
    "- **Additional Code**:\n",
    "  - Constructs the path to a JSON file.\n",
    "  - Opens and loads the JSON file into a variable named `specification`.\n",
    "\n",
    "The `renderer` function helps visualize the current state of the game, making it easier to debug or understand the progress, while the additional code is for loading a game specification from a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.827137Z",
     "iopub.status.busy": "2024-06-01T17:52:53.826659Z",
     "iopub.status.idle": "2024-06-01T17:52:53.844687Z",
     "shell.execute_reply": "2024-06-01T17:52:53.843323Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.827107Z"
    }
   },
   "outputs": [],
   "source": [
    "def renderer(state, env):\n",
    "    for s in state:\n",
    "        print(\"role: \", s.observation.role)\n",
    "        if s.observation.role == GUESSER:\n",
    "            transcript = \"\"\n",
    "            for i in range(0, len(s.observation.guesses)):\n",
    "                transcript = \"{}Q: {} A: {}\\nG: {}\\n\".format(\n",
    "                    transcript, s.observation.questions[i],\n",
    "                    s.observation.answers[i],\n",
    "                    s.observation.guesses[i]\n",
    "                )\n",
    "            print(transcript)\n",
    "        print(\"keyword: \", s.observation.keyword)\n",
    "        print(\"score: \", s.reward)\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "    return \"\"\n",
    "jsonpath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.json\"))\n",
    "with open(jsonpath) as f:\n",
    "    specification = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28bddd",
   "metadata": {},
   "source": [
    "### `html_renderer` Function\n",
    "\n",
    "```python\n",
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Construct JavaScript Path**:\n",
    "    ```python\n",
    "    jspath = path.abspath(path.join(path.dirname(__file__), \"llm_20_questions.js\"))\n",
    "    ```\n",
    "    - Uses `path.abspath` to get the absolute path to the `llm_20_questions.js` file.\n",
    "    - Uses `path.join` to concatenate the directory of the current file (`__file__`) with `llm_20_questions.js`.\n",
    "\n",
    "2. **Open and Read JavaScript File**:\n",
    "    ```python\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "    ```\n",
    "    - Opens the JavaScript file located at the path `jspath`.\n",
    "    - Reads the entire content of the file using `f.read()`.\n",
    "    - Returns the content as a string.\n",
    "\n",
    "This function reads a JavaScript file named `llm_20_questions.js` and returns its content as a string. This can be useful for embedding JavaScript into an HTML page dynamically.\n",
    "\n",
    "### `keyword_guessed` Function\n",
    "\n",
    "```python\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    return False\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Define `normalize` Function**:\n",
    "    ```python\n",
    "    def normalize(s: str) -> str:\n",
    "        t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "        return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    ```\n",
    "    - `normalize` is a helper function to standardize strings for comparison.\n",
    "    - Removes all punctuation from the string using `str.maketrans`.\n",
    "    - Converts the string to lowercase with `s.lower()`.\n",
    "    - Removes occurrences of \"the\" and spaces by replacing them with an empty string.\n",
    "    - Uses `translate(t)` to remove punctuation.\n",
    "\n",
    "2. **Check If Guess Matches Keyword**:\n",
    "    ```python\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "        return True\n",
    "    ```\n",
    "    - Normalizes both `guess` and `keyword`.\n",
    "    - Compares the normalized strings.\n",
    "    - If they match, returns `True`.\n",
    "\n",
    "3. **Check If Guess Matches Any Alternate Keywords**:\n",
    "    ```python\n",
    "    for s in alts:\n",
    "        if normalize(s) == normalize(guess):\n",
    "            return True\n",
    "    ```\n",
    "    - Iterates over each alternate keyword in `alts`.\n",
    "    - Normalizes and compares each alternate keyword with the normalized `guess`.\n",
    "    - If any match, returns `True`.\n",
    "\n",
    "4. **Return False If No Match**:\n",
    "    ```python\n",
    "    return False\n",
    "    ```\n",
    "    - If neither the keyword nor any alternates match the guess, returns `False`.\n",
    "\n",
    "The `keyword_guessed` function checks if a given guess matches the target keyword or any of its alternate keywords. It uses the `normalize` function to standardize the strings by removing punctuation, converting to lowercase, and removing spaces and the word \"the\". This ensures that the comparison is case-insensitive and ignores common variations like punctuation and extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.847051Z",
     "iopub.status.busy": "2024-06-01T17:52:53.846554Z",
     "iopub.status.idle": "2024-06-01T17:52:53.855991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.854737Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.847018Z"
    }
   },
   "outputs": [],
   "source": [
    "def html_renderer():\n",
    "    jspath = path.abspath(path.join(\"/kaggle/input/llm-20-questions/llm_20_questions\", \"llm_20_questions.js\"))\n",
    "    with open(jspath) as f:\n",
    "        return f.read()\n",
    "def keyword_guessed(guess: str) -> bool:\n",
    "    def normalize(s: str) -> str:\n",
    "      t = str.maketrans(\"\", \"\", string.punctuation)\n",
    "      return s.lower().replace(\"the\", \"\").replace(\" \", \"\").translate(t)\n",
    "    if normalize(guess) == normalize(keyword):\n",
    "      return True\n",
    "    for s in alts:\n",
    "      if normalize(s) == normalize(guess):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f8cb6c",
   "metadata": {},
   "source": [
    "### `call_llm` Function\n",
    "\n",
    "```python\n",
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    \n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "```\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "1. **Global Variables**:\n",
    "    ```python\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    ```\n",
    "    - Declares the use of global variables: `model_initialized`, `device`, `model`, and `tokenizer`.\n",
    "\n",
    "2. **Check Model Initialization**:\n",
    "    ```python\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "    ```\n",
    "    - Checks if the model has already been initialized.\n",
    "    - If not, it checks if the directory `llm_parent_dir` exists and contains files.\n",
    "\n",
    "3. **Load Model and Tokenizer**:\n",
    "    ```python\n",
    "    dirs = os.listdir(llm_parent_dir)\n",
    "    llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "    model_initialized = True\n",
    "    ```\n",
    "    - Lists the directories inside `llm_parent_dir`.\n",
    "    - Constructs the path to the model directory.\n",
    "    - Sets the device to GPU if available, otherwise uses CPU.\n",
    "    - Loads the T5 model and tokenizer from the specified directory and moves the model to the selected device.\n",
    "    - Sets `model_initialized` to `True` to avoid re-initialization in subsequent calls.\n",
    "\n",
    "4. **Handle Missing Model Directory**:\n",
    "    ```python\n",
    "    else:\n",
    "        print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "        print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "        raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    ```\n",
    "    - If the model directory does not exist or is empty, prints an error message and raises an exception.\n",
    "\n",
    "5. **Prepare Inputs for Model**:\n",
    "    ```python\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    ```\n",
    "    - Tokenizes the input `prompt` and converts it to PyTorch tensors.\n",
    "    - Moves the tensors to the selected device (CPU or GPU).\n",
    "\n",
    "6. **Generate Outputs**:\n",
    "    ```python\n",
    "    outputs = model.generate(**inputs)\n",
    "    ```\n",
    "    - Uses the model to generate outputs from the tokenized inputs.\n",
    "\n",
    "7. **Decode Outputs**:\n",
    "    ```python\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    return answer[0]\n",
    "    ```\n",
    "    - Decodes the generated outputs back into text, skipping special tokens.\n",
    "    - Returns the first element of the decoded outputs as the final answer.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The `call_llm` function is responsible for interacting with a pre-trained T5 model for generating responses based on a given prompt. It ensures that the model and tokenizer are loaded and initialized only once. If the model is not initialized, it loads the model and tokenizer from the specified directory, sets up the device (CPU/GPU), and marks the model as initialized. Then, it tokenizes the input prompt, generates a response using the model, decodes the response, and returns it as a string. If the model files are not found, it raises an exception and provides instructions for adding the required model files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.859146Z",
     "iopub.status.busy": "2024-06-01T17:52:53.858345Z",
     "iopub.status.idle": "2024-06-01T17:52:53.867991Z",
     "shell.execute_reply": "2024-06-01T17:52:53.866918Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.859113Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_llm(prompt: str) -> str:\n",
    "    global model_initialized\n",
    "    global device\n",
    "    global model\n",
    "    global tokenizer\n",
    "    if not model_initialized:\n",
    "        if os.path.exists(llm_parent_dir) and len(os.listdir(llm_parent_dir)) > 0:\n",
    "            dirs = os.listdir(llm_parent_dir)\n",
    "            llm_dir = \"{}/{}\".format(llm_parent_dir, dirs[0])\n",
    "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "            model = T5ForConditionalGeneration.from_pretrained(llm_dir).to(device)\n",
    "            tokenizer = T5Tokenizer.from_pretrained(llm_dir)\n",
    "            model_initialized = True\n",
    "        else:\n",
    "            print(\"t5-flan model required to use default agents. Add any version of the large model.\")\n",
    "            print(\"https://www.kaggle.com/models/google/flan-t5/frameworks/pyTorch/variations/large.\")\n",
    "            raise Exception(\"t5-flan model required to use default agents.\")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    print(prompt)\n",
    "    return answer[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345acc26",
   "metadata": {},
   "source": [
    "# Run/Debug\n",
    "\n",
    "*References:* \n",
    "1. [test_llm_20_questions.py](https://github.com/Kaggle/kaggle-environments/blob/master/kaggle_environments/envs/llm_20_questions/test_llm_20_questions.py)\n",
    "2. [Run/Debug LLM 20 Questions in a Notebook](https://www.kaggle.com/code/rturley/run-debug-llm-20-questions-in-a-notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.86985Z",
     "iopub.status.busy": "2024-06-01T17:52:53.869355Z",
     "iopub.status.idle": "2024-06-01T17:52:53.887698Z",
     "shell.execute_reply": "2024-06-01T17:52:53.886572Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.869817Z"
    }
   },
   "outputs": [],
   "source": [
    "from kaggle_environments import make\n",
    "def custom_questioner(obs):\n",
    "    if obs.turnType == \"guess\":\n",
    "        return \"banana\"\n",
    "    return \"Is it a banana?\"\n",
    "def custom_answerer():\n",
    "    return \"no\"\n",
    "def bad_answerer():\n",
    "    return \"maybe?\"\n",
    "def error_agent():\n",
    "    raise ValueError\n",
    "def test_llm_20_q_completes():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    game_output = env.run([guesser_agent, answerer_agent, guesser_agent, answerer_agent])\n",
    "    json = env.toJSON()\n",
    "    env.render(mode=\"ipython\", width=400, height=400)\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"DONE\"]\n",
    "def test_llm_20_q_errors_on_bad_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, bad_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_answer():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, custom_questioner, error_agent])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, 1, None]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"DONE\", \"ERROR\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 3\n",
    "def test_llm_20_q_errors_on_error_question():\n",
    "    env = make(\"llm_20_questions\", debug=True)\n",
    "    env.run([custom_questioner, custom_answerer, error_agent, custom_answerer])\n",
    "    json = env.toJSON()\n",
    "    assert json[\"name\"] == \"llm_20_questions\"\n",
    "    assert json[\"rewards\"] == [1, 1, None, 1]\n",
    "    assert json[\"statuses\"] == [\"DONE\", \"DONE\", \"ERROR\", \"DONE\"]\n",
    "    print(len(json[\"steps\"]))\n",
    "    assert len(json[\"steps\"]) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-01T17:52:53.889738Z",
     "iopub.status.busy": "2024-06-01T17:52:53.889163Z",
     "iopub.status.idle": "2024-06-01T17:55:15.400121Z",
     "shell.execute_reply": "2024-06-01T17:55:15.398007Z",
     "shell.execute_reply.started": "2024-06-01T17:52:53.889705Z"
    }
   },
   "outputs": [],
   "source": [
    "test_llm_20_q_completes()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 3047,
     "sourceId": 4261,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
