{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b25625e",
   "metadata": {},
   "source": [
    "# Notebook to show Simple Start\n",
    "\n",
    "Based on the excllent \"LLM 20 Questions Starter Notebook\"  \n",
    "\n",
    "However this is much more simpliffied in order to help to get started with prompt engineering quickly.    \n",
    "\n",
    "It is not as advanced as the \"LLM 20 Questions Starter Notebook\" and the prompts are taken directly from the \"LLM 20 Questions\" notebook supplied for the competition.  \n",
    "\n",
    "At the end there are cells to help test your prompts. \n",
    "\n",
    "Any issues/suggestions for improvements are welcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-22T10:58:08.236875Z",
     "iopub.status.busy": "2024-06-22T10:58:08.236492Z",
     "iopub.status.idle": "2024-06-22T10:58:22.292725Z",
     "shell.execute_reply": "2024-06-22T10:58:22.291888Z",
     "shell.execute_reply.started": "2024-06-22T10:58:08.236838Z"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /kaggle/working\n",
    "pip install -q -U -t /kaggle/working/submission/lib immutabledict sentencepiece\n",
    "git clone https://github.com/google/gemma_pytorch.git > /dev/null\n",
    "mkdir /kaggle/working/submission/lib/gemma/\n",
    "mv /kaggle/working/gemma_pytorch/gemma/* /kaggle/working/submission/lib/gemma/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df5319",
   "metadata": {},
   "source": [
    "**Add the model using Add Input**  \n",
    "This is found on the right hand side of the enivronment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T12:13:23.842116Z",
     "iopub.status.busy": "2024-06-22T12:13:23.841789Z",
     "iopub.status.idle": "2024-06-22T12:13:23.867408Z",
     "shell.execute_reply": "2024-06-22T12:13:23.866335Z",
     "shell.execute_reply.started": "2024-06-22T12:13:23.84209Z"
    }
   },
   "outputs": [],
   "source": [
    "# %%writefile submission/main.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    sys.path.insert(0, os.path.join(KAGGLE_AGENT_PATH, 'lib'))\n",
    "else:\n",
    "    sys.path.insert(0, \"/kaggle/working/submission/lib\")\n",
    "\n",
    "import contextlib\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from typing import Literal, List\n",
    "\n",
    "import torch\n",
    "from gemma.config import get_config_for_7b\n",
    "from gemma.model import GemmaForCausalLM\n",
    "\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    WEIGHTS_PATH = os.path.join(KAGGLE_AGENT_PATH, \"gemma/pytorch/7b-it-quant/2\")\n",
    "else:\n",
    "    WEIGHTS_PATH = \"/kaggle/input/gemma/pytorch/7b-it-quant/2\"\n",
    "\n",
    "\n",
    "# Set our own dataclass so we know what is in the object\n",
    "@dataclass\n",
    "class ObsData:\n",
    "    answers: List[\"str\"]\n",
    "    category: str\n",
    "    keyword: str\n",
    "    questions: List[\"str\"]\n",
    "    turn_type: Literal[\"ask\", \"guess\", \"answer\"]\n",
    "    \n",
    "\n",
    "class Agents:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "        # It is much better if you request a GPU session as a 7B model is rather large\n",
    "        self._device = torch.device(\"cpu\")\n",
    "        if torch.cuda.is_available():\n",
    "            self._device = torch.device(\"cuda:0\")\n",
    "    \n",
    "    def answer_agent(self, question: str, category: str, keyword: str) -> Literal[\"yes\", \"no\"]:\n",
    "        info_prompt = \"\"\"You are a very precise answerer in a game of 20 questions. The keyword that the questioner is trying to guess is [the {category} {keyword}]. \"\"\"\n",
    "        answer_question_prompt = f\"\"\"Answer the following question with only yes, no, or if unsure maybe: {question}\"\"\"\n",
    "    \n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(category=category, keyword=keyword),\n",
    "            answer_question_prompt\n",
    "        )\n",
    "        \n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "    def ask_agent(self, questions: List[str], answers: List[str]) -> str:\n",
    "        info_prompt = \"\"\"You are playing a game of 20 questions where you ask the questions and try to figure out the keyword, which will be a real or fictional person, place, or thing. \\nHere is what you know so far:\\n{q_a_thread}\"\"\"\n",
    "        questions_prompt = \"\"\"Ask one yes or no question.\"\"\"\n",
    "\n",
    "        q_a_thread = \"\"\n",
    "        for i in range(0, len(answers)):\n",
    "            q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "                q_a_thread,\n",
    "                questions[i],\n",
    "                answers[i]\n",
    "            )\n",
    "    \n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            questions_prompt\n",
    "        )\n",
    "\n",
    "        return self._call_llm(prompt)\n",
    "\n",
    "    \n",
    "    def guess_agent(self, questions: List[str], answers: List[str]) -> str:\n",
    "        # It is expected that the answer is surrounder by **         \n",
    "        info_prompt = \"\"\"You are playing a game of 20 questions where you ask the questions and try to figure out the keyword, which will be a real or fictional person, place, or thing. \\nHere is what you know so far:\\n{q_a_thread}\"\"\"\n",
    "        guess_prompt = \"\"\"Guess the keyword. Only respond with the exact word/phrase. For example, if you think the keyword is [paris], don't respond with [I think the keyword is paris] or [Is the kewyord Paris?]. Respond only with the word [paris].\"\"\"\n",
    "\n",
    "        q_a_thread = \"\"\n",
    "        for i in range(0, len(answers)):\n",
    "            q_a_thread = \"{}Q: {} A: {}\\n\".format(\n",
    "                q_a_thread,\n",
    "                questions[i],\n",
    "                answers[i]\n",
    "            )\n",
    "        \n",
    "        prompt = \"{}{}\".format(\n",
    "            info_prompt.format(q_a_thread=q_a_thread),\n",
    "            guess_prompt\n",
    "        )\n",
    "\n",
    "        return f\"**{self._call_llm(prompt)}**\"\n",
    "    \n",
    "    def _call_llm(self, prompt: str):\n",
    "        self._set_model()\n",
    "        \n",
    "        sampler_kwargs = {\n",
    "            'temperature': 0.01,\n",
    "            'top_p': 0.1,\n",
    "            'top_k': 1,\n",
    "        }\n",
    "        \n",
    "        return self.model.generate(\n",
    "            prompt,\n",
    "            device=self._device,\n",
    "            output_len=100,\n",
    "            **sampler_kwargs,\n",
    "        )\n",
    "         \n",
    "    def _set_model(self):\n",
    "        if self.model is None:\n",
    "            print(\"No model yet so setting up\")\n",
    "            model_config = get_config_for_7b()\n",
    "            model_config.tokenizer = os.path.join(WEIGHTS_PATH, \"tokenizer.model\")\n",
    "            model_config.quant = True\n",
    "\n",
    "            # Not using a context manager blows the stack\n",
    "            with self._set_default_tensor_type(model_config.get_dtype()):\n",
    "                model = GemmaForCausalLM(model_config)\n",
    "                ckpt_path = os.path.join(WEIGHTS_PATH , f'gemma-7b-it-quant.ckpt')\n",
    "                model.load_weights(ckpt_path)\n",
    "                self.model = model.to(self._device).eval()\n",
    "    \n",
    "    @contextlib.contextmanager\n",
    "    def _set_default_tensor_type(self, dtype: torch.dtype):\n",
    "        \"\"\"Set the default torch dtype to the given dtype.\"\"\"\n",
    "        torch.set_default_dtype(dtype)\n",
    "        yield\n",
    "        torch.set_default_dtype(torch.float)\n",
    "\n",
    "# The entry point so name and paramters are preset\n",
    "def agent_fn(obs, cfg) -> str:\n",
    "    obs_data = ObsData(\n",
    "        turn_type=obs.turnType,\n",
    "        questions=obs.questions,\n",
    "        answers=obs.answers,\n",
    "        keyword=obs.keyword,\n",
    "        category=obs.category\n",
    "    )\n",
    "    \n",
    "    if obs_data.turn_type == \"ask\":\n",
    "        response = agents.ask_agent(questions=obs.questions, answers=obs.answers)\n",
    "    if obs_data.turn_type == \"guess\":\n",
    "        response = agents.guess_agent(questions=obs.questions, answers=obs.answers)\n",
    "    if obs_data.turn_type == \"answer\":\n",
    "        response = agents.answer_agent(question=obs.questions[-1], category=obs.category, keyword=obs.keyword)\n",
    "    \n",
    "    if response is None or len(response) <= 1:\n",
    "        return \"yes\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Instantiate the agents class so the model is only set once\n",
    "agents = Agents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T12:13:27.586335Z",
     "iopub.status.busy": "2024-06-22T12:13:27.585486Z",
     "iopub.status.idle": "2024-06-22T12:14:15.05232Z",
     "shell.execute_reply": "2024-06-22T12:14:15.051301Z",
     "shell.execute_reply.started": "2024-06-22T12:13:27.586289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually run the answer agent\n",
    "@dataclass\n",
    "class ObsDataIn(ObsData):\n",
    "    turnType: str\n",
    "    \n",
    "obs_data = ObsDataIn(\n",
    "        turn_type=\"\",\n",
    "        turnType=\"answer\",\n",
    "        questions=[\"Is it a place\"],\n",
    "        answers=[],\n",
    "        keyword=\"Antartica\",\n",
    "        category=\"Place\"\n",
    "    )\n",
    "\n",
    "print(agent_fn(obs_data, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T12:14:39.010378Z",
     "iopub.status.busy": "2024-06-22T12:14:39.009974Z",
     "iopub.status.idle": "2024-06-22T12:15:20.042528Z",
     "shell.execute_reply": "2024-06-22T12:15:20.041506Z",
     "shell.execute_reply.started": "2024-06-22T12:14:39.010344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually run the question agent\n",
    "@dataclass\n",
    "class ObsDataIn(ObsData):\n",
    "    turnType: str\n",
    "    \n",
    "obs_data = ObsDataIn(\n",
    "        turn_type=\"\",\n",
    "        turnType=\"ask\",\n",
    "        questions=[\"Is it a place?\"],\n",
    "        answers=[\"Yes\"],\n",
    "        keyword=\"\",\n",
    "        category=\"\"\n",
    "    )\n",
    "\n",
    "print(agent_fn(obs_data, {}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T12:15:51.259776Z",
     "iopub.status.busy": "2024-06-22T12:15:51.259369Z",
     "iopub.status.idle": "2024-06-22T12:16:32.830569Z",
     "shell.execute_reply": "2024-06-22T12:16:32.829575Z",
     "shell.execute_reply.started": "2024-06-22T12:15:51.259747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Manually run the guess agent\n",
    "@dataclass\n",
    "class ObsDataIn(ObsData):\n",
    "    turnType: str\n",
    "    \n",
    "obs_data = ObsDataIn(\n",
    "        turn_type=\"\",\n",
    "        turnType=\"guess\",\n",
    "        questions=[\"Is it a place?\", \"Is it in the northen hemisphere?\", \"Is it a city?\", \"Is it icy?\"],\n",
    "        answers=[\"Yes\", \"No\", \"No\", \"Yes\"],\n",
    "        keyword=\"\",\n",
    "        category=\"\"\n",
    "    )\n",
    "\n",
    "print(agent_fn(obs_data, {}))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 8749,
     "sourceId": 11359,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
