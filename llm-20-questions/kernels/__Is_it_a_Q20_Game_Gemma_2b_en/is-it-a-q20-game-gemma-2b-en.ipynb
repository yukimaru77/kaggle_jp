{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eedfbb5",
   "metadata": {},
   "source": [
    "Published on May 15, 2024. By Mar√≠lia Prata, mpwolke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-16T01:26:47.351907Z",
     "iopub.status.busy": "2024-05-16T01:26:47.351567Z",
     "iopub.status.idle": "2024-05-16T01:26:48.447237Z",
     "shell.execute_reply": "2024-05-16T01:26:48.446456Z",
     "shell.execute_reply.started": "2024-05-16T01:26:47.351879Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6072685f",
   "metadata": {},
   "source": [
    "#Competition Citation\n",
    "\n",
    "@misc{llm-20-questions,\n",
    "    author = {Zoe Mongan, Luke Sernau, Will Lifferth, Bovard Doerschuk-Tiberi, Ryan Holbrook, Will Cukierski, Addison Howard},\n",
    "    title = {LLM 20 Questions},\n",
    "    publisher = {Kaggle},\n",
    "    year = {2024},\n",
    "    url = {https://kaggle.com/competitions/llm-20-questions}\n",
    "}\n",
    "\n",
    "#Is it a Bird? Is it a Plane? No, It's a kaggler!\n",
    "\n",
    "![](https://img1.picmix.com/output/pic/normal/5/6/8/3/11323865_2f559.gif)https://en.picmix.com/pic/bird-plane-bert-11323865\n",
    "\n",
    "#Q20 Game with Reinforcement Learning\n",
    "\n",
    "Playing 20 Question Game with Policy-Based Reinforcement Learning\n",
    "\n",
    "Authors: Huang Hu1, Xianchao Wu, Bingfeng Luo, Chongyang Tao,Can Xu, Wei Wu and Zhan Chen\n",
    "\n",
    "\"In this paper,the authors proposed a novel policy-based Reinforce-ment Learning (RL) method, which enables the questioner agent to learn the optimal pol-icy of question selection through continuous interactions with users. To facilitate training,they also proposed to use a reward network to estimate the more informative reward. Compared to previous methods, their RL method is robust to noisy answers and does not rely onthe Knowledge Base of objects. Experimental results show that our RL method clearly outperforms an entropy-based engineering system and has competitive performance in a noisy-free simulation environment.\"\n",
    "\n",
    "\"It is not easy to design the algorithm to construct a Q20 game system. Although the decision tree based method seems like a natural fit to the Q20 game, it typically require a well defined Knowledge Base (KB) that contains enough information about each object, which is usually not available in practice. It was used a object-question relevance table as the pivot for question and object selection, which does not depend on an existing KB (Knowledge Base). Further it was improved the relevance table with a lot of engineering tricks. Since these table-based methods greedily select questions and the model parameters are only updated by rules, their models are very sensitive to noisy answers from users, which is common in the real-world Q20 games. It was utilized a value-based Reinforcement Learning (RL) model to improve the generalization ability but still relies on the existing KB.\n",
    "\n",
    "\"In this paper, the authors formulated the process of question selection in the game as a Markov Decision Process (MDP), and further propose a novel policy-based RL framework to learn the optimal\n",
    "policy of question selection in the Q20 game. Their questioner agent maintains a probability distribution over all objects to model the confidence of the target object, and updates the confidence based on answers from the user.\"\n",
    "\n",
    "\"At each time-step the agent uses a policy network to take in the confidence vector and output a question distribution for selecting the next question. To solve the problem that there is no immediate reward for each selected question, the authors also proposed to employ a RewardNet to estimate the appropriate immediate reward at each time-step, which is further used to calculate the long-term return to train their RL model.\"\n",
    "\n",
    "\"Their RL (Reinforcement Learning) framework makes the agent robust to noisy answers since the model parameters are fully learnable and the question distribution provides us with a principled way to sample questions, which enables the agent to jump out of the local optimum caused by incorrect answers and also introduces more randomness during training to improve the model generalization ability. Furthermore, the ability to sample questions, compared to greedy selection, also improves the diversity of the questions asked by their agent, which is crucial for user experience.\"\n",
    "\n",
    "https://www.researchgate.net/publication/327199595_Playing_20_Question_Game_with_Policy-Based_Reinforcement_Learning\n",
    "\n",
    "#The llm_20_questions json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:30.842511Z",
     "iopub.status.busy": "2024-05-16T00:56:30.841999Z",
     "iopub.status.idle": "2024-05-16T00:56:30.876504Z",
     "shell.execute_reply": "2024-05-16T00:56:30.875373Z",
     "shell.execute_reply.started": "2024-05-16T00:56:30.842476Z"
    }
   },
   "outputs": [],
   "source": [
    "#df = pd.read_json(path_or_buf='/kaggle/input/llm-20-questions/llm_20_questions/llm_20_questions.json')\n",
    "\n",
    "#df= pd.read_json('../input/llm-20-questions/llm_20_questions/llm_20_questions.json', lines=True)\n",
    "df= pd.read_json('../input/llm-20-questions/llm_20_questions/llm_20_questions.json', typ=\"series\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194ff328",
   "metadata": {},
   "source": [
    "#Near the arrows we have: agents, configuration, reward, observation, action and status\n",
    "\n",
    "I got Error \"Mixing dicts with non-Series may lead to ambiguous ordering\"\n",
    "\n",
    "Because the data types are all over the place, some strings, some lists, multiple {} etc. This error may be solved by normalizing the data.\n",
    "\n",
    "https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:35.970937Z",
     "iopub.status.busy": "2024-05-16T00:56:35.970288Z",
     "iopub.status.idle": "2024-05-16T00:56:35.977922Z",
     "shell.execute_reply": "2024-05-16T00:56:35.97699Z",
     "shell.execute_reply.started": "2024-05-16T00:56:35.970902Z"
    }
   },
   "outputs": [],
   "source": [
    "#Mpwolke https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series\n",
    "\n",
    "#StackOverflow: https://stackoverflow.com/questions/49505872/read-json-to-pandas-dataframe-valueerror-mixing-dicts-with-non-series-may-lea\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "ques = json.load(open('../input/llm-20-questions/llm_20_questions/llm_20_questions.json'))\n",
    "\n",
    "df = pd.DataFrame(ques[\"observation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:41.397293Z",
     "iopub.status.busy": "2024-05-16T00:56:41.396915Z",
     "iopub.status.idle": "2024-05-16T00:56:41.4194Z",
     "shell.execute_reply": "2024-05-16T00:56:41.418396Z",
     "shell.execute_reply.started": "2024-05-16T00:56:41.39726Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:46.507035Z",
     "iopub.status.busy": "2024-05-16T00:56:46.506181Z",
     "iopub.status.idle": "2024-05-16T00:56:46.518447Z",
     "shell.execute_reply": "2024-05-16T00:56:46.517366Z",
     "shell.execute_reply.started": "2024-05-16T00:56:46.507001Z"
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(ques[\"configuration\"])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a1f92",
   "metadata": {},
   "source": [
    "#Transpose Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:51.44785Z",
     "iopub.status.busy": "2024-05-16T00:56:51.447108Z",
     "iopub.status.idle": "2024-05-16T00:56:51.459589Z",
     "shell.execute_reply": "2024-05-16T00:56:51.458641Z",
     "shell.execute_reply.started": "2024-05-16T00:56:51.447815Z"
    }
   },
   "outputs": [],
   "source": [
    "df1_transposed = df1.T\n",
    "df1_transposed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T00:56:56.304742Z",
     "iopub.status.busy": "2024-05-16T00:56:56.303824Z",
     "iopub.status.idle": "2024-05-16T00:56:56.31415Z",
     "shell.execute_reply": "2024-05-16T00:56:56.313011Z",
     "shell.execute_reply.started": "2024-05-16T00:56:56.304705Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(ques[\"status\"])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169218cb",
   "metadata": {},
   "source": [
    "#Install Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T01:27:27.888979Z",
     "iopub.status.busy": "2024-05-16T01:27:27.888524Z",
     "iopub.status.idle": "2024-05-16T01:28:12.99439Z",
     "shell.execute_reply": "2024-05-16T01:28:12.993421Z",
     "shell.execute_reply.started": "2024-05-16T01:27:27.888952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp\n",
    "!pip install -q -U keras>=3\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\"\n",
    "\n",
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745280a1",
   "metadata": {},
   "source": [
    "#Gemma_2b_en\n",
    "\n",
    "The initial Notebook was suppose to apply Gemma 7b however I got an expected error that I wasn't able to solve. Then, I tried to use Gemma 2b. Though I don't have a dataset with the questions I intended to make. In other words, it jinxed. One more for my collection of jinxed code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-05-16T01:28:15.748731Z",
     "iopub.status.busy": "2024-05-16T01:28:15.748018Z",
     "iopub.status.idle": "2024-05-16T01:30:02.607736Z",
     "shell.execute_reply": "2024-05-16T01:30:02.606631Z",
     "shell.execute_reply.started": "2024-05-16T01:28:15.748687Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma_2b_en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b782452",
   "metadata": {},
   "source": [
    "#All the answers are Yes, except the last one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-16T01:30:10.552435Z",
     "iopub.status.busy": "2024-05-16T01:30:10.551987Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Is Gemma, an open model based on Google's Gemini models?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Is Gemma a lightweight, text-to-text, decoder-only large language model?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Is Gemma a support low-latency generative AI used in cases such as streaming text?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Has Gemma 27 billion parameters?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Is LLaVA-Gemma, a MMFM that leverages the powerful Gemma language models for efficient multimodal interactions?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Is JAX a framework developed by Google?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Are you a model Gemma?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_lm.generate(\"Are you participating on this Q20 game Gemma?\", max_length=1024))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04480364",
   "metadata": {},
   "source": [
    "![](https://www.wallyandosborne.com/wp-content/uploads/2006/02/2005-11-01.gif)https://www.wallyandosborne.com/wp-content/uploads/2006/02/2005-11-01.gif\n",
    "\n",
    "#Acknowledgements:\n",
    "\n",
    "mpwolke https://www.kaggle.com/code/mpwolke/eureka-gemma-1-1-instruct-7b-en\n",
    "\n",
    "https://www.kaggle.com/code/mpwolke/thanks-for-delivering-my-writeup-order-gemma/notebook\n",
    "\n",
    "mpwolke https://www.kaggle.com/code/mpwolke/trafic-json-mixing-dicts-with-non-series"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 5388,
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
