{
    "main_topic": {
        "author": "d1v1s10n_by_zer0",
        "title": "Why is the oldest agent being deleted and not the agent with the worst results?",
        "content": "I would like to try new hypotheses, but for that I have to remove the agent with the highest rating. Is it possible to replace new agents with the worst of my attempts rather than the best (in my case, it coincides with the oldest shipment)?\n\n",
        "date": "Thu Jul 11 2024 08:23:29 GMT+0900 (日本標準時)",
        "votes": "4"
    },
    "comments": [
        {
            "author": "Jasper Butcher",
            "content": "Doesn't seem so. Just lose the ego & document the old code, rankings don't matter.\n\n",
            "date": "Posted 23 days ago  ·  36th in this Competition",
            "votes": "1",
            "reply": [
                {
                    "author": "Hadeka",
                    "content": "What do u mean by “ranking don’t matter”?\n\nIsn’t an evidence that this code can overcome others, and can somehow defend itself from other codes to overcome it?\n\nOr am I missing something?\n\n",
                    "date": "Posted 23 days ago  ·  169th in this Competition",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "Jasper Butcher",
                            "content": "You're right, perhaps it's a bit of a blanket statement but I mean in the long-term they won't provide you much information because I've found the rankings are super volatile.\n\nI submitted 3 identical bots, and after 3 days they had scores ranging from 800, 700 and 500. You win once by chance, you shoot up, you lose once, you're stuck with lobotomized bots which give you no information whatsoever. I simply don't have time to wait a week for the rankings to stabilize - even then though, this is very slow signal.\n\nIt's really really hard to submit one decent bot, make some changes, and submit an improved one and use the difference in ranking to see if that truly improved it.\n\nI'm leaning towards trying to test bots offline? Not sure if people have tried doing this?\n\n",
                            "date": "Posted 23 days ago  ·  36th in this Competition",
                            "votes": "1",
                            "reply": []
                        },
                        {
                            "author": "Hadeka",
                            "content": "Well I totally agree with you.\n\nI’ve did the same actually, submitted 3 identical agents, their score ranged from 470 to 890. My rank was 360, then after few hours, I’m the 20th! All with the same agent, same submission.\n\nMy 3 identical agents, one kept around 400, the second is around 600, and the third between 800 and 900!\n\nIt’s not really weird, but stabilizing LLM generations  is actually too hard, almost impossible to do it 100%. We tried a lot in the past AIMO here on Kaggle, but you can only relatively reduce its instability, but you cannot eliminate it. That’s anyway one of the key factors that define LLMs, but for that kind of research (and competitions), it’s really annoying.\n\nI was thinking about testing it offline, but haven’t done so, yet.\n\n",
                            "date": "Posted 22 days ago  ·  169th in this Competition",
                            "votes": "2",
                            "reply": []
                        },
                        {
                            "author": "Jasper Butcher",
                            "content": "My guess is that testing offline wouldn't be needed as much if we could just select one bot to put all of our games quota to. Best work-around is just to submit all of your daily allowance. I sympathise with the hosts though, not an easy competition to run!\n\n",
                            "date": "Posted 22 days ago  ·  36th in this Competition",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                }
            ]
        }
    ]
}