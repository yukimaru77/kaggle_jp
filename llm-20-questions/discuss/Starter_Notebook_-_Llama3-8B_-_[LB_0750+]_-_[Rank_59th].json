{
    "main_topic": {
        "author": "Chris Deotte",
        "title": "Starter Notebook - Llama3-8B - [LB 0.750+] - [Rank 59th]",
        "content": "Hi everyone! I'm sharing my current submission which is currently achieving public LB 0.750+ and public LB rank 59th! (And before keyword update, this notebook was achieving 1st place public LB ðŸ¥‡ ðŸ˜€ ). The notebook is [here](https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750). Enjoy!\n\n## Good Stuff\n\nThis notebook has some problems (i.e. it uses some fixed keywords), but it also has a lot of helpful code to demonstrate stuff. The helpful things this notebook demonstrates are as follows:\n\n- A strategy how to ask questions to narrow down search (and use a CSV of features behind the scenes).\n\n- How to install pip libraries to be used during submission\n\n- How to download and use any LLM model from Hugging Face\n\n- How to perform EDA on your LLM's answering ability\n\n- How to create agent code and create tarball for submission\n\n- How to run Kaggle's API to watch your agent locally\n\n## Bad Stuff\n\nSome problems with this notebook are:\n\n- uses (an old list of) fixed keywords which may change during private LB. (And have changed on public LB.)\n\n- only asks questions about places (i.e. (1) which sub-category? (city, country, landmark), (2) which continent?, (3) which first letter? It does not ask questions about things) \n\n## How To Improve\n\nNote that even if private LB keywords change, we can use this notebook's template and strategy to create a notebook which selects thousands or millions of words from Wikipedia and uses that list as a list of all potential keywords. \n\nThen we create new columns in that dataframe with additional features describing all the words and we create pre-determined questions asking if keyword has these additional featuers. Finally we make guesses based on the keywords in our created dataframe (with additonal column features) and the answerer's responses about features.\n\n# Starter Code\n\nThe starter code is [here](https://www.kaggle.com/code/cdeotte/starter-code-for-llama-8b-llm-lb-0-750).\n\n",
        "date": "Tue Jul 16 2024 09:54:06 GMT+0900 (æ—¥æœ¬æ¨™æº–æ™‚)",
        "votes": "59"
    },
    "comments": [
        {
            "author": "mxmm2123",
            "content": "great job!!!\n\n",
            "date": "Posted 12 days ago",
            "votes": "1",
            "reply": []
        },
        {
            "author": "Rishit Jakharia",
            "content": "Hey!, Thanks for sharing the notebook,\n\nI noticed you used fp4 quantization in your implementation for the llama 3 model..\n\nWanted to ask whether you tried GGUF quantization, if yes what were the results compared to the current implementation\n\n",
            "date": "Posted 19 days ago",
            "votes": "1",
            "reply": [
                {
                    "author": "Chris DeotteTopic Author",
                    "content": "Hi. I have not tried GGUF quantization. In another project (i.e. not Kaggle's 20 question comp), I have tried AWQ quantization with Hugging Face's AutoModelForCausalLM and it was very slow compared with fp4. So when we evaluate GGUF, we must also consider its speed to.\n\n",
                    "date": "Posted 19 days ago  Â·  625th in this Competition",
                    "votes": "1",
                    "reply": [
                        {
                            "author": "Rishit Jakharia",
                            "content": "Okay, thanks !\n\n",
                            "date": "Posted 19 days ago",
                            "votes": "1",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "Valentin Baltazar",
            "content": "This is great for beginners like me! Thank you.\n\n",
            "date": "Posted 20 days ago  Â·  146th in this Competition",
            "votes": "1",
            "reply": []
        },
        {
            "author": "torino",
            "content": "[@cdeotte](https://www.kaggle.com/cdeotte) Thank you for sharing the notebook. I was see you installed python package offline, but in my notebook I can't install new pytorch for the submit environment(It worked well on the normal notebook). Do you have any suggestion? You can see my issue [here](https://www.kaggle.com/competitions/llm-20-questions/discussion/520207)\n\n",
            "date": "Posted 20 days ago  Â·  61st in this Competition",
            "votes": "2",
            "reply": []
        }
    ]
}