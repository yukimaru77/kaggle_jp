{
    "main_topic": {
        "author": "Matthew S Farmer",
        "title": "Llama 3.1 Hack - Confirmed to Work in Kaggle Environment (Notebooks and Competition)",
        "content": "# Llama 3.1\n\nSo, you saw the latest release of Llama 3.1 and thought to yourself \"I bet this would be good in the LLM 20 Questions competition\". Then you fired up a notebook, imported the model, attempted to load it, then were faced with an error about RoPE scaling… You jump on the discussion board and don't find any help. You look online and all the posts say \"update transformers\". You do that and the notebook works, but then you get that pesky validation error. What are we to do! As any tinkerers or hackers know, there's always a workaround somewhere…\n\n## We have a workaround!\n\nI have validated that this works in the notebook and game environment without updating transformers. \n\n```\nimport json\nwith open(\"YOUR_LOCAL_MODEL_PATH/config.json\", \"r\") as file:\n    config = json.load(file)\nconfig[\"rope_scaling\"] = {\"factor\":8.0,\"type\":\"dynamic\"}\nwith open(\"YOUR_LOCAL_MODEL_PATH/config.json\", \"w\") as file:\n    json.dump(config, file)\n\n```\n\n## Implementation\n\nRemove any updates to transformers that you were trying.\nImport your desired llama 3.1 model to your working folder\nValidate the path to config.json in that folder and replace the all caps path in the code above.\nAdd the code in a code block that precedes your submission .py script and tarball submission. \nLoad the model and script as you normally would. \nValidate text generation in the notebook if desired.\nPrepare your script for submission, ensuring that the updated config file is zipped with the model. \nEnjoy the green checkmark after validation. \n\nI hope this raises the bar for everyone in this competition as we approach the final evaluation. May the best agents win!\n\n## TL;DR\n\nModify config.json to a dictionary that the current version of Transformers expects (2 fields). \n\nCheers! Happy Kaggling \n\nIf you have questions about RoPE scaling, check out [the docs! ](https://huggingface.co/docs/text-generation-inference/en/basic_tutorials/preparing_model)\n\n",
        "date": "Fri Aug 02 2024 04:34:42 GMT+0900 (日本標準時)",
        "votes": "17"
    },
    "comments": [
        {
            "author": "VolodymyrBilyachat",
            "content": "Legend! thank you for this simple hack :)\n\n",
            "date": "Posted a day ago  ·  214th in this Competition",
            "votes": "0",
            "reply": []
        }
    ]
}