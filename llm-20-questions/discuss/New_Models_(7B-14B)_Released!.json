{
    "main_topic": {
        "author": "Chris Deotte",
        "title": "New Models (7B-14B) Released!",
        "content": "There have been many new models released in the past 1-2 months. Have people tried these new models? How is their performance?\n\n- Gemma2-9B-IT [here](https://huggingface.co/google/gemma-2-9b-it)\n\n- (Nvidia) Mistral-Nemo-Instruct-2407 (12B) [here](https://huggingface.co/mistralai/Mistral-Nemo-Instruct-2407)\n\n- (Nvidia) Minitron-8B-base [here](https://huggingface.co/nvidia/Minitron-8B-Base)\n\n- Apple-DCLM-7B [here](https://huggingface.co/apple/DCLM-7B)\n\n- Llama-3.1-8B-Instruct [here](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct)\n\n- Qwen2-7B-Instruct [here](https://huggingface.co/Qwen/Qwen2-7B-Instruct)\n\n- Phi-3-Mini-4k-Instruct (4B) [here](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct)\n\n- Phi-3-Medium-4k-Instruct (14B) [here](https://huggingface.co/microsoft/Phi-3-medium-4k-instruct)\n\n",
        "date": "Mon Jul 29 2024 06:07:11 GMT+0900 (日本標準時)",
        "votes": "17"
    },
    "comments": [
        {
            "author": "Matthew S Farmer",
            "content": "gemma 2 - loves to answer in markdown, gives some generic answers, great at following instructions, seems like a good contended for this comp if it can get its things category vocab a bit higher. \n\nmistral variants (nemo int and minitron) - difficult to constraint and follow instructions. \n\nllama 3.1 - get ROPE error in kaggle env \n\nQwen2 7b - great at following instructions but fails to get specific on keyword answers\n\nPhi3 mini - all around good at the three roles, limited vocabulary in the things category\n\nPhi3 medium - interestingly worse than phi3 mini? I had a very difficult time keeping this model from getting philisophical as questioner and guesser, despite multiple attempts. Implemented as AWQ, perhaps quantization affects it's instruction training? \n\nI keep going back to community fine tunings of LLaMa 3… getting the best results there. \n\nMaziyarPanahi/Llama-3-8B-Instruct-v0.10\n\nmlabonne/Daredevil-8B\n\nopenchat/openchat-3.6-8b-20240522\n\n",
            "date": "Posted 6 days ago  ·  69th in this Competition",
            "votes": "12",
            "reply": [
                {
                    "author": "Chris DeotteTopic Author",
                    "content": "Thank you for the comprehensive summary. Great experiments.\n\n",
                    "date": "Posted 6 days ago  ·  625th in this Competition",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "OminousDude",
                            "content": "I have tried most of the above models and can give a more accurate description of which models to use and why.\n\nGemma 2: This will give errors unless huggingface is upgraded (I think that the kaggle env. still uses old version where \"Gemma2ForCasualLM\" is not supported). Furthermore, this is a very good model with the current highest scores in the LLM Leaderboard for its param count. However, as this model just came out it has poor finetuning. What I mean by this is that most models (for example llama 3) have many finetuned variants (Smaug and others) which each help in some ways and are worse in others, to me the perfect model is not Gemma 2 since it does not have these yet. I think that since Gemma 2 is not meant for LLM 20Q some models that are finetuned on similar tasks could outrank it.\n\nMistral + Variants: Like Mathew said above these are difficult to instruct and anyone with a sophisticated prompt is out of luck. I do however think that Nemo can be different that the others because it has the current best tokenizer (out of the smaller models), Tekken, as explained [here](https://mistral.ai/news/mistral-nemo/)\n\nLlama 3.1: Very, very promising but has an error when loading if the loading error is fixed we may see only llama 3.1 in the top places at the end. However, only time will tell and if someone can get this model to work this competition could be ruled by Llama 3.1\n\nQwen2: I disagree with Mathew on this one and the statistics favor me too. I do not beleive this model is great at following robust directions from my testing and from the [LLM Leaderboard](https://huggingface.co/spaces/open-llm-leaderboard/open_llm_leaderboard). On the IFEval score (this explains how well it is at following instructions) it scores a 31.49 (its instruct variant scores a 56.79); however, compared to Llama 3 it is outmatched by quite a bit because Llama 3 gets 74.08 (this is the instruct score). Furthermore, Llama 3.1 gets 77.40 which is more than 20 points ahead. However, Qwen is a good answerer and makes good questions (however it is bad at instruction following)\n\nPhi 3 mini & medium: Mini performs better but it was trained on much less data so it doesn't know many objects/things. Medium is likely the bot that gave [these](https://www.kaggle.com/competitions/llm-20-questions/discussion/519297) flat earth questions, because like Matt said it sometimes asks questions when it is questioner.\n\nI hope this helps you understand the reasons in which Matt made the above statements.\n\nPS: The best strategy to use is obviously alphabetical bisection because it has such a high score on the public leaderboard.\n\n",
                            "date": "Posted 6 days ago  ·  503rd in this Competition",
                            "votes": "4",
                            "reply": []
                        }
                    ]
                },
                {
                    "author": "G R Shanker Sai",
                    "content": "Hello [@matthewsfarmer](https://www.kaggle.com/matthewsfarmer) ,\n\nThank you for you insight on this, just wanted to understand, that by \"community fine tunings of LLaMa 3\", are you referring to the different flavours of llama 3 present in hugging face, or you are fine tuning it with your own data?\n\n",
                    "date": "Posted 4 days ago  ·  584th in this Competition",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "Matthew S Farmer",
                            "content": "Yes, on huggingface. I listed a few at the bottom of my comment. I've also fine tuned a model but the HF ones are too good! \n\n",
                            "date": "Posted 4 days ago  ·  69th in this Competition",
                            "votes": "0",
                            "reply": []
                        }
                    ]
                },
                {
                    "author": "Matthew S Farmer",
                    "content": "RoPE error solved: [https://www.kaggle.com/competitions/llm-20-questions/discussion/523619](https://www.kaggle.com/competitions/llm-20-questions/discussion/523619)\n\n",
                    "date": "Posted 3 days ago  ·  69th in this Competition",
                    "votes": "2",
                    "reply": []
                }
            ]
        },
        {
            "author": "Muhammad Ehsan",
            "content": "(Written by ChatGPT-4o)\n\nBelow a bit more detail on each: \n\n- Gemma2-9B-IT: \n\nThis model has 9 billion parameters and is designed for detailed comprehension and complex tasks. It's useful for applications that require a deep understanding of context and nuance.\n\n- Mistral-Nemo-Instruct-2407: \n\nWith 12 billion parameters, this model is optimized for instructional tasks, meaning it's particularly good at following and executing specific instructions given to it.\n\n- Minitron-8B-base: \n\nAn 8 billion parameter model that serves as a general-purpose base model. It's versatile and can be used for a wide range of tasks, though it might not have specialized capabilities compared to others.\n\n- Apple-DCLM-7B: \n\nThis model, developed by Apple, has 7 billion parameters. It's aimed at various applications and might include unique features or optimizations specific to Apple's ecosystem.\n\n- Llama-3.1-8B-Instruct: \n\nThis version of Llama, with 8 billion parameters, is tailored for tasks that involve following instructions or guidelines. It’s built to better understand and act on specific commands.\n\n- Qwen2-7B-Instruct: \n\nAnother instruction-focused model with 7 billion parameters. It’s designed to interpret and respond to detailed instructions effectively.\n\n- Phi-3-Mini-4k-Instruct: \n\nThis smaller model has 4 billion parameters and is optimized for following instructions, suitable for tasks that don’t require extensive processing power but need good command-following abilities.\n\n- Phi-3-Medium-4k-Instruct: \n\nA medium-sized model with 14 billion parameters, this one is also geared towards instruction-following tasks, offering more processing power and complexity compared to the smaller versions.\n\n",
            "date": "Posted 5 days ago  ·  108th in this Competition",
            "votes": "0",
            "reply": [
                {
                    "author": "OminousDude",
                    "content": "Which model did you use to write this response? Was it llama 3? Looks AI generated to me…\n\n",
                    "date": "Posted 5 days ago  ·  503rd in this Competition",
                    "votes": "2",
                    "reply": []
                },
                {
                    "author": "fufu2022",
                    "content": "Thank you! Gemma2-9B-IT and Llama-3.1-8B are the best for me.\n\n",
                    "date": "Posted 5 days ago",
                    "votes": "0",
                    "reply": [
                        {
                            "author": "torino",
                            "content": "Hi [@fufu2022](https://www.kaggle.com/fufu2022) ,\n\nHow do you load llama3.1 on the submit environment? f it is not a secret, can you share it?\n\n",
                            "date": "Posted 5 days ago  ·  61st in this Competition",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "OminousDude",
                            "content": "I don't think he does not sure if anyone has succeeded with it yet. I think he just thinks it will work well.\n\n",
                            "date": "Posted 3 days ago  ·  503rd in this Competition",
                            "votes": "0",
                            "reply": []
                        },
                        {
                            "author": "Matthew S Farmer",
                            "content": "I developed a [solution today. ](https://www.kaggle.com/competitions/llm-20-questions/discussion/523619)\n\n",
                            "date": "Posted 3 days ago  ·  69th in this Competition",
                            "votes": "1",
                            "reply": []
                        }
                    ]
                }
            ]
        },
        {
            "author": "francesco fiamingo",
            "content": "wow! thanks , few of them i explored (mistral,llama,qwen) but some other even not heard (!) tks a lot! ps which is the best for our game? in your opinion?\n\n",
            "date": "Posted 6 days ago  ·  418th in this Competition",
            "votes": "1",
            "reply": []
        },
        {
            "author": "Aadit Shukla",
            "content": "I haven't had the chance to try these new models yet, but I'm really curious about their performance. From what I've heard, they seem to offer some impressive capabilities. Has anyone here had any experience with them? I'd love to hear your thoughts! \n\n thank you for update [@cdeotte](https://www.kaggle.com/cdeotte) .\n\n",
            "date": "Posted 7 days ago",
            "votes": "0",
            "reply": []
        }
    ]
}