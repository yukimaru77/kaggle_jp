{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_dir = r\"..\\llm-20-questions\"\n",
    "file_path = file_dir + r\"\\overview.md\"\n",
    "output_dir = file_dir + \"_jp\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "output_path = output_dir + r\"\\overview.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import c\n",
    "from urllib import response\n",
    "import nbformat\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "class ResourceExhausted(Exception):\n",
    "    pass\n",
    "from prompt_toolkit import prompt\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "import re\n",
    "from google.generativeai.types import HarmBlockThreshold, HarmCategory\n",
    "\n",
    "generation_config = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 0.95,\n",
    "    \"top_k\": 64,\n",
    "    \"max_output_tokens\": 8192,\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "system_instruction = \"\"\"あなたはプロの翻訳家でかつデータサイエンティストです。ユーザーから送られてくるkaggleのコンペティションの概要説明を翻訳するのがあなたの役割です。ただし、日本語に翻訳する際は単に直訳するのではなく、日本語として自然な文章になるよう心がけてください。\"\"\"\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro\",\n",
    "    generation_config=generation_config,\n",
    "    system_instruction=system_instruction,\n",
    "    safety_settings={\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    ")\n",
    "def modify_filename(path, new_suffix=\"_with_summary\"):\n",
    "    # ディレクトリとファイル名を分割\n",
    "    directory, filename = os.path.split(path)\n",
    "    \n",
    "    # ファイル名と拡張子を分割\n",
    "    name, ext = os.path.splitext(filename)\n",
    "    \n",
    "    # 新しいファイル名を作成\n",
    "    new_filename = f\"{name}{new_suffix}{ext}\"\n",
    "    \n",
    "    # 新しいフルパスを作成\n",
    "    new_path = os.path.join(directory, new_filename)\n",
    "    \n",
    "    return new_path\n",
    "\n",
    "def split_text_by_tokens(file_path, target_tokens=4000):\n",
    "\n",
    "    # ファイルの読み込み\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    current_tokens = 0\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro\",\n",
    "        generation_config=generation_config,\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "    )\n",
    "    for line in content.split('\\n'):\n",
    "        # 空の行をスキップ\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        line_tokens = model.count_tokens(line).total_tokens\n",
    "        \n",
    "        if current_tokens + line_tokens > target_tokens and current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = \"\"\n",
    "            current_tokens = 0\n",
    "\n",
    "        current_chunk += line + '\\n'\n",
    "        current_tokens += line_tokens\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "\n",
    "    return chunks\n",
    "#リクエストの処理\n",
    "def send_request(chat_session,prompt):\n",
    "    try:\n",
    "        response = chat_session.send_message(prompt)\n",
    "    except ResourceExhausted as e:\n",
    "        print(\"Resource exhausted. Waiting for 1 minute before retrying...\")\n",
    "        for i in tqdm(range(60), desc=\"Waiting\", unit=\"second\"):\n",
    "            time.sleep(1)\n",
    "        response = chat_session.send_message(prompt)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "    return response\n",
    "\n",
    "# 要約を生成\n",
    "def summarize(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-pro\",\n",
    "        generation_config=generation_config,\n",
    "        safety_settings={\n",
    "            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "        }\n",
    "    )\n",
    "    chat_session = model.start_chat(history=[])\n",
    "    total_tokens = 0\n",
    "    prompt_summary = \"以下に示すコンペの概要説明を読んで要約を生成してください。また、どのような問題に取り組むのか、簡単な具体例を入れて分かりやすく説明してください。。\\n\\n コンペの概要 :\\n\"+text\n",
    "    prompt_know = \"以下に示すコンペの概要説明を読んで、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説を列挙してください。ただし、初心者なだけで大学の学部でやるようなレベルの機械学習・深層学習の知識はあるので簡単なものや有名なものは説明不要です。ある程度マイナーなものや、実務を経験していないと馴染みのないもの、このコンペ特有のドメイン知識等に焦点を当ててください。\\n\\n コンペの概要 :\\n\"+text\n",
    "    total_tokens += model.count_tokens(prompt_summary).total_tokens\n",
    "    response = send_request(chat_session,prompt_summary)\n",
    "    summary = response.text\n",
    "    summary = \"# 要約 \\n\"+summary+\"\\n\\n---\\n\"\n",
    "    total_tokens += model.count_tokens(prompt_summary).total_tokens\n",
    "    response = send_request(chat_session,prompt_know)\n",
    "    known = response.text\n",
    "    known = \"# 用語概説 \\n\"+known+\"\\n\\n---\\n\"\n",
    "    # 要約を既存のnotebookの先頭にマークダウンセルとして追加\n",
    "    text = summary + known + text\n",
    "    output_path = modify_filename(path)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(text)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# 使用例\n",
    "\n",
    "text_chunks = split_text_by_tokens(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = []\n",
    "responses = []\n",
    "for i, chunk in enumerate(text_chunks):\n",
    "    chat_session = model.start_chat(history=history)\n",
    "    response = send_request(chat_session,chunk)\n",
    "    user_history = {\"role\": \"user\", \"parts\": chunk}\n",
    "    model_history = {\"role\": \"model\", \"parts\": response.text}\n",
    "    history.append(user_history)\n",
    "    history.append(model_history)\n",
    "    responses.append(response.text)\n",
    "    print(f\"Chunk {i+1} response:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#responsesを結合してファイルに書き込む\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    for response in responses:\n",
    "        file.write(response + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
