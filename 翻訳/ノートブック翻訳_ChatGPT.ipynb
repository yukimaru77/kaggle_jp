{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_dir = r\"..\\llm-20-questions\"\n",
    "origin_notebook_dir = file_dir + r\"\\kernels\"\n",
    "overview_dir = file_dir + \"_jp\"\n",
    "overview_path = overview_dir + r\"\\overview.md\"\n",
    "output_dir = file_dir + \"_jp\"\n",
    "output_discuss_dir = output_dir + r\"\\kernels\"\n",
    "if not os.path.exists(output_discuss_dir):\n",
    "    os.makedirs(output_discuss_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_directories(path):\n",
    "    return [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "def list_extension_files(dirs,extension='.ipynb'):\n",
    "    ipynb_files = []\n",
    "    exit_indexs = []\n",
    "    for i,dir in enumerate(dirs):\n",
    "        with os.scandir(dir) as entries:\n",
    "            for entry in entries:\n",
    "                if entry.is_file() and entry.name.endswith(extension):\n",
    "                    ipynb_files.append(entry.path)\n",
    "                    exit_indexs.append(i)\n",
    "                    break\n",
    "    return ipynb_files,exit_indexs\n",
    "\n",
    "notebook_dirs = list_directories(origin_notebook_dir)\n",
    "output_dirs = [os.path.join(output_discuss_dir+\"\\\\\",dir) for dir in notebook_dirs]\n",
    "for output_dir in output_dirs:\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "notebook_dirs = [os.path.join(origin_notebook_dir+\"\\\\\",dir) for dir in notebook_dirs]\n",
    "notebook_files,exit_indexs = list_extension_files(notebook_dirs)\n",
    "tmp,tmp_ = [],[]\n",
    "for i in exit_indexs:\n",
    "    tmp.append(notebook_dirs[i])\n",
    "    tmp_.append(output_dirs[i])\n",
    "notebook_dirs = tmp\n",
    "output_dirs = tmp_\n",
    "# notebook_filesのファイル名を取得\n",
    "notebook_file_names = [os.path.basename(file) for file in notebook_files]\n",
    "#output_dirsとnotebook_file_namesを結合\n",
    "output_files = [os.path.join(output_dirs[i],notebook_file_names[i]) for i in range(len(notebook_files))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dirsの中にファイルがないインデックス番号を取得\n",
    "empty_dirs = [i for i in range(len(output_dirs)) if not os.listdir(output_dirs[i])]\n",
    "\n",
    "#空の物のみを取得\n",
    "output_files = [output_files[i] for i in empty_dirs]\n",
    "notebook_files = [notebook_files[i] for i in empty_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import c\n",
    "from urllib import response\n",
    "import nbformat\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import tiktoken\n",
    "import copy\n",
    "# tiktokenを使ってtokenを数える\n",
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "\n",
    "def remove_python_markers(text):\n",
    "    lines = text.split('\\n')\n",
    "    if lines[0] == '```python':\n",
    "        lines = lines[1:]\n",
    "    if lines[-1] == '```':\n",
    "        lines = lines[:-1]\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "class ResourceExhausted(Exception):\n",
    "    pass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "import re\n",
    "\n",
    "with open(overview_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "system_instruction = \"\"\"あなたはプロの翻訳家兼プログラマーです。ユーザーから送られてくるkaggleの公開jupyter notebookのセルを日本語に翻訳するのがあなたの役割です。具体的にはマークダウンセルだった場合、文章を日本語に翻訳をしてください。コードセルだった場合、コードセル内のコメントを日本語に翻訳し、またpython初学者でもコード理解が出来るように、そのコードが何をしているのか理解を促すようなコメントを追加で日本語で出来るだけ多く挿入することです。ただし、コードそのものを変更してはいけません。日本語に翻訳する際は単に直訳するのではなく、日本語として自然な文章になるよう心がけてください。これらの内容以外は出力せず、また出力の形式はユーザーの入力の形式と絶対に同じになるように、---The following area is a {Markdown|Code} cell (cell numver is n)---\\nで定義される特殊な文字列を先頭につけてからそれぞれ出力することを忘れないでください。ただしnは1以上の整数です。例えば、マークダウンセルの場合以下のような入力が与えられます。\n",
    "\n",
    "ユーザーからの入力例(マークダウンセルの場合):\n",
    "---The following area is a Markdown cell (cell numver is n)---\n",
    "{マークダウンセルの内容}\n",
    "\n",
    "上記の入力に対して期待する出力例:\n",
    "---The following area is a Markdown cell (cell numver is n)---\n",
    "{マークダウンセルの内容の日本語訳したもの}\n",
    "\n",
    "ユーザーからの入力例(コードセルの場合):\n",
    "---The following area is a Code cell (cell numver is n)---\n",
    "{コードセルに書かれているコード}\n",
    "\n",
    "上記の入力に対して期待する出力例:\n",
    "---The following area is a Code cell (cell numver is n)---\n",
    "{コードセルに書かれているコメントを日本語訳し、さらに分かりやすくなるようにコメントを追加したもの}\n",
    "\n",
    "また、チャットの履歴には、現在ユーザーから入力されたセル以前のセルの内容が書いてあります。つまり入力されたcellのcell numverがnなら1~n-1のセルが書いてあります。なので、現在のセルを翻訳する際に文脈上必要であれば適宜参考にしてください。また、コンペティションの概要は以下の通りです。文脈の理解に必要であれば用いて構いません。\n",
    "\n",
    "コンペティションの概要:\n",
    "```markdown\n",
    "\"\"\" + content + \"\\n```\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_instruction}\n",
    "]\n",
    "\n",
    "\n",
    "def merge_markdown_cells(input_path, output_path=None):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    new_cells = []\n",
    "    current_markdown = \"\"\n",
    "\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            if current_markdown:\n",
    "                current_markdown += \"\\n\\n\"  # 各マークダウンセル間に空行を追加\n",
    "            current_markdown += cell.source\n",
    "        else:\n",
    "            if current_markdown:\n",
    "                new_cells.append(nbformat.v4.new_markdown_cell(current_markdown))\n",
    "                current_markdown = \"\"\n",
    "            new_cells.append(cell)\n",
    "\n",
    "    # 最後のマークダウンセルがある場合、それを追加\n",
    "    if current_markdown:\n",
    "        new_cells.append(nbformat.v4.new_markdown_cell(current_markdown))\n",
    "\n",
    "    notebook.cells = new_cells\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            nbformat.write(notebook, f)\n",
    "    return notebook\n",
    "\n",
    "def translate_batch(batch,historys=[]):\n",
    "    historys_ = copy.deepcopy(messages)\n",
    "    for history in historys:\n",
    "        user_history = {\"role\": \"user\", \"content\": history[0]}\n",
    "        model_history = {\"role\": \"assistant\", \"content\": history[1]}\n",
    "        historys_.append(user_history)\n",
    "        historys_.append(model_history)\n",
    "    input_text = \"\\n\".join([f\"---The following area is a {cell_type} cell (cell numver is {i})---\\n{content}\" for cell_type, content, i in batch])\n",
    "    historys_.append({\"role\": \"user\", \"content\": input_text})\n",
    "    print(\"モデルに送るテキスト\")\n",
    "    #トークン数を数える。hitorys_のトークン数も含める\n",
    "    all_text = \"\\n\".join([history[\"content\"] for history in historys_])\n",
    "    print(\"トークン数は : \" , len(enc.encode(all_text+input_text)))\n",
    "    print(input_text)\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=historys_,\n",
    "    max_tokens=16384\n",
    "    )\n",
    "    print(\"モデルからの返答\")\n",
    "    print(response.choices[0].message.content)\n",
    "    historys.append([input_text,response.choices[0].message.content])\n",
    "    # ---Markdown---\\nまたは---Code---\\nで区切る。正規表現で分割する\n",
    "    response_parts = re.split(r'---The following area is a (Markdown|Code) cell \\(cell numver is \\d+\\)---\\n', response.choices[0].message.content)\n",
    "    print(\"パース結果\")\n",
    "    print(response_parts)\n",
    "    response_parts = response_parts[1:]  # 最初の要素は空文字列なので除外\n",
    "    # 奇数番目だけ取り出す\n",
    "    response_parts = response_parts[1::2]\n",
    "    return response_parts,historys\n",
    "\n",
    "def get_md_files_in_same_directory(path):\n",
    "    # 指定されたパスのディレクトリを取得\n",
    "    directory = os.path.dirname(path)\n",
    "    \n",
    "    # 指定されたディレクトリ内のファイルとディレクトリのリストを取得\n",
    "    files_and_dirs = os.listdir(directory)\n",
    "    \n",
    "    # .mdファイルのリストを作成\n",
    "    md_files = [os.path.join(directory, f) for f in files_and_dirs if f.endswith('.md')]\n",
    "    \n",
    "    return md_files\n",
    "def translate_notebook(notebook_path, output_path, max_tokens=0):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "    md_paths = get_md_files_in_same_directory(notebook_path)\n",
    "    if len(md_paths) > 0:\n",
    "        md_path = md_paths[0]\n",
    "        with open(md_path, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "            content = \"---\\n\\n\" + content\n",
    "            #ノートブックの末尾に追加\n",
    "            content_cell = nbformat.v4.new_markdown_cell(content)\n",
    "            notebook.cells.append(content_cell)\n",
    "\n",
    "    cells_to_translate = []\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type in ['markdown', 'code']:\n",
    "            cells_to_translate.append((cell.cell_type.capitalize(), cell.source))\n",
    "\n",
    "    translated_cells = []\n",
    "    historys = []\n",
    "    current_batch = []\n",
    "    current_tokens = 0\n",
    "    # 累積トークン数(最後に表示するため)\n",
    "    total_tokens = 0\n",
    "    for cell_type, content in cells_to_translate:\n",
    "        cell_text = f\"---The following area is a {cell_type} cell (cell numver is {i})---\\n{content}\"\n",
    "        cell_tokens = len(enc.encode(cell_text))\n",
    "        if max_tokens == 0:\n",
    "            current_batch.append((cell_type, content,i))\n",
    "            current_tokens += cell_tokens\n",
    "        if current_tokens + cell_tokens > max_tokens and current_batch:\n",
    "            # 現在のバッチを翻訳\n",
    "            total_tokens += current_tokens\n",
    "            translated_batch, historys = translate_batch(current_batch, historys)\n",
    "            translated_cells.extend(translated_batch)\n",
    "            current_batch = []\n",
    "            current_tokens = 0\n",
    "        if max_tokens > 0:\n",
    "            current_batch.append((cell_type, content,i))\n",
    "            current_tokens += cell_tokens\n",
    "\n",
    "    # 残りのセルを処理\n",
    "    if current_batch:\n",
    "        total_tokens += current_tokens\n",
    "        translated_batch, historys = translate_batch(current_batch, historys)\n",
    "        translated_cells.extend(translated_batch)\n",
    "    translated_index = 0\n",
    "    print(len(translated_cells))\n",
    "    print(len([cell for cell in notebook.cells if cell.cell_type in ['markdown', 'code']]))\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown' or cell.cell_type == 'code':\n",
    "            print(translated_index)\n",
    "            if cell.cell_type == \"code\":\n",
    "                cell.source = remove_python_markers(translated_cells[translated_index].strip())\n",
    "            else:\n",
    "                cell.source = translated_cells[translated_index]\n",
    "            translated_index += 1\n",
    "        # その他のセルタイプ（出力、図など）はそのまま保持\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(notebook, f)\n",
    "\n",
    "\n",
    "\n",
    "# ノートブックの要約を生成\n",
    "def summarize_notebook(notebook_path):\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "    text = \"\"\n",
    "    for cell in notebook.cells:\n",
    "        if cell.cell_type == 'markdown':\n",
    "            text += \"マークダウンセル :\\n\"+cell.source+\"\\n\\n\"\n",
    "        elif cell.cell_type == 'code':\n",
    "            text += \"コードセル :\\n\"+cell.source+\"\\n\\n\"\n",
    "    system_instruction = \"\"\"あなたはプロのプログラマーです。ユーザーから送られてくるkaggleの公開jupyter notebookに関するタスクを遂行してください。また、コンペティションの概要は以下の通りです。文脈の理解に必要であれば用いて構いません。\n",
    "\n",
    "    コンペティションの概要:\n",
    "    ```markdown\n",
    "    \"\"\" + content + \"\\n```\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_instruction}\n",
    "    ]\n",
    "    total_tokens = 0\n",
    "    prompt_summary = \"以下に示すjupyter notebookの要約を生成してください。特にそのnotebookはどのような問題に取り組み、どのような手法やライブラリで解決しているのかは必ず要約に含めてください。\\n\\n ノートブックの内容 :\\n\"+text\n",
    "    prompt_know = \"以下に示すjupyter notebookのを読んで、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説を列挙してください。ただし、初心者なだけで大学の学部でやるようなレベルの機械学習・深層学習の知識はあるので簡単なものや有名なものは説明不要です。ある程度マイナーなものや、実務を経験していないと馴染みのないもの、このノートブック特有のドメイン知識等に焦点を当ててください。\\n\\n ノートブックの内容 :\\n\"+text\n",
    "    total_tokens += len(enc.encode(prompt_summary))\n",
    "    print(\"要約する際のトークン数は : \" , len(enc.encode(prompt_summary)))\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages+[{\"role\": \"user\", \"content\": prompt_summary}],\n",
    "    max_tokens=16384\n",
    "    )\n",
    "    summary = response.choices[0].message.content\n",
    "    summary = \"# 要約 \\n\"+summary+\"\\n\\n---\\n\"\n",
    "    # 要約を既存のnotebookの先頭にマークダウンセルとして追加\n",
    "    summary_cell = nbformat.v4.new_markdown_cell(summary)\n",
    "    notebook.cells.insert(0, summary_cell)\n",
    "    total_tokens += len(enc.encode(prompt_know))\n",
    "    print(\"要約する際のトークン数は : \" , total_tokens)\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages+[{\"role\": \"user\", \"content\": prompt_know}],\n",
    "    max_tokens=16384\n",
    "    )\n",
    "    known = response.choices[0].message.content\n",
    "    known = \"# 用語概説 \\n\"+known+\"\\n\\n---\\n\"\n",
    "    # 要約を既存のnotebookの先頭にマークダウンセルとして追加\n",
    "    known_cell = nbformat.v4.new_markdown_cell(known)\n",
    "    notebook.cells.insert(1, known_cell)\n",
    "    print(f\"Total tokens: {total_tokens}\")\n",
    "    with open(notebook_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(notebook, f)\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(enc.encode(system_instruction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(notebook_files)):\n",
    "    _ = merge_markdown_cells(notebook_files[i], notebook_files[i])\n",
    "    _ = translate_notebook(notebook_files[i], output_files[i])\n",
    "    _ = summarize_notebook(output_files[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
