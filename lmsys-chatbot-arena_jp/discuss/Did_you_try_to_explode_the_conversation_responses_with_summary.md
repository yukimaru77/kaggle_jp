# 要約 
このディスカッションは、KaggleのLMSYS - Chatbot Arena Human Preference Predictionsコンペティションにおける会話応答の分割に関するものです。

**Mattia Vanzetto**は、トレーニングデータの約14%が複数回の会話で構成されているため、モデルに組み込まれるプロンプトと応答の長さが制限される可能性があることを指摘しています。彼は、会話応答を分割してモデルをファインチューニングし、個々の会話部分に対する予測を集計することで、この問題を解決できるのではないかと提案しています。彼は、このアプローチが単純なxgboostモデルでリーダーボードのスコアをわずかに改善したことを報告しています。

**JM**は、このアプローチを試しましたが、推論時間が増え、パブリックLBのスコアは改善されなかったとコメントしています。

**Yi-Fu Chen**は、プロンプトと応答のみを考慮し、ターゲットを相対的なwinner_model_Xとするバイナリ分類器を作成するという別のアイデアを提案しています。彼は、このアプローチは直感的に理にかなっていないと考えています。

**Mattia Vanzetto**は、Yi-Fu Chenのコメントに返信し、負けと引き分けは「比較」されるため、このアプローチは有効であると主張しています。

このディスカッションは、コンペティション参加者が、会話応答の分割やバイナリ分類器の使用など、さまざまなアプローチを試していることを示しています。これらのアプローチは、モデルの性能を向上させる可能性がありますが、推論時間や計算リソースなどの課題も伴う可能性があります。


---
# 会話応答を分割して試しましたか？
**Mattia Vanzetto** *2024年8月1日木曜日 04:42:15 GMT+0900 (日本標準時)* (0票)
皆さん、こんにちは。

トレーニングデータの約86%は、単一のプロンプトと応答で構成されていることがわかりました。しかし、14%はそうではありません。また、少なくとも公開されているノートブックでは、ファインチューニングされたモデルは通常、最大シーケンス長が2000/2400文字で、モデルに組み込まれるプロンプトは、prompt_list + response_a_list + response_b_listのみです。これは、response_bが完全に切り捨てられるか、情報が失われる可能性があることを意味します。

会話応答を分割し、モデルをファインチューニングしてから、個々の会話部分に対する予測を集計することを試しましたか？

単一の会話部分「prompt_i + response_a_i + response_b_i」の平均/中央値の長さは2000〜2400文字で、この実験に最適なようです。

私も試してみたいのですが、ファインチューニングの経験も、計算能力も、時間もないので😂

参考までに、単純なxgboostで、同じ特徴量の前処理、同じ最適化手順で試したところ、分割して集計するアプローチではリーダーボードで1.03、標準的なアプローチでは1.04でした。

もう1つやってみたかった実験は、プロンプト + response_Xのみを考慮し、ターゲットを相対的なwinner_model_Xとするバイナリ分類器を作成することです。これにより、行数を2倍にすることができます。「相手の応答」は考慮しません。その後、すべてを再び集計します。

コンペティション終了後にソリューションを見るのが楽しみです。

コンペティションの残りの数日間、頑張ってください🍀

---
# 他のユーザーからのコメント
> ## JM
> 
> 試しましたが、推論時間が増え、パブリックLBの改善は見られませんでした。
> 
> 
> 
---
> ## Yi-Fu Chen
> 
> 
> もう1つやってみたかった実験は、プロンプト + response_Xのみを考慮し、ターゲットを相対的なwinner_model_Xとするバイナリ分類器を作成することです。これにより、行数を2倍にすることができます。「相手の応答」は考慮しません。その後、すべてを再び集計します。
> 
> 似たような概念を考えたのですが、勝ち負けは比較されるので、直感的に理にかなっていないように思えます。
> 
> 
> 
> > ## Mattia Vanzettoトピック作成者
> > 
> > 負けと引き分けのことですか？そうすると、この2つは「比較」されることになります。
> > 
> > 
> > 
---

