# トレーニングステップがサンプルサイズと一致しません！

**godmysalary** *2024年7月5日 金曜日 12:49:34 JST* (1票)

皆さん、こんにちは！私たちは、[https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b/notebook](url) の素晴らしいファインチューニング作業を実行するために、vscodeを使用していました。

唯一の違いは、モデルをLlama3に変更したことです。

そして、Kaggle GPUでコードを実行すると、すべて正常に動作します。サンプルサイズは500、gradient_accumulate_stepsは16、batch_sizeは1なので、31ステップを実行することになります。これは、下の最初の画像に示されています。

しかし、同じコードをリモートサーバーに接続したvscodeにコピーしたところ、合計ステップ数が10になりました！サンプルサイズ、gradient_accumulate_steps、batch_sizeは変更されていませんが、合計ステップ数は10になり、これは2番目の画像に示されており、約160（16*10）のサンプルしか処理されていないことを意味します。vscodeでは、1つのGPUのみが使用されています。

何が起こっているのか、ヒントをいただけませんか？パッケージは更新されています。

---
# 他のユーザーからのコメント

> ## godmysalaryトピック作成者
> 
> 皆さん、こんにちは！この問題を再度確認したところ、ついに「犯人」を見つけました！私たちのリモートサーバーには3つのGPUがあり、予想通りプログラムは並列化されています。最も厄介な点は、モデルをロードしたときに、device_map={'': 0}を設定したにもかかわらず、なぜか並列に実行されてしまったことです。そこで、コードの先頭にCUDA_VISIBLE_DEVICES = 0を明示的に設定したところ、問題は解消されました！ファインチューニングでお役に立てれば幸いです。
> 
> 
> 
---
> ## Valentin Werner
> 
> データの長さを確認しましたか？誤ってトレーニングデータセットと検証データセットを入れ替えていませんか？
> 
> 
> 
> > ## godmysalaryトピック作成者
> > 
> > はい！train_datasetの長さは500、evaluation_datasetの長さは100です。
> > 
> > 
> > 
---

