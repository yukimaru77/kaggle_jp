# データアノテーションの直感 - ラベルがノイズである理由
**Valentin Werner** *2024年5月13日(月) 23:10:26 JST* (32 votes)

ラベルの質に関する議論がいくつか進行しているのを見ました。データのアノテーションにかなりの時間を費やしてきた（そして他の人にデータのアノテーションを依頼してきた）私としても、自分の意見と直感を共有したいと思います。

データアノテーションでは、一般的に専門家にデータのアノテーションを依頼します。彼らはデータをよく読み、ラベルを慎重に選択するなどするはずですが（しかし、そうしない場合もあります）、アノテーションされたデータは**グランドトゥルース**とみなされます。なぜなら、これらの専門家は、（問題とアノテーションタスクの理解が同じであれば）正しいラベルを客観的に判断できるはずだからです。

その後、一般的に**アノテーター間一致率**（n人の人が同じテキストに同じラベルを付けているか）を計算します。これは、しばしばパフォーマンスの上限とみなされてきました。現実には必ずしもそうではありませんが、これは理にかなっています。なぜなら、それはあなたのモデルが複数のアノテーターからの知識の交差部分を学習できることを意味するからです。

なぜこれが重要なのでしょうか？私たちがトレーニングしているデータは、LLMを試したいと思ったランダムな人々によってアノテーションされています。LMSYSは私がよく使用し、推奨する素晴らしいツールですが、私たちの問題にとっては、アノテーターがアノテーションしたい質問を決定でき、アノテーションするデータがリアルタイムで生成されるアノテーションツールです。

しかし、私たちの課題にはいくつかの問題があります。

- ユーザーはLLMの使用や理解の専門家ではありません。
- ユーザーは、質問しているトピックの専門家ではないことが多く（そして、応答を事実確認していないことがよくあります）。
- ユーザーが同じプロンプトを指定して同じ応答を受け取らない限り、アノテーター間一致率を評価する方法はありません。
- LMSYSでは、アノテーションのやり直しや取り消しはできません（例：間違った側に誤ってクリックした場合）。
- そして最も重要なことですが、ユーザーには異なる好みがあります。このアノテーションタスクは、まったく客観的ではなく、完全に主観的です。

これは、私たちが**ノイズの多いラベル**を持っていることを意味し、この問題に対処するためのテクニックを採用する必要があります。アクティブラーニング、アンサンブル、損失の変更など、この問題に対処するために機能する可能性のあるテクニックがあります。これらすべてをテストする必要があります（アンサンブルはともかく、私たちは行うつもりです😉）。

---
# 他のユーザーからのコメント
> ## aotiandragon
> 
> ありがとう。データについて知ることができました。
> 
> 
> 
---
> ## Pranav Belhekar
> 
> ご意見を共有していただきありがとうございます。コンペティションを分析するのに役立ちました。
> 
> 
> 
---
> ## Fae Gaze
> 
> ラベルノイズに関する素晴らしい洞察です！ノイズの影響を軽減するために、Focal Lossのようなロバストな損失関数を探求することもできますし、Snorkelのようなフレームワークを使用して、プログラム可能なラベリング関数を通じてトレーニングデータを効率的に管理することもできます。
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > Snorkelについてはまだ聞いたことがありません。文献を推薦していただけますか？
> > 
> > 
> > 
---
> ## Takamichi Toda
> 
> ご共有いただきありがとうございます。私も今、同じことを考えていました。
> 
> トレーニングデータには、非常に短いプロンプト（1語）のみで構成されるサンプルがいくつかあります。典型的な例としては、プロンプトが「hey」だけのものがあります。LLMはこのようなプロンプトに対する応答を、一般的に2つのパターンに分類できます。
> 
> 単に「Hello!」と応答する。
> 「Hello」と言った後、「今日は何かお手伝いできますか？」のように、会話を続けるための合図を提供する。
> 
> 2の方が良いと思いますが、トレーニングデータでは、同点と1が勝っているケースがかなりあることが示されています。
> 
> |  | n_sample | id |
> | --- | --- | --- |
> | hello_lose | 5 | 189242591, 211357242, 326037335, 458677274, 3947327386 |
> | tie | 4 | 1329170872, 3422926530, 4197301939, 4265282380 |
> | hello_win | 2 | 1655058446, 2171261721 |
> 
> 「hay」パターンの傾向は、私の好み（主に2）に合っているように思えますが、このようにノイズの多いラベルとして扱う必要があるパターンは他にもたくさんあります。
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > そして、これは、両方のモデルが同じ答えを出しているにもかかわらず、人々が一方の側に投票したという、より明白な例だと思います。これらのユーザーは、明らかに、なぜそうしたのかを説明する必要があるかわいそうなML開発者のことを考えていませんでした😉
> > 
> > 応答の真実性を評価する方法（もし良い方法があれば）は、私たちのモデルをトレーニングするための良い特徴になると思います。
> > 
> > 
> > 
---
> ## Lisa Dunlapコンペティションホスト
> 
> これは素晴らしいポイントだと思います。この課題の大きな課題の1つ（言葉遊びではありません）は、データが非常に最小限のフィルタリングでクラウドソーシングされているため、ラベルノイズに対処する方法を学ぶことが非常に重要です！
> 
> 
> 
---
> ## JunHua Liao
> 
> ラベルノイズの問題も発見しました。これは、同じプロンプトと応答で、勝者がいる場合に、winner_tieになるべきなのに、勝者がいることが原因です。現在考えている2つの解決策は、(1) ラベルをwinner_tieに変更する、(2) ノイズデータを削除することです。
> 
> 
> 
> > ## Lisa Dunlapコンペティションホスト
> > 
> > プロンプトの重複排除や、過剰に表現されているプロンプトの重み付けを下げることも有益かもしれません。
> > 
> > 
> > 
---
> ## xiaotingting
> 
> 現在、データのクレンジングとモデルの選択が、結果に最も大きな影響を与えています。どんな分野であっても、たとえ大きなモデルを使用しても、データの質が非常に重要だと感じています。
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > データをどのようにクレンジングしたかを見るのが楽しみです。私たちは少し試してみましたが、実際に役立つレベルには到達できませんでした。
> > 
> > 
> > 
> > > ## Fae Gaze
> > > 
> > > はい、その通りです。クレンジングしすぎると、スコアに悪影響を与えます。
> > > 
> > > 
> > > 
---
> ## AbChk
> 
> ご意見を共有していただきありがとうございます。この問題から、テストデータにもノイズの多いラベルがあるのではないかと疑問に思うようになりました。
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > 非常に可能性が高いです。私は（それほどではないかもしれませんが）大胆にも、彼らは25,000個のサンプルを手動で品質チェックしていないと仮定しています。ラベルの分布とモデルに基づいて選択されたようなものです。
> > 
> > 
> > 
> > ## Fae Gaze
> > 
> > テストもノイズがあります。しかし、ノイズをクレンジングすることはできません。トレーニングをクレンジングしても、スコアに影響を与えます。
> > 
> > 
> > 
---

