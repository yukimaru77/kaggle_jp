# このコンペティションで後処理は有効でしょうか？
**Nicole** *2024年7月24日 水曜日 08:12:23 GMT+0900 (日本標準時)* (0票)
予測値を扱うために後処理を試みましたが、効果はありませんでした。後処理で改善された方はいますか？
---
# 他のユーザーからのコメント
> ## Valentin Werner
> 
> コンペティションの初期に後処理を試しましたが、うまくいきませんでした。私の考えでは、モデルは基本的にすでに自己較正しているということです。つまり、モデルが「0.4」を最高確率として出力した場合、約40%の確率で正しくなります。そして、80%は、約80%の確率で正しくなります。
> 
> ここで、0.4はあまり自信がないので、0.33にするという処理を行うと、約10回中6回は損失が増加します（予測値が40%で実際にも正しい予測の場合、損失は低いため）。
> 
> このことを示すために、簡単なコードスニペットを用意しました。
> 
> ```
> from sklearn.metrics import log_loss
> 
> y_true = [[1,0,0]] * 4 + [[0,1,0]] * 3 + [[0,0,1]] * 3
> y_pred = [[0.4, 0.3, 0.3]] * 10
> print("raw log_loss:", log_loss(y_true, y_pred))
> # raw log_loss: 1.0888999753452235
> 
> y_true = [[1,0,0]] * 4 + [[0,1,0]] * 3 + [[0,0,1]] * 3
> y_pred = [[0.334, 0.333, 0.333]] * 10
> print("post processed (overconfident) log_loss):", log_loss(y_true, y_pred))
> # post processed (overconfident) log_loss): 1.0984133878031905
> 
> ```
> 
> さらに、過信は致命傷です。0.8（おそらく80%の確率で正しい）を0.9に設定すると、過信している20%のケースで損失が大幅に増加します。高信頼度の誤分類に対しては、はるかに高いペナルティが課せられます。
> 
> このことを示すために、簡単なコードスニペットを用意しました。
> 
> ```
> from sklearn.metrics import log_loss
> 
> y_true = [[1,0,0]] * 2 + [[0,1,0]] * 8
> y_pred = [[0.1, 0.8, 0.05]] * 10
> print("raw log_loss:", log_loss(y_true, y_pred))
> # raw log_loss: 0.5877385652626266
> 
> y_true = [[1,0,0]] * 2 + [[0,1,0]] * 8
> y_pred = [[0.075, 0.90, 0.025]] * 10
> print("post processed (overconfident) log_loss):", log_loss(y_true, y_pred))
> # post processed (overconfident) log_loss): 0.6023418456154264
> 
> ```
> 
> 私の直感に何か欠陥があるのかもしれませんが、モデルが適切に較正されていると仮定すると、修正を行うと、修正よりも悪化する可能性が高くなります。
> 
> 
> 
> > ## NicoleTopic Author
> > 
> > 同意します。
> > 
> > 
> > 
---
> ## Lorry Zou
> 
> 対数損失のクリッピングを試しましたが、結果は同じでした。
> 
> 
> 
---

