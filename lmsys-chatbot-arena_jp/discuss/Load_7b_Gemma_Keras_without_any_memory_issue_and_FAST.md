# 7B Gemma Keras をメモリ問題なく高速にロードする方法

**Marília Prata** *2024年5月12日日曜日 07:28:29 GMT+0900 (日本標準時)* (27票)

# メモリ問題を回避するためのヒント: Gemma/Keras モデル (1.1 - 7b_instruct_en) を実行する場合

[Gemma 1.1 7B Int8 Load](https://www.kaggle.com/code/awsaf49/gemma-1-1-7b-int8-load) Awsaf 著

前回のトピック（2日前）で、「Gemma Keras 1.1- 7b instruct-en を、Kaggle Notebook がメモリ不足で再起動することなく、どのように使用すればいいのか」という質問をしました。Google Cloud を使うか、作業を諦めるしかない状況でした。

その前のトピックに対する回答として、バッチサイズと max_length を減らすことで、モデルをロードしてメモリ問題に対処できるという情報を得ました。しかし、7B（70億パラメータ）のモデルでは、必ずしも有効ではありません。

しかし、Kaggle Notebook のスクリプトに max_length やバッチサイズが記述されていない場合もあります。そのような場合に備えて、Plan B があると便利です。

幸運なことに、Awsaf のコードを見つけ、私の最初の Gemma 1.1-7b-instruct-en を公開することができました。

Awsaf の素晴らしい、非常に分かりやすいコードをご覧ください:

[Gemma 1.1 7B Int8 Load](https://www.kaggle.com/code/awsaf49/gemma-1-1-7b-int8-load) Awsaf 著

記録として、7B Gemma Keras の Kaggle Notebook は多くありません。2B モデルはたくさん見つかりますが。

---

# 他のユーザーからのコメント

> ## Adnan Alaref
> 
> 解決策が見つかって嬉しいです。共有してくれてありがとうございます  [@mpwolke](https://www.kaggle.com/mpwolke) 
> 
> 
> 
> > ## Marília Prata トピック作成者
> > 
> > Alaref さん、その通りです。
> > 
> > メモリ問題なく Gemma/Keras 1.1-7b_instruct-en を使用できたことにとても喜び、このトピックを共有すべきだと感じました。なぜなら、Awsaf のコードに対する感謝の気持ちを表明した人はほとんどいなかったからです（昨日まで、彼の素晴らしい、役に立つコードと 2 つのデータセットに対して、わずか 6 票しかありませんでした）。
> > 
> > Kagglers は、そのコードの重要性に気づいていなかったのかもしれません。
> > 
> > 記録として、Notebook は GPU でわずか 15 分で実行されました！素晴らしいと思いませんか？
> > 
> > さらに、このコンペティションでホストがピン留めしていた最後のモデルを提出することができました。
> > 
> > 1.1_7b_instruct を使用しているユーザーは多くありません。実際、Awsaf のコード以外には、他に見たことがありません。
> > 
> > それは、私にとってほぼ「白鯨」のようなモデルでした。
> > 
> > Alaref さん、ありがとうございます。
> > 
> > 
> > 
---

