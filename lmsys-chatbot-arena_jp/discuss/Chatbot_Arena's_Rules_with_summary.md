# 要約 
このディスカッションは、Chatbot Arenaコンペティションのトレーニングデータが、単一の質問と回答ではなく、会話で構成されていることを明らかにしています。

**steubk**は、Chatbot Arenaのルールを説明し、会話の最後の質問が勝敗を決定し、それ以前の質問は引き分けとみなせることを示唆しています。

**Valentin Werner**は、最後の質問が最初の質問よりも重要であるため、トレーニングデータから最初の質問を削除する方が良いと主張しています。

**Shreshth Sharma**は、会話全体がモデルの評価に重要であり、最後の質問だけでなく、会話全体で生成された応答も考慮すべきだと主張しています。

**Valentin Werner**は、モデルが会話全体からユーザーにとって重要な質問と回答を学習できる可能性があると述べています。

このディスカッションは、Chatbot Arenaコンペティションのトレーニングデータの構造と、モデルの評価方法について重要な洞察を提供しています。参加者は、会話全体を考慮し、モデルが会話全体からユーザーの好みを学習できるようにする必要があります。


---
# チャットボットアリーナのルール

**steubk** *2024年5月9日 木曜日 14:01:52 日本標準時* (8票)

トレーニングセットが単一のプロンプトと応答ではなく、会話で構成されていることに気づきました。([https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633](https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633))。

チャットボットアリーナのルールは以下のとおりです（[https://chat.lmsys.org/](https://chat.lmsys.org/)）：

- 2つの匿名のモデル（例：ChatGPT、Claude、Llama）に質問をし、どちらが優れているか投票します！
- 勝者が見つかるまで、複数ターンにわたってチャットできます。
- 会話中にモデルのアイデンティティが明らかになった場合、投票はカウントされません。

大まかな近似として、最後の質問に勝者がいると考え、それ以前の質問はすべて引き分けと考えることができます。

お役に立てれば幸いです！

---

# 他のユーザーからのコメント

> ## Valentin Werner
> 
> これは非常に重要です。なぜなら、これは最後のプロンプトと応答が最初のものよりも価値があることを意味するからです。
> 
> この情報を切り捨てる場合は、終わりではなく、始めを切り捨てるべきです！
> 
> 
> 
> > ## Shreshth Sharma
> > 
> > 理想的には、モデルの違いは最初に尋ねられたプロンプトと最後に生成された応答によって生成されます。しかし、人間の最終的な選択は、LLMの思考プロセスも考慮するため、間に生成された応答も重要な情報を保持していると思いませんか？説明できない思考で正しい答えにたどり着くことは、モデルの信頼性を低下させる結果になります。
> > 
> > 
> > 
> > > ## Valentin Werner
> > > 
> > > モデルは、どのプロンプトと応答の組み合わせが実際にユーザーにとって重要だったかを学習できるかもしれません。私は自分のことしか言えませんが、私は常に「その応答の方が良い」と思ったときに投票し、それ以前のことはすべて無視していました。
> > > 
> > > 
> > > 
---

