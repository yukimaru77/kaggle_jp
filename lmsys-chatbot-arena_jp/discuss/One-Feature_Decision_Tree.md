# 単一特徴による決定木
**AbaoJiang** *2024年6月5日 水曜日 00:50:58 GMT+0900 (日本標準時)* (3票)
皆さん、こんにちは。

応答AとBの長さの差に基づく特徴が有用であることを示す多くの例を見てきました。そこで、私は[こちら](https://www.kaggle.com/code/abaojiang/lmsys-detailed-eda?scriptVersionId=181492294)で、単一の特徴のみを供給したDecisionTreeClassifierを使って簡単な実験を行いました。以下は、1つのフォールドの決定木を示しています。

[](https://postimg.cc/Y4YBzCJS)

ご覧のとおり、モデルは長さの差の特徴と勝者との関係を学習しています。

* 右側では、応答が長いモデルAが勝者です。
* 中央では、引き分けが大多数です。
* 左側では、モデルBが勝者です。

このアプローチは、StratifiedKFoldを用いて1.0588のローカルCVスコアを達成しましたが、ナイーブなベースラインを上回ることはできませんでした。これは、この重要な関係（冗長性バイアスに関連）を探求するもう1つの方法です。興味があれば幸いです！

---
# 他のユーザーからのコメント
> ## Valentin Werner
> 
> 特徴値を示す興味深い方法ですね。
> 
> 長さは私がこれまでに見つけた最も価値のある特徴ですが、回答の質は完全に無視しています。私は、実際には私の特徴の上位4位に入っていた特徴を作成しました。これは、モデルが「AIとして、それについては助けられません」のようなことを言っているかどうかを調べます。この種の定性的評価は、長さ（そして悲しいことに、埋め込みに戻らなければならない理由でもある）などの構造的特徴を超えて必要になるでしょう。
> 
> 
> 
> > ## AbaoJiangトピック作成者
> > 
> > こんにちは [@valentinwerner](https://www.kaggle.com/valentinwerner)さん、
> > 
> > ご返信ありがとうございます。
> > 
> > 私はこれまで構造的な特徴のみを試してきましたが、応答の長さの差のバケットに基づくナイーブなベースラインを上回るものは何もありません。冗長性バイアスは確かに存在しますが、さまざまな方法（例：コンテキスト埋め込み）で抽出できる情報はまだたくさんあります。正直に言うと、私はNLP初心者で、この学習の旅の中で発見したことを共有しようとしています。洞察に富んだ共有をありがとうございます！
> > 
> > 
> > 
> > > ## Valentin Werner
> > > 
> > > どのベースラインを指していますか？
> > > 
> > > 洞察を共有していただきありがとうございます。いつも感謝しています！
> > > 
> > > 
> > > 
> > > ## AbaoJiangトピック作成者
> > > 
> > > こんにちは [@valentinwerner](https://www.kaggle.com/valentinwerner)さん、
> > > 
> > > 返信が遅れて申し訳ありません。私のEDAノートブックの「応答の長さの差のバケット平均予測」セクションにあるナイーブなベースラインを指しています！
> > > 
> > > 
> > > 
---
> ## KTibow 個人
> 
> 決定木は奇妙な選択のように思えたので、いくつかの多項式回帰を試してみました。基本的に、「より大きな応答はより良い」と言っているだけです。
> 
> 
> 
> > ## AbaoJiangトピック作成者
> > 
> > こんにちは、
> > 
> > DTを選んだ理由は、応答の長さの差を手動でビン分割したナイーブなベースラインとの比較を行いたかったからです。DTは、長さの差を自動的にビン分割することを学習するため、異なる角度から同様のプロパティを観察できることを共有しました。
> > 
> > とにかく、共有していただきありがとうございます。
> > 
> > 
> > 
> > ## Vishal Maurya
> > 
> > こんにちは [@ktibow](https://www.kaggle.com/ktibow)さん、共有していただきありがとうございます。上記のこれらの多項式モデルのR2スコアを共有していただけませんか？これらの関係がどれほど強く、有意なのかを知りたいだけです。
> > 
> > 
> > 
---

