# Kaggleのリソースのみで優勝できますか？
**Areej Malkawi** *2024年6月10日 月曜日 03:35:55 GMT+0900 (日本標準時)* (5 votes)
このコンペティションのデータは膨大で、多くの公開ノートブックが推論に事前学習済みモデルを使用しているのを見ました。私も事前学習済みモデルを使ってコンペティションデータのトレーニングを試みましたが、メモリとスコアのトレードオフに直面しています。メモリの問題を克服し、高いLBスコアを得るために、KaggleのGPU/TPUクォータ以上のものを使用する必要があるのでしょうか？外部リソースを使用せずに優勝したり、LBの上位に食い込むことは可能でしょうか？
---
# 他のユーザーからのコメント
> ## Ebi
> 
> 
> 外部リソースを使用せずに優勝したり、LBの上位に食い込むことは可能でしょうか？
> 
> ほとんど不可能だと思います。これはほとんどのKaggleコンペティションに当てはまります。なぜなら、ほとんどの場合、多くの実験サイクルを実行する必要があるからです。
> 
> 実は、私は約3年間、CPUのみのラップトップとColabのような安価なクラウドサービスを使って参加してきましたが、銀メダルを獲得できただけです。数か月前にRTX 4090を購入し、すぐに金メダルを獲得することができました。これは、このコンペティションでも有利に働きます。
> 
> 
> 
> > ## Hassan Abedi
> > 
> > はい、ほとんどのNLPコンペティションでは、VRAMが豊富な高性能なGPUがあると大きな違いが出ます。
> > 
> > 
> > 
> > ## Valentin Werner
> > 
> > ドイツでは、GPUのレンタルは1時間あたり約50セントから始まります。トレーニングに8時間かかるとすると、4ユーロになります。何回か反復処理を行うので、間違いなくそれ以上の費用がかかりますが、ドイツでは4090は約1800ユーロです。つまり、レンタルGPUで約450回のトレーニング（または3600時間のトレーニング！）を行うことができます。このような大きな投資をする前に何か試したい場合は、このように始めることができます。
> > 
> > さらに、Kaggleは30GBのVRAMを提供しています（Windows PCの4090は約23GB）。そのため、投資する前にあらゆることを試すことができます。KaggleのGPUの大きな問題は、可能性ではなく速度です。
> > 
> > 
> > 
---
> ## tanaka
> 
> なるほど、外部リソースを使わずにこれらのコンペティションで競うのはかなり難しいようですね。
> 
> しかし、いきなりGPUを購入するのはハードルが高いと感じます。
> 
> Colabや他のGPUレンタルサーバーなど、さまざまなオプションを試してから、GPUの購入またはレンタルを決定するのが良いようです。
> 
> [Vast.ai](http://vast.ai/)は人気のある選択肢のようですよね 🤔？
> 
> - [https://vast.ai/](https://vast.ai/)
> 
> - [https://cloud-gpus.com/](https://cloud-gpus.com/)
> 
> - [https://gist.github.com/devinschumacher/87dd5b87234f2d0e5dba56503bfba533](https://gist.github.com/devinschumacher/87dd5b87234f2d0e5dba56503bfba533)
> 
> - [https://getdeploying.com/reference/cloud-gpu](https://getdeploying.com/reference/cloud-gpu#paperspace)
> 
> 
> 
> > ## Ebi
> > 
> > 私はVast.aiを使ったことがありませんが、個人的には[jarvislabs.ai](https://jarvislabs.ai/)が好きです。
> > 
> > インスタンスの作成とSSHによるアクセスが簡単で高速です。価格も非常に安いと思います。私は主にホームサーバーに移行するまで、このサービスを利用していました。
> > 
> > 
> > 
---
> ## Andreas Bisi
> 
> 過去のNLPコンペティションを考えると、金メダルを獲得するには外部リソースが必要になります。しかし、TF-IDFソリューション（Kaggleのハードウェアを使用）で、運が良ければ銅メダルを獲得できると思います…
> 
> 
> 
---
