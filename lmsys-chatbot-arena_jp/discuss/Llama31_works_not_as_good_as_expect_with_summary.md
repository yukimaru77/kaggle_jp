# 要約 
このディスカッションは、KaggleのLMSYS - Chatbot Arena Human Preference PredictionsコンペティションにおけるLlama3.1モデルのパフォーマンスに関するものです。

多くの参加者が、Llama3.1モデルが期待通りのパフォーマンスを発揮せず、gemma-2モデルよりも劣る結果が出ていると報告しています。

具体的には、QLoRA+SFTのftメソッドを使用した場合、Llama3.1モデルのクロスバリデーションスコアが0.914と非常に低く、gemma-2モデルよりも劣る結果が出ています。

この問題の原因として、トークナイザーが正しいbosトークンを使用していない可能性が指摘されています。しかし、トークナイザーを修正してもパフォーマンスが改善しないという報告もあります。

また、他の参加者も同様の結果を得ており、Llama3.1モデルのパフォーマンスがgemma-2モデルよりも劣ることは事実のようです。

このディスカッションは、Llama3.1モデルのパフォーマンスに関する懸念を共有し、解決策を探るためのものです。参加者たちは、互いに情報交換を行い、より良い結果を得るための方法を探しています。


---
# Llama3.1 のパフォーマンスが期待通りに良くない

**justin1357** *2024年7月24日 13:44:46 (日本標準時)* (10票)

最初の1000ステップの後、Llama3.1のパフォーマンスはgemma-2よりもわずかに劣ることがわかりました。

---
# 他のユーザーからのコメント

> ## Rise_Hand
> 
> QLoRA+SFTのftメソッドを使用しているのですが、Llama3.1では非常に悪い結果が出ています。CVは0.914です。
> 
> 
> 
---
> ## Nicholas Broad
> 
> トークナイザーが[正しいbosトークン](https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct/discussions/29)を使用していることを確認してください。
> 
> 
> 
> > ## justin1357トピック作成者
> > 
> > まだパフォーマンスが悪いですね。
> > 
> > 
> > 
---
> ## Xinyuan Qiao
> 
> [@emiz6413](https://www.kaggle.com/emiz6413)のノートブックで、まったく同じパラメータでテストしたところ、評価ログ損失は0.958でした。gemma2バージョンは0.927でした。
> 
> 
> 
---
> ## sayoulala
> 
> 共有してくれてありがとうございます。素晴らしいですね！これで電気代を大幅に節約できそうです。笑
> 
> 
> 
> > ## william.wu
> > 
> > 1位は安泰ですね。改善するのは難しいです😭
> > 
> > 
> > 
---
> ## justin1357トピック作成者
> 
> 4000ステップ後、gemma-2よりも大幅に悪くなりました。笑
> 
> 
> 
---
> ## Lorry Zou
> 
> 時間とTPUクォータを節約してくれてありがとうございます😁
> 
> 
> 
---
> ## Yixiao Yuan
> 
> 私も同じです。
> 
> 
> 
---

