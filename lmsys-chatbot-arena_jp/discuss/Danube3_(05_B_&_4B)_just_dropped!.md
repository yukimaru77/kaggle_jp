# Danube3 (0.5B & 4B) がリリースされました！
**Valentin Werner** *2024年7月15日 月曜日 15:57:26 GMT+0900 (日本標準時)* (32 votes)

私はいくつかの実験で Danube2 を使用してきましたが、Kaggle の GPU で QLoRA を使用しても、DeBERTa Large よりもはるかに優れた代替手段であるように思えます。
Danube3 は 0.5B と 4B でリリースされ、チャットモデルも付属しており、このコンペティションでは有利になるかもしれません。4B モデルは、すべてのベンチマークで 1.5B の先行モデルを大幅に上回っており（サイズも少し異なります）、0.5B はほとんどのベンチマークで Qwen2 0.5B を上回っています。しかし、私にとって特に興味深いのは、4B モデルが Phi3-Mini とどのように比較されるかということです。これは、私が知っている同等のサイズの唯一のモデルです。これが Danube チームの秘密かもしれませんね？😉
私の経験では、0.5B のような小さなモデルは、Kaggle の GPU には依然として収まりません（4090 では動作するはずです）。そのため、私は 4B モデルに焦点を当てるつもりです。
また、Kaggle で非常に活発な H2O チームにも、この新しいリリースについて称賛したいと思います！才能ある研究者やデータサイエンティストがオープンな LLM の取り組みに貢献することは、常に素晴らしいことです（新しいリリースのスピードも驚異的です）。このモデルがどれほど優れているかを見るのが楽しみです！

リンク:
モデルカード: [https://huggingface.co/h2oai/h2o-danube3-4b-chat](https://huggingface.co/h2oai/h2o-danube3-4b-chat)
技術レポート: [https://arxiv.org/abs/2407.09276](https://arxiv.org/abs/2407.09276)
ベンチマーク:
[古いオープン LLM リーダーボード](https://huggingface.co/spaces/open-llm-leaderboard-old/open_llm_leaderboard)から集計したいくつかのベンチマークです。Danube3 はまだリーダーボードに含まれていませんが、モデルカードにこれらの値を報告しています。Danube3 が Gemma-7B と Mistral-7B にどれほど近いかを見るのは非常に興味深いと思います。

| カテゴリ | ベンチマーク | Danube3-4b-Chat | Danube2-1.8B-Chat | Phi-3-Mini-4K-Ins | Gemma-7B | Mistral-7B Ins 0.2 |
|---|---|---|---|---|---|---|
| 人気の集計 | MMLU (5-shot) | 54.74 | 37.77 | 69.08 | 64.56 | 60.78 |
| 言語理解 | HellaSwag (5-shot) | 80.36 | 73.54 | 80.60 | 82.20 | 84.88 |
| 推論 | ARC Challenge (5-shot) | 58.96 | 43.43 | 62.97 | 61.09 | 63.14 |
|  | TruthfulQA (0-shot) | 47.79 | 39.96 | 59.88 | 44.79 | 68.26 |
|  | WinoGrande (5-shot) | 76.48 | 69.77 | 71.6 | 79.01 | 77.19 |
| 数学 | GSM8K CoT (5-shot) | 50.18 | 26.16 | 85.7 | 50.87 | 40.03 |
| 平均 |  | 61.42 | 48.44 | 69.91 | 63.75 | 63.14 |

モデルは、microsoft phi3-mini がモデルカードで報告しているモデルに基づいて選択されました。

---
# 他のユーザーからのコメント
> ## chaneyMA
> 
> 素晴らしい仕事です!!!!
> 
> 
> 
---
> ## madarshbb
> 
> 単なる好奇心ですが、
> 
> 私の経験では、0.5B のような小さなモデルは、Kaggle の GPU には依然として収まりません（4090 では動作するはずです）。そのため、私は 4B モデルに焦点を当てるつもりです。
> 
> これはどういう意味ですか？0.5B モデルは 4B よりも収まりやすいはずではありませんか？
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > 0.5 は、量子化なしで Kaggle でトレーニングできないほどちょうど良い大きさです。これは、DeBERTa Large とほぼ同じサイズです。
> > 
> > 
> > 
---
> ## Abhay Ayare
> 
> 素晴らしいガイドですね！データサイエンティストになるための貴重なリソースと洞察を共有していただきありがとうございます。データサイエンスに対するあなたの情熱は、刺激的です。「Kaggle for Beginners」という本を調べてみたいと思います。
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > Kaggle の本はたくさんありますが、私は確かにそのうちの1冊を書いたわけではありません 😉
> > 
> > 
> > 
---
> ## sayoulala
> 
> 共有していただきありがとうございます。このコンペティションのモデルによるスコアを教えていただけますか？
> 
> 
> 
> > ## Valentin Wernerトピック作成者
> > 
> > まだトレーニングしていません。いくつかの実験（それほど熱心ではありませんでしたが）で、danube2-1.8B を 0.98x にすることができました。
> > 
> > 
> > 
---
> ## The-Hai Nguyen
> 
> あなたは、PII 検出コンペティションからずっと、私の学習の進捗に光を当ててきました。本当に感謝していますし、あなたの共有に感謝しています。それは、私や他の人の旅を通して多くのことを学ぶのに役立ちます 🙏。
> 
> 
> 
---

