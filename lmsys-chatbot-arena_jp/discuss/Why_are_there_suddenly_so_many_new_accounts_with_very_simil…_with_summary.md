# 要約 
このディスカッションは、Kaggleコンペティションで、多くの新規アカウントが突然現れ、似たような高いスコア（0.941）を記録していることに対する懸念を表明しています。

ユーザーは、この現象が、公開されたノートブックで提供されているGemma 2推論コードを利用した結果であると推測しています。このコードは、高いスコアを簡単に達成できるため、新規アカウントがそれを利用してランキングを上げるために作成された可能性があると指摘されています。

議論の中で、ユーザーは、このコードの利用がコンペティションの公平性に影響を与えている可能性を懸念し、コンペティションのルールや倫理的な問題について議論しています。また、Gemma 2とLlama3のどちらが優れているか、同じ条件下で比較する必要があるという意見も出ています。

このディスカッションは、コンペティションにおける不正行為やデータの共有に関する倫理的な問題を浮き彫りにしています。コンペティション主催者は、このような状況に対処するために、ルールを明確化したり、不正行為に対する対策を強化する必要があるかもしれません。


---
# なぜ急に似たようなスコアの新規アカウントが増えたのですか？
**Robert0921** *2024年7月12日 金曜日 11:58:20 GMT+0900 (日本標準時)* (-1 votes)
PBを見ると、過去1日でほぼ100個の新規アカウントが突然現れ、それらのスコアはすべて0.941でした。何か問題があるのでしょうか？
---
# 他のユーザーからのコメント
> ## Valentin Werner
> 
> シルバーソリューションを無料で提供しています！
> 
> 
> 
> > ## Cody_Null
> > 
> > 幸いにも、コンペティション終了時にはメダル圏外になると思いますが、コンペティションの最後の月にメダルを獲得できるノートブックを見るのはいつも面白いですね。
> > 
> > 
> > 
> > > ## Valentin Werner
> > > 
> > > 一番驚くのは、コピーして提出することです。初期に参加して、その後は提出していない場合は理解できます。しかし、次に何が起こるかというと、5つのノートブックがこれらをアンサンブルして、.940、.939、…というスコアを、新しいアイデアなしに取得することです。
> > > 
> > > これは、私の意見では、Kaggleのやり方ではありません。
> > > 
> > > このアプローチが共有されたのは素晴らしいことだと思います。なぜなら、多くの人がGPUリソースを使って何かを動かすのに苦労しているからです。共有されたノートブックは「少しだけうまく機能する」だけです。
> > > 
> > > 
> > > 
---
> ## Xinyuan Qiao
> 
> PBで0.941のGemma 2推論コードを提供する新しいノートブックがあります。私の元のスコアは0.942でした😂
> 
> 
> 
> > ## yechenzhi1
> > 
> > アンサンブルしてみましょう😂
> > 
> > 
> > 
> > > ## Lorry Zou
> > > 
> > > 私の0.957 Llama3推論とアンサンブルしてみたところ、0.959になりました😅😅
> > > 
> > > 
> > > 
> > > ## Allen Wang
> > > 
> > > [@lorryzouzelun](https://www.kaggle.com/lorryzouzelun) GemmaとLlama3の統合は効果的ですか？試してみたのですが、LBが大幅に下がりました。
> > > 
> > > 
> > > 
> > ## Robert0921トピック作成者
> > 
> > 
> > PBで0.941のGemma 2推論コードを提供する新しいノートブックがあります。私の元のスコアは0.942でした😂
> > 
> > 同じ条件下で、どちらが良いのでしょうか？Gemma 2とLlama3
> > 
> > 
> > 
> > > ## Xinyuan Qiao
> > > 
> > > わかりません。Gemmaのノートブック提供者は、トレーニングにA6000を使用しており、ハイパーパラメータはわかりません。両方を同じパラメータでトレーニングして、後で返信します。
> > > 
> > > 
> > > 
---

