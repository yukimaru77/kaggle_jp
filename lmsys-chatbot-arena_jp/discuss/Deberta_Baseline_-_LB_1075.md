# Deberta ベースライン - LB 1.075
**Fritz Cremer** *2024年5月3日 金曜日 21:45:56 GMT+0900 (日本標準時)* (5 votes)

Deberta-v3-base を使った非常に簡単なベースラインを作成しました。
[https://www.kaggle.com/code/fritzcremer/lmsys-deberta-v3-base-baseline/notebook](https://www.kaggle.com/code/fritzcremer/lmsys-deberta-v3-base-baseline/notebook)

現時点では、トレーニングデータのほんの一部しか使用しておらず、スコアも良くありません。しかし、これは Deberta を使った提出コードの例です。

改善点としては、以下のようなものがあります。

- 全てのデータを使用する
- K-Fold 交差検証
- 応答を交換してデータを増やす
- 損失関数を変更する

特に最後の項目は重要です。2段階モデルにするのが良いかもしれません。最初の段階では、応答がデュエルで勝ったかどうかを予測するだけ（もう一方の応答は提供しない）、2段階目では、そのような予測を2つと手作業で作成した特徴量を使って、より良い応答を予測します。これは非常に興味深いコンペティションで、明確な道筋がないように思えます。

ご意見をお聞かせください！

---
# 他のユーザーからのコメント
> ## Nicholas Broad
> 
> ご存知かもしれませんが、これは基本的にランダムな推測です。
> 
> ```
> from sklearn.metrics import log_loss
> log_loss([1], [[1/3, 1/3, 1/3]], labels=[0,1,2])
> 
> # 1.0986122886681098
> 
> ```
> 
> 
> 
> > ## Valentin Werner
> > 
> > ノートブックはラベルの分布を正確に複製しています。Huggingface Trainer を使った基本的なスターターでは、データから学習できないようです。
> > 
> > 
> > 
> > ## Fritz Cremerトピック作成者
> > 
> > [@nbroad](https://www.kaggle.com/nbroad) はい、知っています。これは、Huggingface でこのタスクに適したモデルを構築するための一般的な設定のようなものでした。トレーニングが非常に不安定であることがわかりました。一部の実行では、モデルはラベルの分布以上のものを学習しました（たとえば、LB では、提出されたバージョンでノートブックが 1.075 を記録しています）。しかし、他の実行では完全に失敗しました。しかし、繰り返しになりますが、これは全く調整されていないアプローチであり、最初の日の簡単なアプローチです 😄
> > 
> > 
> > 
---

