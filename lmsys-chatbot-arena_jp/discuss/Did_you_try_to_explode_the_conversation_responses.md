# 会話応答を分割して試しましたか？
**Mattia Vanzetto** *2024年8月1日木曜日 04:42:15 GMT+0900 (日本標準時)* (0票)
皆さん、こんにちは。

トレーニングデータの約86%は、単一のプロンプトと応答で構成されていることがわかりました。しかし、14%はそうではありません。また、少なくとも公開されているノートブックでは、ファインチューニングされたモデルは通常、最大シーケンス長が2000/2400文字で、モデルに組み込まれるプロンプトは、prompt_list + response_a_list + response_b_listのみです。これは、response_bが完全に切り捨てられるか、情報が失われる可能性があることを意味します。

会話応答を分割し、モデルをファインチューニングしてから、個々の会話部分に対する予測を集計することを試しましたか？

単一の会話部分「prompt_i + response_a_i + response_b_i」の平均/中央値の長さは2000〜2400文字で、この実験に最適なようです。

私も試してみたいのですが、ファインチューニングの経験も、計算能力も、時間もないので😂

参考までに、単純なxgboostで、同じ特徴量の前処理、同じ最適化手順で試したところ、分割して集計するアプローチではリーダーボードで1.03、標準的なアプローチでは1.04でした。

もう1つやってみたかった実験は、プロンプト + response_Xのみを考慮し、ターゲットを相対的なwinner_model_Xとするバイナリ分類器を作成することです。これにより、行数を2倍にすることができます。「相手の応答」は考慮しません。その後、すべてを再び集計します。

コンペティション終了後にソリューションを見るのが楽しみです。

コンペティションの残りの数日間、頑張ってください🍀

---
# 他のユーザーからのコメント
> ## JM
> 
> 試しましたが、推論時間が増え、パブリックLBの改善は見られませんでした。
> 
> 
> 
---
> ## Yi-Fu Chen
> 
> 
> もう1つやってみたかった実験は、プロンプト + response_Xのみを考慮し、ターゲットを相対的なwinner_model_Xとするバイナリ分類器を作成することです。これにより、行数を2倍にすることができます。「相手の応答」は考慮しません。その後、すべてを再び集計します。
> 
> 似たような概念を考えたのですが、勝ち負けは比較されるので、直感的に理にかなっていないように思えます。
> 
> 
> 
> > ## Mattia Vanzettoトピック作成者
> > 
> > 負けと引き分けのことですか？そうすると、この2つは「比較」されることになります。
> > 
> > 
> > 
---

