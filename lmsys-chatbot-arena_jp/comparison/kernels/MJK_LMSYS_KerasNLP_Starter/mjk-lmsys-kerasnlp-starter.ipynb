{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b4562a",
   "metadata": {},
   "source": [
    "# è¦ç´„ \n",
    "ã“ã®Jupyter Notebookã¯ã€KerasãŠã‚ˆã³KerasNLPã‚’ä½¿ç”¨ã—ã¦ã€LMSYS - Chatbot Arenaã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã«ãŠã‘ã‚‹äººé–“ã«ã‚ˆã‚‹å¥½ã¿äºˆæ¸¬ã®ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã™ã‚‹ã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã™ã€‚å…·ä½“çš„ã«ã¯ã€LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®å¿œç­”ã«å¯¾ã—ã¦ã€ã©ã®å¿œç­”ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¥½ã¾ã‚Œã‚‹ã‹ã‚’äºˆæ¸¬ã™ã‚‹å•é¡Œã«å–ã‚Šçµ„ã‚“ã§ã„ã¾ã™ã€‚\n",
    "\n",
    "## å•é¡Œ\n",
    "ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ç›®çš„ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæç¤ºã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã—ã¦è¤‡æ•°ã®å¿œç­”ã‹ã‚‰é¸ã‚“ã å ´åˆã«ã€ãã®é¸ã°ã‚Œã‚‹å¯èƒ½æ€§ã®é«˜ã„å¿œç­”ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã‚Œã¯ã€å¤šæ•°ã®LLMã‹ã‚‰ã®å¿œç­”ã«åŸºã¥ã„ã¦è¡Œã‚ã‚Œã¾ã™ã€‚\n",
    "\n",
    "## ä½¿ç”¨ã—ã¦ã„ã‚‹æ‰‹æ³•\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€**DebertaV3**ã¨ã„ã†ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã€é¸æŠè‚¢å•é¡Œã®å½¢å¼ã§å¿œç­”ã‚’å‡¦ç†ã—ã¦ã„ã¾ã™ã€‚å…·ä½“çš„ã«ã¯ã€å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’ãƒšã‚¢ã§ä½¿ç”¨ã—ã€LLMãŒã©ã®å¿œç­”ã‚’å¥½ã¾ã—ãè©•ä¾¡ã™ã‚‹ã‹ã‚’å­¦ç¿’ã—ã¾ã™ã€‚ãƒ¢ãƒ‡ãƒ«ã«ã¯KerasNLPã‚’ä½¿ç”¨ã—ã€æ··åˆç²¾åº¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’åˆ©ç”¨ã™ã‚‹ã“ã¨ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚é–“ã‚’çŸ­ç¸®ã—ã€GPUã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æ¸›ã‚‰ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "## ä½¿ç”¨ã—ã¦ã„ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "- **Keras**: ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä½¿ç”¨ã•ã‚Œã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæŒ‡å®šã—ãŸãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼ˆTensorFlowã€PyTorchã€JAXï¼‰ã‚’é¸æŠã—ã¦ä½¿ç”¨ã§ãã¾ã™ã€‚\n",
    "- **KerasNLP**: NLPã®ãŸã‚ã«è¨­è¨ˆã•ã‚ŒãŸKerasã®ã‚µãƒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€ç‰¹ã«DebertaV3ã®ã‚ˆã†ãªæ§˜ã€…ãªäº‹å‰å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚\n",
    "- **TensorFlow**: ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã®ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã€‚\n",
    "- **NumPy/Pandas**: ãƒ‡ãƒ¼ã‚¿æ“ä½œãŠã‚ˆã³åˆ†æã«ä½¿ç”¨ã€‚\n",
    "- **Matplotlib/Plotly**: ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–ã«ä½¿ç”¨ã€‚\n",
    "\n",
    "## ãã®ä»–\n",
    "ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã‹ã‚‰å‰å‡¦ç†ã€ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã€è¨“ç·´ã€äºˆæ¸¬ã€æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆã¾ã§ã®ãƒ—ãƒ­ã‚»ã‚¹ãŒè©³ç´°ã«ç¤ºã•ã‚Œã¦ãŠã‚Šã€å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®ã‚³ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚å¤šæ®µéšã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’å–ã‚Šå…¥ã‚Œã¦ãŠã‚Šã€æœ€è‰¯ã®ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚‚è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚ã¾ãŸã€ä»Šå¾Œã®æ”¹å–„ãƒã‚¤ãƒ³ãƒˆã¨ã—ã¦ã€å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã¸ã®æ‹¡å¤§ã€ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã€å¿œç­”ã®é †åºã‚·ãƒ£ãƒƒãƒ•ãƒ«ã€ã‚¨ãƒãƒƒã‚¯æ•°ã®å¢—åŠ ãªã©ãŒææ¡ˆã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6da78",
   "metadata": {},
   "source": [
    "# ç”¨èªæ¦‚èª¬ \n",
    "ä»¥ä¸‹ã¯ã€Jupyter Notebookã«é–¢é€£ã™ã‚‹å°‚é–€ç”¨èªã®ç°¡å˜ãªè§£èª¬ã§ã™ã€‚ç‰¹ã«ã€åˆå¿ƒè€…ãŒã¤ã¾ãšãã‚„ã™ã„è©³ç´°ã‚„å®Ÿå‹™çµŒé¨“ãŒãªã„ã¨é¦´æŸ“ã¿ãŒè–„ã„ã‚‚ã®ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "### å°‚é–€ç”¨èªã®è§£èª¬\n",
    "\n",
    "1. **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° (Fine-tuning)**:\n",
    "   äº‹å‰ã«å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ã«æ–°ãŸãªãƒ‡ãƒ¼ã‚¿ã‚’ç”¨ã„ã¦è¿½åŠ ã®å­¦ç¿’ã‚’è¡Œã†ã“ã¨ã€‚ç‰¹ã«è»¢ç§»å­¦ç¿’ã®æ–‡è„ˆã§ã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã«ç‰¹åŒ–ã•ã›ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚\n",
    "\n",
    "2. **æ··åˆç²¾åº¦ (Mixed Precision)**:\n",
    "   ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ™‚ã«ç•°ãªã‚‹ç²¾åº¦ã®ãƒ‡ãƒ¼ã‚¿å‹ã‚’æ··ãœã¦ä½¿ç”¨ã™ã‚‹æŠ€è¡“ã€‚é€šå¸¸ã€è¨ˆç®—å‡¦ç†ã®åŠ¹ç‡ã‚’é«˜ã‚ã€GPUãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€‚ãŸã¨ãˆã°ã€`float16`ï¼ˆåŠç²¾åº¦ï¼‰ã¨`float32`ï¼ˆå˜ç²¾åº¦ï¼‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã€‚\n",
    "\n",
    "3. **å‰å‡¦ç†å™¨ (Preprocessor)**:\n",
    "   ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ã—ã¦ä½¿ç”¨ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã™ã‚‹ãŸã‚ã®ãƒ„ãƒ¼ãƒ«ã€‚å…·ä½“çš„ã«ã¯ã€ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã€æ­£è¦åŒ–ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ç­‰ãŒå«ã¾ã‚Œã‚‹ã€‚\n",
    "\n",
    "4. **ãƒˆãƒ¼ã‚¯ãƒ³åŒ– (Tokenization)**:\n",
    "   ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ„å‘³ã®ã‚ã‚‹å˜ä½ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ï¼‰ã«åˆ†å‰²ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã—ã‚„ã™ã„å½¢å¼ã«å¤‰æ›ã§ãã‚‹ã€‚\n",
    "\n",
    "5. **ãƒ‘ãƒ‡ã‚£ãƒ³ã‚° (Padding)**:\n",
    "   ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚’ä¸€å®šã«ã™ã‚‹ãŸã‚ã«ã€çŸ­ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«è¿½åŠ ã®ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆé€šå¸¸ã¯ã‚¼ãƒ­ï¼‰ã‚’ä»˜ä¸ã™ã‚‹ã“ã¨ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ãƒŸãƒ‹ãƒãƒƒãƒå‡¦ç†ã‚’åŠ¹ç‡çš„ã«è¡Œã†ã“ã¨ãŒå¯èƒ½ã«ãªã‚‹ã€‚\n",
    "\n",
    "6. **ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (Encoding)**:\n",
    "   æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã€‚ç‰¹ã«ã€ãƒ¢ãƒ‡ãƒ«ãŒãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã§ãã‚‹å½¢å¼ã«å¤‰æ›ã™ã‚‹ãŸã‚ã«é‡è¦ã§ã€UTF-8ãªã©ã®æ¨™æº–çš„ãªæ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ãŒä½¿ã‚ã‚Œã‚‹ã€‚\n",
    "\n",
    "7. **å±¤åˆ¥åŒ– (Stratification)**:\n",
    "   ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã™ã‚‹éš›ã«ã€ç‰¹å®šã®å±æ€§ã«åŸºã¥ã„ã¦ãã®åˆ†å¸ƒã‚’ä¿ã¤ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã€‚ç‰¹ã«ã€ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒ«ãŒå‡ç­‰ã«åˆ†å‰²ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€‚\n",
    "\n",
    "8. **ãƒ­ã‚¹ (Loss)**:\n",
    "   ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ãŒæ­£è§£ã¨ã©ã‚Œã ã‘ä¹–é›¢ã—ã¦ã„ã‚‹ã‹ã‚’ç¤ºã™æŒ‡æ¨™ã€‚å­¦ç¿’ä¸­ã¯ã“ã®å€¤ã‚’æœ€å°åŒ–ã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹ã€‚`ãƒ­ã‚°ãƒ­ã‚¹`ã¯ç‰¹ã«ã€ã‚¯ãƒ©ã‚¹ç¢ºç‡ã®äºˆæ¸¬ç²¾åº¦ã‚’æ¸¬ã‚‹ãŸã‚ã«ç”¨ã„ã‚‰ã‚Œã‚‹ã€‚\n",
    "\n",
    "9. **ã‚¦ã‚§ã‚¤ãƒˆã‚·ã‚§ã‚¢ãƒªãƒ³ã‚° (Weight Sharing)**:\n",
    "   è¤‡æ•°ã®éƒ¨åˆ†ã§åŒä¸€ã®é‡ã¿ã‚’å…±æœ‰ã™ã‚‹ã“ã¨ã€‚ç‰¹ã«ã€åŒã˜å…¥åŠ›å½¢å¼ã®ç•°ãªã‚‹éƒ¨åˆ†ï¼ˆä¾‹ãˆã°ã€ç•°ãªã‚‹å¿œç­”ã®å‡¦ç†ï¼‰ã«åŒã˜ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹æ‰‹æ³•ã€‚\n",
    "\n",
    "10. **ãƒ¡ãƒˆãƒªãƒƒã‚¯ (Metric)**:\n",
    "    ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è©•ä¾¡ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹æŒ‡æ¨™ã€‚ç²¾åº¦ã‚„ãƒ­ã‚¹ãªã©ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ¸¬ã‚‹ãŸã‚ã«é¸æŠã•ã‚Œã‚‹ã€‚\n",
    "\n",
    "11. **å…¥åŠ›å±¤ (Input Layer)**:\n",
    "    ãƒ¢ãƒ‡ãƒ«ã«ãƒ‡ãƒ¼ã‚¿ã‚’ä¾›çµ¦ã™ã‚‹ãŸã‚ã®å±¤ã§ã€ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´ã‚’å®šç¾©ã—ã¾ã™ã€‚å½¢çŠ¶ã‚„ãƒ‡ãƒ¼ã‚¿å‹ãŒæŒ‡å®šã•ã‚Œã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã™ã€‚\n",
    "\n",
    "12. **ã‚°ãƒ­ãƒ¼ãƒãƒ«å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚° (Global Average Pooling)**:\n",
    "    ç‰¹å¾´ãƒãƒƒãƒ—å…¨ä½“ã®å¹³å‡ã‚’è¨ˆç®—ã—ã¦å‡ºåŠ›ã™ã‚‹å±¤ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚„ç”»åƒã®æƒ…å ±ã‚’åœ§ç¸®ã—ã€éå‰°é©åˆã‚’é˜²ãæ‰‹åŠ©ã‘ãŒã•ã‚Œã‚‹ã€‚\n",
    "\n",
    "ã“ã‚Œã‚‰ã®ç”¨èªã¯ã€ç‰¹ã«å®Ÿå‹™çµŒé¨“ãŒãªã„åˆå­¦è€…ã«ã¨ã£ã¦ã¯é¦´æŸ“ã¿ãŒè–„ã„ã‚‚ã®ãŒå¤šã„ã§ã™ãŒã€ç†è§£ãŒæ·±ã¾ã‚‹ã¨åŒæ™‚ã«æ©Ÿæ¢°å­¦ç¿’ã‚„æ·±å±¤å­¦ç¿’ã®å®Ÿè·µçš„ãªã‚¹ã‚­ãƒ«å‘ä¸Šã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f6492",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Keras logo\" width=\"100\"><br/>\n",
    "This starter notebook is provided by the Keras team.</center>\n",
    "\n",
    "# LMSYS - Chatbot Arena Human Preference Predictions with [KerasNLP](https://github.com/keras-team/keras-nlp) and [Keras](https://github.com/keras-team/keras)\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.ibb.co/wJMF5HL/lmsys.png\">\n",
    "</div>\n",
    "\n",
    "In this competition, our aim is to predict which LLM responses users will prefer in a head-to-head battle between chatbots powered by large language models (LLMs). In other words, the goal of the competition is to predict the preferences of the judges and determine the likelihood that a given prompt/response pair is selected as the winner. This notebook will guide you through the process of fine-tuning the **DebertaV3** model for this competition using the **Shared Weight** strategy with KerasNLP. This strategy is similar to how Multiple Choice Question (MCQ) models are trained. Additionally, we will use mixed precision for faster training and inference.\n",
    "\n",
    "**Did you know**: This notebook is backend-agnostic, which means it supports TensorFlow, PyTorch, and JAX backends. However, the best performance can be achieved with `JAX`. KerasNLP and Keras enable the choice of the preferred backend. Explore further details on [Keras](https://keras.io/keras_3/).\n",
    "\n",
    "**Note**: For a deeper understanding of KerasNLP, refer to the [KerasNLP guides](https://keras.io/keras_nlp/).\n",
    "\n",
    "\n",
    "# ğŸ“š | Import Libraries \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Kerasã®ãƒ­ã‚´\" width=\"100\"><br/>\n",
    "ã“ã®ã‚¹ã‚¿ãƒ¼ã‚¿ãƒ¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯Kerasãƒãƒ¼ãƒ ã«ã‚ˆã£ã¦æä¾›ã•ã‚Œã¦ã„ã¾ã™ã€‚</center>\n",
    "\n",
    "# LMSYS - Chatbot Arena äººé–“ã«ã‚ˆã‚‹å¥½ã¿äºˆæ¸¬ [KerasNLP](https://github.com/keras-team/keras-nlp) ã¨ [Keras](https://github.com/keras-team/keras) ã‚’ä½¿ç”¨\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.ibb.co/wJMF5HL/lmsys.png\">\n",
    "</div>\n",
    "\n",
    "ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§ã¯ã€æˆ‘ã€…ã®ç›®çš„ã¯ã€LLMï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼‰ã«ã‚ˆã£ã¦å‹•ã‹ã•ã‚Œã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆåŒå£«ã®å¯¾æˆ¦ã«ãŠã„ã¦ã€ã©ã®LLMã®å¿œç­”ãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ã«å¥½ã¾ã‚Œã‚‹ã‹ã‚’äºˆæ¸¬ã™ã‚‹ã“ã¨ã§ã™ã€‚è¨€ã„æ›ãˆã‚Œã°ã€ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ç›®æ¨™ã¯ã€å¯©æŸ»å“¡ã®å¥½ã¿ã‚’äºˆæ¸¬ã—ã€ç‰¹å®šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ/å¿œç­”ãƒšã‚¢ãŒå‹è€…ã¨ã—ã¦é¸ã°ã‚Œã‚‹å¯èƒ½æ€§ã‚’æ±ºå®šã™ã‚‹ã“ã¨ã§ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€KerasNLPã‚’ä½¿ç”¨ã—ã¦ã€ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãŸã‚ã«**DebertaV3**ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ãƒ—ãƒ­ã‚»ã‚¹ã‚’æ¡ˆå†…ã—ã¾ã™ã€‚ã“ã®æˆ¦ç•¥ã¯ã€é¸æŠè‚¢å•é¡Œï¼ˆMCQï¼‰ãƒ¢ãƒ‡ãƒ«ãŒãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚Œã‚‹æ–¹æ³•ã«ä¼¼ã¦ã„ã¾ã™ã€‚ã•ã‚‰ã«ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã‚’è¿…é€ŸåŒ–ã™ã‚‹ãŸã‚ã«æ··åˆç²¾åº¦ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "**ã”å­˜çŸ¥ã§ã—ãŸã‹**: ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ä¾å­˜ã—ãªã„ãŸã‚ã€TensorFlowã€PyTorchã€JAXã®ã„ãšã‚Œã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ã‚‚å¯¾å¿œã—ã¦ã„ã¾ã™ã€‚ãŸã ã—ã€æœ€è‰¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’é”æˆã™ã‚‹ã«ã¯ `JAX` ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚KerasNLPã¨Kerasã¯ã€å¥½ã¿ã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’é¸æŠã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¦ã„ã¾ã™ã€‚ã•ã‚‰ãªã‚‹è©³ç´°ã¯[Keras](https://keras.io/keras_3/)ã§ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "**æ³¨æ„**: KerasNLPã«ã¤ã„ã¦ã®ã‚ˆã‚Šæ·±ã„ç†è§£ã‚’å¾—ã‚‹ãŸã‚ã«ã¯ã€[KerasNLPã‚¬ã‚¤ãƒ‰](https://keras.io/keras_nlp/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "# ğŸ“š | ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ea48a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import plotly.express as px\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "import os\n",
    "# Kerasã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’\"jax\"ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "# \"tensorflow\" ã¾ãŸã¯ \"torch\" ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # ã¾ãŸã¯ \"tensorflow\" ã¾ãŸã¯ \"torch\"\n",
    "\n",
    "# KerasNLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import keras_nlp\n",
    "# Kerasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import keras\n",
    "# TensorFlowãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import tensorflow as tf\n",
    "\n",
    "# æ•°å€¤è¨ˆç®—ã®ãŸã‚ã®NumPyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import numpy as np \n",
    "# ãƒ‡ãƒ¼ã‚¿æ“ä½œã®ãŸã‚ã®Pandasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import pandas as pd\n",
    "# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¡¨ç¤ºã®ãŸã‚ã®tqdmãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "from tqdm import tqdm\n",
    "# JSONæ“ä½œã®ãŸã‚ã®jsonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import json\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•æç”»ã®ãŸã‚ã®Matplotlibãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlibã®è¨­å®šã‚’è¡Œã†ãŸã‚ã®mplãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import matplotlib as mpl\n",
    "# Plotlyã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®expressãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import plotly.express as px\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:09.411574Z",
     "iopub.status.busy": "2024-07-03T03:01:09.410774Z",
     "iopub.status.idle": "2024-07-03T03:01:09.417451Z",
     "shell.execute_reply": "2024-07-03T03:01:09.416382Z",
     "shell.execute_reply.started": "2024-07-03T03:01:09.411539Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Kerasã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’\"jax\"ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "# \"tensorflow\" ã¾ãŸã¯ \"torch\" ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # ã¾ãŸã¯ \"tensorflow\" ã¾ãŸã¯ \"torch\"\n",
    "\n",
    "# KerasNLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import keras_nlp\n",
    "# Kerasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import keras\n",
    "# TensorFlowãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import tensorflow as tf\n",
    "\n",
    "# æ•°å€¤è¨ˆç®—ã®ãŸã‚ã®NumPyãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import numpy as np \n",
    "# ãƒ‡ãƒ¼ã‚¿æ“ä½œã®ãŸã‚ã®Pandasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import pandas as pd\n",
    "# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®è¡¨ç¤ºã®ãŸã‚ã®tqdmãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "from tqdm import tqdm\n",
    "# JSONæ“ä½œã®ãŸã‚ã®jsonãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import json\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•æç”»ã®ãŸã‚ã®Matplotlibãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlibã®è¨­å®šã‚’è¡Œã†ãŸã‚ã®mplãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import matplotlib as mpl\n",
    "# Plotlyã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹ãŸã‚ã®expressãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f364b6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Library Version\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff0d570",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Keras:\", keras.__version__)\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ç¾åœ¨ã®TensorFlowã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# ç¾åœ¨ã®Kerasã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"Keras:\", keras.__version__)\n",
    "# ç¾åœ¨ã®KerasNLPã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:20.664741Z",
     "iopub.status.busy": "2024-07-03T03:01:20.663852Z",
     "iopub.status.idle": "2024-07-03T03:01:20.670008Z",
     "shell.execute_reply": "2024-07-03T03:01:20.668776Z",
     "shell.execute_reply.started": "2024-07-03T03:01:20.664707Z"
    }
   },
   "outputs": [],
   "source": [
    "# ç¾åœ¨ã®TensorFlowã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# ç¾åœ¨ã®Kerasã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"Keras:\", keras.__version__)\n",
    "# ç¾åœ¨ã®KerasNLPã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799abc9",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# âš™ï¸ | Configuration\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# âš™ï¸ | è¨­å®š\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1673f97",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    seed = 42  # Random seed\n",
    "    preset = \"deberta_v3_extra_small_en\" # Name of pretrained models\n",
    "    sequence_length = 512  # Input sequence length\n",
    "    epochs = 3 # Training epochs\n",
    "    batch_size = 16  # Batch size\n",
    "    scheduler = 'cosine'  # Learning rate scheduler\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    class_labels = list(label2name.keys())\n",
    "    class_names = list(label2name.values())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    seed = 42  # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰\n",
    "    # ä½¿ç”¨ã™ã‚‹äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "    preset = \"deberta_v3_extra_small_en\" # äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åå‰\n",
    "    # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    sequence_length = 512  # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•\n",
    "    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    epochs = 3 # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°\n",
    "    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "    batch_size = 16  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚¿ã‚¤ãƒ—ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    scheduler = 'cosine'  # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©\n",
    "    # ãƒ©ãƒ™ãƒ«ã¨ãã®åå‰ã®å¯¾å¿œã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    # åå‰ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    # ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    class_labels = list(label2name.keys())\n",
    "    # ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    class_names = list(label2name.values())\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:22.100663Z",
     "iopub.status.busy": "2024-07-03T03:01:22.100299Z",
     "iopub.status.idle": "2024-07-03T03:01:22.106816Z",
     "shell.execute_reply": "2024-07-03T03:01:22.105711Z",
     "shell.execute_reply.started": "2024-07-03T03:01:22.100634Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    seed = 42  # ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰\n",
    "    # ä½¿ç”¨ã™ã‚‹äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åå‰ã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "    preset = \"deberta_v3_extra_small_en\" # äº‹å‰ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®åå‰\n",
    "    # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    sequence_length = 512  # å…¥åŠ›ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®é•·ã•\n",
    "    # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯ã®æ•°ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    epochs = 3 # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚¨ãƒãƒƒã‚¯æ•°\n",
    "    # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’æŒ‡å®šã—ã¾ã™ã€‚\n",
    "    batch_size = 16  # ãƒãƒƒãƒã‚µã‚¤ã‚º\n",
    "    # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ã®ã‚¿ã‚¤ãƒ—ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    scheduler = 'cosine'  # å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©\n",
    "    # ãƒ©ãƒ™ãƒ«ã¨ãã®åå‰ã®å¯¾å¿œã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    # åå‰ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’å–å¾—ã™ã‚‹è¾æ›¸ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    # ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    class_labels = list(label2name.keys())\n",
    "    # ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    class_names = list(label2name.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41757606",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# â™»ï¸ | Reproducibility \n",
    "Sets value for random seed to produce similar result in each run.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# â™»ï¸ | å†ç¾æ€§\n",
    "ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã®å€¤ã‚’è¨­å®šã—ã¦ã€å„å®Ÿè¡Œã§é¡ä¼¼ã—ãŸçµæœã‚’å¾—ã‚‰ã‚Œã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82482fc9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keras.utils.set_random_seed(CFG.seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# Kerasã§ä½¿ç”¨ã™ã‚‹ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "keras.utils.set_random_seed(CFG.seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:23.340681Z",
     "iopub.status.busy": "2024-07-03T03:01:23.340338Z",
     "iopub.status.idle": "2024-07-03T03:01:23.34536Z",
     "shell.execute_reply": "2024-07-03T03:01:23.344456Z",
     "shell.execute_reply.started": "2024-07-03T03:01:23.340653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasã§ä½¿ç”¨ã™ã‚‹ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994f69c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ§® | Mixed Precision\n",
    "\n",
    "In this notebook, we will use mixed precision instead of float32 precision for training and inference to reduce GPU memory usage. This will ultimately allow us to use larger batch sizes, thus reducing our training and inference time.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ§® | æ··åˆç²¾åº¦\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®éš›ã«float32ç²¾åº¦ã®ä»£ã‚ã‚Šã«æ··åˆç²¾åº¦ã‚’ä½¿ç”¨ã—ã¦ã€GPUãƒ¡ãƒ¢ãƒªã®ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨æ¨è«–ã®æ™‚é–“ã‚’çŸ­ç¸®ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd48a39",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# Kerasã®å…¨ä½“çš„ãªãƒãƒªã‚·ãƒ¼ã‚’æ··åˆç²¾åº¦ï¼ˆmixed_float16ï¼‰ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:34.266272Z",
     "iopub.status.busy": "2024-07-03T03:01:34.265925Z",
     "iopub.status.idle": "2024-07-03T03:01:34.270737Z",
     "shell.execute_reply": "2024-07-03T03:01:34.269676Z",
     "shell.execute_reply.started": "2024-07-03T03:01:34.266246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasã®å…¨ä½“çš„ãªãƒãƒªã‚·ãƒ¼ã‚’æ··åˆç²¾åº¦ï¼ˆmixed_float16ï¼‰ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6482a09d",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ“ | Dataset Path \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ“ | ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ‘ã‚¹\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad901dc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:39.653268Z",
     "iopub.status.busy": "2024-07-03T03:01:39.652928Z",
     "iopub.status.idle": "2024-07-03T03:01:39.657264Z",
     "shell.execute_reply": "2024-07-03T03:01:39.656349Z",
     "shell.execute_reply.started": "2024-07-03T03:01:39.653242Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec238a7",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ“– | Meta Data \n",
    "\n",
    "The competition dataset comprises user interactions from the ChatBot Arena. In each interaction, a judge presents one or more prompts to two different large language models and then indicates which model provided the more satisfactory response. The training data contains `55,000` rows, with an expected `25,000` rows in the test set.\n",
    "\n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n",
    "\n",
    "\n",
    "## Train Data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ“– | ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€ChatBot Arenaã‹ã‚‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã§ã¯ã€å¯©æŸ»å“¡ãŒ2ã¤ã®ç•°ãªã‚‹å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã«å¯¾ã—ã¦1ã¤ä»¥ä¸Šã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æç¤ºã—ã€ã©ã®ãƒ¢ãƒ‡ãƒ«ãŒã‚ˆã‚Šæº€è¶³ã®ã„ãå¿œç­”ã‚’æä¾›ã—ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã«ã¯`55,000`è¡ŒãŒå«ã¾ã‚Œã¦ãŠã‚Šã€ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã«ã¯ç´„`25,000`è¡ŒãŒæœŸå¾…ã•ã‚Œã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "## ãƒ•ã‚¡ã‚¤ãƒ«\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: å„è¡Œã®ä¸€æ„ã®è­˜åˆ¥å­ã€‚\n",
    "- `model_[a/b]`: ãƒ¢ãƒ‡ãƒ«ã®è­˜åˆ¥å­ã€‚train.csvã«ã¯å­˜åœ¨ã—ã¾ã™ãŒã€test.csvã«ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚\n",
    "- `prompt`: ä¸¡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‰ã‚Œã‚‹å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚\n",
    "- `response_[a/b]`: ãƒ¢ãƒ‡ãƒ«_[a/b]ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã€‚\n",
    "- `winner_model_[a/b/tie]`: å¯©æŸ»å“¡ã®é¸æŠï¼ˆæ­£è§£ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰ã‚’ç¤ºã™ãƒã‚¤ãƒŠãƒªåˆ—ã€‚\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: å„è¡Œã®ä¸€æ„ã®è­˜åˆ¥å­ã€‚\n",
    "- `prompt`: ä¸¡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ã«ä¸ãˆã‚‰ã‚Œã‚‹å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‚\n",
    "- `response_[a/b]`: ãƒ¢ãƒ‡ãƒ«_[a/b]ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã€‚\n",
    "\n",
    "> æ³¨æ„: å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯è¤‡æ•°ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ãŒã‚ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ãŒã€ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯**å„ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã«ã¤ã1ã¤ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ**ã®ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã™ã¹ã¦ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚ã¾ãŸã€ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ å†…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã¯æ–‡å­—åˆ—å½¢å¼ã®ãƒªã‚¹ãƒˆã¨ã—ã¦æä¾›ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€`eval()`ã‚’ä½¿ç”¨ã—ã¦ãƒªãƒ†ãƒ©ãƒ«ãƒªã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "\n",
    "## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f5fc9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load Train Data\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# Sample data\n",
    "# df = df.sample(frac=0.10)\n",
    "\n",
    "# Take the first prompt and its associated response\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Label conversion\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# Show Sample\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "# df = df.sample(frac=0.10)\n",
    "\n",
    "# æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãã®é–¢é€£ã™ã‚‹å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«ã®å¤‰æ›ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:41.865573Z",
     "iopub.status.busy": "2024-07-03T03:01:41.865244Z",
     "iopub.status.idle": "2024-07-03T03:01:49.241992Z",
     "shell.execute_reply": "2024-07-03T03:01:49.24084Z",
     "shell.execute_reply.started": "2024-07-03T03:01:41.865549Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿\n",
    "# df = df.sample(frac=0.10)\n",
    "\n",
    "# æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãã®é–¢é€£ã™ã‚‹å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# ãƒ©ãƒ™ãƒ«ã®å¤‰æ›ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69f1c3",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Test Data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68d1581",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load Test Data\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# Take the first prompt and response\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# Show Sample\n",
    "test_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "test_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:00.748821Z",
     "iopub.status.busy": "2024-07-03T03:02:00.748482Z",
     "iopub.status.idle": "2024-07-03T03:02:00.766516Z",
     "shell.execute_reply": "2024-07-03T03:02:00.765701Z",
     "shell.execute_reply.started": "2024-07-03T03:02:00.748794Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# æœ€åˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac025986",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Contextualize Response with Prompt\n",
    "\n",
    "In our approach, we will contextualize each response with the prompt instead of using a single prompt for all responses. This means that for each response, we will provide the model with the same set of prompts combined with their respective response (e.g., `(P + R_A)`, `(P + R_B)`, etc.). This approach is similar to the multiple-choice question task in NLP.\n",
    "\n",
    "> Note that some prompts and responses may not be encoded with `utf-8`, resulting in errors when creating the dataloader. In such cases, we will replace them with an empty string.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«ã‚ˆã‚‹å¿œç­”ã®æ–‡è„ˆåŒ–\n",
    "\n",
    "æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€ã™ã¹ã¦ã®å¿œç­”ã«å¯¾ã—ã¦å˜ä¸€ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã®ã§ã¯ãªãã€å„å¿œç­”ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§æ–‡è„ˆåŒ–ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€å„å¿œç­”ã«å¯¾ã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ã«ãã‚Œãã‚Œã®å¿œç­”ã¨çµ„ã¿åˆã‚ã›ãŸåŒã˜ã‚»ãƒƒãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æä¾›ã™ã‚‹ã“ã¨ã«ãªã‚Šã¾ã™ï¼ˆä¾‹: `(P + R_A)`ã€`(P + R_B)`ãªã©ï¼‰ã€‚ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¯ã€NLPã«ãŠã‘ã‚‹é¸æŠè‚¢å•é¡Œã®ã‚¿ã‚¹ã‚¯ã«é¡ä¼¼ã—ã¦ã„ã¾ã™ã€‚\n",
    "\n",
    "> æ³¨æ„: ä¸€éƒ¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚„å¿œç­”ãŒ`utf-8`ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„å ´åˆã€ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆã™ã‚‹éš›ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚ãã®å ´åˆã€ç©ºã®æ–‡å­—åˆ—ã«ç½®ãæ›ãˆã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799e8de",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Define a function to create options based on the prompt and choices\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # Response from Model A\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # Response from Model B\n",
    "                     ]\n",
    "    return row\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨é¸æŠè‚¢ã«åŸºã¥ã„ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # ãƒ¢ãƒ‡ãƒ«Aã®å¿œç­”ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # ãƒ¢ãƒ‡ãƒ«Bã®å¿œç­”ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’çµ„ã¿åˆã‚ã›ãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # ãƒ¢ãƒ‡ãƒ«Aã‹ã‚‰ã®å¿œç­”\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # ãƒ¢ãƒ‡ãƒ«Bã‹ã‚‰ã®å¿œç­”\n",
    "                     ]\n",
    "    return row\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:03.654162Z",
     "iopub.status.busy": "2024-07-03T03:02:03.653385Z",
     "iopub.status.idle": "2024-07-03T03:02:03.660622Z",
     "shell.execute_reply": "2024-07-03T03:02:03.659762Z",
     "shell.execute_reply.started": "2024-07-03T03:02:03.654128Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨é¸æŠè‚¢ã«åŸºã¥ã„ã¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # ãƒ¢ãƒ‡ãƒ«Aã®å¿œç­”ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # ãƒ¢ãƒ‡ãƒ«Bã®å¿œç­”ã‚’UTF-8ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€ãƒ‡ã‚³ãƒ¼ãƒ‰ã—ã¾ã™ã€‚\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯ç©ºã®æ–‡å­—åˆ—ã«ã—ã¾ã™ã€‚\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã‚’çµ„ã¿åˆã‚ã›ãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # ãƒ¢ãƒ‡ãƒ«Aã‹ã‚‰ã®å¿œç­”\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # ãƒ¢ãƒ‡ãƒ«Bã‹ã‚‰ã®å¿œç­”\n",
    "                     ]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218d867",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df = df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(df.head(2))  # Display the first 2 rows of df\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # Apply the make_pairs function to each row in df\n",
    "display(test_df.head(2))  # Display the first 2 rows of df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# make_pairsé–¢æ•°ã‚’dfã®å„è¡Œã«é©ç”¨ã—ã¾ã™ã€‚\n",
    "df = df.apply(make_pairs, axis=1)  \n",
    "# dfã®æœ€åˆã®2è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "display(df.head(2))  \n",
    "\n",
    "# make_pairsé–¢æ•°ã‚’test_dfã®å„è¡Œã«é©ç”¨ã—ã¾ã™ã€‚\n",
    "test_df = test_df.apply(make_pairs, axis=1)  \n",
    "# test_dfã®æœ€åˆã®2è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "display(test_df.head(2))\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:04.251033Z",
     "iopub.status.busy": "2024-07-03T03:02:04.250673Z",
     "iopub.status.idle": "2024-07-03T03:03:06.883282Z",
     "shell.execute_reply": "2024-07-03T03:03:06.882333Z",
     "shell.execute_reply.started": "2024-07-03T03:02:04.251004Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_pairsé–¢æ•°ã‚’dfã®å„è¡Œã«é©ç”¨ã—ã¾ã™ã€‚\n",
    "df = df.apply(make_pairs, axis=1)  \n",
    "# dfã®æœ€åˆã®2è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "display(df.head(2))  \n",
    "\n",
    "# make_pairsé–¢æ•°ã‚’test_dfã®å„è¡Œã«é©ç”¨ã—ã¾ã™ã€‚\n",
    "test_df = test_df.apply(make_pairs, axis=1)  \n",
    "# test_dfã®æœ€åˆã®2è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b14e6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Encoding Fail Statistics\n",
    "\n",
    "Let's examine how many samples have encoding issues. From the code below, we can see that only $1\\%$ of the samples failed to be encoded, while $99\\%$ of the samples don't have any issues. A similar pattern can be expected for the test data as well. Thus, considering empty strings for this small portion of the data will not have much impact on our training and inference.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—çµ±è¨ˆ\n",
    "\n",
    "ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®å•é¡ŒãŒã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’ç¢ºèªã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã«å¤±æ•—ã—ãŸã‚µãƒ³ãƒ—ãƒ«ã¯ã‚ãšã‹$1\\%$ã§ã‚ã‚Šã€$99\\%$ã®ã‚µãƒ³ãƒ—ãƒ«ã«ã¯å•é¡ŒãŒãªã„ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚‚åŒæ§˜ã®å‚¾å‘ãŒæœŸå¾…ã§ãã¾ã™ã€‚ã“ã®ãŸã‚ã€ãƒ‡ãƒ¼ã‚¿ã®ã”ãä¸€éƒ¨ã‚’ç©ºã®æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã£ã¦ã‚‚ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚„æ¨è«–ã«å¤§ããªå½±éŸ¿ã¯ãªã„ã§ã—ã‚‡ã†ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5f6e9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df.encode_fail.value_counts(normalize=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—ã®çµ±è¨ˆã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚\n",
    "df.encode_fail.value_counts(normalize=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:25.535096Z",
     "iopub.status.busy": "2024-07-03T03:03:25.534482Z",
     "iopub.status.idle": "2024-07-03T03:03:25.5487Z",
     "shell.execute_reply": "2024-07-03T03:03:25.547732Z",
     "shell.execute_reply.started": "2024-07-03T03:03:25.535061Z"
    }
   },
   "outputs": [],
   "source": [
    "# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¤±æ•—ã®çµ±è¨ˆã‚’ã‚«ã‚¦ãƒ³ãƒˆã—ã¾ã™ã€‚\n",
    "df.encode_fail.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8405e4",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ¨ | Exploratory Data Analysis (EDA)\n",
    "\n",
    "## LLM Distribution\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ¨ | æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æ (EDA)\n",
    "\n",
    "## LLMã®åˆ†å¸ƒ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b01ee5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Create a bar plot with custom styling using Plotly\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='Distribution of LLMs',\n",
    "             color='Count', color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "fig.show()\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ¢ãƒ‡ãƒ«Aã¨ãƒ¢ãƒ‡ãƒ«Bã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¾ã™ã€‚\n",
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "# å„ãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Plotlyã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã®æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='LLMã®åˆ†å¸ƒ',\n",
    "             color='Count', color_continuous_scale='viridis')\n",
    "\n",
    "# xè»¸ãƒ©ãƒ™ãƒ«ã‚’å›è»¢ã•ã›ã¦ã€èª­ã¿ã‚„ã™ãã—ã¾ã™ã€‚\n",
    "fig.update_layout(xaxis_tickangle=-45)  \n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:28.92519Z",
     "iopub.status.busy": "2024-07-03T03:03:28.924349Z",
     "iopub.status.idle": "2024-07-03T03:03:30.427658Z",
     "shell.execute_reply": "2024-07-03T03:03:30.426828Z",
     "shell.execute_reply.started": "2024-07-03T03:03:28.925156Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«Aã¨ãƒ¢ãƒ‡ãƒ«Bã®ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¾ã™ã€‚\n",
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "# å„ãƒ¢ãƒ‡ãƒ«ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Plotlyã‚’ä½¿ç”¨ã—ã¦ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã®æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='LLMã®åˆ†å¸ƒ',\n",
    "             color='Count', color_continuous_scale='viridis')\n",
    "\n",
    "# xè»¸ãƒ©ãƒ™ãƒ«ã‚’å›è»¢ã•ã›ã¦ã€èª­ã¿ã‚„ã™ãã—ã¾ã™ã€‚\n",
    "fig.update_layout(xaxis_tickangle=-45)  \n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4ddbe",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Winning Distribution\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## å‹åˆ©ã®åˆ†å¸ƒ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8100e8e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "             title='Winner distribution for Train Data',\n",
    "             labels={'Winner': 'Winner', 'Win Count': 'Win Count'},\n",
    "             color='Winner', color_continuous_scale='viridis')\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Winner\", yaxis_title=\"Win Count\")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# å‹è€…ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å‹è€…åˆ†å¸ƒã‚’ç¤ºã™æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "             title='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å‹è€…åˆ†å¸ƒ',\n",
    "             labels={'Winner': 'å‹è€…', 'Win Count': 'å‹åˆ©ã®æ•°'},\n",
    "             color='Winner', color_continuous_scale='viridis')\n",
    "\n",
    "# xè»¸ã¨yè»¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "fig.update_layout(xaxis_title=\"å‹è€…\", yaxis_title=\"å‹åˆ©ã®æ•°\")\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:32.598799Z",
     "iopub.status.busy": "2024-07-03T03:03:32.598445Z",
     "iopub.status.idle": "2024-07-03T03:03:32.699131Z",
     "shell.execute_reply": "2024-07-03T03:03:32.698246Z",
     "shell.execute_reply.started": "2024-07-03T03:03:32.59877Z"
    }
   },
   "outputs": [],
   "source": [
    "# å‹è€…ã®ã‚«ã‚¦ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å‹è€…åˆ†å¸ƒã‚’ç¤ºã™æ£’ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "             title='ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®å‹è€…åˆ†å¸ƒ',\n",
    "             labels={'Winner': 'å‹è€…', 'Win Count': 'å‹åˆ©ã®æ•°'},\n",
    "             color='Winner', color_continuous_scale='viridis')\n",
    "\n",
    "# xè»¸ã¨yè»¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "fig.update_layout(xaxis_title=\"å‹è€…\", yaxis_title=\"å‹åˆ©ã®æ•°\")\n",
    "\n",
    "# ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e5a186",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ”ª | Data Split\n",
    "\n",
    "In the code snippet provided below, we will divide the existing data into training and validation using a stratification of `class_label` column.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ”ª | ãƒ‡ãƒ¼ã‚¿åˆ†å‰²\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆã§ã¯ã€`class_label`åˆ—ã®å±¤åˆ¥åŒ–ã‚’ä½¿ç”¨ã—ã¦ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3559214",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split  # Import package\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "from sklearn.model_selection import train_test_split  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ã¾ã™ã€‚\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:34.279102Z",
     "iopub.status.busy": "2024-07-03T03:03:34.278745Z",
     "iopub.status.idle": "2024-07-03T03:03:35.091617Z",
     "shell.execute_reply": "2024-07-03T03:03:35.090834Z",
     "shell.execute_reply.started": "2024-07-03T03:03:34.279073Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚\n",
    "from sklearn.model_selection import train_test_split  # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã¨æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²ã—ã¾ã™ã€‚\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ff81f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ½ï¸ | Preprocessing\n",
    "\n",
    "**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n",
    "\n",
    "**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n",
    "\n",
    "Explore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n",
    "- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ½ï¸ | å‰å‡¦ç†\n",
    "\n",
    "**ä½•ã‚’ã™ã‚‹ã®ã‹:** å‰å‡¦ç†å™¨ã¯å…¥åŠ›æ–‡å­—åˆ—ã‚’å—ã‘å–ã‚Šã€ãã‚Œã‚’å‰å‡¦ç†ã•ã‚ŒãŸãƒ†ãƒ³ã‚½ãƒ«ã‚’å«ã‚€è¾æ›¸ï¼ˆ`token_ids`, `padding_mask`ï¼‰ã«å¤‰æ›ã—ã¾ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚»ã‚¹ã¯ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ã‹ã‚‰å§‹ã¾ã‚Šã€å…¥åŠ›æ–‡å­—åˆ—ãŒãƒˆãƒ¼ã‚¯ãƒ³IDã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "**ãªãœé‡è¦ãªã®ã‹:** ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ã€ãã®é«˜æ¬¡å…ƒæ€§ã®ãŸã‚ã«ãƒ¢ãƒ‡ãƒ«åŒ–ãŒé›£ã—ãã€è¤‡é›‘ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒˆãƒ¼ã‚¯ãƒ³ã®ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªã‚»ãƒƒãƒˆã«å¤‰æ›ã™ã‚‹ã“ã¨ã§ã€ä¾‹ãˆã° `\"The quick brown fox\"` ã‚’ `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]` ã«å¤‰æ›ã™ã‚‹ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚’å˜ç´”åŒ–ã—ã¾ã™ã€‚å¤šãã®ãƒ¢ãƒ‡ãƒ«ã¯ã€ç‰¹åˆ¥ãªãƒˆãƒ¼ã‚¯ãƒ³ã‚„è¿½åŠ ã®ãƒ†ãƒ³ã‚½ãƒ«ã‚’ä½¿ç”¨ã—ã¦å…¥åŠ›ã‚’ç†è§£ã—ã¾ã™ã€‚ã“ã‚Œã‚‰ã®ãƒˆãƒ¼ã‚¯ãƒ³ã¯ã€å…¥åŠ›ã‚’åˆ†å‰²ã—ã€ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç‰¹å®šã™ã‚‹ãªã©ã®ã‚¿ã‚¹ã‚¯ã«å½¹ç«‹ã¡ã¾ã™ã€‚ã™ã¹ã¦ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã‚’ä½¿ã£ã¦åŒã˜é•·ã•ã«ã™ã‚‹ã“ã¨ã§ã€è¨ˆç®—åŠ¹ç‡ãŒå‘ä¸Šã—ã€ãã®å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ãŒã‚¹ãƒ ãƒ¼ã‚ºã«ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "**KerasNLP**ã§åˆ©ç”¨å¯èƒ½ãªå‰å‡¦ç†ãŠã‚ˆã³ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼å±¤ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ãƒšãƒ¼ã‚¸ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n",
    "- [å‰å‡¦ç†](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼](https://keras.io/api/keras_nlp/tokenizers/)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be303231",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # Name of the model\n",
    "    sequence_length=CFG.sequence_length, # Max sequence length, will be padded if shorter\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# DebertaV3ãƒ¢ãƒ‡ãƒ«ã®å‰å‡¦ç†å™¨ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # ãƒ¢ãƒ‡ãƒ«ã®åå‰\n",
    "    sequence_length=CFG.sequence_length, # æœ€å¤§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã€çŸ­ã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:38.194065Z",
     "iopub.status.busy": "2024-07-03T03:03:38.193696Z",
     "iopub.status.idle": "2024-07-03T03:03:42.601299Z",
     "shell.execute_reply": "2024-07-03T03:03:42.600413Z",
     "shell.execute_reply.started": "2024-07-03T03:03:38.194034Z"
    }
   },
   "outputs": [],
   "source": [
    "# DebertaV3ãƒ¢ãƒ‡ãƒ«ã®å‰å‡¦ç†å™¨ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # ãƒ¢ãƒ‡ãƒ«ã®åå‰\n",
    "    sequence_length=CFG.sequence_length, # æœ€å¤§ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã€çŸ­ã„å ´åˆã¯ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°ã•ã‚Œã‚‹\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41a75c3",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Now, let's examine what the output shape of the preprocessing layer looks like. The output shape of the layer can be represented as $(num\\_responses, sequence\\_length)$.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "æ¬¡ã«ã€å‰å‡¦ç†å±¤ã®å‡ºåŠ›å½¢çŠ¶ãŒã©ã®ã‚ˆã†ã«ãªã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã—ã‚‡ã†ã€‚å±¤ã®å‡ºåŠ›å½¢çŠ¶ã¯ $(num\\_responses, sequence\\_length)$ ã¨ã—ã¦è¡¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136de24",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "outs = preprocessor(df.options.iloc[0])  # Process options for the first row\n",
    "\n",
    "# Display the shape of each processed output\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# æœ€åˆã®è¡Œã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã—ã¾ã™ã€‚\n",
    "outs = preprocessor(df.options.iloc[0])  \n",
    "\n",
    "# å„å‡¦ç†ã•ã‚ŒãŸå‡ºåŠ›ã®å½¢çŠ¶ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:44.404213Z",
     "iopub.status.busy": "2024-07-03T03:03:44.403854Z",
     "iopub.status.idle": "2024-07-03T03:03:45.484601Z",
     "shell.execute_reply": "2024-07-03T03:03:45.483734Z",
     "shell.execute_reply.started": "2024-07-03T03:03:44.404184Z"
    }
   },
   "outputs": [],
   "source": [
    "# æœ€åˆã®è¡Œã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†ã—ã¾ã™ã€‚\n",
    "outs = preprocessor(df.options.iloc[0])  \n",
    "\n",
    "# å„å‡¦ç†ã•ã‚ŒãŸå‡ºåŠ›ã®å½¢çŠ¶ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32685d",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "`preprocessing_fn`é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã€`dataset.map(preprocessing_fn)`ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»‹ã—ã¦å„ãƒ†ã‚­ã‚¹ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’å¤‰æ›ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97323f21",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # Preprocess text\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def preprocess_fn(text, label=None):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ã—ã¾ã™ã€‚\n",
    "    text = preprocessor(text)  \n",
    "    # ãƒ©ãƒ™ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ã€å‡¦ç†ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "    return (text, label) if label is not None else text\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:51.848513Z",
     "iopub.status.busy": "2024-07-03T03:03:51.848175Z",
     "iopub.status.idle": "2024-07-03T03:03:51.853591Z",
     "shell.execute_reply": "2024-07-03T03:03:51.852609Z",
     "shell.execute_reply.started": "2024-07-03T03:03:51.848488Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def preprocess_fn(text, label=None):\n",
    "    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å‰å‡¦ç†ã—ã¾ã™ã€‚\n",
    "    text = preprocessor(text)  \n",
    "    # ãƒ©ãƒ™ãƒ«ãŒåˆ©ç”¨å¯èƒ½ã§ã‚ã‚Œã°ã€å‡¦ç†ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’è¿”ã—ã¾ã™ã€‚\n",
    "    return (text, label) if label is not None else text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf006dd",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸš | DataLoader\n",
    "\n",
    "The code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n",
    "\n",
    "To learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data).\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸš | ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã®ãŸã‚ã«`tf.data.Dataset`ã‚’ä½¿ç”¨ã—ã¦å …ç‰¢ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚`tf.data`ã®ä¸»ãªç‰¹å¾´ã¯ã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰ã‚’ç°¡ç´ åŒ–ã—ã€ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã§è¡¨ç¾ã§ãã‚‹ç‚¹ã§ã™ã€‚\n",
    "\n",
    "`tf.data`ã«é–¢ã™ã‚‹è©³ç´°ã¯ã€ã“ã®[ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://www.tensorflow.org/guide/data)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443f3fc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNE option\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # Create dataset from slices\n",
    "    ds = ds.cache() if cache else ds  # Cache dataset if enabled\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # Map preprocessing function\n",
    "    opt = tf.data.Options()  # Create dataset options\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # Shuffle dataset if enabled\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)  # Set dataset options\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # Batch dataset\n",
    "    ds = ds.prefetch(AUTO)  # Prefetch next batch\n",
    "    return ds  # Return the built dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNEã‚ªãƒ—ã‚·ãƒ§ãƒ³\n",
    "    # ãƒ©ãƒ™ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€slicesã‚’ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ãƒ—ãƒ«ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ä½œæˆ\n",
    "    # ã‚¹ãƒ©ã‚¤ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚\n",
    "    ds = ds.cache() if cache else ds  \n",
    "    # å‰å‡¦ç†é–¢æ•°ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  \n",
    "    opt = tf.data.Options()  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n",
    "    if shuffle: \n",
    "        # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¾ã™ã€‚\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  \n",
    "        opt.experimental_deterministic = False\n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    ds = ds.with_options(opt)  \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒƒãƒåŒ–ã—ã¾ã™ã€‚\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  \n",
    "    # æ¬¡ã®ãƒãƒƒãƒã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã—ã¾ã™ã€‚\n",
    "    ds = ds.prefetch(AUTO)  \n",
    "    return ds  # æ§‹ç¯‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿”ã—ã¾ã™\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:55.445788Z",
     "iopub.status.busy": "2024-07-03T03:03:55.445396Z",
     "iopub.status.idle": "2024-07-03T03:03:55.454007Z",
     "shell.execute_reply": "2024-07-03T03:03:55.452986Z",
     "shell.execute_reply.started": "2024-07-03T03:03:55.445757Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNEã‚ªãƒ—ã‚·ãƒ§ãƒ³\n",
    "    # ãƒ©ãƒ™ãƒ«ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€slicesã‚’ãƒ†ã‚­ã‚¹ãƒˆã®ã‚¿ãƒ—ãƒ«ã«è¨­å®šã—ã¾ã™ã€‚\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # ã‚¹ãƒ©ã‚¤ã‚¹ã‚’ä½œæˆ\n",
    "    # ã‚¹ãƒ©ã‚¤ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  \n",
    "    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãŒæœ‰åŠ¹ãªå ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã—ã¾ã™ã€‚\n",
    "    ds = ds.cache() if cache else ds  \n",
    "    # å‰å‡¦ç†é–¢æ•°ã‚’ãƒãƒƒãƒ”ãƒ³ã‚°ã—ã¾ã™ã€‚\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  \n",
    "    opt = tf.data.Options()  # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½œæˆ\n",
    "    if shuffle: \n",
    "        # ã‚·ãƒ£ãƒƒãƒ•ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã€ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¾ã™ã€‚\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  \n",
    "        opt.experimental_deterministic = False\n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’è¨­å®šã—ã¾ã™ã€‚\n",
    "    ds = ds.with_options(opt)  \n",
    "    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒãƒƒãƒåŒ–ã—ã¾ã™ã€‚\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  \n",
    "    # æ¬¡ã®ãƒãƒƒãƒã‚’ãƒ—ãƒªãƒ•ã‚§ãƒƒãƒã—ã¾ã™ã€‚\n",
    "    ds = ds.prefetch(AUTO)  \n",
    "    return ds  # æ§‹ç¯‰ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è¿”ã—ã¾ã™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1810e1f0",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Build Train/Valid Dataloader\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ§‹ç¯‰\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07e4816",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Train\n",
    "train_texts = train_df.options.tolist()  # Extract training texts\n",
    "train_labels = train_df.class_label.tolist()  # Extract training labels\n",
    "train_ds = build_dataset(train_texts, train_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# Valid\n",
    "valid_texts = valid_df.options.tolist()  # Extract validation texts\n",
    "valid_labels = valid_df.class_label.tolist()  # Extract validation labels\n",
    "valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "train_texts = train_df.options.tolist()  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º\n",
    "train_labels = train_df.class_label.tolist()  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "train_ds = build_dataset(train_texts, train_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "valid_texts = valid_df.options.tolist()  # æ¤œè¨¼ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º\n",
    "valid_labels = valid_df.class_label.tolist()  # æ¤œè¨¼ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:07.792009Z",
     "iopub.status.busy": "2024-07-03T03:06:07.791295Z",
     "iopub.status.idle": "2024-07-03T03:06:13.267405Z",
     "shell.execute_reply": "2024-07-03T03:06:13.266631Z",
     "shell.execute_reply.started": "2024-07-03T03:06:07.791974Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "train_texts = train_df.options.tolist()  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º\n",
    "train_labels = train_df.class_label.tolist()  # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "train_ds = build_dataset(train_texts, train_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡ºã—ã¾ã™ã€‚\n",
    "valid_texts = valid_df.options.tolist()  # æ¤œè¨¼ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º\n",
    "valid_labels = valid_df.class_label.tolist()  # æ¤œè¨¼ãƒ©ãƒ™ãƒ«ã‚’æŠ½å‡º\n",
    "# æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf1a80",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# âš“ | LR Schedule\n",
    "\n",
    "Implementing a learning rate scheduler is crucial for transfer learning. The learning rate initiates at `lr_start` and gradually tapers down to `lr_min` using various techniques, including:\n",
    "- `step`: Lowering the learning rate in step-wise manner resembling stairs.\n",
    "- `cos`: Utilizing a cosine curve to gradually reduce the learning rate.\n",
    "- `exp`: Exponentially decreasing the learning rate.\n",
    "\n",
    "**Importance:** A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# âš“ | å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«\n",
    "\n",
    "å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã®å®Ÿè£…ã¯ã€è»¢ç§»å­¦ç¿’ã«ãŠã„ã¦éå¸¸ã«é‡è¦ã§ã™ã€‚å­¦ç¿’ç‡ã¯`lr_start`ã‹ã‚‰å§‹ã¾ã‚Šã€ã•ã¾ã–ã¾ãªæ‰‹æ³•ã‚’ç”¨ã„ã¦å¾ã€…ã«`lr_min`ã¾ã§æ¸›å°‘ã—ã¾ã™ã€‚æ‰‹æ³•ã«ã¯ä»¥ä¸‹ãŒå«ã¾ã‚Œã¾ã™:\n",
    "- `step`: ã‚¹ãƒ†ãƒƒãƒ—çŠ¶ã«å­¦ç¿’ç‡ã‚’ä¸‹ã’ã‚‹æ–¹æ³•ã§ã€éšæ®µã®ã‚ˆã†ã«è¦‹ãˆã¾ã™ã€‚\n",
    "- `cos`: ã‚³ã‚µã‚¤ãƒ³ã‚«ãƒ¼ãƒ–ã‚’åˆ©ç”¨ã—ã¦ã€å­¦ç¿’ç‡ã‚’å¾ã€…ã«æ¸›å°‘ã•ã›ã‚‹æ–¹æ³•ã§ã™ã€‚\n",
    "- `exp`: å­¦ç¿’ç‡ã‚’æŒ‡æ•°çš„ã«æ¸›å°‘ã•ã›ã‚‹æ–¹æ³•ã§ã™ã€‚\n",
    "\n",
    "**é‡è¦æ€§:** é©åˆ‡ã«æ§‹ç¯‰ã•ã‚ŒãŸå­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ã€åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã«ä¸å¯æ¬ ã§ã‚ã‚Šã€æœ€é©ãªåæŸã‚’ä¿è¨¼ã—ã€ã‚ªãƒ¼ãƒãƒ¼ã‚·ãƒ¥ãƒ¼ãƒˆã‚„åœæ»ã¨ã„ã£ãŸå•é¡Œã‚’é¿ã‘ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6193c79e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # Plot lr curve if plot is True\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('LR Scheduler')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "# å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # å­¦ç¿’ç‡ã®é–‹å§‹ã€æœ€å¤§ã€æœ€å°å€¤ã‚’è¨­å®š\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # å­¦ç¿’ç‡ãƒ©ãƒ³ãƒ—ã®ã‚¨ãƒãƒƒã‚¯æ•°ã€æŒç¶šã‚¨ãƒãƒƒã‚¯æ•°ã€æ¸›è¡°ç‡ã‚’è¨­å®š\n",
    "\n",
    "    def lrfn(epoch):  # å­¦ç¿’ç‡æ›´æ–°é–¢æ•°\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # æœ€å¤§å€¤ã§ç¶­æŒ\n",
    "        elif mode == 'exp': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # æŒ‡æ•°æ¸›è¡°\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ã‚¹ãƒ†ãƒƒãƒ—æ¸›è¡°\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # plotãŒTrueã®å ´åˆã€å­¦ç¿’ç‡æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:18.470471Z",
     "iopub.status.busy": "2024-07-03T03:06:18.470112Z",
     "iopub.status.idle": "2024-07-03T03:06:18.481152Z",
     "shell.execute_reply": "2024-07-03T03:06:18.48017Z",
     "shell.execute_reply.started": "2024-07-03T03:06:18.470441Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã™ã‚‹é–¢æ•°ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # å­¦ç¿’ç‡ã®é–‹å§‹ã€æœ€å¤§ã€æœ€å°å€¤ã‚’è¨­å®š\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # å­¦ç¿’ç‡ãƒ©ãƒ³ãƒ—ã®ã‚¨ãƒãƒƒã‚¯æ•°ã€æŒç¶šã‚¨ãƒãƒƒã‚¯æ•°ã€æ¸›è¡°ç‡ã‚’è¨­å®š\n",
    "\n",
    "    def lrfn(epoch):  # å­¦ç¿’ç‡æ›´æ–°é–¢æ•°\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ãƒ©ãƒ³ãƒ—ã‚¢ãƒƒãƒ—\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # æœ€å¤§å€¤ã§ç¶­æŒ\n",
    "        elif mode == 'exp': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # æŒ‡æ•°æ¸›è¡°\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ã‚¹ãƒ†ãƒƒãƒ—æ¸›è¡°\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # ã‚³ã‚µã‚¤ãƒ³æ¸›è¡°\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # plotãŒTrueã®å ´åˆã€å­¦ç¿’ç‡æ›²ç·šã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆã™ã‚‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53dcdb6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lr_cb = get_lr_callback(CFG.batch_size, plot=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "lr_cb = get_lr_callback(CFG.batch_size, plot=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:21.533106Z",
     "iopub.status.busy": "2024-07-03T03:06:21.532624Z",
     "iopub.status.idle": "2024-07-03T03:06:21.825406Z",
     "shell.execute_reply": "2024-07-03T03:06:21.824443Z",
     "shell.execute_reply.started": "2024-07-03T03:06:21.533073Z"
    }
   },
   "outputs": [],
   "source": [
    "# å­¦ç¿’ç‡ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã™ã€‚ãƒ—ãƒ­ãƒƒãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "lr_cb = get_lr_callback(CFG.batch_size, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25858235",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ’¾ | Model Checkpointing\n",
    "\n",
    "The following code will create a callback that will save the best checkpoint of the model during training, which we will use for inference in the submission.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ’¾ | ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ãƒ¢ãƒ‡ãƒ«ã®æœ€è‰¯ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ä¿å­˜ã™ã‚‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½œæˆã—ã¾ã™ã€‚ã“ã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã¯ã€æå‡ºæ™‚ã®æ¨è«–ã«ä½¿ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89034f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',\n",
    "                                          save_best_only=True,\n",
    "                                          save_weights_only=True,\n",
    "                                          mode='min')  # Get Model checkpoint callback\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # æ¤œè¨¼ãƒ­ã‚¹ã‚’ç›£è¦–\n",
    "                                          save_best_only=True,  # æœ€è‰¯ã®ã¿ã‚’ä¿å­˜\n",
    "                                          save_weights_only=True,  # é‡ã¿ã®ã¿ã‚’ä¿å­˜\n",
    "                                          mode='min')  # æœ€å°å€¤ã§ç›£è¦–\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:24.427293Z",
     "iopub.status.busy": "2024-07-03T03:06:24.426939Z",
     "iopub.status.idle": "2024-07-03T03:06:24.432176Z",
     "shell.execute_reply": "2024-07-03T03:06:24.431208Z",
     "shell.execute_reply.started": "2024-07-03T03:06:24.427265Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å–å¾—ã—ã¾ã™ã€‚\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # æ¤œè¨¼ãƒ­ã‚¹ã‚’ç›£è¦–\n",
    "                                          save_best_only=True,  # æœ€è‰¯ã®ã¿ã‚’ä¿å­˜\n",
    "                                          save_weights_only=True,  # é‡ã¿ã®ã¿ã‚’ä¿å­˜\n",
    "                                          mode='min')  # æœ€å°å€¤ã§ç›£è¦–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101e5b82",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ“ | Metric\n",
    "\n",
    "The metric for this competition is **Log Loss**. This metric can be expressed mathematically as,\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "where $ N $ is the number of samples, $ y_i $ is the true label, and $ p_i $ is the predicted probability of the sample belonging to the positive class.\n",
    "\n",
    "Note that this metric is similar to categorical cross entropy widely used in classification tasks. Thus, we don't need to implement the loss from scratch. As the Keras library already has an implementation of this metric, we will simply use the metric to monitor performance of our model.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ“ | ãƒ¡ãƒˆãƒªãƒƒã‚¯\n",
    "\n",
    "ã“ã®ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯**ãƒ­ã‚°ãƒ­ã‚¹**ã§ã™ã€‚ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯æ•°å­¦çš„ã«æ¬¡ã®ã‚ˆã†ã«è¡¨ã•ã‚Œã¾ã™ã€‚\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "ã“ã“ã§ã€$ N $ã¯ã‚µãƒ³ãƒ—ãƒ«ã®æ•°ã€$ y_i $ã¯çœŸã®ãƒ©ãƒ™ãƒ«ã€$ p_i $ã¯ã‚µãƒ³ãƒ—ãƒ«ãŒæ­£ã®ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹äºˆæ¸¬ç¢ºç‡ã§ã™ã€‚\n",
    "\n",
    "ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¯ã€åˆ†é¡ã‚¿ã‚¹ã‚¯ã§åºƒãä½¿ç”¨ã•ã‚Œã‚‹ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã«ä¼¼ã¦ã„ã¾ã™ã€‚ã—ãŸãŒã£ã¦ã€ãƒ­ã‚¹ã‚’ã‚¼ãƒ­ã‹ã‚‰å®Ÿè£…ã™ã‚‹å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚Kerasãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®å®Ÿè£…ãŒæ—¢ã«ã‚ã‚‹ãŸã‚ã€å˜ã«ã“ã®ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ç›£è¦–ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00262bb3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ­ã‚°ãƒ­ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’Kerasã®CategoricalCrossentropyã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:26.316344Z",
     "iopub.status.busy": "2024-07-03T03:06:26.315994Z",
     "iopub.status.idle": "2024-07-03T03:06:26.340548Z",
     "shell.execute_reply": "2024-07-03T03:06:26.339407Z",
     "shell.execute_reply.started": "2024-07-03T03:06:26.316317Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ­ã‚°ãƒ­ã‚¹ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚’Kerasã®CategoricalCrossentropyã¨ã—ã¦å®šç¾©ã—ã¾ã™ã€‚\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bdf6f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ¤– | Modeling\n",
    "\n",
    "The `KerasNLP` library provides various NLP model architectures such as `Bert`, `Roberta`, `DebertaV3`, and more. While this notebook focuses on `DebertaV3`, you can explore others in the [KerasNLP documentation](https://keras.io/api/keras_nlp/models/). For a deeper understanding, refer to the [getting started guide](https://keras.io/guides/keras_nlp/getting_started/).\n",
    "\n",
    "Our approach utilizes `keras_nlp.models.DebertaV3Classifier` to process each prompt and response pair, generating output embeddings. We then concatenate these embeddings and pass them through a Pooling layer and a classifier to obtain logits, followed by a `softmax` function for the final output.\n",
    "\n",
    "When dealing with multiple responses, we use a weight-sharing strategy. This means we provide the model with one response at a time along with the prompt `(P + R_A)`, `(P + R_B)`, etc., using the same model weights for all responses. After obtaining embeddings for all responses, we concatenate them and apply average pooling. Next, we use a `Linear/Dense` layer along with the `Softmax` function as the classifier for the final result. Providing all responses at once would increase text length and complicate model handling. Note that, in the classifier, we use 3 classes for `winner_model_a`, `winner_model_b`, and `draw` cases.\n",
    "\n",
    "The diagram below illustrates this approach:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.postimg.cc/g0gcvy3f/Kaggle-drawio.png\">\n",
    "</div>\n",
    "\n",
    "From a coding perspective, note that we use the same model for all responses with shared weights, contrary to the separate models implied in the diagram.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ¤– | ãƒ¢ãƒ‡ãƒªãƒ³ã‚°\n",
    "\n",
    "`KerasNLP`ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¯ã€`Bert`ã€`Roberta`ã€`DebertaV3`ãªã©ã®ã•ã¾ã–ã¾ãªNLPãƒ¢ãƒ‡ãƒ«ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯`DebertaV3`ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã¾ã™ãŒã€ä»–ã®ãƒ¢ãƒ‡ãƒ«ã¯[KerasNLPã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://keras.io/api/keras_nlp/models/)ã§æ¢ç´¢ã§ãã¾ã™ã€‚ã‚ˆã‚Šæ·±ã„ç†è§£ã®ãŸã‚ã«ã¯ã€[å…¥é–€ã‚¬ã‚¤ãƒ‰](https://keras.io/guides/keras_nlp/getting_started/)ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "æˆ‘ã€…ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã§ã¯ã€`keras_nlp.models.DebertaV3Classifier`ã‚’åˆ©ç”¨ã—ã¦å„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨å¿œç­”ã®ãƒšã‚¢ã‚’å‡¦ç†ã—ã€å‡ºåŠ›åŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã™ã€‚ãã®å¾Œã€ã“ã‚Œã‚‰ã®åŸ‹ã‚è¾¼ã¿ã‚’é€£çµã—ã€ãƒ—ãƒ¼ãƒªãƒ³ã‚°å±¤ã¨åˆ†é¡å™¨ã‚’é€šã—ã¦ãƒ­ã‚°itsã‚’å–å¾—ã—ã€æœ€çµ‚çš„ãªå‡ºåŠ›ã®ãŸã‚ã«`softmax`é–¢æ•°ã‚’é©ç”¨ã—ã¾ã™ã€‚\n",
    "\n",
    "è¤‡æ•°ã®å¿œç­”ã‚’æ‰±ã†éš›ã«ã¯ã€ã‚¦ã‚§ã‚¤ãƒˆã‚·ã‚§ã‚¢ãƒªãƒ³ã‚°æˆ¦ç•¥ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚ã¤ã¾ã‚Šã€ãƒ¢ãƒ‡ãƒ«ã«ã¯ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ã¨ã‚‚ã«1ã¤ã®å¿œç­”ã‚’ãšã¤æä¾›ã—ã€`(P + R_A)`, `(P + R_B)`ãªã©ã®å½¢ã§å…¨ã¦ã®å¿œç­”ã«å¯¾ã—ã¦åŒã˜ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚å…¨ã¦ã®å¿œç­”ã®åŸ‹ã‚è¾¼ã¿ã‚’å–å¾—ã—ãŸå¾Œã€ãã‚Œã‚‰ã‚’é€£çµã—ã€å¹³å‡ãƒ—ãƒ¼ãƒªãƒ³ã‚°ã‚’é©ç”¨ã—ã¾ã™ã€‚æ¬¡ã«ã€`Linear/Dense`å±¤ã¨`Softmax`é–¢æ•°ã‚’åˆ†é¡å™¨ã¨ã—ã¦æœ€çµ‚çµæœã‚’å–å¾—ã—ã¾ã™ã€‚ä¸€åº¦ã«å…¨ã¦ã®å¿œç­”ã‚’æä¾›ã™ã‚‹ã¨ã€ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ãŒå¢—åŠ ã—ã€ãƒ¢ãƒ‡ãƒ«ã®æ‰±ã„ãŒè¤‡é›‘ã«ãªã‚Šã¾ã™ã€‚åˆ†é¡å™¨ã§ã¯`winner_model_a`ã€`winner_model_b`ã€ãŠã‚ˆã³`draw`ã‚±ãƒ¼ã‚¹ã®3ã¤ã®ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "ä¸‹ã®å›³ã¯ã“ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ç¤ºã—ã¦ã„ã¾ã™ï¼š\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.postimg.cc/g0gcvy3f/Kaggle-drawio.png\">\n",
    "</div>\n",
    "\n",
    "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è¦³ç‚¹ã‹ã‚‰ã¯ã€å›³ã«ç¤ºã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«åˆ¥ã€…ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ãªãã€å…±æœ‰é‡ã¿ã‚’æŒã¤åŒä¸€ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã™ã¹ã¦ã®å¿œç­”ã«ä½¿ç”¨ã™ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee2c01d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Define input layers\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "# Create a DebertaV3Classifier backbone\n",
    "backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "    CFG.preset,\n",
    ")\n",
    "\n",
    "# Compute embeddings for first response: (P + R_A) using backbone\n",
    "response_a = {k: v[:, 0, :] for k, v in inputs.items()}\n",
    "embed_a = backbone(response_a)\n",
    "\n",
    "# Compute embeddings for second response: (P + R_B), using the same backbone\n",
    "response_b = {k: v[:, 1, :] for k, v in inputs.items()}\n",
    "embed_b = backbone(response_b)\n",
    "\n",
    "# Compute final output\n",
    "embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\n",
    "embeds = keras.layers.GlobalAveragePooling1D()(embeds)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model with optimizer, loss, and metrics\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-6),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=[\n",
    "        log_loss,\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# å…¥åŠ›å±¤ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "# DebertaV3Classifierãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "    CFG.preset,\n",
    ")\n",
    "\n",
    "# æœ€åˆã®å¿œç­”: (P + R_A) ã®åŸ‹ã‚è¾¼ã¿ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "response_a = {k: v[:, 0, :] for k, v in inputs.items()}\n",
    "embed_a = backbone(response_a)\n",
    "\n",
    "# 2ç•ªç›®ã®å¿œç­”: (P + R_B) ã®åŸ‹ã‚è¾¼ã¿ã‚’ã€åŒã˜ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "response_b = {k: v[:, 1, :] for k, v in inputs.items()}\n",
    "embed_b = backbone(response_b)\n",
    "\n",
    "# æœ€çµ‚çš„ãªå‡ºåŠ›ã‚’è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\n",
    "embeds = keras.layers.GlobalAveragePooling1D()(embeds)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€æå¤±ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã¨ã‚‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-6),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=[\n",
    "        log_loss,\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:28.027331Z",
     "iopub.status.busy": "2024-07-03T03:06:28.026985Z",
     "iopub.status.idle": "2024-07-03T03:06:36.425525Z",
     "shell.execute_reply": "2024-07-03T03:06:36.424584Z",
     "shell.execute_reply.started": "2024-07-03T03:06:28.027304Z"
    }
   },
   "outputs": [],
   "source": [
    "# å…¥åŠ›å±¤ã‚’å®šç¾©ã—ã¾ã™ã€‚\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "# DebertaV3Classifierãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "    CFG.preset,\n",
    ")\n",
    "\n",
    "# æœ€åˆã®å¿œç­”: (P + R_A) ã®åŸ‹ã‚è¾¼ã¿ã‚’ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "response_a = {k: v[:, 0, :] for k, v in inputs.items()}\n",
    "embed_a = backbone(response_a)\n",
    "\n",
    "# 2ç•ªç›®ã®å¿œç­”: (P + R_B) ã®åŸ‹ã‚è¾¼ã¿ã‚’ã€åŒã˜ãƒãƒƒã‚¯ãƒœãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¦è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "response_b = {k: v[:, 1, :] for k, v in inputs.items()}\n",
    "embed_b = backbone(response_b)\n",
    "\n",
    "# æœ€çµ‚çš„ãªå‡ºåŠ›ã‚’è¨ˆç®—ã—ã¾ã™ã€‚\n",
    "embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\n",
    "embeds = keras.layers.GlobalAveragePooling1D()(embeds)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã€æå¤±ã€ãƒ¡ãƒˆãƒªãƒƒã‚¯ã¨ã¨ã‚‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã—ã¾ã™ã€‚\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-6),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=[\n",
    "        log_loss,\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79511f3",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Model Summary\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "### ãƒ¢ãƒ‡ãƒ«ã‚µãƒãƒªãƒ¼\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b075187",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:39.067045Z",
     "iopub.status.busy": "2024-07-03T03:06:39.066199Z",
     "iopub.status.idle": "2024-07-03T03:06:39.100211Z",
     "shell.execute_reply": "2024-07-03T03:06:39.099373Z",
     "shell.execute_reply.started": "2024-07-03T03:06:39.067011Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017352c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Model Plot\n",
    "\n",
    "In the model graph below, it may seem there are **four** inputs, but actually, there are **two** as discussed before. Our input consists of two parts, one for each response. However, for each input, we have `token_ids` and `padding_mask`, which makes it look like we have four inputs, but in reality, we have two inputs.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "### ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆ\n",
    "\n",
    "ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ã‚°ãƒ©ãƒ•ã§ã¯ã€**4ã¤**ã®å…¥åŠ›ãŒã‚ã‚‹ã‚ˆã†ã«è¦‹ãˆã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€å®Ÿéš›ã«ã¯å‰è¿°ã®é€šã‚Š**2ã¤**ã®å…¥åŠ›ãŒã‚ã‚Šã¾ã™ã€‚æˆ‘ã€…ã®å…¥åŠ›ã¯2ã¤ã®éƒ¨åˆ†ã‹ã‚‰æ§‹æˆã•ã‚Œã¦ãŠã‚Šã€ãã‚Œãã‚Œã®å¿œç­”ã«å¯¾ã™ã‚‹ã‚‚ã®ã§ã™ã€‚ã—ã‹ã—ã€å„å…¥åŠ›ã«ã¯`token_ids`ã¨`padding_mask`ãŒã‚ã‚‹ãŸã‚ã€4ã¤ã®å…¥åŠ›ãŒã‚ã‚‹ã‚ˆã†ã«è¦‹ãˆã¾ã™ãŒã€å®Ÿéš›ã«ã¯2ã¤ã®å…¥åŠ›ã¨ãªã‚Šã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402a83d5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Currently throwing error !! [probably library or env issue, so hopefully will be fixed soon]\n",
    "\n",
    "# keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ç¾åœ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™!! [ãŠãã‚‰ããƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ç’°å¢ƒã®å•é¡Œã§ã™ã®ã§ã€è¿‘ã„ã†ã¡ã«ä¿®æ­£ã•ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™]\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’è©¦ã¿ã¾ã™ãŒã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "# keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:42.873525Z",
     "iopub.status.busy": "2024-07-03T03:06:42.872898Z",
     "iopub.status.idle": "2024-07-03T03:06:42.87754Z",
     "shell.execute_reply": "2024-07-03T03:06:42.87662Z",
     "shell.execute_reply.started": "2024-07-03T03:06:42.873486Z"
    }
   },
   "outputs": [],
   "source": [
    "# ç¾åœ¨ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã„ã¾ã™!! [ãŠãã‚‰ããƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„ç’°å¢ƒã®å•é¡Œã§ã™ã®ã§ã€è¿‘ã„ã†ã¡ã«ä¿®æ­£ã•ã‚Œã‚‹ã“ã¨ã‚’é¡˜ã£ã¦ã„ã¾ã™]\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ—ãƒ­ãƒƒãƒˆã‚’è©¦ã¿ã¾ã™ãŒã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "# keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead0497",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸš‚ | Training\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸš‚ | ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e5830",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Start training the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=CFG.epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[lr_cb, ckpt_cb]\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=CFG.epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[lr_cb, ckpt_cb]\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:44.56032Z",
     "iopub.status.busy": "2024-07-03T03:06:44.559968Z",
     "iopub.status.idle": "2024-07-03T05:21:44.517705Z",
     "shell.execute_reply": "2024-07-03T05:21:44.516664Z",
     "shell.execute_reply.started": "2024-07-03T03:06:44.560292Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™ã€‚\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=CFG.epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[lr_cb, ckpt_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9ad688",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load Best Model\n",
    "\n",
    "After training, let's load the weight with best result to get the best performance.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "## æœ€è‰¯ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿\n",
    "\n",
    "ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãŒå®Œäº†ã—ãŸå¾Œã€æœ€è‰¯ã®çµæœã‚’å¾—ã‚‹ãŸã‚ã«é‡ã¿ã‚’èª­ã¿è¾¼ã¿ã€æœ€è‰¯ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¾—ã¾ã—ã‚‡ã†ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8060cd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# æœ€è‰¯ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:21:46.299458Z",
     "iopub.status.busy": "2024-07-03T05:21:46.299204Z",
     "iopub.status.idle": "2024-07-03T05:21:47.893914Z",
     "shell.execute_reply": "2024-07-03T05:21:47.893141Z",
     "shell.execute_reply.started": "2024-07-03T05:21:46.299433Z"
    }
   },
   "outputs": [],
   "source": [
    "# æœ€è‰¯ã®é‡ã¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f5d0d9",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ§ª | Prediction\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ§ª | äºˆæ¸¬\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4aaffd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Build test dataset\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset(test_texts,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset(test_texts,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:25:55.97338Z",
     "iopub.status.busy": "2024-07-03T05:25:55.973023Z",
     "iopub.status.idle": "2024-07-03T05:25:56.361133Z",
     "shell.execute_reply": "2024-07-03T05:25:56.360269Z",
     "shell.execute_reply.started": "2024-07-03T05:25:55.973356Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset(test_texts,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f44d24",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Make predictions using the trained model on test data\n",
    "test_preds = model.predict(test_ds, verbose=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "test_preds = model.predict(test_ds, verbose=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:26:01.567019Z",
     "iopub.status.busy": "2024-07-03T05:26:01.566397Z",
     "iopub.status.idle": "2024-07-03T05:26:06.882117Z",
     "shell.execute_reply": "2024-07-03T05:26:06.881359Z",
     "shell.execute_reply.started": "2024-07-03T05:26:01.566983Z"
    }
   },
   "outputs": [],
   "source": [
    "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã¾ã™ã€‚\n",
    "test_preds = model.predict(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d585d",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ“¬ | Submission\n",
    "\n",
    "Following code will prepare the submission file.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ“¬ | æå‡º\n",
    "\n",
    "ä»¥ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯ã€æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ã‚’ã—ã¾ã™ã€‚\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d19d16",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonã‚³ãƒ¼ãƒ‰ã®æ¯”è¼ƒï¼ˆã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨å±•é–‹ã•ã‚Œã¾ã™ï¼‰</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "sub_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "```python\n",
    "# æå‡ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "# äºˆæ¸¬çµæœã‚’è¿½åŠ ã—ã¾ã™ã€‚\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "# æœ€åˆã®æ•°è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "sub_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:26:18.174315Z",
     "iopub.status.busy": "2024-07-03T05:26:18.173702Z",
     "iopub.status.idle": "2024-07-03T05:26:18.19321Z",
     "shell.execute_reply": "2024-07-03T05:26:18.192347Z",
     "shell.execute_reply.started": "2024-07-03T05:26:18.174283Z"
    }
   },
   "outputs": [],
   "source": [
    "# æå‡ºç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "# äºˆæ¸¬çµæœã‚’è¿½åŠ ã—ã¾ã™ã€‚\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "# æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã‚’CSVå½¢å¼ã§ä¿å­˜ã—ã¾ã™ã€‚\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "# æœ€åˆã®æ•°è¡Œã‚’è¡¨ç¤ºã—ã¾ã™ã€‚\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4a525a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# ğŸ”­ | Future Directions\n",
    "\n",
    "In this notebook, we've achieved a good score with a small model and modest token length. But there's plenty of room to improve. Here's how:\n",
    "\n",
    "1. Try bigger models like `Deberta-Base` or `Deberta-Small`, or even LLMs like `Gemma`.\n",
    "2. Increase max token length to reduce loss of data.\n",
    "3. Use a five-fold cross-validation and ensemble to make the model robust and get better scores.\n",
    "4. Add augmentation like shuffling response orders for more robust performance.\n",
    "5. Train for more epochs.\n",
    "6. Tune the learning rate scheduler.\n",
    "\n",
    "# ğŸ“Œ | Reference\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLP Starter](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# æ—¥æœ¬èªè¨³\n",
    "\n",
    "# ğŸ”­ | ä»Šå¾Œã®æ–¹å‘æ€§\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€å°ã•ãªãƒ¢ãƒ‡ãƒ«ã¨æ§ãˆã‚ãªãƒˆãƒ¼ã‚¯ãƒ³é•·ã§è‰¯ã„ã‚¹ã‚³ã‚¢ã‚’é”æˆã—ã¾ã—ãŸãŒã€æ”¹å–„ã®ä½™åœ°ã¯ã¾ã ãŸãã•ã‚“ã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã®æ–¹æ³•ã§ã•ã‚‰ãªã‚‹å‘ä¸Šã‚’å›³ã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š\n",
    "\n",
    "1. `Deberta-Base`ã‚„`Deberta-Small`ã®ã‚ˆã†ãªå¤§ããªãƒ¢ãƒ‡ãƒ«ã€ã‚ã‚‹ã„ã¯`Gemma`ã®ã‚ˆã†ãªLLMã‚’è©¦ã—ã¦ã¿ã‚‹ã€‚\n",
    "2. æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³é•·ã‚’å¢—ã‚„ã—ã¦ãƒ‡ãƒ¼ã‚¿ã®æå¤±ã‚’æ¸›ã‚‰ã™ã€‚\n",
    "3. 5ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å …ç‰¢ã«ã—ã€ã‚ˆã‚Šè‰¯ã„ã‚¹ã‚³ã‚¢ã‚’å¾—ã‚‹ã€‚\n",
    "4. å¿œç­”ã®é †åºã‚’ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã™ã‚‹ãªã©ã®æ‹¡å¼µã‚’è¿½åŠ ã—ã¦ã€ã‚ˆã‚Šå …ç‰¢ãªãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’å¾—ã‚‹ã€‚\n",
    "5. ã‚ˆã‚Šå¤šãã®ã‚¨ãƒãƒƒã‚¯ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã™ã‚‹ã€‚\n",
    "6. å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã‚’èª¿æ•´ã™ã‚‹ã€‚\n",
    "\n",
    "# ğŸ“Œ | å‚è€ƒæ–‡çŒ®\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLP Starter](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
