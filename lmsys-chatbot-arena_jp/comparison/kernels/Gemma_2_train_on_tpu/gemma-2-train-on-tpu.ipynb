{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa7f6e83",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Gemma 2 9bモデルを使用して埋め込みを計算し、それに基づいて分類器をトレーニングする準備を行うものです。ノートブックは、主に埋め込みの取得に焦点を当てています。\n",
    "\n",
    "## 問題設定\n",
    "ユーザーは、Chatbot Arenaのデータを用いて、異なるモデルが生成した応答に基づいてユーザーの好みを予測するための埋め込みを計算することを目的としています。具体的には、Gemma 2モデルを利用して、プロンプトと2つのモデルの応答を組み合わせたテキストから埋め込みを生成します。これにより、機械学習モデルのトレーニングデータとして使えるベクトル表現を作成します。\n",
    "\n",
    "## 使用する手法やライブラリ\n",
    "このノートブックでは、以下のライブラリと手法が用いられています。\n",
    "\n",
    "1. **ライブラリのインポート**:\n",
    "   - `bitsandbytes`: メモリ効率を向上させるためのライブラリ。\n",
    "   - `transformers`: Hugging Faceのライブラリを使用し、Gemma 2モデルおよびトークナイザーを利用。\n",
    "   - `torch`: PyTorchライブラリを用いた深層学習。\n",
    "   - `pandas`、`numpy`、`matplotlib`: データ操作や可視化のためのライブラリ。\n",
    "\n",
    "2. **モデルの設定**:\n",
    "   - Gemma 2モデルを4ビット量子化し、2つのGPUデバイスを使用してモデルの異なるインスタンスをロードします。\n",
    "\n",
    "3. **データ前処理**:\n",
    "   - 提供されたトレーニングデータを読み込み、プロンプトと応答を整形します。\n",
    "\n",
    "4. **トークン化**:\n",
    "   - 整形したテキストをトークナイズし、PyTorchのテンソル形式に変換します。\n",
    "\n",
    "5. **埋め込みの計算**:\n",
    "   - モデルを用いてトークン化されたデータから埋め込みを計算。\n",
    "   - 並行処理を利用し、2つのスレッドで異なるデバイスを活用して埋め込みを取得します。\n",
    "\n",
    "6. **結果の保存**:\n",
    "   - 計算された埋め込みを保存し、さらにトレーニングデータをCSV形式で保存します。\n",
    "\n",
    "このノートブックは、Chatbot Arenaコンペティションのデータを活用し、LLM（大規模言語モデル）を使用したユーザーの好み予測へ向けた埋め込み計算を効率的に行うための基盤を提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff70886",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関して、機械学習や深層学習の初心者がつまずきやすい専門用語の簡単な解説を示します。この解説は、あまり一般的でない用語や、このノートブック特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **埋め込み (Embeddings)**:\n",
    "   - 文や単語等のデータを、数値ベクトル（通常は高次元）の形式で表現する方法。深層学習モデルにおいては、この数値ベクトルを用いて意味的な情報を保持しつつ、計算を効率化します。\n",
    "\n",
    "2. **量子化 (Quantization)**:\n",
    "   - モデルのサイズを小さくし、計算速度を向上させるために、浮動小数点数を低ビットの整数表現に変換する技術。ここでは「4ビット」と「float16」という形式が用いられています。\n",
    "\n",
    "3. **アテンションマスク (Attention Mask)**:\n",
    "   - トランスフォーマー型モデルにおいて、入力シーケンスのどの部分に注意を向けるべきかを指定するマスク。特に、パディングされた部分を無視するために使用されます。\n",
    "\n",
    "4. **自動混合精度計算 (Automatic Mixed Precision - AMP)**:\n",
    "   - 計算の精度を高めつつ、モデルのトレーニングや推論を高速化するために、異なるデータ型（例えば、`float16` と `float32`）を自動的に使い分ける技術。\n",
    "\n",
    "5. **ガーベジコレクション (Garbage Collection)**:\n",
    "   - プログラムが使用しているメモリを自動的に管理し、不要になったメモリを開放する仕組み。大規模データ処理ではメモリ管理が重要です。\n",
    "\n",
    "6. **スレッド (Thread)**:\n",
    "   - プログラム内での異なる作業を同時に実行するための単位。並行処理により、処理時間を短縮することを目的としています。\n",
    "\n",
    "7. **トークナイズ (Tokenization)**:\n",
    "   - テキストを単語や部分に分割するプロセス。このプロセスによって、テキストデータがモデルに入力できる形式に変換されます。\n",
    "\n",
    "8. **メモリ効率的SDP (Memory-Efficient SDP)**:\n",
    "   - 深層学習モデルのメモリ使用効率を高めるための特定の設定や技術。ここでは具体的な設定が変更されています。\n",
    "\n",
    "9. **隠れ状態 (Hidden States)**:\n",
    "   - トランスフォーマーモデル内での中間的な出力。各層で生成され、モデルの内部状態を保存しています。\n",
    "\n",
    "10. **平均プーリング (Mean Pooling)**:\n",
    "    - インプットのデータに対する平均を計算して特徴ベクトルを得る操作。特に埋め込みの取得時に利用されます。\n",
    "\n",
    "これらの定義を通じて、初心者でもNotebookの内容をよりよく理解できるようになると思います。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f59dcb",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Gemma 2 - 9b \n",
    "\n",
    "We use Gemma 2 9b model to get embeddings and train a classifier on it. This is first part and in this we only compute embed. You can also use other models. Let's get started!\n",
    "\n",
    "Upvote if you found this helpful!\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## Gemma 2 - 9b \n",
    "\n",
    "Gemma 2 9bモデルを使用して埋め込みを取得し、それに基づいて分類器をトレーニングします。これはその第一部であり、ここでは埋め込みのみを計算します。他のモデルを使用することもできます。それでは始めましょう！\n",
    "\n",
    "役に立ったら、ぜひアップボートしてください！\n",
    "\n",
    "# ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb43b084",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Import libs \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# bitsandbytesライブラリをインストールします\n",
    "!pip install -q -U bitsandbytes \n",
    "\n",
    "# Hugging FaceのtransformersライブラリをGitHubからインストールします\n",
    "!pip install -q git+https://github.com/huggingface/transformers\n",
    "\n",
    "# SentencePieceライブラリをインストールします（テキスト処理に使用します）\n",
    "!pip install sentencepiece\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32023673",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes \n",
    "!pip install -q git+https://github.com/huggingface/transformers\n",
    "!pip install sentencepiece\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートします\n",
    "import os  # OS関連の機能を提供します\n",
    "import gc  # ガーベジコレクションを扱うためのライブラリです\n",
    "import re  # 正規表現操作用ライブラリです\n",
    "from time import time  # 時間を計測するための機能をインポートします\n",
    "\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "import transformers  # transformersライブラリをインポートします\n",
    "import sklearn  # scikit-learnライブラリをインポートします（機械学習用）\n",
    "import random  # ランダム数生成用ライブラリをインポートします\n",
    "import numpy as np  # 数値計算用ライブラリをインポートします\n",
    "import pandas as pd  # データ操作用ライブラリをインポートします\n",
    "import matplotlib.pyplot as plt  # プロット作成用ライブラリをインポートします\n",
    "\n",
    "from transformers import Gemma2ForCausalLM, GemmaTokenizer, BitsAndBytesConfig  # Gemmaモデルとトークナイザーをインポート\n",
    "\n",
    "import time  # 時間計測用ライブラリを再度インポート\n",
    "from torch.cuda.amp import autocast  # 自動混合精度計算用のautocast機能をインポート\n",
    "from threading import Thread  # スレッド処理用ライブラリをインポート\n",
    "\n",
    "# CUDAのメモリ効率的なSDPを有効化します。この設定により、GPUのメモリ使用効率が改善されます\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# CUDAが利用可能でない場合、GPUが必要であることを知らせるメッセージを表示します\n",
    "# if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T17:57:07.709581Z",
     "iopub.status.busy": "2024-07-09T17:57:07.709215Z",
     "iopub.status.idle": "2024-07-09T17:57:07.715439Z",
     "shell.execute_reply": "2024-07-09T17:57:07.714762Z",
     "shell.execute_reply.started": "2024-07-09T17:57:07.709548Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします\n",
    "import os  # OS関連の機能を提供します\n",
    "import gc  # ガーベジコレクションを扱うためのライブラリです\n",
    "import re  # 正規表現操作用ライブラリです\n",
    "from time import time  # 時間を計測するための機能をインポートします\n",
    "\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "import transformers  # transformersライブラリをインポートします\n",
    "import sklearn  # scikit-learnライブラリをインポートします（機械学習用）\n",
    "import random  # ランダム数生成用ライブラリをインポートします\n",
    "import numpy as np  # 数値計算用ライブラリをインポートします\n",
    "import pandas as pd  # データ操作用ライブラリをインポートします\n",
    "import matplotlib.pyplot as plt  # プロット作成用ライブラリをインポートします\n",
    "\n",
    "from transformers import Gemma2ForCausalLM, GemmaTokenizer, BitsAndBytesConfig  # Gemmaモデルとトークナイザーをインポート\n",
    "\n",
    "import time  # 時間計測用ライブラリを再度インポート\n",
    "from torch.cuda.amp import autocast  # 自動混合精度計算用のautocast機能をインポート\n",
    "from threading import Thread  # スレッド処理用ライブラリをインポート\n",
    "\n",
    "# CUDAのメモリ効率的なSDPを有効化します。この設定により、GPUのメモリ使用効率が改善されます\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# CUDAが利用可能でない場合、GPUが必要であることを知らせるメッセージを表示します\n",
    "# if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca4d866",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import sklearn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import Gemma2ForCausalLM, GemmaTokenizer, BitsAndBytesConfig\n",
    "\n",
    "import time\n",
    "from torch.cuda.amp import autocast\n",
    "from threading import Thread\n",
    "\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbc156",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fd287f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Configs \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 設定クラスを定義します\n",
    "class CFG:\n",
    "    # モデルのパスを指定します（Kaggle上のGemma 2 9bモデルのパス）\n",
    "    MODEL_PATH = '/kaggle/input/gemma-2-9b-hf'\n",
    "    # 最大入力シーケンスの長さを設定します\n",
    "    MAX_LENGTH = 1024\n",
    "    # バッチサイズを設定します\n",
    "    BATCH_SIZE = 2\n",
    "    \n",
    "# 使用するデバイスを指定します（GPUの0番目のデバイス）\n",
    "device0 = torch.device('cuda:0')\n",
    "# 使用するデバイスを指定します（GPUの1番目のデバイス）\n",
    "device1 = torch.device('cuda:1')\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcfeb0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    MODEL_PATH = '/kaggle/input/gemma-2-9b-hf'\n",
    "    MAX_LENGTH = 1024\n",
    "    BATCH_SIZE = 2\n",
    "    \n",
    "device0 = torch.device('cuda:0')\n",
    "device1 = torch.device('cuda:1')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの読み込み\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78415344",
   "metadata": {},
   "source": [
    "# モデルの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fe8e05",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Load model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# トークナイザーを指定したモデルパスから読み込みます\n",
    "tokenizer = GemmaTokenizer.from_pretrained(CFG.MODEL_PATH)\n",
    "\n",
    "# 4ビットの量子化設定を定義します\n",
    "bnb_config_4bit = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4ビットでモデルを読み込みます\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 計算データ型をfloat16に指定します\n",
    "    bnb_4bit_use_double_quant=False)  # 二重量子化を使用するかどうかを指定します（ここでは無効にします）\n",
    "\n",
    "# GPUの0番目のデバイスにモデルを読み込みます\n",
    "model_0 = Gemma2ForCausalLM.from_pretrained(CFG.MODEL_PATH,\n",
    "                                        revision=\"float16\",  # モデルのバージョンをfloat16に指定\n",
    "                                        device_map='cuda:0',  # モデルをデバイス0にマッピング\n",
    "                                        quantization_config=bnb_config_4bit)  # 量子化設定を適用します\n",
    "\n",
    "# GPUの1番目のデバイスにモデルを読み込みます\n",
    "model_1 = Gemma2ForCausalLM.from_pretrained(CFG.MODEL_PATH,\n",
    "                                        revision=\"float16\",  # モデルのバージョンをfloat16に指定\n",
    "                                        device_map='cuda:1',  # モデルをデバイス1にマッピング\n",
    "                                        quantization_config=bnb_config_4bit)  # 量子化設定を適用します\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e56903",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = GemmaTokenizer.from_pretrained(CFG.MODEL_PATH)\n",
    "\n",
    "bnb_config_4bit = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False)\n",
    "\n",
    "model_0 = Gemma2ForCausalLM.from_pretrained(CFG.MODEL_PATH,\n",
    "                                        revision=\"float16\",\n",
    "                                        device_map='cuda:0',\n",
    "                                        quantization_config=bnb_config_4bit)        \n",
    "\n",
    "model_1 = Gemma2ForCausalLM.from_pretrained(CFG.MODEL_PATH,\n",
    "                                        revision=\"float16\",\n",
    "                                        device_map='cuda:1',\n",
    "                                        quantization_config=bnb_config_4bit)     \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータの準備\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c622be",
   "metadata": {},
   "source": [
    "# トレーニングデータの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9dc1d2",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Prepare train \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 入力文字列を処理する関数を定義します\n",
    "def process(input_str):\n",
    "    # 角括弧を剥がし、文字列を分割します\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # 文章を抽出し、各文の前後のダブルクォートを削除します\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    # 最後の文を返します。もし文がなければ空文字を返します\n",
    "    return sentences[-1] if sentences else ''\n",
    "  \n",
    "# トレーニングデータをCSVファイルから読み込みます\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena-additional-data-90k-columns/Merged_data.csv')\n",
    "\n",
    "# 各列のプロンプトと応答を処理して整形します\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # プロンプトを処理\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # モデルAの応答を処理\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # モデルBの応答を処理\n",
    "\n",
    "# モデルのインプットテキストを整形します\n",
    "train['text'] = '<start_of_turn>User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n----\\n\\nModel B:\\n'  + train['response_b'] + '<end_of_turn><eos>'  # モデルのプロンプトと応答の形式を設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b0528",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return sentences[-1] if sentences else ''\n",
    "  \n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena-additional-data-90k-columns/Merged_data.csv')\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "\n",
    "train['text'] = '<start_of_turn>User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n----\\n\\nModel B:\\n'  + train['response_b'] + '<end_of_turn><eos>'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットからサンプルを40,000件のみ取得します\n",
    "train = train[:40000]\n",
    "\n",
    "# トレーニングデータの最初の1行を表示します\n",
    "train.head(1)  # データフレームの最初の1行を表示して中身を確認します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:58:12.634501Z",
     "iopub.status.busy": "2024-06-29T12:58:12.634177Z",
     "iopub.status.idle": "2024-06-29T12:58:12.650767Z",
     "shell.execute_reply": "2024-06-29T12:58:12.649794Z",
     "shell.execute_reply.started": "2024-06-29T12:58:12.634468Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットからサンプルを40,000件のみ取得します\n",
    "train = train[:40000]\n",
    "\n",
    "# トレーニングデータの最初の1行を表示します\n",
    "train.head(1)  # データフレームの最初の1行を表示して中身を確認します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f674a1c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# taking only 40k sample\n",
    "train = train[:40000]\n",
    "train.head(1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# インデックス10のトレーニングデータテキストを表示します\n",
    "print(train['text'][10])  # 特定のテキストの内容を確認するために出力します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T12:58:12.653707Z",
     "iopub.status.busy": "2024-06-29T12:58:12.651973Z",
     "iopub.status.idle": "2024-06-29T12:58:12.658726Z",
     "shell.execute_reply": "2024-06-29T12:58:12.657852Z",
     "shell.execute_reply.started": "2024-06-29T12:58:12.653681Z"
    }
   },
   "outputs": [],
   "source": [
    "# インデックス10のトレーニングデータテキストを表示します\n",
    "print(train['text'][10])  # 特定のテキストの内容を確認するために出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a17ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(train['text'][10])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイズ（トークン化）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c14522",
   "metadata": {},
   "source": [
    "# トークナイズ（トークン化）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521dfcb5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Tokenize \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# トレーニングテキストをトークナイズします\n",
    "tokens = tokenizer(train['text'].tolist(),\n",
    "                   padding='max_length',  # 最大長さにパディングを施します\n",
    "                   max_length=CFG.MAX_LENGTH,  # 最大シーケンス長を設定します\n",
    "                   truncation=True,  # 長すぎるテキストは切り捨てます\n",
    "                   return_tensors='pt')  # PyTorchテンソルとして戻します\n",
    "\n",
    "# トークン化された入力IDとアテンションマスクを取得します\n",
    "INPUT_IDS = tokens['input_ids']  # 入力ID\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスク\n",
    "\n",
    "# 新しいDataFrameを作成します\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = [tensor.tolist() for tensor in INPUT_IDS]  # 入力IDをリストに変換\n",
    "data['ATTENTION_MASKS'] = [tensor.tolist() for tensor in ATTENTION_MASKS]  # アテンションマスクをリストに変換\n",
    "\n",
    "# 最初の2行を表示して内容を確認します\n",
    "data[:2]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4927aa",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokens = tokenizer(train['text'].tolist(),\n",
    "                   padding='max_length',\n",
    "                   max_length=CFG.MAX_LENGTH,\n",
    "                   truncation=True,\n",
    "                   return_tensors='pt')\n",
    "\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = [tensor.tolist() for tensor in INPUT_IDS]\n",
    "data['ATTENTION_MASKS'] = [tensor.tolist() for tensor in ATTENTION_MASKS]\n",
    "data[:2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 埋め込みの計算\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d0ecee",
   "metadata": {},
   "source": [
    "# 埋め込みの計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1102a36",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Compute embedding\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 埋め込みを計算する関数を定義します\n",
    "def get_embeddings(df, model, device, batch_size=CFG.BATCH_SIZE):  \n",
    "    # INPUT_IDSとATTENTION_MASKSをTensorに変換します\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "\n",
    "    embed_list = []  # 埋め込みを格納するリストを初期化\n",
    "\n",
    "    # バッチサイズに基づいてデータフレームを処理します\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終了インデックスを計算\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # バッチの入力IDをデバイスに転送\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # バッチのアテンションマスクをデバイスに転送\n",
    "        gc.collect()  # ガーベジコレクションを実行してメモリを解放\n",
    "        torch.cuda.empty_cache()  # GPUメモリのキャッシュをクリア\n",
    "\n",
    "        with torch.no_grad():  # 勾配を計算しないコンテキストで実行\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, output_hidden_states=True)  # モデルに入力\n",
    "            embed = outputs.hidden_states[-1]  # 最後の隠れ状態を取得\n",
    "            embed_mean = torch.mean(embed, dim=1).cpu()  # 平均プーリングを行いCPUに戻す\n",
    "            embed_list.append(embed_mean)  # 埋め込みをリストに追加\n",
    "            \n",
    "            torch.cuda.empty_cache()  # GPUメモリのキャッシュをクリア\n",
    "        \n",
    "    # リスト内のすべての埋め込みを結合します\n",
    "    embeddings = torch.cat(embed_list, dim=0)\n",
    "    return embeddings  # 計算された埋め込みを返します\n",
    "\n",
    "# 埋め込みを計算するための関数を定義します\n",
    "def compute_embed(df, model, device, results, index):\n",
    "    results[index] = get_embeddings(df, model, device)  # 結果を指定されたインデックスに保存します\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75250dd6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def get_embeddings(df, model, device, batch_size=CFG.BATCH_SIZE):  \n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "\n",
    "    embed_list = []\n",
    "\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, output_hidden_states=True)\n",
    "            embed = outputs.hidden_states[-1]\n",
    "            embed_mean = torch.mean(embed, dim=1).cpu() #mean pool\n",
    "            embed_list.append(embed_mean) \n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "    embeddings = torch.cat(embed_list, dim=0)\n",
    "    return embeddings\n",
    "\n",
    "def compute_embed(df, model, device, results, index):\n",
    "    results[index] = get_embeddings(df, model, device)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 処理開始のタイムスタンプを記録します\n",
    "st = time.time()\n",
    "\n",
    "# データのサンプル数を取得します\n",
    "N_SAMPLES = len(data)\n",
    "# サンプル数の半分を計算します\n",
    "half = round(N_SAMPLES / 2)\n",
    "# データフレームを2つの部分に分割します\n",
    "sub1 = data.iloc[0:half].copy()  # 前半のサブセット\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 後半のサブセット\n",
    "\n",
    "results = {}  # 埋め込みを格納するための辞書を初期化\n",
    "\n",
    "# スレッドを使用して並行処理を行います\n",
    "t0 = Thread(target=compute_embed, args=(sub1, model_0, device0, results, 0))  # モデル0を使用するスレッド\n",
    "t1 = Thread(target=compute_embed, args=(sub2, model_1, device1, results, 1))  # モデル1を使用するスレッド\n",
    "\n",
    "# スレッドを開始します\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# スレッドの終了を待ちます\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 処理が完了したことを知らせるメッセージをプリントします\n",
    "print(f\"Processing complete. Total time: {time.time() - st:.2f} seconds\")  # 処理にかかった合計時間を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T13:00:19.18125Z",
     "iopub.status.busy": "2024-06-29T13:00:19.180946Z",
     "iopub.status.idle": "2024-06-29T13:01:33.893412Z",
     "shell.execute_reply": "2024-06-29T13:01:33.892379Z",
     "shell.execute_reply.started": "2024-06-29T13:00:19.181227Z"
    }
   },
   "outputs": [],
   "source": [
    "# 処理開始のタイムスタンプを記録します\n",
    "st = time.time()\n",
    "\n",
    "# データのサンプル数を取得します\n",
    "N_SAMPLES = len(data)\n",
    "# サンプル数の半分を計算します\n",
    "half = round(N_SAMPLES / 2)\n",
    "# データフレームを2つの部分に分割します\n",
    "sub1 = data.iloc[0:half].copy()  # 前半のサブセット\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 後半のサブセット\n",
    "\n",
    "results = {}  # 埋め込みを格納するための辞書を初期化\n",
    "\n",
    "# スレッドを使用して並行処理を行います\n",
    "t0 = Thread(target=compute_embed, args=(sub1, model_0, device0, results, 0))  # モデル0を使用するスレッド\n",
    "t1 = Thread(target=compute_embed, args=(sub2, model_1, device1, results, 1))  # モデル1を使用するスレッド\n",
    "\n",
    "# スレッドを開始します\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# スレッドの終了を待ちます\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 処理が完了したことを知らせるメッセージをプリントします\n",
    "print(f\"Processing complete. Total time: {time.time() - st:.2f} seconds\")  # 処理にかかった合計時間を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b77e89f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "N_SAMPLES = len(data)\n",
    "half = round(N_SAMPLES / 2)\n",
    "sub1 = data.iloc[0:half].copy()\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()\n",
    "\n",
    "results = {}\n",
    "\n",
    "t0 = Thread(target=compute_embed, args=(sub1, model_0, device0, results, 0))\n",
    "t1 = Thread(target=compute_embed, args=(sub2, model_1, device1, results, 1))\n",
    "\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "print(f\"Processing complete. Total time: {time.time() - st:.2f} seconds\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 2つのスレッドから得られた埋め込みを結合します\n",
    "embeddings = torch.cat([results[0], results[1]], dim=0)\n",
    "\n",
    "# 結合された埋め込みの形状を表示します\n",
    "embeddings.shape  # 埋め込みのテンソルの形状を出力して確認します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T13:02:04.396297Z",
     "iopub.status.busy": "2024-06-29T13:02:04.394965Z",
     "iopub.status.idle": "2024-06-29T13:02:04.403043Z",
     "shell.execute_reply": "2024-06-29T13:02:04.401994Z",
     "shell.execute_reply.started": "2024-06-29T13:02:04.396259Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2つのスレッドから得られた埋め込みを結合します\n",
    "embeddings = torch.cat([results[0], results[1]], dim=0)\n",
    "\n",
    "# 結合された埋め込みの形状を表示します\n",
    "embeddings.shape  # 埋め込みのテンソルの形状を出力して確認します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af2e3ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "embeddings = torch.cat([results[0], results[1]], dim=0)\n",
    "embeddings.shape\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ガーベジコレクションを実行してメモリを解放します\n",
    "gc.collect()\n",
    "\n",
    "# 使用が終了したモデルを削除してメモリを解放します\n",
    "del model_1  # モデル1を削除\n",
    "del model_0  # モデル0を削除\n",
    "\n",
    "# GPUメモリのキャッシュをクリアします\n",
    "torch.cuda.empty_cache()  # メモリの効率的な使用のためにキャッシュをクリアします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T13:02:05.604684Z",
     "iopub.status.busy": "2024-06-29T13:02:05.603536Z",
     "iopub.status.idle": "2024-06-29T13:02:05.935315Z",
     "shell.execute_reply": "2024-06-29T13:02:05.934344Z",
     "shell.execute_reply.started": "2024-06-29T13:02:05.604649Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガーベジコレクションを実行してメモリを解放します\n",
    "gc.collect()\n",
    "\n",
    "# 使用が終了したモデルを削除してメモリを解放します\n",
    "del model_1  # モデル1を削除\n",
    "del model_0  # モデル0を削除\n",
    "\n",
    "# GPUメモリのキャッシュをクリアします\n",
    "torch.cuda.empty_cache()  # メモリの効率的な使用のためにキャッシュをクリアします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c5593",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "gc.collect()\n",
    "del model_1\n",
    "del  model_0\n",
    "torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 埋め込みの保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6edfb83",
   "metadata": {},
   "source": [
    "# 埋め込みの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be130e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Save embed\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 埋め込みを保存するパスを指定します\n",
    "save_path = 'gemma2_train_embed.npy'\n",
    "\n",
    "# 埋め込みを.npyファイルとして保存します\n",
    "np.save(save_path, embeddings.numpy())  # NumPy形式で埋め込みを保存\n",
    "\n",
    "# 完全性のためにトレーニングデータも保存します\n",
    "train.to_csv('train_embed.csv', index=False)  # トレーニングデータをCSVファイルとして保存\n",
    "\n",
    "# 保存完了メッセージを表示します\n",
    "print(f\"Concatenated embeddings saved to {save_path}\")  # 保存されたファイルのパスを表示します\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4505960,
     "sourceId": 7715453,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4505971,
     "sourceId": 7715470,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5260293,
     "sourceId": 8756307,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5299906,
     "sourceId": 8811121,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 58215,
     "sourceId": 69765,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
