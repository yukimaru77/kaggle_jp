{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3729d496",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、チャットボットの応答の好みを予測する問題に取り組んでいます。具体的には、2つの異なる言語モデルが生成した応答のうち、どちらがユーザーに好まれるかを判定するモデルを構築することを目指しています。\n",
    "\n",
    "### 主要な手法とライブラリ\n",
    "- **ライブラリ**: 主に`pandas`（データ処理）、`torch`（深層学習処理）、および`transformers`（言語モデルの利用）を使用しています。\n",
    "  \n",
    "- **データ処理**: `process_data`関数を用いて、CSVファイルから読込んだプロンプトおよび応答を整形しています。このプロセスでは、前後の角括弧やダブルクオーテーションを取り除き、文章を結合しています。\n",
    "\n",
    "- **モデルのロード**: `AutoTokenizer`と`AutoModelForCausalLM`を利用して、事前トレーニングされたGemma-2-9Bモデルをロードしています。モデルはbfloat16の形式でCUDAデバイスにロードされ、推論に対応しています。\n",
    "\n",
    "- **推論処理**: `predict`関数を定義し、入力クエリと2つの応答を元にどちらの応答が優れているかを判断します。評価基準には関連性、正確性、完全性、一貫性が考慮されており、応答の判定結果に基づいて出力が行われます。\n",
    "\n",
    "- **結果の蓄積**: ループ処理を通じて、全テストデータに対して予測を行い、その結果をリストにまとめ、最終的に`submission.csv`という形式で出力します。各エントリは、クエリID、モデルAの勝者、モデルBの勝者、および引き分けのフラグを含みます。\n",
    "\n",
    "全体的には、このノートブックは機械学習を介して言語モデルの応答を評価し、人間の好みに基づいて最適な応答を予測するための手法を示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9116ba6f",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookで使用されている専門用語に関する簡易解説を示します。初心者がつまずきやすいマイナーな用語や、特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **bfloat16**: \n",
    "   - バイナリ浮動小数点数の一種で、16ビットの精度を持ちます。機械学習においては、メモリの使用量を削減し、計算効率の向上を図るために用いられます。特に、TPU（Tensor Processing Unit）でよく利用されるフォーマットです。\n",
    "\n",
    "2. **プロンプトエンジニアリング**:\n",
    "   - 大規模言語モデル（LLM）に対する入出力を最適化するための手法で、モデルに与える指示や質問（プロンプト）を慎重に設計することです。これにより、モデルから得られる応答の品質を向上させることが目的です。\n",
    "\n",
    "3. **CUDA**:\n",
    "   - NVIDIAが開発した、GPUを用いた計算を効率的に行うための並列計算プラットフォームおよびAPIです。機械学習や深層学習のトレーニングおよび推論において、GPUを利用するために広く用いられます。\n",
    "\n",
    "4. **トークン化**:\n",
    "   - 自然言語処理において、テキストを分析可能な単位（トークン）に分割するプロセスです。これは、モデルが理解できる形式に変換するための前処理の一環として行われます。\n",
    "\n",
    "5. **生成モデル**:\n",
    "   - 入力データを基に新しいデータを生成することを目的とする機械学習モデルの一種です。本ノートブックでは、特に言語生成に関与するモデル（例えば、文や会話の生成）を指します。\n",
    "\n",
    "6. **メモリ効率の良いSDP (Stochastic Dynamic Programming)**:\n",
    "   - モデルの計算を効率化する手法で、メモリの使用を抑えつつ動的プログラミングを行うものです。大規模なモデルのトレーニング時に特に重要です。\n",
    "\n",
    "7. **重み**:\n",
    "   - 機械学習モデルがデータから学習するパラメータのこと。重みは、モデルの性能に大きな影響を与え、トレーニングの過程で調整されます。\n",
    "\n",
    "8. **次元削減**:\n",
    "   - 多次元空間のデータを少ない次元に圧縮する手法で、データの可視化や処理の効率化に用いられます。具体的な手法にはPCA（主成分分析）やt-SNEが含まれますが、ノートブック内では直接触れられていないかもしれません。\n",
    "\n",
    "9. **スニペット**:\n",
    "   - プログラムコードの短い部分やフラグメントを示す用語で、通常は再利用可能なものを指します。コーディングの際によく用いられます。\n",
    "\n",
    "10. **グラデーション降下法**:\n",
    "    - 最適化アルゴリズムの一つで、誤差を最小化するためにモデルの重みを更新する方法です。勾配を計算し、その反対方向に重みを調整することで、より良いパラメータを見つけ出します。\n",
    "\n",
    "これらの用語は、特に実務経験がない初心者にとっては馴染みが薄いか、理解が難しいことがあります。これらの解説が理解の助けとなれば幸いです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c98cce",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:06.677065Z",
     "iopub.status.busy": "2024-07-15T06:48:06.676325Z",
     "iopub.status.idle": "2024-07-15T06:48:07.827666Z",
     "shell.execute_reply": "2024-07-15T06:48:07.826627Z",
     "shell.execute_reply.started": "2024-07-15T06:48:06.677019Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44209735",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T07:59:57.252098Z",
     "iopub.status.busy": "2024-07-15T07:59:57.25174Z",
     "iopub.status.idle": "2024-07-15T07:59:57.256785Z",
     "shell.execute_reply": "2024-07-15T07:59:57.255788Z",
     "shell.execute_reply.started": "2024-07-15T07:59:57.25207Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe781f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)  # メモリ効率の良いSDPを無効にする\n",
    "torch.backends.cuda.enable_flash_sdp(False)  # フラッシュSDPを無効にする\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:11.113603Z",
     "iopub.status.busy": "2024-07-15T06:48:11.11297Z",
     "iopub.status.idle": "2024-07-15T06:48:11.118344Z",
     "shell.execute_reply": "2024-07-15T06:48:11.117441Z",
     "shell.execute_reply.started": "2024-07-15T06:48:11.113569Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)  # メモリ効率の良いSDPを無効にする\n",
    "torch.backends.cuda.enable_flash_sdp(False)  # フラッシュSDPを無効にする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0011eb45",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process_data(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    sentences = ' '.join(sentences)\n",
    "    return sentences\n",
    "\n",
    "def get_data(path, system_prompt=None):\n",
    "    df = pd.read_csv(path)\n",
    "    df['prompt'] = df['prompt'].apply(process_data)\n",
    "    df['response_a'] = df['response_a'].apply(process_data)\n",
    "    df['response_b'] = df['response_b'].apply(process_data)\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def process_data(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 文字列の前後の角括弧を削除する\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文章を分割し、各部分の前後のダブルクオーテーションを削除\n",
    "    sentences = ' '.join(sentences)  # 分割した文章をスペースで結合\n",
    "    return sentences\n",
    "\n",
    "def get_data(path, system_prompt=None):\n",
    "    df = pd.read_csv(path)  # 指定したパスからCSVファイルを読み込む\n",
    "    df['prompt'] = df['prompt'].apply(process_data)  # プロンプト列に対してprocess_dataを適用\n",
    "    df['response_a'] = df['response_a'].apply(process_data)  # 応答A列に対してprocess_dataを適用\n",
    "    df['response_b'] = df['response_b'].apply(process_data)  # 応答B列に対してprocess_dataを適用\n",
    "    return df  # 処理済みのデータフレームを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:48:01.813641Z",
     "iopub.status.busy": "2024-07-15T07:48:01.813261Z",
     "iopub.status.idle": "2024-07-15T07:48:01.822292Z",
     "shell.execute_reply": "2024-07-15T07:48:01.821373Z",
     "shell.execute_reply.started": "2024-07-15T07:48:01.813612Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_data(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 文字列の前後の角括弧を削除する\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文章を分割し、各部分の前後のダブルクオーテーションを削除\n",
    "    sentences = ' '.join(sentences)  # 分割した文章をスペースで結合\n",
    "    return sentences\n",
    "\n",
    "def get_data(path, system_prompt=None):\n",
    "    df = pd.read_csv(path)  # 指定したパスからCSVファイルを読み込む\n",
    "    df['prompt'] = df['prompt'].apply(process_data)  # プロンプト列に対してprocess_dataを適用\n",
    "    df['response_a'] = df['response_a'].apply(process_data)  # 応答A列に対してprocess_dataを適用\n",
    "    df['response_b'] = df['response_b'].apply(process_data)  # 応答B列に対してprocess_dataを適用\n",
    "    return df  # 処理済みのデータフレームを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b952230",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n",
    "test_df = get_data(test_path)\n",
    "test_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'  # テストデータのパスを指定\n",
    "test_df = get_data(test_path)  # テストデータを取得\n",
    "test_df.head()  # テストデータの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:48:02.367062Z",
     "iopub.status.busy": "2024-07-15T07:48:02.366648Z",
     "iopub.status.idle": "2024-07-15T07:48:02.382044Z",
     "shell.execute_reply": "2024-07-15T07:48:02.381191Z",
     "shell.execute_reply.started": "2024-07-15T07:48:02.367032Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'  # テストデータのパスを指定\n",
    "test_df = get_data(test_path)  # テストデータを取得\n",
    "test_df.head()  # テストデータの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e6d187",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load Gemma-2-9B model\n",
    "> google/gemma-2-9b-it \n",
    "\n",
    "I have already downloaded and stored bfloat16 weights.\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## Gemma-2-9Bモデルのロード\n",
    "> google/gemma-2-9b-it \n",
    "\n",
    "私はすでにbfloat16の重みをダウンロードして保存しました。\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dab5d9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer  # Transformersライブラリからモデルとトークナイザーをインポート\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:14.572235Z",
     "iopub.status.busy": "2024-07-15T06:48:14.571879Z",
     "iopub.status.idle": "2024-07-15T06:48:15.465156Z",
     "shell.execute_reply": "2024-07-15T06:48:15.464383Z",
     "shell.execute_reply.started": "2024-07-15T06:48:14.572207Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer  # Transformersライブラリからモデルとトークナイザーをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59ef3b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-tokenizer'\n",
    "model_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-model'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-tokenizer'  # トークナイザーのパスを指定\n",
    "model_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-model'  # モデルのパスを指定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:15.467426Z",
     "iopub.status.busy": "2024-07-15T06:48:15.466814Z",
     "iopub.status.idle": "2024-07-15T06:48:15.471513Z",
     "shell.execute_reply": "2024-07-15T06:48:15.470542Z",
     "shell.execute_reply.started": "2024-07-15T06:48:15.467393Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-tokenizer'  # トークナイザーのパスを指定\n",
    "model_path = '/kaggle/input/gemma-2-9b-it/gemma-2-9b-it-palash-model'  # モデルのパスを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc47e1c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)  # トークナイザーを指定したパスからロード\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:15.517944Z",
     "iopub.status.busy": "2024-07-15T06:48:15.517688Z",
     "iopub.status.idle": "2024-07-15T06:48:16.445695Z",
     "shell.execute_reply": "2024-07-15T06:48:16.444823Z",
     "shell.execute_reply.started": "2024-07-15T06:48:15.517922Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)  # トークナイザーを指定したパスからロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09131f12",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype=torch.bfloat16)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype=torch.bfloat16)  # モデルを指定したパスからロードし、デバイスマップを自動で取得、データ型をbfloat16に設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:48:22.429128Z",
     "iopub.status.busy": "2024-07-15T06:48:22.428103Z",
     "iopub.status.idle": "2024-07-15T06:51:09.409078Z",
     "shell.execute_reply": "2024-07-15T06:51:09.40808Z",
     "shell.execute_reply.started": "2024-07-15T06:48:22.429097Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map='auto', torch_dtype=torch.bfloat16)  # モデルを指定したパスからロードし、デバイスマップを自動で取得、データ型をbfloat16に設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376b636",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model  # モデルオブジェクトを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:51:09.411816Z",
     "iopub.status.busy": "2024-07-15T06:51:09.410924Z",
     "iopub.status.idle": "2024-07-15T06:51:09.421473Z",
     "shell.execute_reply": "2024-07-15T06:51:09.420593Z",
     "shell.execute_reply.started": "2024-07-15T06:51:09.41178Z"
    }
   },
   "outputs": [],
   "source": [
    "model  # モデルオブジェクトを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d29564",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Let's do a simple inference\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## シンプルな推論を行ってみましょう\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbbd680",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "prompt = 'Write a conversation between gemma and llama llm models'\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=200)\n",
    "response = tokenizer.decode(outputs[0])\n",
    "print(response)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "prompt = 'Write a conversation between gemma and llama llm models'  # プロンプトを定義\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')  # プロンプトをトークン化し、テンソル形式に変換してCUDAデバイスに移動\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=200)  # モデルを使って新しいトークンを生成\n",
    "response = tokenizer.decode(outputs[0])  # 生成したトークンをデコードして応答を取得\n",
    "print(response)  # 応答を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T06:51:09.42281Z",
     "iopub.status.busy": "2024-07-15T06:51:09.422507Z",
     "iopub.status.idle": "2024-07-15T06:51:42.214722Z",
     "shell.execute_reply": "2024-07-15T06:51:42.213751Z",
     "shell.execute_reply.started": "2024-07-15T06:51:09.422785Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "prompt = 'Write a conversation between gemma and llama llm models'  # プロンプトを定義\n",
    "input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')  # プロンプトをトークン化し、テンソル形式に変換してCUDAデバイスに移動\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=200)  # モデルを使って新しいトークンを生成\n",
    "response = tokenizer.decode(outputs[0])  # 生成したトークンをデコードして応答を取得\n",
    "print(response)  # 応答を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5401a0",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Let's do inference on test set with some prompt engineering\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## テストセットに対して、プロンプトエンジニアリングを行った推論を行いましょう\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241d6ba1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_df  # テストデータフレームを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:09:50.637151Z",
     "iopub.status.busy": "2024-07-15T08:09:50.636469Z",
     "iopub.status.idle": "2024-07-15T08:09:50.646948Z",
     "shell.execute_reply": "2024-07-15T08:09:50.64597Z",
     "shell.execute_reply.started": "2024-07-15T08:09:50.637121Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df  # テストデータフレームを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b24008f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def get_prompt(query, response_a, response_b):\n",
    "    prompt = f\"\"\"\n",
    "You are tasked with evaluating two responses generated by different models to determine which one is better. Given a query and two responses (RESPONSE_A from MODEL_A and RESPONSE_B from MODEL_B), you will assess the quality of each response based on relevance, accuracy, completeness, and overall coherence. If both responses are equally good or equally poor, you may declare a tie.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "Query: {query}\n",
    "RESPONSE_A (MODEL_A): {response_a}\n",
    "RESPONSE_B (MODEL_B): {response_b}\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Relevance: How well does the response address the query?\n",
    "Accuracy: Is the information provided correct and reliable?\n",
    "Completeness: Does the response provide a comprehensive answer?\n",
    "Coherence: Is the response logically structured and easy to understand?\n",
    "Output:\n",
    "\n",
    "If RESPONSE_A is better, output: RESPONSE_A\n",
    "If RESPONSE_B is better, output: RESPONSE_B\n",
    "If both responses are equally good or poor, output: TIE\n",
    "\n",
    "You have to output a single line having either of these words - RESPONSE_A or RESPONSE_B or TIE \\n\n",
    "OUTPUT: \n",
    "\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def get_prompt(query, response_a, response_b):\n",
    "    prompt = f\"\"\"\n",
    "あなたは、異なるモデルによって生成された2つの応答を評価し、どちらの方が優れているかを判断する任務を負っています。クエリと2つの応答（モデルAからの応答AとモデルBからの応答B）を与えられた場合、各応答の質を関連性、正確性、完全性、全体的な一貫性に基づいて評価します。両方の応答が同等に良いか悪い場合は、引き分けと宣言することができます。\n",
    "\n",
    "指示：\n",
    "\n",
    "クエリ: {query}\n",
    "応答A（モデルA）: {response_a}\n",
    "応答B（モデルB）: {response_b}\n",
    "\n",
    "評価基準：\n",
    "\n",
    "関連性: 応答はクエリにどれだけ対応しているか？\n",
    "正確性: 提供された情報は正確で信頼性があるか？\n",
    "完全性: 応答は包括的な回答を提供しているか？\n",
    "一貫性: 応答は論理的に構成されており、理解しやすいか？\n",
    "出力：\n",
    "\n",
    "応答Aが優れている場合、出力: 応答A\n",
    "応答Bが優れている場合、出力: 応答B\n",
    "両方の応答が同等に良いまたは悪い場合、出力: 引き分け\n",
    "\n",
    "単一行を出力する必要があります – 応答Aまたは応答Bまたは引き分けのいずれかの単語\\n\n",
    "出力: \n",
    "\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T07:37:15.073395Z",
     "iopub.status.busy": "2024-07-15T07:37:15.072935Z",
     "iopub.status.idle": "2024-07-15T07:37:15.078959Z",
     "shell.execute_reply": "2024-07-15T07:37:15.078025Z",
     "shell.execute_reply.started": "2024-07-15T07:37:15.073366Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_prompt(query, response_a, response_b):\n",
    "    prompt = f\"\"\"\n",
    "あなたは、異なるモデルによって生成された2つの応答を評価し、どちらの方が優れているかを判断する任務を負っています。クエリと2つの応答（モデルAからの応答AとモデルBからの応答B）を与えられた場合、各応答の質を関連性、正確性、完全性、全体的な一貫性に基づいて評価します。両方の応答が同等に良いか悪い場合は、引き分けと宣言することができます。\n",
    "\n",
    "指示：\n",
    "\n",
    "クエリ: {query}\n",
    "応答A（モデルA）: {response_a}\n",
    "応答B（モデルB）: {response_b}\n",
    "\n",
    "評価基準：\n",
    "\n",
    "関連性: 応答はクエリにどれだけ対応しているか？\n",
    "正確性: 提供された情報は正確で信頼性があるか？\n",
    "完全性: 応答は包括的な回答を提供しているか？\n",
    "一貫性: 応答は論理的に構成されており、理解しやすいか？\n",
    "出力：\n",
    "\n",
    "応答Aが優れている場合、出力: 応答A\n",
    "応答Bが優れている場合、出力: 応答B\n",
    "両方の応答が同等に良いまたは悪い場合、出力: 引き分け\n",
    "\n",
    "単一行を出力する必要があります – 応答Aまたは応答Bまたは引き分けのいずれかの単語\\n\n",
    "出力: \n",
    "\n",
    "    \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93a8531",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def predict(query, response_a, response_b, max_new_tokens=50, do_sample=False, temperature=1.0):\n",
    "    prompt = get_prompt(query=query, response_a=response_a, response_b=response_b)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=do_sample, temperature=temperature)\n",
    "    response = tokenizer.decode(outputs[0])\n",
    "\n",
    "    pattern = r\"OUTPUT:\\s*(RESPONSE_A|RESPONSE_B|TIE)\"\n",
    "    match = re.search(pattern, response)\n",
    "    if match:\n",
    "        pred = match.group(1)\n",
    "    else:\n",
    "        pred = None\n",
    "    return pred\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def predict(query, response_a, response_b, max_new_tokens=50, do_sample=False, temperature=1.0):\n",
    "    prompt = get_prompt(query=query, response_a=response_a, response_b=response_b)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')  # プロンプトをトークン化し、テンソル形式に変換してCUDAデバイスに移動\n",
    "\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=do_sample, temperature=temperature)  # モデルが新しいトークンを生成\n",
    "    response = tokenizer.decode(outputs[0])  # 生成したトークンをデコードして応答を取得\n",
    "\n",
    "    pattern = r\"OUTPUT:\\s*(RESPONSE_A|RESPONSE_B|TIE)\"  # 出力のパターンを定義\n",
    "    match = re.search(pattern, response)  # 応答の中から出力パターンを検索\n",
    "    if match:\n",
    "        pred = match.group(1)  # マッチした場合、出力を取得\n",
    "    else:\n",
    "        pred = None  # マッチしなかった場合はNoneを設定\n",
    "    return pred  # 予測結果を返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:01:15.237464Z",
     "iopub.status.busy": "2024-07-15T08:01:15.236745Z",
     "iopub.status.idle": "2024-07-15T08:01:15.243954Z",
     "shell.execute_reply": "2024-07-15T08:01:15.243011Z",
     "shell.execute_reply.started": "2024-07-15T08:01:15.237431Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(query, response_a, response_b, max_new_tokens=50, do_sample=False, temperature=1.0):\n",
    "    prompt = get_prompt(query=query, response_a=response_a, response_b=response_b)\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors='pt').to('cuda')  # プロンプトをトークン化し、テンソル形式に変換してCUDAデバイスに移動\n",
    "\n",
    "    outputs = model.generate(**input_ids, max_new_tokens=50, do_sample=do_sample, temperature=temperature)  # モデルが新しいトークンを生成\n",
    "    response = tokenizer.decode(outputs[0])  # 生成したトークンをデコードして応答を取得\n",
    "\n",
    "    pattern = r\"OUTPUT:\\s*(RESPONSE_A|RESPONSE_B|TIE)\"  # 出力のパターンを定義\n",
    "    match = re.search(pattern, response)  # 応答の中から出力パターンを検索\n",
    "    if match:\n",
    "        pred = match.group(1)  # マッチした場合、出力を取得\n",
    "    else:\n",
    "        pred = None  # マッチしなかった場合はNoneを設定\n",
    "    return pred  # 予測結果を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6efc56",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "id_list = []\n",
    "winner_model_a_list = []\n",
    "winner_model_b_list = []\n",
    "winner_tie_list = []\n",
    "for idx in tqdm(range(0, len(test_df))):\n",
    "    query_id = test_df.iloc[idx]['id']\n",
    "    query = test_df.iloc[idx]['prompt']\n",
    "    response_a = test_df.iloc[idx]['response_a']\n",
    "    response_b = test_df.iloc[idx]['response_b']\n",
    "    pred = predict(query, response_a, response_b, max_new_tokens=20, do_sample=True, temperature=0.7)\n",
    "    id_list.append(query_id)\n",
    "    if pred is not None:\n",
    "        if 'A' in pred or 'a' in pred:\n",
    "            winner_model_a_list.append(1)\n",
    "            winner_model_b_list.append(0)                    \n",
    "            winner_tie_list.append(0)\n",
    "        if 'B' in pred or 'b' in pred:\n",
    "            winner_model_a_list.append(0)\n",
    "            winner_model_b_list.append(1)        \n",
    "            winner_tie_list.append(0)            \n",
    "    else:\n",
    "        winner_model_a_list.append(0)\n",
    "        winner_model_b_list.append(0)        \n",
    "        winner_tie_list.append(1)\n",
    "    torch.cuda.empty_cache()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "id_list = []\n",
    "winner_model_a_list = []\n",
    "winner_model_b_list = []\n",
    "winner_tie_list = []\n",
    "for idx in tqdm(range(0, len(test_df))):  # テストデータフレームの各行についてループ\n",
    "    query_id = test_df.iloc[idx]['id']  # クエリIDを取得\n",
    "    query = test_df.iloc[idx]['prompt']  # クエリを取得\n",
    "    response_a = test_df.iloc[idx]['response_a']  # 応答Aを取得\n",
    "    response_b = test_df.iloc[idx]['response_b']  # 応答Bを取得\n",
    "    pred = predict(query, response_a, response_b, max_new_tokens=20, do_sample=True, temperature=0.7)  # 予測を実行\n",
    "    id_list.append(query_id)  # IDをリストに追加\n",
    "    if pred is not None:  # 予測結果がNoneでない場合\n",
    "        if 'A' in pred or 'a' in pred:  # 応答Aが優れている場合\n",
    "            winner_model_a_list.append(1)  # 応答Aの勝者リストに1を追加\n",
    "            winner_model_b_list.append(0)  # 応答Bの勝者リストに0を追加                    \n",
    "            winner_tie_list.append(0)  # 引き分けリストに0を追加\n",
    "        if 'B' in pred or 'b' in pred:  # 応答Bが優れている場合\n",
    "            winner_model_a_list.append(0)  # 応答Aの勝者リストに0を追加\n",
    "            winner_model_b_list.append(1)  # 応答Bの勝者リストに1を追加        \n",
    "            winner_tie_list.append(0)  # 引き分けリストに0を追加            \n",
    "    else:\n",
    "        winner_model_a_list.append(0)  # 応答Aの勝者リストに0を追加\n",
    "        winner_model_b_list.append(0)  # 応答Bの勝者リストに0を追加        \n",
    "        winner_tie_list.append(1)  # 引き分けリストに1を追加\n",
    "    torch.cuda.empty_cache()  # CUDAメモリのキャッシュをクリア\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:07:33.054676Z",
     "iopub.status.busy": "2024-07-15T08:07:33.054312Z",
     "iopub.status.idle": "2024-07-15T08:08:01.168403Z",
     "shell.execute_reply": "2024-07-15T08:08:01.167462Z",
     "shell.execute_reply.started": "2024-07-15T08:07:33.054648Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "id_list = []\n",
    "winner_model_a_list = []\n",
    "winner_model_b_list = []\n",
    "winner_tie_list = []\n",
    "for idx in tqdm(range(0, len(test_df))):  # テストデータフレームの各行についてループ\n",
    "    query_id = test_df.iloc[idx]['id']  # クエリIDを取得\n",
    "    query = test_df.iloc[idx]['prompt']  # クエリを取得\n",
    "    response_a = test_df.iloc[idx]['response_a']  # 応答Aを取得\n",
    "    response_b = test_df.iloc[idx]['response_b']  # 応答Bを取得\n",
    "    pred = predict(query, response_a, response_b, max_new_tokens=20, do_sample=True, temperature=0.7)  # 予測を実行\n",
    "    id_list.append(query_id)  # IDをリストに追加\n",
    "    if pred is not None:  # 予測結果がNoneでない場合\n",
    "        if 'A' in pred or 'a' in pred:  # 応答Aが優れている場合\n",
    "            winner_model_a_list.append(1)  # 応答Aの勝者リストに1を追加\n",
    "            winner_model_b_list.append(0)  # 応答Bの勝者リストに0を追加                    \n",
    "            winner_tie_list.append(0)  # 引き分けリストに0を追加\n",
    "        if 'B' in pred or 'b' in pred:  # 応答Bが優れている場合\n",
    "            winner_model_a_list.append(0)  # 応答Aの勝者リストに0を追加\n",
    "            winner_model_b_list.append(1)  # 応答Bの勝者リストに1を追加        \n",
    "            winner_tie_list.append(0)  # 引き分けリストに0を追加            \n",
    "    else:\n",
    "        winner_model_a_list.append(0)  # 応答Aの勝者リストに0を追加\n",
    "        winner_model_b_list.append(0)  # 応答Bの勝者リストに0を追加        \n",
    "        winner_tie_list.append(1)  # 引き分けリストに1を追加\n",
    "    torch.cuda.empty_cache()  # CUDAメモリのキャッシュをクリア"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a717f31c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "submission_df = pd.DataFrame({'id': id_list, 'winner_model_a': winner_model_a_list, 'winner_model_b': winner_model_b_list, 'winner_tie': winner_tie_list})\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "submission_df = pd.DataFrame({'id': id_list, 'winner_model_a': winner_model_a_list, 'winner_model_b': winner_model_b_list, 'winner_tie': winner_tie_list})  # 提出用のデータフレームを作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:08:32.901906Z",
     "iopub.status.busy": "2024-07-15T08:08:32.901214Z",
     "iopub.status.idle": "2024-07-15T08:08:32.906789Z",
     "shell.execute_reply": "2024-07-15T08:08:32.905883Z",
     "shell.execute_reply.started": "2024-07-15T08:08:32.901875Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({'id': id_list, 'winner_model_a': winner_model_a_list, 'winner_model_b': winner_model_b_list, 'winner_tie': winner_tie_list})  # 提出用のデータフレームを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a858096e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "submission_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "submission_df  # 提出用データフレームを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:08:36.702362Z",
     "iopub.status.busy": "2024-07-15T08:08:36.701617Z",
     "iopub.status.idle": "2024-07-15T08:08:36.711417Z",
     "shell.execute_reply": "2024-07-15T08:08:36.71021Z",
     "shell.execute_reply.started": "2024-07-15T08:08:36.70233Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df  # 提出用データフレームを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc7bea9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "submission_df.to_csv('submission.csv', index=False)  # 提出データフレームをCSVファイルとして保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T08:10:31.19526Z",
     "iopub.status.busy": "2024-07-15T08:10:31.19451Z",
     "iopub.status.idle": "2024-07-15T08:10:31.202885Z",
     "shell.execute_reply": "2024-07-15T08:10:31.201907Z",
     "shell.execute_reply.started": "2024-07-15T08:10:31.195228Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)  # 提出データフレームをCSVファイルとして保存"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5390170,
     "sourceId": 8956282,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
