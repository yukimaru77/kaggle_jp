{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2b6ee2",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、「Llama-3 8b」を使用してTPU上で大規模言語モデル（LLM）のトレーニングを実行することを目的としています。コンペティションの文脈では、異なるLLMの応答の好みを予測するために必要なデータ処理やモデルのトレーニング手法に焦点を当てています。\n",
    "\n",
    "### 主な内容と手法:\n",
    "1. **ライブラリのインポート**: \n",
    "   - トレーニングには、`transformers`, `torch`, `peft`, `torch_xla`などのライブラリが使用されます。これらは、MLモデルの構築、データ処理、およびTPUでの効率的なトレーニングに役立ちます。\n",
    "  \n",
    "2. **TPU環境の設定**:\n",
    "   - TPU上での作業を行うため、TPU関連のモジュールがインポートされ、デバイスを初期化しています。\n",
    "\n",
    "3. **データの前処理**:\n",
    "   - KaggleのデータセットをCSVから読み込み、プロンプトと応答を整形します。無効なデータ（両方の応答が`null`の場合）は削除され、トークン長が計算されてデータフレームに追加されます。\n",
    "\n",
    "4. **トークナイゼーション**:\n",
    "   - トークン化に`AutoTokenizer`を利用し、テキストの長さを設定、パディングを施し、ラベルを取得します。\n",
    "\n",
    "5. **モデルの構築**:\n",
    "   - `LlamaForSequenceClassification`を使用して、3つのターゲットラベルに基づく分類モデルを構築します。また、LoRA（Low-Rank Adaptation）の手法を用いてモデルのパラメータ最適化を図ります。\n",
    "\n",
    "6. **トレーニング実行**:\n",
    "   - モデルを指定されたエポックでトレーニングし、損失関数として交差エントロピーを使用。学習率の調整やメトリクスの記録を行いながら、各エポックの進捗を追うことができます。\n",
    "\n",
    "7. **モデルの保存**:\n",
    "   - トレーニング後、モデルとオプティマイザの状態を保存し、後の利用や再トレーニングに備えます。\n",
    "\n",
    "8. **ビジュアライゼーション**:\n",
    "   - トレーニング過程での損失をプロットし、モデルの学習の進捗を評価する手段を提供しています。\n",
    "\n",
    "### 結論:\n",
    "このノートブックは、TPUを使用したLLMトレーニングに特化しており、効率的なデータ処理、モデル構築、トレーニング手法を整備しています。トレーニングのスピードや最適化の余地があることを指摘し、さらなる改善のための方向性を示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f22b0",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関連する、機械学習・深層学習の初心者がつまずきそうな専門用語の解説を示します。\n",
    "\n",
    "1. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが開発した専用のハードウェアで、深層学習モデルのトレーニングを加速するために設計されています。GPUよりも高速で大規模なデータ処理に適しているため、大規模なモデルのトレーニングに広く使用されます。\n",
    "\n",
    "2. **LoRA (Low-Rank Adaptation)**:\n",
    "   - モデル微調整の手法で、特定のタスクにおいて大規模言語モデルの一部のパラメータを効率的に適応させるためのアプローチです。従来の微調整と比べてメモリ消費を抑え、より少ないデータで効果的に学習を行えます。\n",
    "\n",
    "3. **シャーディング (Sharding)**:\n",
    "   - データやモデルの大規模な分散処理の手法で、計算資源を効率的に使用するために、データを複数の部分に分けて同時に処理する方法です。TPU環境では、モデルやデータを複数のTPUデバイスに分散させることで、トレーニング速度を向上させます。\n",
    "\n",
    "4. **アテンションマスク (Attention Mask)**:\n",
    "   - モデルが入力を処理する際に、どの部分に注意を向けるべきかを示すための配列です。特に、パディングされた部分を無視するために使用され、計算の効率を高めます。\n",
    "\n",
    "5. **ウォームアップ (Warmup)**:\n",
    "   - 学習率スケジュールの一部で、トレーニングの初期段階で学習率を徐々に増加させる手法です。これにより、モデルが安定した状態で学習を開始でき、オーバーシュートを防ぐ効果があります。\n",
    "\n",
    "6. **ガーベジコレクション (Garbage Collection)**:\n",
    "   - プログラミングにおいて、自動でメモリを管理し、使用されていないメモリを解放するプロセスです。特に、大規模なデータを扱う機械学習において、メモリ使用量を適切に管理することは重要です。\n",
    "\n",
    "7. **ロジット (Logits)**:\n",
    "   - モデルの出力として得られる未正規化の値で、最終的なクラス予測を行う前に、Softmax関数を通じて確率に変換される値です。\n",
    "\n",
    "8. **SPMD (Single Program Multiple Data)**:\n",
    "   - 同じプログラムを複数のデータに対して同時に実行するパラダイムです。TPUやGPUでの並列アルゴリズムにおいて、効率的な計算を行うために重要です。\n",
    "\n",
    "9. **NumPyとPandas**:\n",
    "   - NumPyは数値計算用のライブラリで、行列演算に特化しており、Pandasはデータ操作のためのライブラリです。特にデータフレームを扱うことで、データの前処理や分析を効率的に行います。\n",
    "\n",
    "10. **スケジューラ (Scheduler)**:\n",
    "    - 学習率などのハイパーパラメータをトレーニングの進行に応じて調整するための仕組みです。これにより、トレーニングの各段階で最適な値を使用して、学習の効率を改善します。\n",
    "\n",
    "この用語集は、該当のノートブックの内容に特有の概念や技術に焦点を当てており、初心者が理解を深めることに役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfff83",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "#  Llama-3 8b [TPU Train]\n",
    "\n",
    "Learning to train llms on tpu, Hope this will help you too!\n",
    "\n",
    "Notebook inspired from:\n",
    "\n",
    "* [LLM detect AI comp Mistral-7B](https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b/notebook)\n",
    "* [DAIGT Mistral-7B TPU BFloat16 [Train]](https://www.kaggle.com/code/markwijkhuizen/daigt-mistral-7b-tpu-bfloat16-train)\n",
    "* [LLAMA 2 13B on TPU (Training)](https://www.kaggle.com/code/defdet/llama-2-13b-on-tpu-training)\n",
    "\n",
    "\n",
    "Prerequisite: Access to using llama-3\n",
    "\n",
    "Note: This is only training notebook, you can find inference notebook [here](https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b)\n",
    "\n",
    "Please upvote if you learn or find this helpful!\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# Llama-3 8b [TPUトレーニング]\n",
    "\n",
    "TPU上での大規模言語モデル（LLM）のトレーニングを学びます。これがあなたにも役に立つことを願っています！\n",
    "\n",
    "このノートブックは以下のリソースに触発されました：\n",
    "\n",
    "* [LLM detect AI competition Mistral-7B](https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b/notebook)\n",
    "* [DAIGT Mistral-7B TPU BFloat16 [トレーニング]](https://www.kaggle.com/code/markwijkhuizen/daigt-mistral-7b-tpu-bfloat16-train)\n",
    "* [LLAMA 2 13B on TPU (トレーニング)](https://www.kaggle.com/code/defdet/llama-2-13b-on-tpu-training)\n",
    "\n",
    "前提条件：Llama-3を使用するためのアクセス\n",
    "\n",
    "注意：これはトレーニング用のノートブックであり、推論用のノートブックは[こちら](https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b)で見つけることができます。\n",
    "\n",
    "学びがあったり、役立つと感じた場合は、ぜひ投票してください！\n",
    "\n",
    "# ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234b1f7",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Import libs \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ライブラリのインストール\n",
    "!pip install -qq peft==0.6.0  # peftライブラリのインストール\n",
    "!pip install -qq bitsandbytes==0.41.1  # bitsandbytesライブラリのインストール\n",
    "!pip install -qq accelerate==0.24.1  # accelerateライブラリのインストール\n",
    "!pip install -qq transformers==4.35.0  # transformersライブラリのインストール\n",
    "!pip install -qq torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q  # CPU版のPyTorchのインストール\n",
    "!pip install -qq torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q  # TPU用のtorch_xlaのインストール\n",
    "!pip uninstall -qq tensorflow -y  # TensorFlowがTPUを占有して権限エラーを引き起こすため、アンインストールします\n",
    "!cp /kaggle/input/utils-xla/spmd_util.py .  # このリポジトリからのファイルコピー：https://github.com/HeegyuKim/torch-xla-SPMD\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70225a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Install libs\n",
    "!pip install -qq peft==0.6.0\n",
    "!pip install -qq bitsandbytes==0.41.1\n",
    "!pip install -qq accelerate==0.24.1\n",
    "!pip install -qq transformers==4.35.0\n",
    "!pip install -qq torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q \n",
    "!pip install -qq torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q\n",
    "!pip uninstall -qq tensorflow -y # If we don't do this, TF will take over TPU and cause permission error for PT\n",
    "!cp /kaggle/input/utils-xla/spmd_util.py . # From this repo: https://github.com/HeegyuKim/torch-xla-SPMD\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os  # osモジュールのインポート\n",
    "import gc  # ガーベジコレクション用モジュールのインポート\n",
    "import re  # 正規表現操作用モジュールのインポート\n",
    "from time import time  # 時間関連の関数用にtimeをインポート\n",
    "import random  # 乱数生成用モジュールのインポート\n",
    "import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "import torch  # PyTorchのインポート\n",
    "import transformers  # transformersライブラリのインポート\n",
    "from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:06.395601Z",
     "iopub.status.busy": "2024-07-18T06:18:06.395209Z",
     "iopub.status.idle": "2024-07-18T06:18:06.563828Z",
     "shell.execute_reply": "2024-07-18T06:18:06.563166Z",
     "shell.execute_reply.started": "2024-07-18T06:18:06.395564Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # osモジュールのインポート\n",
    "import gc  # ガーベジコレクション用モジュールのインポート\n",
    "import re  # 正規表現操作用モジュールのインポート\n",
    "from time import time  # 時間関連の関数用にtimeをインポート\n",
    "import random  # 乱数生成用モジュールのインポート\n",
    "import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "import torch  # PyTorchのインポート\n",
    "import transformers  # transformersライブラリのインポート\n",
    "from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ef2aad",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_xla.debug.profiler as xp\n",
    "import torch_xla.core.xla_model as xm\n",
    "import torch_xla.experimental.xla_sharding as xs\n",
    "import torch_xla.runtime as xr\n",
    "\n",
    "xr.use_spmd()\n",
    "\n",
    "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\n",
    "from torch_xla.experimental.xla_sharding import Mesh\n",
    "from spmd_util import partition_module\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "print(f'Torch Version: {torch.__version__}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ライブラリのインポート\n",
    "# import os  # osモジュールのインポート\n",
    "# import gc  # ガーベジコレクション用モジュールのインポート\n",
    "# import re  # 正規表現操作用モジュールのインポート\n",
    "# from time import time  # 時間関連の関数用にtimeをインポート\n",
    "# import random  # 乱数生成用モジュールのインポート\n",
    "# import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "# import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "# import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "# import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "# from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "# import torch  # PyTorchのインポート\n",
    "# import transformers  # transformersライブラリのインポート\n",
    "# from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "# from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "# from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "# import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "# import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "# import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "# import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "# import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "# xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "# from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "# from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "# from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "# tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "# print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します\n",
    "# /usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
    "#   warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
    "# Torch Version: 2.1.2+cpu\n",
    "\n",
    "# 設定\n",
    "# class CFG:\n",
    "#     NUM_EPOCHS = 1  # エポック数\n",
    "#     BATCH_SIZE = 1  # バッチサイズ（以前は16）\n",
    "#     DROPOUT = 0.05  # ドロップアウト率\n",
    "#     MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのパス\n",
    "#     SEED = 2024  # 乱数シード\n",
    "#     MAX_LENGTH = 1024  # 最大シーケンス長\n",
    "#     NUM_WARMUP_STEPS = 128  # ウォームアップステップ数\n",
    "#     LR_MAX = 5e-5  # 最大学習率\n",
    "#     NUM_LABELS = 3  # ラベル数\n",
    "#     LORA_RANK = 4  # LoRAのランク\n",
    "#     LORA_ALPHA = 8  # LoRAのアルファ値\n",
    "#     LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモジュール\n",
    "    \n",
    "# DEVICE = xm.xla_device()  # TPUデバイスの初期化\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:39:35.941175Z",
     "iopub.status.busy": "2024-07-18T06:39:35.94052Z",
     "iopub.status.idle": "2024-07-18T06:39:35.957638Z",
     "shell.execute_reply": "2024-07-18T06:39:35.95664Z",
     "shell.execute_reply.started": "2024-07-18T06:39:35.941134Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "# import os  # osモジュールのインポート\n",
    "# import gc  # ガーベジコレクション用モジュールのインポート\n",
    "# import re  # 正規表現操作用モジュールのインポート\n",
    "# from time import time  # 時間関連の関数用にtimeをインポート\n",
    "# import random  # 乱数生成用モジュールのインポート\n",
    "# import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "# import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "# import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "# import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "# from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "# import torch  # PyTorchのインポート\n",
    "# import transformers  # transformersライブラリのインポート\n",
    "# from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "# from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "# from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "# import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "# import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "# import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "# import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "# import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "# xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "# from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "# from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "# from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "# tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "# print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します\n",
    "# /usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
    "#   warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
    "# Torch Version: 2.1.2+cpu\n",
    "\n",
    "# 設定\n",
    "# class CFG:\n",
    "#     NUM_EPOCHS = 1  # エポック数\n",
    "#     BATCH_SIZE = 1  # バッチサイズ（以前は16）\n",
    "#     DROPOUT = 0.05  # ドロップアウト率\n",
    "#     MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのパス\n",
    "#     SEED = 2024  # 乱数シード\n",
    "#     MAX_LENGTH = 1024  # 最大シーケンス長\n",
    "#     NUM_WARMUP_STEPS = 128  # ウォームアップステップ数\n",
    "#     LR_MAX = 5e-5  # 最大学習率\n",
    "#     NUM_LABELS = 3  # ラベル数\n",
    "#     LORA_RANK = 4  # LoRAのランク\n",
    "#     LORA_ALPHA = 8  # LoRAのアルファ値\n",
    "#     LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモジュール\n",
    "    \n",
    "# DEVICE = xm.xla_device()  # TPUデバイスの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b1ddb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# import os\n",
    "# import gc\n",
    "# import re\n",
    "# from time import time\n",
    "# import random\n",
    "# import warnings\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm\n",
    "\n",
    "# import torch\n",
    "# import transformers\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification\n",
    "# from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# import torch_xla.debug.profiler as xp\n",
    "# import torch_xla.core.xla_model as xm\n",
    "# import torch_xla.experimental.xla_sharding as xs\n",
    "# import torch_xla.runtime as xr\n",
    "\n",
    "# xr.use_spmd()\n",
    "\n",
    "# from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\n",
    "# from torch_xla.experimental.xla_sharding import Mesh\n",
    "# from spmd_util import partition_module\n",
    "\n",
    "# tqdm.pandas()\n",
    "\n",
    "# print(f'Torch Version: {torch.__version__}')\n",
    "# /usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
    "#   warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
    "# Torch Version: 2.1.2+cpu\n",
    "\n",
    "# # Configs\n",
    "# class CFG:\n",
    "#     NUM_EPOCHS = 1\n",
    "#     BATCH_SIZE = 1  # It was 16 before\n",
    "#     DROPOUT = 0.05 \n",
    "#     MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "#     SEED = 2024 \n",
    "#     MAX_LENGTH = 1024 \n",
    "#     NUM_WARMUP_STEPS = 128\n",
    "#     LR_MAX = 5e-5 \n",
    "#     NUM_LABELS = 3 \n",
    "#     LORA_RANK = 4\n",
    "#     LORA_ALPHA = 8\n",
    "#     LORA_MODULES = ['o_proj', 'v_proj']\n",
    "    \n",
    "# DEVICE = xm.xla_device()  # Initialize TPU Device\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca9c70",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05000179",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Configs\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "class CFG:\n",
    "    NUM_EPOCHS = 1  # エポック数\n",
    "    BATCH_SIZE = 1  # バッチサイズ（以前は16だった）\n",
    "    DROPOUT = 0.05  # ドロップアウト率\n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのパス\n",
    "    SEED = 2024  # 乱数シード\n",
    "    MAX_LENGTH = 1024  # 最大シーケンス長\n",
    "    NUM_WARMUP_STEPS = 128  # ウォームアップステップ数\n",
    "    LR_MAX = 5e-5  # 最大学習率\n",
    "    NUM_LABELS = 3  # ラベルの数\n",
    "    LORA_RANK = 4  # LoRAのランク\n",
    "    LORA_ALPHA = 8  # LoRAのアルファ値\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモジュールのリスト\n",
    "    \n",
    "DEVICE = xm.xla_device()  # TPUデバイスの初期化\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a67d7c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    NUM_EPOCHS = 1\n",
    "    BATCH_SIZE = 1 # It was 16 before\n",
    "    DROPOUT = 0.05 \n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "    SEED = 2024 \n",
    "    MAX_LENGTH = 1024 \n",
    "    NUM_WARMUP_STEPS = 128\n",
    "    LR_MAX = 5e-5 \n",
    "    NUM_LABELS = 3 \n",
    "    LORA_RANK = 4\n",
    "    LORA_ALPHA = 8\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']\n",
    "    \n",
    "DEVICE = xm.xla_device() # Initialize TPU Device\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def set_seeds(seed):\n",
    "    \"\"\"再現性のためのシードを設定します\"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Pythonのハッシュシードを設定\n",
    "    random.seed(seed)  # randomモジュールのシードを設定\n",
    "    np.random.seed(seed)  # NumPyのシードを設定\n",
    "    torch.manual_seed(seed)  # PyTorchのシードを設定\n",
    "    if torch.cuda.is_available():  # GPUが利用可能な場合\n",
    "        torch.cuda.manual_seed(seed)  # CUDA用のシードを設定\n",
    "        torch.cuda.manual_seed_all(seed)  # 全てのCUDAデバイスにシードを設定\n",
    "        \n",
    "    # 全TPUコアのためにシードを設定\n",
    "    xm.set_rng_state(seed, device=xm.xla_device())  \n",
    "\n",
    "set_seeds(seed=CFG.SEED)  # 設定したシードを使ってシードを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:24.361144Z",
     "iopub.status.busy": "2024-07-18T06:18:24.36047Z",
     "iopub.status.idle": "2024-07-18T06:18:24.36895Z",
     "shell.execute_reply": "2024-07-18T06:18:24.368251Z",
     "shell.execute_reply.started": "2024-07-18T06:18:24.361105Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    \"\"\"再現性のためのシードを設定します\"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Pythonのハッシュシードを設定\n",
    "    random.seed(seed)  # randomモジュールのシードを設定\n",
    "    np.random.seed(seed)  # NumPyのシードを設定\n",
    "    torch.manual_seed(seed)  # PyTorchのシードを設定\n",
    "    if torch.cuda.is_available():  # GPUが利用可能な場合\n",
    "        torch.cuda.manual_seed(seed)  # CUDA用のシードを設定\n",
    "        torch.cuda.manual_seed_all(seed)  # 全てのCUDAデバイスにシードを設定\n",
    "        \n",
    "    # 全TPUコアのためにシードを設定\n",
    "    xm.set_rng_state(seed, device=xm.xla_device())  \n",
    "\n",
    "set_seeds(seed=CFG.SEED)  # 設定したシードを使ってシードを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f9f3ad",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def set_seeds(seed):\n",
    "    \"\"\"Set seeds for reproducibility \"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "    # Set seed for all TPU cores\n",
    "    xm.set_rng_state(seed, device=xm.xla_device())  \n",
    "\n",
    "set_seeds(seed=CFG.SEED)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザー\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba86a36",
   "metadata": {},
   "source": [
    "# トークナイザー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7f3c2",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)  # 指定したモデル名からトークナイザーをロード\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンに設定\n",
    "tokenizer.padding_side = 'right'  # パディングを右側に設定\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加する設定\n",
    "\n",
    "# 推論時にオフラインでロードできるようにトークナイザーを保存\n",
    "tokenizer.save_pretrained('tokenizer')  # トークナイザーを指定したディレクトリに保存します\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c51cb7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.add_eos_token = True\n",
    "\n",
    "# save tokenizer to load offline during inference\n",
    "tokenizer.save_pretrained('tokenizer')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークン長を取得するユーティリティ関数\n",
    "def get_token_lengths(texts):\n",
    "    # テキストをトークナイズし、各テキストのinput_idsを取得\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # 各テキストのinput_idsの長さを返す\n",
    "    return [len(t) for t in input_ids]  # 各トークンの長さをリストとして返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:32.691262Z",
     "iopub.status.busy": "2024-07-18T06:18:32.690884Z",
     "iopub.status.idle": "2024-07-18T06:18:32.696118Z",
     "shell.execute_reply": "2024-07-18T06:18:32.695375Z",
     "shell.execute_reply.started": "2024-07-18T06:18:32.69123Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン長を取得するユーティリティ関数\n",
    "def get_token_lengths(texts):\n",
    "    # テキストをトークナイズし、各テキストのinput_idsを取得\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # 各テキストのinput_idsの長さを返す\n",
    "    return [len(t) for t in input_ids]  # 各トークンの長さをリストとして返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa359bd1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Utility function giving token length\n",
    "def get_token_lengths(texts):\n",
    "    # tokenize and receive input_ids for reach text\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # return length of inputs_ids for each text\n",
    "    return [len(t) for t in input_ids]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータの準備\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15760842",
   "metadata": {},
   "source": [
    "# トレーニングデータの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6a7a2",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Prepare train\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータのCSVファイルを読み込む\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 角括弧を取り除く\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文章を分割し、各文章の余分な引用符を取り除く\n",
    "    return ' '.join(sentences)  # 文章をスペースで結合して返す\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # プロンプト列を処理\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # 応答A列を処理\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # 応答B列を処理\n",
    "\n",
    "# トレーニングに向けて 'Null' を削除\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index  # 応答Aと応答Bが両方 'null' の行を見つける\n",
    "train.drop(indexes, inplace=True)  # 該当する行を削除\n",
    "train.reset_index(inplace=True, drop=True)  # インデックスをリセット\n",
    "\n",
    "print(f\"総計 {len(indexes)} 行のNull応答が削除されました\")\n",
    "print('トレーニングサンプルの合計: ', len(train))  # 残ったトレーニングサンプルの数を表示\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cfc29a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Null' for training\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")\n",
    "print('Total train samples: ', len(train))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train.head(5)  # トレーニングデータの最初の5行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:40.06401Z",
     "iopub.status.busy": "2024-07-18T06:18:40.063715Z",
     "iopub.status.idle": "2024-07-18T06:18:40.079067Z",
     "shell.execute_reply": "2024-07-18T06:18:40.078222Z",
     "shell.execute_reply.started": "2024-07-18T06:18:40.06398Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(5)  # トレーニングデータの最初の5行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241b8c0a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train.head(5)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train['text'] = 'User prompt: ' + train['prompt'] + '\\n\\nModel A:\\n' + train['response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + train['response_b']  # 各行にユーザープロンプトとモデルの応答を結合\n",
    "print(train['text'][4])  # 4番目のテキストを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:43.496382Z",
     "iopub.status.busy": "2024-07-18T06:18:43.496034Z",
     "iopub.status.idle": "2024-07-18T06:18:43.808097Z",
     "shell.execute_reply": "2024-07-18T06:18:43.807411Z",
     "shell.execute_reply.started": "2024-07-18T06:18:43.496349Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = 'User prompt: ' + train['prompt'] + '\\n\\nModel A:\\n' + train['response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + train['response_b']  # 各行にユーザープロンプトとモデルの応答を結合\n",
    "print(train['text'][4])  # 4番目のテキストを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcd955",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(train['text'][4])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータセットの50%のみを使用してトレーニング\n",
    "# train = train[:int(len(train) * 0.5)]  # 最初の50%を使用する場合（コメントアウト）\n",
    "train = train[int(len(train) * 0.5):]  # データセットの後半を使用\n",
    "\n",
    "# データを2つの半分に分割\n",
    "first_half = train[:int(len(train) * 0.5)]  # 最初の半分を取得\n",
    "\n",
    "first_half.loc[:, 'token_count'] = get_token_lengths(first_half['text'])  # 最初の半分のテキストのトークン数をカウント\n",
    "first_half.loc[:, 'label'] = np.argmax(first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # トレーニングデータ全体のトークン数をカウント\n",
    "\n",
    "# モデルのラベルを準備し、最大インデックスを取得\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "# データを表示\n",
    "display(train.head())  # トレーニングデータの最初の数行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:20.62856Z",
     "iopub.status.busy": "2024-07-18T06:45:20.628221Z",
     "iopub.status.idle": "2024-07-18T06:45:20.650268Z",
     "shell.execute_reply": "2024-07-18T06:45:20.649282Z",
     "shell.execute_reply.started": "2024-07-18T06:45:20.62853Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータセットの50%のみを使用してトレーニング\n",
    "# train = train[:int(len(train) * 0.5)]  # 最初の50%を使用する場合（コメントアウト）\n",
    "train = train[int(len(train) * 0.5):]  # データセットの後半を使用\n",
    "\n",
    "# データを2つの半分に分割\n",
    "first_half = train[:int(len(train) * 0.5)]  # 最初の半分を取得\n",
    "\n",
    "first_half.loc[:, 'token_count'] = get_token_lengths(first_half['text'])  # 最初の半分のテキストのトークン数をカウント\n",
    "first_half.loc[:, 'label'] = np.argmax(first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # トレーニングデータ全体のトークン数をカウント\n",
    "\n",
    "# モデルのラベルを準備し、最大インデックスを取得\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "# データを表示\n",
    "display(train.head())  # トレーニングデータの最初の数行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e602b39",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Train with only take 50% train dataset\n",
    "# train = train[:int(len(train) * 0.5)]\n",
    "train = train[int(len(train) * 0.5):]\n",
    "\n",
    "# Tsplit to two halves\n",
    "first_half = train[:int(len(train) * 0.5)]\n",
    "\n",
    "first_half.loc[:, 'token_count'] = get_token_lengths(first_half['text'])\n",
    "first_half.loc[:, 'label'] = np.argmax(first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)\n",
    "\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])\n",
    "\n",
    "# prepare label for model and get the max index\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n",
    "\n",
    "# Display data\n",
    "display(train.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70018e5c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train.label.value_counts()  # ラベルの値カウントを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:43.073681Z",
     "iopub.status.busy": "2024-07-18T06:19:43.073305Z",
     "iopub.status.idle": "2024-07-18T06:19:43.080943Z",
     "shell.execute_reply": "2024-07-18T06:19:43.080199Z",
     "shell.execute_reply.started": "2024-07-18T06:19:43.073646Z"
    }
   },
   "outputs": [],
   "source": [
    "train.label.value_counts()  # ラベルの値カウントを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6088f40",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train.label.value_counts()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークン数の統計を表示\n",
    "display(train['token_count'].describe().to_frame().astype(int))  # トークン数の統計情報を整数型のデータフレームとして表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:43.919899Z",
     "iopub.status.busy": "2024-07-18T06:19:43.919256Z",
     "iopub.status.idle": "2024-07-18T06:19:43.930622Z",
     "shell.execute_reply": "2024-07-18T06:19:43.929879Z",
     "shell.execute_reply.started": "2024-07-18T06:19:43.919861Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン数の統計を表示\n",
    "display(train['token_count'].describe().to_frame().astype(int))  # トークン数の統計情報を整数型のデータフレームとして表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4134850",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# token Count\n",
    "display(train['token_count'].describe().to_frame().astype(int))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データの90%をカバーするトークンの長さを取得しますが、1024の長さを維持します！\n",
    "np.percentile(train['token_count'], 90)  # トークン数の90パーセンタイルを取得します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:47.811834Z",
     "iopub.status.busy": "2024-07-18T06:19:47.811444Z",
     "iopub.status.idle": "2024-07-18T06:19:47.818289Z",
     "shell.execute_reply": "2024-07-18T06:19:47.817447Z",
     "shell.execute_reply.started": "2024-07-18T06:19:47.811798Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの90%をカバーするトークンの長さを取得しますが、1024の長さを維持します！\n",
    "np.percentile(train['token_count'], 90)  # トークン数の90パーセンタイルを取得します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f40dd9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# get length of tokens which covers 90% of data, we'll still take 1024 length!\n",
    "np.percentile(train['token_count'], 90)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイズ\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfe7f4",
   "metadata": {},
   "source": [
    "# トークナイズ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce112760",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# データをトークナイズします\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(),  # テキストをリストとしてトークナイズ\n",
    "    padding='max_length',  # 最大長でパディング\n",
    "    max_length=CFG.MAX_LENGTH,  # 最大長を設定\n",
    "    truncation=True,  # 長すぎるテキストは切り詰める\n",
    "    return_tensors='np')  # NumPyテンソルとして返す\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_IDS = tokens['input_ids']  # トークンIDを取得\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得\n",
    "# テキストのラベル\n",
    "LABELS = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values  # ラベルを取得\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079f90bd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # Tokenize Data\n",
    "# tokens = tokenizer(\n",
    "#     train['text'].tolist(), \n",
    "#     padding='max_length', \n",
    "#     max_length=CFG.MAX_LENGTH, \n",
    "#     truncation=True, \n",
    "#     return_tensors='np')\n",
    "\n",
    "# # Input IDs are the token IDs\n",
    "# INPUT_IDS = tokens['input_ids']\n",
    "# # Attention Masks to Ignore Padding Tokens\n",
    "# ATTENTION_MASKS = tokens['attention_mask']\n",
    "# # Label of Texts\n",
    "# LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values\n",
    "\n",
    "# print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "# print(f'LABELS shape: {LABELS.shape}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokens = tokenizer(\n",
    "    first_half['text'].tolist(),  # 最初の半分のテキストをリストとしてトークナイズ\n",
    "    padding='max_length',  # 最大長でパディングを行う\n",
    "    max_length=CFG.MAX_LENGTH,  # 最大長を設定\n",
    "    truncation=True,  # 長すぎるテキストは切り捨てる\n",
    "    return_tensors='np'  # NumPyテンソルとして返す\n",
    ")\n",
    "\n",
    "INPUT_IDS = tokens['input_ids']  # トークンIDを取得\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得\n",
    "LABELS = first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values  # ラベルを取得\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:20:44.78341Z",
     "iopub.status.busy": "2024-07-18T06:20:44.782805Z",
     "iopub.status.idle": "2024-07-18T06:20:48.556603Z",
     "shell.execute_reply": "2024-07-18T06:20:48.555869Z",
     "shell.execute_reply.started": "2024-07-18T06:20:44.783355Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(\n",
    "    first_half['text'].tolist(),  # 最初の半分のテキストをリストとしてトークナイズ\n",
    "    padding='max_length',  # 最大長でパディングを行う\n",
    "    max_length=CFG.MAX_LENGTH,  # 最大長を設定\n",
    "    truncation=True,  # 長すぎるテキストは切り捨てる\n",
    "    return_tensors='np'  # NumPyテンソルとして返す\n",
    ")\n",
    "\n",
    "INPUT_IDS = tokens['input_ids']  # トークンIDを取得\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得\n",
    "LABELS = first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values  # ラベルを取得\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764360e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokens = tokenizer(\n",
    "    first_half['text'].tolist(), \n",
    "    padding='max_length', \n",
    "    max_length=CFG.MAX_LENGTH, \n",
    "    truncation=True, \n",
    "    return_tensors='np'\n",
    ")\n",
    "\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "LABELS = first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "print(f'LABELS shape: {LABELS.shape}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def train_dataset(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        # インデックスをシャッフル\n",
    "        np.random.shuffle(IDXS)\n",
    "        # 全インデックスを一度だけイテレート\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る（マルチラベル出力）\n",
    "            \n",
    "            # TPUノードにシャーディングを行う（適用可能であれば、メッシュを適切に定義する必要があります）\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            \n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)  # トレーニングデータセットを作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:13.638946Z",
     "iopub.status.busy": "2024-07-18T06:45:13.638158Z",
     "iopub.status.idle": "2024-07-18T06:45:13.662002Z",
     "shell.execute_reply": "2024-07-18T06:45:13.661088Z",
     "shell.execute_reply.started": "2024-07-18T06:45:13.638914Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_dataset(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        # インデックスをシャッフル\n",
    "        np.random.shuffle(IDXS)\n",
    "        # 全インデックスを一度だけイテレート\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る（マルチラベル出力）\n",
    "            \n",
    "            # TPUノードにシャーディングを行う（適用可能であれば、メッシュを適切に定義する必要があります）\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            \n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)  # トレーニングデータセットを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58de10f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def train_dataset(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))\n",
    "    while True:\n",
    "        # Shuffle Indices\n",
    "        np.random.shuffle(IDXS)\n",
    "        # Iterate Over All Indices Once\n",
    "        for idxs in IDXS.reshape(-1, batch_size):\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # Multi-label output\n",
    "            \n",
    "            # Shard Over TPU Nodes if applicable (you need to define mesh appropriately)\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))\n",
    "            \n",
    "            yield input_ids, attention_mask, labels\n",
    "\n",
    "TRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最初の半分のデータセット生成器を定義します\n",
    "def train_dataset_first_half(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        np.random.shuffle(IDXS)  # インデックスをシャッフル\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset_first_half(CFG.BATCH_SIZE)  # 最初の半分のトレーニングデータセットを作成\n",
    "\n",
    "# 最初の半分のためのエポックごとのステップ数を計算\n",
    "STEPS_PER_EPOCH = len(first_half) // CFG.BATCH_SIZE  # エポックごとのステップ数を計算\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:42:27.644213Z",
     "iopub.status.busy": "2024-07-18T06:42:27.643351Z",
     "iopub.status.idle": "2024-07-18T06:42:27.650446Z",
     "shell.execute_reply": "2024-07-18T06:42:27.649653Z",
     "shell.execute_reply.started": "2024-07-18T06:42:27.644165Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最初の半分のデータセット生成器を定義します\n",
    "def train_dataset_first_half(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        np.random.shuffle(IDXS)  # インデックスをシャッフル\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset_first_half(CFG.BATCH_SIZE)  # 最初の半分のトレーニングデータセットを作成\n",
    "\n",
    "# 最初の半分のためのエポックごとのステップ数を計算\n",
    "STEPS_PER_EPOCH = len(first_half) // CFG.BATCH_SIZE  # エポックごとのステップ数を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f46953",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Define dataset generator for the first half\n",
    "def train_dataset_first_half(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))\n",
    "    while True:\n",
    "        np.random.shuffle(IDXS)\n",
    "        for idxs in IDXS.reshape(-1, batch_size):\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))\n",
    "            yield input_ids, attention_mask, labels\n",
    "\n",
    "TRAIN_DATASET = train_dataset_first_half(CFG.BATCH_SIZE)\n",
    "# Calculate STEPS_PER_EPOCH for the first half\n",
    "STEPS_PER_EPOCH = len(first_half) // CFG.BATCH_SIZE\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの読み込み\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae51fc",
   "metadata": {},
   "source": [
    "# モデルの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd355d9a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Load Model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 3つのターゲットラベルを用いた分類用のモデルを読み込みます\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    CFG.MODEL_NAME,  # 指定したモデル名から読み込む\n",
    "    num_labels=CFG.NUM_LABELS,  # ラベルの数を指定\n",
    "    torch_dtype=torch.bfloat16)  # PyTorchのデータ型を指定\n",
    "\n",
    "base_model.config.pretraining_tp = 1  # 事前トレーニングのTPを1に設定\n",
    "\n",
    "# パディングトークンを設定\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンIDを設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b6f00",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load model for classification with 3 target label\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    CFG.MODEL_NAME,\n",
    "    num_labels=CFG.NUM_LABELS,\n",
    "    torch_dtype=torch.bfloat16)\n",
    "\n",
    "base_model.config.pretraining_tp = 1 \n",
    "\n",
    "# Assign Padding TOKEN\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "413ef9d4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ローレンジ適応（LORA）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebb861e",
   "metadata": {},
   "source": [
    "# ローレンジ適応（LORA）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cd79cd",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Low-Rank Adaptation [LORA]\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.LORA_RANK,  # ローランク行列の次元\n",
    "    lora_alpha=CFG.LORA_ALPHA,  # LoRAのアクティベーションと事前トレーニングされた重みアクティベーションのスケーリング係数\n",
    "    lora_dropout=CFG.DROPOUT,  # ドロップアウト率\n",
    "    bias='none',  # バイアスの設定\n",
    "    inference_mode=False,  # 推論モードの設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプをシーケンス分類に設定\n",
    "    target_modules=CFG.LORA_MODULES  # 出力と値のプロジェクションのみを使用\n",
    ")\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd6df5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=CFG.LORA_RANK,  # the dimension of the low-rank matrices\n",
    "    lora_alpha = CFG.LORA_ALPHA, # scaling factor for LoRA activations vs pre-trained weight activations\n",
    "    lora_dropout= CFG.DROPOUT, \n",
    "    bias='none',\n",
    "    inference_mode=False,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=CFG.LORA_MODULES ) # Only Use Output and Values Projection\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoRAモデルを作成\n",
    "model = get_peft_model(base_model, lora_config)  # 基本モデルとLoRA設定からLoRAモデルを生成\n",
    "# 学習可能なパラメータを表示\n",
    "model.print_trainable_parameters()  # 学習可能なパラメータの情報を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:44:56.918569Z",
     "iopub.status.busy": "2024-07-18T06:44:56.91778Z",
     "iopub.status.idle": "2024-07-18T06:44:56.934615Z",
     "shell.execute_reply": "2024-07-18T06:44:56.93381Z",
     "shell.execute_reply.started": "2024-07-18T06:44:56.918535Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoRAモデルを作成\n",
    "model = get_peft_model(base_model, lora_config)  # 基本モデルとLoRA設定からLoRAモデルを生成\n",
    "# 学習可能なパラメータを表示\n",
    "model.print_trainable_parameters()  # 学習可能なパラメータの情報を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6e941",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Create LoRa Model\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "# Trainable Parameters\n",
    "model.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# TPUノードの数を取得\n",
    "num_devices = xr.global_runtime_device_count()  # グローバルなランタイムデバイスの数を取得\n",
    "mesh_shape = (1, num_devices, 1)  # メッシュの形状を定義\n",
    "device_ids = np.array(range(num_devices))  # デバイスIDの配列を作成\n",
    "mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))  # メッシュを作成\n",
    "\n",
    "# モデルを分割\n",
    "partition_module(model, mesh)  # モデルをメッシュに分配\n",
    "\n",
    "print(f'num_devices: {num_devices}')  # 使用するデバイスの数を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPUノードの数を取得\n",
    "num_devices = xr.global_runtime_device_count()  # グローバルなランタイムデバイスの数を取得\n",
    "mesh_shape = (1, num_devices, 1)  # メッシュの形状を定義\n",
    "device_ids = np.array(range(num_devices))  # デバイスIDの配列を作成\n",
    "mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))  # メッシュを作成\n",
    "\n",
    "# モデルを分割\n",
    "partition_module(model, mesh)  # モデルをメッシュに分配\n",
    "\n",
    "print(f'num_devices: {num_devices}')  # 使用するデバイスの数を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72b1c0f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Number of TPU Nodes\n",
    "num_devices = xr.global_runtime_device_count()\n",
    "mesh_shape = (1, num_devices, 1)\n",
    "device_ids = np.array(range(num_devices))\n",
    "mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\n",
    "# distribute model\n",
    "partition_module(model, mesh)\n",
    "\n",
    "print(f'num_devices: {num_devices}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 学習可能な層を確認します\n",
    "MODEL_LAYERS_ROWS = []  # モデル層情報を格納するリスト\n",
    "TRAINABLE_PARAMS = []  # 学習可能なパラメータを格納するリスト\n",
    "N_TRAINABLE_PARAMS = 0  # 学習可能なパラメータの総数\n",
    "\n",
    "# モデルの各パラメータをループ\n",
    "for name, param in model.named_parameters():\n",
    "    # レイヤーのパラメータ数を計算\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "    # 学習可能な層のみ\n",
    "    if param.requires_grad:\n",
    "        # 層の情報を追加\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            'param': n_parameters,  # パラメータ数\n",
    "            'name': name,  # レイヤー名\n",
    "            'dtype': param.data.dtype,  # データ型\n",
    "        })\n",
    "        # 学習可能なパラメータを追加\n",
    "        TRAINABLE_PARAMS.append({'params': param})\n",
    "        # 学習可能なパラメータの数を加算\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "        \n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))  # モデル層情報のデータフレームを表示\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}  # 学習可能なパラメータの総数を表示\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}  # 学習可能な層の数を表示\n",
    "===============================\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:44:31.246215Z",
     "iopub.status.busy": "2024-07-18T06:44:31.2459Z",
     "iopub.status.idle": "2024-07-18T06:44:31.476841Z",
     "shell.execute_reply": "2024-07-18T06:44:31.476084Z",
     "shell.execute_reply.started": "2024-07-18T06:44:31.246187Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習可能な層を確認します\n",
    "MODEL_LAYERS_ROWS = []  # モデル層情報を格納するリスト\n",
    "TRAINABLE_PARAMS = []  # 学習可能なパラメータを格納するリスト\n",
    "N_TRAINABLE_PARAMS = 0  # 学習可能なパラメータの総数\n",
    "\n",
    "# モデルの各パラメータをループ\n",
    "for name, param in model.named_parameters():\n",
    "    # レイヤーのパラメータ数を計算\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "    # 学習可能な層のみ\n",
    "    if param.requires_grad:\n",
    "        # 層の情報を追加\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            'param': n_parameters,  # パラメータ数\n",
    "            'name': name,  # レイヤー名\n",
    "            'dtype': param.data.dtype,  # データ型\n",
    "        })\n",
    "        # 学習可能なパラメータを追加\n",
    "        TRAINABLE_PARAMS.append({'params': param})\n",
    "        # 学習可能なパラメータの数を加算\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "        \n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))  # モデル層情報のデータフレームを表示\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}  # 学習可能なパラメータの総数を表示\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}  # 学習可能な層の数を表示\n",
    "===============================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d9f840",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Verfy The Trainable Layers\n",
    "MODEL_LAYERS_ROWS = []\n",
    "TRAINABLE_PARAMS = []\n",
    "N_TRAINABLE_PARAMS = 0\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    # Layer Parameter Count\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "    # Only Trainable Layers\n",
    "    if param.requires_grad:\n",
    "        # Add Layer Information\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            'param': n_parameters,\n",
    "            'name': name,\n",
    "            'dtype': param.data.dtype,\n",
    "        })\n",
    "        # Append Trainable Parameter\n",
    "        TRAINABLE_PARAMS.append({ 'params': param })\n",
    "        # Add Number Of Trainable Parameters\"\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "        \n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}\n",
    "===============================\n",
    "\"\"\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニング\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a088b",
   "metadata": {},
   "source": [
    "# トレーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd958a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Training\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 学習率とオプティマイザーの設定\n",
    "N_SAMPLES = len(train)  # トレーニングサンプルの数を取得\n",
    "STEPS_PER_EPOCH = N_SAMPLES // CFG.BATCH_SIZE  # エポックごとのステップ数を計算\n",
    "\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=CFG.LR_MAX)  # AdamWオプティマイザーを設定\n",
    "\n",
    "# ウォームアップ付きコサイン学習率スケジューラ\n",
    "lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer=OPTIMIZER,  # オプティマイザーを指定\n",
    "    num_warmup_steps=CFG.NUM_WARMUP_STEPS,  # ウォームアップステップ数を指定\n",
    "    num_training_steps=STEPS_PER_EPOCH * CFG.NUM_EPOCHS  # 総トレーニングステップ数を計算\n",
    ")\n",
    "\n",
    "print(f'BATCH_SIZE: {CFG.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')  # バッチサイズ、サンプル数、エポックごとのステップ数を表示\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef16aad",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# LR & Optimizer\n",
    "N_SAMPLES = len(train)\n",
    "STEPS_PER_EPOCH = N_SAMPLES // CFG.BATCH_SIZE\n",
    "\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=CFG.LR_MAX)\n",
    "\n",
    "# Cosine Learning Rate With Warmup\n",
    "lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer=OPTIMIZER,\n",
    "    num_warmup_steps=CFG.NUM_WARMUP_STEPS,\n",
    "    num_training_steps=STEPS_PER_EPOCH * CFG.NUM_EPOCHS)\n",
    "\n",
    "print(f'BATCH_SIZE: {CFG.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# オプティマイザーの状態（例えば、モーメンタムバッファ）のデータ型を設定\n",
    "for state in OPTIMIZER.state.values():  # オプティマイザーの状態をループ\n",
    "    for k, v in state.items():  # 各状態のキーと値をループ\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:  # 値がテンソルで、データ型がfloat32でない場合\n",
    "            state[v] = v.to(dtype=torch.float32)  # データ型をfloat32に変換\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:00:12.013144Z",
     "iopub.status.busy": "2024-07-18T01:00:12.012839Z",
     "iopub.status.idle": "2024-07-18T01:00:15.084005Z",
     "shell.execute_reply": "2024-07-18T01:00:15.082811Z",
     "shell.execute_reply.started": "2024-07-18T01:00:12.013118Z"
    }
   },
   "outputs": [],
   "source": [
    "# オプティマイザーの状態（例えば、モーメンタムバッファ）のデータ型を設定\n",
    "for state in OPTIMIZER.state.values():  # オプティマイザーの状態をループ\n",
    "    for k, v in state.items():  # 各状態のキーと値をループ\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:  # 値がテンソルで、データ型がfloat32でない場合\n",
    "            state[v] = v.to(dtype=torch.float32)  # データ型をfloat32に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8576bf26",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Set the data type for the optimizer's state (e.g., momentum buffers)\n",
    "for state in OPTIMIZER.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:\n",
    "            state[v] = v.to(dtype=torch.float32)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)  # トレーニングデータセットから次のバッチを取得\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')  # 入力IDの形状とデータ型を表示\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')  # アテンションマスクの形状とデータ型を表示\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')  # ラベルの形状とデータ型を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:36.095228Z",
     "iopub.status.busy": "2024-07-18T00:33:36.095004Z",
     "iopub.status.idle": "2024-07-18T00:33:36.108934Z",
     "shell.execute_reply": "2024-07-18T00:33:36.108232Z",
     "shell.execute_reply.started": "2024-07-18T00:33:36.095206Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)  # トレーニングデータセットから次のバッチを取得\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')  # 入力IDの形状とデータ型を表示\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')  # アテンションマスクの形状とデータ型を表示\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')  # ラベルの形状とデータ型を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc777a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "# ダミー予測\n",
    "with torch.no_grad():  # 勾配計算を行わない設定\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # モデルに入力IDとアテンションマスクを与えて出力を取得\n",
    "    \n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')  # ロジットとそのデータ型を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:36.110039Z",
     "iopub.status.busy": "2024-07-18T00:33:36.109801Z",
     "iopub.status.idle": "2024-07-18T00:33:58.48704Z",
     "shell.execute_reply": "2024-07-18T00:33:58.486299Z",
     "shell.execute_reply.started": "2024-07-18T00:33:36.110017Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ダミー予測\n",
    "with torch.no_grad():  # 勾配計算を行わない設定\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # モデルに入力IDとアテンションマスクを与えて出力を取得\n",
    "    \n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')  # ロジットとそのデータ型を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b443b6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "# Dummy Prediction\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルをトレーニングモードに設定\n",
    "model.train()\n",
    "\n",
    "# 損失関数、交差エントロピー\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss().to(dtype=torch.float32)  # 交差エントロピー損失関数をfloat32型に設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:58.489137Z",
     "iopub.status.busy": "2024-07-18T00:33:58.488884Z",
     "iopub.status.idle": "2024-07-18T00:33:58.496974Z",
     "shell.execute_reply": "2024-07-18T00:33:58.496317Z",
     "shell.execute_reply.started": "2024-07-18T00:33:58.489112Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルをトレーニングモードに設定\n",
    "model.train()\n",
    "\n",
    "# 損失関数、交差エントロピー\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss().to(dtype=torch.float32)  # 交差エントロピー損失関数をfloat32型に設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b03a93",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Put Model In Train Mode\n",
    "model.train()\n",
    "\n",
    "# Loss Function, Cross Entropy\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss().to(dtype=torch.float32)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "st = time()  # 開始時間を記録\n",
    "warnings.filterwarnings(\"error\")  # 警告をエラーとして表示\n",
    "METRICS = {\n",
    "    'loss': [],  # 損失を格納するリスト\n",
    "    'accuracy': {'y_true': [], 'y_pred': []}  # 正解ラベルと予測ラベルを格納する辞書\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(CFG.NUM_EPOCHS)):  # エポックをループ\n",
    "    ste = time()  # 各エポックの開始時間を記録\n",
    "    for step in range(STEPS_PER_EPOCH):  # 各エポックのステップをループ\n",
    "        # 勾配をゼロに設定\n",
    "        OPTIMIZER.zero_grad()\n",
    "        \n",
    "        # バッチを取得\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "        \n",
    "        # フォワードパス\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "       \n",
    "        # ロジットをfloat32に設定\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "        \n",
    "        # バックワードパス\n",
    "        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))  # 損失を計算\n",
    "        loss.backward()  # 勾配を計算\n",
    "        \n",
    "        # オプティマイザステップ\n",
    "        OPTIMIZER.step()  # パラメータを更新\n",
    "        xm.mark_step()  # TPUステップをマーク\n",
    "        \n",
    "        # 学習率スケジューラを更新\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # メトリクスとプログレスバーを更新\n",
    "        METRICS['loss'].append(float(loss))  # 損失を追加\n",
    "        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()  # 正解ラベルを追加\n",
    "        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=1).cpu().tolist()  # 予測ラベルを追加\n",
    "        \n",
    "        if (step + 1) % 200 == 0:  # 200ステップごとにメトリクスを表示\n",
    "            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])  # 最新の損失を追加\n",
    "            metrics += ', µ_auc: {:.3f}'.format(accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), axis=-1), \\\n",
    "                                                               METRICS['accuracy']['y_pred']))  # 精度を計算\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']  # 学習率を取得\n",
    "            print(f'{epoch+1:02}/{CFG.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n",
    "            print(f'\\nSteps per epoch: {step+1} complete | Time elapsed: {time()- st}')  # 経過時間を表示\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1} Completed | Total time for epoch: {time() - ste} ' )  # エポックの完了時間を表示\n",
    "\n",
    "    # 停止した場合、TPUで将来的にトレーニングを続けるためにモデルとオプティマイザを保存\n",
    "    xm.save({k: v.cpu() for k, v in model.named_parameters() if v.requires_grad}, f'model_llama_3_cp_{epoch+1}_v1.pth')  # モデルを保存\n",
    "    xm.save(OPTIMIZER.state_dict(), f'optimizer_llama_3_cp_{epoch+1}_v1.pth')  # オプティマイザを保存\n",
    "    \n",
    "    print(f'Model saved at epoch {epoch+1}| Elapsed time: {time() - st} ')  # モデル保存のメッセージを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:58.4981Z",
     "iopub.status.busy": "2024-07-18T00:33:58.497867Z"
    }
   },
   "outputs": [],
   "source": [
    "st = time()  # 開始時間を記録\n",
    "warnings.filterwarnings(\"error\")  # 警告をエラーとして表示\n",
    "METRICS = {\n",
    "    'loss': [],  # 損失を格納するリスト\n",
    "    'accuracy': {'y_true': [], 'y_pred': []}  # 正解ラベルと予測ラベルを格納する辞書\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(CFG.NUM_EPOCHS)):  # エポックをループ\n",
    "    ste = time()  # 各エポックの開始時間を記録\n",
    "    for step in range(STEPS_PER_EPOCH):  # 各エポックのステップをループ\n",
    "        # 勾配をゼロに設定\n",
    "        OPTIMIZER.zero_grad()\n",
    "        \n",
    "        # バッチを取得\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "        \n",
    "        # フォワードパス\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "       \n",
    "        # ロジットをfloat32に設定\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "        \n",
    "        # バックワードパス\n",
    "        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))  # 損失を計算\n",
    "        loss.backward()  # 勾配を計算\n",
    "        \n",
    "        # オプティマイザステップ\n",
    "        OPTIMIZER.step()  # パラメータを更新\n",
    "        xm.mark_step()  # TPUステップをマーク\n",
    "        \n",
    "        # 学習率スケジューラを更新\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # メトリクスとプログレスバーを更新\n",
    "        METRICS['loss'].append(float(loss))  # 損失を追加\n",
    "        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()  # 正解ラベルを追加\n",
    "        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=1).cpu().tolist()  # 予測ラベルを追加\n",
    "        \n",
    "        if (step + 1) % 200 == 0:  # 200ステップごとにメトリクスを表示\n",
    "            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])  # 最新の損失を追加\n",
    "            metrics += ', µ_auc: {:.3f}'.format(accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), axis=-1), \\\n",
    "                                                               METRICS['accuracy']['y_pred']))  # 精度を計算\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']  # 学習率を取得\n",
    "            print(f'{epoch+1:02}/{CFG.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n",
    "            print(f'\\nSteps per epoch: {step+1} complete | Time elapsed: {time()- st}')  # 経過時間を表示\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1} Completed | Total time for epoch: {time() - ste} ' )  # エポックの完了時間を表示\n",
    "\n",
    "    # 停止した場合、TPUで将来的にトレーニングを続けるためにモデルとオプティマイザを保存\n",
    "    xm.save({k: v.cpu() for k, v in model.named_parameters() if v.requires_grad}, f'model_llama_3_cp_{epoch+1}_v1.pth')  # モデルを保存\n",
    "    xm.save(OPTIMIZER.state_dict(), f'optimizer_llama_3_cp_{epoch+1}_v1.pth')  # オプティマイザを保存\n",
    "    \n",
    "    print(f'Model saved at epoch {epoch+1}| Elapsed time: {time() - st} ')  # モデル保存のメッセージを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14b3ecc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time()\n",
    "warnings.filterwarnings(\"error\")\n",
    "METRICS = {\n",
    "    'loss': [],\n",
    "    'accuracy': {'y_true': [], 'y_pred': [] }}\n",
    "\n",
    "for epoch in tqdm(range(CFG.NUM_EPOCHS)):\n",
    "    ste = time()\n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # Zero Out Gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "        \n",
    "        # Get Batch\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "       \n",
    "        # Logits Float32\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "        \n",
    "        # Backward Pass\n",
    "        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))\n",
    "        loss.backward()\n",
    "        \n",
    "        # optimizer step\n",
    "        OPTIMIZER.step()\n",
    "        xm.mark_step()\n",
    "        \n",
    "        # Update Learning Rate Scheduler\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # Update Metrics And Progress Bar\n",
    "        METRICS['loss'].append(float(loss))\n",
    "        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()\n",
    "        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=1).cpu().tolist()\n",
    "        \n",
    "        if (step + 1) % 200 == 0:  \n",
    "            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])\n",
    "            metrics += ', µ_auc: {:.3f}'.format(accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), axis=-1), \\\n",
    "                                                               METRICS['accuracy']['y_pred']))\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']\n",
    "            print(f'{epoch+1:02}/{CFG.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n",
    "            print(f'\\nSteps per epoch: {step+1} complete | Time elapsed: {time()- st}')\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1} Completed | Total time for epoch: {time() - ste} ' )\n",
    "\n",
    "    # If stopped, and to continue training in future on tpu we save model and optimizer\n",
    "    xm.save({k: v.cpu() for k, v in model.named_parameters() if v.requires_grad}, f'model_llama_3_cp_{epoch+1}_v1.pth')\n",
    "    xm.save(OPTIMIZER.state_dict(), f'optimizer_llama_3_cp_{epoch+1}_v1.pth')    \n",
    "    \n",
    "    print(f'Model saved at epoch {epoch+1}| Elapsed time: {time() - st} ')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(15, 6))  # グラフのサイズを設定\n",
    "plt.plot(METRICS['loss'])  # 損失のプロット\n",
    "plt.xlabel('Step per epoch')  # x軸のラベル\n",
    "plt.ylabel('Loss')  # y軸のラベル\n",
    "plt.title('Loss Plot step per epoch')  # グラフのタイトル\n",
    "plt.show()  # グラフを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:39:32.034628Z",
     "iopub.status.busy": "2024-07-18T00:39:32.034322Z",
     "iopub.status.idle": "2024-07-18T00:39:32.2572Z",
     "shell.execute_reply": "2024-07-18T00:39:32.25633Z",
     "shell.execute_reply.started": "2024-07-18T00:39:32.034602Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))  # グラフのサイズを設定\n",
    "plt.plot(METRICS['loss'])  # 損失のプロット\n",
    "plt.xlabel('Step per epoch')  # x軸のラベル\n",
    "plt.ylabel('Loss')  # y軸のラベル\n",
    "plt.title('Loss Plot step per epoch')  # グラフのタイトル\n",
    "plt.show()  # グラフを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc4fcb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(METRICS['loss'])    \n",
    "plt.xlabel('Step per epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Plot step per epoch')    \n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f369c",
   "metadata": {},
   "source": [
    "# モデルの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288266f1",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Save Model\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "model = model.cpu()  # モデルをCPUに移動\n",
    "torch.save(dict([(k, v) for k, v in model.named_parameters() if v.requires_grad]), 'llama_3_finetuned_model.pth')  # 学習可能なパラメータを保存\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd95535",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = model.cpu()\n",
    "torch.save(dict([(k,v) for k, v in model.named_parameters() if v.requires_grad]), 'llama_3_finetuned_model.pth')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結論\n",
    "\n",
    "トレーニングの速度を上げて最適化する余地はまだたくさんあります！ より多くのデータや異なるバッチサイズ、学習率を試してみてください... すべての成功を祈ります！\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e56c1",
   "metadata": {},
   "source": [
    "# 結論\n",
    "\n",
    "トレーニングの速度を上げて最適化する余地はまだたくさんあります！ より多くのデータや異なるバッチサイズ、学習率を試してみてください... すべての成功を祈ります！"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 3863727,
     "sourceId": 6703755,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30748,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
