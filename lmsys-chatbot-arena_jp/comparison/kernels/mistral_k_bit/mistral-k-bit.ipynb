{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e6570d4",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookでは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、人間の好みに基づいたモデルのトレーニングおよび評価を行うための準備と実行が取り扱われています。具体的には、異なる応答を提示するチャットボットのモデルを比較し、どちらが好まれるかを予測するための機械学習モデルの構築を目指しています。\n",
    "\n",
    "### 取り組んでいる問題\n",
    "Notebookは、ユーザープロンプトに対する2つの異なる応答の好みを判定する「報酬モデル」を構築するという課題に取り組んでいます。具体的には、トレーニングデータを処理し、必要な特徴量を抽出し、最終的にモデルのトレーニングを行う過程を示しています。\n",
    "\n",
    "### 主な手法とライブラリ\n",
    "1. **データ読み込みと前処理**:\n",
    "   - Pandasを使用してトレーニングデータおよびテストデータをCSVファイルから読み込み、各応答に関する特徴を処理するカスタム関数が定義されています。\n",
    "   - Hugging Faceの`datasets`ライブラリを利用してデータセットを管理します。\n",
    "\n",
    "2. **モデルの選定と設定**:\n",
    "   - Hugging FaceのTransformersライブラリから、Mistralという事前学習済みの因果言語モデルを使用し、量子化設定を行った上でモデルを読み込みます。\n",
    "   - LoRA（Low-Rank Adaptation）技術を用いて、モデルにファインチューニングする設定が適用されます。\n",
    "\n",
    "3. **トレーニング**:\n",
    "   - `Trainer`クラスを拡張してカスタムトレーナーを定義し、損失計算にクラス重みを用いるなどの工夫がされています。\n",
    "   - モデルのトレーニングは、PyTorchを使用し、勾配チェックポイント機能や、評価メトリクスを定義して行います。\n",
    "\n",
    "4. **評価**:\n",
    "   - トレーニング後、ユーザーが提示したプロンプトに基づいてモデルがどのように応答するかを生成し、その性能を評価します。\n",
    "\n",
    "このNotebookは、データの前処理からモデルのトレーニングと評価に至る一連の流れを詳細に記述し、実践的な機械学習プロジェクトの進め方を示しています。使用するライブラリには、NumPy、Pandas、Transformers、Hugging FaceのDatasets、PyTorch、PEFT（Parameter-Efficient Fine-Tuning）などがあります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c1144",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、そのJupyter Notebook内の機械学習および深層学習関連の専門用語の簡単な解説です。特に、初心者がつまずきやすいものに焦点を当てています。\n",
    "\n",
    "1. **量子化 (Quantization)**:\n",
    "   - モデルのサイズを削減し、推論速度を向上させるために、モデルの重みを低精度（例：32ビットから8ビットや4ビット）に変換するプロセスです。これにより、メモリ使用量や計算コストが減少します。\n",
    "\n",
    "2. **ダブル量子化 (Double Quantization)**:\n",
    "   - 通常の量子化に加え、さらに別の段階で量子化を行うことです。この手法は、さらなる圧縮を実現するために使用されます。\n",
    "\n",
    "3. **bfloat16 (Brain Floating Point)**:\n",
    "   - Googleが開発した浮動小数点数形式で、深層学習の計算でよく使用されます。従来の16ビット浮動小数点よりも大きな範囲を持ちながら、表現精度をある程度保持します。\n",
    "\n",
    "4. **Gradient Checkpointing (勾配チェックポイント)**:\n",
    "   - メモリを節約する手法で、順伝播中に計算された中間結果を保持せず、逆伝播中に必要な部分を再計算することでメモリ使用量を削減します。\n",
    "\n",
    "5. **クラス重み (Class Weights)**:\n",
    "   - 不均衡なデータセットにおいて、特定のクラスの影響を強調または抑えるために、損失関数に独自の重みを設定することです。これにより、少数クラスの学習を改善します。\n",
    "\n",
    "6. **トレーニング可能なパラメータ (Trainable Parameters)**:\n",
    "   - モデルのトレーニングによって更新されるパラメータのことを指します。これには、モデルの重みやバイアスが含まれます。\n",
    "\n",
    "7. **PEFT (Parameter-Efficient Fine-Tuning)**:\n",
    "   - モデルの全体を微調整するのではなく、特定の部分のみを微調整する手法で、少ないパラメータで効果的なトレーニングを実現します。\n",
    "\n",
    "8. **LoRA (Low-Rank Adaptation)**:\n",
    "   - PEFTの一種で、モデルの重みを低ランクで近似する手法です。これにより計算コストを削減し、効率的なファインチューニングが可能となります。\n",
    "\n",
    "9. **FSDP (Fully Sharded Data Parallel)**:\n",
    "   - モデルのパラメータを完全に分割し、複数のデバイスで並行してトレーニングしたりチェックポイントを保存したりするための手法です。これにより、メモリ効率が向上します。\n",
    "\n",
    "10. **Data Collator (データコレータ)**:\n",
    "    - トレーニングデータをバッチ処理する際に、必要なフォーマットに整形するための関数やオブジェクトです。特に、パディングやマスキングを考慮する必要があります。\n",
    "\n",
    "11. **ウォームアップステップ (Warmup Steps)**:\n",
    "    - トレーニングの初期段階で、学習率を徐々に増加させるためのステップです。これにより、モデルが安定し、トレーニングの初期の不安定さを軽減します。\n",
    "\n",
    "これらの用語は、特に初心者が実務体験がない場合に馴染みが薄い範囲で、深層学習モデルやトレーニングプロセスを理解する上で重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c627d9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# たとえば、いくつかの便利なパッケージを読み込むことができます\n",
    "\n",
    "import numpy as np # 線形代数用\n",
    "import pandas as pd # データ処理、CSVファイルの入出力（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは、読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# たとえば、これを実行することで（実行をクリックするか、Shift + Enterを押すことで）入力ディレクトリ内のすべてのファイルをリスト表示できます\n",
    "\n",
    "import os # オペレーティングシステムに関する機能を使用するためのモジュール\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'): # \"/kaggle/input\"ディレクトリ内のファイルやフォルダを再帰的に巡回します\n",
    "    for filename in filenames: # ファイル名のリストをループします\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのフルパスを出力します\n",
    "\n",
    "# あなたは現在のディレクトリ（/kaggle/working/）に最大20GBを保存できます。これは「すべて保存して実行」機能を使用してバージョンを作成したときに出力として保持されます\n",
    "# また、一時ファイルを/kaggle/temp/に書き込むこともできますが、現在のセッションの外では保存されません\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-30T10:56:16.328454Z",
     "iopub.status.busy": "2024-06-30T10:56:16.32813Z",
     "iopub.status.idle": "2024-06-30T10:56:16.733353Z",
     "shell.execute_reply": "2024-06-30T10:56:16.732434Z",
     "shell.execute_reply.started": "2024-06-30T10:56:16.32843Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# たとえば、いくつかの便利なパッケージを読み込むことができます\n",
    "\n",
    "import numpy as np # 線形代数用\n",
    "import pandas as pd # データ処理、CSVファイルの入出力（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは、読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# たとえば、これを実行することで（実行をクリックするか、Shift + Enterを押すことで）入力ディレクトリ内のすべてのファイルをリスト表示できます\n",
    "\n",
    "import os # オペレーティングシステムに関する機能を使用するためのモジュール\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'): # \"/kaggle/input\"ディレクトリ内のファイルやフォルダを再帰的に巡回します\n",
    "    for filename in filenames: # ファイル名のリストをループします\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのフルパスを出力します\n",
    "\n",
    "# あなたは現在のディレクトリ（/kaggle/working/）に最大20GBを保存できます。これは「すべて保存して実行」機能を使用してバージョンを作成したときに出力として保持されます\n",
    "# また、一時ファイルを/kaggle/temp/に書き込むこともできますが、現在のセッションの外では保存されません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c2b43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# !pip install cupy-cuda11x>=12.0.0\n",
    "# !pip install packaging>=22\n",
    "# !pip install shapely>=2.0.1\n",
    "# !pip install numpy<1.26\n",
    "# !pip install scipy<1.12\n",
    "!pip install transformers datasets accelerate peft\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# !pip install cupy-cuda11x>=12.0.0  # GPUを利用したCuPyライブラリのインストール（CUDA 11.x以上）\n",
    "# !pip install packaging>=22  # パッケージ管理用ライブラリのインストール（バージョン22以上）\n",
    "# !pip install shapely>=2.0.1  # 幾何学的操作を行うためのShapelyライブラリのインストール（バージョン2.0.1以上）\n",
    "# !pip install numpy<1.26  # 数値計算用のNumPyライブラリのインストール（バージョン1.26未満）\n",
    "# !pip install scipy<1.12  # 科学計算用のSciPyライブラリのインストール（バージョン1.12未満）\n",
    "!pip install transformers datasets accelerate peft  # Transformers、データセット、加速化、PEFTライブラリのインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:56:16.891816Z",
     "iopub.status.busy": "2024-06-30T10:56:16.891352Z",
     "iopub.status.idle": "2024-06-30T10:56:31.055106Z",
     "shell.execute_reply": "2024-06-30T10:56:31.053847Z",
     "shell.execute_reply.started": "2024-06-30T10:56:16.891786Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install cupy-cuda11x>=12.0.0  # GPUを利用したCuPyライブラリのインストール（CUDA 11.x以上）\n",
    "# !pip install packaging>=22  # パッケージ管理用ライブラリのインストール（バージョン22以上）\n",
    "# !pip install shapely>=2.0.1  # 幾何学的操作を行うためのShapelyライブラリのインストール（バージョン2.0.1以上）\n",
    "# !pip install numpy<1.26  # 数値計算用のNumPyライブラリのインストール（バージョン1.26未満）\n",
    "# !pip install scipy<1.12  # 科学計算用のSciPyライブラリのインストール（バージョン1.12未満）\n",
    "!pip install transformers datasets accelerate peft  # Transformers、データセット、加速化、PEFTライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7600b72",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# You only need to run this once per machine\n",
    "!pip install -q -U bitsandbytes\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "# !pip install -q -U datasets scipy ipywidgets\n",
    "!pip install datasets\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このコマンドは、マシンごとに一度だけ実行すれば十分です\n",
    "!pip install -q -U bitsandbytes  # bitsandbytesライブラリのインストール（省略モードで、アップグレードする）\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git  # Hugging FaceのTransformersライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git  # Hugging FaceのPEFTライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git  # Hugging FaceのAccelerateライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U datasets scipy ipywidgets  # データセット、SciPy、およびipywidgetsライブラリのインストール（アップグレード）\n",
    "!pip install datasets  # datasetsライブラリのインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:56:31.057594Z",
     "iopub.status.busy": "2024-06-30T10:56:31.057299Z",
     "iopub.status.idle": "2024-06-30T10:57:00.598862Z",
     "shell.execute_reply": "2024-06-30T10:57:00.597749Z",
     "shell.execute_reply.started": "2024-06-30T10:56:31.057568Z"
    }
   },
   "outputs": [],
   "source": [
    "# このコマンドは、マシンごとに一度だけ実行すれば十分です\n",
    "!pip install -q -U bitsandbytes  # bitsandbytesライブラリのインストール（省略モードで、アップグレードする）\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git  # Hugging FaceのTransformersライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git  # Hugging FaceのPEFTライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git  # Hugging FaceのAccelerateライブラリをGitHubからインストール（アップグレード）\n",
    "# !pip install -q -U datasets scipy ipywidgets  # データセット、SciPy、およびipywidgetsライブラリのインストール（アップグレード）\n",
    "!pip install datasets  # datasetsライブラリのインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1901f3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset('csv', data_files='/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from datasets import load_dataset  # datasetsモジュールからload_dataset関数をインポートします\n",
    "\n",
    "# 'csv'形式のデータセットを読み込みます。特に'test.csv'ファイルを指定しています。\n",
    "train_dataset = load_dataset('csv', data_files='/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを含むCSVファイルを読み込み、train_datasetに格納します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:57:00.600629Z",
     "iopub.status.busy": "2024-06-30T10:57:00.600293Z",
     "iopub.status.idle": "2024-06-30T10:57:02.118465Z",
     "shell.execute_reply": "2024-06-30T10:57:02.117732Z",
     "shell.execute_reply.started": "2024-06-30T10:57:00.600598Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset  # datasetsモジュールからload_dataset関数をインポートします\n",
    "\n",
    "# 'csv'形式のデータセットを読み込みます。特に'test.csv'ファイルを指定しています。\n",
    "train_dataset = load_dataset('csv', data_files='/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを含むCSVファイルを読み込み、train_datasetに格納します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569175c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from huggingface_hub import notebook_login  # Hugging Face Hubからnotebook_login関数をインポートします\n",
    "\n",
    "# Hugging Face Hubへのログインプロンプトを表示します\n",
    "notebook_login()  # ユーザーがHugging Face Hubにログインできるようにします。これにより、モデルやデータセットにアクセスできるようになります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:57:02.120522Z",
     "iopub.status.busy": "2024-06-30T10:57:02.120048Z",
     "iopub.status.idle": "2024-06-30T10:57:02.143838Z",
     "shell.execute_reply": "2024-06-30T10:57:02.143188Z",
     "shell.execute_reply.started": "2024-06-30T10:57:02.120496Z"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login  # Hugging Face Hubからnotebook_login関数をインポートします\n",
    "\n",
    "# Hugging Face Hubへのログインプロンプトを表示します\n",
    "notebook_login()  # ユーザーがHugging Face Hubにログインできるようにします。これにより、モデルやデータセットにアクセスできるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60caf6ed",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config,device_map=\"auto\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  # Hugging FaceのTransformersライブラリから必要なクラスをインポートします\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"  # 使用する基本モデルのIDを指定します\n",
    "bnb_config = BitsAndBytesConfig(  # 量子化に関する設定を作成します\n",
    "    load_in_4bit=True,  # 4ビットでモデルを読み込む設定をします\n",
    "    bnb_4bit_use_double_quant=True,  # ダブル量子化を使用する設定を行います\n",
    "    bnb_4bit_quant_type=\"nf4\",  # 量子化のタイプを指定します（nf4を使用）\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 計算データ型をbfloat16に設定します\n",
    ")\n",
    "\n",
    "# モデルを事前学習済みの状態から読み込みます。量子化設定とデバイスマップを指定します。\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")  # 自動デバイスマッピングでモデルを読み込みます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:57:25.093855Z",
     "iopub.status.busy": "2024-06-30T10:57:25.092858Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorchライブラリをインポートします\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  # Hugging FaceのTransformersライブラリから必要なクラスをインポートします\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"  # 使用する基本モデルのIDを指定します\n",
    "bnb_config = BitsAndBytesConfig(  # 量子化に関する設定を作成します\n",
    "    load_in_4bit=True,  # 4ビットでモデルを読み込む設定をします\n",
    "    bnb_4bit_use_double_quant=True,  # ダブル量子化を使用する設定を行います\n",
    "    bnb_4bit_quant_type=\"nf4\",  # 量子化のタイプを指定します（nf4を使用）\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 計算データ型をbfloat16に設定します\n",
    ")\n",
    "\n",
    "# モデルを事前学習済みの状態から読み込みます。量子化設定とデバイスマップを指定します。\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")  # 自動デバイスマッピングでモデルを読み込みます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b6f003",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(  # 基本モデルのトークナイザーを読み込みます\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    model_max_length=512,  # モデルの最大長を512トークンに設定します\n",
    "    padding_side=\"left\",  # パディングを左側に設定します\n",
    "    add_eos_token=True  # 終了トークンを追加する設定をします\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンを終了トークンに設定します\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定することで、モデル入力の整合性を保ちます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(  # 基本モデルのトークナイザーを読み込みます\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    model_max_length=512,  # モデルの最大長を512トークンに設定します\n",
    "    padding_side=\"left\",  # パディングを左側に設定します\n",
    "    add_eos_token=True  # 終了トークンを追加する設定をします\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンを終了トークンに設定します\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定することで、モデル入力の整合性を保ちます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7265d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('../input/lmsys-chatbot-arena/train.csv')\n",
    "test_data = pd.read_csv('../input/lmsys-chatbot-arena/test.csv')\n",
    "submission_data = pd.read_csv('../input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Pandasライブラリを使用して、CSVファイルを読み込みます\n",
    "train_data = pd.read_csv('../input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込みます\n",
    "test_data = pd.read_csv('../input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込みます\n",
    "submission_data = pd.read_csv('../input/lmsys-chatbot-arena/sample_submission.csv')  # 提出用サンプルデータを読み込みます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandasライブラリを使用して、CSVファイルを読み込みます\n",
    "train_data = pd.read_csv('../input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込みます\n",
    "test_data = pd.read_csv('../input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込みます\n",
    "submission_data = pd.read_csv('../input/lmsys-chatbot-arena/sample_submission.csv')  # 提出用サンプルデータを読み込みます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4687c419",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.shape,test_data.shape,submission_data.shape\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 各データセットの形状（行数と列数）を表示します\n",
    "train_data.shape, test_data.shape, submission_data.shape  # トレーニングデータ、テストデータ、および提出データのサイズを確認します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:05:32.797047Z",
     "iopub.status.busy": "2024-06-30T10:05:32.79666Z",
     "iopub.status.idle": "2024-06-30T10:05:32.804768Z",
     "shell.execute_reply": "2024-06-30T10:05:32.803647Z",
     "shell.execute_reply.started": "2024-06-30T10:05:32.797016Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各データセットの形状（行数と列数）を表示します\n",
    "train_data.shape, test_data.shape, submission_data.shape  # トレーニングデータ、テストデータ、および提出データのサイズを確認します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1332948",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "def trim_endings(custom_string):\n",
    "    return custom_string[:-2][2:]\n",
    "\n",
    "def count_newlines(custom_string):\n",
    "    return custom_string.count('\\\\n')\n",
    "\n",
    "def word_counts(custom_string):\n",
    "    return len(custom_string.split())\n",
    "\n",
    "\n",
    "def apply_transformations(df):\n",
    "    \n",
    "    df['prompt'] =  df['prompt'].map(process)\n",
    "    df['response_a'] =  df['response_a'].map(process)\n",
    "    df['response_b'] =  df['response_b'].map(process)\n",
    "    \n",
    "    df['prompt'] =  df['prompt'].map(trim_endings)\n",
    "    df['response_a'] =  df['response_a'].map(trim_endings)\n",
    "    df['response_b'] =  df['response_b'].map(trim_endings)\n",
    "    \n",
    "    df['res_a_line_count'] = df['response_a'].map(count_newlines).astype(str)\n",
    "    df['res_b_line_count'] = df['response_b'].map(count_newlines).astype(str)\n",
    "    \n",
    "    df['res_a_word_count'] = df['response_a'].map(word_counts).astype(str)\n",
    "    df['res_b_word_count'] = df['response_b'].map(word_counts).astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_summary(df):\n",
    "    df['summary'] = 'User prompt: ' + df['prompt'] +  '\\n\\n Model A :\\n' + df['response_a'] +'\\n\\n Model A length:\\n' + df['res_a_word_count'] +'\\n\\n Model A Line Count:\\n' + df['res_a_line_count'] +'\\n\\nModel B:\\n'  + df['response_b'] +'\\n\\n \\n\\nModel B length:\\n'  + df['res_b_word_count'] +'\\n\\n \\n\\nModel B Line Count:\\n'  + df['res_b_line_count']\n",
    "    return df\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def process(input_str):  # 入力文字列を処理する関数\n",
    "    stripped_str = input_str.strip('[]')  # 角括弧を削除します\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 各文を分離し、両端の引用符を削除します\n",
    "    return  ' '.join(sentences)  # 文をスペースで結合して返します\n",
    "\n",
    "def trim_endings(custom_string):  # 文字列の末尾をトリミングする関数\n",
    "    return custom_string[:-2][2:]  # 最後の2文字を削除し、最初の2文字を除去して返します\n",
    "\n",
    "def count_newlines(custom_string):  # 改行文字のカウントを行う関数\n",
    "    return custom_string.count('\\\\n')  # 文字列内の改行数を返します\n",
    "\n",
    "def word_counts(custom_string):  # 単語のカウントを行う関数\n",
    "    return len(custom_string.split())  # 文字列を単語に分割し、その数を返します\n",
    "\n",
    "\n",
    "def apply_transformations(df):  # データフレームに変換を適用する関数\n",
    "    \n",
    "    df['prompt'] =  df['prompt'].map(process)  # 'prompt'列にprocess関数を適用します\n",
    "    df['response_a'] =  df['response_a'].map(process)  # 'response_a'列にprocess関数を適用します\n",
    "    df['response_b'] =  df['response_b'].map(process)  # 'response_b'列にprocess関数を適用します\n",
    "    \n",
    "    df['prompt'] =  df['prompt'].map(trim_endings)  # 'prompt'列の末尾をトリミングします\n",
    "    df['response_a'] =  df['response_a'].map(trim_endings)  # 'response_a'列の末尾をトリミングします\n",
    "    df['response_b'] =  df['response_b'].map(trim_endings)  # 'response_b'列の末尾をトリミングします\n",
    "    \n",
    "    df['res_a_line_count'] = df['response_a'].map(count_newlines).astype(str)  # 'response_a'の改行数を計算し、新しい列に格納します\n",
    "    df['res_b_line_count'] = df['response_b'].map(count_newlines).astype(str)  # 'response_b'の改行数を計算し、新しい列に格納します\n",
    "    \n",
    "    df['res_a_word_count'] = df['response_a'].map(word_counts).astype(str)  # 'response_a'の単語数を計算し、新しい列に格納します\n",
    "    df['res_b_word_count'] = df['response_b'].map(word_counts).astype(str)  # 'response_b'の単語数を計算し、新しい列に格納します\n",
    "    \n",
    "    return df  # 変換後のデータフレームを返します\n",
    "\n",
    "def create_summary(df):  # サマリーを作成する関数\n",
    "    df['summary'] = 'User prompt: ' + df['prompt'] +  '\\n\\n Model A :\\n' + df['response_a'] +'\\n\\n Model A length:\\n' + df['res_a_word_count'] +'\\n\\n Model A Line Count:\\n' + df['res_a_line_count'] +'\\n\\nModel B:\\n'  + df['response_b'] +'\\n\\n \\n\\nModel B length:\\n'  + df['res_b_word_count'] +'\\n\\n \\n\\nModel B Line Count:\\n'  + df['res_b_line_count']\n",
    "    return df  # データフレームにサマリー列を追加して返します\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2db3e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = apply_transformations(train_data)\n",
    "train_data = create_summary(train_data)\n",
    "test_data = apply_transformations(test_data)    \n",
    "test_data = create_summary(test_data)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータに変換を適用し、サマリーを作成します\n",
    "train_data = apply_transformations(train_data)  # トレーニングデータに変換を適用します\n",
    "train_data = create_summary(train_data)  # トレーニングデータにサマリーを作成します\n",
    "\n",
    "# テストデータにも同様に変換を適用し、サマリーを作成します\n",
    "test_data = apply_transformations(test_data)  # テストデータに変換を適用します    \n",
    "test_data = create_summary(test_data)  # テストデータにサマリーを作成します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:05:40.281316Z",
     "iopub.status.busy": "2024-06-30T10:05:40.2804Z",
     "iopub.status.idle": "2024-06-30T10:05:43.420432Z",
     "shell.execute_reply": "2024-06-30T10:05:43.419516Z",
     "shell.execute_reply.started": "2024-06-30T10:05:40.28127Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータに変換を適用し、サマリーを作成します\n",
    "train_data = apply_transformations(train_data)  # トレーニングデータに変換を適用します\n",
    "train_data = create_summary(train_data)  # トレーニングデータにサマリーを作成します\n",
    "\n",
    "# テストデータにも同様に変換を適用し、サマリーを作成します\n",
    "test_data = apply_transformations(test_data)  # テストデータに変換を適用します    \n",
    "test_data = create_summary(test_data)  # テストデータにサマリーを作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c1994",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data['summary'][2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータのサマリー列の3番目の要素を表示します\n",
    "train_data['summary'][2]  # インデックス2のサマリーを取得して表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:05:44.365731Z",
     "iopub.status.busy": "2024-06-30T10:05:44.364877Z",
     "iopub.status.idle": "2024-06-30T10:05:44.371369Z",
     "shell.execute_reply": "2024-06-30T10:05:44.370456Z",
     "shell.execute_reply.started": "2024-06-30T10:05:44.365694Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータのサマリー列の3番目の要素を表示します\n",
    "train_data['summary'][2]  # インデックス2のサマリーを取得して表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5806aca1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data['labels'] = train_data[['winner_model_a','winner_model_b','winner_tie']].idxmax(axis=1)\n",
    "train_data['labels']=train_data['label'].astype('category')\n",
    "train_data['target']=train_data['label'].cat.codes\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータにラベル列を追加します。最高スコアのモデルを特定します\n",
    "train_data['labels'] = train_data[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)  # 各行で最大値を持つ列のインデックスを取得して'labels'列に格納します\n",
    "\n",
    "train_data['labels'] = train_data['labels'].astype('category')  # 'labels'列をカテゴリ型に変換します\n",
    "train_data['target'] = train_data['labels'].cat.codes  # 'labels'のカテゴリコードを' target'列に格納します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:04.487272Z",
     "iopub.status.busy": "2024-06-30T10:24:04.486415Z",
     "iopub.status.idle": "2024-06-30T10:24:04.513266Z",
     "shell.execute_reply": "2024-06-30T10:24:04.512224Z",
     "shell.execute_reply.started": "2024-06-30T10:24:04.487236Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータにラベル列を追加します。最高スコアのモデルを特定します\n",
    "train_data['labels'] = train_data[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)  # 各行で最大値を持つ列のインデックスを取得して'labels'列に格納します\n",
    "\n",
    "train_data['labels'] = train_data['labels'].astype('category')  # 'labels'列をカテゴリ型に変換します\n",
    "train_data['target'] = train_data['labels'].cat.codes  # 'labels'のカテゴリコードを' target'列に格納します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33baf84b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "category_map = {code: category for code, category in enumerate(train_data['labels'].cat.categories)}\n",
    "category_map\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 'labels'列のカテゴリに対するコードを作成します\n",
    "category_map = {code: category for code, category in enumerate(train_data['labels'].cat.categories)}  # 各カテゴリに対するコードを辞書形式で作成します\n",
    "category_map  # カテゴリマップを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:06.693799Z",
     "iopub.status.busy": "2024-06-30T10:24:06.692976Z",
     "iopub.status.idle": "2024-06-30T10:24:06.70254Z",
     "shell.execute_reply": "2024-06-30T10:24:06.701465Z",
     "shell.execute_reply.started": "2024-06-30T10:24:06.693764Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'labels'列のカテゴリに対するコードを作成します\n",
    "category_map = {code: category for code, category in enumerate(train_data['labels'].cat.categories)}  # 各カテゴリに対するコードを辞書形式で作成します\n",
    "category_map  # カテゴリマップを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0820dc86",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "SEED = 7920\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 再現性を持たせるためのランダムシードを設定します\n",
    "SEED = 7920  # シード値を7920に設定します。これにより、結果が一貫性を持つようになります\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:22:08.804678Z",
     "iopub.status.busy": "2024-06-30T10:22:08.803825Z",
     "iopub.status.idle": "2024-06-30T10:22:08.81028Z",
     "shell.execute_reply": "2024-06-30T10:22:08.808883Z",
     "shell.execute_reply.started": "2024-06-30T10:22:08.804647Z"
    }
   },
   "outputs": [],
   "source": [
    "# 再現性を持たせるためのランダムシードを設定します\n",
    "SEED = 7920  # シード値を7920に設定します。これにより、結果が一貫性を持つようになります"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7350fd41",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score\n",
    "train_df = train_data[['id','summary','target']]\n",
    "test_df = train_data[['id','summary']]\n",
    "\n",
    "df_train,df_val = train_test_split(train_df,test_size=0.2,random_state=SEED,stratify=train_df['target'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import make_classification  # データセットを生成するためのsklearnの関数をインポートします\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用と検証用に分割するための関数をインポートします\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰モデルをインポートします\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score  # 評価指標を計算するための関数をインポートします\n",
    "\n",
    "# 使用するカラムを選択してトレーニングデータとテストデータを準備します\n",
    "train_df = train_data[['id', 'summary', 'target']]  # トレーニングデータから'id', 'summary', 'target'を選択します\n",
    "test_df = train_data[['id', 'summary']]  # テストデータから'id'と'summary'を選択します\n",
    "\n",
    "# トレーニングデータを訓練セットと検証セットに分割します\n",
    "df_train, df_val = train_test_split(train_df, test_size=0.2, random_state=SEED, stratify=train_df['target'])  # 20%を検証データとして分割します。分類のバランスを保ちます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:10.554189Z",
     "iopub.status.busy": "2024-06-30T10:24:10.553265Z",
     "iopub.status.idle": "2024-06-30T10:24:10.604219Z",
     "shell.execute_reply": "2024-06-30T10:24:10.603135Z",
     "shell.execute_reply.started": "2024-06-30T10:24:10.554152Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification  # データセットを生成するためのsklearnの関数をインポートします\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用と検証用に分割するための関数をインポートします\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰モデルをインポートします\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, balanced_accuracy_score, accuracy_score  # 評価指標を計算するための関数をインポートします\n",
    "\n",
    "# 使用するカラムを選択してトレーニングデータとテストデータを準備します\n",
    "train_df = train_data[['id', 'summary', 'target']]  # トレーニングデータから'id', 'summary', 'target'を選択します\n",
    "test_df = train_data[['id', 'summary']]  # テストデータから'id'と'summary'を選択します\n",
    "\n",
    "# トレーニングデータを訓練セットと検証セットに分割します\n",
    "df_train, df_val = train_test_split(train_df, test_size=0.2, random_state=SEED, stratify=train_df['target'])  # 20%を検証データとして分割します。分類のバランスを保ちます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b0b62",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from datasets import Dataset, DatasetDict\n",
    "dataset_train = Dataset.from_pandas(df_train,preserve_index=False)\n",
    "dataset_val = Dataset.from_pandas(df_val,preserve_index=False)\n",
    "dataset_test = Dataset.from_pandas(test_df,preserve_index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from datasets import Dataset, DatasetDict  # datasetsモジュールからDatasetおよびDatasetDictをインポートします\n",
    "\n",
    "# PandasデータフレームからHugging FaceのDataset形式に変換します\n",
    "dataset_train = Dataset.from_pandas(df_train, preserve_index=False)  # トレーニングデータをDatasetに変換します（インデックスは保存しません）\n",
    "dataset_val = Dataset.from_pandas(df_val, preserve_index=False)  # 検証データをDatasetに変換します（インデックスは保存しません）\n",
    "dataset_test = Dataset.from_pandas(test_df, preserve_index=False)  # テストデータをDatasetに変換します（インデックスは保存しません）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:12.178932Z",
     "iopub.status.busy": "2024-06-30T10:24:12.178234Z",
     "iopub.status.idle": "2024-06-30T10:24:13.791462Z",
     "shell.execute_reply": "2024-06-30T10:24:13.790313Z",
     "shell.execute_reply.started": "2024-06-30T10:24:12.178896Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict  # datasetsモジュールからDatasetおよびDatasetDictをインポートします\n",
    "\n",
    "# PandasデータフレームからHugging FaceのDataset形式に変換します\n",
    "dataset_train = Dataset.from_pandas(df_train, preserve_index=False)  # トレーニングデータをDatasetに変換します（インデックスは保存しません）\n",
    "dataset_val = Dataset.from_pandas(df_val, preserve_index=False)  # 検証データをDatasetに変換します（インデックスは保存しません）\n",
    "dataset_test = Dataset.from_pandas(test_df, preserve_index=False)  # テストデータをDatasetに変換します（インデックスは保存しません）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85606e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    " dataset_train_shuffled = dataset_train.shuffle(seed=SEED)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータセットをシャッフルして、新しいデータセットを作成します\n",
    "dataset_train_shuffled = dataset_train.shuffle(seed=SEED)  # 指定したシードを使用してデータをランダムに並び替えます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:14.245859Z",
     "iopub.status.busy": "2024-06-30T10:24:14.24494Z",
     "iopub.status.idle": "2024-06-30T10:24:14.276496Z",
     "shell.execute_reply": "2024-06-30T10:24:14.275549Z",
     "shell.execute_reply.started": "2024-06-30T10:24:14.245823Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータセットをシャッフルして、新しいデータセットを作成します\n",
    "dataset_train_shuffled = dataset_train.shuffle(seed=SEED)  # 指定したシードを使用してデータをランダムに並び替えます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f20cd11",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "dataset = DatasetDict({\n",
    "    'train': dataset_train_shuffled,\n",
    "#     'val': dataset_val,\n",
    "#     'test': dataset_test\n",
    "})\n",
    "dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットを辞書形式でまとめて、トレーニング、検証、テストのデータセットを管理します\n",
    "dataset = DatasetDict({  # データセットの辞書を作成します\n",
    "    'train': dataset_train_shuffled,  # シャッフルしたトレーニングデータを追加します\n",
    "    # 'val': dataset_val,  # 検証データを追加します（コメントアウト中）\n",
    "    # 'test': dataset_test  # テストデータを追加します（コメントアウト中）\n",
    "})\n",
    "dataset  # 作成したデータセット辞書を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:14.74363Z",
     "iopub.status.busy": "2024-06-30T10:24:14.7427Z",
     "iopub.status.idle": "2024-06-30T10:24:14.752724Z",
     "shell.execute_reply": "2024-06-30T10:24:14.751038Z",
     "shell.execute_reply.started": "2024-06-30T10:24:14.743596Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットを辞書形式でまとめて、トレーニング、検証、テストのデータセットを管理します\n",
    "dataset = DatasetDict({  # データセットの辞書を作成します\n",
    "    'train': dataset_train_shuffled,  # シャッフルしたトレーニングデータを追加します\n",
    "    # 'val': dataset_val,  # 検証データを追加します（コメントアウト中）\n",
    "    # 'test': dataset_test  # テストデータを追加します（コメントアウト中）\n",
    "})\n",
    "dataset  # 作成したデータセット辞書を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facbb3a0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df_train.target.value_counts(normalize=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータの'target'列の値のカウントを正規化して表示します\n",
    "df_train.target.value_counts(normalize=True)  # 各クラスの割合を表示します。これにより、データのバランスを確認できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:16.289475Z",
     "iopub.status.busy": "2024-06-30T10:24:16.288626Z",
     "iopub.status.idle": "2024-06-30T10:24:16.300414Z",
     "shell.execute_reply": "2024-06-30T10:24:16.299274Z",
     "shell.execute_reply.started": "2024-06-30T10:24:16.289439Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの'target'列の値のカウントを正規化して表示します\n",
    "df_train.target.value_counts(normalize=True)  # 各クラスの割合を表示します。これにより、データのバランスを確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74be1b2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class_weights=(1/df_train.target.value_counts(normalize=True).sort_index()).tolist()\n",
    "class_weights=torch.tensor(class_weights)\n",
    "class_weights=class_weights/class_weights.sum()\n",
    "class_weights\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# クラスの重みを計算します。これにより、クラス間の不均衡を扱います\n",
    "class_weights = (1 / df_train.target.value_counts(normalize=True).sort_index()).tolist()  # 正規化されたターゲットの値を使って、それらの逆数を計算します\n",
    "class_weights = torch.tensor(class_weights)  # リストをPyTorchのテンソルに変換します\n",
    "class_weights = class_weights / class_weights.sum()  # 重みを合計で割って、正規化された重みにします\n",
    "class_weights  # 計算したクラス重みを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:18.146546Z",
     "iopub.status.busy": "2024-06-30T10:24:18.145661Z",
     "iopub.status.idle": "2024-06-30T10:24:18.157909Z",
     "shell.execute_reply": "2024-06-30T10:24:18.156933Z",
     "shell.execute_reply.started": "2024-06-30T10:24:18.146512Z"
    }
   },
   "outputs": [],
   "source": [
    "# クラスの重みを計算します。これにより、クラス間の不均衡を扱います\n",
    "class_weights = (1 / df_train.target.value_counts(normalize=True).sort_index()).tolist()  # 正規化されたターゲットの値を使って、それらの逆数を計算します\n",
    "class_weights = torch.tensor(class_weights)  # リストをPyTorchのテンソルに変換します\n",
    "class_weights = class_weights / class_weights.sum()  # 重みを合計で割って、正規化された重みにします\n",
    "class_weights  # 計算したクラス重みを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd2025f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    model_max_length=512,\n",
    "    padding_side=\"left\",\n",
    "    add_eos_token=True)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーを再度設定します。これによりトークン化が可能になります\n",
    "tokenizer = AutoTokenizer.from_pretrained(  # 基本モデルのトークナイザーを読み込みます\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    model_max_length=512,  # モデルの最大長を512トークンに設定します\n",
    "    padding_side=\"left\",  # パディングを左側に設定します\n",
    "    add_eos_token=True  # 終了トークンを追加する設定をします\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンを終了トークンに設定します\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:16:12.398089Z",
     "iopub.status.busy": "2024-06-30T10:16:12.397697Z",
     "iopub.status.idle": "2024-06-30T10:16:12.582641Z",
     "shell.execute_reply": "2024-06-30T10:16:12.581589Z",
     "shell.execute_reply.started": "2024-06-30T10:16:12.39806Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーを再度設定します。これによりトークン化が可能になります\n",
    "tokenizer = AutoTokenizer.from_pretrained(  # 基本モデルのトークナイザーを読み込みます\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    model_max_length=512,  # モデルの最大長を512トークンに設定します\n",
    "    padding_side=\"left\",  # パディングを左側に設定します\n",
    "    add_eos_token=True  # 終了トークンを追加する設定をします\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンを終了トークンに設定します\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f773337e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "MAX_LEN = 512\n",
    "col_to_delete = ['summary']\n",
    "\n",
    "def llama_preprocessing_function(examples):\n",
    "    return tokenizer(examples['summary'], truncation=True, max_length=MAX_LEN)\n",
    "\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "MAX_LEN = 512  # モデルの最大入力長を512トークンに設定します\n",
    "col_to_delete = ['summary']  # 削除する列のリストを定義します\n",
    "\n",
    "def llama_preprocessing_function(examples):  # データを前処理する関数を定義します\n",
    "    return tokenizer(examples['summary'], truncation=True, max_length=MAX_LEN)  # 'summary'カラムをトークン化し、長さを最大値でトランケーションします\n",
    "\n",
    "# データセット全体に前処理関数を適用し、バッチ処理を行い、不要な列を削除します\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "\n",
    "# 'target'列を'labels'列に名前を変更します\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "\n",
    "# データセットのフォーマットをPyTorch形式に設定します\n",
    "tokenized_datasets.set_format(\"torch\")  # トレーニング時にPyTorchが使用できる形式に設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:24:22.647924Z",
     "iopub.status.busy": "2024-06-30T10:24:22.647127Z",
     "iopub.status.idle": "2024-06-30T10:25:06.432728Z",
     "shell.execute_reply": "2024-06-30T10:25:06.431801Z",
     "shell.execute_reply.started": "2024-06-30T10:24:22.647888Z"
    }
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 512  # モデルの最大入力長を512トークンに設定します\n",
    "col_to_delete = ['summary']  # 削除する列のリストを定義します\n",
    "\n",
    "def llama_preprocessing_function(examples):  # データを前処理する関数を定義します\n",
    "    return tokenizer(examples['summary'], truncation=True, max_length=MAX_LEN)  # 'summary'カラムをトークン化し、長さを最大値でトランケーションします\n",
    "\n",
    "# データセット全体に前処理関数を適用し、バッチ処理を行い、不要な列を削除します\n",
    "tokenized_datasets = dataset.map(llama_preprocessing_function, batched=True, remove_columns=col_to_delete)\n",
    "\n",
    "# 'target'列を'labels'列に名前を変更します\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"target\", \"labels\")\n",
    "\n",
    "# データセットのフォーマットをPyTorch形式に設定します\n",
    "tokenized_datasets.set_format(\"torch\")  # トレーニング時にPyTorchが使用できる形式に設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b1ba8e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from peft import prepare_model_for_kbit_training  # PEFTからkビットトレーニング用のモデル準備関数をインポートします\n",
    "\n",
    "model.gradient_checkpointing_enable()  # 勾配チェックポイントを有効にして、メモリを節約します\n",
    "model = prepare_model_for_kbit_training(model)  # モデルをkビットトレーニング用に準備します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:12.033837Z",
     "iopub.status.busy": "2024-06-30T10:18:12.033061Z",
     "iopub.status.idle": "2024-06-30T10:18:12.092712Z",
     "shell.execute_reply": "2024-06-30T10:18:12.091596Z",
     "shell.execute_reply.started": "2024-06-30T10:18:12.033806Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training  # PEFTからkビットトレーニング用のモデル準備関数をインポートします\n",
    "\n",
    "model.gradient_checkpointing_enable()  # 勾配チェックポイントを有効にして、メモリを節約します\n",
    "model = prepare_model_for_kbit_training(model)  # モデルをkビットトレーニング用に準備します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7a5d51",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def print_trainable_parameters(model):  # モデルのトレーニング可能なパラメータを表示する関数\n",
    "    \"\"\"\n",
    "    モデル内のトレーニング可能なパラメータの数を表示します。\n",
    "    \"\"\"\n",
    "    trainable_params = 0  # トレーニング可能なパラメータの初期化\n",
    "    all_param = 0  # すべてのパラメータの初期化\n",
    "    for _, param in model.named_parameters():  # モデル内のすべてのパラメータをループします\n",
    "        all_param += param.numel()  # 総パラメータ数を計算します\n",
    "        if param.requires_grad:  # パラメータが勾配計算を必要とする場合\n",
    "            trainable_params += param.numel()  # トレーニング可能なパラメータ数を累積します\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )  # トレーニング可能なパラメータ数、すべてのパラメータ数、トレーニング可能なパラメータの割合を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:12.740827Z",
     "iopub.status.busy": "2024-06-30T10:18:12.740447Z",
     "iopub.status.idle": "2024-06-30T10:18:12.750671Z",
     "shell.execute_reply": "2024-06-30T10:18:12.749196Z",
     "shell.execute_reply.started": "2024-06-30T10:18:12.740796Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_trainable_parameters(model):  # モデルのトレーニング可能なパラメータを表示する関数\n",
    "    \"\"\"\n",
    "    モデル内のトレーニング可能なパラメータの数を表示します。\n",
    "    \"\"\"\n",
    "    trainable_params = 0  # トレーニング可能なパラメータの初期化\n",
    "    all_param = 0  # すべてのパラメータの初期化\n",
    "    for _, param in model.named_parameters():  # モデル内のすべてのパラメータをループします\n",
    "        all_param += param.numel()  # 総パラメータ数を計算します\n",
    "        if param.requires_grad:  # パラメータが勾配計算を必要とする場合\n",
    "            trainable_params += param.numel()  # トレーニング可能なパラメータ数を累積します\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )  # トレーニング可能なパラメータ数、すべてのパラメータ数、トレーニング可能なパラメータの割合を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad3c35",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(model)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの詳細を表示します\n",
    "print(model)  # モデルの構造とパラメータの詳細を出力します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:17.312999Z",
     "iopub.status.busy": "2024-06-30T10:18:17.312075Z",
     "iopub.status.idle": "2024-06-30T10:18:17.336991Z",
     "shell.execute_reply": "2024-06-30T10:18:17.336114Z",
     "shell.execute_reply.started": "2024-06-30T10:18:17.312964Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの詳細を表示します\n",
    "print(model)  # モデルの構造とパラメータの詳細を出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5979e8ea",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator  # Accelerateライブラリから関連するクラスをインポートします\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig  # FSDPのための設定クラスをインポートします\n",
    "\n",
    "# Fully Sharded Data Parallelプラグインを設定します\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),  # チェックポイントをCPUにオフロードする設定\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),  # 最適化ステート情報もCPUにオフロードする設定\n",
    ")\n",
    "\n",
    "# Acceleratorインスタンスを作成します\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)  # FSDPプラグインを使用してAcceleratorを初期化します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:21.348412Z",
     "iopub.status.busy": "2024-06-30T10:18:21.3477Z",
     "iopub.status.idle": "2024-06-30T10:18:21.359511Z",
     "shell.execute_reply": "2024-06-30T10:18:21.358311Z",
     "shell.execute_reply.started": "2024-06-30T10:18:21.348375Z"
    }
   },
   "outputs": [],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator  # Accelerateライブラリから関連するクラスをインポートします\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig  # FSDPのための設定クラスをインポートします\n",
    "\n",
    "# Fully Sharded Data Parallelプラグインを設定します\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),  # チェックポイントをCPUにオフロードする設定\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),  # 最適化ステート情報もCPUにオフロードする設定\n",
    ")\n",
    "\n",
    "# Acceleratorインスタンスを作成します\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)  # FSDPプラグインを使用してAcceleratorを初期化します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c35ea3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.05,  # Conventional\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "print_trainable_parameters(model)\n",
    "\n",
    "# Apply the accelerator. You can comment this out to remove the accelerator.\n",
    "model = accelerator.prepare_model(model)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from peft import LoraConfig, get_peft_model  # PEFTライブラリからLoraConfigとモデル取得関数をインポートします\n",
    "\n",
    "# LoRAの設定を定義します\n",
    "config = LoraConfig(\n",
    "    r=8,  # rankの値\n",
    "    lora_alpha=16,  # LoRAのスケーリングファクター\n",
    "    target_modules=[  # 対象モジュールのリスト\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",  # バイアスの設定\n",
    "    lora_dropout=0.05,  # LoRAのドロップアウト率\n",
    "    task_type=\"CAUSAL_LM\",  # タスクタイプを指定します（因果言語モデル）\n",
    ")\n",
    "\n",
    "# モデルにLoRA設定を適用します\n",
    "model = get_peft_model(model, config)  # LoRAの設定を持つモデルを取得します\n",
    "print_trainable_parameters(model)  # トレーニング可能なパラメータを表示します\n",
    "\n",
    "# アクセラレーターを適用します。必要に応じてコメントアウトできます。\n",
    "model = accelerator.prepare_model(model)  # Accelerateを使用してモデルを準備します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:21.751883Z",
     "iopub.status.busy": "2024-06-30T10:18:21.751248Z",
     "iopub.status.idle": "2024-06-30T10:18:22.37163Z",
     "shell.execute_reply": "2024-06-30T10:18:22.37053Z",
     "shell.execute_reply.started": "2024-06-30T10:18:21.751849Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model  # PEFTライブラリからLoraConfigとモデル取得関数をインポートします\n",
    "\n",
    "# LoRAの設定を定義します\n",
    "config = LoraConfig(\n",
    "    r=8,  # rankの値\n",
    "    lora_alpha=16,  # LoRAのスケーリングファクター\n",
    "    target_modules=[  # 対象モジュールのリスト\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "        \"gate_proj\",\n",
    "        \"up_proj\",\n",
    "        \"down_proj\",\n",
    "        \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",  # バイアスの設定\n",
    "    lora_dropout=0.05,  # LoRAのドロップアウト率\n",
    "    task_type=\"CAUSAL_LM\",  # タスクタイプを指定します（因果言語モデル）\n",
    ")\n",
    "\n",
    "# モデルにLoRA設定を適用します\n",
    "model = get_peft_model(model, config)  # LoRAの設定を持つモデルを取得します\n",
    "print_trainable_parameters(model)  # トレーニング可能なパラメータを表示します\n",
    "\n",
    "# アクセラレーターを適用します。必要に応じてコメントアウトできます。\n",
    "model = accelerator.prepare_model(model)  # Accelerateを使用してモデルを準備します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6a4701",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q wandb -U\n",
    "\n",
    "import wandb, os\n",
    "wandb.login()\n",
    "\n",
    "wandb_project = \"mistral-finetune\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Weights & Biases（WandB）ライブラリをインストールします\n",
    "!pip install -q wandb -U  # WandBをアップグレードします\n",
    "\n",
    "import wandb, os  # WandBとOSモジュールをインポートします\n",
    "wandb.login()  # WandBにログインします\n",
    "\n",
    "wandb_project = \"mistral-finetune\"  # プロジェクト名を設定します\n",
    "if len(wandb_project) > 0:  # プロジェクト名が空でない場合\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project  # 環境変数にプロジェクト名を設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:18:59.252077Z",
     "iopub.status.busy": "2024-06-30T10:18:59.251685Z",
     "iopub.status.idle": "2024-06-30T10:19:09.470832Z",
     "shell.execute_reply": "2024-06-30T10:19:09.469719Z",
     "shell.execute_reply.started": "2024-06-30T10:18:59.252046Z"
    }
   },
   "outputs": [],
   "source": [
    "# Weights & Biases（WandB）ライブラリをインストールします\n",
    "!pip install -q wandb -U  # WandBをアップグレードします\n",
    "\n",
    "import wandb, os  # WandBとOSモジュールをインポートします\n",
    "wandb.login()  # WandBにログインします\n",
    "\n",
    "wandb_project = \"mistral-finetune\"  # プロジェクト名を設定します\n",
    "if len(wandb_project) > 0:  # プロジェクト名が空でない場合\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project  # 環境変数にプロジェクト名を設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c067f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPUの数が1つより多い場合の処理を行います\n",
    "if torch.cuda.device_count() > 1:  # 使用可能なGPUが1つ以上の場合\n",
    "    model.is_parallelizable = True  # モデルが並列化可能であることを指定します\n",
    "    model.model_parallel = True  # モデル並列を有効にします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:19:12.502929Z",
     "iopub.status.busy": "2024-06-30T10:19:12.502066Z",
     "iopub.status.idle": "2024-06-30T10:19:12.512449Z",
     "shell.execute_reply": "2024-06-30T10:19:12.511432Z",
     "shell.execute_reply.started": "2024-06-30T10:19:12.502887Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPUの数が1つより多い場合の処理を行います\n",
    "if torch.cuda.device_count() > 1:  # 使用可能なGPUが1つ以上の場合\n",
    "    model.is_parallelizable = True  # モデルが並列化可能であることを指定します\n",
    "    model.model_parallel = True  # モデル並列を有効にします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e8ed3c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!nvcc --version\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch==2.0.0+cu121 torchvision==0.15.0+cu121 torchaudio==2.0.0+cu121 -f https://download.pytorch.org/whl/nightly/cu121/torch_nightly.html\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# NVIDIAのCUDAコンパイラのバージョンを表示します\n",
    "!nvcc --version  # nvccのバージョン情報を表示します\n",
    "\n",
    "# 古いバージョンのPyTorch関連ライブラリをアンインストールします\n",
    "!pip uninstall torch torchvision torchaudio -y  # PyTorch、TorchVision、およびTorchAudioを強制的にアンインストールします\n",
    "\n",
    "# CUDA 12.1対応の指定バージョンのPyTorch関連ライブラリをインストールします\n",
    "!pip install torch==2.0.0+cu121 torchvision==0.15.0+cu121 torchaudio==2.0.0+cu121 -f https://download.pytorch.org/whl/nightly/cu121/torch_nightly.html  # PyTorchの特定バージョンをインストールします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:28:25.804874Z",
     "iopub.status.busy": "2024-06-30T10:28:25.803904Z",
     "iopub.status.idle": "2024-06-30T10:28:50.744939Z",
     "shell.execute_reply": "2024-06-30T10:28:50.743611Z",
     "shell.execute_reply.started": "2024-06-30T10:28:25.804832Z"
    }
   },
   "outputs": [],
   "source": [
    "# NVIDIAのCUDAコンパイラのバージョンを表示します\n",
    "!nvcc --version  # nvccのバージョン情報を表示します\n",
    "\n",
    "# 古いバージョンのPyTorch関連ライブラリをアンインストールします\n",
    "!pip uninstall torch torchvision torchaudio -y  # PyTorch、TorchVision、およびTorchAudioを強制的にアンインストールします\n",
    "\n",
    "# CUDA 12.1対応の指定バージョンのPyTorch関連ライブラリをインストールします\n",
    "!pip install torch==2.0.0+cu121 torchvision==0.15.0+cu121 torchaudio==2.0.0+cu121 -f https://download.pytorch.org/whl/nightly/cu121/torch_nightly.html  # PyTorchの特定バージョンをインストールします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6bebc2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Uninstall existing versions of torch, torchvision, and torchaudio\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# Install compatible versions with CUDA 11.2 support\n",
    "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu112/torch_stable.html\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 既存のtorch、torchvision、torchaudioのバージョンをアンインストールします\n",
    "!pip uninstall torch torchvision torchaudio -y  # PyTorch、TorchVision、およびTorchAudioを強制的にアンインストールします\n",
    "\n",
    "# CUDA 11.2に対応した互換性のあるバージョンをインストールします\n",
    "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu112/torch_stable.html  # PyTorchの安定したバージョンをインストールします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:29:18.230437Z",
     "iopub.status.busy": "2024-06-30T10:29:18.230016Z",
     "iopub.status.idle": "2024-06-30T10:31:31.423457Z",
     "shell.execute_reply": "2024-06-30T10:31:31.422192Z",
     "shell.execute_reply.started": "2024-06-30T10:29:18.230402Z"
    }
   },
   "outputs": [],
   "source": [
    "# 既存のtorch、torchvision、torchaudioのバージョンをアンインストールします\n",
    "!pip uninstall torch torchvision torchaudio -y  # PyTorch、TorchVision、およびTorchAudioを強制的にアンインストールします\n",
    "\n",
    "# CUDA 11.2に対応した互換性のあるバージョンをインストールします\n",
    "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu112/torch_stable.html  # PyTorchの安定したバージョンをインストールします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e237c417",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os  # OSモジュールをインポートします\n",
    "\n",
    "# CUDAの起動ブロッキングを無効にします\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # CUDAカーネルの起動時にブロッキングを無効にします。これにより、実行時のパフォーマンスが向上する可能性があります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:37:10.710967Z",
     "iopub.status.busy": "2024-06-30T10:37:10.710194Z",
     "iopub.status.idle": "2024-06-30T10:37:10.719709Z",
     "shell.execute_reply": "2024-06-30T10:37:10.718053Z",
     "shell.execute_reply.started": "2024-06-30T10:37:10.71093Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # OSモジュールをインポートします\n",
    "\n",
    "# CUDAの起動ブロッキングを無効にします\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # CUDAカーネルの起動時にブロッキングを無効にします。これにより、実行時のパフォーマンスが向上する可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be97486b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch\n",
    "\n",
    "seed = 7920  # Replace with your desired seed\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    generator = torch.Generator(device='cuda').manual_seed(seed)\n",
    "else:\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "\n",
    "seed = 7920  # 使用するシード値を設定します\n",
    "\n",
    "# CUDAが使用可能であれば、CUDAデバイス用の乱数生成器を設定します\n",
    "if torch.cuda.is_available():\n",
    "    generator = torch.Generator(device='cuda').manual_seed(seed)  # CUDAデバイス用にシードを設定します\n",
    "else:\n",
    "    generator = torch.Generator().manual_seed(seed)  # CPU用にシードを設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:56:06.912496Z",
     "iopub.status.busy": "2024-06-30T10:56:06.911774Z",
     "iopub.status.idle": "2024-06-30T10:56:06.917517Z",
     "shell.execute_reply": "2024-06-30T10:56:06.916595Z",
     "shell.execute_reply.started": "2024-06-30T10:56:06.912463Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorchライブラリをインポートします\n",
    "\n",
    "seed = 7920  # 使用するシード値を設定します\n",
    "\n",
    "# CUDAが使用可能であれば、CUDAデバイス用の乱数生成器を設定します\n",
    "if torch.cuda.is_available():\n",
    "    generator = torch.Generator(device='cuda').manual_seed(seed)  # CUDAデバイス用にシードを設定します\n",
    "else:\n",
    "    generator = torch.Generator().manual_seed(seed)  # CPU用にシードを設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f409197e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if torch.cuda.is_available():\n",
    "  generator = torch.Generator('cuda').manual_seed(seed)\n",
    "else:\n",
    "  generator = torch.Generator().manual_seed(seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# CUDAが利用可能であれば、CUDAデバイス用の乱数生成器を設定します\n",
    "if torch.cuda.is_available():  \n",
    "    generator = torch.Generator('cuda').manual_seed(seed)  # CUDAデバイスの乱数生成器をシードで初期化します\n",
    "else:\n",
    "    generator = torch.Generator().manual_seed(seed)  # CPU用の乱数生成器をシードで初期化します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:37:12.02127Z",
     "iopub.status.busy": "2024-06-30T10:37:12.020896Z",
     "iopub.status.idle": "2024-06-30T10:37:12.074962Z",
     "shell.execute_reply": "2024-06-30T10:37:12.073402Z",
     "shell.execute_reply.started": "2024-06-30T10:37:12.021241Z"
    }
   },
   "outputs": [],
   "source": [
    "# CUDAが利用可能であれば、CUDAデバイス用の乱数生成器を設定します\n",
    "if torch.cuda.is_available():  \n",
    "    generator = torch.Generator('cuda').manual_seed(seed)  # CUDAデバイスの乱数生成器をシードで初期化します\n",
    "else:\n",
    "    generator = torch.Generator().manual_seed(seed)  # CPU用の乱数生成器をシードで初期化します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae1118",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import transformers\n",
    "class CustomTrainer(transformers.Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # Ensure label_weights is a tensor\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        # Extract labels and convert them to long type for cross_entropy\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Extract logits assuming they are directly outputted by the model\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        # Compute custom loss with class weights for imbalanced data handling\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import transformers  # Transformersライブラリをインポートします\n",
    "\n",
    "class CustomTrainer(transformers.Trainer):  # Trainerクラスを継承したカスタムトレーナークラスを定義します\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):  # コンストラクタを定義します\n",
    "        super().__init__(*args, **kwargs)  # 親クラスのコンストラクタを呼び出します\n",
    "        # クラス重みが与えられた場合、テンソルに変換します\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)  # クラス重みをデバイスに移動します\n",
    "        else:\n",
    "            self.class_weights = None  # クラス重みがない場合はNoneとします\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):  # 損失を計算する関数を定義します\n",
    "        # ラベルを抽出し、cross_entropy用にlong型に変換します\n",
    "        labels = inputs.pop(\"labels\").long()  # 入力からラベルを取り出します\n",
    "\n",
    "        # フォワードパス\n",
    "        outputs = model(**inputs)  # モデルを介して入力を処理します\n",
    "\n",
    "        # 出力されたロジットを抽出します\n",
    "        logits = outputs.get('logits')  # モデル出力からロジットを取り出します\n",
    "\n",
    "        # 不均衡データ処理のためのクラス重みを用いたカスタム損失を計算します\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)  # クラス重みを使った損失計算\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)  # クラス重みなしで損失計算\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss  # 出力の条件に応じて損失と出力を返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:38:52.877824Z",
     "iopub.status.busy": "2024-06-30T10:38:52.877466Z",
     "iopub.status.idle": "2024-06-30T10:38:52.888061Z",
     "shell.execute_reply": "2024-06-30T10:38:52.886773Z",
     "shell.execute_reply.started": "2024-06-30T10:38:52.877799Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers  # Transformersライブラリをインポートします\n",
    "\n",
    "class CustomTrainer(transformers.Trainer):  # Trainerクラスを継承したカスタムトレーナークラスを定義します\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):  # コンストラクタを定義します\n",
    "        super().__init__(*args, **kwargs)  # 親クラスのコンストラクタを呼び出します\n",
    "        # クラス重みが与えられた場合、テンソルに変換します\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)  # クラス重みをデバイスに移動します\n",
    "        else:\n",
    "            self.class_weights = None  # クラス重みがない場合はNoneとします\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):  # 損失を計算する関数を定義します\n",
    "        # ラベルを抽出し、cross_entropy用にlong型に変換します\n",
    "        labels = inputs.pop(\"labels\").long()  # 入力からラベルを取り出します\n",
    "\n",
    "        # フォワードパス\n",
    "        outputs = model(**inputs)  # モデルを介して入力を処理します\n",
    "\n",
    "        # 出力されたロジットを抽出します\n",
    "        logits = outputs.get('logits')  # モデル出力からロジットを取り出します\n",
    "\n",
    "        # 不均衡データ処理のためのクラス重みを用いたカスタム損失を計算します\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)  # クラス重みを使った損失計算\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)  # クラス重みなしで損失計算\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss  # 出力の条件に応じて損失と出力を返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c6ea55",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),'accuracy':accuracy_score(predictions,labels)}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_pred):  # 評価予測をもとにメトリクスを計算する関数を定義します\n",
    "    predictions, labels = eval_pred  # 評価予測から予測値とラベルを取得します\n",
    "    predictions = np.argmax(predictions, axis=1)  # 予測の中で最大値のインデックスを取得してクラスラベルを決定します\n",
    "    # 精度とバランス精度を計算して返します\n",
    "    return {\n",
    "        'balanced_accuracy': balanced_accuracy_score(predictions, labels),  # バランス精度を計算します\n",
    "        'accuracy': accuracy_score(predictions, labels)  # 純粋な精度を計算します\n",
    "    }\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:40:42.940778Z",
     "iopub.status.busy": "2024-06-30T10:40:42.939862Z",
     "iopub.status.idle": "2024-06-30T10:40:42.947877Z",
     "shell.execute_reply": "2024-06-30T10:40:42.946591Z",
     "shell.execute_reply.started": "2024-06-30T10:40:42.940728Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):  # 評価予測をもとにメトリクスを計算する関数を定義します\n",
    "    predictions, labels = eval_pred  # 評価予測から予測値とラベルを取得します\n",
    "    predictions = np.argmax(predictions, axis=1)  # 予測の中で最大値のインデックスを取得してクラスラベルを決定します\n",
    "    # 精度とバランス精度を計算して返します\n",
    "    return {\n",
    "        'balanced_accuracy': balanced_accuracy_score(predictions, labels),  # バランス精度を計算します\n",
    "        'accuracy': accuracy_score(predictions, labels)  # 純粋な精度を計算します\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ad7272",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir = 'model_classification',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 1,\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "\tlogging_steps=10,\n",
    "\tmax_steps=100,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングに関する引数を設定します\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir='model_classification',  # モデルの出力先ディレクトリ\n",
    "    learning_rate=1e-4,  # 学習率\n",
    "    per_device_train_batch_size=8,  # デバイスごとのトレーニングバッチサイズ\n",
    "    per_device_eval_batch_size=8,  # デバイスごとの評価バッチサイズ\n",
    "    num_train_epochs=1,  # トレーニングエポック数\n",
    "    weight_decay=0.01,  # 重み減衰率\n",
    "    evaluation_strategy='epoch',  # 評価戦略をエポック単位に設定\n",
    "    save_strategy='epoch',  # モデルの保存戦略をエポック単位に設定\n",
    "    load_best_model_at_end=True,  # 最良のモデルを最後にロード\n",
    "\tlogging_steps=10,  # ロギングの頻度\n",
    "\tmax_steps=100,  # 最大ステップ数\n",
    "    fp16=True,  # 16ビット浮動小数点でトレーニングを実行\n",
    "    push_to_hub=False  # モデルをHugging Face Hubにプッシュしない設定\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:40:47.846323Z",
     "iopub.status.busy": "2024-06-30T10:40:47.845447Z",
     "iopub.status.idle": "2024-06-30T10:40:47.88476Z",
     "shell.execute_reply": "2024-06-30T10:40:47.883933Z",
     "shell.execute_reply.started": "2024-06-30T10:40:47.846288Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングに関する引数を設定します\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir='model_classification',  # モデルの出力先ディレクトリ\n",
    "    learning_rate=1e-4,  # 学習率\n",
    "    per_device_train_batch_size=8,  # デバイスごとのトレーニングバッチサイズ\n",
    "    per_device_eval_batch_size=8,  # デバイスごとの評価バッチサイズ\n",
    "    num_train_epochs=1,  # トレーニングエポック数\n",
    "    weight_decay=0.01,  # 重み減衰率\n",
    "    evaluation_strategy='epoch',  # 評価戦略をエポック単位に設定\n",
    "    save_strategy='epoch',  # モデルの保存戦略をエポック単位に設定\n",
    "    load_best_model_at_end=True,  # 最良のモデルを最後にロード\n",
    "\tlogging_steps=10,  # ロギングの頻度\n",
    "\tmax_steps=100,  # 最大ステップ数\n",
    "    fp16=True,  # 16ビット浮動小数点でトレーニングを実行\n",
    "    push_to_hub=False  # モデルをHugging Face Hubにプッシュしない設定\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d12586a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "collate_fn = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データのコラテーションを行うための関数を設定します\n",
    "collate_fn = transformers.DataCollatorWithPadding(tokenizer=tokenizer)  # トークナイザーを用いてパディング付きのデータコレータを作成します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:40:48.844753Z",
     "iopub.status.busy": "2024-06-30T10:40:48.844362Z",
     "iopub.status.idle": "2024-06-30T10:40:48.852048Z",
     "shell.execute_reply": "2024-06-30T10:40:48.850644Z",
     "shell.execute_reply.started": "2024-06-30T10:40:48.84471Z"
    }
   },
   "outputs": [],
   "source": [
    "# データのコラテーションを行うための関数を設定します\n",
    "collate_fn = transformers.DataCollatorWithPadding(tokenizer=tokenizer)  # トークナイザーを用いてパディング付きのデータコレータを作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c860976",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets['train'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "    class_weights=class_weights,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# カスタムトレーナーのインスタンスを作成します\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  # 使用するモデル\n",
    "    args=training_args,  # トレーニング引数\n",
    "    train_dataset=tokenized_datasets['train'],  # トレーニングデータセット\n",
    "    tokenizer=tokenizer,  # トークナイザー\n",
    "    data_collator=collate_fn,  # データコレータ\n",
    "    compute_metrics=compute_metrics,  # メトリクス計算関数\n",
    "    class_weights=class_weights,  # クラス重み\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:42:16.536193Z",
     "iopub.status.busy": "2024-06-30T10:42:16.535812Z",
     "iopub.status.idle": "2024-06-30T10:42:16.72858Z",
     "shell.execute_reply": "2024-06-30T10:42:16.727087Z",
     "shell.execute_reply.started": "2024-06-30T10:42:16.536164Z"
    }
   },
   "outputs": [],
   "source": [
    "# カスタムトレーナーのインスタンスを作成します\n",
    "trainer = CustomTrainer(\n",
    "    model=model,  # 使用するモデル\n",
    "    args=training_args,  # トレーニング引数\n",
    "    train_dataset=tokenized_datasets['train'],  # トレーニングデータセット\n",
    "    tokenizer=tokenizer,  # トークナイザー\n",
    "    data_collator=collate_fn,  # データコレータ\n",
    "    compute_metrics=compute_metrics,  # メトリクス計算関数\n",
    "    class_weights=class_weights,  # クラス重み\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1a177a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install torch\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# PyTorchライブラリをインストールします\n",
    "!pip install torch  # 最新のPyTorchをインストールします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:42:34.528039Z",
     "iopub.status.busy": "2024-06-30T10:42:34.527638Z",
     "iopub.status.idle": "2024-06-30T10:42:47.820535Z",
     "shell.execute_reply": "2024-06-30T10:42:47.81924Z",
     "shell.execute_reply.started": "2024-06-30T10:42:34.528008Z"
    }
   },
   "outputs": [],
   "source": [
    "# PyTorchライブラリをインストールします\n",
    "!pip install torch  # 最新のPyTorchをインストールします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ee6f0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import transformers\n",
    "from datetime import datetime\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "project = \"mistral-finetune\"\n",
    "base_model_name = \"mistral\"\n",
    "run_name = base_model_name + \"-\" + project\n",
    "output_dir = \"./\" + run_name\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        warmup_steps=5,\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_checkpointing=True,\n",
    "        gradient_accumulation_steps=4,\n",
    "        max_steps=1000,\n",
    "        learning_rate=2.5e-5, # Want about 10x smaller than the Mistral learning rate\n",
    "        logging_steps=50,\n",
    "        fp16=False,\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        logging_dir=\"./logs\",        # Directory for storing logs\n",
    "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
    "        save_steps=50,                # Save checkpoints every 50 steps\n",
    "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
    "        eval_steps=50,               # Evaluate and save checkpoints every 50 steps\n",
    "        do_eval=True,                # Perform evaluation at the end of training\n",
    "        report_to=\"wandb\",           # Comment this out if you don't want to use weights & baises\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import transformers  # Transformersライブラリをインポートします\n",
    "from datetime import datetime  # 日付時刻を扱うためのライブラリをインポートします\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # CUDAカーネルの起動をブロッキングします\n",
    "\n",
    "# CUDAの利用可能性を確認します\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())  # CUDAが使用可能かどうかを表示します\n",
    "project = \"mistral-finetune\"  # プロジェクト名を設定します\n",
    "base_model_name = \"mistral\"  # 基本モデル名を設定します\n",
    "run_name = base_model_name + \"-\" + project  # 実行名を設定します\n",
    "output_dir = \"./\" + run_name  # 出力ディレクトリを設定します\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンに設定します\n",
    "\n",
    "# Trainerインスタンスを作成します\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,  # 使用するモデル\n",
    "    train_dataset=tokenized_datasets['train'],  # トレーニングデータセット\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,  # 出力ディレクトリ\n",
    "        warmup_steps=5,  # ウォームアップステップ数\n",
    "        per_device_train_batch_size=2,  # デバイスごとのトレーニングバッチサイズ\n",
    "        gradient_checkpointing=True,  # 勾配チェックポイントを有効にします\n",
    "        gradient_accumulation_steps=4,  # 勾配蓄積ステップ数\n",
    "        max_steps=1000,  # 最大ステップ数\n",
    "        learning_rate=2.5e-5,  # 学習率\n",
    "        logging_steps=50,  # ロギングの頻度\n",
    "        fp16=False,  # 16ビット浮動小数点を無効にします\n",
    "        optim=\"paged_adamw_8bit\",  # 最適化手法を指定します\n",
    "        logging_dir=\"./logs\",  # ログの保存先ディレクトリ\n",
    "        save_strategy=\"steps\",  # ステップごとにモデルチェックポイントを保存\n",
    "        save_steps=50,  # 50ステップごとにチェックポイントを保存\n",
    "        evaluation_strategy=\"steps\",  # ステップごとに評価\n",
    "        eval_steps=50,  # 50ステップごとに評価しチェックポイントを保存\n",
    "        do_eval=True,  # トレーニングの終了時に評価を実行\n",
    "        report_to=\"wandb\",  # Weights & Biasesにレポートするかどうか\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",  # W&Bランの名前の設定\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),  # 言語モデル用のデータコラレータを設定\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # 警告を抑制します。推論時には再度有効にしてください\n",
    "trainer.train()  # トレーニングを開始します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-30T10:42:47.823897Z",
     "iopub.status.busy": "2024-06-30T10:42:47.823352Z",
     "iopub.status.idle": "2024-06-30T10:42:48.063002Z",
     "shell.execute_reply": "2024-06-30T10:42:48.060733Z",
     "shell.execute_reply.started": "2024-06-30T10:42:47.823843Z"
    }
   },
   "outputs": [],
   "source": [
    "import transformers  # Transformersライブラリをインポートします\n",
    "from datetime import datetime  # 日付時刻を扱うためのライブラリをインポートします\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # CUDAカーネルの起動をブロッキングします\n",
    "\n",
    "# CUDAの利用可能性を確認します\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())  # CUDAが使用可能かどうかを表示します\n",
    "project = \"mistral-finetune\"  # プロジェクト名を設定します\n",
    "base_model_name = \"mistral\"  # 基本モデル名を設定します\n",
    "run_name = base_model_name + \"-\" + project  # 実行名を設定します\n",
    "output_dir = \"./\" + run_name  # 出力ディレクトリを設定します\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンに設定します\n",
    "\n",
    "# Trainerインスタンスを作成します\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,  # 使用するモデル\n",
    "    train_dataset=tokenized_datasets['train'],  # トレーニングデータセット\n",
    "    args=transformers.TrainingArguments(\n",
    "        output_dir=output_dir,  # 出力ディレクトリ\n",
    "        warmup_steps=5,  # ウォームアップステップ数\n",
    "        per_device_train_batch_size=2,  # デバイスごとのトレーニングバッチサイズ\n",
    "        gradient_checkpointing=True,  # 勾配チェックポイントを有効にします\n",
    "        gradient_accumulation_steps=4,  # 勾配蓄積ステップ数\n",
    "        max_steps=1000,  # 最大ステップ数\n",
    "        learning_rate=2.5e-5,  # 学習率\n",
    "        logging_steps=50,  # ロギングの頻度\n",
    "        fp16=False,  # 16ビット浮動小数点を無効にします\n",
    "        optim=\"paged_adamw_8bit\",  # 最適化手法を指定します\n",
    "        logging_dir=\"./logs\",  # ログの保存先ディレクトリ\n",
    "        save_strategy=\"steps\",  # ステップごとにモデルチェックポイントを保存\n",
    "        save_steps=50,  # 50ステップごとにチェックポイントを保存\n",
    "        evaluation_strategy=\"steps\",  # ステップごとに評価\n",
    "        eval_steps=50,  # 50ステップごとに評価しチェックポイントを保存\n",
    "        do_eval=True,  # トレーニングの終了時に評価を実行\n",
    "        report_to=\"wandb\",  # Weights & Biasesにレポートするかどうか\n",
    "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\",  # W&Bランの名前の設定\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),  # 言語モデル用のデータコラレータを設定\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # 警告を抑制します。推論時には再度有効にしてください\n",
    "trainer.train()  # トレーニングを開始します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebf374c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,\n",
    "    add_bos_token=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  # 必要なクラスをインポートします\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"  # 使用する基本モデルのIDを指定します\n",
    "bnb_config = BitsAndBytesConfig(  # 量子化に関する設定を作成します\n",
    "    load_in_4bit=True,  # 4ビットでモデルを読み込む設定\n",
    "    bnb_4bit_use_double_quant=True,  # 2重量子化を使用する設定\n",
    "    bnb_4bit_quant_type=\"nf4\",  # 量子化のタイプを指定します（nf4）\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 計算データ型をbfloat16に設定\n",
    ")\n",
    "\n",
    "# 事前学習済みのモデルを読み込みます\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistralモデル\n",
    "    quantization_config=bnb_config,  # 量子化設定\n",
    "    device_map=\"auto\",  # 自動デバイスマッピング\n",
    "    trust_remote_code=True,  # リモートコードを信頼する設定\n",
    ")\n",
    "\n",
    "# 評価用のトークナイザーを読み込みます\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    add_bos_token=True,  # 始まりのトークンを追加する設定\n",
    "    trust_remote_code=True,  # リモートコードを信頼する設定\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # PyTorchライブラリをインポートします\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig  # 必要なクラスをインポートします\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-v0.1\"  # 使用する基本モデルのIDを指定します\n",
    "bnb_config = BitsAndBytesConfig(  # 量子化に関する設定を作成します\n",
    "    load_in_4bit=True,  # 4ビットでモデルを読み込む設定\n",
    "    bnb_4bit_use_double_quant=True,  # 2重量子化を使用する設定\n",
    "    bnb_4bit_quant_type=\"nf4\",  # 量子化のタイプを指定します（nf4）\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 計算データ型をbfloat16に設定\n",
    ")\n",
    "\n",
    "# 事前学習済みのモデルを読み込みます\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistralモデル\n",
    "    quantization_config=bnb_config,  # 量子化設定\n",
    "    device_map=\"auto\",  # 自動デバイスマッピング\n",
    "    trust_remote_code=True,  # リモートコードを信頼する設定\n",
    ")\n",
    "\n",
    "# 評価用のトークナイザーを読み込みます\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model_id,  # 使用するモデルIDを指定します\n",
    "    add_bos_token=True,  # 始まりのトークンを追加する設定\n",
    "    trust_remote_code=True,  # リモートコードを信頼する設定\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863f8442",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-viggo-finetune/checkpoint-1000\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from peft import PeftModel  # PEFTライブラリからPeftModelをインポートします\n",
    "\n",
    "# 事前学習済みのモデルにファインチューニングされたモデルをロードします\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-viggo-finetune/checkpoint-1000\")  # 指定されたチェックポイントからファインチューニングモデルを読み込みます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel  # PEFTライブラリからPeftModelをインポートします\n",
    "\n",
    "# 事前学習済みのモデルにファインチューニングされたモデルをロードします\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"mistral-viggo-finetune/checkpoint-1000\")  # 指定されたチェックポイントからファインチューニングモデルを読み込みます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba8a14d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
    "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
    "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
    "\n",
    "### Target sentence:\n",
    "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
    "\n",
    "### Meaning representation:\n",
    "\"\"\"\n",
    "\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "ft_model.eval()\n",
    "with torch.no_grad():\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 評価用のプロンプトを定義します\n",
    "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
    "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
    "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
    "\n",
    "### Target sentence:\n",
    "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
    "\n",
    "### Meaning representation:\n",
    "\"\"\" \n",
    "\n",
    "# トークナイザーを使用してモデル入力を準備します\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")  # CUDAデバイスに転送します\n",
    "\n",
    "# モデルを評価モードに設定します\n",
    "ft_model.eval()\n",
    "with torch.no_grad():  # 勾配計算を無効にします\n",
    "    # モデルを使って生成した出力を表示します\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))  # 生成されたトークンをデコードし、特殊トークンをスキップして表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価用のプロンプトを定義します\n",
    "eval_prompt = \"\"\"Given a target sentence construct the underlying meaning representation of the input sentence as a single function with attributes and attribute values.\n",
    "This function should describe the target string accurately and the function must be one of the following ['inform', 'request', 'give_opinion', 'confirm', 'verify_attribute', 'suggest', 'request_explanation', 'recommend', 'request_attribute'].\n",
    "The attributes must be one of the following: ['name', 'exp_release_date', 'release_year', 'developer', 'esrb', 'rating', 'genres', 'player_perspective', 'has_multiplayer', 'platforms', 'available_on_steam', 'has_linux_release', 'has_mac_release', 'specifier']\n",
    "\n",
    "### Target sentence:\n",
    "Earlier, you stated that you didn't have strong feelings about PlayStation's Little Big Adventure. Is your opinion true for all games which don't have multiplayer?\n",
    "\n",
    "### Meaning representation:\n",
    "\"\"\" \n",
    "\n",
    "# トークナイザーを使用してモデル入力を準備します\n",
    "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")  # CUDAデバイスに転送します\n",
    "\n",
    "# モデルを評価モードに設定します\n",
    "ft_model.eval()\n",
    "with torch.no_grad():  # 勾配計算を無効にします\n",
    "    # モデルを使って生成した出力を表示します\n",
    "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))  # 生成されたトークンをデコードし、特殊トークンをスキップして表示します"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
