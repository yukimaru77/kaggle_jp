{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ad2c17c",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYS - Chatbot Arenaコンペティションにおいて、ユーザーのプロンプトに対する2つの異なる応答のいずれが好まれるかを予測する問題に取り組んでいます。具体的には、機械学習モデルを用いて、人工知能チャットボットの応答の選好を学習します。\n",
    "\n",
    "### 問題の概要\n",
    "Notebook内での主な目的は、与えられたプロンプトに対して2つの応答モデル（応答Aと応答B）のいずれが好まれるかの確率を予測することです。予測は、訓練データセットとテストデータセットを使用して行われます。\n",
    "\n",
    "### 手法とライブラリ\n",
    "この問題を解決するために、以下の手法とライブラリが使用されています：\n",
    "\n",
    "1. **ライブラリ**\n",
    "   - **PyTorch**: 深層学習フレームワークで、モデルの構築と訓練に使用されています。\n",
    "   - **Transformers**: 事前訓練済みの言語モデルを取得するためのライブラリで、チャットボットの応答生成に利用されています。\n",
    "   - **Pandas**: データ操作と処理のためのライブラリで、データセットの読み込みや前処理に使用されています。\n",
    "   - **NumPy**: 数値計算を補助するためのライブラリで、ベクトル計算などに活用されています。\n",
    "\n",
    "2. **モデルアーキテクチャ**\n",
    "   - **EmbeddingModel**: プロンプトと応答を埋め込みベクトルに変換し、それらのベクトルを統合するためのクラス。\n",
    "   - **Model**: 埋め込み出力をLSTMとCNNで処理し、その後全結合層を通してクラス（勝者モデル）を出力するニューラルネットワークの定義。\n",
    "   - **Datasetクラス**: データのサンプリングを行うためのカスタムデータセットクラス。\n",
    "\n",
    "3. **トレーニングプロセス**\n",
    "   - データセットの読み込み後、トレーニングデータをDataLoaderを用いてバッチ処理し、モデルの訓練を行います。\n",
    "   - 損失関数には交差エントロピー損失が使用され、Adamオプティマイザーでモデルのパラメータの更新を行います。\n",
    "   - トレーニングはエポック数に基づいて繰り返され、各エポックの損失と精度が記録されます。\n",
    "\n",
    "4. **テストと評価**\n",
    "   - 学習済みモデルを用いてテストデータに対する予測を実施し、予測結果をデータフレームにまとめて出力します。\n",
    "\n",
    "このNotebookは、機械学習アルゴリズムを用いて言語モデルの応答に対するユーザーの好みを科学的に予測し、人間とAIのインタラクションを改善するための重要なステップを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f4e72",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebook内で使用されている専門用語や概念に関する解説です。初心者がつまずきそうなマイナーなものや特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **tqdm**:\n",
    "   - プログレスバーを提供するライブラリで、ループ処理の進行状況を視覚化するために使用されます。長時間かかる処理の進行を示し、ユーザーに操作中であることを伝えるために便利です。\n",
    "\n",
    "2. **AutoModel**:\n",
    "   - Hugging Faceの`transformers`ライブラリから提供されるクラスで、事前訓練された大規模な言語モデルを簡単にロードするためのものです。特定のモデルを指定でき、異なるプロンプトや応答を埋め込むために使われます。\n",
    "\n",
    "3. **埋め込み (Embedding)**:\n",
    "   - テキストデータをベクトル空間に変換する手法です。自然言語処理において、単語や文を数値で表現するために使用され、モデルが計算しやすくするための重要な技術です。\n",
    "\n",
    "4. **LSTM (Long Short-Term Memory)**:\n",
    "   - 特徴の時系列データを処理するためのリカレントニューラルネットワーク（RNN）の一種です。長期的な依存関係を保持するためのセル状態を持ち、自然言語処理の分野で広く使用されます。\n",
    "\n",
    "5. **Conv1d (1次元畳み込み)**:\n",
    "   - 1次元のデータ（例えば、時間系列データやシーケンスデータ）に対して適用される畳み込み層です。隣接する入力データを結合して特徴を抽出し、効率的な情報処理を行います。\n",
    "\n",
    "6. **ドロップアウト (Dropout)**:\n",
    "   - モデルの過学習を防ぐための手法です。トレーニング中にランダムに一定割合のニューロンを無効にし、モデルが特定のパターンに依存しないようにします。\n",
    "\n",
    "7. **パディング (Padding)**:\n",
    "   - 畳み込み層やLSTMレイヤーに入力する際に、入力データを指定した形状に合わせるためにゼロなどで埋める処理です。データのサイズを揃える必要があるため、重要な技術です。\n",
    "\n",
    "8. **JSON（JavaScript Object Notation）**:\n",
    "   - 軽量なデータ交換フォーマットで、人間にも読みやすく、プログラムからも容易に読み書きできる形式です。特にAPIなどでデータをやり取りする際によく使われます。\n",
    "\n",
    "9. **カスタムデータセット (Custom Dataset)**:\n",
    "   - PyTorchで作成したさまざまなデータ処理のために独自に定義した`Dataset`クラスです。特定のデータの構造や形式に応じてデータを扱う方法を提供します。\n",
    "\n",
    "10. **ミニバッチ (Mini-batch)**:\n",
    "    - 一度に処理するデータの小さなグループです。これはモデルの訓練効率を高め、メモリ使用量を抑えるための一般的な手法です。\n",
    "\n",
    "11. **勾配 (Gradient)**:\n",
    "    - ニュートン法に基づく最適化アルゴリズムで、モデルの重みを更新するために使用される値です。損失関数の変化率を表し、最適化のステップサイズを決定します。\n",
    "\n",
    "12. **Cross Entropy Loss**:\n",
    "    - モデルの予測確率と実際のラベルとの違いを測定するために使用される損失関数です。特に多クラス分類問題で一般的に使われます。また、モデルの出力が確率であることを考慮します。\n",
    "\n",
    "これらの用語は、機械学習や深層学習の実践において重要ですが、初心者にとっては専門的な背景が必要な場合があります。理解を深めるために、各概念を補完する文献やリソースを参照することをお勧めします。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64985af",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "from numpy.linalg import norm\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# tqdmをインポートします。これはプログレスバーを提供するライブラリです。\n",
    "from tqdm import tqdm\n",
    "# データ処理のためにpandasをインポートします。\n",
    "import pandas as pd\n",
    "# JSONファイルを読み込むためのjsonライブラリをインポートします。\n",
    "import json\n",
    "# PyTorchライブラリをインポートします。深層学習を行うためのフレームワークです。\n",
    "import torch\n",
    "# 事前訓練済みのモデルを取り扱うためにtransformersライブラリからAutoModelをインポートします。\n",
    "from transformers import AutoModel\n",
    "# numpyの線形代数機能からnorm関数をインポートします。ベクトルのノルム計算に使用します。\n",
    "from numpy.linalg import norm\n",
    "# PyTorchのニューラルネットワークモジュールをインポートします。\n",
    "import torch.nn as nn\n",
    "# numpyをインポートします。数値計算に使用されるライブラリです。\n",
    "import numpy as np\n",
    "# PyTorchのデータセットおよびデータローダーをインポートします。データを扱うための便利なツールです。\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# PyTorchの関数型APIをインポートします。ニューラルネットワークの活性化関数などに使用されます。\n",
    "import torch.nn.functional as F\n",
    "# 正規表現を扱うためのreライブラリをインポートします。\n",
    "import re\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-02T08:49:33.158666Z",
     "iopub.status.busy": "2024-08-02T08:49:33.158285Z",
     "iopub.status.idle": "2024-08-02T08:49:33.16425Z",
     "shell.execute_reply": "2024-08-02T08:49:33.163288Z",
     "shell.execute_reply.started": "2024-08-02T08:49:33.158636Z"
    }
   },
   "outputs": [],
   "source": [
    "# tqdmをインポートします。これはプログレスバーを提供するライブラリです。\n",
    "from tqdm import tqdm\n",
    "# データ処理のためにpandasをインポートします。\n",
    "import pandas as pd\n",
    "# JSONファイルを読み込むためのjsonライブラリをインポートします。\n",
    "import json\n",
    "# PyTorchライブラリをインポートします。深層学習を行うためのフレームワークです。\n",
    "import torch\n",
    "# 事前訓練済みのモデルを取り扱うためにtransformersライブラリからAutoModelをインポートします。\n",
    "from transformers import AutoModel\n",
    "# numpyの線形代数機能からnorm関数をインポートします。ベクトルのノルム計算に使用します。\n",
    "from numpy.linalg import norm\n",
    "# PyTorchのニューラルネットワークモジュールをインポートします。\n",
    "import torch.nn as nn\n",
    "# numpyをインポートします。数値計算に使用されるライブラリです。\n",
    "import numpy as np\n",
    "# PyTorchのデータセットおよびデータローダーをインポートします。データを扱うための便利なツールです。\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# PyTorchの関数型APIをインポートします。ニューラルネットワークの活性化関数などに使用されます。\n",
    "import torch.nn.functional as F\n",
    "# 正規表現を扱うためのreライブラリをインポートします。\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfdc557",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "device\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 使用可能なデバイスを確認し、CUDA（GPU）が利用可能であればそれを使用します。\n",
    "# そうでない場合は、CPUを使用します。\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 現在のデバイス（GPUまたはCPU）を表示します。\n",
    "device\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T08:49:33.170388Z",
     "iopub.status.busy": "2024-08-02T08:49:33.169448Z",
     "iopub.status.idle": "2024-08-02T08:49:33.187453Z",
     "shell.execute_reply": "2024-08-02T08:49:33.186421Z",
     "shell.execute_reply.started": "2024-08-02T08:49:33.170353Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用可能なデバイスを確認し、CUDA（GPU）が利用可能であればそれを使用します。\n",
    "# そうでない場合は、CPUを使用します。\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# 現在のデバイス（GPUまたはCPU）を表示します。\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76741ccf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoModel.from_pretrained('/kaggle/input/jinaai/pytorch/default/4')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 事前訓練済みのモデルを指定したパスからロードします。\n",
    "# AutoModelを使用して、指定されたディレクトリのモデルを取得し、トークナイザーとして設定します。\n",
    "tokenizer = AutoModel.from_pretrained('/kaggle/input/jinaai/pytorch/default/4')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:21:58.340116Z",
     "iopub.status.busy": "2024-08-02T09:21:58.339099Z",
     "iopub.status.idle": "2024-08-02T09:21:58.733531Z",
     "shell.execute_reply": "2024-08-02T09:21:58.732695Z",
     "shell.execute_reply.started": "2024-08-02T09:21:58.340082Z"
    }
   },
   "outputs": [],
   "source": [
    "# 事前訓練済みのモデルを指定したパスからロードします。\n",
    "# AutoModelを使用して、指定されたディレクトリのモデルを取得し、トークナイザーとして設定します。\n",
    "tokenizer = AutoModel.from_pretrained('/kaggle/input/jinaai/pytorch/default/4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46910df6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = embedding_model\n",
    "        self.max_seq_length = max_sequences\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_features_a = []\n",
    "        batch_features_b = []\n",
    "\n",
    "        for prompt, response_a, response_b in zip(prompts, responses_a, responses_b):\n",
    "            prompt = json.loads(prompt)\n",
    "            response_a = json.loads(response_a)\n",
    "            response_b = json.loads(response_b)\n",
    "            \n",
    "            prompt = [\"\" if p is None else p for p in prompt]\n",
    "            response_a = [\"\" if r is None else r for r in response_a]\n",
    "            response_b = [\"\" if r is None else r for r in response_b]\n",
    "            \n",
    "            \n",
    "            embedded_prompt = torch.from_numpy(self.embedding.encode(prompt)).to(self.device)\n",
    "           \n",
    "            embedded_response_a = torch.from_numpy(self.embedding.encode(response_a)).to(self.device)\n",
    "            embedded_response_b = torch.from_numpy(self.embedding.encode(response_b)).to(self.device)\n",
    "\n",
    "            features_a = []\n",
    "            features_b = []\n",
    "            for i in range(len(embedded_prompt)):\n",
    "                combined_a = torch.cat((embedded_prompt[i], embedded_response_a[i]), dim=0)\n",
    "                combined_b = torch.cat((embedded_prompt[i], embedded_response_b[i]), dim=0)\n",
    "\n",
    "                features_a.append(combined_a)\n",
    "                features_b.append(combined_b)\n",
    "\n",
    "            features_a = torch.stack(features_a) if features_a else torch.tensor([]).to(self.device)\n",
    "            features_b = torch.stack(features_b) if features_b else torch.tensor([]).to(self.device)\n",
    "\n",
    "            features_a = self.pad_to_shape(features_a, (self.max_seq_length, 768 * 2))\n",
    "            features_b = self.pad_to_shape(features_b, (self.max_seq_length, 768 * 2))\n",
    "\n",
    "            batch_features_a.append(features_a)\n",
    "            batch_features_b.append(features_b)\n",
    "\n",
    "        return torch.stack(batch_features_a).to(self.device), torch.stack(batch_features_b).to(self.device)\n",
    "\n",
    "    def pad_to_shape(self, tensor, shape):\n",
    "        current_shape = tensor.shape\n",
    "        padding = [(0, max(s - cs, 0)) for cs, s in zip(current_shape, shape)]\n",
    "        padded_tensor = F.pad(tensor, pad=[p for pair in reversed(padding) for p in pair], mode='constant', value=0)\n",
    "        return padded_tensor[:shape[0], :shape[1]]\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences=64, hidden_dim=512, dropout=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = EmbeddingModel(embedding_model, max_sequences)\n",
    "        self.lstm_input_a = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "        self.lstm_input_b = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "\n",
    "        self.conv_input_a = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "        self.conv_input_b = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + hidden_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 3),\n",
    "            nn.Softmax()\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_a, batch_b = self.embedding(prompts, responses_a, responses_b)\n",
    "\n",
    "        batch_a_lstm, _ = self.lstm_input_a(batch_a)  # (batch, 64, hidden_dim)\n",
    "        batch_b_lstm, _ = self.lstm_input_b(batch_b)  # (batch, 64, hidden_dim)\n",
    "\n",
    "        batch_a_cnn = self.conv_input_a(batch_a.permute(0, 2, 1)).permute(0, 2, 1)  # (batch, 64, hidden_dim)\n",
    "        batch_b_cnn = self.conv_input_b(batch_b.permute(0, 2, 1)).permute(0, 2, 1)  # (batch, 64, hidden_dim)\n",
    "\n",
    "        batch_a_lstm = batch_a_lstm[:, -1, :] \n",
    "        batch_b_lstm = batch_b_lstm[:, -1, :]  \n",
    "        batch_a_cnn = batch_a_cnn[:, -1, :]    \n",
    "        batch_b_cnn = batch_b_cnn[:, -1, :]\n",
    "        \n",
    "        combined = torch.cat([batch_a_lstm, batch_a_cnn, batch_b_lstm, batch_b_cnn], dim=1)\n",
    "        flattened = combined.view(combined.size(0), -1)\n",
    "\n",
    "        output = self.fc(flattened)\n",
    "        return output\n",
    "    \n",
    "class DatasetLMSYS(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        prompt = sample['prompt']\n",
    "        response_a = sample['response_a']\n",
    "        response_b = sample['response_b']\n",
    "        label = sample['model_result']\n",
    "        return prompt, response_a, response_b, label\n",
    "    \n",
    "class DatasetLMSYSTest(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]\n",
    "        _id = sample['id']\n",
    "        _prompt = sample['prompt']\n",
    "        _response_a = sample['response_a']\n",
    "        _response_b = sample['response_b']\n",
    "        return _id, _prompt, _response_a, _response_b\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 埋め込みモデルを定義するクラス\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = embedding_model  # 埋め込みモデルを指定\n",
    "        self.max_seq_length = max_sequences  # 最大シーケンス長を設定\n",
    "        self.device = device  # 使用するデバイスを指定\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_features_a = []  # 応答Aの特徴を格納するリスト\n",
    "        batch_features_b = []  # 応答Bの特徴を格納するリスト\n",
    "\n",
    "        # 各プロンプトと応答を処理するループ\n",
    "        for prompt, response_a, response_b in zip(prompts, responses_a, responses_b):\n",
    "            prompt = json.loads(prompt)  # プロンプトをJSONから読み込む\n",
    "            response_a = json.loads(response_a)  # 応答AをJSONから読み込む\n",
    "            response_b = json.loads(response_b)  # 応答BをJSONから読み込む\n",
    "            \n",
    "            prompt = [\"\" if p is None else p for p in prompt]  # Noneの場合は空文字に変換\n",
    "            response_a = [\"\" if r is None else r for r in response_a]  # Noneの場合は空文字に変換\n",
    "            response_b = [\"\" if r is None else r for r in response_b]  # Noneの場合は空文字に変換\n",
    "            \n",
    "            # プロンプトを埋め込む\n",
    "            embedded_prompt = torch.from_numpy(self.embedding.encode(prompt)).to(self.device)\n",
    "           \n",
    "            # 応答Aを埋め込む\n",
    "            embedded_response_a = torch.from_numpy(self.embedding.encode(response_a)).to(self.device)\n",
    "            # 応答Bを埋め込む\n",
    "            embedded_response_b = torch.from_numpy(self.embedding.encode(response_b)).to(self.device)\n",
    "\n",
    "            features_a = []  # 応答Aの特徴を格納するリスト\n",
    "            features_b = []  # 応答Bの特徴を格納するリスト\n",
    "            # 各埋め込みを結合して特徴を作成\n",
    "            for i in range(len(embedded_prompt)):\n",
    "                combined_a = torch.cat((embedded_prompt[i], embedded_response_a[i]), dim=0)\n",
    "                combined_b = torch.cat((embedded_prompt[i], embedded_response_b[i]), dim=0)\n",
    "\n",
    "                features_a.append(combined_a)  # 応答Aの特徴を追加\n",
    "                features_b.append(combined_b)  # 応答Bの特徴を追加\n",
    "\n",
    "            features_a = torch.stack(features_a) if features_a else torch.tensor([]).to(self.device)\n",
    "            features_b = torch.stack(features_b) if features_b else torch.tensor([]).to(self.device)\n",
    "\n",
    "            # 特徴を指定の形状にパディングする\n",
    "            features_a = self.pad_to_shape(features_a, (self.max_seq_length, 768 * 2))\n",
    "            features_b = self.pad_to_shape(features_b, (self.max_seq_length, 768 * 2))\n",
    "\n",
    "            batch_features_a.append(features_a)  # バッチに応答Aの特徴を追加\n",
    "            batch_features_b.append(features_b)  # バッチに応答Bの特徴を追加\n",
    "\n",
    "        return torch.stack(batch_features_a).to(self.device), torch.stack(batch_features_b).to(self.device)\n",
    "\n",
    "    def pad_to_shape(self, tensor, shape):\n",
    "        current_shape = tensor.shape  # 現在のテンソルの形状を取得\n",
    "        padding = [(0, max(s - cs, 0)) for cs, s in zip(current_shape, shape)]  # パディングサイズを計算\n",
    "        # テンソルにパディングを適用\n",
    "        padded_tensor = F.pad(tensor, pad=[p for pair in reversed(padding) for p in pair], mode='constant', value=0)\n",
    "        return padded_tensor[:shape[0], :shape[1]]  # 指定した形状に合わせてトリミング\n",
    "\n",
    "# 全体のモデルを定義するクラス\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences=64, hidden_dim=512, dropout=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device  # デバイスを指定\n",
    "        self.embedding = EmbeddingModel(embedding_model, max_sequences)  # 埋め込みモデルを作成\n",
    "        # LSTMレイヤーを初期化\n",
    "        self.lstm_input_a = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "        self.lstm_input_b = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "\n",
    "        # 畳み込みレイヤーを初期化\n",
    "        self.conv_input_a = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "        self.conv_input_b = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "\n",
    "        # 全結合層の定義\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + hidden_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 3),  # 出力は3クラス\n",
    "            nn.Softmax()\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_a, batch_b = self.embedding(prompts, responses_a, responses_b)  # 埋め込みを計算\n",
    "\n",
    "        # LSTMを通す\n",
    "        batch_a_lstm, _ = self.lstm_input_a(batch_a)  # (バッチ, 64, hidden_dim)\n",
    "        batch_b_lstm, _ = self.lstm_input_b(batch_b)  # (バッチ, 64, hidden_dim)\n",
    "\n",
    "        # 畳み込み層を通す\n",
    "        batch_a_cnn = self.conv_input_a(batch_a.permute(0, 2, 1)).permute(0, 2, 1)  # (バッチ, 64, hidden_dim)\n",
    "        batch_b_cnn = self.conv_input_b(batch_b.permute(0, 2, 1)).permute(0, 2, 1)  # (バッチ, 64, hidden_dim)\n",
    "\n",
    "        # LSTMの最終出力を取得\n",
    "        batch_a_lstm = batch_a_lstm[:, -1, :] \n",
    "        batch_b_lstm = batch_b_lstm[:, -1, :]  \n",
    "        # 畳み込みの最終出力を取得\n",
    "        batch_a_cnn = batch_a_cnn[:, -1, :]    \n",
    "        batch_b_cnn = batch_b_cnn[:, -1, :]\n",
    "        \n",
    "        # 特徴を結合\n",
    "        combined = torch.cat([batch_a_lstm, batch_a_cnn, batch_b_lstm, batch_b_cnn], dim=1)\n",
    "        flattened = combined.view(combined.size(0), -1)  # 転置して線形層に適した形状にする\n",
    "\n",
    "        output = self.fc(flattened)  # 全結合層を通す\n",
    "        return output  # 出力を返す\n",
    "\n",
    "# 学習データセット用のクラス\n",
    "class DatasetLMSYS(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # データを保存\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # データの長さを返す\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]  # データフレームからサンプルを取得\n",
    "        prompt = sample['prompt']  # プロンプトを取得\n",
    "        response_a = sample['response_a']  # 応答Aを取得\n",
    "        response_b = sample['response_b']  # 応答Bを取得\n",
    "        label = sample['model_result']  # ラベルを取得\n",
    "        return prompt, response_a, response_b, label  # プロンプト、応答A、応答B、およびラベルを返す\n",
    "    \n",
    "# テストデータセット用のクラス\n",
    "class DatasetLMSYSTest(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # データを保存\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # データの長さを返す\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]  # データフレームからサンプルを取得\n",
    "        _id = sample['id']  # IDを取得\n",
    "        _prompt = sample['prompt']  # プロンプトを取得\n",
    "        _response_a = sample['response_a']  # 応答Aを取得\n",
    "        _response_b = sample['response_b']  # 応答Bを取得\n",
    "        return _id, _prompt, _response_a, _response_b  # ID、プロンプト、応答A、および応答Bを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:20:17.03872Z",
     "iopub.status.busy": "2024-08-02T09:20:17.038348Z",
     "iopub.status.idle": "2024-08-02T09:20:17.067718Z",
     "shell.execute_reply": "2024-08-02T09:20:17.066641Z",
     "shell.execute_reply.started": "2024-08-02T09:20:17.038692Z"
    }
   },
   "outputs": [],
   "source": [
    "# 埋め込みモデルを定義するクラス\n",
    "class EmbeddingModel(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences):\n",
    "        super(EmbeddingModel, self).__init__()\n",
    "        self.embedding = embedding_model  # 埋め込みモデルを指定\n",
    "        self.max_seq_length = max_sequences  # 最大シーケンス長を設定\n",
    "        self.device = device  # 使用するデバイスを指定\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_features_a = []  # 応答Aの特徴を格納するリスト\n",
    "        batch_features_b = []  # 応答Bの特徴を格納するリスト\n",
    "\n",
    "        # 各プロンプトと応答を処理するループ\n",
    "        for prompt, response_a, response_b in zip(prompts, responses_a, responses_b):\n",
    "            prompt = json.loads(prompt)  # プロンプトをJSONから読み込む\n",
    "            response_a = json.loads(response_a)  # 応答AをJSONから読み込む\n",
    "            response_b = json.loads(response_b)  # 応答BをJSONから読み込む\n",
    "            \n",
    "            prompt = [\"\" if p is None else p for p in prompt]  # Noneの場合は空文字に変換\n",
    "            response_a = [\"\" if r is None else r for r in response_a]  # Noneの場合は空文字に変換\n",
    "            response_b = [\"\" if r is None else r for r in response_b]  # Noneの場合は空文字に変換\n",
    "            \n",
    "            # プロンプトを埋め込む\n",
    "            embedded_prompt = torch.from_numpy(self.embedding.encode(prompt)).to(self.device)\n",
    "           \n",
    "            # 応答Aを埋め込む\n",
    "            embedded_response_a = torch.from_numpy(self.embedding.encode(response_a)).to(self.device)\n",
    "            # 応答Bを埋め込む\n",
    "            embedded_response_b = torch.from_numpy(self.embedding.encode(response_b)).to(self.device)\n",
    "\n",
    "            features_a = []  # 応答Aの特徴を格納するリスト\n",
    "            features_b = []  # 応答Bの特徴を格納するリスト\n",
    "            # 各埋め込みを結合して特徴を作成\n",
    "            for i in range(len(embedded_prompt)):\n",
    "                combined_a = torch.cat((embedded_prompt[i], embedded_response_a[i]), dim=0)\n",
    "                combined_b = torch.cat((embedded_prompt[i], embedded_response_b[i]), dim=0)\n",
    "\n",
    "                features_a.append(combined_a)  # 応答Aの特徴を追加\n",
    "                features_b.append(combined_b)  # 応答Bの特徴を追加\n",
    "\n",
    "            features_a = torch.stack(features_a) if features_a else torch.tensor([]).to(self.device)\n",
    "            features_b = torch.stack(features_b) if features_b else torch.tensor([]).to(self.device)\n",
    "\n",
    "            # 特徴を指定の形状にパディングする\n",
    "            features_a = self.pad_to_shape(features_a, (self.max_seq_length, 768 * 2))\n",
    "            features_b = self.pad_to_shape(features_b, (self.max_seq_length, 768 * 2))\n",
    "\n",
    "            batch_features_a.append(features_a)  # バッチに応答Aの特徴を追加\n",
    "            batch_features_b.append(features_b)  # バッチに応答Bの特徴を追加\n",
    "\n",
    "        return torch.stack(batch_features_a).to(self.device), torch.stack(batch_features_b).to(self.device)\n",
    "\n",
    "    def pad_to_shape(self, tensor, shape):\n",
    "        current_shape = tensor.shape  # 現在のテンソルの形状を取得\n",
    "        padding = [(0, max(s - cs, 0)) for cs, s in zip(current_shape, shape)]  # パディングサイズを計算\n",
    "        # テンソルにパディングを適用\n",
    "        padded_tensor = F.pad(tensor, pad=[p for pair in reversed(padding) for p in pair], mode='constant', value=0)\n",
    "        return padded_tensor[:shape[0], :shape[1]]  # 指定した形状に合わせてトリミング\n",
    "\n",
    "# 全体のモデルを定義するクラス\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_model, max_sequences=64, hidden_dim=512, dropout=0.3):\n",
    "        super(Model, self).__init__()\n",
    "        self.device = device  # デバイスを指定\n",
    "        self.embedding = EmbeddingModel(embedding_model, max_sequences)  # 埋め込みモデルを作成\n",
    "        # LSTMレイヤーを初期化\n",
    "        self.lstm_input_a = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "        self.lstm_input_b = nn.LSTM(768 * 2, hidden_dim, batch_first=True).to(self.device)\n",
    "\n",
    "        # 畳み込みレイヤーを初期化\n",
    "        self.conv_input_a = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "        self.conv_input_b = nn.Conv1d(768 * 2, hidden_dim, kernel_size=3, padding=1).to(self.device)\n",
    "\n",
    "        # 全結合層の定義\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2 + hidden_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 3),  # 出力は3クラス\n",
    "            nn.Softmax()\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self, prompts, responses_a, responses_b):\n",
    "        batch_a, batch_b = self.embedding(prompts, responses_a, responses_b)  # 埋め込みを計算\n",
    "\n",
    "        # LSTMを通す\n",
    "        batch_a_lstm, _ = self.lstm_input_a(batch_a)  # (バッチ, 64, hidden_dim)\n",
    "        batch_b_lstm, _ = self.lstm_input_b(batch_b)  # (バッチ, 64, hidden_dim)\n",
    "\n",
    "        # 畳み込み層を通す\n",
    "        batch_a_cnn = self.conv_input_a(batch_a.permute(0, 2, 1)).permute(0, 2, 1)  # (バッチ, 64, hidden_dim)\n",
    "        batch_b_cnn = self.conv_input_b(batch_b.permute(0, 2, 1)).permute(0, 2, 1)  # (バッチ, 64, hidden_dim)\n",
    "\n",
    "        # LSTMの最終出力を取得\n",
    "        batch_a_lstm = batch_a_lstm[:, -1, :] \n",
    "        batch_b_lstm = batch_b_lstm[:, -1, :]  \n",
    "        # 畳み込みの最終出力を取得\n",
    "        batch_a_cnn = batch_a_cnn[:, -1, :]    \n",
    "        batch_b_cnn = batch_b_cnn[:, -1, :]\n",
    "        \n",
    "        # 特徴を結合\n",
    "        combined = torch.cat([batch_a_lstm, batch_a_cnn, batch_b_lstm, batch_b_cnn], dim=1)\n",
    "        flattened = combined.view(combined.size(0), -1)  # 転置して線形層に適した形状にする\n",
    "\n",
    "        output = self.fc(flattened)  # 全結合層を通す\n",
    "        return output  # 出力を返す\n",
    "\n",
    "# 学習データセット用のクラス\n",
    "class DatasetLMSYS(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # データを保存\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # データの長さを返す\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]  # データフレームからサンプルを取得\n",
    "        prompt = sample['prompt']  # プロンプトを取得\n",
    "        response_a = sample['response_a']  # 応答Aを取得\n",
    "        response_b = sample['response_b']  # 応答Bを取得\n",
    "        label = sample['model_result']  # ラベルを取得\n",
    "        return prompt, response_a, response_b, label  # プロンプト、応答A、応答B、およびラベルを返す\n",
    "    \n",
    "# テストデータセット用のクラス\n",
    "class DatasetLMSYSTest(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data  # データを保存\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)  # データの長さを返す\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data.iloc[idx]  # データフレームからサンプルを取得\n",
    "        _id = sample['id']  # IDを取得\n",
    "        _prompt = sample['prompt']  # プロンプトを取得\n",
    "        _response_a = sample['response_a']  # 応答Aを取得\n",
    "        _response_b = sample['response_b']  # 応答Bを取得\n",
    "        return _id, _prompt, _response_a, _response_b  # ID、プロンプト、応答A、および応答Bを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d070ae37",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = Model(tokenizer).to(device)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 定義したモデルをインスタンス化します。\n",
    "# 事前訓練済みのトークナイザーを渡し、指定したデバイス（GPUまたはCPU）に移動させます。\n",
    "model = Model(tokenizer).to(device)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:33.366619Z",
     "iopub.status.busy": "2024-08-02T09:08:33.3659Z",
     "iopub.status.idle": "2024-08-02T09:08:33.499952Z",
     "shell.execute_reply": "2024-08-02T09:08:33.499165Z",
     "shell.execute_reply.started": "2024-08-02T09:08:33.366588Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義したモデルをインスタンス化します。\n",
    "# 事前訓練済みのトークナイザーを渡し、指定したデバイス（GPUまたはCPU）に移動させます。\n",
    "model = Model(tokenizer).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a50f2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ミニバッチのサイズを設定します。これは一度に処理するデータの数です。\n",
    "batch_size = 128\n",
    "# 学習率を設定します。これはモデルの重みの更新に使用されるステップサイズです。\n",
    "learning_rate = 0.001\n",
    "# エポック数を設定します。エポックとは、全データセットを1回学習させることを指します。\n",
    "epochs = 5\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:34.030007Z",
     "iopub.status.busy": "2024-08-02T09:08:34.029641Z",
     "iopub.status.idle": "2024-08-02T09:08:34.034188Z",
     "shell.execute_reply": "2024-08-02T09:08:34.033273Z",
     "shell.execute_reply.started": "2024-08-02T09:08:34.029978Z"
    }
   },
   "outputs": [],
   "source": [
    "# ミニバッチのサイズを設定します。これは一度に処理するデータの数です。\n",
    "batch_size = 128\n",
    "# 学習率を設定します。これはモデルの重みの更新に使用されるステップサイズです。\n",
    "learning_rate = 0.001\n",
    "# エポック数を設定します。エポックとは、全データセットを1回学習させることを指します。\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d4108",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "file_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "file_data['model_result'] = file_data.apply(lambda row: 0 if row['winner_model_a'] == 1 else (1 if row['winner_model_b'] == 1 else 2), axis=1)\n",
    "file_data = file_data[['prompt', 'response_a', 'response_b', 'model_result']]\n",
    "train_loader = DataLoader(\n",
    "    dataset=DatasetLMSYS(file_data),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "file_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "test_loader = DataLoader(\n",
    "    dataset=DatasetLMSYSTest(file_test),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータをCSVファイルから読み込みます。\n",
    "file_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "# モデルの結果を計算します。winner_model_aが1なら0、winner_model_bが1なら1、どちらでもなければ2を設定します。\n",
    "file_data['model_result'] = file_data.apply(lambda row: 0 if row['winner_model_a'] == 1 else (1 if row['winner_model_b'] == 1 else 2), axis=1)\n",
    "# 使用するカラムを指定します。プロンプト、応答A、応答B、モデルの結果のみを残します。\n",
    "file_data = file_data[['prompt', 'response_a', 'response_b', 'model_result']]\n",
    "# データローダーを作成します。これによりミニバッチでデータを効率的に処理できます。\n",
    "train_loader = DataLoader(\n",
    "    dataset=DatasetLMSYS(file_data),  # 自作のDatasetを使用\n",
    "    batch_size=batch_size,  # バッチサイズを指定\n",
    "    shuffle=True  # データをランダムにシャッフルします\n",
    ")\n",
    "\n",
    "# テストデータをCSVファイルから読み込みます。\n",
    "file_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "# テストデータ用のデータローダーを作成します。\n",
    "test_loader = DataLoader(\n",
    "    dataset=DatasetLMSYSTest(file_test),  # 自作のテストDatasetを使用\n",
    "    batch_size=batch_size,  # バッチサイズを指定\n",
    "    shuffle=False  # テストデータはシャッフルしません\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:34.645007Z",
     "iopub.status.busy": "2024-08-02T09:08:34.644017Z",
     "iopub.status.idle": "2024-08-02T09:08:37.197375Z",
     "shell.execute_reply": "2024-08-02T09:08:37.196582Z",
     "shell.execute_reply.started": "2024-08-02T09:08:34.64496Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータをCSVファイルから読み込みます。\n",
    "file_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "# モデルの結果を計算します。winner_model_aが1なら0、winner_model_bが1なら1、どちらでもなければ2を設定します。\n",
    "file_data['model_result'] = file_data.apply(lambda row: 0 if row['winner_model_a'] == 1 else (1 if row['winner_model_b'] == 1 else 2), axis=1)\n",
    "# 使用するカラムを指定します。プロンプト、応答A、応答B、モデルの結果のみを残します。\n",
    "file_data = file_data[['prompt', 'response_a', 'response_b', 'model_result']]\n",
    "# データローダーを作成します。これによりミニバッチでデータを効率的に処理できます。\n",
    "train_loader = DataLoader(\n",
    "    dataset=DatasetLMSYS(file_data),  # 自作のDatasetを使用\n",
    "    batch_size=batch_size,  # バッチサイズを指定\n",
    "    shuffle=True  # データをランダムにシャッフルします\n",
    ")\n",
    "\n",
    "# テストデータをCSVファイルから読み込みます。\n",
    "file_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "# テストデータ用のデータローダーを作成します。\n",
    "test_loader = DataLoader(\n",
    "    dataset=DatasetLMSYSTest(file_test),  # 自作のテストDatasetを使用\n",
    "    batch_size=batch_size,  # バッチサイズを指定\n",
    "    shuffle=False  # テストデータはシャッフルしません\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795497d8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 損失関数を設定します。ここでは交差エントロピー損失を使用します。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 最適化手法としてAdamを選択し、モデルのパラメータに対して学習率を設定します。\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:37.19986Z",
     "iopub.status.busy": "2024-08-02T09:08:37.199256Z",
     "iopub.status.idle": "2024-08-02T09:08:37.205323Z",
     "shell.execute_reply": "2024-08-02T09:08:37.204358Z",
     "shell.execute_reply.started": "2024-08-02T09:08:37.199825Z"
    }
   },
   "outputs": [],
   "source": [
    "# 損失関数を設定します。ここでは交差エントロピー損失を使用します。\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 最適化手法としてAdamを選択し、モデルのパラメータに対して学習率を設定します。\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748d9941",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    running_loss = 0\n",
    "    total_train = 0\n",
    "    correct_train = 0\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        prompts, responses_a, responses_b, labels = batch\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(prompts, responses_a, responses_b)\n",
    "        _, predicted_idx = torch.max(outputs.data, 1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted_idx == labels).sum().item()\n",
    "\n",
    "        del labels, outputs\n",
    "        \n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    print(f\"\\nTraining Loss: {running_loss/len(train_loader):.4f} | Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(\"\\n==> Training finished!\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# エポック数分ループします。各エポックは1回の学習サイクルを示します。\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")  # 現在のエポック数を表示\n",
    "    running_loss = 0  # 現在の損失の累積値\n",
    "    total_train = 0  # 総トレーニングサンプル数\n",
    "    correct_train = 0  # 正しく分類されたサンプルの数\n",
    "\n",
    "    # モデルをトレーニングモードに設定\n",
    "    model.train()\n",
    "    # トレーニングデータローダーからバッチを取得\n",
    "    for batch in tqdm(train_loader):\n",
    "        prompts, responses_a, responses_b, labels = batch  # バッチからデータを取得\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "\n",
    "        # モデルの出力を計算\n",
    "        outputs = model(prompts, responses_a, responses_b)\n",
    "        # 最大値を持つインデックスを取得\n",
    "        _, predicted_idx = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 損失を計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 勾配をゼロに設定\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 損失に基づいて勾配を計算\n",
    "        loss.backward()\n",
    "        # パラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # 損失の累積値を更新\n",
    "        running_loss += loss.item()\n",
    "        total_train += labels.size(0)  # トレーニングサンプル数を増加\n",
    "        correct_train += (predicted_idx == labels).sum().item()  # 正解をカウント\n",
    "\n",
    "        # メモリ管理のためにラベルと出力を削除\n",
    "        del labels, outputs\n",
    "        \n",
    "    # トレーニング精度を計算\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    # トレーニング損失と精度を表示\n",
    "    print(f\"\\nTraining Loss: {running_loss/len(train_loader):.4f} | Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(\"\\n==> Training finished!\")  # トレーニング終了のメッセージを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:37.206796Z",
     "iopub.status.busy": "2024-08-02T09:08:37.206464Z",
     "iopub.status.idle": "2024-08-02T09:09:12.449928Z",
     "shell.execute_reply": "2024-08-02T09:09:12.448103Z",
     "shell.execute_reply.started": "2024-08-02T09:08:37.206766Z"
    }
   },
   "outputs": [],
   "source": [
    "# エポック数分ループします。各エポックは1回の学習サイクルを示します。\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")  # 現在のエポック数を表示\n",
    "    running_loss = 0  # 現在の損失の累積値\n",
    "    total_train = 0  # 総トレーニングサンプル数\n",
    "    correct_train = 0  # 正しく分類されたサンプルの数\n",
    "\n",
    "    # モデルをトレーニングモードに設定\n",
    "    model.train()\n",
    "    # トレーニングデータローダーからバッチを取得\n",
    "    for batch in tqdm(train_loader):\n",
    "        prompts, responses_a, responses_b, labels = batch  # バッチからデータを取得\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "\n",
    "        # モデルの出力を計算\n",
    "        outputs = model(prompts, responses_a, responses_b)\n",
    "        # 最大値を持つインデックスを取得\n",
    "        _, predicted_idx = torch.max(outputs.data, 1)\n",
    "\n",
    "        # 損失を計算\n",
    "        loss = criterion(outputs, labels)\n",
    "        # 勾配をゼロに設定\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 損失に基づいて勾配を計算\n",
    "        loss.backward()\n",
    "        # パラメータを更新\n",
    "        optimizer.step()\n",
    "\n",
    "        # 損失の累積値を更新\n",
    "        running_loss += loss.item()\n",
    "        total_train += labels.size(0)  # トレーニングサンプル数を増加\n",
    "        correct_train += (predicted_idx == labels).sum().item()  # 正解をカウント\n",
    "\n",
    "        # メモリ管理のためにラベルと出力を削除\n",
    "        del labels, outputs\n",
    "        \n",
    "    # トレーニング精度を計算\n",
    "    train_accuracy = 100 * correct_train / total_train\n",
    "    # トレーニング損失と精度を表示\n",
    "    print(f\"\\nTraining Loss: {running_loss/len(train_loader):.4f} | Training Accuracy: {train_accuracy:.2f}%\")\n",
    "print(\"\\n==> Training finished!\")  # トレーニング終了のメッセージを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008a9b9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def test(model, test_loader, device):\n",
    "    model.eval() \n",
    "    results = [] \n",
    "    with torch.no_grad(): \n",
    "        for batch in tqdm(test_loader):\n",
    "            ids, prompts, responses_a, responses_b = batch\n",
    "            outputs = model(prompts, responses_a, responses_b)\n",
    "            _, predicted_idx = torch.max(outputs.data, 1)\n",
    "            \n",
    "            for idx, output, prediction in zip(ids, outputs, predicted_idx):\n",
    "                results.append({\n",
    "                    'id': idx.item(),\n",
    "                    'winner_model_a': output[0].item(),\n",
    "                    'winner_model_b': output[1].item(),\n",
    "                    'winner_tie': output[2].item()\n",
    "                })\n",
    "    df_results = pd.DataFrame(results)\n",
    "    return df_results\n",
    "\n",
    "df_results = test(model, test_loader, device)\n",
    "df_results\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルのテストを行う関数を定義します。\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    results = []  # 結果を格納するリスト\n",
    "    with torch.no_grad():  # 勾配計算を無効にしてメモリを節約\n",
    "        # テストデータローダーからバッチを取得\n",
    "        for batch in tqdm(test_loader):\n",
    "            ids, prompts, responses_a, responses_b = batch  # バッチからデータを取得\n",
    "            # モデルの出力を計算\n",
    "            outputs = model(prompts, responses_a, responses_b)\n",
    "            # 最大値のインデックスを取得\n",
    "            _, predicted_idx = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # 結果をリストに追加\n",
    "            for idx, output, prediction in zip(ids, outputs, predicted_idx):\n",
    "                results.append({\n",
    "                    'id': idx.item(),  # IDを追加\n",
    "                    'winner_model_a': output[0].item(),  # モデルAの勝者確率を追加\n",
    "                    'winner_model_b': output[1].item(),  # モデルBの勝者確率を追加\n",
    "                    'winner_tie': output[2].item()  # 引き分けの確率を追加\n",
    "                })\n",
    "    df_results = pd.DataFrame(results)  # 結果をデータフレームに変換\n",
    "    return df_results  # データフレームを返す\n",
    "\n",
    "# テスト関数を呼び出し、結果を取得\n",
    "df_results = test(model, test_loader, device)\n",
    "# 結果を表示\n",
    "df_results\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T09:08:05.640383Z",
     "iopub.status.busy": "2024-08-02T09:08:05.639993Z",
     "iopub.status.idle": "2024-08-02T09:08:05.854033Z",
     "shell.execute_reply": "2024-08-02T09:08:05.853063Z",
     "shell.execute_reply.started": "2024-08-02T09:08:05.640353Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのテストを行う関数を定義します。\n",
    "def test(model, test_loader, device):\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    results = []  # 結果を格納するリスト\n",
    "    with torch.no_grad():  # 勾配計算を無効にしてメモリを節約\n",
    "        # テストデータローダーからバッチを取得\n",
    "        for batch in tqdm(test_loader):\n",
    "            ids, prompts, responses_a, responses_b = batch  # バッチからデータを取得\n",
    "            # モデルの出力を計算\n",
    "            outputs = model(prompts, responses_a, responses_b)\n",
    "            # 最大値のインデックスを取得\n",
    "            _, predicted_idx = torch.max(outputs.data, 1)\n",
    "            \n",
    "            # 結果をリストに追加\n",
    "            for idx, output, prediction in zip(ids, outputs, predicted_idx):\n",
    "                results.append({\n",
    "                    'id': idx.item(),  # IDを追加\n",
    "                    'winner_model_a': output[0].item(),  # モデルAの勝者確率を追加\n",
    "                    'winner_model_b': output[1].item(),  # モデルBの勝者確率を追加\n",
    "                    'winner_tie': output[2].item()  # 引き分けの確率を追加\n",
    "                })\n",
    "    df_results = pd.DataFrame(results)  # 結果をデータフレームに変換\n",
    "    return df_results  # データフレームを返す\n",
    "\n",
    "# テスト関数を呼び出し、結果を取得\n",
    "df_results = test(model, test_loader, device)\n",
    "# 結果を表示\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelId": 98230,
     "modelInstanceId": 73373,
     "sourceId": 87350,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
