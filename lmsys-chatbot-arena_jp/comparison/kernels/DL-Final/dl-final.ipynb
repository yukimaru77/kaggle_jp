{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea2d692d",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、「LMSYS - Chatbot Arena」コンペティションに関連するタスクに取り組んでいます。目的は、異なる大規模言語モデル（LLM）が生成した応答に基づいて、どちらのモデルの応答がユーザーに好まれるかを予測することです。\n",
    "\n",
    "## 問題の取り組み\n",
    "Notebookでは、ユーザーのプロンプトとそれに対する二つのモデルの応答を組み合わせたテキストデータを使用して、モデルの応答の好みを予測します。具体的には、トレーニングデータを取得し、トークン化してラベル付きデータを準備し、最終的に深層学習モデルをトレーニングしてテストデータに対する予測を行います。\n",
    "\n",
    "## 使用された手法とライブラリ\n",
    "以下の手法とライブラリが使用されています：\n",
    "\n",
    "1. **ライブラリのインポート**:\n",
    "   - 基本的なオペレーションのために`os`, `gc`, `re`, `time`, `random`などの標準ライブラリを使用。\n",
    "   - 数値計算とデータ操作のために`NumPy`と`Pandas`を使用。\n",
    "   - ビジュアライゼーションのために`Matplotlib`をインポート。\n",
    "   - トークン化と深層学習モデルのために`PyTorch`と`Transformers`ライブラリを使用。\n",
    "   - モデル評価のために`sklearn.metrics`から`accuracy_score`をインポート。\n",
    "\n",
    "2. **データの前処理**:\n",
    "   - トレーニングデータの読み込み、ユーザーのプロンプトとモデルの応答を組み合わせた新しいテキスト列を作成。\n",
    "   - 入力テキストをトークン化し、入力IDとアテンションマスクを生成。\n",
    "\n",
    "3. **モデルの構築**:\n",
    "   - Kerasを用いてLSTM（長短期記憶）とCNN（畳み込みニューラルネットワーク）のアーキテクチャを組み合わせた複合モデルを定義。バッチ正規化やドロップアウトなどのテクニックを使用して、過学習を防止。\n",
    "   - モデルのコンパイルとトレーニングが行われ、精度や損失といったメトリクスで評価されます。\n",
    "\n",
    "4. **予測と提出ファイルの作成**:\n",
    "   - テストデータに対してモデルを適用し、予測を行った後、結果をCSVフォーマットで保存します。\n",
    "\n",
    "このNotebookは、深層学習を利用して人間の好みに基づく応答の予測を行うための包括的な手法を示しており、実際の機械学習パイプラインにおける重要な工程を構成しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3c307a",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は与えられたJupyter notebookの内容に基づいて、機械学習・深層学習の初心者がつまずきそうなマイナーな専門用語や特有のドメイン知識に関する解説です。\n",
    "\n",
    "1. **トークナイザー (Tokenizer)**:\n",
    "   テキストデータを処理する際に、文章を単語やサブ単語に分割するツール。自然言語処理では、モデルに入力するためにテキストを数値に変換する必要があり、そのための第一歩がトークナイザーによるトークン化である。\n",
    "\n",
    "2. **パディング (Padding)**:\n",
    "   不足する長さの情報を埋めるために適用される手法。Deep Learningでは、入力データのサイズを揃えるために、特定の長さまで無意味なデータ（例えば、0）を追加することが多い。これはLSTMやCNNなどのモデルが一定のサイズのデータを要求するために必要である。\n",
    "\n",
    "3. **アテンションマスク (Attention Mask)**:\n",
    "   Attention機構を持つモデル（特にTransformerアーキテクチャ）で、パディングされた部分をモデルが無視できるようにするためのマスク。値が0の位置は無視され、1の位置のみが計算に使われる。\n",
    "\n",
    "4. **バッチ正規化 (Batch Normalization)**:\n",
    "   ニューラルネットワークのトレーニング中に、各ミニバッチの出力を正規化する技術。これにより、学習の安定性と速度が向上し、過学習を防ぐ助けとなる。特に深いネットワークで有効。\n",
    "\n",
    "5. **ドロップアウト (Dropout)**:\n",
    "   学習中にランダムにニューロンを無効化（0にする）する手法。これにより、過学習を防ぎ、モデルの一般化能力を向上させる。特に深層学習モデルでよく使用される。\n",
    "\n",
    "6. **グローバル最大プーリング (Global Max Pooling)**:\n",
    "   畳み込みニューラルネットワークの出力を圧縮する手法で、各フィルターから最大の値を取得し、新たな特徴ベクトルを形成する。この手法は、特徴の次元削減や、異なるサイズの入力に対応するために有用。\n",
    "\n",
    "7. **LSTM (長短期記憶) (Long Short-Term Memory)**:\n",
    "   RNN（リカレントニューラルネットワーク）の一種で、長期依存関係を学習するために設計された。このモデルは、情報の保持と忘却を制御するゲート構造を持つ。\n",
    "\n",
    "8. **アダデルタ (Adadelta)**:\n",
    "   学習率を調整するオプティマイザーの一種で、過去の勾配の情報を使用して更新を行う。これにより、学習率が適応的に変化し、モデルの収束を助ける。\n",
    "\n",
    "9. **エポック (Epoch)**:\n",
    "   データセット全体がモデルを通過した回数を指し、トレーニングプロセスにおいて重要な概念。エポック数が多すぎると過学習が発生しやすくなる。\n",
    "\n",
    "10. **カテゴリカルクロスエントロピー (Categorical Crossentropy)**:\n",
    "   多クラス分類において、ターゲットと予測の間の差異を測定するために使われる損失関数。予測確率が正解ラベルに近いほど損失が低くなる。\n",
    "\n",
    "これらの用語について理解しておくと、ノートブックのコードやその背後にある理論をより深く理解できるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5776c626",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Import libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3002dd0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, AutoModel\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import torch.nn.functional as F\n",
    "np.random.seed(1337)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os  # オペレーティングシステムとのやり取りをするためのライブラリをインポートします\n",
    "import gc  # ガーベジコレクションを扱うためのライブラリをインポートします\n",
    "import re  # 正規表現を使用するためのライブラリをインポートします\n",
    "from time import time  # 時間を計測するためのtime関数をインポートします\n",
    "import random  # ランダムな数値を生成するためのライブラリをインポートします\n",
    "import warnings  # 警告を管理するためのライブラリをインポートします\n",
    "import numpy as np  # 数値計算を行うためのNumPyライブラリをインポートします\n",
    "import pandas as pd  # データ操作と解析を行うためのPandasライブラリをインポートします\n",
    "import matplotlib.pyplot as plt  # グラフを描画するためのMatplotlibライブラリをインポートします\n",
    "from tqdm.auto import tqdm  # 進捗状況を表示するためのtqdmライブラリをインポートします\n",
    "\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "import transformers  # トランスフォーマモデルを扱うためのライブラリをインポートします\n",
    "from sklearn.metrics import accuracy_score  # 精度を計算するための関数をインポートします\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, AutoModel  # 自動トークナイザーやLlamaモデルをインポートします\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer  # 原因モデルとトークナイザーをインポートします\n",
    "import torch.nn.functional as F  # PyTorchの関数を扱うためのモジュールをインポートします\n",
    "\n",
    "np.random.seed(1337)  # NumPyの乱数生成のシードを設定します。これにより、結果の再現性が確保されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:07:36.874819Z",
     "iopub.status.busy": "2024-07-27T09:07:36.874432Z",
     "iopub.status.idle": "2024-07-27T09:07:36.883946Z",
     "shell.execute_reply": "2024-07-27T09:07:36.88256Z",
     "shell.execute_reply.started": "2024-07-27T09:07:36.874773Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # オペレーティングシステムとのやり取りをするためのライブラリをインポートします\n",
    "import gc  # ガーベジコレクションを扱うためのライブラリをインポートします\n",
    "import re  # 正規表現を使用するためのライブラリをインポートします\n",
    "from time import time  # 時間を計測するためのtime関数をインポートします\n",
    "import random  # ランダムな数値を生成するためのライブラリをインポートします\n",
    "import warnings  # 警告を管理するためのライブラリをインポートします\n",
    "import numpy as np  # 数値計算を行うためのNumPyライブラリをインポートします\n",
    "import pandas as pd  # データ操作と解析を行うためのPandasライブラリをインポートします\n",
    "import matplotlib.pyplot as plt  # グラフを描画するためのMatplotlibライブラリをインポートします\n",
    "from tqdm.auto import tqdm  # 進捗状況を表示するためのtqdmライブラリをインポートします\n",
    "\n",
    "import torch  # PyTorchライブラリをインポートします\n",
    "import transformers  # トランスフォーマモデルを扱うためのライブラリをインポートします\n",
    "from sklearn.metrics import accuracy_score  # 精度を計算するための関数をインポートします\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, AutoModel  # 自動トークナイザーやLlamaモデルをインポートします\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer  # 原因モデルとトークナイザーをインポートします\n",
    "import torch.nn.functional as F  # PyTorchの関数を扱うためのモジュールをインポートします\n",
    "\n",
    "np.random.seed(1337)  # NumPyの乱数生成のシードを設定します。これにより、結果の再現性が確保されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec099f5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenizer\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイザー\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723597c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = \"/kaggle/input/llama-3/transformers/70b-chat-hf/1/llama3-70b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = 'right'\n",
    "tokenizer.add_eos_token = True\n",
    "\n",
    "# save tokenizer to load offline during inference\n",
    "tokenizer.save_pretrained('tokenizer')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = \"/kaggle/input/llama-3/transformers/70b-chat-hf/1/llama3-70b-chat-hf\"  # 使用するモデルのパスを指定します\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)  # モデルからトークナイザーを読み込みます\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定します\n",
    "tokenizer.padding_side = 'right'  # パディングを右側に適用するよう設定します\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加することを許可します\n",
    "\n",
    "# 推論中にオフラインでトークナイザーをロードするために保存します\n",
    "tokenizer.save_pretrained('tokenizer')  # トークナイザーの設定を指定したフォルダに保存します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:07:36.886467Z",
     "iopub.status.busy": "2024-07-27T09:07:36.886008Z"
    }
   },
   "outputs": [],
   "source": [
    "model = \"/kaggle/input/llama-3/transformers/70b-chat-hf/1/llama3-70b-chat-hf\"  # 使用するモデルのパスを指定します\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)  # モデルからトークナイザーを読み込みます\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンと同じに設定します\n",
    "tokenizer.padding_side = 'right'  # パディングを右側に適用するよう設定します\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加することを許可します\n",
    "\n",
    "# 推論中にオフラインでトークナイザーをロードするために保存します\n",
    "tokenizer.save_pretrained('tokenizer')  # トークナイザーの設定を指定したフォルダに保存します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049a0a58",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Utility function giving token length\n",
    "def get_token_lengths(texts):\n",
    "    # tokenize and receive input_ids for reach text\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # return length of inputs_ids for each text\n",
    "    return [len(t) for t in input_ids]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Utility function giving token length\n",
    "# トークンの長さを返すユーティリティ関数を定義します\n",
    "def get_token_lengths(texts):\n",
    "    # 各テキストに対してトークン化し、input_idsを取得します\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']  # テキストをトークン化し、NumPy形式の入力IDを取得します\n",
    "    # 各テキストに対するinput_idsの長さを返します\n",
    "    return [len(t) for t in input_ids]  # 各トークンの長さをリストとして返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function giving token length\n",
    "# トークンの長さを返すユーティリティ関数を定義します\n",
    "def get_token_lengths(texts):\n",
    "    # 各テキストに対してトークン化し、input_idsを取得します\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']  # テキストをトークン化し、NumPy形式の入力IDを取得します\n",
    "    # 各テキストに対するinput_idsの長さを返します\n",
    "    return [len(t) for t in input_ids]  # 各トークンの長さをリストとして返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0cb099",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Prepare train set\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トレーニングセットの準備\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7c3ad9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "train.head(5)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込みます\n",
    "train.head(5)  # トレーニングセットの最初の5行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込みます\n",
    "train.head(5)  # トレーニングセットの最初の5行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1384db6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def put_text(train):\n",
    "    train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A:\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "    return train\n",
    "\n",
    "train = put_text(train)\n",
    "print(train['text'][0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def put_text(train):\n",
    "    # 新しいテキスト列を作成し、ユーザーのプロンプトとモデルAおよびモデルBの応答を組み合わせます\n",
    "    train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A:\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "    return train  # 変更を加えたトレーニングデータを返します\n",
    "\n",
    "train = put_text(train)  # トレーニングデータに新しいテキスト列を追加します\n",
    "print(train['text'][0])  # 新しく作成したテキスト列の最初の要素を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_text(train):\n",
    "    # 新しいテキスト列を作成し、ユーザーのプロンプトとモデルAおよびモデルBの応答を組み合わせます\n",
    "    train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A:\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "    return train  # 変更を加えたトレーニングデータを返します\n",
    "\n",
    "train = put_text(train)  # トレーニングデータに新しいテキスト列を追加します\n",
    "print(train['text'][0])  # 新しく作成したテキスト列の最初の要素を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60b9e4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "\n",
    "train = put_text(train)\n",
    "print(train['text'][0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def process(input_str):\n",
    "    # 入力文字列から角括弧を取り除きます\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # 文字列を分割して、各文から囲いを除きます\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return ' '.join(sentences)  # 文をスペースで結合して返します\n",
    "\n",
    "# 'prompt', 'response_a', 'response_b'列の各値にprocess関数を適用します\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "train = put_text(train)  # 新しいテキスト列をトレーニングデータに再度追加します\n",
    "print(train['text'][0])  # 更新されたテキスト列の最初の要素を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(input_str):\n",
    "    # 入力文字列から角括弧を取り除きます\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # 文字列を分割して、各文から囲いを除きます\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return ' '.join(sentences)  # 文をスペースで結合して返します\n",
    "\n",
    "# 'prompt', 'response_a', 'response_b'列の各値にprocess関数を適用します\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "train = put_text(train)  # 新しいテキスト列をトレーニングデータに再度追加します\n",
    "print(train['text'][0])  # 更新されたテキスト列の最初の要素を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f7dd66",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])\n",
    "\n",
    "# prepare label for model\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n",
    "\n",
    "# Display data\n",
    "display(train.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # トレーニングデータの'text'列に基づいてトークンのカウントを追加します\n",
    "\n",
    "# モデル用のラベルを準備します\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)  # 各行の勝者モデルをラベルとして取得します\n",
    "\n",
    "# データを表示します\n",
    "display(train.head())  # 最初の数行のトレーニングデータを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # トレーニングデータの'text'列に基づいてトークンのカウントを追加します\n",
    "\n",
    "# モデル用のラベルを準備します\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)  # 各行の勝者モデルをラベルとして取得します\n",
    "\n",
    "# データを表示します\n",
    "display(train.head())  # 最初の数行のトレーニングデータを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df66b13",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train.label.value_counts()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train.label.value_counts()  # 各ラベルの出現回数をカウントして表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.label.value_counts()  # 各ラベルの出現回数をカウントして表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0e376",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# token Count\n",
    "display(train['token_count'].describe().to_frame().astype(int))\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークンのカウント\n",
    "display(train['token_count'].describe().to_frame().astype(int))  # トークンのカウントに関する統計情報を計算し、整数型のデータフレームとして表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークンのカウント\n",
    "display(train['token_count'].describe().to_frame().astype(int))  # トークンのカウントに関する統計情報を計算し、整数型のデータフレームとして表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d26fc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# get length of tokens which covers 90% of data, we'll still take 1024 length!\n",
    "np.percentile(train['token_count'], 90)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データの90%をカバーするトークンの長さを取得しますが、1024の長さを使用します\n",
    "np.percentile(train['token_count'], 90)  # トークンのカウントの90パーセンタイルを計算します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの90%をカバーするトークンの長さを取得しますが、1024の長さを使用します\n",
    "np.percentile(train['token_count'], 90)  # トークンのカウントの90パーセンタイルを計算します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8972f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークン化\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6617fc1e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Tokenize Data\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')\n",
    "\n",
    "# Input IDs are the token IDs\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "# Attention Masks to Ignore Padding Tokens\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "# Label of Texts\n",
    "LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')\n",
    "print(f'LABELS shape: {LABELS.shape}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データをトークン化します\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(),  # テキストをリストに変換してトークン化します\n",
    "    max_length=1024,  # 最大長を1024に設定します\n",
    "    truncation=True,  # 長すぎるトークンは切り詰めます\n",
    "    return_tensors='np')  # NumPy形式のテンソルを返します\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_IDS = tokens['input_ids']  # トークン化された入力IDを取得します\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得します\n",
    "# テキストのラベル\n",
    "LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values  # ラベルを取得します\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示します\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをトークン化します\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(),  # テキストをリストに変換してトークン化します\n",
    "    max_length=1024,  # 最大長を1024に設定します\n",
    "    truncation=True,  # 長すぎるトークンは切り詰めます\n",
    "    return_tensors='np')  # NumPy形式のテンソルを返します\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_IDS = tokens['input_ids']  # トークン化された入力IDを取得します\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得します\n",
    "# テキストのラベル\n",
    "LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values  # ラベルを取得します\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示します\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f694d072",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "max_features = 14300\n",
    "max_len = 1024\n",
    "maxlen = max_len\n",
    "batch_size = 16\n",
    "embedding_dims = 100\n",
    "nb_filter = 150\n",
    "filter_length = 3\n",
    "hidden_dims = 100\n",
    "nb_epoch = 100\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "max_features = 14300  # モデルで使用する最大特徴数を設定します\n",
    "max_len = 1024  # トークンの最大長を設定します\n",
    "maxlen = max_len  # max_lenをmaxlenに割り当てます\n",
    "batch_size = 16  # バッチサイズを設定します\n",
    "embedding_dims = 100  # 埋め込み次元の数を設定します\n",
    "nb_filter = 150  # フィルタの数を設定します\n",
    "filter_length = 3  # フィルタの長さを設定します\n",
    "hidden_dims = 100  # 隠れ層の次元の数を設定します\n",
    "nb_epoch = 100  # エポック数を設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 14300  # モデルで使用する最大特徴数を設定します\n",
    "max_len = 1024  # トークンの最大長を設定します\n",
    "maxlen = max_len  # max_lenをmaxlenに割り当てます\n",
    "batch_size = 16  # バッチサイズを設定します\n",
    "embedding_dims = 100  # 埋め込み次元の数を設定します\n",
    "nb_filter = 150  # フィルタの数を設定します\n",
    "filter_length = 3  # フィルタの長さを設定します\n",
    "hidden_dims = 100  # 隠れ層の次元の数を設定します\n",
    "nb_epoch = 100  # エポック数を設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a05cc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta,Adamax\n",
    "from keras.preprocessing import sequence as sq\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda,Input,TimeDistributed,Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session as K\n",
    "num_samples = INPUT_IDS.shape[0]\n",
    "\n",
    "# Số lượng mẫu cho X_valid (20% của X_train)\n",
    "num_valid_samples = int(num_samples * 0.2)\n",
    "\n",
    "# Xáo trộn các chỉ số của X_train\n",
    "indices = np.random.permutation(num_samples)\n",
    "\n",
    "# Chọn 20% chỉ số đầu tiên làm chỉ số cho X_valid\n",
    "valid_indices = indices[:num_valid_samples]\n",
    "\n",
    "# Các chỉ số còn lại làm chỉ số cho X_train\n",
    "train_indices = indices[num_valid_samples:]\n",
    "\n",
    "# Tạo X_valid và X_train mới từ các chỉ số đã chọn\n",
    "X_train = sq.pad_sequences(INPUT_IDS[train_indices], maxlen=max_len)\n",
    "X_train_attention = sq.pad_sequences(ATTENTION_MASKS[train_indices], maxlen=max_len)\n",
    "y_train = LABELS[train_indices]\n",
    "\n",
    "X_valid = sq.pad_sequences(INPUT_IDS[valid_indices], maxlen=max_len)\n",
    "X_valid_attention = sq.pad_sequences(ATTENTION_MASKS[valid_indices], maxlen=max_len)\n",
    "y_valid = LABELS[valid_indices]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from __future__ import print_function  # print_functionを将来のバージョンからインポートして、Python 2と3の互換性を持たせます\n",
    "import numpy as np  # NumPyライブラリをインポートします\n",
    "\n",
    "from keras.preprocessing import sequence  # シーケンスデータを処理するためのKerasモジュールをインポートします\n",
    "from keras.models import Sequential  # シーケンシャルモデルをインポートします\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda  # 完全結合層などのレイヤーをインポートします\n",
    "from keras.layers import Embedding  # 埋め込み層をインポートします\n",
    "from keras.layers import Convolution1D, LSTM  # 1次元畳み込み層とLSTM層をインポートします\n",
    "from keras.datasets import imdb  # IMDBデータセットをインポートします\n",
    "from keras import backend as K  # Kerasのバックエンドをインポートします\n",
    "from keras.optimizers import Adadelta, Adamax  # オプティマイザーをインポートします\n",
    "from keras.preprocessing import sequence as sq  # シーケンス処理モジュールをインポートし、sqの別名を付けます\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Input, TimeDistributed, Flatten  # その他のレイヤーをインポートします\n",
    "from keras.models import Model  # モデル推定に使用するKerasのモデルをインポートします\n",
    "from keras.callbacks import ModelCheckpoint  # モデルのチェックポイントを管理するためのコールバックをインポートします\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session as K  # TensorFlowの適切なセッション管理用のKerasバックエンドをインポートします\n",
    "num_samples = INPUT_IDS.shape[0]  # サンプルの総数を取得します\n",
    "\n",
    "# X_validのサンプル数（X_trainの20%）\n",
    "num_valid_samples = int(num_samples * 0.2)  # バリデーション用サンプル数を計算します\n",
    "\n",
    "# X_trainのインデックスをシャッフルします\n",
    "indices = np.random.permutation(num_samples)  # サンプルのインデックスをランダムに並べ替えます\n",
    "\n",
    "# 最初の20%のインデックスをX_valid用として選択します\n",
    "valid_indices = indices[:num_valid_samples]  # バリデーション用のインデックスを取得します\n",
    "\n",
    "# 残りのインデックスをX_train用として選択します\n",
    "train_indices = indices[num_valid_samples:]  # トレーニング用のインデックスを取得します\n",
    "\n",
    "# 選択したインデックスから新しいX_validとX_trainを作成します\n",
    "X_train = sq.pad_sequences(INPUT_IDS[train_indices], maxlen=max_len)  # トレーニングデータのパディングを行います\n",
    "X_train_attention = sq.pad_sequences(ATTENTION_MASKS[train_indices], maxlen=max_len)  # アテンションマスクのパディングを行います\n",
    "y_train = LABELS[train_indices]  # トレーニングラベルを設定します\n",
    "\n",
    "X_valid = sq.pad_sequences(INPUT_IDS[valid_indices], maxlen=max_len)  # バリデーションデータのパディングを行います\n",
    "X_valid_attention = sq.pad_sequences(ATTENTION_MASKS[valid_indices], maxlen=max_len)  # バリデーションのアテンションマスクのパディングを行います\n",
    "y_valid = LABELS[valid_indices]  # バリデーションラベルを設定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function  # print_functionを将来のバージョンからインポートして、Python 2と3の互換性を持たせます\n",
    "import numpy as np  # NumPyライブラリをインポートします\n",
    "\n",
    "from keras.preprocessing import sequence  # シーケンスデータを処理するためのKerasモジュールをインポートします\n",
    "from keras.models import Sequential  # シーケンシャルモデルをインポートします\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda  # 完全結合層などのレイヤーをインポートします\n",
    "from keras.layers import Embedding  # 埋め込み層をインポートします\n",
    "from keras.layers import Convolution1D, LSTM  # 1次元畳み込み層とLSTM層をインポートします\n",
    "from keras.datasets import imdb  # IMDBデータセットをインポートします\n",
    "from keras import backend as K  # Kerasのバックエンドをインポートします\n",
    "from keras.optimizers import Adadelta, Adamax  # オプティマイザーをインポートします\n",
    "from keras.preprocessing import sequence as sq  # シーケンス処理モジュールをインポートし、sqの別名を付けます\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, Input, TimeDistributed, Flatten  # その他のレイヤーをインポートします\n",
    "from keras.models import Model  # モデル推定に使用するKerasのモデルをインポートします\n",
    "from keras.callbacks import ModelCheckpoint  # モデルのチェックポイントを管理するためのコールバックをインポートします\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session as K  # TensorFlowの適切なセッション管理用のKerasバックエンドをインポートします\n",
    "num_samples = INPUT_IDS.shape[0]  # サンプルの総数を取得します\n",
    "\n",
    "# X_validのサンプル数（X_trainの20%）\n",
    "num_valid_samples = int(num_samples * 0.2)  # バリデーション用サンプル数を計算します\n",
    "\n",
    "# X_trainのインデックスをシャッフルします\n",
    "indices = np.random.permutation(num_samples)  # サンプルのインデックスをランダムに並べ替えます\n",
    "\n",
    "# 最初の20%のインデックスをX_valid用として選択します\n",
    "valid_indices = indices[:num_valid_samples]  # バリデーション用のインデックスを取得します\n",
    "\n",
    "# 残りのインデックスをX_train用として選択します\n",
    "train_indices = indices[num_valid_samples:]  # トレーニング用のインデックスを取得します\n",
    "\n",
    "# 選択したインデックスから新しいX_validとX_trainを作成します\n",
    "X_train = sq.pad_sequences(INPUT_IDS[train_indices], maxlen=max_len)  # トレーニングデータのパディングを行います\n",
    "X_train_attention = sq.pad_sequences(ATTENTION_MASKS[train_indices], maxlen=max_len)  # アテンションマスクのパディングを行います\n",
    "y_train = LABELS[train_indices]  # トレーニングラベルを設定します\n",
    "\n",
    "X_valid = sq.pad_sequences(INPUT_IDS[valid_indices], maxlen=max_len)  # バリデーションデータのパディングを行います\n",
    "X_valid_attention = sq.pad_sequences(ATTENTION_MASKS[valid_indices], maxlen=max_len)  # バリデーションのアテンションマスクのパディングを行います\n",
    "y_valid = LABELS[valid_indices]  # バリデーションラベルを設定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a550cdb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "X_train = np.array(X_train)  # トレーニングデータをNumPy配列に変換します\n",
    "y_train = np.array(y_train)  # トレーニングラベルをNumPy配列に変換します\n",
    "X_valid = np.array(X_valid)  # バリデーションデータをNumPy配列に変換します\n",
    "y_valid = np.array(y_valid)  # バリデーションラベルをNumPy配列に変換します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)  # トレーニングデータをNumPy配列に変換します\n",
    "y_train = np.array(y_train)  # トレーニングラベルをNumPy配列に変換します\n",
    "X_valid = np.array(X_valid)  # バリデーションデータをNumPy配列に変換します\n",
    "y_valid = np.array(y_valid)  # バリデーションラベルをNumPy配列に変換します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f494651e",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Define Model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルの定義\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68700985",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.layers import concatenate, Dropout, BatchNormalization, LSTM, Conv1D\n",
    "from keras.layers import  GlobalMaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "class ApplyAttentionMask(Layer):\n",
    "    def call(self, inputs):\n",
    "        embeddings, attention_mask = inputs\n",
    "        return embeddings * tf.expand_dims(attention_mask, -1)\n",
    "\n",
    "input_layer = Input(shape=(max_len,),dtype='int32', name='main_input')\n",
    "attention_masks = Input(shape=(max_len,), dtype='float32', name=\"attention_masks\")\n",
    "\n",
    "emb_layer = Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=max_len\n",
    "                      )(input_layer)\n",
    "\n",
    "masked_embeddings = ApplyAttentionMask(name='apply_attention_mask')([emb_layer, attention_masks])\n",
    "\n",
    "# LSTM branch (with Batch Normalization and Dropout)\n",
    "lstm_out = LSTM(128, return_sequences=True)(masked_embeddings)\n",
    "lstm_out = BatchNormalization()(lstm_out) # Batch Normalization helps to normalize activations and speed up convergence\n",
    "lstm_out = Dropout(0.5)(lstm_out) # Dropout = 0.5 helps to prevent overfitting\n",
    "lstm_out = LSTM(64, return_sequences=True)(lstm_out)\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "lstm_out = LSTM(32)(lstm_out)\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "# CNN layer branch (with Batch Normalization and Dropout)\n",
    "cnn_out = Conv1D(64, 5, activation='relu')(masked_embeddings)\n",
    "cnn_out = BatchNormalization()(cnn_out)\n",
    "cnn_out = Dropout(0.5)(cnn_out)\n",
    "cnn_out = Conv1D(32, 5, activation='relu')(cnn_out)\n",
    "cnn_out = BatchNormalization()(cnn_out)\n",
    "cnn_out = Dropout(0.5)(cnn_out)\n",
    "cnn_out = GlobalMaxPooling1D()(cnn_out)\n",
    "\n",
    "\n",
    "# Concatenate LSTM and CNN outputs\n",
    "merged = concatenate([lstm_out, cnn_out])\n",
    "merged = Dense(32, activation='sigmoid')(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.5)(merged)\n",
    "pred = Dense(3, activation='softmax')(merged)\n",
    "\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[input_layer, attention_masks], outputs=[pred])\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.75, epsilon=1e-06)\n",
    "adamax = Adamax(learning_rate=0.001)\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.layers import Layer  # Kerasのレイヤーをインポートします\n",
    "from keras.layers import concatenate, Dropout, BatchNormalization, LSTM, Conv1D  # 各種レイヤーをインポートします\n",
    "from keras.layers import GlobalMaxPooling1D  # 1次元の全体最大プーリングレイヤーをインポートします\n",
    "import tensorflow as tf  # TensorFlowをインポートします\n",
    "\n",
    "class ApplyAttentionMask(Layer):\n",
    "    def call(self, inputs):\n",
    "        # 埋め込みとアテンションマスクを適用する関数を定義します\n",
    "        embeddings, attention_mask = inputs\n",
    "        return embeddings * tf.expand_dims(attention_mask, -1)  # アテンションマスクを埋め込みに適用します\n",
    "\n",
    "input_layer = Input(shape=(max_len,), dtype='int32', name='main_input')  # メイン入力レイヤーを定義します\n",
    "attention_masks = Input(shape=(max_len,), dtype='float32', name=\"attention_masks\")  # アテンションマスクの入力レイヤーを定義します\n",
    "\n",
    "# 埋め込み層\n",
    "emb_layer = Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=max_len)(input_layer)  # 埋め込み層を定義します\n",
    "\n",
    "masked_embeddings = ApplyAttentionMask(name='apply_attention_mask')([emb_layer, attention_masks])  # アテンションマスクを適用します\n",
    "\n",
    "# LSTMブランチ（バッチ正規化とドロップアウトを含む）\n",
    "lstm_out = LSTM(128, return_sequences=True)(masked_embeddings)  # LSTM層を追加します\n",
    "lstm_out = BatchNormalization()(lstm_out)  # バッチ正規化を適用します\n",
    "lstm_out = Dropout(0.5)(lstm_out)  # ドロップアウトを適用して過学習を防ぎます\n",
    "lstm_out = LSTM(64, return_sequences=True)(lstm_out)  # さらにLSTM層を追加\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "lstm_out = LSTM(32)(lstm_out)  # 最後のLSTM層を追加\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "# CNNレイヤーブランチ（バッチ正規化とドロップアウトを含む）\n",
    "cnn_out = Conv1D(64, 5, activation='relu')(masked_embeddings)  # 1次元畳み込み層を追加\n",
    "cnn_out = BatchNormalization()(cnn_out)  # バッチ正規化を適用します\n",
    "cnn_out = Dropout(0.5)(cnn_out)  # ドロップアウトを適用します\n",
    "cnn_out = Conv1D(32, 5, activation='relu')(cnn_out)  # さらに1次元畳み込み層を追加\n",
    "cnn_out = BatchNormalization()(cnn_out)\n",
    "cnn_out = Dropout(0.5)(cnn_out)\n",
    "cnn_out = GlobalMaxPooling1D()(cnn_out)  # グローバル最大プーリングを適用します\n",
    "\n",
    "# LSTMとCNNの出力を連結します\n",
    "merged = concatenate([lstm_out, cnn_out])  # 両者の出力を結合します\n",
    "merged = Dense(32, activation='sigmoid')(merged)  # 隠れ層を追加します\n",
    "merged = BatchNormalization()(merged)  # バッチ正規化を適用します\n",
    "merged = Dropout(0.5)(merged)  # ドロップアウトを適用します\n",
    "pred = Dense(3, activation='softmax')(merged)  # 出力層を追加します\n",
    "\n",
    "# モデルを構築します\n",
    "model = Model(inputs=[input_layer, attention_masks], outputs=[pred])  # モデルとして入力と出力を指定します\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.75, epsilon=1e-06)  # Adadeltaオプティマイザーを設定します\n",
    "adamax = Adamax(learning_rate=0.001)  # Adamaxオプティマイザーを設定します\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])  # モデルをコンパイルします\n",
    "model.summary()  # モデルの概要を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer  # Kerasのレイヤーをインポートします\n",
    "from keras.layers import concatenate, Dropout, BatchNormalization, LSTM, Conv1D  # 各種レイヤーをインポートします\n",
    "from keras.layers import GlobalMaxPooling1D  # 1次元の全体最大プーリングレイヤーをインポートします\n",
    "import tensorflow as tf  # TensorFlowをインポートします\n",
    "\n",
    "class ApplyAttentionMask(Layer):\n",
    "    def call(self, inputs):\n",
    "        # 埋め込みとアテンションマスクを適用する関数を定義します\n",
    "        embeddings, attention_mask = inputs\n",
    "        return embeddings * tf.expand_dims(attention_mask, -1)  # アテンションマスクを埋め込みに適用します\n",
    "\n",
    "input_layer = Input(shape=(max_len,), dtype='int32', name='main_input')  # メイン入力レイヤーを定義します\n",
    "attention_masks = Input(shape=(max_len,), dtype='float32', name=\"attention_masks\")  # アテンションマスクの入力レイヤーを定義します\n",
    "\n",
    "# 埋め込み層\n",
    "emb_layer = Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=max_len)(input_layer)  # 埋め込み層を定義します\n",
    "\n",
    "masked_embeddings = ApplyAttentionMask(name='apply_attention_mask')([emb_layer, attention_masks])  # アテンションマスクを適用します\n",
    "\n",
    "# LSTMブランチ（バッチ正規化とドロップアウトを含む）\n",
    "lstm_out = LSTM(128, return_sequences=True)(masked_embeddings)  # LSTM層を追加します\n",
    "lstm_out = BatchNormalization()(lstm_out)  # バッチ正規化を適用します\n",
    "lstm_out = Dropout(0.5)(lstm_out)  # ドロップアウトを適用して過学習を防ぎます\n",
    "lstm_out = LSTM(64, return_sequences=True)(lstm_out)  # さらにLSTM層を追加\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "lstm_out = LSTM(32)(lstm_out)  # 最後のLSTM層を追加\n",
    "lstm_out = BatchNormalization()(lstm_out)\n",
    "lstm_out = Dropout(0.5)(lstm_out)\n",
    "\n",
    "# CNNレイヤーブランチ（バッチ正規化とドロップアウトを含む）\n",
    "cnn_out = Conv1D(64, 5, activation='relu')(masked_embeddings)  # 1次元畳み込み層を追加\n",
    "cnn_out = BatchNormalization()(cnn_out)  # バッチ正規化を適用します\n",
    "cnn_out = Dropout(0.5)(cnn_out)  # ドロップアウトを適用します\n",
    "cnn_out = Conv1D(32, 5, activation='relu')(cnn_out)  # さらに1次元畳み込み層を追加\n",
    "cnn_out = BatchNormalization()(cnn_out)\n",
    "cnn_out = Dropout(0.5)(cnn_out)\n",
    "cnn_out = GlobalMaxPooling1D()(cnn_out)  # グローバル最大プーリングを適用します\n",
    "\n",
    "# LSTMとCNNの出力を連結します\n",
    "merged = concatenate([lstm_out, cnn_out])  # 両者の出力を結合します\n",
    "merged = Dense(32, activation='sigmoid')(merged)  # 隠れ層を追加します\n",
    "merged = BatchNormalization()(merged)  # バッチ正規化を適用します\n",
    "merged = Dropout(0.5)(merged)  # ドロップアウトを適用します\n",
    "pred = Dense(3, activation='softmax')(merged)  # 出力層を追加します\n",
    "\n",
    "# モデルを構築します\n",
    "model = Model(inputs=[input_layer, attention_masks], outputs=[pred])  # モデルとして入力と出力を指定します\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.75, epsilon=1e-06)  # Adadeltaオプティマイザーを設定します\n",
    "adamax = Adamax(learning_rate=0.001)  # Adamaxオプティマイザーを設定します\n",
    "model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])  # モデルをコンパイルします\n",
    "model.summary()  # モデルの概要を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9068bab4",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Training\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トレーニング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1ae3b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def clip_indices(data, max_index):\n",
    "    return np.where(data >= max_index, max_index - 1, data)\n",
    "X_train = clip_indices(X_train, 14300)\n",
    "X_train_attention = clip_indices(X_train_attention, 14300)\n",
    "X_valid = clip_indices(X_valid, 14300)\n",
    "X_valid_attention = clip_indices(X_valid_attention, 14300)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def clip_indices(data, max_index):\n",
    "    # インデックスが最大のインデックスを超えた場合、最大インデックス-1にクリップします\n",
    "    return np.where(data >= max_index, max_index - 1, data)\n",
    "\n",
    "X_train = clip_indices(X_train, 14300)  # トレーニングデータのインデックスをクリップします\n",
    "X_train_attention = clip_indices(X_train_attention, 14300)  # トレーニングアテンションマスクのインデックスをクリップします\n",
    "X_valid = clip_indices(X_valid, 14300)  # バリデーションデータのインデックスをクリップします\n",
    "X_valid_attention = clip_indices(X_valid_attention, 14300)  # バリデーションアテンションマスクのインデックスをクリップします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_indices(data, max_index):\n",
    "    # インデックスが最大のインデックスを超えた場合、最大インデックス-1にクリップします\n",
    "    return np.where(data >= max_index, max_index - 1, data)\n",
    "\n",
    "X_train = clip_indices(X_train, 14300)  # トレーニングデータのインデックスをクリップします\n",
    "X_train_attention = clip_indices(X_train_attention, 14300)  # トレーニングアテンションマスクのインデックスをクリップします\n",
    "X_valid = clip_indices(X_valid, 14300)  # バリデーションデータのインデックスをクリップします\n",
    "X_valid_attention = clip_indices(X_valid_attention, 14300)  # バリデーションアテンションマスクのインデックスをクリップします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11fa54",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint('/kaggle/working/model.keras',\n",
    "                                 monitor='val_acc', verbose=0, save_best_only=True,\n",
    "                                 mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)\n",
    "\n",
    "model.fit([X_train,X_train_attention], y_train,\n",
    "          batch_size=16,\n",
    "          epochs=nb_epoch,\n",
    "#           callbacks=[checkpoint, early_stopping],\n",
    "          callbacks=[early_stopping],\n",
    "          validation_data=([X_valid,X_valid_attention], y_valid))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from keras.callbacks import EarlyStopping  # 早期停止のためのコールバックをインポートします\n",
    "checkpoint = ModelCheckpoint('/kaggle/working/model.keras',\n",
    "                                 monitor='val_acc', verbose=0, save_best_only=True,\n",
    "                                 mode='max')  # モデルのチェックポイントを設定します\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)  # 早期停止を設定します\n",
    "\n",
    "# モデルをトレーニングします\n",
    "model.fit([X_train, X_train_attention], y_train,\n",
    "          batch_size=16,  # バッチサイズを設定します\n",
    "          epochs=nb_epoch,  # エポック数を設定します\n",
    "#           callbacks=[checkpoint, early_stopping],  # チェックポイントと早期停止のコールバック（コメントアウト）\n",
    "          callbacks=[early_stopping],  # 早期停止のコールバックのみ使用します\n",
    "          validation_data=([X_valid, X_valid_attention], y_valid))  # バリデーションデータを指定します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping  # 早期停止のためのコールバックをインポートします\n",
    "checkpoint = ModelCheckpoint('/kaggle/working/model.keras',\n",
    "                                 monitor='val_acc', verbose=0, save_best_only=True,\n",
    "                                 mode='max')  # モデルのチェックポイントを設定します\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)  # 早期停止を設定します\n",
    "\n",
    "# モデルをトレーニングします\n",
    "model.fit([X_train, X_train_attention], y_train,\n",
    "          batch_size=16,  # バッチサイズを設定します\n",
    "          epochs=nb_epoch,  # エポック数を設定します\n",
    "#           callbacks=[checkpoint, early_stopping],  # チェックポイントと早期停止のコールバック（コメントアウト）\n",
    "          callbacks=[early_stopping],  # 早期停止のコールバックのみ使用します\n",
    "          validation_data=([X_valid, X_valid_attention], y_valid))  # バリデーションデータを指定します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278fc3ae",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save('model.keras', overwrite=True)\n",
    "model.save_weights(\"model.weights.h5\", overwrite=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.compile(loss='categorical_crossentropy',  # 損失関数をカテゴリカルクロスエントロピーとして設定します\n",
    "              optimizer='adadelta',  # オプティマイザーをAdadeltaとして設定します\n",
    "              metrics=['accuracy'])  # 評価指標として精度を設定します\n",
    "\n",
    "model.save('model.keras', overwrite=True)  # モデル全体を指定したファイル名で保存します\n",
    "model.save_weights(\"model.weights.h5\", overwrite=True)  # モデルの重みのみを保存します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',  # 損失関数をカテゴリカルクロスエントロピーとして設定します\n",
    "              optimizer='adadelta',  # オプティマイザーをAdadeltaとして設定します\n",
    "              metrics=['accuracy'])  # 評価指標として精度を設定します\n",
    "\n",
    "model.save('model.keras', overwrite=True)  # モデル全体を指定したファイル名で保存します\n",
    "model.save_weights(\"model.weights.h5\", overwrite=True)  # モデルの重みのみを保存します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ff999",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Test Model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルのテスト\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd637166",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Null' for training\n",
    "indexes = test[(test.response_a == 'null') & (test.response_b == 'null')].index\n",
    "test.drop(indexes, inplace=True)\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")\n",
    "print('Total train samples: ', len(test))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます\n",
    "\n",
    "# プロンプトと応答を処理します\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # プロンプト列にprocess関数を適用します\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # モデルAの応答列にprocess関数を適用します\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # モデルBの応答列にprocess関数を適用します\n",
    "\n",
    "# トレーニングにおいて'null'を含む行を削除します\n",
    "indexes = test[(test.response_a == 'null') & (test.response_b == 'null')].index  # 'null'応答を持つインデックスを取得します\n",
    "test.drop(indexes, inplace=True)  # 該当行をデータフレームから削除します\n",
    "test.reset_index(inplace=True, drop=True)  # インデックスをリセットします\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")  # 削除された'null'応答の行数を表示します\n",
    "print('Total train samples: ', len(test))  # 残ったトレーニングサンプルの総数を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます\n",
    "\n",
    "# プロンプトと応答を処理します\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # プロンプト列にprocess関数を適用します\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # モデルAの応答列にprocess関数を適用します\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # モデルBの応答列にprocess関数を適用します\n",
    "\n",
    "# トレーニングにおいて'null'を含む行を削除します\n",
    "indexes = test[(test.response_a == 'null') & (test.response_b == 'null')].index  # 'null'応答を持つインデックスを取得します\n",
    "test.drop(indexes, inplace=True)  # 該当行をデータフレームから削除します\n",
    "test.reset_index(inplace=True, drop=True)  # インデックスをリセットします\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")  # 削除された'null'応答の行数を表示します\n",
    "print('Total train samples: ', len(test))  # 残ったトレーニングサンプルの総数を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e331e6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test.head()  # テストデータの最初の5行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()  # テストデータの最初の5行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dd5805",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A:\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(test['text'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A:\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + test['response_b']  # テストデータに新しいテキスト列を追加します\n",
    "print(test['text'])  # 新しく作成したテキスト列の内容を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A:\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + test['response_b']  # テストデータに新しいテキスト列を追加します\n",
    "print(test['text'])  # 新しく作成したテキスト列の内容を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100cfa12",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Tokenize Data\n",
    "tokens_test = tokenizer(\n",
    "    test['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')\n",
    "\n",
    "# Input IDs are the token IDs\n",
    "INPUT_test = tokens_test['input_ids']\n",
    "# Attention Masks to Ignore Padding Tokens\n",
    "ATTENTION_MASKS2 = tokens_test['attention_mask']\n",
    "\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_test.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS2.shape}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータをトークン化します\n",
    "tokens_test = tokenizer(\n",
    "    test['text'].tolist(),  # テキストをリストに変換してトークン化します\n",
    "    max_length=1024,  # 最大長を1024に設定します\n",
    "    truncation=True,  # 長すぎるトークンは切り詰めます\n",
    "    return_tensors='np')  # NumPy形式のテンソルを返します\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_test = tokens_test['input_ids']  # トークン化された入力IDを取得します\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS2 = tokens_test['attention_mask']  # アテンションマスクを取得します\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_test.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS2.shape}')  # 入力IDとアテンションマスクの形状を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータをトークン化します\n",
    "tokens_test = tokenizer(\n",
    "    test['text'].tolist(),  # テキストをリストに変換してトークン化します\n",
    "    max_length=1024,  # 最大長を1024に設定します\n",
    "    truncation=True,  # 長すぎるトークンは切り詰めます\n",
    "    return_tensors='np')  # NumPy形式のテンソルを返します\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_test = tokens_test['input_ids']  # トークン化された入力IDを取得します\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS2 = tokens_test['attention_mask']  # アテンションマスクを取得します\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_test.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS2.shape}')  # 入力IDとアテンションマスクの形状を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26087493",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "X_test = sq.pad_sequences(INPUT_test, maxlen=max_len)\n",
    "X_test_attention = sq.pad_sequences(ATTENTION_MASKS2, maxlen=max_len)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "X_test = sq.pad_sequences(INPUT_test, maxlen=max_len)  # テストデータの入力IDをパディングして最大長に揃えます\n",
    "X_test_attention = sq.pad_sequences(ATTENTION_MASKS2, maxlen=max_len)  # テストデータのアテンションマスクをパディングして最大長に揃えます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sq.pad_sequences(INPUT_test, maxlen=max_len)  # テストデータの入力IDをパディングして最大長に揃えます\n",
    "X_test_attention = sq.pad_sequences(ATTENTION_MASKS2, maxlen=max_len)  # テストデータのアテンションマスクをパディングして最大長に揃えます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efe0ad1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test  # テストデータフレームの内容を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  # テストデータフレームの内容を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69934b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "y_predict = model.predict([X_test,X_test_attention])\n",
    "y_predict\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "y_predict = model.predict([X_test, X_test_attention])  # テストデータに対する予測を行います\n",
    "y_predict  # 予測結果を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict([X_test, X_test_attention])  # テストデータに対する予測を行います\n",
    "y_predict  # 予測結果を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7cb9b4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "winner_df = pd.DataFrame(y_predict, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "result_df = pd.concat([test['id'], winner_df], axis=1)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "winner_df = pd.DataFrame(y_predict, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])  # 予測結果をデータフレームに変換します\n",
    "result_df = pd.concat([test['id'], winner_df], axis=1)  # テストデータのIDと予測結果を結合して新しいデータフレームを作成します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df = pd.DataFrame(y_predict, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])  # 予測結果をデータフレームに変換します\n",
    "result_df = pd.concat([test['id'], winner_df], axis=1)  # テストデータのIDと予測結果を結合して新しいデータフレームを作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3ef60c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "result_df.to_csv('submission.csv', index=False)\n",
    "result_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "result_df.to_csv('submission.csv', index=False)  # 予測結果をCSVファイルとして保存します\n",
    "result_df  # 最終的な結果データフレームを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', index=False)  # 予測結果をCSVファイルとして保存します\n",
    "result_df  # 最終的な結果データフレームを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3c8b0",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "____________________\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "____________________\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec593bd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # Import necessary libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# # Load the data\n",
    "# train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "# test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# # Inspect the data\n",
    "# print(train.head())\n",
    "# print(test.head())\n",
    "\n",
    "# # Data Preprocessing\n",
    "# # Combine responses into one text feature\n",
    "# train['response_combined'] = train['response_a'] + ' ' + train['response_b']\n",
    "# test['response_combined'] = test['response_a'] + ' ' + test['response_b']\n",
    "\n",
    "# # Encode the target labels\n",
    "# label_encoder = LabelEncoder()\n",
    "# train['winner'] = label_encoder.fit_transform(train[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1))\n",
    "\n",
    "# # Feature Engineering\n",
    "# # Vectorize the combined responses using TF-IDF\n",
    "# tfidf = TfidfVectorizer(max_features=1000)\n",
    "# X_train_tfidf = tfidf.fit_transform(train['response_combined'])\n",
    "# X_test_tfidf = tfidf.transform(test['response_combined'])\n",
    "\n",
    "# # Prepare the data for model training\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, train['winner'], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Validate the model\n",
    "# y_val_pred_proba = model.predict_proba(X_val)\n",
    "# val_log_loss = log_loss(y_val, y_val_pred_proba)\n",
    "# print(f'Validation Log Loss: {val_log_loss}')\n",
    "\n",
    "# # Predict on the test set\n",
    "# test_pred_proba = model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# # Prepare the submission file\n",
    "# submission = pd.DataFrame(test['id'], columns=['id'])\n",
    "# submission['winner_model_a'] = test_pred_proba[:, label_encoder.transform(['winner_model_a'])]\n",
    "# submission['winner_model_b'] = test_pred_proba[:, label_encoder.transform(['winner_model_b'])]\n",
    "# submission['winner_tie'] = test_pred_proba[:, label_encoder.transform(['winner_tie'])]\n",
    "# submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "# # Inspect the submission file\n",
    "# print(submission.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# # 必要なライブラリをインポートします\n",
    "# import pandas as pd  # データ操作用ライブラリのインポート\n",
    "# import numpy as np  # 数値計算用ライブラリのインポート\n",
    "# from sklearn.model_selection import train_test_split  # データ分割用モジュールのインポート\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトライザーをインポート\n",
    "# from sklearn.ensemble import RandomForestClassifier  # ランダムフォレスト分類器をインポート\n",
    "# from sklearn.metrics import log_loss  # ログロスを計算する関数をインポート\n",
    "# from sklearn.preprocessing import LabelEncoder  # ラベルエンコーダをインポート\n",
    "\n",
    "# # データをロードします\n",
    "# train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータの読み込み\n",
    "# test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータの読み込み\n",
    "\n",
    "# # データを検査します\n",
    "# print(train.head())  # トレーニングデータの最初の5行を表示\n",
    "# print(test.head())  # テストデータの最初の5行を表示\n",
    "\n",
    "# # データの前処理\n",
    "# # 応答を1つのテキスト特徴として結合します\n",
    "# train['response_combined'] = train['response_a'] + ' ' + train['response_b']  # 応答の結合\n",
    "# test['response_combined'] = test['response_a'] + ' ' + test['response_b']  # テストデータの応答も結合\n",
    "\n",
    "# # ターゲットラベルをエンコードします\n",
    "# label_encoder = LabelEncoder()  # ラベルエンコーダのインスタンスを作成\n",
    "# train['winner'] = label_encoder.fit_transform(train[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1))  # 勝者のラベルをエンコード\n",
    "\n",
    "# # 特徴量エンジニアリング\n",
    "# # 結合された応答をTF-IDFを使用してベクトル化します\n",
    "# tfidf = TfidfVectorizer(max_features=1000)  # TF-IDFベクトライザーを作成\n",
    "# X_train_tfidf = tfidf.fit_transform(train['response_combined'])  # トレーニングデータをベクトル化\n",
    "# X_test_tfidf = tfidf.transform(test['response_combined'])  # テストデータをベクトル化\n",
    "\n",
    "# # モデル学習のためのデータを準備します\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, train['winner'], test_size=0.2, random_state=42)  # データをトレーニングとバリデーションに分割\n",
    "\n",
    "# # モデルをトレーニングします\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)  # ランダムフォレストモデルを作成\n",
    "# model.fit(X_train, y_train)  # モデルのトレーニング\n",
    "\n",
    "# # モデルをバリデーションします\n",
    "# y_val_pred_proba = model.predict_proba(X_val)  # バリデーションデータに対する予測確率を計算\n",
    "# val_log_loss = log_loss(y_val, y_val_pred_proba)  # バリデーションロスを計算\n",
    "# print(f'Validation Log Loss: {val_log_loss}')  # バリデーションロスを表示\n",
    "\n",
    "# # テストセットに対して予測します\n",
    "# test_pred_proba = model.predict_proba(X_test_tfidf)  # テストデータに対する予測確率を計算\n",
    "\n",
    "# # 提出ファイルを準備します\n",
    "# submission = pd.DataFrame(test['id'], columns=['id'])  # 提出用データフレームを作成\n",
    "# submission['winner_model_a'] = test_pred_proba[:, label_encoder.transform(['winner_model_a'])]  # モデルAの勝者確率を加える\n",
    "# submission['winner_model_b'] = test_pred_proba[:, label_encoder.transform(['winner_model_b'])]  # モデルBの勝者確率を加える\n",
    "# submission['winner_tie'] = test_pred_proba[:, label_encoder.transform(['winner_tie'])]  # 引き分けの勝者確率を加える\n",
    "# submission.to_csv('submission.csv', index=False)  # 提出ファイルをCSV形式で保存\n",
    "\n",
    "# # 提出ファイルを検査します\n",
    "# print(submission.head())  # 提出ファイルの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# # 必要なライブラリをインポートします\n",
    "# import pandas as pd  # データ操作用ライブラリのインポート\n",
    "# import numpy as np  # 数値計算用ライブラリのインポート\n",
    "# from sklearn.model_selection import train_test_split  # データ分割用モジュールのインポート\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトライザーをインポート\n",
    "# from sklearn.ensemble import RandomForestClassifier  # ランダムフォレスト分類器をインポート\n",
    "# from sklearn.metrics import log_loss  # ログロスを計算する関数をインポート\n",
    "# from sklearn.preprocessing import LabelEncoder  # ラベルエンコーダをインポート\n",
    "\n",
    "# # データをロードします\n",
    "# train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータの読み込み\n",
    "# test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータの読み込み\n",
    "\n",
    "# # データを検査します\n",
    "# print(train.head())  # トレーニングデータの最初の5行を表示\n",
    "# print(test.head())  # テストデータの最初の5行を表示\n",
    "\n",
    "# # データの前処理\n",
    "# # 応答を1つのテキスト特徴として結合します\n",
    "# train['response_combined'] = train['response_a'] + ' ' + train['response_b']  # 応答の結合\n",
    "# test['response_combined'] = test['response_a'] + ' ' + test['response_b']  # テストデータの応答も結合\n",
    "\n",
    "# # ターゲットラベルをエンコードします\n",
    "# label_encoder = LabelEncoder()  # ラベルエンコーダのインスタンスを作成\n",
    "# train['winner'] = label_encoder.fit_transform(train[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1))  # 勝者のラベルをエンコード\n",
    "\n",
    "# # 特徴量エンジニアリング\n",
    "# # 結合された応答をTF-IDFを使用してベクトル化します\n",
    "# tfidf = TfidfVectorizer(max_features=1000)  # TF-IDFベクトライザーを作成\n",
    "# X_train_tfidf = tfidf.fit_transform(train['response_combined'])  # トレーニングデータをベクトル化\n",
    "# X_test_tfidf = tfidf.transform(test['response_combined'])  # テストデータをベクトル化\n",
    "\n",
    "# # モデル学習のためのデータを準備します\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train_tfidf, train['winner'], test_size=0.2, random_state=42)  # データをトレーニングとバリデーションに分割\n",
    "\n",
    "# # モデルをトレーニングします\n",
    "# model = RandomForestClassifier(n_estimators=100, random_state=42)  # ランダムフォレストモデルを作成\n",
    "# model.fit(X_train, y_train)  # モデルのトレーニング\n",
    "\n",
    "# # モデルをバリデーションします\n",
    "# y_val_pred_proba = model.predict_proba(X_val)  # バリデーションデータに対する予測確率を計算\n",
    "# val_log_loss = log_loss(y_val, y_val_pred_proba)  # バリデーションロスを計算\n",
    "# print(f'Validation Log Loss: {val_log_loss}')  # バリデーションロスを表示\n",
    "\n",
    "# # テストセットに対して予測します\n",
    "# test_pred_proba = model.predict_proba(X_test_tfidf)  # テストデータに対する予測確率を計算\n",
    "\n",
    "# # 提出ファイルを準備します\n",
    "# submission = pd.DataFrame(test['id'], columns=['id'])  # 提出用データフレームを作成\n",
    "# submission['winner_model_a'] = test_pred_proba[:, label_encoder.transform(['winner_model_a'])]  # モデルAの勝者確率を加える\n",
    "# submission['winner_model_b'] = test_pred_proba[:, label_encoder.transform(['winner_model_b'])]  # モデルBの勝者確率を加える\n",
    "# submission['winner_tie'] = test_pred_proba[:, label_encoder.transform(['winner_tie'])]  # 引き分けの勝者確率を加える\n",
    "# submission.to_csv('submission.csv', index=False)  # 提出ファイルをCSV形式で保存\n",
    "\n",
    "# # 提出ファイルを検査します\n",
    "# print(submission.head())  # 提出ファイルの最初の5行を表示"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28500,
     "sourceId": 34046,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68878,
     "sourceId": 81968,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 94809,
     "modelInstanceId": 69677,
     "sourceId": 82943,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
