{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373571eb",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このノートブックは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、チャットボットの応答に対する人間の好みを予測するための機械学習モデルを構築することに取り組んでいます。具体的には、提供されたデータセット内のPythonとTensorFlow、およびKerasを使用して、自然言語処理を行い、複数の異なるモデルの出力を評価し、勝者を予測するシステムを作成します。\n",
    "\n",
    "### 使用ライブラリと手法\n",
    "1. **ライブラリのインポート**: `Keras`, `TensorFlow`, `NumPy`, `Pandas`など、モデル構築やデータ処理のために多くのライブラリをインポートします。また、`keras_nlp`を利用して自然言語処理を実行します。\n",
    "  \n",
    "2. **ハードウェアの設定**: 利用可能なGPUやTPUを確認し、最適な学習戦略を選択します。これにより、分散学習を利用してトレーニングの効率を向上させます。\n",
    "\n",
    "3. **データの前処理**: トレーニングデータとテストデータを読み込み、重複を削除するなどして基本的な整形を行います。また、応答をプロンプトに基づいて文脈化してペアを作成し、各応答をテキストクリーニングします。\n",
    "\n",
    "4. **特徴量の生成**: `DataFrameStatsProcessor`クラスを使用し、データフレームから特徴量を計算し、欠損値の統計や応答の長さに関する情報を整理します。\n",
    "\n",
    "5. **モデル構築**: `DebertaV3Backbone`を用いたニューラルネットワークモデルを構築し、層を追加して最後はSoftmax関数を用いてクラス確率を予測します。ここでは、L2正則化やドロップアウトレイヤーを使用して過学習を防ぎます。\n",
    "\n",
    "6. **トレーニング**: 学習率のスケジュールを設定し、モデルをトレーニングします。学習が進むにつれてモデルの性能を評価しつつ、最良のモデルを保存します。\n",
    "\n",
    "7. **評価と予測**: トレーニングを経たモデルを使用して、テストデータセットに対して予測を実行します。また、FGM（Fast Gradient Method）を利用してモデルの堅牢性を評価します。\n",
    "\n",
    "8. **出力ファイルの作成**: 最後に、予測結果をCSVファイルとして保存し、コンペティションに提出します。\n",
    "\n",
    "このノートブックは、全体を通して深層学習を活用した自然言語処理モデルの構築と評価に焦点を当てており、特にモデルの再現性を高めるための工夫が随所に見られます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7cc478",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に関連する専門用語の解説です。初心者がつまずきそうな要点に焦点を当てています。\n",
    "\n",
    "1. **Kerasバックエンド (Keras backend)**:\n",
    "   - Kerasは高レベルのニューラルネットワークAPIであり、TensorFlowやTheanoといった他の深層学習ライブラリの上で動作します。`KERAS_BACKEND`を設定することで、Kerasがどのライブラリを使用するかを指定します。\n",
    "\n",
    "2. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが開発した、特に機械学習のために設計されたハードウェア加速器です。TPUは演算を効率化し、大規模なモデルをより速く訓練または推論するために特化しています。\n",
    "\n",
    "3. **混合精度 (Mixed Precision)**:\n",
    "   - 深層学習トレーニング中に、異なる精度（通常はfloat32とfloat16）を使用してメモリ使用量を減少させる手法です。これにより、トレーニングプロセスが速くなり、大きなバッチサイズを使用できるようになります。\n",
    "\n",
    "4. **データローダー (DataLoader)**:\n",
    "   - モデルにデータを供給するための仕組みを指します。効率的なデータ読み込みや前処理のために使用され、ハードウェアのキャパシティを最大限に活用するのに役立ちます。\n",
    "\n",
    "5. **FGM (Fast Gradient Method)**:\n",
    "   - モデルの堅牢性を向上させる手法の一つで、特徴量に摺動（微小なランダムな変更）を加えることによって、モデルが攻撃に強くなることを目的としています。\n",
    "\n",
    "6. **AWP (Adversarial Weight Perturbation)**:\n",
    "   - モデルの重みを動的に微調整することにより、強化学習されたモデルの堅牢性を高める手法です。この手法では、各バッチの開始時に重みに摺動を加えます。\n",
    "\n",
    "7. **Zスコア正規化 (Z-score Normalization)**:\n",
    "   - データを標準化する手法で、データの平均を0、標準偏差を1に調整します。これにより、異なるスケールの特徴量を比較可能にします。\n",
    "\n",
    "8. **前処理器 (Preprocessor)**:\n",
    "   - データをモデルが扱いやすい形式に変換するための仕組み。トークン化、パディング、エンコーディングなどの操作を行います。\n",
    "\n",
    "9. **温度スケーリング (Temperature Scaling)**:\n",
    "   - モデルの予測確率を調整するための手法です。ロジット（ニューラルネットワークの出力）を温度パラメータで割ることによって、確率分布を平滑化し、過剰適合を防ぎます。\n",
    "\n",
    "10. **ラベルスムージング (Label Smoothing)**:\n",
    "    - 正解ラベルに対して、ほんの少しノイズを加えて柔軟性を持たせる手法です。これにより、過剰適合を防ぎ、一般化性能を向上させる効果があります。\n",
    "\n",
    "これらの用語は、実務経験が乏しい初心者にとっては馴染みが薄いものでありながら、深層学習モデルの実装においては非常に重要な要素です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2af063f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Import Libraries \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25b7d1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"jax\" or \"torch\"\n",
    "import re\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # または \"jax\" または \"torch\"\n",
    "# Kerasのバックエンドとして使用するフレームワークを環境変数に設定します\n",
    "\n",
    "import re  # 正規表現を操作するためのライブラリをインポートします\n",
    "\n",
    "import keras_nlp  # Kerasの自然言語処理用ライブラリをインポートします\n",
    "import keras  # Kerasライブラリをインポートします\n",
    "import tensorflow as tf  # TensorFlowライブラリをインポートします\n",
    "\n",
    "import numpy as np  # NumPyライブラリをインポートします（数値計算用）\n",
    "import pandas as pd  # Pandasライブラリをインポートします（データ操作用）\n",
    "from tqdm import tqdm  # プログレスバー表示のためのライブラリをインポートします\n",
    "import json  # JSONデータを扱うためのライブラリをインポートします\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:24.696323Z",
     "iopub.status.busy": "2024-07-06T08:18:24.695656Z",
     "iopub.status.idle": "2024-07-06T08:18:38.603387Z",
     "shell.execute_reply": "2024-07-06T08:18:38.602609Z",
     "shell.execute_reply.started": "2024-07-06T08:18:24.696269Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # または \"jax\" または \"torch\"\n",
    "# Kerasのバックエンドとして使用するフレームワークを環境変数に設定します\n",
    "\n",
    "import re  # 正規表現を操作するためのライブラリをインポートします\n",
    "\n",
    "import keras_nlp  # Kerasの自然言語処理用ライブラリをインポートします\n",
    "import keras  # Kerasライブラリをインポートします\n",
    "import tensorflow as tf  # TensorFlowライブラリをインポートします\n",
    "\n",
    "import numpy as np  # NumPyライブラリをインポートします（数値計算用）\n",
    "import pandas as pd  # Pandasライブラリをインポートします（データ操作用）\n",
    "from tqdm import tqdm  # プログレスバー表示のためのライブラリをインポートします\n",
    "import json  # JSONデータを扱うためのライブラリをインポートします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20da623a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Num GPUs Available\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 利用可能なGPUの数\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d01b98",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# 利用可能なGPUの数を出力します\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# モデルの分散学習のために、MirroredStrategyを使用します\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# 同期中のデバイス（GPU）の数を出力します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:38.605512Z",
     "iopub.status.busy": "2024-07-06T08:18:38.604965Z",
     "iopub.status.idle": "2024-07-06T08:18:39.274199Z",
     "shell.execute_reply": "2024-07-06T08:18:39.272847Z",
     "shell.execute_reply.started": "2024-07-06T08:18:38.605485Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# 利用可能なGPUの数を出力します\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# モデルの分散学習のために、MirroredStrategyを使用します\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# 同期中のデバイス（GPU）の数を出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a542c4b5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# TPU\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# TPU（Tensor Processing Unit）\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b85fe4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # Detect hardware, return appropriate distribution strategy\n",
    "# try:\n",
    "#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n",
    "#     print('Running on TPU ', tpu.master())\n",
    "# except ValueError:\n",
    "#     tpu = None\n",
    "\n",
    "# if tpu:\n",
    "#     tf.config.experimental_connect_to_cluster(tpu)\n",
    "#     tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "# else:\n",
    "#     strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "\n",
    "# print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ハードウェアを検出し、適切な分散戦略を返します\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUの検出。TPU_NAME環境変数が設定されていればパラメータは不要です。Kaggleでは常にこの設定が行われています。\n",
    "    print('Running on TPU ', tpu.master())\n",
    "    # TPUが見つかった場合、そのマスターの情報を出力します\n",
    "except ValueError:\n",
    "    tpu = None  # TPUが見つからない場合、tpuをNoneに設定します\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    # TPUクラスタへの接続を確立します\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    # TPUシステムを初期化します\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    # TPU用の分散戦略を設定します\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()  # TensorFlowのデフォルトの分散戦略を取得します。CPUおよび単一GPUで動作します。\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "# 同期中の複製数を出力します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.275981Z",
     "iopub.status.busy": "2024-07-06T08:18:39.275537Z",
     "iopub.status.idle": "2024-07-06T08:18:39.296311Z",
     "shell.execute_reply": "2024-07-06T08:18:39.295509Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.275939Z"
    }
   },
   "outputs": [],
   "source": [
    "# ハードウェアを検出し、適切な分散戦略を返します\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUの検出。TPU_NAME環境変数が設定されていればパラメータは不要です。Kaggleでは常にこの設定が行われています。\n",
    "    print('Running on TPU ', tpu.master())\n",
    "    # TPUが見つかった場合、そのマスターの情報を出力します\n",
    "except ValueError:\n",
    "    tpu = None  # TPUが見つからない場合、tpuをNoneに設定します\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    # TPUクラスタへの接続を確立します\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    # TPUシステムを初期化します\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    # TPU用の分散戦略を設定します\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()  # TensorFlowのデフォルトの分散戦略を取得します。CPUおよび単一GPUで動作します。\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "# 同期中の複製数を出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1261a88",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Configuration\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d054d89a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    seed = 42  # Random seed\n",
    "    preset = \"deberta_v3_extra_small_en\"\n",
    "    sequence_length = 512\n",
    "    epochs = 6\n",
    "    batch_size = 16\n",
    "#     batch_size = 16 * strategy.num_replicas_in_sync\n",
    "    scheduler = 'cosine'  # Learning rate scheduler\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    class_labels = list(label2name.keys())\n",
    "    class_names = list(label2name.values())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    seed = 42  # ランダムシードの設定\n",
    "    preset = \"deberta_v3_extra_small_en\"  # 使用するモデルのプリセット\n",
    "    sequence_length = 512  # 入力シーケンスの最大長\n",
    "    epochs = 6  # 学習するエポック数\n",
    "    batch_size = 16  # バッチサイズ\n",
    "#     batch_size = 16 * strategy.num_replicas_in_sync  # (コメントアウトされたコード) 複製に応じたバッチサイズの計算\n",
    "    scheduler = 'cosine'  # 学習率スケジューラーの設定\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}  # ラベルと名前のマッピング\n",
    "    name2label = {v:k for k, v in label2name.items()}  # 名前からラベルへの逆マッピング\n",
    "    class_labels = list(label2name.keys())  # 使用するクラスラベルのリスト\n",
    "    class_names = list(label2name.values())  # 使用するクラス名のリスト\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.299068Z",
     "iopub.status.busy": "2024-07-06T08:18:39.298649Z",
     "iopub.status.idle": "2024-07-06T08:18:39.307362Z",
     "shell.execute_reply": "2024-07-06T08:18:39.306565Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.299039Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42  # ランダムシードの設定\n",
    "    preset = \"deberta_v3_extra_small_en\"  # 使用するモデルのプリセット\n",
    "    sequence_length = 512  # 入力シーケンスの最大長\n",
    "    epochs = 6  # 学習するエポック数\n",
    "    batch_size = 16  # バッチサイズ\n",
    "#     batch_size = 16 * strategy.num_replicas_in_sync  # (コメントアウトされたコード) 複製に応じたバッチサイズの計算\n",
    "    scheduler = 'cosine'  # 学習率スケジューラーの設定\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}  # ラベルと名前のマッピング\n",
    "    name2label = {v:k for k, v in label2name.items()}  # 名前からラベルへの逆マッピング\n",
    "    class_labels = list(label2name.keys())  # 使用するクラスラベルのリスト\n",
    "    class_names = list(label2name.values())  # 使用するクラス名のリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ddbcfc",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Reproducibility \n",
    "设置随机种子的值以在每次运行中产生类似的结果。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 再現性\n",
    "ランダムシードの値を設定することで、毎回の実行で類似の結果を得ることができます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d0fa45",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keras.utils.set_random_seed(CFG.seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "keras.utils.set_random_seed(CFG.seed)  # Kerasのランダムシードを設定します。これにより、モデルの再現性が確保されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.308477Z",
     "iopub.status.busy": "2024-07-06T08:18:39.308223Z",
     "iopub.status.idle": "2024-07-06T08:18:39.317829Z",
     "shell.execute_reply": "2024-07-06T08:18:39.316936Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.308456Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)  # Kerasのランダムシードを設定します。これにより、モデルの再現性が確保されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80649154",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "#  Mixed Precision\n",
    "\n",
    "在本笔记中，我们将使用混合精度而不是 float32 精度进行训练和推理，以减少 GPU 内存使用量。这最终将使我们能够使用更大的批量大小，从而减少我们的训练和推理时间。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 混合精度\n",
    "\n",
    "本ノートブックでは、GPUのメモリ使用量を減少させるために、float32精度の代わりに混合精度を使用してトレーニングと推論を行います。これにより、より大きなバッチサイズを使用できるようになり、トレーニングと推論の時間を短縮できます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a211ac",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "#在mixed_float16策略下，模型的某些部分会自动使用float16进行计算，而其他部分（如损失函数的计算）则可能仍然使用float32以保持稳定性。\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "# \"mixed_float16\"ポリシーを設定します。この設定により、モデルの一部は自動的にfloat16で計算され、他の部分（例えば損失関数の計算）は安定性を保つために引き続きfloat32を使用します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.319115Z",
     "iopub.status.busy": "2024-07-06T08:18:39.318845Z",
     "iopub.status.idle": "2024-07-06T08:18:39.328914Z",
     "shell.execute_reply": "2024-07-06T08:18:39.328119Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.319092Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "# \"mixed_float16\"ポリシーを設定します。この設定により、モデルの一部は自動的にfloat16で計算され、他の部分（例えば損失関数の計算）は安定性を保つために引き続きfloat32を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d14151",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Dataset Path \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# データセットのパス\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdceb0a1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'  # データセットのベースパスを設定します。このパスはKaggleの入力データを指します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.330581Z",
     "iopub.status.busy": "2024-07-06T08:18:39.329996Z",
     "iopub.status.idle": "2024-07-06T08:18:39.339076Z",
     "shell.execute_reply": "2024-07-06T08:18:39.338163Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.330549Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'  # データセットのベースパスを設定します。このパスはKaggleの入力データを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959c7f00",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Meta Data \n",
    "## Files\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: Unique identifier for each row.\n",
    "- `prompt`: Input prompt given to both models.\n",
    "- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# メタデータ\n",
    "## ファイル\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: 各行のユニーク識別子。\n",
    "- `model_[a/b]`: モデルの識別子。train.csvには存在するが、test.csvには存在しません。\n",
    "- `prompt`: 両モデルに与えられた入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。\n",
    "- `winner_model_[a/b/tie]`: 審査員の選択を示すバイナリ列（正解ターゲット）。\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: 各行のユニーク識別子。\n",
    "- `prompt`: 両モデルに与えられた入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9aa3b2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load Train Data\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "ultrachat_df = pd.read_csv('/kaggle/input/ultrachat-train/ultrachat_s42_a0.5.csv')\n",
    "df = pd.concat([df, ultrachat_df], axis=0)\n",
    "lmsys_33k_deduplicated = pd.read_csv('/kaggle/input/lmsys-33k-deduplicated/lmsys-33k-deduplicated.csv')\n",
    "df = pd.concat([df, lmsys_33k_deduplicated], axis=0)\n",
    "# ultrafeedback_lmsysformat = pd.read_parquet('/kaggle/input/ultrafeedback-lmsysformat/ultrafeedback_lmsysformat.parquet', engine='pyarrow')\n",
    "# ultrafeedback_lmsysformat['prompt'] = ultrafeedback_lmsysformat['prompt'].apply(lambda x: f'[\"{x}\"]')\n",
    "# df = pd.concat([df, ultrafeedback_lmsysformat], axis=0)\n",
    "\n",
    "# Load Test Data\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# display(ultrafeedback_lmsysformat.head())\n",
    "display(df.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータを読み込む\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv')  # train.csvファイルを読み込みます\n",
    "ultrachat_df = pd.read_csv('/kaggle/input/ultrachat-train/ultrachat_s42_a0.5.csv')  # ultrachatデータを読み込みます\n",
    "df = pd.concat([df, ultrachat_df], axis=0)  # データフレームを縦に結合します\n",
    "lmsys_33k_deduplicated = pd.read_csv('/kaggle/input/lmsys-33k-deduplicated/lmsys-33k-deduplicated.csv')  # 重複のないlmsysデータを読み込みます\n",
    "df = pd.concat([df, lmsys_33k_deduplicated], axis=0)  # 再びデータフレームを結合します\n",
    "# ultrafeedback_lmsysformat = pd.read_parquet('/kaggle/input/ultrafeedback-lmsysformat/ultrafeedback_lmsysformat.parquet', engine='pyarrow')\n",
    "# ultrafeedback_lmsysformat['prompt'] = ultrafeedback_lmsysformat['prompt'].apply(lambda x: f'[\"{x}\"]')\n",
    "# df = pd.concat([df, ultrafeedback_lmsysformat], axis=0)  # コメントアウトされたコード。別のデータフレームの読み込みと結合。\n",
    "\n",
    "# テストデータを読み込む\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')  # test.csvファイルを読み込みます\n",
    "\n",
    "# display(ultrafeedback_lmsysformat.head())  # コメントアウトされたコード。ultrafeedbackデータの先頭を表示。\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.340799Z",
     "iopub.status.busy": "2024-07-06T08:18:39.340245Z",
     "iopub.status.idle": "2024-07-06T08:18:46.525334Z",
     "shell.execute_reply": "2024-07-06T08:18:46.524439Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.340768Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータを読み込む\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv')  # train.csvファイルを読み込みます\n",
    "ultrachat_df = pd.read_csv('/kaggle/input/ultrachat-train/ultrachat_s42_a0.5.csv')  # ultrachatデータを読み込みます\n",
    "df = pd.concat([df, ultrachat_df], axis=0)  # データフレームを縦に結合します\n",
    "lmsys_33k_deduplicated = pd.read_csv('/kaggle/input/lmsys-33k-deduplicated/lmsys-33k-deduplicated.csv')  # 重複のないlmsysデータを読み込みます\n",
    "df = pd.concat([df, lmsys_33k_deduplicated], axis=0)  # 再びデータフレームを結合します\n",
    "# ultrafeedback_lmsysformat = pd.read_parquet('/kaggle/input/ultrafeedback-lmsysformat/ultrafeedback_lmsysformat.parquet', engine='pyarrow')\n",
    "# ultrafeedback_lmsysformat['prompt'] = ultrafeedback_lmsysformat['prompt'].apply(lambda x: f'[\"{x}\"]')\n",
    "# df = pd.concat([df, ultrafeedback_lmsysformat], axis=0)  # コメントアウトされたコード。別のデータフレームの読み込みと結合。\n",
    "\n",
    "# テストデータを読み込む\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')  # test.csvファイルを読み込みます\n",
    "\n",
    "# display(ultrafeedback_lmsysformat.head())  # コメントアウトされたコード。ultrafeedbackデータの先頭を表示。\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c332c23",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df = df.drop(\"id\", axis=1)\n",
    "df = df.drop_duplicates(keep=\"first\", ignore_index=True)\n",
    "\n",
    "for col in [\"prompt\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x))\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x))\n",
    "for col in [\"response_a\", \"response_b\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))\n",
    "    \n",
    "# Sample data\n",
    "# df = df.sample(frac=0.01)\n",
    "\n",
    "# Label conversion\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# Show Sample\n",
    "display(df.head())\n",
    "# Show Sample\n",
    "display(test_df.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "df = df.drop(\"id\", axis=1)  # 'id'列を削除します\n",
    "df = df.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、インデックスを再設定します\n",
    "\n",
    "for col in [\"prompt\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x))  # 'prompt'列の各要素を評価してリストに変換します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x))  # テストデータの'prompt'列も同様に処理します\n",
    "for col in [\"response_a\", \"response_b\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # 'null'を'None'に置き換え、評価します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # テストデータも同様に処理します\n",
    "    \n",
    "# サンプリングデータ（コメントアウト）\n",
    "# df = df.sample(frac=0.01)  # データの1%をサンプリングします\n",
    "\n",
    "# ラベル変換\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)  # 各行で最大値のインデックスを取得し、クラス名を設定\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)  # クラス名をラベルに変換します\n",
    "\n",
    "# サンプルを表示\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します\n",
    "# サンプルを表示\n",
    "display(test_df.head())  # テストデータフレームの先頭5行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:46.526829Z",
     "iopub.status.busy": "2024-07-06T08:18:46.526529Z",
     "iopub.status.idle": "2024-07-06T08:18:55.668662Z",
     "shell.execute_reply": "2024-07-06T08:18:55.667798Z",
     "shell.execute_reply.started": "2024-07-06T08:18:46.526804Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"id\", axis=1)  # 'id'列を削除します\n",
    "df = df.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、インデックスを再設定します\n",
    "\n",
    "for col in [\"prompt\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x))  # 'prompt'列の各要素を評価してリストに変換します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x))  # テストデータの'prompt'列も同様に処理します\n",
    "for col in [\"response_a\", \"response_b\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # 'null'を'None'に置き換え、評価します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # テストデータも同様に処理します\n",
    "    \n",
    "# サンプリングデータ（コメントアウト）\n",
    "# df = df.sample(frac=0.01)  # データの1%をサンプリングします\n",
    "\n",
    "# ラベル変換\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)  # 各行で最大値のインデックスを取得し、クラス名を設定\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)  # クラス名をラベルに変換します\n",
    "\n",
    "# サンプルを表示\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します\n",
    "# サンプルを表示\n",
    "display(test_df.head())  # テストデータフレームの先頭5行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3d4b6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Contextualize Response with Prompt\n",
    "\n",
    "在我们的方法中，我们将根据提示对每个回答进行情境化，而不是对所有回答使用单一提示。这意味着，对于每个回答，我们将为模型提供同一组提示及其各自的回答（例如，“(P + R_A)”，“(P + R_B)”等）。\n",
    "\n",
    "> 某些提示和响应可能未使用 `utf-8` 编码，导致创建数据加载器时出错。在这种情况下，我们将用空字符串替换它们。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## プロンプトで応答を文脈化する\n",
    "\n",
    "私たちのアプローチでは、すべての応答に対して単一のプロンプトを使用するのではなく、各応答をプロンプトに基づいて文脈化します。これは、各応答ごとに、モデルに同じプロンプトのセットとその各応答（例えば、「(P + R_A)」、「(P + R_B)」など）を提供することを意味します。\n",
    "\n",
    "> 一部のプロンプトおよび応答は `utf-8` エンコーディングが使用されていない場合があり、その結果データローダーの作成時にエラーが発生する可能性があります。この場合、これらを空の文字列に置き換えます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355be468",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def make_pairs(row):\n",
    "    row['options'] = []\n",
    "    row[\"encode_fail\"] = False\n",
    "\n",
    "    try:\n",
    "        # 确保所有需要的键都存在于row字典中\n",
    "        prompts = row['prompt']\n",
    "        responses_a = row['response_a']\n",
    "        responses_b = row['response_b']\n",
    "        \n",
    "        # 检查列表长度是否匹配\n",
    "        if not (len(prompts) == len(responses_a) == len(responses_b)):\n",
    "            raise ValueError(\"The lists 'prompt', 'response_a', and 'response_b' must be of the same length.\")\n",
    "            \n",
    "        response_a_str = ''\n",
    "        response_b_str = ''\n",
    "        \n",
    "        for idx in range(len(prompts)):\n",
    "            response_a_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_a[idx]}\"\n",
    "            response_b_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_b[idx]}\"\n",
    "        \n",
    "        # 文本清洗，例如去除无法识别的Unicode字符或替换它们\n",
    "        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_a_str))\n",
    "        clean_response_b_str = \"\".join(filter(lambda x: ord(x) < 128, response_b_str))\n",
    "        \n",
    "        row['options'].append(clean_response_a_str)\n",
    "        row['options'].append(clean_response_b_str)\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in row: {e}\")\n",
    "        row[\"encode_fail\"] = True\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        row[\"encode_fail\"] = True\n",
    "    except Exception as e:\n",
    "        # 捕获其他所有异常\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    return row\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def make_pairs(row):\n",
    "    row['options'] = []  # optionsリストを初期化します\n",
    "    row[\"encode_fail\"] = False  # エンコード失敗フラグを初期化します\n",
    "\n",
    "    try:\n",
    "        # 必要なキーがすべてrow辞書に存在することを確認します\n",
    "        prompts = row['prompt']  # プロンプトを取得します\n",
    "        responses_a = row['response_a']  # 応答Aを取得します\n",
    "        responses_b = row['response_b']  # 応答Bを取得します\n",
    "        \n",
    "        # リストの長さが一致することを確認します\n",
    "        if not (len(prompts) == len(responses_a) == len(responses_b)):\n",
    "            raise ValueError(\"The lists 'prompt', 'response_a', and 'response_b' must be of the same length.\")\n",
    "            # プロンプト、応答A、および応答Bのリストが同じ長さである必要があります\n",
    "            \n",
    "        response_a_str = ''\n",
    "        response_b_str = ''\n",
    "        \n",
    "        for idx in range(len(prompts)):\n",
    "            response_a_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_a[idx]}\"\n",
    "            response_b_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_b[idx]}\"\n",
    "        \n",
    "        # テキストのクリーニング、たとえば、認識できないUnicode文字を除去または置き換えます\n",
    "        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_a_str))  # ASCII文字のみを残します\n",
    "        clean_response_b_str = \"\".join(filter(lambda x: ord(x) < 128, response_b_str))  # ASCII文字のみを残します\n",
    "        \n",
    "        row['options'].append(clean_response_a_str)  # クリーンされた応答Aをoptionsリストに追加\n",
    "        row['options'].append(clean_response_b_str)  # クリーンされた応答Bをoptionsリストに追加\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in row: {e}\")  # 指定されたキーが見つからない場合のエラーメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except ValueError as e:\n",
    "        print(e)  # 値エラーの場合のメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except Exception as e:\n",
    "        # その他すべての例外をキャッチ\n",
    "        print(f\"An unexpected error occurred: {e}\")  # 予期しないエラーのメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "\n",
    "    return row  # 処理された行を返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:55.67367Z",
     "iopub.status.busy": "2024-07-06T08:18:55.673373Z",
     "iopub.status.idle": "2024-07-06T08:18:55.683287Z",
     "shell.execute_reply": "2024-07-06T08:18:55.682351Z",
     "shell.execute_reply.started": "2024-07-06T08:18:55.673644Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pairs(row):\n",
    "    row['options'] = []  # optionsリストを初期化します\n",
    "    row[\"encode_fail\"] = False  # エンコード失敗フラグを初期化します\n",
    "\n",
    "    try:\n",
    "        # 必要なキーがすべてrow辞書に存在することを確認します\n",
    "        prompts = row['prompt']  # プロンプトを取得します\n",
    "        responses_a = row['response_a']  # 応答Aを取得します\n",
    "        responses_b = row['response_b']  # 応答Bを取得します\n",
    "        \n",
    "        # リストの長さが一致することを確認します\n",
    "        if not (len(prompts) == len(responses_a) == len(responses_b)):\n",
    "            raise ValueError(\"The lists 'prompt', 'response_a', and 'response_b' must be of the same length.\")\n",
    "            # プロンプト、応答A、および応答Bのリストが同じ長さである必要があります\n",
    "            \n",
    "        response_a_str = ''\n",
    "        response_b_str = ''\n",
    "        \n",
    "        for idx in range(len(prompts)):\n",
    "            response_a_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_a[idx]}\"\n",
    "            response_b_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_b[idx]}\"\n",
    "        \n",
    "        # テキストのクリーニング、たとえば、認識できないUnicode文字を除去または置き換えます\n",
    "        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_a_str))  # ASCII文字のみを残します\n",
    "        clean_response_b_str = \"\".join(filter(lambda x: ord(x) < 128, response_b_str))  # ASCII文字のみを残します\n",
    "        \n",
    "        row['options'].append(clean_response_a_str)  # クリーンされた応答Aをoptionsリストに追加\n",
    "        row['options'].append(clean_response_b_str)  # クリーンされた応答Bをoptionsリストに追加\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in row: {e}\")  # 指定されたキーが見つからない場合のエラーメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except ValueError as e:\n",
    "        print(e)  # 値エラーの場合のメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except Exception as e:\n",
    "        # その他すべての例外をキャッチ\n",
    "        print(f\"An unexpected error occurred: {e}\")  # 予期しないエラーのメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "\n",
    "    return row  # 処理された行を返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32798588",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df = df.apply(make_pairs, axis=1)\n",
    "display(df.head(2))\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)\n",
    "display(test_df.head(2))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "df = df.apply(make_pairs, axis=1)  # 各行に対してmake_pairs関数を適用します\n",
    "display(df.head(2))  # トレーニングデータフレームの最初の2行を表示します\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # テストデータフレームの各行にも同様にmake_pairs関数を適用します\n",
    "display(test_df.head(2))  # テストデータフレームの最初の2行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:55.68493Z",
     "iopub.status.busy": "2024-07-06T08:18:55.684564Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.apply(make_pairs, axis=1)  # 各行に対してmake_pairs関数を適用します\n",
    "display(df.head(2))  # トレーニングデータフレームの最初の2行を表示します\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # テストデータフレームの各行にも同様にmake_pairs関数を適用します\n",
    "display(test_df.head(2))  # テストデータフレームの最初の2行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a598f40",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Encoding Fail Statistics\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## エンコーディング失敗の統計\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0de7f2e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df.encode_fail.value_counts(normalize=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "df.encode_fail.value_counts(normalize=False)  # エンコーディング失敗フラグのカウントを表示します（正規化せず）。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.encode_fail.value_counts(normalize=False)  # エンコーディング失敗フラグのカウントを表示します（正規化せず）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48215ff5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# EDA\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# EDA（探索的データ分析）\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34df17d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class DataFrameStatsProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def _is_empty(self, string: str) -> bool:\n",
    "        return bool(re.match(\"^\\s*$\", string))\n",
    "\n",
    "    def _len(self, string: str) -> int:\n",
    "        if string is None:\n",
    "            return 0\n",
    "        return len(string)\n",
    "\n",
    "    def _add_len_stats(self, col: str) -> pd.DataFrame:\n",
    "        if col == \"prompt\":\n",
    "            col_prefix = \"p_len\"\n",
    "        elif col == \"response_a\":\n",
    "            col_prefix = \"res_a_len\"\n",
    "        elif col == \"response_b\":\n",
    "            col_prefix = \"res_b_len\"\n",
    "        \n",
    "        self.df[f\"{col_prefix}_sum\"] = self.df[col].apply(lambda x: sum(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_mean\"] =  self.df[col].apply(lambda x: np.mean(list(self._len(s) for s in x)))\n",
    "        self.df[f\"{col_prefix}_max\"] = self.df[col].apply(lambda x: max(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_sum_log\"] = np.log1p(self.df[f\"{col_prefix}_sum\"])\n",
    "        self.df[f\"{col_prefix}_mean_log\"] =  np.log1p(self.df[f\"{col_prefix}_mean\"])\n",
    "        self.df[f\"{col_prefix}_max_log\"] = np.log1p(self.df[f\"{col_prefix}_max\"])\n",
    "        \n",
    "        return self.df\n",
    "    \n",
    "    def z_score_normalize(self, columns):\n",
    "        \"\"\"\n",
    "        对指定的列进行Z得分归一化。\n",
    "        参数:\n",
    "            columns (list): 需要进行Z得分归一化的列名列表。\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()\n",
    "    \n",
    "    def process_dataframe(self):\n",
    "        self.df[\"n_prompts\"] = self.df[\"prompt\"].apply(lambda x: len(x))\n",
    "        self.df[\"n_res_a\"] = self.df[\"response_a\"].apply(lambda x: len(x))\n",
    "        self.df[\"n_res_b\"] = self.df[\"response_b\"].apply(lambda x: len(x))\n",
    "        assert ((self.df[\"n_prompts\"] == self.df[\"n_res_a\"]) & (self.df[\"n_prompts\"] == self.df[\"n_res_b\"])).all()\n",
    "\n",
    "        self.df[\"n_na_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "\n",
    "        self.df[\"n_miss_res_a\"] = self.df[\"n_na_res_a\"] + self.df[\"n_empty_res_a\"]\n",
    "        self.df[\"n_miss_res_b\"] = self.df[\"n_na_res_b\"] + self.df[\"n_empty_res_b\"]\n",
    "\n",
    "        self.df[\"n_eff_res_a\"] = self.df[\"n_res_a\"] - self.df[\"n_miss_res_a\"]\n",
    "        self.df[\"n_eff_res_b\"] = self.df[\"n_res_b\"] - self.df[\"n_miss_res_b\"]\n",
    "\n",
    "        self._add_len_stats(\"prompt\")\n",
    "        self._add_len_stats(\"response_a\")\n",
    "        self._add_len_stats(\"response_b\")\n",
    "\n",
    "        self.df[\"res_len_mean_diff\"] = self.df[\"res_a_len_mean\"] - self.df[\"res_b_len_mean\"]\n",
    "        self.df[\"res_len_mean_diff_clip\"] = self.df[\"res_len_mean_diff\"].clip(-6000, 6000)\n",
    "\n",
    "        self.df[\"n_miss_prompts\"] = self.df[\"n_na_prompts\"] + self.df[\"n_empty_prompts\"]\n",
    "        self.df[\"n_eff_prompts\"] = self.df[\"n_prompts\"] - self.df[\"n_miss_prompts\"]\n",
    "\n",
    "        self.df[\"na_prompt_ratio\"] = self.df[\"n_na_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"empty_prompt_ratio\"] = self.df[\"n_empty_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"miss_prompt_ratio\"] = self.df[\"n_miss_prompts\"] / self.df[\"n_prompts\"]\n",
    "\n",
    "        self.df[\"na_res_a_ratio\"] = self.df[\"n_na_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"empty_res_a_ratio\"] = self.df[\"n_empty_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"miss_res_a_ratio\"] = self.df[\"n_miss_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"na_res_b_ratio\"] = self.df[\"n_na_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"empty_res_b_ratio\"] = self.df[\"n_empty_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"miss_res_b_ratio\"] = self.df[\"n_miss_res_b\"] / self.df[\"n_res_b\"]\n",
    "\n",
    "        for col, col_prefix in zip([\"prompt\", \"response_a\", \"response_b\"], [\"p_len\", \"res_a_len\", \"res_b_len\"]):\n",
    "            self.df[f\"{col_prefix}_med\"] = self.df[col].apply(lambda x: np.median(list(self._len(s) for s in x)))\n",
    "            self.df[f\"{col_prefix}_std\"] = self.df[col].apply(lambda x: np.std(list(self._len(s) for s in x)))\n",
    "\n",
    "        self.df[\"p_len_eff_mean\"] = self.df[\"p_len_sum\"] / self.df[\"n_eff_prompts\"]\n",
    "        self.df[\"res_a_len_eff_mean\"] = self.df[\"res_a_len_sum\"] / self.df[\"n_eff_res_a\"]\n",
    "        self.df[\"res_b_len_eff_mean\"] = self.df[\"res_b_len_sum\"] / self.df[\"n_eff_res_b\"]\n",
    "\n",
    "        for stats in [\"sum\", \"mean\", \"max\", \"med\", \"eff_mean\"]:\n",
    "            self.df[f\"p_a_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_a_len_{stats}\"]\n",
    "            self.df[f\"p_b_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            self.df[f\"a_b_{stats}_diff\"] = self.df[f\"res_a_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            \n",
    "        len_feature_a_col = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                     \"p_a_eff_mean_diff\"]\n",
    "        \n",
    "        len_feature_b_col = [\"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                             \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                             \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        numerical_feature_columns = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                                     \"p_a_eff_mean_diff\", \"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                                     \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                                     \"p_b_eff_mean_diff\"]\n",
    "        # 确保不除以零进行归一化\n",
    "        for col in numerical_feature_columns:\n",
    "            if self.df[col].std() == 0:\n",
    "                print(f\"Warning: Standard deviation is zero for column {col}. Skipping normalization.\")\n",
    "            else:\n",
    "                self.z_score_normalize([col])\n",
    "                \n",
    "        self.df = self.df.fillna(0)\n",
    "        \n",
    "        # 选择这些列并将它们转换为列表\n",
    "        len_features_a = self.df[len_feature_a_col].values.tolist()\n",
    "        len_features_b = self.df[len_feature_b_col].values.tolist()\n",
    "\n",
    "        return len_features_a, len_features_b\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class DataFrameStatsProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df  # 初期化時にデータフレームを設定します\n",
    "\n",
    "    def _is_empty(self, string: str) -> bool:\n",
    "        return bool(re.match(\"^\\s*$\", string))  # 文字列が空かどうかを判断します\n",
    "\n",
    "    def _len(self, string: str) -> int:\n",
    "        if string is None:\n",
    "            return 0  # Noneの場合は長さ0を返します\n",
    "        return len(string)  # 文字列の長さを返します\n",
    "\n",
    "    def _add_len_stats(self, col: str) -> pd.DataFrame:\n",
    "        if col == \"prompt\":\n",
    "            col_prefix = \"p_len\"  # プロンプトの列接頭辞\n",
    "        elif col == \"response_a\":\n",
    "            col_prefix = \"res_a_len\"  # 応答Aの列接頭辞\n",
    "        elif col == \"response_b\":\n",
    "            col_prefix = \"res_b_len\"  # 応答Bの列接頭辞\n",
    "        \n",
    "        # 各長さの統計を計算\n",
    "        self.df[f\"{col_prefix}_sum\"] = self.df[col].apply(lambda x: sum(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_mean\"] =  self.df[col].apply(lambda x: np.mean(list(self._len(s) for s in x)))\n",
    "        self.df[f\"{col_prefix}_max\"] = self.df[col].apply(lambda x: max(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_sum_log\"] = np.log1p(self.df[f\"{col_prefix}_sum\"])\n",
    "        self.df[f\"{col_prefix}_mean_log\"] =  np.log1p(self.df[f\"{col_prefix}_mean\"])\n",
    "        self.df[f\"{col_prefix}_max_log\"] = np.log1p(self.df[f\"{col_prefix}_max\"])\n",
    "        \n",
    "        return self.df  # 更新されたデータフレームを返します\n",
    "    \n",
    "    def z_score_normalize(self, columns):\n",
    "        \"\"\"\n",
    "        指定した列にZスコア正規化を適用します。\n",
    "        パラメータ:\n",
    "            columns (list): Zスコア正規化を実施する列名のリスト。\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()  # Zスコア正規化を実施します\n",
    "    \n",
    "    def process_dataframe(self):\n",
    "        # データフレームの処理を実施します\n",
    "        self.df[\"n_prompts\"] = self.df[\"prompt\"].apply(lambda x: len(x))  # プロンプトの数を数えます\n",
    "        self.df[\"n_res_a\"] = self.df[\"response_a\"].apply(lambda x: len(x))  # 応答Aの数を数えます\n",
    "        self.df[\"n_res_b\"] = self.df[\"response_b\"].apply(lambda x: len(x))  # 応答Bの数を数えます\n",
    "        assert ((self.df[\"n_prompts\"] == self.df[\"n_res_a\"]) & (self.df[\"n_prompts\"] == self.df[\"n_res_b\"])).all()  # 数が一致することを確認します\n",
    "\n",
    "        # プロンプトと応答の欠損値や空の値をカウントします\n",
    "        self.df[\"n_na_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "\n",
    "        # 欠損値の合計を計算します\n",
    "        self.df[\"n_miss_res_a\"] = self.df[\"n_na_res_a\"] + self.df[\"n_empty_res_a\"]\n",
    "        self.df[\"n_miss_res_b\"] = self.df[\"n_na_res_b\"] + self.df[\"n_empty_res_b\"]\n",
    "\n",
    "        # 有効な応答数を計算します\n",
    "        self.df[\"n_eff_res_a\"] = self.df[\"n_res_a\"] - self.df[\"n_miss_res_a\"]\n",
    "        self.df[\"n_eff_res_b\"] = self.df[\"n_res_b\"] - self.df[\"n_miss_res_b\"]\n",
    "\n",
    "        # 長さの統計を追加します\n",
    "        self._add_len_stats(\"prompt\")\n",
    "        self._add_len_stats(\"response_a\")\n",
    "        self._add_len_stats(\"response_b\")\n",
    "\n",
    "        self.df[\"res_len_mean_diff\"] = self.df[\"res_a_len_mean\"] - self.df[\"res_b_len_mean\"]  # 応答AとBの長さの平均の差を計算\n",
    "        self.df[\"res_len_mean_diff_clip\"] = self.df[\"res_len_mean_diff\"].clip(-6000, 6000)  # 差の範囲をクリップします\n",
    "\n",
    "        # プロンプトの欠損値をカウントします\n",
    "        self.df[\"n_miss_prompts\"] = self.df[\"n_na_prompts\"] + self.df[\"n_empty_prompts\"]\n",
    "        self.df[\"n_eff_prompts\"] = self.df[\"n_prompts\"] - self.df[\"n_miss_prompts\"]\n",
    "\n",
    "        # 比率を計算します\n",
    "        self.df[\"na_prompt_ratio\"] = self.df[\"n_na_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"empty_prompt_ratio\"] = self.df[\"n_empty_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"miss_prompt_ratio\"] = self.df[\"n_miss_prompts\"] / self.df[\"n_prompts\"]\n",
    "        \n",
    "        self.df[\"na_res_a_ratio\"] = self.df[\"n_na_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"empty_res_a_ratio\"] = self.df[\"n_empty_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"miss_res_a_ratio\"] = self.df[\"n_miss_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"na_res_b_ratio\"] = self.df[\"n_na_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"empty_res_b_ratio\"] = self.df[\"n_empty_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"miss_res_b_ratio\"] = self.df[\"n_miss_res_b\"] / self.df[\"n_res_b\"]\n",
    "\n",
    "        # 各種長さの統計を追加します\n",
    "        for col, col_prefix in zip([\"prompt\", \"response_a\", \"response_b\"], [\"p_len\", \"res_a_len\", \"res_b_len\"]):\n",
    "            self.df[f\"{col_prefix}_med\"] = self.df[col].apply(lambda x: np.median(list(self._len(s) for s in x)))  # 中央値を計算します\n",
    "            self.df[f\"{col_prefix}_std\"] = self.df[col].apply(lambda x: np.std(list(self._len(s) for s in x)))  # 標準偏差を計算します\n",
    "\n",
    "        # 有効な長さの平均を計算します\n",
    "        self.df[\"p_len_eff_mean\"] = self.df[\"p_len_sum\"] / self.df[\"n_eff_prompts\"]\n",
    "        self.df[\"res_a_len_eff_mean\"] = self.df[\"res_a_len_sum\"] / self.df[\"n_eff_res_a\"]\n",
    "        self.df[\"res_b_len_eff_mean\"] = self.df[\"res_b_len_sum\"] / self.df[\"n_eff_res_b\"]\n",
    "\n",
    "        # 長さの差を計算します\n",
    "        for stats in [\"sum\", \"mean\", \"max\", \"med\", \"eff_mean\"]:\n",
    "            self.df[f\"p_a_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_a_len_{stats}\"]\n",
    "            self.df[f\"p_b_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            self.df[f\"a_b_{stats}_diff\"] = self.df[f\"res_a_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            \n",
    "        # 特徴量列を定義します\n",
    "        len_feature_a_col = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                     \"p_a_eff_mean_diff\"]\n",
    "        \n",
    "        len_feature_b_col = [\"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                             \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                             \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        numerical_feature_columns = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                                     \"p_a_eff_mean_diff\", \"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                                     \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                                     \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        # ゼロで割らないように正規化します\n",
    "        for col in numerical_feature_columns:\n",
    "            if self.df[col].std() == 0:\n",
    "                print(f\"Warning: Standard deviation is zero for column {col}. Skipping normalization.\")\n",
    "            else:\n",
    "                self.z_score_normalize([col])  # Zスコア正規化を適用します\n",
    "                \n",
    "        self.df = self.df.fillna(0)  # NaNを0で埋めます\n",
    "        \n",
    "        # 特徴量をリストに変換します\n",
    "        len_features_a = self.df[len_feature_a_col].values.tolist()\n",
    "        len_features_b = self.df[len_feature_b_col].values.tolist()\n",
    "\n",
    "        return len_features_a, len_features_b  # 長さ特徴量を返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameStatsProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df  # 初期化時にデータフレームを設定します\n",
    "\n",
    "    def _is_empty(self, string: str) -> bool:\n",
    "        return bool(re.match(\"^\\s*$\", string))  # 文字列が空かどうかを判断します\n",
    "\n",
    "    def _len(self, string: str) -> int:\n",
    "        if string is None:\n",
    "            return 0  # Noneの場合は長さ0を返します\n",
    "        return len(string)  # 文字列の長さを返します\n",
    "\n",
    "    def _add_len_stats(self, col: str) -> pd.DataFrame:\n",
    "        if col == \"prompt\":\n",
    "            col_prefix = \"p_len\"  # プロンプトの列接頭辞\n",
    "        elif col == \"response_a\":\n",
    "            col_prefix = \"res_a_len\"  # 応答Aの列接頭辞\n",
    "        elif col == \"response_b\":\n",
    "            col_prefix = \"res_b_len\"  # 応答Bの列接頭辞\n",
    "        \n",
    "        # 各長さの統計を計算\n",
    "        self.df[f\"{col_prefix}_sum\"] = self.df[col].apply(lambda x: sum(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_mean\"] =  self.df[col].apply(lambda x: np.mean(list(self._len(s) for s in x)))\n",
    "        self.df[f\"{col_prefix}_max\"] = self.df[col].apply(lambda x: max(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_sum_log\"] = np.log1p(self.df[f\"{col_prefix}_sum\"])\n",
    "        self.df[f\"{col_prefix}_mean_log\"] =  np.log1p(self.df[f\"{col_prefix}_mean\"])\n",
    "        self.df[f\"{col_prefix}_max_log\"] = np.log1p(self.df[f\"{col_prefix}_max\"])\n",
    "        \n",
    "        return self.df  # 更新されたデータフレームを返します\n",
    "    \n",
    "    def z_score_normalize(self, columns):\n",
    "        \"\"\"\n",
    "        指定した列にZスコア正規化を適用します。\n",
    "        パラメータ:\n",
    "            columns (list): Zスコア正規化を実施する列名のリスト。\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()  # Zスコア正規化を実施します\n",
    "    \n",
    "    def process_dataframe(self):\n",
    "        # データフレームの処理を実施します\n",
    "        self.df[\"n_prompts\"] = self.df[\"prompt\"].apply(lambda x: len(x))  # プロンプトの数を数えます\n",
    "        self.df[\"n_res_a\"] = self.df[\"response_a\"].apply(lambda x: len(x))  # 応答Aの数を数えます\n",
    "        self.df[\"n_res_b\"] = self.df[\"response_b\"].apply(lambda x: len(x))  # 応答Bの数を数えます\n",
    "        assert ((self.df[\"n_prompts\"] == self.df[\"n_res_a\"]) & (self.df[\"n_prompts\"] == self.df[\"n_res_b\"])).all()  # 数が一致することを確認します\n",
    "\n",
    "        # プロンプトと応答の欠損値や空の値をカウントします\n",
    "        self.df[\"n_na_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "\n",
    "        # 欠損値の合計を計算します\n",
    "        self.df[\"n_miss_res_a\"] = self.df[\"n_na_res_a\"] + self.df[\"n_empty_res_a\"]\n",
    "        self.df[\"n_miss_res_b\"] = self.df[\"n_na_res_b\"] + self.df[\"n_empty_res_b\"]\n",
    "\n",
    "        # 有効な応答数を計算します\n",
    "        self.df[\"n_eff_res_a\"] = self.df[\"n_res_a\"] - self.df[\"n_miss_res_a\"]\n",
    "        self.df[\"n_eff_res_b\"] = self.df[\"n_res_b\"] - self.df[\"n_miss_res_b\"]\n",
    "\n",
    "        # 長さの統計を追加します\n",
    "        self._add_len_stats(\"prompt\")\n",
    "        self._add_len_stats(\"response_a\")\n",
    "        self._add_len_stats(\"response_b\")\n",
    "\n",
    "        self.df[\"res_len_mean_diff\"] = self.df[\"res_a_len_mean\"] - self.df[\"res_b_len_mean\"]  # 応答AとBの長さの平均の差を計算\n",
    "        self.df[\"res_len_mean_diff_clip\"] = self.df[\"res_len_mean_diff\"].clip(-6000, 6000)  # 差の範囲をクリップします\n",
    "\n",
    "        # プロンプトの欠損値をカウントします\n",
    "        self.df[\"n_miss_prompts\"] = self.df[\"n_na_prompts\"] + self.df[\"n_empty_prompts\"]\n",
    "        self.df[\"n_eff_prompts\"] = self.df[\"n_prompts\"] - self.df[\"n_miss_prompts\"]\n",
    "\n",
    "        # 比率を計算します\n",
    "        self.df[\"na_prompt_ratio\"] = self.df[\"n_na_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"empty_prompt_ratio\"] = self.df[\"n_empty_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"miss_prompt_ratio\"] = self.df[\"n_miss_prompts\"] / self.df[\"n_prompts\"]\n",
    "        \n",
    "        self.df[\"na_res_a_ratio\"] = self.df[\"n_na_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"empty_res_a_ratio\"] = self.df[\"n_empty_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"miss_res_a_ratio\"] = self.df[\"n_miss_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"na_res_b_ratio\"] = self.df[\"n_na_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"empty_res_b_ratio\"] = self.df[\"n_empty_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"miss_res_b_ratio\"] = self.df[\"n_miss_res_b\"] / self.df[\"n_res_b\"]\n",
    "\n",
    "        # 各種長さの統計を追加します\n",
    "        for col, col_prefix in zip([\"prompt\", \"response_a\", \"response_b\"], [\"p_len\", \"res_a_len\", \"res_b_len\"]):\n",
    "            self.df[f\"{col_prefix}_med\"] = self.df[col].apply(lambda x: np.median(list(self._len(s) for s in x)))  # 中央値を計算します\n",
    "            self.df[f\"{col_prefix}_std\"] = self.df[col].apply(lambda x: np.std(list(self._len(s) for s in x)))  # 標準偏差を計算します\n",
    "\n",
    "        # 有効な長さの平均を計算します\n",
    "        self.df[\"p_len_eff_mean\"] = self.df[\"p_len_sum\"] / self.df[\"n_eff_prompts\"]\n",
    "        self.df[\"res_a_len_eff_mean\"] = self.df[\"res_a_len_sum\"] / self.df[\"n_eff_res_a\"]\n",
    "        self.df[\"res_b_len_eff_mean\"] = self.df[\"res_b_len_sum\"] / self.df[\"n_eff_res_b\"]\n",
    "\n",
    "        # 長さの差を計算します\n",
    "        for stats in [\"sum\", \"mean\", \"max\", \"med\", \"eff_mean\"]:\n",
    "            self.df[f\"p_a_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_a_len_{stats}\"]\n",
    "            self.df[f\"p_b_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            self.df[f\"a_b_{stats}_diff\"] = self.df[f\"res_a_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            \n",
    "        # 特徴量列を定義します\n",
    "        len_feature_a_col = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                     \"p_a_eff_mean_diff\"]\n",
    "        \n",
    "        len_feature_b_col = [\"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                             \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                             \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        numerical_feature_columns = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                                     \"p_a_eff_mean_diff\", \"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                                     \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                                     \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        # ゼロで割らないように正規化します\n",
    "        for col in numerical_feature_columns:\n",
    "            if self.df[col].std() == 0:\n",
    "                print(f\"Warning: Standard deviation is zero for column {col}. Skipping normalization.\")\n",
    "            else:\n",
    "                self.z_score_normalize([col])  # Zスコア正規化を適用します\n",
    "                \n",
    "        self.df = self.df.fillna(0)  # NaNを0で埋めます\n",
    "        \n",
    "        # 特徴量をリストに変換します\n",
    "        len_features_a = self.df[len_feature_a_col].values.tolist()\n",
    "        len_features_b = self.df[len_feature_b_col].values.tolist()\n",
    "\n",
    "        return len_features_a, len_features_b  # 長さ特徴量を返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca6994",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Data Split\n",
    "\n",
    "在下面提供的代码片段中，我们将使用class_label列的分层将现有数据分为训练和验证。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# データ分割\n",
    "\n",
    "以下のコードスニペットでは、class_label列の層化を使用して、既存のデータをトレーニングデータと検証データに分割します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf5b193",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split  # Import package\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split  # パッケージをインポートします\n",
    "\n",
    "# データフレームをトレーニングデータ（80%）と検証データ（20%）に分割します\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])  # class_label列をもとに層化分割を行います\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # パッケージをインポートします\n",
    "\n",
    "# データフレームをトレーニングデータ（80%）と検証データ（20%）に分割します\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])  # class_label列をもとに層化分割を行います"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6545faf2",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 前処理\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820935ec",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, \n",
    "    sequence_length=CFG.sequence_length, \n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset,  # 設定されたプリセットを使用して前処理器を作成します\n",
    "    sequence_length=CFG.sequence_length,  # 設定されたシーケンス長を指定します\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset,  # 設定されたプリセットを使用して前処理器を作成します\n",
    "    sequence_length=CFG.sequence_length,  # 設定されたシーケンス長を指定します\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f215a6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def preprocess_fn(text, label=None, features_a=None, features_b=None):\n",
    "    text = preprocessor(text)\n",
    "    if features_a is not None:\n",
    "        text['features_a'] = features_a\n",
    "    if features_b is not None:\n",
    "         text['features_b'] = features_b\n",
    "    return (text, label) if label is not None else text  # Return processed text and label if available\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def preprocess_fn(text, label=None, features_a=None, features_b=None):\n",
    "    text = preprocessor(text)  # テキストを前処理します\n",
    "    if features_a is not None:\n",
    "        text['features_a'] = features_a  # features_aが指定されている場合、テキストに追加します\n",
    "    if features_b is not None:\n",
    "         text['features_b'] = features_b  # features_bが指定されている場合、テキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None, features_a=None, features_b=None):\n",
    "    text = preprocessor(text)  # テキストを前処理します\n",
    "    if features_a is not None:\n",
    "        text['features_a'] = features_a  # features_aが指定されている場合、テキストに追加します\n",
    "    if features_b is not None:\n",
    "         text['features_b'] = features_b  # features_bが指定されている場合、テキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b60f55",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# FGM\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# FGM（Fast Gradient Method）\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58fcdcc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # 添加 FGM 扰动函数\n",
    "# def fgm_perturb(features, epsilon=1.0):\n",
    "#     # 计算扰动量，epsilon 为扰动比例\n",
    "#     perturbation = np.random.uniform(-1, 1, features.shape) * epsilon\n",
    "#     # 应用扰动\n",
    "#     return features + perturbation\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# FGMの摂動関数を追加します\n",
    "def fgm_perturb(features, epsilon=1.0):\n",
    "    # 摂動量を計算します。epsilonは摂動の割合です。\n",
    "    perturbation = np.random.uniform(-1, 1, features.shape) * epsilon  # 特徴量の形状に基づいてランダムな摂動を生成します\n",
    "    # 摂動を適用します\n",
    "    return features + perturbation  # 特徴量に摂動を加えたものを返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGMの摂動関数を追加します\n",
    "def fgm_perturb(features, epsilon=1.0):\n",
    "    # 摂動量を計算します。epsilonは摂動の割合です。\n",
    "    perturbation = np.random.uniform(-1, 1, features.shape) * epsilon  # 特徴量の形状に基づいてランダムな摂動を生成します\n",
    "    # 摂動を適用します\n",
    "    return features + perturbation  # 特徴量に摂動を加えたものを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58e035",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # 修改数据预处理函数以包含 FGM 扰动\n",
    "# def preprocess_fn(text, label=None, features_a=None, features_b=None, is_fgm=False, epsilon=1.0):\n",
    "#     # 预处理文本\n",
    "#     text = preprocessor(text)\n",
    "#     if features_a is not None:\n",
    "#         if is_fgm:\n",
    "#             # 如果是 FGM，应用扰动\n",
    "#             features_a = fgm_perturb(features_a, epsilon)\n",
    "#         text['features_a'] = features_a\n",
    "#     if features_b is not None:\n",
    "#         if is_fgm:\n",
    "#             # 如果是 FGM，应用扰动\n",
    "#             features_b = fgm_perturb(features_b, epsilon)\n",
    "#         text['features_b'] = features_b\n",
    "#     return (text, label) if label is not None else text\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データ前処理関数を修正してFGM摂動を含めます\n",
    "def preprocess_fn(text, label=None, features_a=None, features_b=None, is_fgm=False, epsilon=1.0):\n",
    "    # テキストを前処理します\n",
    "    text = preprocessor(text)\n",
    "    if features_a is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_a = fgm_perturb(features_a, epsilon)  # 特徴量AにFGM摂動を加えます\n",
    "        text['features_a'] = features_a  # 特徴量Aをテキストに追加します\n",
    "    if features_b is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_b = fgm_perturb(features_b, epsilon)  # 特徴量BにFGM摂動を加えます\n",
    "        text['features_b'] = features_b  # 特徴量Bをテキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理関数を修正してFGM摂動を含めます\n",
    "def preprocess_fn(text, label=None, features_a=None, features_b=None, is_fgm=False, epsilon=1.0):\n",
    "    # テキストを前処理します\n",
    "    text = preprocessor(text)\n",
    "    if features_a is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_a = fgm_perturb(features_a, epsilon)  # 特徴量AにFGM摂動を加えます\n",
    "        text['features_a'] = features_a  # 特徴量Aをテキストに追加します\n",
    "    if features_b is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_b = fgm_perturb(features_b, epsilon)  # 特徴量BにFGM摂動を加えます\n",
    "        text['features_b'] = features_b  # 特徴量Bをテキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd918ec",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# AWP\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# AWP（Adversarial Weight Perturbation）\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b395e1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#定义 AWP 扰动函数\n",
    "def awp_perturb(model, epsilon=1e-4):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            # 获取权重\n",
    "            weights = layer.kernel\n",
    "            # 计算扰动\n",
    "            perturbation = tf.random.normal(weights.shape, stddev=epsilon)\n",
    "            # 应用扰动\n",
    "            layer.kernel.assign_add(perturbation)\n",
    "\n",
    "#创建 AWP 回调函数\n",
    "class AWPCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, epsilon):\n",
    "        super(AWPCallback, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # 在每个批次开始时应用 AWP 扰动\n",
    "        awp_perturb(self.model, self.epsilon)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# AWP摺動関数を定義します\n",
    "def awp_perturb(model, epsilon=1e-4):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            # 重みを取得します\n",
    "            weights = layer.kernel\n",
    "            # 摺動を計算します\n",
    "            perturbation = tf.random.normal(weights.shape, stddev=epsilon)  # 標準偏差epsilonの正規分布から摺動を生成します\n",
    "            # 摺動を適用します\n",
    "            layer.kernel.assign_add(perturbation)  # 重みに摺動を加えます\n",
    "\n",
    "# AWPコールバック関数を作成します\n",
    "class AWPCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, epsilon):\n",
    "        super(AWPCallback, self).__init__()  # 親クラスの初期化\n",
    "        self.epsilon = epsilon  # 摺動の値を保存します\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # 各バッチの開始時にAWP摺動を適用します\n",
    "        awp_perturb(self.model, self.epsilon)  # モデルにAWP摺動を加えます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWP摺動関数を定義します\n",
    "def awp_perturb(model, epsilon=1e-4):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            # 重みを取得します\n",
    "            weights = layer.kernel\n",
    "            # 摺動を計算します\n",
    "            perturbation = tf.random.normal(weights.shape, stddev=epsilon)  # 標準偏差epsilonの正規分布から摺動を生成します\n",
    "            # 摺動を適用します\n",
    "            layer.kernel.assign_add(perturbation)  # 重みに摺動を加えます\n",
    "\n",
    "# AWPコールバック関数を作成します\n",
    "class AWPCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, epsilon):\n",
    "        super(AWPCallback, self).__init__()  # 親クラスの初期化\n",
    "        self.epsilon = epsilon  # 摺動の値を保存します\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # 各バッチの開始時にAWP摺動を適用します\n",
    "        awp_perturb(self.model, self.epsilon)  # モデルにAWP摺動を加えます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b877ff",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# DataLoader\n",
    "\n",
    "下面的代码使用tf.data.Dataset为数据处理设置了一个健壮的数据流管道。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# DataLoader\n",
    "\n",
    "以下のコードは、tf.data.Datasetを使用してデータ処理のための堅牢なデータフロー・パイプラインを設定します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a72d6d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def build_dataset_with_features(texts, labels=None, features_a=None, features_b=None, batch_size=32, is_fgm=False,  epsilon=1.0,\n",
    "                                cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE\n",
    "    if (features_a is not None) and (features_b is not None):\n",
    "        slices = (texts, None, features_a, features_b) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3), features_a, features_b)  # Create slices\n",
    "    else:\n",
    "        slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)\n",
    "    ds = ds.cache() if cache else ds\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)\n",
    "#     ds = ds.map(lambda x: preprocess_fn(x, features_a=features_a, features_b=features_b, is_fgm=is_fgm, epsilon=epsilon),\n",
    "#                 num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    opt = tf.data.Options()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
    "        opt.experimental_deterministic = False\n",
    "    ds = ds.with_options(opt)\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    \n",
    "    return ds\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def build_dataset_with_features(texts, labels=None, features_a=None, features_b=None, batch_size=32, is_fgm=False,  epsilon=1.0,\n",
    "                                cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # 自動調整を有効にします\n",
    "    if (features_a is not None) and (features_b is not None):\n",
    "        # ラベルがない場合はテキストと特徴量のみ、ある場合はラベルも追加します\n",
    "        slices = (texts, None, features_a, features_b) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3), features_a, features_b)  # スライスを作成します\n",
    "    else:\n",
    "        slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # スライスを作成します\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # テンソルのスライスからデータセットを生成します\n",
    "    ds = ds.cache() if cache else ds  # キャッシュを使用するかどうかを設定します\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # 前処理関数を各要素に適用します\n",
    "#     ds = ds.map(lambda x: preprocess_fn(x, features_a=features_a, features_b=features_b, is_fgm=is_fgm, epsilon=epsilon),\n",
    "#                 num_parallel_calls=tf.data.AUTOTUNE)  # (コメントアウトされたコード)摺動を考慮した前処理\n",
    "    opt = tf.data.Options()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # シャッフルを有効にします\n",
    "        opt.experimental_deterministic = False  # 結果の非決定性を許可します\n",
    "    ds = ds.with_options(opt)  # オプションを適用します\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # バッチに分けます\n",
    "    ds = ds.prefetch(AUTO)  # プリフェッチを使用してデータを事前に読み込む\n",
    "\n",
    "    return ds  # データセットを返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def build_dataset_with_features(texts, labels=None, features_a=None, features_b=None, batch_size=32, is_fgm=False,  epsilon=1.0,\n",
    "                                cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # 自動調整を有効にします\n",
    "    if (features_a is not None) and (features_b is not None):\n",
    "        # ラベルがない場合はテキストと特徴量のみ、ある場合はラベルも追加します\n",
    "        slices = (texts, None, features_a, features_b) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3), features_a, features_b)  # スライスを作成します\n",
    "    else:\n",
    "        slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # スライスを作成します\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # テンソルのスライスからデータセットを生成します\n",
    "    ds = ds.cache() if cache else ds  # キャッシュを使用するかどうかを設定します\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # 前処理関数を各要素に適用します\n",
    "#     ds = ds.map(lambda x: preprocess_fn(x, features_a=features_a, features_b=features_b, is_fgm=is_fgm, epsilon=epsilon),\n",
    "#                 num_parallel_calls=tf.data.AUTOTUNE)  # (コメントアウトされたコード)摺動を考慮した前処理\n",
    "    opt = tf.data.Options()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # シャッフルを有効にします\n",
    "        opt.experimental_deterministic = False  # 結果の非決定性を許可します\n",
    "    ds = ds.with_options(opt)  # オプションを適用します\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # バッチに分けます\n",
    "    ds = ds.prefetch(AUTO)  # プリフェッチを使用してデータを事前に読み込む\n",
    "\n",
    "    return ds  # データセットを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3743c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Build Train/Valid Dataloader\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トレーニング/検証データローダーの構築\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530aa48",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_features_processor = DataFrameStatsProcessor(train_df.copy())\n",
    "train_features_a, train_features_b = train_features_processor.process_dataframe()\n",
    "valid_features_processor = DataFrameStatsProcessor(valid_df.copy())\n",
    "valid_features_a, valid_features_b = valid_features_processor.process_dataframe()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_features_processor = DataFrameStatsProcessor(train_df.copy())  # トレーニングデータフレームのコピーを使用して特徴量処理器を作成します\n",
    "train_features_a, train_features_b = train_features_processor.process_dataframe()  # トレーニングデータの特徴量を処理します\n",
    "valid_features_processor = DataFrameStatsProcessor(valid_df.copy())  # 検証データフレームのコピーを使用して特徴量処理器を作成します\n",
    "valid_features_a, valid_features_b = valid_features_processor.process_dataframe()  # 検証データの特徴量を処理します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_processor = DataFrameStatsProcessor(train_df.copy())  # トレーニングデータフレームのコピーを使用して特徴量処理器を作成します\n",
    "train_features_a, train_features_b = train_features_processor.process_dataframe()  # トレーニングデータの特徴量を処理します\n",
    "valid_features_processor = DataFrameStatsProcessor(valid_df.copy())  # 検証データフレームのコピーを使用して特徴量処理器を作成します\n",
    "valid_features_a, valid_features_b = valid_features_processor.process_dataframe()  # 検証データの特徴量を処理します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1944a2b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # Train\n",
    "train_texts = train_df.options.tolist()  \n",
    "train_labels = train_df.class_label.tolist() \n",
    "train_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b, \n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True)\n",
    "# # Valid\n",
    "valid_texts = valid_df.options.tolist()  \n",
    "valid_labels = valid_df.class_label.tolist() \n",
    "valid_ds = build_dataset_with_features(valid_texts, valid_labels, valid_features_a, valid_features_b, \n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False)\n",
    "print(train_ds)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータの準備\n",
    "train_texts = train_df.options.tolist()  # トレーニングデータのテキストをリストに変換します\n",
    "train_labels = train_df.class_label.tolist()  # トレーニングデータのラベルをリストに変換します\n",
    "train_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=True)  # シャッフルを有効にします\n",
    "\n",
    "# 検証データの準備\n",
    "valid_texts = valid_df.options.tolist()  # 検証データのテキストをリストに変換します\n",
    "valid_labels = valid_df.class_label.tolist()  # 検証データのラベルをリストに変換します\n",
    "valid_ds = build_dataset_with_features(valid_texts, valid_labels, valid_features_a, valid_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(train_ds)  # トレーニングデータセットの情報を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの準備\n",
    "train_texts = train_df.options.tolist()  # トレーニングデータのテキストをリストに変換します\n",
    "train_labels = train_df.class_label.tolist()  # トレーニングデータのラベルをリストに変換します\n",
    "train_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=True)  # シャッフルを有効にします\n",
    "\n",
    "# 検証データの準備\n",
    "valid_texts = valid_df.options.tolist()  # 検証データのテキストをリストに変換します\n",
    "valid_labels = valid_df.class_label.tolist()  # 検証データのラベルをリストに変換します\n",
    "valid_ds = build_dataset_with_features(valid_texts, valid_labels, valid_features_a, valid_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(train_ds)  # トレーニングデータセットの情報を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ca11a6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# LR Schedule\n",
    "\n",
    "实施学习率调度程序对于迁移学习至关重要。\n",
    "\n",
    "学习率从 lr_start 开始，然后使用各种技术逐渐减小到 lr_min，包括：\n",
    "\n",
    "- step：以类似楼梯的方式逐步降低学习率。\n",
    "- cos：利用余弦曲线逐渐降低学习率。\n",
    "- exp：以指数方式降低学习率。\n",
    "\n",
    "**重要性**：结构良好的学习率调度对于有效的模型训练至关重要，可确保最佳收敛并避免诸如过冲或停滞等问题。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 学習率スケジュール\n",
    "\n",
    "学習率スケジューラの実装は、転移学習において重要です。\n",
    "\n",
    "学習率は、lr_startから始まり、さまざまな手法を使用してlr_minまで徐々に減少します。これには以下が含まれます：\n",
    "\n",
    "- step：階段状に学習率を段階的に減少させます。\n",
    "- cos：コサイン曲線を利用して学習率を徐々に減少させます。\n",
    "- exp：指数関数的に学習率を減少させます。\n",
    "\n",
    "**重要性**：適切に構造化された学習率スケジュールは、モデルの効果的なトレーニングに不可欠であり、最適な収束を保証し、オーバーシュートや停滞などの問題を回避します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f40bf5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n",
    "\n",
    "    def lrfn(epoch):  # Learning rate update function\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "    \n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # 学習率の開始値、最大値、最小値を設定します\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # 学習率のランプアップエポック、持続エポック、減衰率を設定します\n",
    "\n",
    "    def lrfn(epoch):  # 学習率更新関数\n",
    "        # エポックに応じて学習率を計算します\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ランプアップ段階\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # 最大学習率を維持します\n",
    "        elif mode == 'exp:': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # 指数的減衰\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ステップ減衰\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # コサインの位相を計算します\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min  # コサイン曲線による減衰\n",
    "        return lr  # 計算された学習率を返します\n",
    "    \n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # 学習率コールバックを作成します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # 学習率の開始値、最大値、最小値を設定します\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # 学習率のランプアップエポック、持続エポック、減衰率を設定します\n",
    "\n",
    "    def lrfn(epoch):  # 学習率更新関数\n",
    "        # エポックに応じて学習率を計算します\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ランプアップ段階\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # 最大学習率を維持します\n",
    "        elif mode == 'exp:': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # 指数的減衰\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ステップ減衰\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # コサインの位相を計算します\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min  # コサイン曲線による減衰\n",
    "        return lr  # 計算された学習率を返します\n",
    "    \n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # 学習率コールバックを作成します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bda00",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lr_cb = get_lr_callback(CFG.batch_size, epochs=CFG.epochs)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "lr_cb = get_lr_callback(CFG.batch_size, epochs=CFG.epochs)  # 設定されたバッチサイズとエポック数で学習率コールバックを取得します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cb = get_lr_callback(CFG.batch_size, epochs=CFG.epochs)  # 設定されたバッチサイズとエポック数で学習率コールバックを取得します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1102105",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Model Checkpointing\n",
    "\n",
    "下面的代码将创建一个回调，在训练期间保存模型的最佳检查点，我们将在提交时使用它进行推理。\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# モデルチェックポイント\n",
    "\n",
    "以下のコードは、トレーニング中にモデルの最良のチェックポイントを保存するコールバックを作成します。これは、提出時の推論に使用します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8936595",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',\n",
    "                                          save_best_only=True,\n",
    "                                          save_weights_only=True,\n",
    "                                          mode='min')  # Get Model checkpoint callback\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # 検証ロスを監視します\n",
    "                                          save_best_only=True,  # 最良のモデルのみを保存します\n",
    "                                          save_weights_only=True,  # 重みのみを保存します\n",
    "                                          mode='min')  # 最小化モードで監視します（ロスが最小のときに保存）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # 検証ロスを監視します\n",
    "                                          save_best_only=True,  # 最良のモデルのみを保存します\n",
    "                                          save_weights_only=True,  # 重みのみを保存します\n",
    "                                          mode='min')  # 最小化モードで監視します（ロスが最小のときに保存）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a968ed4c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Metric\n",
    "\n",
    "这次比赛的指标是对数损失。这个度量可以用数学表示为：\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# メトリック\n",
    "\n",
    "今回のコンペティションの評価指標は対数損失です。この尺度は数学的に次のように表されます：\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc1659c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\", label_smoothing=0.1, from_logits=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\", label_smoothing=0.1, from_logits=False)  # 対数損失を計算するためのメトリックを定義します。ラベルスムージングを適用します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\", label_smoothing=0.1, from_logits=False)  # 対数損失を計算するためのメトリックを定義します。ラベルスムージングを適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2736da",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Modeling\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# モデリング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82bfe09",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # 将所有输入层整合到一个字典中\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "        \"padding_mask\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "        \"features_a\": keras.layers.Input(shape=(14,), name=\"features_a\", dtype=tf.float32),\n",
    "        \"features_b\": keras.layers.Input(shape=(14,), name=\"features_b\", dtype=tf.float32),\n",
    "    }\n",
    "    \n",
    "    # Create a DebertaV3Classifier backbone\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "        CFG.preset,\n",
    "    )\n",
    "\n",
    "   # 修改 response_a 和 response_b 的创建方式，包含 padding_mask\n",
    "    response_a = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 0, :],\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 0, :]\n",
    "    }\n",
    "    embed_a = backbone(response_a)\n",
    "\n",
    "    response_b = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 1, :],\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 1, :]\n",
    "    }\n",
    "    embed_b = backbone(response_b)\n",
    "    \n",
    "    # 将数值特征嵌入\n",
    "    len_features_a_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_a\"])\n",
    "    len_features_b_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_b\"])\n",
    "    \n",
    "    # 使用 Flatten 层将数值特征嵌入展平为二维张量\n",
    "    flattened_len_features_a = keras.layers.Flatten()(len_features_a_embedding)\n",
    "    flattened_len_features_b = keras.layers.Flatten()(len_features_b_embedding)\n",
    "    \n",
    "    embed_a = keras.layers.GlobalAveragePooling1D()(embed_a)\n",
    "    embed_b = keras.layers.GlobalAveragePooling1D()(embed_b)\n",
    "    embeds_text_features_a = keras.layers.Concatenate(axis=-1)([embed_a, flattened_len_features_a])\n",
    "    embeds_text_features_b = keras.layers.Concatenate(axis=-1)([embed_b, flattened_len_features_b])\n",
    "    \n",
    "    # 合并文本嵌入和数值特征嵌入\n",
    "    combined_embeds = keras.layers.Concatenate(axis=-1)([embeds_text_features_a, embeds_text_features_a])\n",
    "    \n",
    "    # 添加L2正则化和Dropout到模型中\n",
    "    combined_embeds = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(combined_embeds)  # L2正则化\n",
    "    combined_embeds = Dropout(0.05)(combined_embeds)  # Dropout层，丢弃5%的神经元\n",
    "    \n",
    "    # 定义 temperature_scale 函数\n",
    "    def temperature_scale(logits, T=1.0):\n",
    "        return logits / T\n",
    "    \n",
    "    # 定义温度参数 T\n",
    "    T = 0.85\n",
    "    # 应用温度缩放\n",
    "    scaled_logits = temperature_scale(combined_embeds, T)\n",
    "    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(scaled_logits)\n",
    "    \n",
    "    model = keras.Model(inputs,  outputs)\n",
    "    \n",
    "    # Compile the model with optimizer, loss, and metrics\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-6, clipnorm=1.0),\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1, from_logits=False),\n",
    "        metrics=[\n",
    "            log_loss,\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # 添加 AWP 回调到模型训练中\n",
    "    awp_cb = AWPCallback(epsilon=1e-4)  # 您可以根据需要调整 epsilon 的值\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # すべての入力層を辞書にまとめます\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),  # トークンIDの入力\n",
    "        \"padding_mask\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),  # パディングマスクの入力\n",
    "        \"features_a\": keras.layers.Input(shape=(14,), name=\"features_a\", dtype=tf.float32),  # 特徴量Aの入力\n",
    "        \"features_b\": keras.layers.Input(shape=(14,), name=\"features_b\", dtype=tf.float32),  # 特徴量Bの入力\n",
    "    }\n",
    "\n",
    "    # DebertaV3Classifierバックボーンを作成します\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "        CFG.preset,\n",
    "    )\n",
    "\n",
    "    # response_aとresponse_bの作成方法を修正し、padding_maskを含めます\n",
    "    response_a = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 0, :],  # 最初のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 0, :]  # 最初のパディングマスクを取得\n",
    "    }\n",
    "    embed_a = backbone(response_a)  # バックボーンを通して埋め込みを取得します\n",
    "\n",
    "    response_b = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 1, :],  # 2番目のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 1, :]  # 2番目のパディングマスクを取得\n",
    "    }\n",
    "    embed_b = backbone(response_b)  # バックボーンを通して埋め込みを取得します\n",
    "    \n",
    "    # 数値特徴を埋め込みます\n",
    "    len_features_a_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_a\"])  # 特徴量Aの数値埋め込み\n",
    "    len_features_b_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_b\"])  # 特徴量Bの数値埋め込み\n",
    "    \n",
    "    # Flatten層を使用して数値特徴埋め込みを2次元テンソルに展開します\n",
    "    flattened_len_features_a = keras.layers.Flatten()(len_features_a_embedding)  # Flattenによる変換\n",
    "    flattened_len_features_b = keras.layers.Flatten()(len_features_b_embedding)  # Flattenによる変換\n",
    "    \n",
    "    embed_a = keras.layers.GlobalAveragePooling1D()(embed_a)  # グローバル平均プーリング\n",
    "    embed_b = keras.layers.GlobalAveragePooling1D()(embed_b)  # グローバル平均プーリング\n",
    "    embeds_text_features_a = keras.layers.Concatenate(axis=-1)([embed_a, flattened_len_features_a])  # テキスト埋め込みと数値特徴を結合\n",
    "    embeds_text_features_b = keras.layers.Concatenate(axis=-1)([embed_b, flattened_len_features_b])  # テキスト埋め込みと数値特徴を結合\n",
    "    \n",
    "    # テキスト埋め込みと数値特徴埋め込みを結合します\n",
    "    combined_embeds = keras.layers.Concatenate(axis=-1)([embeds_text_features_a, embeds_text_features_b])  # テキストと特徴を結合\n",
    "    \n",
    "    # モデルにL2正則化とDropoutを追加します\n",
    "    combined_embeds = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(combined_embeds)  # L2正則化\n",
    "    combined_embeds = Dropout(0.05)(combined_embeds)  # Dropoutレイヤー、5%のニューロンをドロップ\n",
    "    \n",
    "    # 温度スケール関数を定義します\n",
    "    def temperature_scale(logits, T=1.0):\n",
    "        return logits / T  # ロジットを温度で割ります\n",
    "    \n",
    "    # 温度パラメータTを定義します\n",
    "    T = 0.85\n",
    "    # 温度スケーリングを適用します\n",
    "    scaled_logits = temperature_scale(combined_embeds, T)  # 温度スケールを適用したロジット\n",
    "    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(scaled_logits)  # 出力層を定義します\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)  # モデルを作成します\n",
    "    \n",
    "    # オプティマイザ、損失、メトリックでモデルをコンパイルします\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-6, clipnorm=1.0),  # Adamオプティマイザを使用\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1, from_logits=False),  # カテゴリカルクロスエントロピー損失\n",
    "        metrics=[\n",
    "            log_loss,  # 定義した対数損失\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),  # 精度メトリック\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # AWPコールバックをモデルのトレーニングに追加します\n",
    "    awp_cb = AWPCallback(epsilon=1e-4)  # epsilon値は必要に応じて調整できます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # すべての入力層を辞書にまとめます\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),  # トークンIDの入力\n",
    "        \"padding_mask\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),  # パディングマスクの入力\n",
    "        \"features_a\": keras.layers.Input(shape=(14,), name=\"features_a\", dtype=tf.float32),  # 特徴量Aの入力\n",
    "        \"features_b\": keras.layers.Input(shape=(14,), name=\"features_b\", dtype=tf.float32),  # 特徴量Bの入力\n",
    "    }\n",
    "\n",
    "    # DebertaV3Classifierバックボーンを作成します\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "        CFG.preset,\n",
    "    )\n",
    "\n",
    "    # response_aとresponse_bの作成方法を修正し、padding_maskを含めます\n",
    "    response_a = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 0, :],  # 最初のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 0, :]  # 最初のパディングマスクを取得\n",
    "    }\n",
    "    embed_a = backbone(response_a)  # バックボーンを通して埋め込みを取得します\n",
    "\n",
    "    response_b = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 1, :],  # 2番目のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 1, :]  # 2番目のパディングマスクを取得\n",
    "    }\n",
    "    embed_b = backbone(response_b)  # バックボーンを通して埋め込みを取得します\n",
    "    \n",
    "    # 数値特徴を埋め込みます\n",
    "    len_features_a_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_a\"])  # 特徴量Aの数値埋め込み\n",
    "    len_features_b_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_b\"])  # 特徴量Bの数値埋め込み\n",
    "    \n",
    "    # Flatten層を使用して数値特徴埋め込みを2次元テンソルに展開します\n",
    "    flattened_len_features_a = keras.layers.Flatten()(len_features_a_embedding)  # Flattenによる変換\n",
    "    flattened_len_features_b = keras.layers.Flatten()(len_features_b_embedding)  # Flattenによる変換\n",
    "    \n",
    "    embed_a = keras.layers.GlobalAveragePooling1D()(embed_a)  # グローバル平均プーリング\n",
    "    embed_b = keras.layers.GlobalAveragePooling1D()(embed_b)  # グローバル平均プーリング\n",
    "    embeds_text_features_a = keras.layers.Concatenate(axis=-1)([embed_a, flattened_len_features_a])  # テキスト埋め込みと数値特徴を結合\n",
    "    embeds_text_features_b = keras.layers.Concatenate(axis=-1)([embed_b, flattened_len_features_b])  # テキスト埋め込みと数値特徴を結合\n",
    "    \n",
    "    # テキスト埋め込みと数値特徴埋め込みを結合します\n",
    "    combined_embeds = keras.layers.Concatenate(axis=-1)([embeds_text_features_a, embeds_text_features_b])  # テキストと特徴を結合\n",
    "    \n",
    "    # モデルにL2正則化とDropoutを追加します\n",
    "    combined_embeds = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(combined_embeds)  # L2正則化\n",
    "    combined_embeds = Dropout(0.05)(combined_embeds)  # Dropoutレイヤー、5%のニューロンをドロップ\n",
    "    \n",
    "    # 温度スケール関数を定義します\n",
    "    def temperature_scale(logits, T=1.0):\n",
    "        return logits / T  # ロジットを温度で割ります\n",
    "    \n",
    "    # 温度パラメータTを定義します\n",
    "    T = 0.85\n",
    "    # 温度スケーリングを適用します\n",
    "    scaled_logits = temperature_scale(combined_embeds, T)  # 温度スケールを適用したロジット\n",
    "    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(scaled_logits)  # 出力層を定義します\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)  # モデルを作成します\n",
    "    \n",
    "    # オプティマイザ、損失、メトリックでモデルをコンパイルします\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-6, clipnorm=1.0),  # Adamオプティマイザを使用\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1, from_logits=False),  # カテゴリカルクロスエントロピー損失\n",
    "        metrics=[\n",
    "            log_loss,  # 定義した対数損失\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),  # 精度メトリック\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # AWPコールバックをモデルのトレーニングに追加します\n",
    "    awp_cb = AWPCallback(epsilon=1e-4)  # epsilon値は必要に応じて調整できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e3fbf",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Model Summary\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### モデルの概要\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67f1b43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.summary()  # モデルのサマリーを表示します。各層の出力形状やパラメータ数を確認できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model.summary()  # モデルのサマリーを表示します。各層の出力形状やパラメータ数を確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600c5fe0",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Training\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# トレーニング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452f27f5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# try:\n",
    "#     history = model.fit(\n",
    "#         train_ds,\n",
    "#         epochs=CFG.epochs,\n",
    "#         validation_data=valid_ds,\n",
    "#         callbacks=[lr_cb, ckpt_cb]\n",
    "#     )\n",
    "# except tf.errors.InvalidArgumentError as e:\n",
    "#     print(f\"出现无效参数错误：{e}\")\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=CFG.epochs,\n",
    "        validation_data=valid_ds,\n",
    "        callbacks=[lr_cb, ckpt_cb, awp_cb]  # 将 AWP 回调添加到训练回调列表中\n",
    "    )\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"出现无效参数错误：{e}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# tryブロック内でエラー処理を実装します\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,  # トレーニングデータセット\n",
    "        epochs=CFG.epochs,  # 設定されたエポック数で学習\n",
    "        validation_data=valid_ds,  # 検証データセット\n",
    "        callbacks=[lr_cb, ckpt_cb, awp_cb]  # 学習率コールバック、チェックポイントコールバック、AWPコールバックを追加\n",
    "    )\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"無効な引数エラーが発生しました：{e}\")  # エラーが発生した場合、そのメッセージを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# tryブロック内でエラー処理を実装します\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,  # トレーニングデータセット\n",
    "        epochs=CFG.epochs,  # 設定されたエポック数で学習\n",
    "        validation_data=valid_ds,  # 検証データセット\n",
    "        callbacks=[lr_cb, ckpt_cb, awp_cb]  # 学習率コールバック、チェックポイントコールバック、AWPコールバックを追加\n",
    "    )\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"無効な引数エラーが発生しました：{e}\")  # エラーが発生した場合、そのメッセージを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0593a0e4",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load Best Model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 最良モデルの読み込み\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d89b0d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')  # 最良モデルの重みを読み込みます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/working/best_model.weights.h5')  # 最良モデルの重みを読み込みます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675c7c83",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Prediction\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 予測\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb4c7a9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# # 使用 FGM 扰动的数据集评估模型\n",
    "# fgm_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b,\n",
    "#                                      is_fgm=True, epsilon=1.0)\n",
    "# evaluation_results = model.evaluate(fgm_ds)\n",
    "\n",
    "# print(f\"Evaluation results on FGM perturbed dataset: {evaluation_results}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# FGM摺動を使用したデータセットでモデルを評価します\n",
    "fgm_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b,\n",
    "                                     is_fgm=True, epsilon=1.0)  # FGMを使用してデータセットを構築します\n",
    "evaluation_results = model.evaluate(fgm_ds)  # 評価を実行します\n",
    "\n",
    "print(f\"FGM摺動データセットの評価結果: {evaluation_results}\")  # FGM摺動データセットでの評価結果を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGM摺動を使用したデータセットでモデルを評価します\n",
    "fgm_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b,\n",
    "                                     is_fgm=True, epsilon=1.0)  # FGMを使用してデータセットを構築します\n",
    "evaluation_results = model.evaluate(fgm_ds)  # 評価を実行します\n",
    "\n",
    "print(f\"FGM摺動データセットの評価結果: {evaluation_results}\")  # FGM摺動データセットでの評価結果を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b63574",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_df_features_processor = DataFrameStatsProcessor(test_df)\n",
    "test_df_features_a, test_df_features_b = test_df_features_processor.process_dataframe()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_df_features_processor = DataFrameStatsProcessor(test_df)  # テストデータフレームの特徴量処理器を作成します\n",
    "test_df_features_a, test_df_features_b = test_df_features_processor.process_dataframe()  # テストデータの特徴量を処理します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_features_processor = DataFrameStatsProcessor(test_df)  # テストデータフレームの特徴量処理器を作成します\n",
    "test_df_features_a, test_df_features_b = test_df_features_processor.process_dataframe()  # テストデータの特徴量を処理します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d53f7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset_with_features(test_texts, features_a=test_df_features_a, features_b=test_df_features_b,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)\n",
    "print(test_ds)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_texts = test_df.options.tolist()  # テストデータのテキストをリストに変換します\n",
    "test_ds = build_dataset_with_features(test_texts, features_a=test_df_features_a, features_b=test_df_features_b,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),  # テストデータの長さと設定されたバッチサイズの最小値を使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(test_ds)  # テストデータセットの情報を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df.options.tolist()  # テストデータのテキストをリストに変換します\n",
    "test_ds = build_dataset_with_features(test_texts, features_a=test_df_features_a, features_b=test_df_features_b,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),  # テストデータの長さと設定されたバッチサイズの最小値を使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(test_ds)  # テストデータセットの情報を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1ed60",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test_preds = model.predict(test_ds, verbose=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_preds = model.predict(test_ds, verbose=1)  # テストデータセットに対してモデルの予測を実行します。進捗を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_ds, verbose=1)  # テストデータセットに対してモデルの予測を実行します。進捗を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885f3d1",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Submission\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 提出\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c7a81",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "sub_df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "sub_df = test_df[[\"id\"]].copy()  # テストデータから'id'列をコピーします\n",
    "sub_df[CFG.class_names] = test_preds.tolist()  # 予測結果をコピーして新しいデータフレームに追加します\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # 提出用ファイルをCSV形式で保存します\n",
    "sub_df.head()  # 提出データフレームの先頭を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_df[[\"id\"]].copy()  # テストデータから'id'列をコピーします\n",
    "sub_df[CFG.class_names] = test_preds.tolist()  # 予測結果をコピーして新しいデータフレームに追加します\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # 提出用ファイルをCSV形式で保存します\n",
    "sub_df.head()  # 提出データフレームの先頭を表示します"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5306138,
     "sourceId": 8820093,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5310688,
     "sourceId": 8826860,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5310716,
     "sourceId": 8826894,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
