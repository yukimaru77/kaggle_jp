{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ce74b2",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおける、人間が好む応答を予測するための機械学習モデルの構築を目的としています。具体的には、異なる言語モデル（LLM）が生成した応答に基づき、どちらのモデルの応答が優れているかを予測する問題に取り組んでいます。\n",
    "\n",
    "### 手法\n",
    "ノートブックでは、次の手法やライブラリが使用されています。\n",
    "\n",
    "1. **データ前処理**:\n",
    "   - NLTKやSpaCyを用いてテキストデータのトークン化、ストップワードの除去、類似度の計算を行っています。\n",
    "   - 特徴量エンジニアリングにより、応答の長さ、文の多様性、共通単語数などを特徴量として抽出しています。\n",
    "\n",
    "2. **モデルの構築**:\n",
    "   - 勾配ブースティングアルゴリズムを使用し、XGBoost、CatBoost、GradientBoostingClassifierなどのモデルが選定されています。\n",
    "   - データセットは80:20の比率で訓練データと検証データに分割され、層別交差検証を適用してモデルの検証が行われています。\n",
    "\n",
    "3. **モデルの評価**:\n",
    "   - モデルのパフォーマンスは、対数損失（log loss）を使用して評価されています。\n",
    "   - 各モデルの平均ロスを比較し、最良のモデルのハイパーパラメータチューニングにはグリッドサーチが利用されています。\n",
    "\n",
    "4. **結果の予測と提出**:\n",
    "   - 最終的に得られたモデルを用いてテストデータに対する予測を行い、その結果を提出用フォーマットに整形しています。\n",
    "\n",
    "### 使用ライブラリ\n",
    "ノートブックでは、以下の主要なライブラリがインポートされています：\n",
    "- **Pandas** と **NumPy**: データ操作と数値計算のため。\n",
    "- **Matplotlib** と **Seaborn**: データの可視化のため。\n",
    "- **Scikit-learn**: 機械学習モデル、評価指標、データ分割のため。\n",
    "- **XGBoost** と **CatBoost**: 高効率な勾配ブースティングアルゴリズムのため。\n",
    "- **NLTK** と **SpaCy**: 自然言語処理のためのライブラリです。\n",
    "\n",
    "このノートブックは、応答の優劣を判別するモデルの作成を通じて、ユーザーの好みを予測することに注力しており、様々な特徴量をデータから抽出し、機械学習技術を駆使して問題解決に取り組んでいます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03bb85c",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容から、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説です。有名なものや簡単なものは含まれていません。\n",
    "\n",
    "1. **ブースティング**\n",
    "   - 複数の「弱い」機械学習モデル（精度の低いモデル）を結合して「強い」モデルを作成する手法。弱いモデルの予測誤差を次のモデルが学習し修正することを目的とする。\n",
    "\n",
    "2. **XGBoost**\n",
    "   - 勾配ブースティングに基づくアルゴリズムで、決定木を用いた高性能な分類器。特に計算速度とパフォーマンスに優れ、高速な学習が可能。\n",
    "\n",
    "3. **CatBoost**\n",
    "   - カテゴリカルデータ（文字列やカテゴリー型データ）を効果的に処理するために設計された勾配ブースティングアルゴリズム。デフォルトでオーバーフィッティングを防ぐ機能があり、前処理の手間を減らす特徴がある。\n",
    "\n",
    "4. **ストップワード**\n",
    "   - 自然言語処理において、意味が薄かったり頻繁に使われるため情報価値が低い単語（例：the, is, atなど）。これらを分析から除外することで、重要な情報に焦点を当てる。\n",
    "\n",
    "5. **トークン化**\n",
    "   - テキストデータを単語や文といった小さな部分（トークン）に分割するプロセス。自然言語処理の前処理で行われ、モデルが入力を理解する助けとなる。\n",
    "\n",
    "6. **ステミング**\n",
    "   - 単語の語幹を取り出す処理。例えば、\"running\" や \"ran\" はどちらも \"run\" に変換される。単語の基本形に揃えることで、同じ意味の単語を統一して扱うことができる。\n",
    "\n",
    "7. **レmmatization**\n",
    "   - ステミングに似ているが、文脈に応じて言葉を正しい形に変換するより高度なプロセス。辞書に基づいた変換を行うため、より自然な結果が得られる。\n",
    "\n",
    "8. **探索的分析**\n",
    "   - データの特性やパターン、関係性を視覚化や統計的手法を用いて探るプロセス。機械学習モデルを構築する前に重要なステップ。\n",
    "\n",
    "9. **クロスバリデーション**\n",
    "   - モデルの性能をより正確に評価するための手法。データセットをいくつかのサブセットに分割し、各サブセットをテストデータとして使用してモデルの一般化能力を確認する。\n",
    "\n",
    "10. **ハイパーパラメータ**\n",
    "    - 機械学習アルゴリズムの設定値で、モデルの学習プロセスに影響を及ぼす。これらの値は学習によって決定されるのではなく、事前に設定する必要がある。\n",
    "\n",
    "11. **グリッドサーチ**\n",
    "    - 複数のハイパーパラメータの組み合わせを試して、最適なパラメータセットを探す手法。各組み合わせにおいてモデルを評価し、最も性能が良いものを選択する。\n",
    "\n",
    "12. **メトリクス**\n",
    "    - モデルの性能を評価するための指標。例えば、精度、再現率、F1スコア、ログ損失などがある。\n",
    "\n",
    "13. **類似度**\n",
    "    - 2つのテキストの関連性や一致度を示す指標。自然言語処理でこの概念は、応答とプロンプト間の関係を測るのに用いられる。\n",
    "\n",
    "これらの用語は、特に実務経験がない初心者には馴染みが薄いことが多く、理解を深めるために重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ac436",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# LMSys Chatbot Arena\n",
    "\n",
    "Propose, document and defend a solution that can determine which answer is better, or if there is a tie, based on criteria you define..  \n",
    "\n",
    "\n",
    "**Proposal**: Boosting is a machine learning technique that combines the results of several weak model trainings to create a strong model. The process uses a sequence of interactions, where weights are used for the errors obtained in each training session.\n",
    "\n",
    "**Example**: XGBoost is a machine learning algorithm based on gradient boosting and using decision trees, where each tree tries to correct the errors of the previous tree.\n",
    "\n",
    "**Features**: For this problem, we will use features extracted from the texts in our dataset.\n",
    "\n",
    "In this case, we can use exploratory analysis to establish features add to our classification, such as:\n",
    "- Size of the texts;\n",
    "- Words present in the question and answears;\n",
    "- Difference between answears, etc.\n",
    "\n",
    "## 1 - Pre-processing\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# LMSys Chatbot Arena\n",
    "\n",
    "提案、文書作成、そして定義した基準に基づいてどの回答が優れているか、または引き分けかを判断するソリューションを擁護します。  \n",
    "\n",
    "**提案**: ブースティングは、複数の弱いモデルのトレーニング結果を組み合わせて強いモデルを作成する機械学習手法です。このプロセスでは、一連の相互作用が使用され、各トレーニングセッションで得られた誤差に重みが付けられます。\n",
    "\n",
    "**例**: XGBoostは、勾配ブースティングに基づく機械学習アルゴリズムであり、決定木を使用します。各木は前の木の誤差を修正しようとします。\n",
    "\n",
    "**特徴**: この問題に対して、私たちのデータセットに含まれるテキストから抽出した特徴を使用します。\n",
    "\n",
    "この場合、特徴を確立するために探査的分析を使用し、分類に追加できる要素としては以下のようなものがあります：\n",
    "- テキストのサイズ；\n",
    "- 質問と回答に存在する単語；\n",
    "- 回答間の違いなど。\n",
    "\n",
    "## 1 - 前処理\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644afb36",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Librarys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = 14,5\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style = 'whitegrid'\n",
    "\n",
    "import plotly.express as px\n",
    "px.defaults.template = \"plotly_dark\"\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Classification models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ライブラリのインポート\n",
    "import pandas as pd  # データ操作のためのPandasライブラリをインポートします。\n",
    "import numpy as np  # 数値計算のためのNumPyライブラリをインポートします。\n",
    "import matplotlib.pyplot as plt  # グラフ作成のためのMatplotlibライブラリをインポートします。\n",
    "plt.rcParams['figure.figsize'] = 14,5  # グラフのサイズを14x5に設定します。\n",
    "\n",
    "import seaborn as sns  # データ可視化のためのSeabornライブラリをインポートします。\n",
    "sns.set_style = 'whitegrid'  # グラフのスタイルを白いグリッドに設定します。\n",
    "\n",
    "import plotly.express as px  # インタラクティブなグラフ作成のためのPlotly Expressライブラリをインポートします。\n",
    "px.defaults.template = \"plotly_dark\"  # グラフのテンプレートをダークテーマに設定します。\n",
    "\n",
    "from sklearn import metrics  # 評価指標を提供するScikit-learnのmetricsモジュールをインポートします。\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用とテスト用に分割するための関数をインポートします。\n",
    "from sklearn.model_selection import StratifiedKFold  # 層別交差検証のためのクラスをインポートします。\n",
    "from sklearn.model_selection import GridSearchCV  # ハイパーパラメータのチューニングを行うためのクラスをインポートします。\n",
    "\n",
    "# 分類モデル\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 勾配ブースティング分類器をインポートします。\n",
    "from xgboost import XGBClassifier  # XGBoost分類器をインポートします。\n",
    "from catboost import CatBoostClassifier  # CatBoost分類器をインポートします。\n",
    "\n",
    "import nltk  # 自然言語処理のためのNLTKライブラリをインポートします。\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # 単語と文のトークン化を行うための関数をインポートします。\n",
    "from nltk.corpus import stopwords  # ストップワードを提供するNLTKのコーパスをインポートします。\n",
    "from nltk.stem import PorterStemmer  # ステミングに使用するポーターステマーをインポートします。\n",
    "from nltk.stem import WordNetLemmatizer  # レmmatizationに使用するWordNetレmmatizerをインポートします。\n",
    "\n",
    "from gensim.models import Word2Vec  # Word2Vecモデルをインポートします。\n",
    "import spacy  # SpaCyライブラリをインポートします。\n",
    "nlp = spacy.load('en_core_web_sm')  # 英語用のSpaCyモデルをロードします。\n",
    "\n",
    "import re  # 正規表現処理のためのreライブラリをインポートします。\n",
    "import string  # 文字列処理のためのstringライブラリをインポートします。\n",
    "\n",
    "from warnings import filterwarnings  # 警告のフィルタリングを行うための関数をインポートします。\n",
    "filterwarnings('ignore')  # 警告を無視するように設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:55:36.054866Z",
     "iopub.status.busy": "2024-07-28T12:55:36.054427Z",
     "iopub.status.idle": "2024-07-28T12:56:06.798802Z",
     "shell.execute_reply": "2024-07-28T12:56:06.79741Z",
     "shell.execute_reply.started": "2024-07-28T12:55:36.054829Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd  # データ操作のためのPandasライブラリをインポートします。\n",
    "import numpy as np  # 数値計算のためのNumPyライブラリをインポートします。\n",
    "import matplotlib.pyplot as plt  # グラフ作成のためのMatplotlibライブラリをインポートします。\n",
    "plt.rcParams['figure.figsize'] = 14,5  # グラフのサイズを14x5に設定します。\n",
    "\n",
    "import seaborn as sns  # データ可視化のためのSeabornライブラリをインポートします。\n",
    "sns.set_style = 'whitegrid'  # グラフのスタイルを白いグリッドに設定します。\n",
    "\n",
    "import plotly.express as px  # インタラクティブなグラフ作成のためのPlotly Expressライブラリをインポートします。\n",
    "px.defaults.template = \"plotly_dark\"  # グラフのテンプレートをダークテーマに設定します。\n",
    "\n",
    "from sklearn import metrics  # 評価指標を提供するScikit-learnのmetricsモジュールをインポートします。\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用とテスト用に分割するための関数をインポートします。\n",
    "from sklearn.model_selection import StratifiedKFold  # 層別交差検証のためのクラスをインポートします。\n",
    "from sklearn.model_selection import GridSearchCV  # ハイパーパラメータのチューニングを行うためのクラスをインポートします。\n",
    "\n",
    "# 分類モデル\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 勾配ブースティング分類器をインポートします。\n",
    "from xgboost import XGBClassifier  # XGBoost分類器をインポートします。\n",
    "from catboost import CatBoostClassifier  # CatBoost分類器をインポートします。\n",
    "\n",
    "import nltk  # 自然言語処理のためのNLTKライブラリをインポートします。\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize  # 単語と文のトークン化を行うための関数をインポートします。\n",
    "from nltk.corpus import stopwords  # ストップワードを提供するNLTKのコーパスをインポートします。\n",
    "from nltk.stem import PorterStemmer  # ステミングに使用するポーターステマーをインポートします。\n",
    "from nltk.stem import WordNetLemmatizer  # レmmatizationに使用するWordNetレmmatizerをインポートします。\n",
    "\n",
    "from gensim.models import Word2Vec  # Word2Vecモデルをインポートします。\n",
    "import spacy  # SpaCyライブラリをインポートします。\n",
    "nlp = spacy.load('en_core_web_sm')  # 英語用のSpaCyモデルをロードします。\n",
    "\n",
    "import re  # 正規表現処理のためのreライブラリをインポートします。\n",
    "import string  # 文字列処理のためのstringライブラリをインポートします。\n",
    "\n",
    "from warnings import filterwarnings  # 警告のフィルタリングを行うための関数をインポートします。\n",
    "filterwarnings('ignore')  # 警告を無視するように設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275c75ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# loading datasets\n",
    "df_train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "df_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "df_submission = df_test.copy()\n",
    "sample_example = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "df_train.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットの読み込み\n",
    "df_train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データをCSVファイルから読み込みます。\n",
    "df_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "df_submission = df_test.copy()  # テストデータのコピーを提出用データフレームとして作成します。\n",
    "sample_example = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # サンプル提出ファイルを読み込みます。\n",
    "df_train.head()  # 訓練データの最初の5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:06.805284Z",
     "iopub.status.busy": "2024-07-28T12:56:06.804818Z",
     "iopub.status.idle": "2024-07-28T12:56:11.030445Z",
     "shell.execute_reply": "2024-07-28T12:56:11.029073Z",
     "shell.execute_reply.started": "2024-07-28T12:56:06.805244Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "df_train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データをCSVファイルから読み込みます。\n",
    "df_test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "df_submission = df_test.copy()  # テストデータのコピーを提出用データフレームとして作成します。\n",
    "sample_example = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # サンプル提出ファイルを読み込みます。\n",
    "df_train.head()  # 訓練データの最初の5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d87f70",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Sample example visualization\n",
    "sample_example.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# サンプル例の可視化\n",
    "sample_example.head()  # サンプル提出ファイルの最初の5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.033741Z",
     "iopub.status.busy": "2024-07-28T12:56:11.033235Z",
     "iopub.status.idle": "2024-07-28T12:56:11.049732Z",
     "shell.execute_reply": "2024-07-28T12:56:11.048347Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.033706Z"
    }
   },
   "outputs": [],
   "source": [
    "# サンプル例の可視化\n",
    "sample_example.head()  # サンプル提出ファイルの最初の5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4eb661",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# train dataset\n",
    "df_test.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータセットの表示\n",
    "df_test.head()  # テストデータの最初の5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.051844Z",
     "iopub.status.busy": "2024-07-28T12:56:11.051464Z",
     "iopub.status.idle": "2024-07-28T12:56:11.070692Z",
     "shell.execute_reply": "2024-07-28T12:56:11.069451Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.051813Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータセットの表示\n",
    "df_test.head()  # テストデータの最初の5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e09c9f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Dataset's shape\n",
    "print(f'Train dataset shape: {df_train.shape}')\n",
    "print(f'Test dataset shape: {df_test.shape}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットの形状を表示\n",
    "print(f'Train dataset shape: {df_train.shape}')  # 訓練データの形状（行数と列数）を表示します。\n",
    "print(f'Test dataset shape: {df_test.shape}')  # テストデータの形状（行数と列数）を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.073115Z",
     "iopub.status.busy": "2024-07-28T12:56:11.072499Z",
     "iopub.status.idle": "2024-07-28T12:56:11.084323Z",
     "shell.execute_reply": "2024-07-28T12:56:11.08299Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.073074Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットの形状を表示\n",
    "print(f'Train dataset shape: {df_train.shape}')  # 訓練データの形状（行数と列数）を表示します。\n",
    "print(f'Test dataset shape: {df_test.shape}')  # テストデータの形状（行数と列数）を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efacc7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Dataset info\n",
    "df_train.info()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットの情報を表示\n",
    "df_train.info()  # 訓練データの情報（各列のデータ型や欠損値の数など）を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.086155Z",
     "iopub.status.busy": "2024-07-28T12:56:11.085747Z",
     "iopub.status.idle": "2024-07-28T12:56:11.15365Z",
     "shell.execute_reply": "2024-07-28T12:56:11.152264Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.086121Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットの情報を表示\n",
    "df_train.info()  # 訓練データの情報（各列のデータ型や欠損値の数など）を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feead51b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Null values train\n",
    "df_train.isnull().sum()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 訓練データの欠損値を確認\n",
    "df_train.isnull().sum()  # 訓練データの各列に存在する欠損値の数を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.155667Z",
     "iopub.status.busy": "2024-07-28T12:56:11.15529Z",
     "iopub.status.idle": "2024-07-28T12:56:11.204561Z",
     "shell.execute_reply": "2024-07-28T12:56:11.203288Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.155633Z"
    }
   },
   "outputs": [],
   "source": [
    "# 訓練データの欠損値を確認\n",
    "df_train.isnull().sum()  # 訓練データの各列に存在する欠損値の数を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8e52d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Null values test\n",
    "df_test.isnull().sum()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータの欠損値を確認\n",
    "df_test.isnull().sum()  # テストデータの各列に存在する欠損値の数を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.206559Z",
     "iopub.status.busy": "2024-07-28T12:56:11.206165Z",
     "iopub.status.idle": "2024-07-28T12:56:11.219704Z",
     "shell.execute_reply": "2024-07-28T12:56:11.218387Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.206529Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータの欠損値を確認\n",
    "df_test.isnull().sum()  # テストデータの各列に存在する欠損値の数を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ad8d26",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Text Preprocessing \n",
    "def preprocess(string):\n",
    "    strip = string.strip('[]')\n",
    "    parts = [x.strip('\"') for x in strip.split('\",\"')]\n",
    "    return ''.join(parts)\n",
    "columns = ['prompt','response_a','response_b']\n",
    "\n",
    "for colum in df_train[columns]:\n",
    "    df_train[colum] = df_train[colum].apply(preprocess)\n",
    "    \n",
    "for colum in df_test[columns]:\n",
    "    df_test[colum] = df_test[colum].apply(preprocess)\n",
    "    \n",
    "df_train.head(2)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストの前処理\n",
    "def preprocess(string):  # 前処理を行う関数を定義します。\n",
    "    strip = string.strip('[]')  # 文字列の両端から'[]'を削除します。\n",
    "    parts = [x.strip('\"') for x in strip.split('\",\"')]  # 文字列を'\",\"'で分割し、各部分から'\"'を削除します。\n",
    "    return ''.join(parts)  # 部分を結合して一つの文字列を返します。\n",
    "\n",
    "columns = ['prompt', 'response_a', 'response_b']  # 前処理を行う列を指定します。\n",
    "\n",
    "# 訓練データの各指定列に対して前処理を適用\n",
    "for colum in df_train[columns]:\n",
    "    df_train[colum] = df_train[colum].apply(preprocess)  # 各列に前処理関数を適用します。\n",
    "\n",
    "# テストデータの各指定列に対して前処理を適用\n",
    "for colum in df_test[columns]:\n",
    "    df_test[colum] = df_test[colum].apply(preprocess)  # 各列に前処理関数を適用します。\n",
    "\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:11.224008Z",
     "iopub.status.busy": "2024-07-28T12:56:11.223574Z",
     "iopub.status.idle": "2024-07-28T12:56:11.870179Z",
     "shell.execute_reply": "2024-07-28T12:56:11.868854Z",
     "shell.execute_reply.started": "2024-07-28T12:56:11.223965Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストの前処理\n",
    "def preprocess(string):  # 前処理を行う関数を定義します。\n",
    "    strip = string.strip('[]')  # 文字列の両端から'[]'を削除します。\n",
    "    parts = [x.strip('\"') for x in strip.split('\",\"')]  # 文字列を'\",\"'で分割し、各部分から'\"'を削除します。\n",
    "    return ''.join(parts)  # 部分を結合して一つの文字列を返します。\n",
    "\n",
    "columns = ['prompt', 'response_a', 'response_b']  # 前処理を行う列を指定します。\n",
    "\n",
    "# 訓練データの各指定列に対して前処理を適用\n",
    "for colum in df_train[columns]:\n",
    "    df_train[colum] = df_train[colum].apply(preprocess)  # 各列に前処理関数を適用します。\n",
    "\n",
    "# テストデータの各指定列に対して前処理を適用\n",
    "for colum in df_test[columns]:\n",
    "    df_test[colum] = df_test[colum].apply(preprocess)  # 各列に前処理関数を適用します。\n",
    "\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb28a13",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# create new columns for data exploration\n",
    "columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "def class_label(df):\n",
    "    df['class_label'] = None\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        for col in columns:\n",
    "            if row[col] == 1:\n",
    "                df.at[index, 'class_label'] = col\n",
    "                break\n",
    "\n",
    "# Call the function on your DataFrame\n",
    "class_label(df_train)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データ探索のための新しい列を作成\n",
    "columns = ['winner_model_a', 'winner_model_b', 'winner_tie']  # 勝者モデルを示す列を指定します。\n",
    "\n",
    "def class_label(df):  # クラスラベルを設定する関数を定義します。\n",
    "    df['class_label'] = None  # 新しい列'class_label'をNoneで初期化します。\n",
    "    \n",
    "    # データフレーム内の各行に対して処理を行います。\n",
    "    for index, row in df.iterrows():\n",
    "        for col in columns:  # 指定した各列をチェックします。\n",
    "            if row[col] == 1:  # 列の値が1の場合\n",
    "                df.at[index, 'class_label'] = col  # 'class_label'列に該当する列名を設定します。\n",
    "                break  # 一度設定したらループを抜けます。\n",
    "\n",
    "# データフレームに対して関数を呼び出す\n",
    "class_label(df_train)  # 訓練データに対してクラスラベルを設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:17.434164Z",
     "iopub.status.busy": "2024-07-28T12:56:17.433724Z",
     "iopub.status.idle": "2024-07-28T12:56:22.891657Z",
     "shell.execute_reply": "2024-07-28T12:56:22.890224Z",
     "shell.execute_reply.started": "2024-07-28T12:56:17.43413Z"
    }
   },
   "outputs": [],
   "source": [
    "# データ探索のための新しい列を作成\n",
    "columns = ['winner_model_a', 'winner_model_b', 'winner_tie']  # 勝者モデルを示す列を指定します。\n",
    "\n",
    "def class_label(df):  # クラスラベルを設定する関数を定義します。\n",
    "    df['class_label'] = None  # 新しい列'class_label'をNoneで初期化します。\n",
    "    \n",
    "    # データフレーム内の各行に対して処理を行います。\n",
    "    for index, row in df.iterrows():\n",
    "        for col in columns:  # 指定した各列をチェックします。\n",
    "            if row[col] == 1:  # 列の値が1の場合\n",
    "                df.at[index, 'class_label'] = col  # 'class_label'列に該当する列名を設定します。\n",
    "                break  # 一度設定したらループを抜けます。\n",
    "\n",
    "# データフレームに対して関数を呼び出す\n",
    "class_label(df_train)  # 訓練データに対してクラスラベルを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f256af",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Define class number\n",
    "class_number = {'winner_model_a':0 ,'winner_model_b':1,'winner_tie':2}\n",
    "\n",
    "df_train['class'] = df_train['class_label'].map(class_number)\n",
    "df_train.head(2)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# クラス番号を定義\n",
    "class_number = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}  # 勝者モデルのクラス番号を定義します。\n",
    "\n",
    "df_train['class'] = df_train['class_label'].map(class_number)  # 'class_label'から対応するクラス番号を新しい列'class'にマッピングします。\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:22.893926Z",
     "iopub.status.busy": "2024-07-28T12:56:22.893458Z",
     "iopub.status.idle": "2024-07-28T12:56:22.919076Z",
     "shell.execute_reply": "2024-07-28T12:56:22.917946Z",
     "shell.execute_reply.started": "2024-07-28T12:56:22.893871Z"
    }
   },
   "outputs": [],
   "source": [
    "# クラス番号を定義\n",
    "class_number = {'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2}  # 勝者モデルのクラス番号を定義します。\n",
    "\n",
    "df_train['class'] = df_train['class_label'].map(class_number)  # 'class_label'から対応するクラス番号を新しい列'class'にマッピングします。\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00b4918",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Which model was chosen\n",
    "def chose_model(row):\n",
    "    if row['class'] == 0:\n",
    "        return row['model_a']\n",
    "    elif row['class'] == 1:\n",
    "        return row['model_b']\n",
    "    else:\n",
    "        return 'tie'\n",
    "\n",
    "df_train['chose_model'] = df_train.apply(chose_model, axis=1)\n",
    "df_train.head(2)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 選ばれたモデルを決定する関数\n",
    "def chose_model(row):  # 行に基づいて選ばれたモデルを返す関数を定義します。\n",
    "    if row['class'] == 0:  # クラスが0の場合\n",
    "        return row['model_a']  # model_aを返します。\n",
    "    elif row['class'] == 1:  # クラスが1の場合\n",
    "        return row['model_b']  # model_bを返します。\n",
    "    else:\n",
    "        return 'tie'  # それ以外（引き分け）の場合は'tie'を返します。\n",
    "\n",
    "# データフレームの各行に対して関数を適用し、新しい列'chose_model'を作成\n",
    "df_train['chose_model'] = df_train.apply(chose_model, axis=1)  # 各行に関数を適用して選ばれたモデルを列に設定します。\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:22.923358Z",
     "iopub.status.busy": "2024-07-28T12:56:22.92233Z",
     "iopub.status.idle": "2024-07-28T12:56:24.054951Z",
     "shell.execute_reply": "2024-07-28T12:56:24.053692Z",
     "shell.execute_reply.started": "2024-07-28T12:56:22.923307Z"
    }
   },
   "outputs": [],
   "source": [
    "# 選ばれたモデルを決定する関数\n",
    "def chose_model(row):  # 行に基づいて選ばれたモデルを返す関数を定義します。\n",
    "    if row['class'] == 0:  # クラスが0の場合\n",
    "        return row['model_a']  # model_aを返します。\n",
    "    elif row['class'] == 1:  # クラスが1の場合\n",
    "        return row['model_b']  # model_bを返します。\n",
    "    else:\n",
    "        return 'tie'  # それ以外（引き分け）の場合は'tie'を返します。\n",
    "\n",
    "# データフレームの各行に対して関数を適用し、新しい列'chose_model'を作成\n",
    "df_train['chose_model'] = df_train.apply(chose_model, axis=1)  # 各行に関数を適用して選ばれたモデルを列に設定します。\n",
    "df_train.head(2)  # 訓練データの最初の2行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf26d34",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## 2 - Data Exploration\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 2 - データ探索\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fef367",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df_train[['winner_model_a','winner_model_b','winner_tie']].mean()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].mean()  # 各モデルの勝率の平均を計算して表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:33.64687Z",
     "iopub.status.busy": "2024-07-28T12:56:33.646323Z",
     "iopub.status.idle": "2024-07-28T12:56:33.664827Z",
     "shell.execute_reply": "2024-07-28T12:56:33.663305Z",
     "shell.execute_reply.started": "2024-07-28T12:56:33.646827Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].mean()  # 各モデルの勝率の平均を計算して表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de867a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Analysing class distribuitions\n",
    "# Objective: is the base balanced?\n",
    "fig = px.pie(df_train[['winner_model_a','winner_model_b','winner_tie']].mean(), names=df_train['class_label'], title='Class distribuition')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# クラス分布の分析\n",
    "# 目的: 基本がバランスされているかどうかを確認します。\n",
    "fig = px.pie(df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].mean(), names=df_train['class_label'], title='クラス分布')  # 各モデルの勝率に基づいて円グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:41.218562Z",
     "iopub.status.busy": "2024-07-28T12:56:41.217723Z",
     "iopub.status.idle": "2024-07-28T12:56:43.699012Z",
     "shell.execute_reply": "2024-07-28T12:56:43.697638Z",
     "shell.execute_reply.started": "2024-07-28T12:56:41.218522Z"
    }
   },
   "outputs": [],
   "source": [
    "# クラス分布の分析\n",
    "# 目的: 基本がバランスされているかどうかを確認します。\n",
    "fig = px.pie(df_train[['winner_model_a', 'winner_model_b', 'winner_tie']].mean(), names=df_train['class_label'], title='クラス分布')  # 各モデルの勝率に基づいて円グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9498e0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Models distribuitions\n",
    "# Objective: The winningest models in the comparison\n",
    "df_models = df_train.groupby('chose_model')['class'].count().reset_index().sort_values(by='class',ascending=False)\n",
    "df_models.rename(columns={'chose_model':'model'}, inplace=True)\n",
    "\n",
    "# Results Graphs\n",
    "fig = px.bar(df_models[1:11].sort_values(by='class'), y='model', x='class', title='Top 10 Most Chosen Models', text_auto='.3s')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの分布\n",
    "# 目的: 比較における最も勝利したモデルを確認します。\n",
    "df_models = df_train.groupby('chose_model')['class'].count().reset_index().sort_values(by='class', ascending=False)  # 選ばれたモデルごとにカウントし、降順にソートします。\n",
    "df_models.rename(columns={'chose_model': 'model'}, inplace=True)  # 列名を' ch ose_model'から'model'に変更します。\n",
    "\n",
    "# 結果のグラフ\n",
    "fig = px.bar(df_models[1:11].sort_values(by='class'), y='model', x='class', title='最も選ばれたモデルTOP10', text_auto='.3s')  # 上位10モデルの棒グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:44.567146Z",
     "iopub.status.busy": "2024-07-28T12:56:44.566669Z",
     "iopub.status.idle": "2024-07-28T12:56:44.70399Z",
     "shell.execute_reply": "2024-07-28T12:56:44.702698Z",
     "shell.execute_reply.started": "2024-07-28T12:56:44.56711Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの分布\n",
    "# 目的: 比較における最も勝利したモデルを確認します。\n",
    "df_models = df_train.groupby('chose_model')['class'].count().reset_index().sort_values(by='class', ascending=False)  # 選ばれたモデルごとにカウントし、降順にソートします。\n",
    "df_models.rename(columns={'chose_model': 'model'}, inplace=True)  # 列名を' ch ose_model'から'model'に変更します。\n",
    "\n",
    "# 結果のグラフ\n",
    "fig = px.bar(df_models[1:11].sort_values(by='class'), y='model', x='class', title='最も選ばれたモデルTOP10', text_auto='.3s')  # 上位10モデルの棒グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28da0704",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Models chosen from those mentioned\n",
    "# Objective: The most of these models\n",
    "df_uni1 = df_train.groupby('model_a')['id'].count().reset_index().sort_values('id', ascending=False)\n",
    "df_uni1.rename(columns={'model_a':'model'}, inplace=True)\n",
    "df_uni2 = df_train.groupby('model_b')['id'].count().reset_index().sort_values('id', ascending=False)\n",
    "df_uni2.rename(columns={'model_b':'model'}, inplace=True)\n",
    "\n",
    "df_uni = df_uni1.merge(df_uni2, how='left', on = 'model')\n",
    "df_uni['total_mentions'] = df_uni['id_x'] + df_uni['id_y']\n",
    "mentions = df_uni['total_mentions'].sum()\n",
    "df_uni['%mentions'] = (df_uni['total_mentions'] / mentions) * 100\n",
    "\n",
    "df_uni = df_uni.merge(df_models, how='left', on = 'model')\n",
    "df_uni['chose_in_mentions'] = (df_uni['class'] / df_uni['total_mentions']) * 100\n",
    "df_uni = df_uni.sort_values(by = 'chose_in_mentions', ascending=False)[:10]\n",
    "df_uni.head(3)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 語及されたモデルの選択\n",
    "# 目的: これらのモデルの中で最も選ばれたものを確認します。\n",
    "df_uni1 = df_train.groupby('model_a')['id'].count().reset_index().sort_values('id', ascending=False)  # model_aごとの出現回数をカウントし、降順でソートします。\n",
    "df_uni1.rename(columns={'model_a': 'model'}, inplace=True)  # 列名を'model_a'から'model'に変更します。\n",
    "df_uni2 = df_train.groupby('model_b')['id'].count().reset_index().sort_values('id', ascending=False)  # model_bごとの出現回数をカウントし、降順でソートします。\n",
    "df_uni2.rename(columns={'model_b': 'model'}, inplace=True)  # 列名を'model_b'から'model'に変更します。\n",
    "\n",
    "# model_aとmodel_bのデータをマージして統一データフレームを作成\n",
    "df_uni = df_uni1.merge(df_uni2, how='left', on='model')  # 左外部結合でデータを統合します。\n",
    "df_uni['total_mentions'] = df_uni['id_x'] + df_uni['id_y']  # id_xとid_yの合計を新しい列'total_mentions'に格納します。\n",
    "mentions = df_uni['total_mentions'].sum()  # 総出現回数を計算します。\n",
    "df_uni['%mentions'] = (df_uni['total_mentions'] / mentions) * 100  # 出現割合を計算します。\n",
    "\n",
    "# モデルの選出割合を追加\n",
    "df_uni = df_uni.merge(df_models, how='left', on='model')  # df_modelsとマージして選出回数を追加します。\n",
    "df_uni['chose_in_mentions'] = (df_uni['class'] / df_uni['total_mentions']) * 100  # 選出回数の割合を計算します。\n",
    "df_uni = df_uni.sort_values(by='chose_in_mentions', ascending=False)[:10]  # 選出回数の割合でソートし上位10件を取得します。\n",
    "df_uni.head(3)  # 上位3件を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:46.249769Z",
     "iopub.status.busy": "2024-07-28T12:56:46.249328Z",
     "iopub.status.idle": "2024-07-28T12:56:46.303936Z",
     "shell.execute_reply": "2024-07-28T12:56:46.302641Z",
     "shell.execute_reply.started": "2024-07-28T12:56:46.249732Z"
    }
   },
   "outputs": [],
   "source": [
    "# 語及されたモデルの選択\n",
    "# 目的: これらのモデルの中で最も選ばれたものを確認します。\n",
    "df_uni1 = df_train.groupby('model_a')['id'].count().reset_index().sort_values('id', ascending=False)  # model_aごとの出現回数をカウントし、降順でソートします。\n",
    "df_uni1.rename(columns={'model_a': 'model'}, inplace=True)  # 列名を'model_a'から'model'に変更します。\n",
    "df_uni2 = df_train.groupby('model_b')['id'].count().reset_index().sort_values('id', ascending=False)  # model_bごとの出現回数をカウントし、降順でソートします。\n",
    "df_uni2.rename(columns={'model_b': 'model'}, inplace=True)  # 列名を'model_b'から'model'に変更します。\n",
    "\n",
    "# model_aとmodel_bのデータをマージして統一データフレームを作成\n",
    "df_uni = df_uni1.merge(df_uni2, how='left', on='model')  # 左外部結合でデータを統合します。\n",
    "df_uni['total_mentions'] = df_uni['id_x'] + df_uni['id_y']  # id_xとid_yの合計を新しい列'total_mentions'に格納します。\n",
    "mentions = df_uni['total_mentions'].sum()  # 総出現回数を計算します。\n",
    "df_uni['%mentions'] = (df_uni['total_mentions'] / mentions) * 100  # 出現割合を計算します。\n",
    "\n",
    "# モデルの選出割合を追加\n",
    "df_uni = df_uni.merge(df_models, how='left', on='model')  # df_modelsとマージして選出回数を追加します。\n",
    "df_uni['chose_in_mentions'] = (df_uni['class'] / df_uni['total_mentions']) * 100  # 選出回数の割合を計算します。\n",
    "df_uni = df_uni.sort_values(by='chose_in_mentions', ascending=False)[:10]  # 選出回数の割合でソートし上位10件を取得します。\n",
    "df_uni.head(3)  # 上位3件を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc865ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Results - Graphs\n",
    "fig = px.bar(df_uni.sort_values('chose_in_mentions'), y='model', x='chose_in_mentions', title='% Top 10 Most Chosen Models',\n",
    "             text_auto='.3s')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結果 - グラフ\n",
    "fig = px.bar(df_uni.sort_values('chose_in_mentions'), y='model', x='chose_in_mentions', title='% 最も選ばれたモデルTOP10',\n",
    "             text_auto='.3s')  # 上位10モデルの選出割合の棒グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:56:47.41905Z",
     "iopub.status.busy": "2024-07-28T12:56:47.418581Z",
     "iopub.status.idle": "2024-07-28T12:56:47.497398Z",
     "shell.execute_reply": "2024-07-28T12:56:47.496226Z",
     "shell.execute_reply.started": "2024-07-28T12:56:47.419015Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果 - グラフ\n",
    "fig = px.bar(df_uni.sort_values('chose_in_mentions'), y='model', x='chose_in_mentions', title='% 最も選ばれたモデルTOP10',\n",
    "             text_auto='.3s')  # 上位10モデルの選出割合の棒グラフを作成します。\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0b4879",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## 3 Modeling\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 3 モデリング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bd6f6d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# Word Processing\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def word_processing(text):\n",
    "    '''Process text: remove special characters, convert to lowercase, tokenize, and remove stopwords'''\n",
    "    text = re.sub(r'[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', text)  # Remove special characters\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    tokens = word_tokenize(text)  # Tokenize the text\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_list]  # Remove stopwords\n",
    "    return filtered_tokens\n",
    "\n",
    "# Features engineering\n",
    "def count_token(tokens):\n",
    "    '''Count number of tokens'''\n",
    "    return len(tokens)\n",
    "\n",
    "def diff_response(tokens1, tokens2):\n",
    "    '''Difference in token count between responses'''\n",
    "    len_1 = len(tokens1)\n",
    "    len_2 = len(tokens2)\n",
    "    diff = abs(len_1 - len_2)\n",
    "    return len_1, len_2, diff\n",
    "\n",
    "def prompt_u_response(text1, text2):\n",
    "    '''Common words between the prompt and the responses'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)\n",
    "    return len(intersec)\n",
    "\n",
    "def aUb(text1, text2):\n",
    "    '''Common words between the responses'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)\n",
    "    return len(intersec)\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    '''Proportion of unique words'''\n",
    "    return len(set(text)) / len(text) if text else 0\n",
    "\n",
    "def avg_words_per_sentence(text):\n",
    "    '''Calculate average number of words per sentence'''\n",
    "    sentences = sent_tokenize(text)\n",
    "    word_count = sum(len(word_tokenize(sentence)) for sentence in sentences)\n",
    "    return word_count / len(sentences) if sentences else 0\n",
    "\n",
    "def sentence_diversity(text):\n",
    "    '''Calculate sentence diversity (variety in sentence length)'''\n",
    "    sentences = sent_tokenize(text)\n",
    "    lengths = [len(word_tokenize(sentence)) for sentence in sentences]\n",
    "    return len(set(lengths)) / len(lengths) if lengths else 0\n",
    "\n",
    "def Simylarity(text1, text2):\n",
    "    '''Calculate the similaty between prompt and responses'''\n",
    "    tokenA = nlp(text1)\n",
    "    tokenB = nlp(text2)\n",
    "    return tokenA.similarity(tokenB)\n",
    "\n",
    "df['similaty_promptUresponse_a'] = df.apply(lambda row: Simylarity(row['prompt'],row['response_a']), axis=1)\n",
    "df['similaty_promptUresponse_b'] = df.apply(lambda row: Simylarity(row['prompt'],row['response_b']), axis=1)\n",
    "\n",
    "\n",
    "# Applying word processing to columns\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df[col] = df[col].apply(word_processing)\n",
    "    df[f'{col}_count_token'] = df[col].apply(count_token)\n",
    "\n",
    "# Applying additional features\n",
    "for index, row in df.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)\n",
    "        \n",
    "        df.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)\n",
    "        df.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)\n",
    "        df.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)\n",
    "        \n",
    "        # Existing features\n",
    "        df.at[index, f'{col}_count_token'] = count_token(tokens)\n",
    "\n",
    "# Applying diferences functions in the train dataframe \n",
    "for index, row in df.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)\n",
    "    response_b_text = ' '.join(response_b_tokens)\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)\n",
    "    df.at[index, 'response_len_a'] = len_a\n",
    "    df.at[index, 'response_len_b'] = len_b\n",
    "    df.at[index, 'response_diff'] = diff\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)\n",
    "    df.at[index, 'common_words_ab'] = common_words_ab\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)\n",
    "    df.at[index, 'common_words_prompt_a'] = common_words_prompt_a\n",
    "    df.at[index, 'common_words_prompt_b'] = common_words_prompt_b\n",
    "    \n",
    "\n",
    "df.head(2)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "df = df_train.copy()  # 訓練データのコピーを作成します。\n",
    "\n",
    "# 単語処理のためのストップワードリストを取得\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def word_processing(text):  # テキストを処理する関数を定義します。\n",
    "    '''テキストを処理します: 特殊文字を削除し、小文字に変換し、トークン化し、ストップワードを削除します'''\n",
    "    text = re.sub(r'[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', text)  # 特殊文字を削除します。\n",
    "    text = text.lower()  # 小文字に変換します。\n",
    "    tokens = word_tokenize(text)  # テキストをトークン化します。\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_list]  # ストップワードを削除します。\n",
    "    return filtered_tokens\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "def count_token(tokens):  # トークンの数をカウントする関数\n",
    "    '''トークンの数をカウントします'''\n",
    "    return len(tokens)\n",
    "\n",
    "def diff_response(tokens1, tokens2):  # 二つの応答のトークン数の違いを計算する関数\n",
    "    '''応答間のトークン数の違い'''\n",
    "    len_1 = len(tokens1)\n",
    "    len_2 = len(tokens2)\n",
    "    diff = abs(len_1 - len_2)  # 二つの応答のトークン数の差の絶対値を計算します。\n",
    "    return len_1, len_2, diff\n",
    "\n",
    "def prompt_u_response(text1, text2):  # プロンプトと応答間の共通単語を計算する関数\n",
    "    '''プロンプトと応答間の共通単語'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)  # 二つの集合の共通部分を計算します。\n",
    "    return len(intersec)  # 共通部分の長さを返します。\n",
    "\n",
    "def aUb(text1, text2):  # 応答間の共通単語を計算する関数\n",
    "    '''応答間の共通単語'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)  # 二つの集合の共通部分を計算します。\n",
    "    return len(intersec)  # 共通部分の長さを返します。\n",
    "\n",
    "def lexical_diversity(text):  # 単語の多様性を計算する関数\n",
    "    '''ユニークな単語の比率'''\n",
    "    return len(set(text)) / len(text) if text else 0  # ユニークな単語の数を全体の単語数で割ります。\n",
    "\n",
    "def avg_words_per_sentence(text):  # 文章あたりの単語数の平均を計算する関数\n",
    "    '''文あたりの平均単語数を計算します'''\n",
    "    sentences = sent_tokenize(text)  # 文をトークン化します。\n",
    "    word_count = sum(len(word_tokenize(sentence)) for sentence in sentences)  # 各文の単語数をカウントします。\n",
    "    return word_count / len(sentences) if sentences else 0  # 平均を返します。\n",
    "\n",
    "def sentence_diversity(text):  # 文の多様性を計算する関数\n",
    "    '''文の多様性を計算します（文の長さのバリエーション）'''\n",
    "    sentences = sent_tokenize(text)  # 文をトークン化します。\n",
    "    lengths = [len(word_tokenize(sentence)) for sentence in sentences]  # 各文の単語数をカウントします。\n",
    "    return len(set(lengths)) / len(lengths) if lengths else 0  # 文の長さのユニークな値の比率を返します。\n",
    "\n",
    "def Simylarity(text1, text2):  # プロンプトと応答の類似度を計算する関数\n",
    "    '''プロンプトと応答間の類似度を計算します'''\n",
    "    tokenA = nlp(text1)  # テキストをSpaCyでトークン化します。\n",
    "    tokenB = nlp(text2)  # テキストをSpaCyでトークン化します。\n",
    "    return tokenA.similarity(tokenB)  # 類似度を計算して返します。\n",
    "\n",
    "# プロンプトと応答間の類似度を新しい列に追加\n",
    "df['similaty_promptUresponse_a'] = df.apply(lambda row: Simylarity(row['prompt'], row['response_a']), axis=1)\n",
    "df['similaty_promptUresponse_b'] = df.apply(lambda row: Simylarity(row['prompt'], row['response_b']), axis=1)\n",
    "\n",
    "# 指定した列に対して単語処理を適用\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df[col] = df[col].apply(word_processing)  # 各列に前処理を適用します。\n",
    "    df[f'{col}_count_token'] = df[col].apply(count_token)  # トークンの数をカウントします。\n",
    "\n",
    "# 追加の特徴を適用\n",
    "for index, row in df.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)  # トークンを結合してテキストを再構築します。\n",
    "        \n",
    "        df.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)  # 単語の多様性を計算して設定します。\n",
    "        df.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)  # 文章あたりの平均単語数を計算して設定します。\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)  # キーワード使用の計算を行う（コメントアウト中）。\n",
    "        df.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)  # 文の多様性を計算して設定します。\n",
    "        \n",
    "        # 既存の特徴も設定\n",
    "        df.at[index, f'{col}_count_token'] = count_token(tokens)  # トークンのカウントを設定します。\n",
    "\n",
    "# 訓練データフレームにおける差異関数を適用\n",
    "for index, row in df.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    response_b_text = ' '.join(response_b_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)  # 応答の長さと差を計算します。\n",
    "    df.at[index, 'response_len_a'] = len_a  # 応答Aのトークン数を設定します。\n",
    "    df.at[index, 'response_len_b'] = len_b  # 応答Bのトークン数を設定します。\n",
    "    df.at[index, 'response_diff'] = diff  # 応答間のトークン数の差を設定します。\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)  # 応答間の共通単語数を計算します。\n",
    "    df.at[index, 'common_words_ab'] = common_words_ab  # 共通単語数を設定します。\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)  # プロンプトのトークンを結合してテキストを再構築します。\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)  # プロンプトと応答Aの共通単語数を計算します。\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)  # プロンプトと応答Bの共通単語数を計算します。\n",
    "    df.at[index, 'common_words_prompt_a'] = common_words_prompt_a  # 共通単語数を設定します。\n",
    "    df.at[index, 'common_words_prompt_b'] = common_words_prompt_b  # 共通単語数を設定します。\n",
    "\n",
    "df.head(2)  # 訓練データの最初の2行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T12:57:15.523984Z",
     "iopub.status.busy": "2024-07-28T12:57:15.523553Z",
     "iopub.status.idle": "2024-07-28T15:29:38.126535Z",
     "shell.execute_reply": "2024-07-28T15:29:38.125267Z",
     "shell.execute_reply.started": "2024-07-28T12:57:15.523951Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df = df_train.copy()  # 訓練データのコピーを作成します。\n",
    "\n",
    "# 単語処理のためのストップワードリストを取得\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "def word_processing(text):  # テキストを処理する関数を定義します。\n",
    "    '''テキストを処理します: 特殊文字を削除し、小文字に変換し、トークン化し、ストップワードを削除します'''\n",
    "    text = re.sub(r'[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', text)  # 特殊文字を削除します。\n",
    "    text = text.lower()  # 小文字に変換します。\n",
    "    tokens = word_tokenize(text)  # テキストをトークン化します。\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords_list]  # ストップワードを削除します。\n",
    "    return filtered_tokens\n",
    "\n",
    "# 特徴量エンジニアリング\n",
    "def count_token(tokens):  # トークンの数をカウントする関数\n",
    "    '''トークンの数をカウントします'''\n",
    "    return len(tokens)\n",
    "\n",
    "def diff_response(tokens1, tokens2):  # 二つの応答のトークン数の違いを計算する関数\n",
    "    '''応答間のトークン数の違い'''\n",
    "    len_1 = len(tokens1)\n",
    "    len_2 = len(tokens2)\n",
    "    diff = abs(len_1 - len_2)  # 二つの応答のトークン数の差の絶対値を計算します。\n",
    "    return len_1, len_2, diff\n",
    "\n",
    "def prompt_u_response(text1, text2):  # プロンプトと応答間の共通単語を計算する関数\n",
    "    '''プロンプトと応答間の共通単語'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)  # 二つの集合の共通部分を計算します。\n",
    "    return len(intersec)  # 共通部分の長さを返します。\n",
    "\n",
    "def aUb(text1, text2):  # 応答間の共通単語を計算する関数\n",
    "    '''応答間の共通単語'''\n",
    "    conj1 = set(text1.split())\n",
    "    conj2 = set(text2.split())\n",
    "    intersec = conj1.intersection(conj2)  # 二つの集合の共通部分を計算します。\n",
    "    return len(intersec)  # 共通部分の長さを返します。\n",
    "\n",
    "def lexical_diversity(text):  # 単語の多様性を計算する関数\n",
    "    '''ユニークな単語の比率'''\n",
    "    return len(set(text)) / len(text) if text else 0  # ユニークな単語の数を全体の単語数で割ります。\n",
    "\n",
    "def avg_words_per_sentence(text):  # 文章あたりの単語数の平均を計算する関数\n",
    "    '''文あたりの平均単語数を計算します'''\n",
    "    sentences = sent_tokenize(text)  # 文をトークン化します。\n",
    "    word_count = sum(len(word_tokenize(sentence)) for sentence in sentences)  # 各文の単語数をカウントします。\n",
    "    return word_count / len(sentences) if sentences else 0  # 平均を返します。\n",
    "\n",
    "def sentence_diversity(text):  # 文の多様性を計算する関数\n",
    "    '''文の多様性を計算します（文の長さのバリエーション）'''\n",
    "    sentences = sent_tokenize(text)  # 文をトークン化します。\n",
    "    lengths = [len(word_tokenize(sentence)) for sentence in sentences]  # 各文の単語数をカウントします。\n",
    "    return len(set(lengths)) / len(lengths) if lengths else 0  # 文の長さのユニークな値の比率を返します。\n",
    "\n",
    "def Simylarity(text1, text2):  # プロンプトと応答の類似度を計算する関数\n",
    "    '''プロンプトと応答間の類似度を計算します'''\n",
    "    tokenA = nlp(text1)  # テキストをSpaCyでトークン化します。\n",
    "    tokenB = nlp(text2)  # テキストをSpaCyでトークン化します。\n",
    "    return tokenA.similarity(tokenB)  # 類似度を計算して返します。\n",
    "\n",
    "# プロンプトと応答間の類似度を新しい列に追加\n",
    "df['similaty_promptUresponse_a'] = df.apply(lambda row: Simylarity(row['prompt'], row['response_a']), axis=1)\n",
    "df['similaty_promptUresponse_b'] = df.apply(lambda row: Simylarity(row['prompt'], row['response_b']), axis=1)\n",
    "\n",
    "# 指定した列に対して単語処理を適用\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df[col] = df[col].apply(word_processing)  # 各列に前処理を適用します。\n",
    "    df[f'{col}_count_token'] = df[col].apply(count_token)  # トークンの数をカウントします。\n",
    "\n",
    "# 追加の特徴を適用\n",
    "for index, row in df.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)  # トークンを結合してテキストを再構築します。\n",
    "        \n",
    "        df.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)  # 単語の多様性を計算して設定します。\n",
    "        df.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)  # 文章あたりの平均単語数を計算して設定します。\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)  # キーワード使用の計算を行う（コメントアウト中）。\n",
    "        df.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)  # 文の多様性を計算して設定します。\n",
    "        \n",
    "        # 既存の特徴も設定\n",
    "        df.at[index, f'{col}_count_token'] = count_token(tokens)  # トークンのカウントを設定します。\n",
    "\n",
    "# 訓練データフレームにおける差異関数を適用\n",
    "for index, row in df.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    response_b_text = ' '.join(response_b_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)  # 応答の長さと差を計算します。\n",
    "    df.at[index, 'response_len_a'] = len_a  # 応答Aのトークン数を設定します。\n",
    "    df.at[index, 'response_len_b'] = len_b  # 応答Bのトークン数を設定します。\n",
    "    df.at[index, 'response_diff'] = diff  # 応答間のトークン数の差を設定します。\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)  # 応答間の共通単語数を計算します。\n",
    "    df.at[index, 'common_words_ab'] = common_words_ab  # 共通単語数を設定します。\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)  # プロンプトのトークンを結合してテキストを再構築します。\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)  # プロンプトと応答Aの共通単語数を計算します。\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)  # プロンプトと応答Bの共通単語数を計算します。\n",
    "    df.at[index, 'common_words_prompt_a'] = common_words_prompt_a  # 共通単語数を設定します。\n",
    "    df.at[index, 'common_words_prompt_b'] = common_words_prompt_b  # 共通単語数を設定します。\n",
    "\n",
    "df.head(2)  # 訓練データの最初の2行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a913536a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df[['similaty_promptUresponse_a','similaty_promptUresponse_b']].describe().T\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "df[['similaty_promptUresponse_a', 'similaty_promptUresponse_b']].describe().T  # プロンプトと応答間の類似度の統計情報を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:31:36.353796Z",
     "iopub.status.busy": "2024-07-28T15:31:36.35334Z",
     "iopub.status.idle": "2024-07-28T15:31:36.388101Z",
     "shell.execute_reply": "2024-07-28T15:31:36.386931Z",
     "shell.execute_reply.started": "2024-07-28T15:31:36.353761Z"
    }
   },
   "outputs": [],
   "source": [
    "df[['similaty_promptUresponse_a', 'similaty_promptUresponse_b']].describe().T  # プロンプトと応答間の類似度の統計情報を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ea0daf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "# features and target selection\n",
    "X = df.drop(['id','model_a','model_b','prompt','response_a','response_b','winner_model_a','winner_model_b','winner_tie',\n",
    "            'class_label','chose_model','class'], axis=1).values\n",
    "y = df['class'].values\n",
    "\n",
    "# Split train and valid\n",
    "X_train,X_valid,y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Models use\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'CatBoost': CatBoostClassifier(random_state=42,verbose=False)\n",
    "}\n",
    "\n",
    "# Trainning the models\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Metrics\n",
    "result_loss = []\n",
    "result_models = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    i = 0\n",
    "    print(f'Model {model_name}')\n",
    "\n",
    "    model_losses = []  # Loss Models List\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):\n",
    "        X_train_fold, X_test_fold = X[train_index], X[valid_index]\n",
    "        y_train_fold, y_test_fold = y[train_index], y[valid_index]\n",
    "        \n",
    "        # Training the model\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Metrics evaluation\n",
    "        y_test_pred_proba = model.predict_proba(X_test_fold)\n",
    "        loss = metrics.log_loss(y_test_fold, y_test_pred_proba)\n",
    "        model_losses.append(loss)  # Add loss in list\n",
    "        \n",
    "        # Display the results\n",
    "        print(f'Fold {i} | Log Loss: {loss}')\n",
    "        i += 1\n",
    "        \n",
    "        mean_loss = np.mean(model_losses)\n",
    "        result_loss.append(model_losses)\n",
    "        result_models.append((model_name, model_losses))\n",
    "\n",
    "    print(f'Mean Loss for model {model_name} is {mean_loss}')\n",
    "    print('---' * 30)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "# 特徴量とターゲットの選択\n",
    "X = df.drop(['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie',\n",
    "            'class_label', 'chose_model', 'class'], axis=1).values  # 特徴量を選択します。\n",
    "y = df['class'].values  # ターゲットのクラスを選択します。\n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)  # データを80:20で分割します。\n",
    "\n",
    "# 使用するモデル\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(random_state=42),  # XGBoostモデルを定義します。\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),  # 勾配ブースティングモデルを定義します。\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=False)  # CatBoostモデルを定義します（出力を抑制します）。\n",
    "}\n",
    "\n",
    "# モデルのトレーニング\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 層別交差検証を設定します。\n",
    "\n",
    "# メトリクス\n",
    "result_loss = []  # 各モデルのロスを記録するリスト\n",
    "result_models = []  # 各モデルの結果を記録するリスト\n",
    "\n",
    "# 各モデルに対するトレーニング\n",
    "for model_name, model in models.items():\n",
    "    i = 0\n",
    "    print(f'Model {model_name}')  # 現在のモデル名を表示します。\n",
    "\n",
    "    model_losses = []  # ロスを記録するリスト\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):  # クロスバリデーションの分割\n",
    "        X_train_fold, X_test_fold = X[train_index], X[valid_index]  # 学習データと検証データを分割します。\n",
    "        y_train_fold, y_test_fold = y[train_index], y[valid_index]  # ターゲットを分割します。\n",
    "        \n",
    "        # モデルのトレーニング\n",
    "        model.fit(X_train_fold, y_train_fold)  # 学習データでモデルを訓練します。\n",
    "        \n",
    "        # メトリクスの評価\n",
    "        y_test_pred_proba = model.predict_proba(X_test_fold)  # 検証データに対する予測確率を計算します。\n",
    "        loss = metrics.log_loss(y_test_fold, y_test_pred_proba)  # ロスを計算します。\n",
    "        model_losses.append(loss)  # ロスをリストに追加します。\n",
    "        \n",
    "        # 結果を表示\n",
    "        print(f'Fold {i} | Log Loss: {loss}')  # 各フォールドのロスを表示します。\n",
    "        i += 1\n",
    "        \n",
    "    mean_loss = np.mean(model_losses)  # 各モデルの平均ロスを計算します。\n",
    "    result_loss.append(model_losses)  # モデルごとのロスを結果に追加します。\n",
    "    result_models.append((model_name, model_losses))  # モデル名とロスをペアで結果に追加します。\n",
    "\n",
    "    print(f'Mean Loss for model {model_name} is {mean_loss}')  # 各モデルの平均ロスを表示します。\n",
    "    print('---' * 30)  # 区切り線を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:32:15.79069Z",
     "iopub.status.busy": "2024-07-28T15:32:15.789718Z",
     "iopub.status.idle": "2024-07-28T15:39:33.148986Z",
     "shell.execute_reply": "2024-07-28T15:39:33.147634Z",
     "shell.execute_reply.started": "2024-07-28T15:32:15.790649Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# 特徴量とターゲットの選択\n",
    "X = df.drop(['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie',\n",
    "            'class_label', 'chose_model', 'class'], axis=1).values  # 特徴量を選択します。\n",
    "y = df['class'].values  # ターゲットのクラスを選択します。\n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)  # データを80:20で分割します。\n",
    "\n",
    "# 使用するモデル\n",
    "models = {\n",
    "    'XGBoost': XGBClassifier(random_state=42),  # XGBoostモデルを定義します。\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),  # 勾配ブースティングモデルを定義します。\n",
    "    'CatBoost': CatBoostClassifier(random_state=42, verbose=False)  # CatBoostモデルを定義します（出力を抑制します）。\n",
    "}\n",
    "\n",
    "# モデルのトレーニング\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # 層別交差検証を設定します。\n",
    "\n",
    "# メトリクス\n",
    "result_loss = []  # 各モデルのロスを記録するリスト\n",
    "result_models = []  # 各モデルの結果を記録するリスト\n",
    "\n",
    "# 各モデルに対するトレーニング\n",
    "for model_name, model in models.items():\n",
    "    i = 0\n",
    "    print(f'Model {model_name}')  # 現在のモデル名を表示します。\n",
    "\n",
    "    model_losses = []  # ロスを記録するリスト\n",
    "    \n",
    "    for train_index, valid_index in skf.split(X, y):  # クロスバリデーションの分割\n",
    "        X_train_fold, X_test_fold = X[train_index], X[valid_index]  # 学習データと検証データを分割します。\n",
    "        y_train_fold, y_test_fold = y[train_index], y[valid_index]  # ターゲットを分割します。\n",
    "        \n",
    "        # モデルのトレーニング\n",
    "        model.fit(X_train_fold, y_train_fold)  # 学習データでモデルを訓練します。\n",
    "        \n",
    "        # メトリクスの評価\n",
    "        y_test_pred_proba = model.predict_proba(X_test_fold)  # 検証データに対する予測確率を計算します。\n",
    "        loss = metrics.log_loss(y_test_fold, y_test_pred_proba)  # ロスを計算します。\n",
    "        model_losses.append(loss)  # ロスをリストに追加します。\n",
    "        \n",
    "        # 結果を表示\n",
    "        print(f'Fold {i} | Log Loss: {loss}')  # 各フォールドのロスを表示します。\n",
    "        i += 1\n",
    "        \n",
    "    mean_loss = np.mean(model_losses)  # 各モデルの平均ロスを計算します。\n",
    "    result_loss.append(model_losses)  # モデルごとのロスを結果に追加します。\n",
    "    result_models.append((model_name, model_losses))  # モデル名とロスをペアで結果に追加します。\n",
    "\n",
    "    print(f'Mean Loss for model {model_name} is {mean_loss}')  # 各モデルの平均ロスを表示します。\n",
    "    print('---' * 30)  # 区切り線を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b379f5a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Plot results\n",
    "data_dict = {'CV': list(range(0, 5))}\n",
    "\n",
    "for model, values in result_models:\n",
    "    data_dict[model] = values\n",
    "\n",
    "results_df = pd.DataFrame(data_dict)\n",
    "\n",
    "fig = px.line(results_df, x='CV', y=['XGBoost','GradientBoosting','CatBoost'], title='Loss Models')\n",
    "fig.update_layout(width=600, height=400)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結果のプロット\n",
    "data_dict = {'CV': list(range(0, 5))}  # クロスバリデーションのフォールド番号を作成します。\n",
    "\n",
    "for model, values in result_models:  # 各モデルとその値のペアをループします。\n",
    "    data_dict[model] = values  # モデル名をキーとしてロスの値を辞書に追加します。\n",
    "\n",
    "results_df = pd.DataFrame(data_dict)  # 辞書からデータフレームを作成します。\n",
    "\n",
    "# モデルロスの線グラフを作成\n",
    "fig = px.line(results_df, x='CV', y=['XGBoost', 'GradientBoosting', 'CatBoost'], title='モデルロスの比較')\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:40:20.886693Z",
     "iopub.status.busy": "2024-07-28T15:40:20.886267Z",
     "iopub.status.idle": "2024-07-28T15:40:21.030166Z",
     "shell.execute_reply": "2024-07-28T15:40:21.028702Z",
     "shell.execute_reply.started": "2024-07-28T15:40:20.886662Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果のプロット\n",
    "data_dict = {'CV': list(range(0, 5))}  # クロスバリデーションのフォールド番号を作成します。\n",
    "\n",
    "for model, values in result_models:  # 各モデルとその値のペアをループします。\n",
    "    data_dict[model] = values  # モデル名をキーとしてロスの値を辞書に追加します。\n",
    "\n",
    "results_df = pd.DataFrame(data_dict)  # 辞書からデータフレームを作成します。\n",
    "\n",
    "# モデルロスの線グラフを作成\n",
    "fig = px.line(results_df, x='CV', y=['XGBoost', 'GradientBoosting', 'CatBoost'], title='モデルロスの比較')\n",
    "fig.update_layout(width=600, height=400)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47b0436",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "# The best model are GradientBoosting\n",
    "# Now, we'll use the gridsearch for tunning hyperparametros\n",
    "model_grad = GradientBoostingClassifier()\n",
    "params = {\n",
    "    'n_estimators':[100, 150, 170],\n",
    "    'max_depth': [1, 3, 5],\n",
    "    'learning_rate': [0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model_grad, params, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=False)\n",
    "grid.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time\n",
    "# 最良のモデルはGradientBoostingです\n",
    "# ハイパーパラメータのチューニングのためにグリッドサーチを使用します\n",
    "model_grad = GradientBoostingClassifier()  # GradientBoostingのインスタンスを作成します。\n",
    "params = {  # ハイパーパラメータの候補を設定します。\n",
    "    'n_estimators': [100, 150, 170],  # 決定木の数の候補リスト。\n",
    "    'max_depth': [1, 3, 5],  # 各決定木の最大深さの候補リスト。\n",
    "    'learning_rate': [0.1, 0.01]  # 学習率の候補リスト。\n",
    "}\n",
    "\n",
    "# グリッドサーチの設定\n",
    "grid = GridSearchCV(model_grad, params, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=False)  # グリッドサーチを設定します。\n",
    "grid.fit(X_train, y_train)  # 訓練データでグリッドサーチを実行します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-28T15:40:59.332186Z",
     "iopub.status.busy": "2024-07-28T15:40:59.33173Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 最良のモデルはGradientBoostingです\n",
    "# ハイパーパラメータのチューニングのためにグリッドサーチを使用します\n",
    "model_grad = GradientBoostingClassifier()  # GradientBoostingのインスタンスを作成します。\n",
    "params = {  # ハイパーパラメータの候補を設定します。\n",
    "    'n_estimators': [100, 150, 170],  # 決定木の数の候補リスト。\n",
    "    'max_depth': [1, 3, 5],  # 各決定木の最大深さの候補リスト。\n",
    "    'learning_rate': [0.1, 0.01]  # 学習率の候補リスト。\n",
    "}\n",
    "\n",
    "# グリッドサーチの設定\n",
    "grid = GridSearchCV(model_grad, params, n_jobs=-1, cv=5, scoring='neg_log_loss', verbose=False)  # グリッドサーチを設定します。\n",
    "grid.fit(X_train, y_train)  # 訓練データでグリッドサーチを実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7448fd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(f'The best params {grid.best_params_}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "print(f'最良のハイパーパラメータは {grid.best_params_} です。')  # 最良のハイパーパラメータを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:01:45.541169Z",
     "iopub.status.busy": "2024-07-19T13:01:45.540725Z",
     "iopub.status.idle": "2024-07-19T13:01:45.547128Z",
     "shell.execute_reply": "2024-07-19T13:01:45.546118Z",
     "shell.execute_reply.started": "2024-07-19T13:01:45.541129Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f'最良のハイパーパラメータは {grid.best_params_} です。')  # 最良のハイパーパラメータを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386ad3c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Selection the best model\n",
    "best_model = grid.best_estimator_\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最良のモデルを選択\n",
    "best_model = grid.best_estimator_  # グリッドサーチで得られた最良のモデルを選択します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:01:51.323862Z",
     "iopub.status.busy": "2024-07-19T13:01:51.323434Z",
     "iopub.status.idle": "2024-07-19T13:01:51.3287Z",
     "shell.execute_reply": "2024-07-19T13:01:51.327547Z",
     "shell.execute_reply.started": "2024-07-19T13:01:51.323828Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最良のモデルを選択\n",
    "best_model = grid.best_estimator_  # グリッドサーチで得られた最良のモデルを選択します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6ecb23",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Avaluation the best model\n",
    "y_predict_valid_prob = best_model.predict_proba(X_valid)\n",
    "\n",
    "logloss = metrics.log_loss(y_valid, y_predict_valid_prob)\n",
    "\n",
    "print(f'LogLoss the Best Models with GridSearch: {logloss}')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最良モデルの評価\n",
    "y_predict_valid_prob = best_model.predict_proba(X_valid)  # 検証データに対する予測確率を計算します。\n",
    "\n",
    "logloss = metrics.log_loss(y_valid, y_predict_valid_prob)  # 検証データに対するロス（LogLoss）を計算します。\n",
    "\n",
    "print(f'グリッドサーチによる最良モデルのLogLoss: {logloss}')  # 最良モデルのロスを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:03:01.162878Z",
     "iopub.status.busy": "2024-07-19T13:03:01.162415Z",
     "iopub.status.idle": "2024-07-19T13:03:01.260652Z",
     "shell.execute_reply": "2024-07-19T13:03:01.2595Z",
     "shell.execute_reply.started": "2024-07-19T13:03:01.162843Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最良モデルの評価\n",
    "y_predict_valid_prob = best_model.predict_proba(X_valid)  # 検証データに対する予測確率を計算します。\n",
    "\n",
    "logloss = metrics.log_loss(y_valid, y_predict_valid_prob)  # 検証データに対するロス（LogLoss）を計算します。\n",
    "\n",
    "print(f'グリッドサーチによる最良モデルのLogLoss: {logloss}')  # 最良モデルのロスを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6809a5c5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "There was no significant improvement with GridSearch\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "グリッドサーチによる改善は見られませんでした。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b4a09a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Features importance\n",
    "features_importance = best_model.feature_importances_\n",
    "features_names = ['prompt_count_token', 'response_a_count_token',\n",
    "       'response_b_count_token', 'response_a_lexical_diversity',\n",
    "       'response_a_avg_words_per_sentence', 'response_a_sentence_diversity',\n",
    "       'response_b_lexical_diversity', 'response_b_avg_words_per_sentence',\n",
    "       'response_b_sentence_diversity', 'response_len_a', 'response_len_b',\n",
    "       'response_diff', 'common_words_ab', 'common_words_prompt_a',\n",
    "       'common_words_prompt_b','similaty_promptUresponse_a', 'similaty_promptUresponse_b']\n",
    "\n",
    "fig = px.bar(y=features_names, x=features_importance, color=features_importance, title='Features Importance')\n",
    "scale = px.colors.sequential.BuGn\n",
    "fig.update_traces(marker=dict(colorscale=scale))\n",
    "fig.update_layout(width=800, height=500)\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 特徴量の重要度\n",
    "features_importance = best_model.feature_importances_  # 最良モデルから特徴量の重要度を取得します。\n",
    "features_names = ['prompt_count_token', 'response_a_count_token',\n",
    "       'response_b_count_token', 'response_a_lexical_diversity',\n",
    "       'response_a_avg_words_per_sentence', 'response_a_sentence_diversity',\n",
    "       'response_b_lexical_diversity', 'response_b_avg_words_per_sentence',\n",
    "       'response_b_sentence_diversity', 'response_len_a', 'response_len_b',\n",
    "       'response_diff', 'common_words_ab', 'common_words_prompt_a',\n",
    "       'common_words_prompt_b', 'similaty_promptUresponse_a', 'similaty_promptUresponse_b']  # 特徴量名のリストを定義します。\n",
    "\n",
    "fig = px.bar(y=features_names, x=features_importance, color=features_importance, title='特徴量の重要度')  # 特徴量の重要度を棒グラフで可視化します。\n",
    "scale = px.colors.sequential.BuGn  # カラーグラデーションを設定します。\n",
    "fig.update_traces(marker=dict(colorscale=scale))  # グラフの色を設定します。\n",
    "fig.update_layout(width=800, height=500)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:20:47.24073Z",
     "iopub.status.busy": "2024-07-19T13:20:47.240315Z",
     "iopub.status.idle": "2024-07-19T13:20:47.310384Z",
     "shell.execute_reply": "2024-07-19T13:20:47.309207Z",
     "shell.execute_reply.started": "2024-07-19T13:20:47.240683Z"
    }
   },
   "outputs": [],
   "source": [
    "# 特徴量の重要度\n",
    "features_importance = best_model.feature_importances_  # 最良モデルから特徴量の重要度を取得します。\n",
    "features_names = ['prompt_count_token', 'response_a_count_token',\n",
    "       'response_b_count_token', 'response_a_lexical_diversity',\n",
    "       'response_a_avg_words_per_sentence', 'response_a_sentence_diversity',\n",
    "       'response_b_lexical_diversity', 'response_b_avg_words_per_sentence',\n",
    "       'response_b_sentence_diversity', 'response_len_a', 'response_len_b',\n",
    "       'response_diff', 'common_words_ab', 'common_words_prompt_a',\n",
    "       'common_words_prompt_b', 'similaty_promptUresponse_a', 'similaty_promptUresponse_b']  # 特徴量名のリストを定義します。\n",
    "\n",
    "fig = px.bar(y=features_names, x=features_importance, color=features_importance, title='特徴量の重要度')  # 特徴量の重要度を棒グラフで可視化します。\n",
    "scale = px.colors.sequential.BuGn  # カラーグラデーションを設定します。\n",
    "fig.update_traces(marker=dict(colorscale=scale))  # グラフの色を設定します。\n",
    "fig.update_layout(width=800, height=500)  # グラフのサイズを設定します。\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e76a90",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Above we can see the most important features for the model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "上記のグラフでは、モデルにおける最も重要な特徴量を確認できます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59118559",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Preparing the test data to predict\n",
    "df_test['similaty_promptUresponse_a'] = df_test.apply(lambda row: Simylarity(row['prompt'],row['response_a']), axis=1)\n",
    "df_test['similaty_promptUresponse_b'] = df_test.apply(lambda row: Simylarity(row['prompt'],row['response_b']), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Applying word processing to columns\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df_test[col] = df_test[col].apply(word_processing)\n",
    "    df_test[f'{col}_count_token'] = df_test[col].apply(count_token)\n",
    "\n",
    "# Applying additional features\n",
    "for index, row in df_test.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)\n",
    "        \n",
    "        df_test.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)\n",
    "        df_test.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)\n",
    "        #df.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)\n",
    "        df_test.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)\n",
    "        \n",
    "        # Existing features\n",
    "        df_test.at[index, f'{col}_count_token'] = count_token(tokens)\n",
    "\n",
    "\n",
    "# Applying diferences functions in the test dataframe \n",
    "for index, row in df_test.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)\n",
    "    response_b_text = ' '.join(response_b_tokens)\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)\n",
    "    df_test.at[index, 'response_len_a'] = len_a\n",
    "    df_test.at[index, 'response_len_b'] = len_b\n",
    "    df_test.at[index, 'response_diff'] = diff\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)\n",
    "    df_test.at[index, 'common_words_ab'] = common_words_ab\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)\n",
    "    df_test.at[index, 'common_words_prompt_a'] = common_words_prompt_a\n",
    "    df_test.at[index, 'common_words_prompt_b'] = common_words_prompt_b\n",
    "\n",
    "df_test.drop(columns = ['id','prompt','response_a','response_b'], axis=1, inplace=True)\n",
    "df_test.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測のためのテストデータの準備\n",
    "df_test['similaty_promptUresponse_a'] = df_test.apply(lambda row: Simylarity(row['prompt'], row['response_a']), axis=1)  # プロンプトと応答A間の類似度を計算します。\n",
    "df_test['similaty_promptUresponse_b'] = df_test.apply(lambda row: Simylarity(row['prompt'], row['response_b']), axis=1)  # プロンプトと応答B間の類似度を計算します。\n",
    "\n",
    "# 指定した列に対して単語処理を適用\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df_test[col] = df_test[col].apply(word_processing)  # 各列に前処理を適用します。\n",
    "    df_test[f'{col}_count_token'] = df_test[col].apply(count_token)  # トークンの数をカウントします。\n",
    "\n",
    "# 追加の特徴を適用\n",
    "for index, row in df_test.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)  # トークンを結合してテキストを再構築します。\n",
    "        \n",
    "        df_test.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)  # 単語の多様性を計算して設定します。\n",
    "        df_test.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)  # 文章あたりの平均単語数を計算して設定します。\n",
    "        # df_test.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)  # キーワード使用の計算を行う（コメントアウト中）。\n",
    "        df_test.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)  # 文の多様性を計算して設定します。\n",
    "        \n",
    "        # 既存の特徴も設定\n",
    "        df_test.at[index, f'{col}_count_token'] = count_token(tokens)  # トークンのカウントを設定します。\n",
    "\n",
    "# テストデータフレームにおける差異関数を適用\n",
    "for index, row in df_test.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    response_b_text = ' '.join(response_b_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)  # 応答の長さと差を計算します。\n",
    "    df_test.at[index, 'response_len_a'] = len_a  # 応答Aのトークン数を設定します。\n",
    "    df_test.at[index, 'response_len_b'] = len_b  # 応答Bのトークン数を設定します。\n",
    "    df_test.at[index, 'response_diff'] = diff  # 応答間のトークン数の差を設定します。\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)  # 応答間の共通単語数を計算します。\n",
    "    df_test.at[index, 'common_words_ab'] = common_words_ab  # 共通単語数を設定します。\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)  # プロンプトのトークンを結合してテキストを再構築します。\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)  # プロンプトと応答Aの共通単語数を計算します。\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)  # プロンプトと応答Bの共通単語数を計算します。\n",
    "    df_test.at[index, 'common_words_prompt_a'] = common_words_prompt_a  # 共通単語数を設定します。\n",
    "    df_test.at[index, 'common_words_prompt_b'] = common_words_prompt_b  # 共通単語数を設定します。\n",
    "\n",
    "df_test.drop(columns=['id', 'prompt', 'response_a', 'response_b'], axis=1, inplace=True)  # 不要な列を削除します。\n",
    "df_test.head()  # テストデータの最初の5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:05.820087Z",
     "iopub.status.busy": "2024-07-19T13:04:05.81966Z",
     "iopub.status.idle": "2024-07-19T13:04:06.117529Z",
     "shell.execute_reply": "2024-07-19T13:04:06.11641Z",
     "shell.execute_reply.started": "2024-07-19T13:04:05.820054Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測のためのテストデータの準備\n",
    "df_test['similaty_promptUresponse_a'] = df_test.apply(lambda row: Simylarity(row['prompt'], row['response_a']), axis=1)  # プロンプトと応答A間の類似度を計算します。\n",
    "df_test['similaty_promptUresponse_b'] = df_test.apply(lambda row: Simylarity(row['prompt'], row['response_b']), axis=1)  # プロンプトと応答B間の類似度を計算します。\n",
    "\n",
    "# 指定した列に対して単語処理を適用\n",
    "for col in ['prompt', 'response_a', 'response_b']:\n",
    "    df_test[col] = df_test[col].apply(word_processing)  # 各列に前処理を適用します。\n",
    "    df_test[f'{col}_count_token'] = df_test[col].apply(count_token)  # トークンの数をカウントします。\n",
    "\n",
    "# 追加の特徴を適用\n",
    "for index, row in df_test.iterrows():\n",
    "    for col in ['response_a', 'response_b']:\n",
    "        tokens = row[col]\n",
    "        text = ' '.join(tokens)  # トークンを結合してテキストを再構築します。\n",
    "        \n",
    "        df_test.at[index, f'{col}_lexical_diversity'] = lexical_diversity(tokens)  # 単語の多様性を計算して設定します。\n",
    "        df_test.at[index, f'{col}_avg_words_per_sentence'] = avg_words_per_sentence(text)  # 文章あたりの平均単語数を計算して設定します。\n",
    "        # df_test.at[index, f'{col}_keyword_usage'] = keyword_usage(text, keywords)  # キーワード使用の計算を行う（コメントアウト中）。\n",
    "        df_test.at[index, f'{col}_sentence_diversity'] = sentence_diversity(text)  # 文の多様性を計算して設定します。\n",
    "        \n",
    "        # 既存の特徴も設定\n",
    "        df_test.at[index, f'{col}_count_token'] = count_token(tokens)  # トークンのカウントを設定します。\n",
    "\n",
    "# テストデータフレームにおける差異関数を適用\n",
    "for index, row in df_test.iterrows():\n",
    "    response_a_tokens = row['response_a']\n",
    "    response_b_tokens = row['response_b']\n",
    "    response_a_text = ' '.join(response_a_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    response_b_text = ' '.join(response_b_tokens)  # トークンを結合してテキストを再構築します。\n",
    "    \n",
    "    len_a, len_b, diff = diff_response(response_a_tokens, response_b_tokens)  # 応答の長さと差を計算します。\n",
    "    df_test.at[index, 'response_len_a'] = len_a  # 応答Aのトークン数を設定します。\n",
    "    df_test.at[index, 'response_len_b'] = len_b  # 応答Bのトークン数を設定します。\n",
    "    df_test.at[index, 'response_diff'] = diff  # 応答間のトークン数の差を設定します。\n",
    "    \n",
    "    common_words_ab = aUb(response_a_text, response_b_text)  # 応答間の共通単語数を計算します。\n",
    "    df_test.at[index, 'common_words_ab'] = common_words_ab  # 共通単語数を設定します。\n",
    "    \n",
    "    prompt_tokens = row['prompt']\n",
    "    prompt_text = ' '.join(prompt_tokens)  # プロンプトのトークンを結合してテキストを再構築します。\n",
    "    common_words_prompt_a = prompt_u_response(prompt_text, response_a_text)  # プロンプトと応答Aの共通単語数を計算します。\n",
    "    common_words_prompt_b = prompt_u_response(prompt_text, response_b_text)  # プロンプトと応答Bの共通単語数を計算します。\n",
    "    df_test.at[index, 'common_words_prompt_a'] = common_words_prompt_a  # 共通単語数を設定します。\n",
    "    df_test.at[index, 'common_words_prompt_b'] = common_words_prompt_b  # 共通単語数を設定します。\n",
    "\n",
    "df_test.drop(columns=['id', 'prompt', 'response_a', 'response_b'], axis=1, inplace=True)  # 不要な列を削除します。\n",
    "df_test.head()  # テストデータの最初の5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1b8a1c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Predict proba in test\n",
    "y_sub_proba = best_model.predict_proba(df_test)\n",
    "y_sub_proba\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータに対する予測確率を計算\n",
    "y_sub_proba = best_model.predict_proba(df_test)  # 最良モデルを使用してテストデータに対する予測確率を計算します。\n",
    "y_sub_proba  # 予測確率を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:10.15887Z",
     "iopub.status.busy": "2024-07-19T13:04:10.158443Z",
     "iopub.status.idle": "2024-07-19T13:04:10.169863Z",
     "shell.execute_reply": "2024-07-19T13:04:10.168724Z",
     "shell.execute_reply.started": "2024-07-19T13:04:10.158835Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに対する予測確率を計算\n",
    "y_sub_proba = best_model.predict_proba(df_test)  # 最良モデルを使用してテストデータに対する予測確率を計算します。\n",
    "y_sub_proba  # 予測確率を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445fd9d3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Submission df\n",
    "submission = pd.DataFrame({\n",
    "    'id':df_submission['id'],\n",
    "    'winner_model_a': y_sub_proba[:, 0],\n",
    "    'winner_model_b': y_sub_proba[:, 1],\n",
    "    'winner_tie': y_sub_proba[:, 2]\n",
    "})\n",
    "\n",
    "submission.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 提出用データフレームの作成\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_submission['id'],  # 提出用のID列を設定します。\n",
    "    'winner_model_a': y_sub_proba[:, 0],  # モデルAの勝者確率を設定します。\n",
    "    'winner_model_b': y_sub_proba[:, 1],  # モデルBの勝者確率を設定します。\n",
    "    'winner_tie': y_sub_proba[:, 2]  # 引き分けの確率を設定します。\n",
    "})\n",
    "\n",
    "submission.head()  # 提出用データフレームの最初の5行を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:14.135325Z",
     "iopub.status.busy": "2024-07-19T13:04:14.134831Z",
     "iopub.status.idle": "2024-07-19T13:04:14.151783Z",
     "shell.execute_reply": "2024-07-19T13:04:14.150521Z",
     "shell.execute_reply.started": "2024-07-19T13:04:14.135288Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用データフレームの作成\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_submission['id'],  # 提出用のID列を設定します。\n",
    "    'winner_model_a': y_sub_proba[:, 0],  # モデルAの勝者確率を設定します。\n",
    "    'winner_model_b': y_sub_proba[:, 1],  # モデルBの勝者確率を設定します。\n",
    "    'winner_tie': y_sub_proba[:, 2]  # 引き分けの確率を設定します。\n",
    "})\n",
    "\n",
    "submission.head()  # 提出用データフレームの最初の5行を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5584a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 提出ファイルの保存\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出用データフレームをCSVファイルとして保存します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-19T13:04:17.05701Z",
     "iopub.status.busy": "2024-07-19T13:04:17.056603Z",
     "iopub.status.idle": "2024-07-19T13:04:17.065393Z",
     "shell.execute_reply": "2024-07-19T13:04:17.064351Z",
     "shell.execute_reply.started": "2024-07-19T13:04:17.056978Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出ファイルの保存\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出用データフレームをCSVファイルとして保存します。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
