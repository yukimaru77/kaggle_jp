{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "260a89b4",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、Gemma-2 9bモデルを使用して、人間の好みに基づくチャットボットの応答を予測するタスクに取り組んでいます。コンペティションにおいて、参加者はどちらのモデルの応答が好まれるかを予測するための機械学習モデルを構築する必要があります。\n",
    "\n",
    "主な手法として、ノートブックではLoRA（Low-Rank Adaptation）およびQLoRA（Quantized Low-Rank Adaptation）を用いてモデルをファインチューニングしています。これは、トレーニング中に元の重みを凍結し、LoRAアダプタの重みだけを更新することで、メモリを効率的に使用しつつ、優れたパフォーマンスを実現する手法です。QLoRAでは、モデルの重みを量子化して計算リソースを最小化し、高精度の計算を維持します。\n",
    "\n",
    "使用しているライブラリには、`transformers`、`bitsandbytes`、および`peft`が含まれ、これらを用いてモデル設定、トークナイザー、データセットにアクセスし、トレーニングを実行します。評価指標としては、対数損失（log loss）と精度（accuracy）が用いられ、特にKaggleのルールに基づいてパフォーマンスが計測されます。\n",
    "\n",
    "ノートブックは、Gemma-2モデルのトレーニングを1エポックで実施し、得られた結果は評価セットに対して0.9371のログロス、リーダーボード上で0.941に達しました。このデモには、100サンプルのデータセットを使用しており、全体の設定やパラメータはカスタマイズ可能です。トレーニング結果はTensorBoardで記録され、リアルタイムでメモリ使用量や損失、精度を観察できるようになっています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6d1fb",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、示されたJupyter Notebookに基づいて、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説です。これは、一般的な定義や広く知られた用語を除き、特に実務経験の少ない初心者がつまづく可能性がある特定の用語に焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **Gemma-2 9b**:\n",
    "   - 特定の大規模な言語モデル（LLM）で、9bは9ビリオン（約90億）のパラメータを持つことを示しています。LLMは、特に自然言語処理に特化したモデルのことを指します。\n",
    "\n",
    "2. **LB (Leader Board)**:\n",
    "   - コンペティションにおけるリーダーボードのスコアを指します。LBスコアはモデルの性能を示し、他の参加者と比較するための指標です。\n",
    "\n",
    "3. **ファインチューニング**:\n",
    "   - 既存のモデルに対して、新しいデータセットで再トレーニングを行い、モデルのパフォーマンスを高めるプロセスです。特に特定のタスクやドメインにおける精度を上げるために利用されます。\n",
    "\n",
    "4. **量子化 (Quantization)**:\n",
    "   - モデルのパラメータを、通常の32ビット浮動小数点数から低精度な形式（例：8ビットや4ビット）に変換するプロセスです。これにより、モデルのサイズを小さくし、計算効率を高めます。\n",
    "\n",
    "5. **LoRA (Low-Rank Adaptation)**:\n",
    "   - モデルのトレーニングを柔軟で効率的にするためのテクニックで、重みの更新を低ランク行列で近似します。これにより、トレーニングのメモリ使用量を下げながら性能を保ちます。\n",
    "\n",
    "6. **QLoRA (Quantized LoRA)**:\n",
    "   - LoRA技術を量子化技術と組み合わせたものです。これは、トレーニング中にモデル重みを量子化しつつ、計算は高精度で行うことで、リソースの使用効率を向上させます。\n",
    "\n",
    "7. **トレーニング引数 (Training Arguments)**:\n",
    "   - 機械学習モデルをトレーニングする際の設定値（例：エポック数やバッチサイズなど）をまとめたものです。これらの引数によって、トレーニングプロセスの挙動が決まります。\n",
    "\n",
    "8. **メトリック (Metric)**:\n",
    "   - モデルのパフォーマンスを評価するための指標です。具体例としては、精度（accuracy）、損失（loss）、ログロス（log loss）などが含まれます。\n",
    "\n",
    "9. **TensorBoard**:\n",
    "   - TensorFlowのための可視化ツールですが、PyTorchユーザーにも利用されています。トレーニング中のメトリックやモデルの挙動をグラフなどで可視化することが可能です。\n",
    "\n",
    "10. **コールバック (Callback)**:\n",
    "    - トレーニングの特定のイベント（例：エポック終了時）に基づいて自動的に呼び出される関数やメソッドです。モデルのトレーニング途中での様々な処理を実装するために役立ちます。\n",
    "\n",
    "これらの用語は、Notebook内での実装や概念に特有なものであり、初心者が理解する上で特に重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708a336a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## What this notebook is\n",
    "This notebook demonstrates how I trained Gemma-2 9b to obtain LB: 0.941. The inference code can be found [here](https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora).\n",
    "I used 4-bit quantized [Gemma 2 9b Instruct](https://huggingface.co/unsloth/gemma-2-9b-it-bnb-4bit) uploaded by unsloth team as a base-model and added LoRA adapters and trained for 1 epoch.\n",
    "\n",
    "## Result\n",
    "\n",
    "I used `id % 5 == 0` as an evaluation set and used all the rest for training.\n",
    "\n",
    "| subset | log loss |\n",
    "| - | - |\n",
    "| eval | 0.9371|\n",
    "| LB | 0.941 |\n",
    "\n",
    "## What is QLoRA fine-tuning?\n",
    "\n",
    "In the conventional fine-tuning, weight ($\\mathbf{W}$) is updated as follows:\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\frac{{\\partial L}}{{\\partial \\mathbf{W}}} = \\mathbf{W} + \\Delta \\mathbf{W}\n",
    "$$\n",
    "\n",
    "where $L$ is a loss at this step and $\\eta$ is a learning rate.\n",
    "\n",
    "[LoRA](https://arxiv.org/abs/2106.09685) tries to approximate the $\\Delta \\mathbf{W} \\in \\mathbb{R}^{\\text{d} \\times \\text{k}}$ by factorizing $\\Delta \\mathbf{W}$ into two (much) smaller matrices, $\\mathbf{B} \\in \\mathbb{R}^{\\text{d} \\times \\text{r}}$ and $\\mathbf{A} \\in \\mathbb{R}^{\\text{r} \\times \\text{k}}$ with $r \\ll \\text{min}(\\text{d}, \\text{k})$.\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{W}_{s} \\approx \\mathbf{B} \\mathbf{A}\n",
    "$$\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/pii_data_detection/lora_diagram.png\">\n",
    "\n",
    "During training, only $\\mathbf{A}$ and $\\mathbf{B}$ are updated while freezing the original weights, meaning that only a fraction (e.g. <1%) of the original weights need to be updated during training. This way, we can reduce the GPU memory usage significantly during training while achieving equivalent performance to the usual (full) fine-tuning.\n",
    "\n",
    "[QLoRA](https://arxiv.org/abs/2305.14314) pushes the efficiency further by quantizing LLM. For example, a 8B parameter model alone would take up 32GB of VRAM in 32-bit, whereas quantized 8-bit/4-bit 8B model only need 8GB/4GB respectively. \n",
    "Note that QLoRA only quantize LLM's weights in low precision (e.g. 8-bit) while the computation of forward/backward are done in higher precision (e.g. 16-bit) and LoRA adapter's weights are also kept in higher precision.\n",
    "\n",
    "1 epoch using A6000 took ~15h in 4-bit while 8-bit took ~24h and the difference in log loss was not significant.\n",
    "\n",
    "## Note\n",
    "It takes prohivitively long time to run full training on kaggle kernel. I recommend to use external compute resource to run the full training.\n",
    "This notebook uses only 100 samples for demo purpose, but everything else is same as my setup.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## このノートブックについて\n",
    "このノートブックでは、Gemma-2 9bをトレーニングしてLB: 0.941を取得する方法を示します。推論コードは[こちら](https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora)で見つけることができます。\n",
    "私は、unslothチームがアップロードした4ビット量子化された[Gemma 2 9b Instruct](https://huggingface.co/unsloth/gemma-2-9b-it-bnb-4bit)をベースモデルとして使用し、LoRAアダプタを追加して1エポックでトレーニングしました。\n",
    "\n",
    "## 結果\n",
    "\n",
    "評価セットとして `id % 5 == 0` を使用し、残りをすべてトレーニングに使用しました。\n",
    "\n",
    "| サブセット | ログロス |\n",
    "| - | - |\n",
    "| 評価 | 0.9371 |\n",
    "| LB | 0.941 |\n",
    "\n",
    "## QLoRAファインチューニングとは？\n",
    "\n",
    "従来のファインチューニングでは、重み ($\\mathbf{W}$) の更新が以下のように行われます：\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\leftarrow \\mathbf{W} - \\eta \\frac{{\\partial L}}{{\\partial \\mathbf{W}}} = \\mathbf{W} + \\Delta \\mathbf{W}\n",
    "$$\n",
    "\n",
    "ここで、$L$ はこのステップでの損失値、$\\eta$ は学習率です。\n",
    "\n",
    "[LoRA](https://arxiv.org/abs/2106.09685)は、$\\Delta \\mathbf{W} \\in \\mathbb{R}^{\\text{d} \\times \\text{k}}$ を、$r \\ll \\text{min}(\\text{d}, \\text{k})$ の2つの (はるかに) 小さい行列、$\\mathbf{B} \\in \\mathbb{R}^{\\text{d} \\times \\text{r}}$ と$\\mathbf{A} \\in \\mathbb{R}^{\\text{r} \\times \\text{k}}$ に因子分解して近似しようとします。\n",
    "\n",
    "$$\n",
    "\\Delta \\mathbf{W}_{s} \\approx \\mathbf{B} \\mathbf{A}\n",
    "$$\n",
    "\n",
    "<img src=\"https://storage.googleapis.com/pii_data_detection/lora_diagram.png\">\n",
    "\n",
    "トレーニング中、元の重みは凍結されるため、$\\mathbf{A}$ と $\\mathbf{B}$ のみが更新されます。これにより、トレーニング中に更新する必要のある元の重みの割合はごくわずか (例えば <1%) に抑えられます。この方法で、トレーニング中のGPUメモリ使用量を大幅に削減しながら、通常の (フル) ファインチューニングと同等のパフォーマンスを達成できます。\n",
    "\n",
    "[QLoRA](https://arxiv.org/abs/2305.14314)は、LLMの量子化により効率をさらに向上させます。例えば、8Bパラメータモデルは32ビットで32GBのVRAMを必要としますが、量子化された8ビット/4ビット8Bモデルはそれぞれ8GB/4GBで済みます。\n",
    "QLoRAは、低精度 (例えば8ビット) でLLMの重みを量子化する一方で、フォワード/バックワードの計算は高精度 (例えば16ビット) で行い、LoRAアダプタの重みも高精度で保持されていることに注意してください。\n",
    "\n",
    "A6000を使用した1エポックは、4ビットで約15時間、8ビットで約24時間かかり、ログロスの差は大きくありませんでした。\n",
    "\n",
    "## 注意\n",
    "Kaggleカーネルでのフルトレーニングには非常に長い時間がかかります。フルトレーニングを実行するには外部の計算リソースを使用することをお勧めします。\n",
    "このノートブックではデモ目的で100サンプルのみを使用していますが、その他はすべて私の設定と同じです。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e9ace",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# gemma-2 is available from transformers>=4.42.3\n",
    "!pip install -U \"transformers>=4.42.3\" bitsandbytes accelerate peft\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# gemma-2はtransformers>=4.42.3から利用可能です\n",
    "!pip install -U \"transformers>=4.42.3\" bitsandbytes accelerate peft\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "de99a304-cf93-4160-809b-7b5a1c5e50ec",
    "_kg_hide-output": true,
    "_uuid": "56a8c3dc-483c-461c-8bc6-4c0733d4af35",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:38:40.444016Z",
     "iopub.status.busy": "2024-07-27T00:38:40.442949Z",
     "iopub.status.idle": "2024-07-27T00:38:53.604759Z",
     "shell.execute_reply": "2024-07-27T00:38:53.603726Z",
     "shell.execute_reply.started": "2024-07-27T00:38:40.443979Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# gemma-2はtransformers>=4.42.3から利用可能です\n",
    "!pip install -U \"transformers>=4.42.3\" bitsandbytes accelerate peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff00873a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "# 导入所需库\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import psutil  # 用于获取系统和进程的资源使用信息\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "# 必要なライブラリをインポート\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import psutil  # システムとプロセスのリソース使用情報を取得するためのライブラリ\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e41a436-7c29-4b36-86d8-e1610791f780",
    "_uuid": "b0447d8e-b453-4866-845b-72b694f5ba9c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:38:53.607997Z",
     "iopub.status.busy": "2024-07-27T00:38:53.607496Z",
     "iopub.status.idle": "2024-07-27T00:38:53.615459Z",
     "shell.execute_reply": "2024-07-27T00:38:53.614468Z",
     "shell.execute_reply.started": "2024-07-27T00:38:53.607956Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "# 必要なライブラリをインポート\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import psutil  # システムとプロセスのリソース使用情報を取得するためのライブラリ\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    BitsAndBytesConfig,\n",
    "    Gemma2ForSequenceClassification,\n",
    "    GemmaTokenizerFast,\n",
    "    Gemma2Config,\n",
    "    PreTrainedTokenizerBase, \n",
    "    EvalPrediction,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainerCallback,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2996ec59",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# !pip install --upgrade kaggle\n",
    "# #要先这么启动下才能创建\n",
    "# !kaggle datasets list\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# !pip install --upgrade kaggle\n",
    "# # まず、これを実行してから作成する必要があります\n",
    "# !kaggle datasets list\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0512ebcc-40cf-4725-a8b7-5819e6f75199",
    "_uuid": "497828fe-8782-4bca-bcfb-0fd87a17658f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:38:53.61719Z",
     "iopub.status.busy": "2024-07-27T00:38:53.616775Z",
     "iopub.status.idle": "2024-07-27T00:39:07.548174Z",
     "shell.execute_reply": "2024-07-27T00:39:07.54661Z",
     "shell.execute_reply.started": "2024-07-27T00:38:53.617133Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade kaggle\n",
    "# # まず、これを実行してから作成する必要があります\n",
    "# !kaggle datasets list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77119231",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# import json\n",
    "\n",
    "# token = {\n",
    "#     \"username\": \"qinhaoyang\",\n",
    "#     \"key\": \"02c6cdf132dabb5ddd9de0d37d8a7777\"\n",
    "# }\n",
    "\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)\n",
    "# with open('/kaggle/working/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# import json\n",
    "\n",
    "# token = {\n",
    "#     \"username\": \"qinhaoyang\",\n",
    "#     \"key\": \"02c6cdf132dabb5ddd9de0d37d8a7777\"\n",
    "# }\n",
    "\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)\n",
    "# with open('/kaggle/working/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5d7cb037-21e0-4f3a-82ae-6874c2c9a099",
    "_uuid": "9900fca5-c550-439a-b2dd-d5e4f4be35ff",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.551406Z",
     "iopub.status.busy": "2024-07-27T00:39:07.551074Z",
     "iopub.status.idle": "2024-07-27T00:39:07.556367Z",
     "shell.execute_reply": "2024-07-27T00:39:07.555351Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.551372Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# token = {\n",
    "#     \"username\": \"qinhaoyang\",\n",
    "#     \"key\": \"02c6cdf132dabb5ddd9de0d37d8a7777\"\n",
    "# }\n",
    "\n",
    "# with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)\n",
    "# with open('/kaggle/working/kaggle.json', 'w') as file:\n",
    "#     json.dump(token, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4990d2d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# # 定义 JSON 数据\n",
    "# data ={\n",
    "#   \"title\": \"LMSYS-model\", #//数据集标题\n",
    "#   \"subtitle\": \"\",\n",
    "#   \"description\": \"\",\n",
    "#   \"id\": \"qinhaoyang/LMSYS-model\",\n",
    "#   \"licenses\": [\n",
    "#         {\n",
    "#             \"name\": \"unknown\"\n",
    "#         }\n",
    "#     ],\n",
    "#     \"keywords\": [],\n",
    "#     \"collaborators\": [],\n",
    "#     \"data\": []\n",
    "# }\n",
    "\n",
    "\n",
    "# with open('/kaggle/working/dataset-metadata.json', 'w') as file:\n",
    "#     json.dump(data, file)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# # JSONデータを定義\n",
    "# data ={\n",
    "#   \"title\": \"LMSYS-model\", # データセットのタイトル\n",
    "#   \"subtitle\": \"\",\n",
    "#   \"description\": \"\",\n",
    "#   \"id\": \"qinhaoyang/LMSYS-model\",\n",
    "#   \"licenses\": [\n",
    "#         {\n",
    "#             \"name\": \"unknown\"\n",
    "#         }\n",
    "#     ],\n",
    "#     \"keywords\": [],\n",
    "#     \"collaborators\": [],\n",
    "#     \"data\": []\n",
    "# }\n",
    "\n",
    "\n",
    "# with open('/kaggle/working/dataset-metadata.json', 'w') as file:\n",
    "#     json.dump(data, file)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5386995f-9b04-4807-90c8-d9a5fcae7a08",
    "_uuid": "ae7431ca-4b8f-4067-8785-ea47d0d2e3c5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.558254Z",
     "iopub.status.busy": "2024-07-27T00:39:07.557911Z",
     "iopub.status.idle": "2024-07-27T00:39:07.566512Z",
     "shell.execute_reply": "2024-07-27T00:39:07.565618Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.558221Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "# # JSONデータを定義\n",
    "# data ={\n",
    "#   \"title\": \"LMSYS-model\", # データセットのタイトル\n",
    "#   \"subtitle\": \"\",\n",
    "#   \"description\": \"\",\n",
    "#   \"id\": \"qinhaoyang/LMSYS-model\",\n",
    "#   \"licenses\": [\n",
    "#         {\n",
    "#             \"name\": \"unknown\"\n",
    "#         }\n",
    "#     ],\n",
    "#     \"keywords\": [],\n",
    "#     \"collaborators\": [],\n",
    "#     \"data\": []\n",
    "# }\n",
    "\n",
    "\n",
    "# with open('/kaggle/working/dataset-metadata.json', 'w') as file:\n",
    "#     json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d33dfa",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Configurations\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### 設定\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a82039",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#!kaggle kernels output qinhaoyang/training-gemma-2-9b-4-bit-qlora-fine-tuning -p /kaggle/working\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#!kaggle kernels output qinhaoyang/training-gemma-2-9b-4-bit-qlora-fine-tuning -p /kaggle/working\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b2944eae-0e87-4884-b28b-87044e25efd3",
    "_uuid": "65a9bd98-9c4d-450c-bc40-18b65303d50e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.567844Z",
     "iopub.status.busy": "2024-07-27T00:39:07.567587Z",
     "iopub.status.idle": "2024-07-27T00:39:07.576561Z",
     "shell.execute_reply": "2024-07-27T00:39:07.575813Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.567822Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle kernels output qinhaoyang/training-gemma-2-9b-4-bit-qlora-fine-tuning -p /kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851d772",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#!kaggle datasets version -p /kaggle/working/output/ -m \"Description of the dataset changes\" --dir-mode tar\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#!kaggle datasets version -p /kaggle/working/output/ -m \"データセットの変更内容についての説明\" --dir-mode tar\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30586798-d09b-4d61-9ec2-dc842d8ac5c5",
    "_uuid": "eb99ccbd-4b4f-4f37-a39c-c03341ef39aa",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.579681Z",
     "iopub.status.busy": "2024-07-27T00:39:07.579348Z",
     "iopub.status.idle": "2024-07-27T00:39:07.585813Z",
     "shell.execute_reply": "2024-07-27T00:39:07.584974Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.579633Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#!kaggle datasets version -p /kaggle/working/output/ -m \"データセットの変更内容についての説明\" --dir-mode tar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5f7d9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"\n",
    "    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\"  # 4-bit quantized gemma-2-9b-instruct\n",
    "    max_length: int = 1024\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 1  # global batch size is 8 \n",
    "    per_device_eval_batch_size: int = 4\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 16  # there're 42 layers in total, we don't add adapters to the first 16 layers\n",
    "    lr: float = 2e-4\n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "    \n",
    "config = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"\n",
    "    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\"  # 4ビット量子化されたgemma-2-9b-instruct\n",
    "    max_length: int = 1024\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 1  # グローバルバッチサイズは8\n",
    "    per_device_eval_batch_size: int = 4\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 16  # 合計42層があるため、最初の16層にはアダプタを追加しない\n",
    "    lr: float = 2e-4\n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "    \n",
    "config = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ccb4170a-062f-49fe-9ed1-10e5ffdec5a6",
    "_uuid": "2d8a779d-8d23-4943-bbe0-df5b6000e45a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.587183Z",
     "iopub.status.busy": "2024-07-27T00:39:07.586907Z",
     "iopub.status.idle": "2024-07-27T00:39:07.597792Z",
     "shell.execute_reply": "2024-07-27T00:39:07.596991Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.58716Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"\n",
    "    checkpoint: str = \"unsloth/gemma-2-9b-it-bnb-4bit\"  # 4ビット量子化されたgemma-2-9b-instruct\n",
    "    max_length: int = 1024\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 1  # グローバルバッチサイズは8\n",
    "    per_device_eval_batch_size: int = 4\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 16  # 合計42層があるため、最初の16層にはアダプタを追加しない\n",
    "    lr: float = 2e-4\n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "    \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3909720",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "#### Training Arguments\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "#### トレーニング引数\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa5375",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c57b7641-e618-4362-a82d-69a452e4d4f8",
    "_uuid": "b51d059f-596e-407c-bc95-cf5d1bd7b99d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.599124Z",
     "iopub.status.busy": "2024-07-27T00:39:07.59883Z",
     "iopub.status.idle": "2024-07-27T00:39:07.720486Z",
     "shell.execute_reply": "2024-07-27T00:39:07.719512Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.5991Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0800fd9",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "#### LoRA config\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "#### LoRA設定\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64b0a10",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    # only target self-attention\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    # 自自己注意メカニズムのみをターゲットする\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5e427dee-36ed-41cb-9f2c-7e03ebef72a1",
    "_uuid": "ab0c6868-b07e-4bec-a432-ff81d6e3e9b7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.724842Z",
     "iopub.status.busy": "2024-07-27T00:39:07.724539Z",
     "iopub.status.idle": "2024-07-27T00:39:07.730167Z",
     "shell.execute_reply": "2024-07-27T00:39:07.729259Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.724818Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    # 自自己注意メカニズムのみをターゲットする\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    layers_to_transform=[i for i in range(42) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c20a18",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Instantiate the tokenizer & model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### トークナイザーとモデルのインスタンス化\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b4fc7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True  # <eos>を末尾に追加\n",
    "tokenizer.padding_side = \"right\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d220cb20-6838-407c-bf71-e2fef68b2ced",
    "_uuid": "019920d2-3dec-40a0-a33b-01c2e2358e14",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:07.731575Z",
     "iopub.status.busy": "2024-07-27T00:39:07.731313Z",
     "iopub.status.idle": "2024-07-27T00:39:13.121438Z",
     "shell.execute_reply": "2024-07-27T00:39:13.12062Z",
     "shell.execute_reply.started": "2024-07-27T00:39:07.731547Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GemmaTokenizerFast.from_pretrained(config.checkpoint)\n",
    "tokenizer.add_eos_token = True  # <eos>を末尾に追加\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3fd3a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False  # キャッシュの使用を無効にする\n",
    "model = prepare_model_for_kbit_training(model)  # 低ビットでのトレーニングの準備\n",
    "model = get_peft_model(model, lora_config)  # LoRAモデルの取得\n",
    "model\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "34f33b24-5e51-4b3f-9fb8-ffe2b9c2e7f5",
    "_uuid": "9c647ec1-ea00-4b96-96f3-c2ada6eff192",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:39:13.123458Z",
     "iopub.status.busy": "2024-07-27T00:39:13.122717Z",
     "iopub.status.idle": "2024-07-27T00:42:03.399037Z",
     "shell.execute_reply": "2024-07-27T00:42:03.398061Z",
     "shell.execute_reply.started": "2024-07-27T00:39:13.123424Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model.config.use_cache = False  # キャッシュの使用を無効にする\n",
    "model = prepare_model_for_kbit_training(model)  # 低ビットでのトレーニングの準備\n",
    "model = get_peft_model(model, lora_config)  # LoRAモデルの取得\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c8279d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.print_trainable_parameters()  # トレーニング可能なパラメータを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "13e94848-f1f1-42d6-85a8-294d151be5ca",
    "_uuid": "e5cda1e1-1fbb-4f33-8f2d-074b61a045ba",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:42:03.400802Z",
     "iopub.status.busy": "2024-07-27T00:42:03.40043Z",
     "iopub.status.idle": "2024-07-27T00:42:03.412602Z",
     "shell.execute_reply": "2024-07-27T00:42:03.411805Z",
     "shell.execute_reply.started": "2024-07-27T00:42:03.40077Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()  # トレーニング可能なパラメータを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07748c6f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Instantiate the dataset\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### データセットのインスタンス化\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d7b71f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "ds = Dataset.from_csv(\"/kaggle/input/lmsys-72k-dataset/lmsys-7.2k.csv\")\n",
    "#ds = ds.select(torch.arange(100))  # We only use the first 100 data for demo purpose\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "ds = Dataset.from_csv(\"/kaggle/input/lmsys-72k-dataset/lmsys-7.2k.csv\")  # データセットの読み込み\n",
    "# ds = ds.select(torch.arange(100))  # デモ目的で最初の100データを使用\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2cab0600-f566-45ea-aea7-721e37e94425",
    "_uuid": "872547ab-b6d8-4481-8c2e-796ad4b3d2dc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:42:03.414486Z",
     "iopub.status.busy": "2024-07-27T00:42:03.413991Z",
     "iopub.status.idle": "2024-07-27T00:42:07.013007Z",
     "shell.execute_reply": "2024-07-27T00:42:07.012267Z",
     "shell.execute_reply.started": "2024-07-27T00:42:03.414454Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# ds = Dataset.from_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "ds = Dataset.from_csv(\"/kaggle/input/lmsys-72k-dataset/lmsys-7.2k.csv\")  # データセットの読み込み\n",
    "# ds = ds.select(torch.arange(100))  # デモ目的で最初の100データを使用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015b7b91",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n",
    "            if a_win:\n",
    "                label = 0\n",
    "            elif b_win:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            labels.append(label)\n",
    "        return {**tokenized, \"labels\": labels}\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]  # プロンプトを処理\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]  # 応答Aを処理\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]  # 応答Bを処理\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # テキストを組み合わせる\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)  # トークナイザーでトークン化\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n",
    "            if a_win:\n",
    "                label = 0  # モデルAが勝った場合\n",
    "            elif b_win:\n",
    "                label = 1  # モデルBが勝った場合\n",
    "            else:\n",
    "                label = 2  # 引き分けの場合\n",
    "            labels.append(label)  # ラベルを追加\n",
    "        return {**tokenized, \"labels\": labels}  # トークン化された結果とラベルを返す\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))  # テキストを処理する\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1ccbfe4b-1a4e-471c-8613-1f0376748ed0",
    "_uuid": "f8a08dd6-d6c5-4ab5-b386-045b59099d9b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:42:07.01487Z",
     "iopub.status.busy": "2024-07-27T00:42:07.01443Z",
     "iopub.status.idle": "2024-07-27T00:42:07.025914Z",
     "shell.execute_reply": "2024-07-27T00:42:07.025004Z",
     "shell.execute_reply.started": "2024-07-27T00:42:07.014833Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = [\"<prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]  # プロンプトを処理\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]  # 応答Aを処理\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]  # 応答Bを処理\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # テキストを組み合わせる\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)  # トークナイザーでトークン化\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n",
    "            if a_win:\n",
    "                label = 0  # モデルAが勝った場合\n",
    "            elif b_win:\n",
    "                label = 1  # モデルBが勝った場合\n",
    "            else:\n",
    "                label = 2  # 引き分けの場合\n",
    "            labels.append(label)  # ラベルを追加\n",
    "        return {**tokenized, \"labels\": labels}  # トークン化された結果とラベルを返す\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))  # テキストを処理する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20bf622",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "ds = ds.map(encode, batched=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)  # カスタムトークナイザーのインスタンス化\n",
    "ds = ds.map(encode, batched=True)  # データセットにトークナイザーを適用\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbb4802e-caff-45d4-8d2f-6a3f6d095529",
    "_uuid": "153ce5c2-9032-4247-9bd5-2fb9980ee666",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:42:07.027338Z",
     "iopub.status.busy": "2024-07-27T00:42:07.027063Z",
     "iopub.status.idle": "2024-07-27T00:43:23.09077Z",
     "shell.execute_reply": "2024-07-27T00:43:23.089848Z",
     "shell.execute_reply.started": "2024-07-27T00:42:07.027313Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)  # カスタムトークナイザーのインスタンス化\n",
    "ds = ds.map(encode, batched=True)  # データセットにトークナイザーを適用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69cf41",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Compute metrics\n",
    "\n",
    "We'll compute the log-loss used in LB and accuracy as a auxiliary metric.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### メトリックの計算\n",
    "\n",
    "LBで使用されるログロスと精度を補助的なメトリックとして計算します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13afef",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
    "    return {\"acc\": acc, \"log_loss\": loss}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions  # 予測結果を取得\n",
    "    labels = eval_preds.label_ids  # ラベルを取得\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()  # 予測値を確率に変換\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)  # ログロスを計算\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))  # 精度を計算\n",
    "    return {\"acc\": acc, \"log_loss\": loss}  # 精度とログロスを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e2cb5b34-83aa-4053-9e8e-55487c11228d",
    "_uuid": "b7bcde97-4ff2-4e55-8b89-df32d50dd91c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:43:23.092385Z",
     "iopub.status.busy": "2024-07-27T00:43:23.092076Z",
     "iopub.status.idle": "2024-07-27T00:43:23.097752Z",
     "shell.execute_reply": "2024-07-27T00:43:23.096916Z",
     "shell.execute_reply.started": "2024-07-27T00:43:23.092358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions  # 予測結果を取得\n",
    "    labels = eval_preds.label_ids  # ラベルを取得\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()  # 予測値を確率に変換\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)  # ログロスを計算\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))  # 精度を計算\n",
    "    return {\"acc\": acc, \"log_loss\": loss}  # 精度とログロスを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7e13b6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Split\n",
    "\n",
    "Here, train and eval is splitted according to their `id % 5`\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### 分割\n",
    "\n",
    "ここでは、`id % 5` に従ってトレーニングと評価を分割します。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7dbdf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],  # トレーニング用\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]  # 評価用\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bc269643-b5c6-44ba-b1cf-5335b09e3628",
    "_uuid": "ed6b0a08-8eb0-41a2-b4a4-30e19b3ccf89",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:43:23.0995Z",
     "iopub.status.busy": "2024-07-27T00:43:23.099106Z",
     "iopub.status.idle": "2024-07-27T00:43:23.423985Z",
     "shell.execute_reply": "2024-07-27T00:43:23.423008Z",
     "shell.execute_reply.started": "2024-07-27T00:43:23.099464Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "folds = [\n",
    "    (\n",
    "        [i for i in range(len(ds)) if i % config.n_splits != fold_idx],  # トレーニング用\n",
    "        [i for i in range(len(ds)) if i % config.n_splits == fold_idx]  # 評価用\n",
    "    ) \n",
    "    for fold_idx in range(config.n_splits)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf05b8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# 加载 checkpoint\n",
    "checkpoint = \"/kaggle/input/lmsys-gemma-checkpoint/output/checkpoint-10200\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# チェックポイントをロード\n",
    "checkpoint = \"/kaggle/input/lmsys-gemma-checkpoint/output/checkpoint-10200\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b202a3d4-b8ef-42c1-b9a6-99f1fbe5d22c",
    "_uuid": "9d3ea4e1-74d4-4821-97ad-735d1079eab7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:43:23.425493Z",
     "iopub.status.busy": "2024-07-27T00:43:23.425195Z",
     "iopub.status.idle": "2024-07-27T00:43:23.429234Z",
     "shell.execute_reply": "2024-07-27T00:43:23.428385Z",
     "shell.execute_reply.started": "2024-07-27T00:43:23.425468Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# チェックポイントをロード\n",
    "checkpoint = \"/kaggle/input/lmsys-gemma-checkpoint/output/checkpoint-10200\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9546c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "#%tensorboard --logdir=/kaggle/working\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "#%tensorboard --logdir=/kaggle/working\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "45315ae7-1961-4007-8c90-9818d67365c6",
    "_uuid": "5552c7ac-aa70-4292-84cf-73e01aef3442",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:43:23.430796Z",
     "iopub.status.busy": "2024-07-27T00:43:23.430449Z",
     "iopub.status.idle": "2024-07-27T00:43:23.438074Z",
     "shell.execute_reply": "2024-07-27T00:43:23.437131Z",
     "shell.execute_reply.started": "2024-07-27T00:43:23.430766Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir=/kaggle/working"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93836161",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# 定义一个函数来记录当前进程的内存使用情况，并写入TensorBoard\n",
    "def log_memory_usage(step, writer):  # step 是记录的步骤标识，writer 是SummaryWriter实例\n",
    "    # 获取当前进程\n",
    "    process = psutil.Process(os.getpid())\n",
    "    # 获取进程的内存信息\n",
    "    mem_info = process.memory_info()\n",
    "    # 将RSS（常驻集大小）和VMS（虚拟内存大小）转换为MB，并记录到TensorBoard\n",
    "    writer.add_scalar('Memory Usage/RSS (MB)', mem_info.rss / (1024 * 1024), step)  # 物理内存使用\n",
    "    writer.add_scalar('Memory Usage/VMS (MB)', mem_info.vms / (1024 * 1024), step)  # 虚拟内存使用\n",
    "    print(f\"Memory usage logged at step {step}\")\n",
    "# 创建一个自定义的TrainerCallback子类来在每个epoch结束时记录内存使用\n",
    "class MemoryUsageLoggingCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):  # 这是在每个epoch结束时被调用的回调方法\n",
    "        # 使用当前的epoch数作为记录的步数\n",
    "        current_epoch = state.epoch\n",
    "        # 调用之前定义的函数，记录内存使用情况\n",
    "        log_memory_usage(current_epoch, tb_writer)\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        logs = kwargs.get(\"logs\", {})\n",
    "        for key, value in logs.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                tb_writer.add_scalar(f\"{key.capitalize()}\", value, state.global_step)\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "        # 额外记录训练和评估的损失与准确率\n",
    "        if \"loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/train\", logs[\"loss\"], state.global_step)\n",
    "        if \"eval_loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/eval\", logs[\"eval_loss\"], state.global_step)\n",
    "        if \"accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/train\", logs[\"accuracy\"], state.global_step)\n",
    "        if \"eval_accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/eval\", logs[\"eval_accuracy\"], state.global_step)\n",
    "\n",
    "# 初始化SummaryWriter\n",
    "tb_writer = SummaryWriter(log_dir=\"/kaggle/working/Gemma/tensorboard_logs\")\n",
    "\n",
    "# 定义训练和评估数据集\n",
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "# 初始化Trainer时，包含模型、数据集等配置，同时加入自定义的内存使用记录Callback\n",
    "trainer = Trainer(\n",
    "    args=training_args,  # 训练参数\n",
    "    model=model,  # 训练的模型\n",
    "    tokenizer=tokenizer,  # 分词器\n",
    "    train_dataset=ds.select(train_idx),  # 训练数据集\n",
    "    eval_dataset=ds.select(eval_idx),  # 评估数据集\n",
    "    compute_metrics=compute_metrics,  # 评估指标计算方法\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),  # 数据处理\n",
    "    callbacks=[MemoryUsageLoggingCallback()],  # 添加自定义回调到Trainer\n",
    ")\n",
    "\n",
    "# 检查是否有 checkpoint 来继续训练\n",
    "if checkpoint:\n",
    "    trainer.train(resume_from_checkpoint=checkpoint)\n",
    "else:\n",
    "    trainer.train()\n",
    "\n",
    "# 训练完成后，记得关闭SummaryWriter以释放资源\n",
    "tb_writer.close()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 現在のプロセスのメモリ使用状況を記録し、TensorBoardに書き込む関数を定義します\n",
    "def log_memory_usage(step, writer):  # step は記録のステップ識別子、writer はSummaryWriterのインスタンス\n",
    "    # 現在のプロセスを取得\n",
    "    process = psutil.Process(os.getpid())\n",
    "    # プロセスのメモリ情報を取得\n",
    "    mem_info = process.memory_info()\n",
    "    # RSS（常駐セットサイズ）とVMS（仮想メモリサイズ）をMBに変換し、TensorBoardに記録\n",
    "    writer.add_scalar('Memory Usage/RSS (MB)', mem_info.rss / (1024 * 1024), step)  # 物理メモリ使用量\n",
    "    writer.add_scalar('Memory Usage/VMS (MB)', mem_info.vms / (1024 * 1024), step)  # 仮想メモリ使用量\n",
    "    print(f\"メモリ使用量がステップ {step} で記録されました\")\n",
    "\n",
    "# 各エポック終了時にメモリ使用状況を記録するカスタムのTrainerCallbackサブクラスを作成\n",
    "class MemoryUsageLoggingCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):  # 各エポック終了時に呼び出されるコールバックメソッド\n",
    "        # 現在のエポック数を記録のステップとして使用\n",
    "        current_epoch = state.epoch\n",
    "        # 前に定義した関数を呼び出し、メモリ使用状況を記録\n",
    "        log_memory_usage(current_epoch, tb_writer)\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        logs = kwargs.get(\"logs\", {})\n",
    "        for key, value in logs.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                tb_writer.add_scalar(f\"{key.capitalize()}\", value, state.global_step)\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "        # トレーニングと評価の損失と精度も追加で記録\n",
    "        if \"loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/train\", logs[\"loss\"], state.global_step)\n",
    "        if \"eval_loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/eval\", logs[\"eval_loss\"], state.global_step)\n",
    "        if \"accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/train\", logs[\"accuracy\"], state.global_step)\n",
    "        if \"eval_accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/eval\", logs[\"eval_accuracy\"], state.global_step)\n",
    "\n",
    "# SummaryWriterを初期化\n",
    "tb_writer = SummaryWriter(log_dir=\"/kaggle/working/Gemma/tensorboard_logs\")\n",
    "\n",
    "# トレーニングと評価のデータセットを定義\n",
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "# Trainerを初期化し、モデル、データセットなどの設定を含め、メモリ使用記録のカスタムコールバックも追加\n",
    "trainer = Trainer(\n",
    "    args=training_args,  # トレーニング引数\n",
    "    model=model,  # トレーニングするモデル\n",
    "    tokenizer=tokenizer,  # トークナイザー\n",
    "    train_dataset=ds.select(train_idx),  # トレーニングデータセット\n",
    "    eval_dataset=ds.select(eval_idx),  # 評価データセット\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算するメソッド\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),  # データ処理\n",
    "    callbacks=[MemoryUsageLoggingCallback()],  # Trainerにカスタムコールバックを追加\n",
    ")\n",
    "\n",
    "# チェックポイントがあるか確認してトレーニングを再開\n",
    "if checkpoint:\n",
    "    trainer.train(resume_from_checkpoint=checkpoint)\n",
    "else:\n",
    "    trainer.train()\n",
    "\n",
    "# トレーニング後、SummaryWriterを閉じてリソースを解放\n",
    "tb_writer.close()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "baecc036-6ad2-4507-bce6-b8a46428b7cd",
    "_uuid": "c1fa5dff-de3b-4ff7-81a8-d28359e4bb48",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-07-27T00:43:23.43957Z",
     "iopub.status.busy": "2024-07-27T00:43:23.439261Z",
     "iopub.status.idle": "2024-07-27T00:44:11.288525Z",
     "shell.execute_reply": "2024-07-27T00:44:11.287047Z",
     "shell.execute_reply.started": "2024-07-27T00:43:23.439534Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 現在のプロセスのメモリ使用状況を記録し、TensorBoardに書き込む関数を定義します\n",
    "def log_memory_usage(step, writer):  # step は記録のステップ識別子、writer はSummaryWriterのインスタンス\n",
    "    # 現在のプロセスを取得\n",
    "    process = psutil.Process(os.getpid())\n",
    "    # プロセスのメモリ情報を取得\n",
    "    mem_info = process.memory_info()\n",
    "    # RSS（常駐セットサイズ）とVMS（仮想メモリサイズ）をMBに変換し、TensorBoardに記録\n",
    "    writer.add_scalar('Memory Usage/RSS (MB)', mem_info.rss / (1024 * 1024), step)  # 物理メモリ使用量\n",
    "    writer.add_scalar('Memory Usage/VMS (MB)', mem_info.vms / (1024 * 1024), step)  # 仮想メモリ使用量\n",
    "    print(f\"メモリ使用量がステップ {step} で記録されました\")\n",
    "\n",
    "# 各エポック終了時にメモリ使用状況を記録するカスタムのTrainerCallbackサブクラスを作成\n",
    "class MemoryUsageLoggingCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):  # 各エポック終了時に呼び出されるコールバックメソッド\n",
    "        # 現在のエポック数を記録のステップとして使用\n",
    "        current_epoch = state.epoch\n",
    "        # 前に定義した関数を呼び出し、メモリ使用状況を記録\n",
    "        log_memory_usage(current_epoch, tb_writer)\n",
    "    \n",
    "    def on_log(self, args, state, control, **kwargs):\n",
    "        logs = kwargs.get(\"logs\", {})\n",
    "        for key, value in logs.items():\n",
    "            if isinstance(value, (int, float)):\n",
    "                tb_writer.add_scalar(f\"{key.capitalize()}\", value, state.global_step)\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "        # トレーニングと評価の損失と精度も追加で記録\n",
    "        if \"loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/train\", logs[\"loss\"], state.global_step)\n",
    "        if \"eval_loss\" in logs:\n",
    "            tb_writer.add_scalar(\"Loss/eval\", logs[\"eval_loss\"], state.global_step)\n",
    "        if \"accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/train\", logs[\"accuracy\"], state.global_step)\n",
    "        if \"eval_accuracy\" in logs:\n",
    "            tb_writer.add_scalar(\"Accuracy/eval\", logs[\"eval_accuracy\"], state.global_step)\n",
    "\n",
    "# SummaryWriterを初期化\n",
    "tb_writer = SummaryWriter(log_dir=\"/kaggle/working/Gemma/tensorboard_logs\")\n",
    "\n",
    "# トレーニングと評価のデータセットを定義\n",
    "train_idx, eval_idx = folds[config.fold_idx]\n",
    "\n",
    "# Trainerを初期化し、モデル、データセットなどの設定を含め、メモリ使用記録のカスタムコールバックも追加\n",
    "trainer = Trainer(\n",
    "    args=training_args,  # トレーニング引数\n",
    "    model=model,  # トレーニングするモデル\n",
    "    tokenizer=tokenizer,  # トークナイザー\n",
    "    train_dataset=ds.select(train_idx),  # トレーニングデータセット\n",
    "    eval_dataset=ds.select(eval_idx),  # 評価データセット\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算するメソッド\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),  # データ処理\n",
    "    callbacks=[MemoryUsageLoggingCallback()],  # Trainerにカスタムコールバックを追加\n",
    ")\n",
    "\n",
    "# チェックポイントがあるか確認してトレーニングを再開\n",
    "if checkpoint:\n",
    "    trainer.train(resume_from_checkpoint=checkpoint)\n",
    "else:\n",
    "    trainer.train()\n",
    "\n",
    "# トレーニング後、SummaryWriterを閉じてリソースを解放\n",
    "tb_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8673a923",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.save_pretrained(\"/kaggle/working/Gemma\") # 指定保存模型的本地路径\n",
    "tokenizer.save_pretrained(\"/kaggle/working/Gemma\") # 如果需要，同时保存tokenizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.save_pretrained(\"/kaggle/working/Gemma\") # モデルを保存するローカルパスを指定\n",
    "tokenizer.save_pretrained(\"/kaggle/working/Gemma\") # 必要に応じて、トークナイザーも同時に保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4298917c-55f9-4655-ba9b-e8f09ad8fd66",
    "_uuid": "04ceab04-8312-4292-a88f-dbddcb852d56",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-07-27T00:44:11.289468Z",
     "iopub.status.idle": "2024-07-27T00:44:11.289979Z",
     "shell.execute_reply": "2024-07-27T00:44:11.289753Z",
     "shell.execute_reply.started": "2024-07-27T00:44:11.289731Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/kaggle/working/Gemma\") # モデルを保存するローカルパスを指定\n",
    "tokenizer.save_pretrained(\"/kaggle/working/Gemma\") # 必要に応じて、トークナイザーも同時に保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb15c2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# !kaggle datasets version -p /kaggle/working -m \"Description of the dataset changes\" --dir-mode tar\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# !kaggle datasets version -p /kaggle/working -m \"データセットの変更内容についての説明\" --dir-mode tar\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a7803780-12fe-4ae0-a3a9-1c6cee4995f7",
    "_uuid": "c9842fb8-7066-4458-90cc-2a7066496ad9",
    "collapsed": false,
    "execution": {
     "iopub.status.busy": "2024-07-27T00:44:11.292202Z",
     "iopub.status.idle": "2024-07-27T00:44:11.292735Z",
     "shell.execute_reply": "2024-07-27T00:44:11.292494Z",
     "shell.execute_reply.started": "2024-07-27T00:44:11.292474Z"
    },
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# !kaggle datasets version -p /kaggle/working -m \"データセットの変更内容についての説明\" --dir-mode tar"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5432805,
     "sourceId": 9016217,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5413855,
     "sourceId": 9045840,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
