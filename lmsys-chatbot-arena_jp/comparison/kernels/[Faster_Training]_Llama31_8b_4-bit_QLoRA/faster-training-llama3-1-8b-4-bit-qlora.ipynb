{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0a20dc",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、「LMSYS - Chatbot Arena」コンペティションにおける人間の好み予測に関する問題を解決するためのものです。具体的には、大規模言語モデル（LLM）を用いて、ユーザーからのプロンプトに対して選択された応答の好ましさを予測します。\n",
    "\n",
    "### 主な内容とアプローチ\n",
    "1. **ライブラリのインストール**: \n",
    "   - `bitsandbytes`, `transformers`, `tokenizers`, `peft` などのライブラリを使用して、LLMやトークナイザー、パラメータの効率的なトレーニングをサポートします。\n",
    "   - また、分析のために`numpy`や`pandas`も利用されます。\n",
    "\n",
    "2. **データの前処理**:\n",
    "   - データセットはCSVファイルから読み込まれ、NaN値や重複データの削除が行われます。\n",
    "   - 各応答の長さを計算し、これを元にデータをソートします。\n",
    "\n",
    "3. **モデルの設定とトレーニング**:\n",
    "   - LLaMAモデルに基づいて系列分類用のモデルを設定し、LoRA（Low-Rank Adaptation）を用いてパラメータを効率的にトレーニングします。\n",
    "   - 設定構成（`Config`クラス）に基づいてトレーニング戦略が定義され、複数の分割に対する検証（交差検証）が行われます。\n",
    "\n",
    "4. **トークナイザーのカスタマイズ**:\n",
    "   - プロンプトと応答を組み合わせたテキストをトークナイズするためのカスタムトークナイザーを使用しています。\n",
    "\n",
    "5. **メトリクスの計算**:\n",
    "   - 予測精度と対数損失（log loss）が評価され、これらの結果を用いてモデルの性能を測定します。\n",
    "\n",
    "6. **トレーニングと評価の反復**:\n",
    "   - 訓練バッチごとにトレーニングを実行し、各エポック後に評価を行う構成になっています。\n",
    "\n",
    "このノートブックでは、特にLLaMAモデルとLoRAを組み合わせて効率的な学習を実現し、Kaggleの競技における大規模言語モデルのトレーニングと評価に関する具体的なアプローチが示されています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23228523",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、提供されたJupyter Notebookで使用されている専門用語の簡単な解説です。特に、初心者にとって馴染みのない用語や、実務での経験がないと理解しにくいものに焦点を当てています。\n",
    "\n",
    "1. **bitsandbytes**: メモリ使用を最適化するためのライブラリで、特に大規模なモデルを効率的に訓練する際に小さいビット数でパラメータを表現することが可能です。\n",
    "\n",
    "2. **peft (Parameter Efficient Fine-Tuning)**: ファインチューニングを行う際に、モデルの一部分（例えばアダプタ層）だけを調整する手法です。全体のモデルを訓練するのではなく、パラメータの数を削減しつつ性能を維持することを目指します。\n",
    "\n",
    "3. **LoRA (Low-Rank Adaptation)**: 大規模モデルを適応させる際に、低ランクの行列分解を利用してネットワークの特定の部分だけを調整するアプローチです。これにより、少ないパラメータで効率的に適応が可能になります。\n",
    "\n",
    "4. **gradient accumulation**: バッチサイズを物理的に増やすことなく、複数のバッチの勾配を累積する手法です。これにより、GPUのメモリ制約を越えて大規模なバッチトレーニングが可能になります。\n",
    "\n",
    "5. **softmax**: 数値の集合を確率として解釈できるように変換するための関数です。出力ベクトルに対して使用すると、各要素のエクスポネンシャル関数を計算し、その合計で各要素を割ることで、合計が1になる確率ベクトルを得られます。\n",
    "\n",
    "6. **EvalPrediction**: 評価時の予測値と真のラベルを格納するためのオブジェクトです。評価指標の計算などに利用されます。\n",
    "\n",
    "7. **packing**: 入力データのトークン数を最大限に活用するためにデータをグループ化し、パディングを最小限に抑える処理です。効率的なバッチ処理を実現するために使用される技術です。\n",
    "\n",
    "8. **SFT (Supervised Fine-Tuning)**: 監視付きのファインチューニング手法で、ラベル付きデータを用いてモデルの性能を向上させるために行います。特に、特定のタスクに対するモデルの適応を意味します。\n",
    "\n",
    "9. **torch_dtype**: PyTorchにおいて、モデルで使用するデータ型を指定するオプションです。例えば、`torch.float16`は半精度浮動小数点数を意味し、メモリ使用量を削減するために使用されます。\n",
    "\n",
    "10. **TaskType**: 特定のタスクに関連するモジュールを特定する列挙型で、ここでは系列分類 (`SEQ_CLS`) のようなタスクタイプを指定します。\n",
    "\n",
    "11. **pretraining_tp (Tensor Parallelism)**: 大規模なモデルを効率よく訓練するために、モデルの計算を複数のGPUに分散させる手法です。これにより、メモリの制約を緩和し、もより大きなモデルを訓練可能にします。\n",
    "\n",
    "12. **dropout**: ニューラルネットワークの訓練中に特定のニューロンをランダムに無効にすることで、過学習を防ぐ技法です。\n",
    "\n",
    "13. **warmup steps**: 学習率を徐々に増加させるための初期ステップで、通常、訓練の初期段階でモデルが安定するように助けます。\n",
    "\n",
    "これらの用語は、特に特定の技術やフレームワークでのみ使用されているため、初心者が理解するのが難しい場合があります。学習を進める上で、これらの用語の理解が助けになるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4fd345",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:51:04.175257Z",
     "iopub.status.busy": "2024-07-29T13:51:04.174328Z",
     "iopub.status.idle": "2024-07-29T13:51:54.577962Z",
     "shell.execute_reply": "2024-07-29T13:51:54.57686Z",
     "shell.execute_reply.started": "2024-07-29T13:51:04.175208Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llama3-1-dependencies/dependencies/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llama3-1-dependencies/dependencies/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4600d7cb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -U trl\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!pip install -U trl\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:51:54.580225Z",
     "iopub.status.busy": "2024-07-29T13:51:54.579915Z",
     "iopub.status.idle": "2024-07-29T13:52:07.53373Z",
     "shell.execute_reply": "2024-07-29T13:52:07.532613Z",
     "shell.execute_reply.started": "2024-07-29T13:51:54.580196Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -U trl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd493c9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このPython 3環境には多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、ここにいくつかの便利なパッケージをロードする例があります\n",
    "\n",
    "import numpy as np # 線形代数ライブラリ\n",
    "import pandas as pd # データ処理、CSVファイルのI/O（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# 例えば、これを実行すると（クリックするかShift+Enterを押す）、入力ディレクトリ内のすべてのファイルがリストされます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 現在のディレクトリ(/kaggle/working/)に最大20GBまで書き込むことができ、\"Save & Run All\"を使ってバージョンを作成すると出力として保存されます\n",
    "# 一時ファイルは/kaggle/temp/に書き込むこともできますが、そのファイルは現在のセッションの外では保存されません\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:07.535399Z",
     "iopub.status.busy": "2024-07-29T13:52:07.535087Z",
     "iopub.status.idle": "2024-07-29T13:52:07.924142Z",
     "shell.execute_reply": "2024-07-29T13:52:07.923271Z",
     "shell.execute_reply.started": "2024-07-29T13:52:07.53537Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、ここにいくつかの便利なパッケージをロードする例があります\n",
    "\n",
    "import numpy as np # 線形代数ライブラリ\n",
    "import pandas as pd # データ処理、CSVファイルのI/O（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# 例えば、これを実行すると（クリックするかShift+Enterを押す）、入力ディレクトリ内のすべてのファイルがリストされます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 現在のディレクトリ(/kaggle/working/)に最大20GBまで書き込むことができ、\"Save & Run All\"を使ってバージョンを作成すると出力として保存されます\n",
    "# 一時ファイルは/kaggle/temp/に書き込むこともできますが、そのファイルは現在のセッションの外では保存されません"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b89d29",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizerFast,\n",
    "    PreTrainedTokenizerBase,\n",
    "    EvalPrediction,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizerFast,\n",
    "    PreTrainedTokenizerBase,\n",
    "    EvalPrediction,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:07.927368Z",
     "iopub.status.busy": "2024-07-29T13:52:07.926794Z",
     "iopub.status.idle": "2024-07-29T13:52:14.42691Z",
     "shell.execute_reply": "2024-07-29T13:52:14.425946Z",
     "shell.execute_reply.started": "2024-07-29T13:52:07.927334Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    DataCollatorWithPadding,\n",
    "    LlamaForSequenceClassification,\n",
    "    LlamaTokenizerFast,\n",
    "    PreTrainedTokenizerBase,\n",
    "    EvalPrediction,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType, PeftModel\n",
    "from sklearn.metrics import log_loss, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfef5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"\n",
    "    checkpoint: str = \"/kaggle/input/unsloth-meta-llama-3.1-8b-bnb-4bit/transformers/default/1/Meta-Llama-3.1-8B-bnb-4bit\"\n",
    "    max_length: int = 2048\n",
    "    n_splits: int = 5\n",
    "    fold_idx: int = 0\n",
    "    optim_type: str = \"adamw_8bit\"\n",
    "    per_device_train_batch_size: int = 4\n",
    "    gradient_accumulation_steps: int = 4\n",
    "    per_device_eval_batch_size: int = 8\n",
    "    n_epochs: int = 1\n",
    "    freeze_layers: int = 16  # there're 32 layers in total, we don't add adapters to the first 16 layers\n",
    "    lr: float = 2e-4\n",
    "    warmup_steps: int = 20\n",
    "    lora_r: int = 4\n",
    "    lora_alpha: float = lora_r * 2\n",
    "    lora_dropout: float = 0.05\n",
    "    lora_bias: str = \"none\"\n",
    "\n",
    "config = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"  # 出力ディレクトリの設定\n",
    "    checkpoint: str = \"/kaggle/input/unsloth-meta-llama-3.1-8b-bnb-4bit/transformers/default/1/Meta-Llama-3.1-8B-bnb-4bit\"  # チェックポイントのパス\n",
    "    max_length: int = 2048  # 最大長さの設定\n",
    "    n_splits: int = 5  # データの分割数\n",
    "    fold_idx: int = 0  # 現在の折り目インデックス\n",
    "    optim_type: str = \"adamw_8bit\"  # 最適化手法\n",
    "    per_device_train_batch_size: int = 4  # デバイスごとのトレーニングバッチサイズ\n",
    "    gradient_accumulation_steps: int = 4  # 勾配蓄積ステップ\n",
    "    per_device_eval_batch_size: int = 8  # デバイスごとの評価バッチサイズ\n",
    "    n_epochs: int = 1  # エポック数\n",
    "    freeze_layers: int = 16  # レイヤーを凍結する数（全体で32レイヤーがあるため最初の16レイヤーにはアダプターを追加しない）\n",
    "    lr: float = 2e-4  # 学習率\n",
    "    warmup_steps: int = 20  # ウォームアップステップ\n",
    "    lora_r: int = 4  # LoRAの設定\n",
    "    lora_alpha: float = lora_r * 2  # LoRAのアルファ\n",
    "    lora_dropout: float = 0.05  # LoRAのドロップアウト率\n",
    "    lora_bias: str = \"none\"  # LoRAのバイアス設定\n",
    "\n",
    "config = Config()  # 設定を生成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:14.429323Z",
     "iopub.status.busy": "2024-07-29T13:52:14.428309Z",
     "iopub.status.idle": "2024-07-29T13:52:14.438543Z",
     "shell.execute_reply": "2024-07-29T13:52:14.437188Z",
     "shell.execute_reply.started": "2024-07-29T13:52:14.429286Z"
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    output_dir: str = \"output\"  # 出力ディレクトリの設定\n",
    "    checkpoint: str = \"/kaggle/input/unsloth-meta-llama-3.1-8b-bnb-4bit/transformers/default/1/Meta-Llama-3.1-8B-bnb-4bit\"  # チェックポイントのパス\n",
    "    max_length: int = 2048  # 最大長さの設定\n",
    "    n_splits: int = 5  # データの分割数\n",
    "    fold_idx: int = 0  # 現在の折り目インデックス\n",
    "    optim_type: str = \"adamw_8bit\"  # 最適化手法\n",
    "    per_device_train_batch_size: int = 4  # デバイスごとのトレーニングバッチサイズ\n",
    "    gradient_accumulation_steps: int = 4  # 勾配蓄積ステップ\n",
    "    per_device_eval_batch_size: int = 8  # デバイスごとの評価バッチサイズ\n",
    "    n_epochs: int = 1  # エポック数\n",
    "    freeze_layers: int = 16  # レイヤーを凍結する数（全体で32レイヤーがあるため最初の16レイヤーにはアダプターを追加しない）\n",
    "    lr: float = 2e-4  # 学習率\n",
    "    warmup_steps: int = 20  # ウォームアップステップ\n",
    "    lora_r: int = 4  # LoRAの設定\n",
    "    lora_alpha: float = lora_r * 2  # LoRAのアルファ\n",
    "    lora_dropout: float = 0.05  # LoRAのドロップアウト率\n",
    "    lora_bias: str = \"none\"  # LoRAのバイアス設定\n",
    "\n",
    "config = Config()  # 設定を生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db91b807",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],\n",
    "    layers_to_transform=[i for i in range(32) if i >= config.freeze_layers],\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=config.lora_bias,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,  # LoRAのr値を設定\n",
    "    lora_alpha=config.lora_alpha,  # LoRAのアルファを設定\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],  # 変換対象のモジュール\n",
    "    layers_to_transform=[i for i in range(32) if i >= config.freeze_layers],  # 変換するレイヤーを選択\n",
    "    lora_dropout=config.lora_dropout,  # LoRAのドロップアウト率\n",
    "    bias=config.lora_bias,  # LoRAのバイアス設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプを定義（系列分類）\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:14.439956Z",
     "iopub.status.busy": "2024-07-29T13:52:14.439666Z",
     "iopub.status.idle": "2024-07-29T13:52:14.454669Z",
     "shell.execute_reply": "2024-07-29T13:52:14.453826Z",
     "shell.execute_reply.started": "2024-07-29T13:52:14.439931Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=config.lora_r,  # LoRAのr値を設定\n",
    "    lora_alpha=config.lora_alpha,  # LoRAのアルファを設定\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"],  # 変換対象のモジュール\n",
    "    layers_to_transform=[i for i in range(32) if i >= config.freeze_layers],  # 変換するレイヤーを選択\n",
    "    lora_dropout=config.lora_dropout,  # LoRAのドロップアウト率\n",
    "    bias=config.lora_bias,  # LoRAのバイアス設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプを定義（系列分類）\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2950af3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(config.checkpoint)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.add_eos_token = True  # We'll add <eos> at the end\n",
    "tokenizer.padding_side = \"right\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer = LlamaTokenizerFast.from_pretrained(config.checkpoint)  # トークナイザーをチェックポイントから初期化\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id  # パディントークンIDを終端トークンIDに設定\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディントークンを終端トークンに設定\n",
    "tokenizer.add_eos_token = True  # 文の終わりに<eos>トークンを追加\n",
    "tokenizer.padding_side = \"right\"  # パディングを右側に設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:14.456298Z",
     "iopub.status.busy": "2024-07-29T13:52:14.45587Z",
     "iopub.status.idle": "2024-07-29T13:52:14.947589Z",
     "shell.execute_reply": "2024-07-29T13:52:14.946815Z",
     "shell.execute_reply.started": "2024-07-29T13:52:14.456266Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizerFast.from_pretrained(config.checkpoint)  # トークナイザーをチェックポイントから初期化\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id  # パディントークンIDを終端トークンIDに設定\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディントークンを終端トークンに設定\n",
    "tokenizer.add_eos_token = True  # 文の終わりに<eos>トークンを追加\n",
    "tokenizer.padding_side = \"right\"  # パディングを右側に設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b413cf4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,  # クラスの数を指定\n",
    "    torch_dtype=torch.float16,  # 使用するテンソルのデータ型を指定\n",
    "    device_map=\"auto\"  # デバイスマップの自動設定\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:52:14.948901Z",
     "iopub.status.busy": "2024-07-29T13:52:14.948607Z",
     "iopub.status.idle": "2024-07-29T13:53:01.613151Z",
     "shell.execute_reply": "2024-07-29T13:53:01.612176Z",
     "shell.execute_reply.started": "2024-07-29T13:52:14.948865Z"
    }
   },
   "outputs": [],
   "source": [
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "    config.checkpoint,\n",
    "    num_labels=3,  # クラスの数を指定\n",
    "    torch_dtype=torch.float16,  # 使用するテンソルのデータ型を指定\n",
    "    device_map=\"auto\"  # デバイスマップの自動設定\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ff0b7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.config.use_cache = False\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.config.use_cache = False  # キャッシュの使用を無効に設定\n",
    "model = prepare_model_for_kbit_training(model)  # モデルをkbitトレーニング用に準備\n",
    "model = get_peft_model(model, lora_config)  # PEFTモデルを取得\n",
    "model\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:01.614976Z",
     "iopub.status.busy": "2024-07-29T13:53:01.614625Z",
     "iopub.status.idle": "2024-07-29T13:53:01.741845Z",
     "shell.execute_reply": "2024-07-29T13:53:01.740868Z",
     "shell.execute_reply.started": "2024-07-29T13:53:01.614948Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False  # キャッシュの使用を無効に設定\n",
    "model = prepare_model_for_kbit_training(model)  # モデルをkbitトレーニング用に準備\n",
    "model = get_peft_model(model, lora_config)  # PEFTモデルを取得\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61c06f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.print_trainable_parameters()  # 訓練可能なパラメータを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:01.746928Z",
     "iopub.status.busy": "2024-07-29T13:53:01.746237Z",
     "iopub.status.idle": "2024-07-29T13:53:01.755231Z",
     "shell.execute_reply": "2024-07-29T13:53:01.754267Z",
     "shell.execute_reply.started": "2024-07-29T13:53:01.746869Z"
    }
   },
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()  # 訓練可能なパラメータを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf512dc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # パディントークンIDを設定\n",
    "model.config.use_cache = False  # キャッシュの使用を無効に設定\n",
    "model.config.pretraining_tp = 1  # 前処理のためのテンソル並列化設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:01.757223Z",
     "iopub.status.busy": "2024-07-29T13:53:01.75664Z",
     "iopub.status.idle": "2024-07-29T13:53:01.766005Z",
     "shell.execute_reply": "2024-07-29T13:53:01.764991Z",
     "shell.execute_reply.started": "2024-07-29T13:53:01.757197Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id  # パディントークンIDを設定\n",
    "model.config.use_cache = False  # キャッシュの使用を無効に設定\n",
    "model.config.pretraining_tp = 1  # 前処理のためのテンソル並列化設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc37163",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates(subset=['response_a', 'response_b'], keep=False)\n",
    "df[\"len\"] = df[\"prompt\"].apply(len) + df[\"response_a\"].apply(len) + df[\"response_b\"].apply(len)\n",
    "df = df.sort_values(by=['len'])\n",
    "df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # データフレームにCSVファイルを読み込む\n",
    "df = df.dropna()  # NaN値を削除\n",
    "df = df.drop_duplicates(subset=['response_a', 'response_b'], keep=False)  # 重複する応答を削除\n",
    "df[\"len\"] = df[\"prompt\"].apply(len) + df[\"response_a\"].apply(len) + df[\"response_b\"].apply(len)  # 各行の長さを計算\n",
    "df = df.sort_values(by=['len'])  # 長さでソート\n",
    "df\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:01.768169Z",
     "iopub.status.busy": "2024-07-29T13:53:01.767361Z",
     "iopub.status.idle": "2024-07-29T13:53:04.250674Z",
     "shell.execute_reply": "2024-07-29T13:53:04.249787Z",
     "shell.execute_reply.started": "2024-07-29T13:53:01.768136Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # データフレームにCSVファイルを読み込む\n",
    "df = df.dropna()  # NaN値を削除\n",
    "df = df.drop_duplicates(subset=['response_a', 'response_b'], keep=False)  # 重複する応答を削除\n",
    "df[\"len\"] = df[\"prompt\"].apply(len) + df[\"response_a\"].apply(len) + df[\"response_b\"].apply(len)  # 各行の長さを計算\n",
    "df = df.sort_values(by=['len'])  # 長さでソート\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a0c2ab",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "ds = Dataset.from_pandas(df)\n",
    "ds = ds.select(torch.arange(1000)) #for demo purposes only\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "ds = Dataset.from_pandas(df)  # pandasデータフレームからデータセットを作成\n",
    "ds = ds.select(torch.arange(1000))  # デモ目的のために最初の1000行を選択\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:04.252112Z",
     "iopub.status.busy": "2024-07-29T13:53:04.251818Z",
     "iopub.status.idle": "2024-07-29T13:53:05.960179Z",
     "shell.execute_reply": "2024-07-29T13:53:05.959221Z",
     "shell.execute_reply.started": "2024-07-29T13:53:04.252087Z"
    }
   },
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df)  # pandasデータフレームからデータセットを作成\n",
    "ds = ds.select(torch.arange(1000))  # デモ目的のために最初の1000行を選択"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc981a1e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        prompt = [\"Which is the better response for the prompt? response_a or response_b or tie? \\n'n give score for each lable \\n\\n <prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):\n",
    "            if a_win:\n",
    "                label = 0\n",
    "            elif b_win:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "            labels.append(label)\n",
    "        return {**tokenized, \"labels\": labels}\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer  # トークナイザーを初期化\n",
    "        self.max_length = max_length  # 最大長を設定\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        # 各プロンプトのベターな応答を評価するためのテキストを作成\n",
    "        prompt = [\"Which is the better response for the prompt? response_a or response_b or tie? \\n'n give score for each lable \\n\\n <prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]  # 応答Aを整形\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]  # 応答Bを整形\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # プロンプト、応答A、応答Bを結合\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)  # テキストをトークン化\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):  # 勝者を判別\n",
    "            if a_win:\n",
    "                label = 0  # 応答Aが勝った場合\n",
    "            elif b_win:\n",
    "                label = 1  # 応答Bが勝った場合\n",
    "            else:\n",
    "                label = 2  # 引き分けの場合\n",
    "            labels.append(label)  # ラベルを追加\n",
    "        return {**tokenized, \"labels\": labels}  # トークン化されたデータとラベルを返す\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))  # テキストを処理して返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:05.961664Z",
     "iopub.status.busy": "2024-07-29T13:53:05.961368Z",
     "iopub.status.idle": "2024-07-29T13:53:05.970848Z",
     "shell.execute_reply": "2024-07-29T13:53:05.969929Z",
     "shell.execute_reply.started": "2024-07-29T13:53:05.961637Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        tokenizer: PreTrainedTokenizerBase, \n",
    "        max_length: int\n",
    "    ) -> None:\n",
    "        self.tokenizer = tokenizer  # トークナイザーを初期化\n",
    "        self.max_length = max_length  # 最大長を設定\n",
    "        \n",
    "    def __call__(self, batch: dict) -> dict:\n",
    "        # 各プロンプトのベターな応答を評価するためのテキストを作成\n",
    "        prompt = [\"Which is the better response for the prompt? response_a or response_b or tie? \\n'n give score for each lable \\n\\n <prompt>: \" + self.process_text(t) for t in batch[\"prompt\"]]\n",
    "        response_a = [\"\\n\\n<response_a>: \" + self.process_text(t) for t in batch[\"response_a\"]]  # 応答Aを整形\n",
    "        response_b = [\"\\n\\n<response_b>: \" + self.process_text(t) for t in batch[\"response_b\"]]  # 応答Bを整形\n",
    "        texts = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # プロンプト、応答A、応答Bを結合\n",
    "        tokenized = self.tokenizer(texts, max_length=self.max_length, truncation=True)  # テキストをトークン化\n",
    "        labels=[]\n",
    "        for a_win, b_win in zip(batch[\"winner_model_a\"], batch[\"winner_model_b\"]):  # 勝者を判別\n",
    "            if a_win:\n",
    "                label = 0  # 応答Aが勝った場合\n",
    "            elif b_win:\n",
    "                label = 1  # 応答Bが勝った場合\n",
    "            else:\n",
    "                label = 2  # 引き分けの場合\n",
    "            labels.append(label)  # ラベルを追加\n",
    "        return {**tokenized, \"labels\": labels}  # トークン化されたデータとラベルを返す\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text: str) -> str:\n",
    "        return \" \".join(eval(text, {\"null\": \"\"}))  # テキストを処理して返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5b730",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)\n",
    "ds = ds.map(encode, batched=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)  # カスタムトークナイザーのインスタンスを作成\n",
    "ds = ds.map(encode, batched=True)  # データセット全体に対してトークナイザーを適用\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:05.972086Z",
     "iopub.status.busy": "2024-07-29T13:53:05.971815Z",
     "iopub.status.idle": "2024-07-29T13:53:06.33407Z",
     "shell.execute_reply": "2024-07-29T13:53:06.333205Z",
     "shell.execute_reply.started": "2024-07-29T13:53:05.972064Z"
    }
   },
   "outputs": [],
   "source": [
    "encode = CustomTokenizer(tokenizer, max_length=config.max_length)  # カスタムトークナイザーのインスタンスを作成\n",
    "ds = ds.map(encode, batched=True)  # データセット全体に対してトークナイザーを適用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957b199f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions\n",
    "    labels = eval_preds.label_ids\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()\n",
    "    # Check for NaNs in predictions and labels\n",
    "    if np.isnan(probs).any() or np.isnan(labels).any():\n",
    "        raise ValueError(\"NaN values found in predictions or labels\")\n",
    "\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))\n",
    "    return {\"acc\": acc, \"log_loss\": loss}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions  # 予測値を取得\n",
    "    labels = eval_preds.label_ids  # ラベルを取得\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()  # 予測値から確率に変換\n",
    "    # 予測値やラベルにNaNが含まれているかチェックする\n",
    "    if np.isnan(probs).any() or np.isnan(labels).any():\n",
    "        raise ValueError(\"NaN values found in predictions or labels\")  # エラーを発生させる\n",
    "\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)  # ログ損失を計算\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))  # 精度を計算\n",
    "    return {\"acc\": acc, \"log_loss\": loss}  # 精度と損失を辞書型で返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:06.335337Z",
     "iopub.status.busy": "2024-07-29T13:53:06.335075Z",
     "iopub.status.idle": "2024-07-29T13:53:06.34184Z",
     "shell.execute_reply": "2024-07-29T13:53:06.340816Z",
     "shell.execute_reply.started": "2024-07-29T13:53:06.335315Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds: EvalPrediction) -> dict:\n",
    "    preds = eval_preds.predictions  # 予測値を取得\n",
    "    labels = eval_preds.label_ids  # ラベルを取得\n",
    "    probs = torch.from_numpy(preds).float().softmax(-1).numpy()  # 予測値から確率に変換\n",
    "    # 予測値やラベルにNaNが含まれているかチェックする\n",
    "    if np.isnan(probs).any() or np.isnan(labels).any():\n",
    "        raise ValueError(\"NaN values found in predictions or labels\")  # エラーを発生させる\n",
    "\n",
    "    loss = log_loss(y_true=labels, y_pred=probs)  # ログ損失を計算\n",
    "    acc = accuracy_score(y_true=labels, y_pred=preds.argmax(-1))  # 精度を計算\n",
    "    return {\"acc\": acc, \"log_loss\": loss}  # 精度と損失を辞書型で返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe07451",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "folds = [\n",
    "        (\n",
    "            [i for i in range(len(ds)) if i % config.n_splits != fold_idx],\n",
    "            [i for i in range(len(ds)) if i % config.n_splits == fold_idx]\n",
    "        ) \n",
    "        for fold_idx in range(config.n_splits)\n",
    "    ]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "folds = [\n",
    "        (\n",
    "            [i for i in range(len(ds)) if i % config.n_splits != fold_idx],  # トレーニングインデックス\n",
    "            [i for i in range(len(ds)) if i % config.n_splits == fold_idx]  # 評価インデックス\n",
    "        ) \n",
    "        for fold_idx in range(config.n_splits)  # 各分割について\n",
    "    ]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:06.343396Z",
     "iopub.status.busy": "2024-07-29T13:53:06.343073Z",
     "iopub.status.idle": "2024-07-29T13:53:06.356154Z",
     "shell.execute_reply": "2024-07-29T13:53:06.355302Z",
     "shell.execute_reply.started": "2024-07-29T13:53:06.34336Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = [\n",
    "        (\n",
    "            [i for i in range(len(ds)) if i % config.n_splits != fold_idx],  # トレーニングインデックス\n",
    "            [i for i in range(len(ds)) if i % config.n_splits == fold_idx]  # 評価インデックス\n",
    "        ) \n",
    "        for fold_idx in range(config.n_splits)  # 各分割について\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deabb78a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"output\",\n",
    "    overwrite_output_dir=True,\n",
    "    report_to=\"none\",\n",
    "    num_train_epochs=config.n_epochs,\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,\n",
    "    logging_steps=1000,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=100,\n",
    "    optim=config.optim_type,\n",
    "    fp16=True,\n",
    "    learning_rate=config.lr,\n",
    "    warmup_steps=config.warmup_steps,\n",
    "    packing=True, \n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=config.max_length,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"output\",  # 出力ディレクトリ\n",
    "    overwrite_output_dir=True,  # 出力ディレクトリを上書きする設定\n",
    "    report_to=\"none\",  # レポートの設定\n",
    "    num_train_epochs=config.n_epochs,  # トレーニングエポック数\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,  # デバイスごとのトレーニングバッチサイズ\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  # 勾配累積ステップ数\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,  # デバイスごとの評価バッチサイズ\n",
    "    logging_steps=1000,  # ロギングのステップ数\n",
    "    save_strategy=\"epoch\",  # 保存戦略\n",
    "    save_steps=100,  # 保存ステップ\n",
    "    optim=config.optim_type,  # 最適化手法\n",
    "    fp16=True,  # 半精度の使用\n",
    "    learning_rate=config.lr,  # 学習率\n",
    "    warmup_steps=config.warmup_steps,  # ウォームアップステップ\n",
    "    packing=True,  # パッキングの設定\n",
    "    dataset_text_field=\"text\",  # データセット内のテキストフィールド名\n",
    "    max_seq_length=config.max_length,  # 最大シーケンス長\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:06.357518Z",
     "iopub.status.busy": "2024-07-29T13:53:06.357275Z",
     "iopub.status.idle": "2024-07-29T13:53:06.646525Z",
     "shell.execute_reply": "2024-07-29T13:53:06.64568Z",
     "shell.execute_reply.started": "2024-07-29T13:53:06.357497Z"
    }
   },
   "outputs": [],
   "source": [
    "from trl import SFTTrainer, SFTConfig\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=\"output\",  # 出力ディレクトリ\n",
    "    overwrite_output_dir=True,  # 出力ディレクトリを上書きする設定\n",
    "    report_to=\"none\",  # レポートの設定\n",
    "    num_train_epochs=config.n_epochs,  # トレーニングエポック数\n",
    "    per_device_train_batch_size=config.per_device_train_batch_size,  # デバイスごとのトレーニングバッチサイズ\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  # 勾配累積ステップ数\n",
    "    per_device_eval_batch_size=config.per_device_eval_batch_size,  # デバイスごとの評価バッチサイズ\n",
    "    logging_steps=1000,  # ロギングのステップ数\n",
    "    save_strategy=\"epoch\",  # 保存戦略\n",
    "    save_steps=100,  # 保存ステップ\n",
    "    optim=config.optim_type,  # 最適化手法\n",
    "    fp16=True,  # 半精度の使用\n",
    "    learning_rate=config.lr,  # 学習率\n",
    "    warmup_steps=config.warmup_steps,  # ウォームアップステップ\n",
    "    packing=True,  # パッキングの設定\n",
    "    dataset_text_field=\"text\",  # データセット内のテキストフィールド名\n",
    "    max_seq_length=config.max_length,  # 最大シーケンス長\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f009dd5b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer = SFTTrainer(\n",
    "        model,\n",
    "        train_dataset=ds,\n",
    "        args=sft_config\n",
    "    )\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "trainer = SFTTrainer(\n",
    "        model,\n",
    "        train_dataset=ds,  # トレーニングデータセットを設定\n",
    "        args=sft_config  # 設定を渡す\n",
    "    )\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:06.647907Z",
     "iopub.status.busy": "2024-07-29T13:53:06.647613Z",
     "iopub.status.idle": "2024-07-29T13:53:06.984498Z",
     "shell.execute_reply": "2024-07-29T13:53:06.983565Z",
     "shell.execute_reply.started": "2024-07-29T13:53:06.64787Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "        model,\n",
    "        train_dataset=ds,  # トレーニングデータセットを設定\n",
    "        args=sft_config  # 設定を渡す\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0337e0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "for fold_idx in range(config.n_splits):\n",
    "    \n",
    "    train_idx, eval_idx = folds[fold_idx]\n",
    "\n",
    "    train_data = ds.select(train_idx).sort(\"len\")\n",
    "    val_data = ds.select(eval_idx).sort(\"len\")\n",
    "    \n",
    "    #split training data into batches with the same range of length\n",
    "    batch_size = 200\n",
    "    num_batches = len(train_data) // batch_size + (1 if len(train_data) % batch_size != 0 else 0)\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(train_data))\n",
    "        ds_temp = train_data.select(range(start_idx, end_idx))\n",
    "        \n",
    "        trainer.train_dataset = ds_temp\n",
    "        \n",
    "        print(f\"Training batch {batch_idx + 1}/{num_batches} on fold {fold_idx + 1}/{config.n_splits}...\")\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        trainer.save_model(f\"model_fold_{fold_idx}_batch{batch_idx}\")\n",
    "\n",
    "    \n",
    "    # Validate after training on all batches\n",
    "    trainer.eval_dataset = val_data\n",
    "    \n",
    "    print(f\"Validating on fold {fold_idx + 1}/{config.n_splits}...\")\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Save metrics if needed\n",
    "    print(f\"Evaluation results for fold {fold_idx + 1}: {eval_results}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "for fold_idx in range(config.n_splits):  # 各分割に対してループ\n",
    "\n",
    "    train_idx, eval_idx = folds[fold_idx]  # トレーニングインデックスと評価インデックスを取得\n",
    "\n",
    "    train_data = ds.select(train_idx).sort(\"len\")  # トレーニングデータを選択して長さでソート\n",
    "    val_data = ds.select(eval_idx).sort(\"len\")  # 評価データを選択して長さでソート\n",
    "    \n",
    "    # 同じ長さの範囲でトレーニングデータをバッチに分割\n",
    "    batch_size = 200  # バッチサイズ\n",
    "    num_batches = len(train_data) // batch_size + (1 if len(train_data) % batch_size != 0 else 0)  # バッチ数の計算\n",
    "    \n",
    "    for batch_idx in range(num_batches):  # 各バッチに対してループ\n",
    "        start_idx = batch_idx * batch_size  # バッチの開始インデックス\n",
    "        end_idx = min(start_idx + batch_size, len(train_data))  # バッチの終了インデックス\n",
    "        ds_temp = train_data.select(range(start_idx, end_idx))  # 一時データセットを選択\n",
    "        \n",
    "        trainer.train_dataset = ds_temp  # トレーナーにトレーニングデータを設定\n",
    "        \n",
    "        print(f\"Training batch {batch_idx + 1}/{num_batches} on fold {fold_idx + 1}/{config.n_splits}...\")  # トレーニング進行状況を表示\n",
    "        \n",
    "        trainer.train()  # モデルのトレーニングを実行\n",
    "        \n",
    "        trainer.save_model(f\"model_fold_{fold_idx}_batch{batch_idx}\")  # モデルを保存\n",
    "\n",
    "    \n",
    "    # すべてのバッチでトレーニングした後は検証を実施\n",
    "    trainer.eval_dataset = val_data  # 評価データを設定\n",
    "    \n",
    "    print(f\"Validating on fold {fold_idx + 1}/{config.n_splits}...\")  # 検証進行状況を表示\n",
    "    eval_results = trainer.evaluate()  # 検証を実施\n",
    "\n",
    "    # 必要に応じてメトリクスを保存\n",
    "    print(f\"Evaluation results for fold {fold_idx + 1}: {eval_results}\")  # 評価結果を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T13:53:06.986055Z",
     "iopub.status.busy": "2024-07-29T13:53:06.985713Z",
     "iopub.status.idle": "2024-07-29T14:33:18.62325Z",
     "shell.execute_reply": "2024-07-29T14:33:18.622123Z",
     "shell.execute_reply.started": "2024-07-29T13:53:06.986026Z"
    }
   },
   "outputs": [],
   "source": [
    "for fold_idx in range(config.n_splits):  # 各分割に対してループ\n",
    "\n",
    "    train_idx, eval_idx = folds[fold_idx]  # トレーニングインデックスと評価インデックスを取得\n",
    "\n",
    "    train_data = ds.select(train_idx).sort(\"len\")  # トレーニングデータを選択して長さでソート\n",
    "    val_data = ds.select(eval_idx).sort(\"len\")  # 評価データを選択して長さでソート\n",
    "    \n",
    "    # 同じ長さの範囲でトレーニングデータをバッチに分割\n",
    "    batch_size = 200  # バッチサイズ\n",
    "    num_batches = len(train_data) // batch_size + (1 if len(train_data) % batch_size != 0 else 0)  # バッチ数の計算\n",
    "    \n",
    "    for batch_idx in range(num_batches):  # 各バッチに対してループ\n",
    "        start_idx = batch_idx * batch_size  # バッチの開始インデックス\n",
    "        end_idx = min(start_idx + batch_size, len(train_data))  # バッチの終了インデックス\n",
    "        ds_temp = train_data.select(range(start_idx, end_idx))  # 一時データセットを選択\n",
    "        \n",
    "        trainer.train_dataset = ds_temp  # トレーナーにトレーニングデータを設定\n",
    "        \n",
    "        print(f\"Training batch {batch_idx + 1}/{num_batches} on fold {fold_idx + 1}/{config.n_splits}...\")  # トレーニング進行状況を表示\n",
    "        \n",
    "        trainer.train()  # モデルのトレーニングを実行\n",
    "        \n",
    "        trainer.save_model(f\"model_fold_{fold_idx}_batch{batch_idx}\")  # モデルを保存\n",
    "\n",
    "    \n",
    "    # すべてのバッチでトレーニングした後は検証を実施\n",
    "    trainer.eval_dataset = val_data  # 評価データを設定\n",
    "    \n",
    "    print(f\"Validating on fold {fold_idx + 1}/{config.n_splits}...\")  # 検証進行状況を表示\n",
    "    eval_results = trainer.evaluate()  # 検証を実施\n",
    "\n",
    "    # 必要に応じてメトリクスを保存\n",
    "    print(f\"Evaluation results for fold {fold_idx + 1}: {eval_results}\")  # 評価結果を表示"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5457551,
     "sourceId": 9051512,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 95591,
     "modelInstanceId": 70540,
     "sourceId": 83988,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
