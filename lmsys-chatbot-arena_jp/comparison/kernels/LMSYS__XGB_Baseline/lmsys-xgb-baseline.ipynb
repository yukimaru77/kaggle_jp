{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3658b6a3",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおけるXGBoostを使用したベースラインモデルを構築することを目的としています。このコンペティションでは、異なる大規模言語モデル（LLM）によるチャットボットの応答に対して、どちらがユーザーに好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "### 主な内容\n",
    "\n",
    "1. **ライブラリのインポート**:\n",
    "   - NumPy、Pandas、nltk、Matplotlib、Seaborn、XGBoostなどのライブラリを使用し、データの前処理や特徴抽出、モデルの構築・評価を行います。\n",
    "\n",
    "2. **データのロード**:\n",
    "   - チャットボットのデータセットをトレーニングとテストの2つに分けて読み込み、必要に応じてデータを事前処理します。特に、テキスト内の不要な形式を整える関数を適用します。\n",
    "\n",
    "3. **特徴エンジニアリング**:\n",
    "   - `Preprocessor`クラスを用いて、コサイン類似度やジャッカード類似度を計算するメソッドを定義します。また、テキストに含まれる引用、改行、箇条書きの数などの特徴量を抽出します。\n",
    "   - ユニグラム、バイグラム、トライグラムのオーバーラップを特徴量として計算し、データフレームに追加します。\n",
    "\n",
    "4. **モデリング**:\n",
    "   - XGBoost分類器を用いて、層化Kフォールド交差検証を行い、モデルのパフォーマンスを評価します。各フォールドのログ損失を計算し、最終的なテスト予測を生成します。\n",
    "   - 特徴量の重要度を評価し、上位の重要な特徴量を可視化します。\n",
    "\n",
    "5. **提出ファイルの作成**:\n",
    "   - 最終的なテスト予測をサンプル提出ファイルに格納し、「submission.csv」として保存します。\n",
    "\n",
    "### 使用される手法とライブラリ\n",
    "\n",
    "- **手法**: XGBoostによるマルチクラス分類、層化Kフォールド交差検証、特徴量抽出に基づくテキストの類似度評価。\n",
    "- **ライブラリ**: NumPy、Pandas、nltk、Matplotlib、Seaborn、XGBoost、Scikit-learn。\n",
    "\n",
    "このノートブックは、コンペティションにおける参加者が独自のモデルを開発するための出発点として活用できます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfbb6f9",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、初心者が理解するのに役立つ、ノートブック特有のドメイン知識やマイナーな専門用語の簡単な解説です。\n",
    "\n",
    "1. **ガーベジコレクション (Garbage Collection)**:\n",
    "   - メモリ管理手法の一つで、不要になったオブジェクトを自動的に解放するプロセスを指します。これにより、メモリリークを防ぎます。\n",
    "\n",
    "2. **TF-IDF (Term Frequency-Inverse Document Frequency)**:\n",
    "   - テキストデータの特徴抽出手法の一つで、特定の単語がある文書にどれだけ重要であるかを計算するために使用されます。高いTF-IDF値を持つ単語は、文書内での出現頻度が高く、他の文書での出現頻度が低いことを示します。\n",
    "\n",
    "3. **n-grams**:\n",
    "   - 文字列（通常はテキスト）をn個の連続した単語や文字の組み合わせに分割したものです。例えば、トライグラムは3つの連続した単語からなります。n-gramは、文脈や文の類似性を測る際に使用されます。\n",
    "\n",
    "4. **コサイン類似度 (Cosine Similarity)**:\n",
    "   - ベクトルの間の角度を測定する手法で、主にテキストや文書の類似性を比較するために用いられます。1に近いほど類似度が高いことを示します。\n",
    "\n",
    "5. **ジャッカード類似度 (Jaccard Similarity)**:\n",
    "   - 2つの集合の間の類似性を測る指標で、共通部分のサイズを和集合のサイズで割ったものです。値は0から1までの範囲で、1に近いほど集合が似ていることを意味します。\n",
    "\n",
    "6. **層化交差検証 (Stratified K-Fold Cross Validation)**:\n",
    "   - データセットを層（クラス）で均等に分割する交差検証手法です。これにより、各フォールドにおけるクラス分布が維持され、モデルの性能評価が安定します。\n",
    "\n",
    "7. **ハイパーパラメータ (Hyperparameter)**:\n",
    "   - モデルの学習前に設定する必要のあるパラメータで、モデル自体の構造や学習プロセスに影響を与えるものです。例として、学習率や決定木の深さなどがあります。\n",
    "\n",
    "8. **早期停止 (Early Stopping)**:\n",
    "   - モデルがバリデーションデータに対して最良の性能を示した時点で訓練を終了するテクニックです。過剰適合（オーバーフィッティング）を防ぐ目的があります。\n",
    "\n",
    "9. **特徴量の重要度 (Feature Importance)**:\n",
    "   - モデルが予測する際に、各特徴量がどの程度重要であるかを示す指標です。重要度が高い特徴量は、モデルの予測に大きく寄与します。\n",
    "\n",
    "10. **マルチクラスログ損失 (Multi-class Log Loss)**:\n",
    "    - 複数のクラスがある場合のモデルの予測精度を評価するための指標で、実際のクラスと予測した確率を基に計算されます。値が低いほどモデルの性能が良いことを示します。\n",
    "\n",
    "これらの用語はノートブックの内容に特有であり、実際の業務や学問の場での応用において重要となるものです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba6566f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# LMSYS | XGB Baseline\n",
    "\n",
    "(original notebook: https://www.kaggle.com/code/sercanyesiloz/lmsys-xgb-baseline)\n",
    "\n",
    "# 1. Libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# LMSYS | XGBベースライン\n",
    "\n",
    "(元のノートブック: https://www.kaggle.com/code/sercanyesiloz/lmsys-xgb-baseline)\n",
    "\n",
    "# 1. ライブラリ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e42cb0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import gc\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import gc  # ガーベジコレクションをインポートします。メモリを解放するのに役立ちます。\n",
    "import os  # OS関連の機能を提供するモジュールをインポートします。\n",
    "import re  # 正規表現操作に使用するモジュールをインポートします。\n",
    "import numpy as np  # 数値計算のためのライブラリであるNumPyをインポートします。\n",
    "import pandas as pd  # データ操作と解析のためのPandasをインポートします。\n",
    "\n",
    "import nltk  # 自然言語処理のためのライブラリであるnltkをインポートします。\n",
    "from nltk.util import ngrams  # n-gramsの生成に使用します。\n",
    "from collections import Counter  # 要素のカウントに使用するCounterをインポートします。\n",
    "import matplotlib.pyplot as plt  # データの可視化のためのMatplotlibをインポートします。\n",
    "import seaborn as sns  # 高度なデータビジュアライゼーションのためのSeabornをインポートします。\n",
    "\n",
    "import xgboost as xgb  # XGBoostライブラリをインポートします。機械学習のためのツールです。\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # テキストの特徴抽出に必要なベクトライザをインポートします。\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # コサイン類似度を計算するための関数をインポートします。\n",
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldを用いた交差検証を行います。\n",
    "from sklearn.metrics import log_loss  # ログ損失を計算するための関数をインポートします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-14T20:14:37.923824Z",
     "iopub.status.busy": "2024-07-14T20:14:37.922961Z",
     "iopub.status.idle": "2024-07-14T20:14:37.929988Z",
     "shell.execute_reply": "2024-07-14T20:14:37.928836Z",
     "shell.execute_reply.started": "2024-07-14T20:14:37.923789Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc  # ガーベジコレクションをインポートします。メモリを解放するのに役立ちます。\n",
    "import os  # OS関連の機能を提供するモジュールをインポートします。\n",
    "import re  # 正規表現操作に使用するモジュールをインポートします。\n",
    "import numpy as np  # 数値計算のためのライブラリであるNumPyをインポートします。\n",
    "import pandas as pd  # データ操作と解析のためのPandasをインポートします。\n",
    "\n",
    "import nltk  # 自然言語処理のためのライブラリであるnltkをインポートします。\n",
    "from nltk.util import ngrams  # n-gramsの生成に使用します。\n",
    "from collections import Counter  # 要素のカウントに使用するCounterをインポートします。\n",
    "import matplotlib.pyplot as plt  # データの可視化のためのMatplotlibをインポートします。\n",
    "import seaborn as sns  # 高度なデータビジュアライゼーションのためのSeabornをインポートします。\n",
    "\n",
    "import xgboost as xgb  # XGBoostライブラリをインポートします。機械学習のためのツールです。\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer  # テキストの特徴抽出に必要なベクトライザをインポートします。\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # コサイン類似度を計算するための関数をインポートします。\n",
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldを用いた交差検証を行います。\n",
    "from sklearn.metrics import log_loss  # ログ損失を計算するための関数をインポートします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c398466",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# 2. Configuration\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 2. 設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff78c84",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class config:\n",
    "    root = \"/kaggle/input/lmsys-chatbot-arena/\"\n",
    "    train_path = os.path.join(root, \"train.csv\")\n",
    "    test_path = os.path.join(root, \"test.csv\")\n",
    "    sample_submission_path = os.path.join(root, \"sample_submission.csv\")\n",
    "    seed = 42\n",
    "    n_splits = 10\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class config:\n",
    "    root = \"/kaggle/input/lmsys-chatbot-arena/\"  # データセットのルートディレクトリを指定します。\n",
    "    train_path = os.path.join(root, \"train.csv\")  # トレーニングデータのファイルパスを設定します。\n",
    "    test_path = os.path.join(root, \"test.csv\")  # テストデータのファイルパスを設定します。\n",
    "    sample_submission_path = os.path.join(root, \"sample_submission.csv\")  # 提出ファイルのサンプルのパスを設定します。\n",
    "    seed = 42  # 再現性のための乱数シードを設定します。\n",
    "    n_splits = 10  # クロスバリデーションの分割数を設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T20:14:37.932291Z",
     "iopub.status.busy": "2024-07-14T20:14:37.93187Z",
     "iopub.status.idle": "2024-07-14T20:14:37.939317Z",
     "shell.execute_reply": "2024-07-14T20:14:37.938498Z",
     "shell.execute_reply.started": "2024-07-14T20:14:37.932255Z"
    }
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    root = \"/kaggle/input/lmsys-chatbot-arena/\"  # データセットのルートディレクトリを指定します。\n",
    "    train_path = os.path.join(root, \"train.csv\")  # トレーニングデータのファイルパスを設定します。\n",
    "    test_path = os.path.join(root, \"test.csv\")  # テストデータのファイルパスを設定します。\n",
    "    sample_submission_path = os.path.join(root, \"sample_submission.csv\")  # 提出ファイルのサンプルのパスを設定します。\n",
    "    seed = 42  # 再現性のための乱数シードを設定します。\n",
    "    n_splits = 10  # クロスバリデーションの分割数を設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8616f391",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# 3. Loading Data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 3. データのロード\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa809bd6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Read the training, test, and sample submission datasets from the specified paths\n",
    "train = pd.read_csv(config.train_path)\n",
    "test = pd.read_csv(config.test_path)\n",
    "sample_submission = pd.read_csv(config.sample_submission_path)\n",
    "\n",
    "# If the test dataset has fewer than 10 rows, limit the training dataset to the first 10,000 rows\n",
    "if test.shape[0] < 10:\n",
    "    train = train.iloc[:10000]\n",
    "\n",
    "# Define a function to process strings by removing brackets and splitting sentences\n",
    "# NOTE: Another way would be to convert to JSON and then join, but this is probably most efficient in Python\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # Remove leading and trailing square brackets\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # Split by \",\" and remove surrounding quotes\n",
    "    return ' '.join(sentences)  # Join the sentences with a space\n",
    "\n",
    "# Apply the `process` function to the prompt and response columns in the train dataset\n",
    "train[\"prompt\"] = train[\"prompt\"].apply(process)\n",
    "train[\"response_a\"] = train[\"response_a\"].apply(process)\n",
    "train[\"response_b\"] = train[\"response_b\"].apply(process)\n",
    "\n",
    "# Apply the `process` function to the prompt and response columns in the test dataset\n",
    "test[\"prompt\"] = test[\"prompt\"].apply(process)\n",
    "test[\"response_a\"] = test[\"response_a\"].apply(process)\n",
    "test[\"response_b\"] = test[\"response_b\"].apply(process)\n",
    "\n",
    "# Print the shapes of the train and test datasets\n",
    "print(f\"train shape: {train.shape}\")\n",
    "print(f\"test shape: {test.shape}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Print the total number of missing values in the train and test datasets\n",
    "print(f\"train missing values: {train.isnull().sum().sum()}\")\n",
    "print(f\"test missing values: {test.isnull().sum().sum()}\")\n",
    "print(\"-\"*90)\n",
    "\n",
    "# Display the first few rows of the train dataset\n",
    "train.head()\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 指定されたパスからトレーニング、テスト、サンプル提出データセットを読み込みます\n",
    "train = pd.read_csv(config.train_path)  # トレーニングデータを読み込みます\n",
    "test = pd.read_csv(config.test_path)  # テストデータを読み込みます\n",
    "sample_submission = pd.read_csv(config.sample_submission_path)  # サンプル提出データを読み込みます\n",
    "\n",
    "# テストデータセットの行数が10未満の場合、トレーニングデータセットを最初の10,000行に制限します\n",
    "if test.shape[0] < 10:\n",
    "    train = train.iloc[:10000]  # 最初の10,000行をトレーニングデータとして使用します\n",
    "\n",
    "# 文字列を処理する関数を定義します。括弧を削除し、文を分割します\n",
    "# 注意: 別の方法としてJSONに変換して結合することもできますが、これはPythonにおいて効率的だと思われます\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 先頭と末尾の角括弧を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # \",\"で分割し、周囲の引用符を削除\n",
    "    return ' '.join(sentences)  # 文をスペースで結合して返します\n",
    "\n",
    "# トレーニングデータセットのプロンプトとレスポンスの列に`process`関数を適用します\n",
    "train[\"prompt\"] = train[\"prompt\"].apply(process)  # プロンプトの列を処理します\n",
    "train[\"response_a\"] = train[\"response_a\"].apply(process)  # レスポンスAの列を処理します\n",
    "train[\"response_b\"] = train[\"response_b\"].apply(process)  # レスポンスBの列を処理します\n",
    "\n",
    "# テストデータセットのプロンプトとレスポンスの列に`process`関数を適用します\n",
    "test[\"prompt\"] = test[\"prompt\"].apply(process)  # プロンプトの列を処理します\n",
    "test[\"response_a\"] = test[\"response_a\"].apply(process)  # レスポンスAの列を処理します\n",
    "test[\"response_b\"] = test[\"response_b\"].apply(process)  # レスポンスBの列を処理します\n",
    "\n",
    "# トレーニングデータとテストデータの形状を表示します\n",
    "print(f\"train shape: {train.shape}\")  # トレーニングデータの形状を表示します\n",
    "print(f\"test shape: {test.shape}\")  # テストデータの形状を表示します\n",
    "print(\"-\"*90)\n",
    "\n",
    "# トレーニングデータとテストデータの欠損値の合計を表示します\n",
    "print(f\"train missing values: {train.isnull().sum().sum()}\")  # トレーニングデータの欠損値の数を表示します\n",
    "print(f\"test missing values: {test.isnull().sum().sum()}\")  # テストデータの欠損値の数を表示します\n",
    "print(\"-\"*90)\n",
    "\n",
    "# トレーニングデータの最初の数行を表示します\n",
    "train.head()  # トレーニングデータの先頭行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T20:14:37.9702Z",
     "iopub.status.busy": "2024-07-14T20:14:37.969439Z",
     "iopub.status.idle": "2024-07-14T20:14:39.831322Z",
     "shell.execute_reply": "2024-07-14T20:14:39.830418Z",
     "shell.execute_reply.started": "2024-07-14T20:14:37.970176Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定されたパスからトレーニング、テスト、サンプル提出データセットを読み込みます\n",
    "train = pd.read_csv(config.train_path)  # トレーニングデータを読み込みます\n",
    "test = pd.read_csv(config.test_path)  # テストデータを読み込みます\n",
    "sample_submission = pd.read_csv(config.sample_submission_path)  # サンプル提出データを読み込みます\n",
    "\n",
    "# テストデータセットの行数が10未満の場合、トレーニングデータセットを最初の10,000行に制限します\n",
    "if test.shape[0] < 10:\n",
    "    train = train.iloc[:10000]  # 最初の10,000行をトレーニングデータとして使用します\n",
    "\n",
    "# 文字列を処理する関数を定義します。括弧を削除し、文を分割します\n",
    "# 注意: 別の方法としてJSONに変換して結合することもできますが、これはPythonにおいて効率的だと思われます\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 先頭と末尾の角括弧を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # \",\"で分割し、周囲の引用符を削除\n",
    "    return ' '.join(sentences)  # 文をスペースで結合して返します\n",
    "\n",
    "# トレーニングデータセットのプロンプトとレスポンスの列に`process`関数を適用します\n",
    "train[\"prompt\"] = train[\"prompt\"].apply(process)  # プロンプトの列を処理します\n",
    "train[\"response_a\"] = train[\"response_a\"].apply(process)  # レスポンスAの列を処理します\n",
    "train[\"response_b\"] = train[\"response_b\"].apply(process)  # レスポンスBの列を処理します\n",
    "\n",
    "# テストデータセットのプロンプトとレスポンスの列に`process`関数を適用します\n",
    "test[\"prompt\"] = test[\"prompt\"].apply(process)  # プロンプトの列を処理します\n",
    "test[\"response_a\"] = test[\"response_a\"].apply(process)  # レスポンスAの列を処理します\n",
    "test[\"response_b\"] = test[\"response_b\"].apply(process)  # レスポンスBの列を処理します\n",
    "\n",
    "# トレーニングデータとテストデータの形状を表示します\n",
    "print(f\"train shape: {train.shape}\")  # トレーニングデータの形状を表示します\n",
    "print(f\"test shape: {test.shape}\")  # テストデータの形状を表示します\n",
    "print(\"-\"*90)\n",
    "\n",
    "# トレーニングデータとテストデータの欠損値の合計を表示します\n",
    "print(f\"train missing values: {train.isnull().sum().sum()}\")  # トレーニングデータの欠損値の数を表示します\n",
    "print(f\"test missing values: {test.isnull().sum().sum()}\")  # テストデータの欠損値の数を表示します\n",
    "print(\"-\"*90)\n",
    "\n",
    "# トレーニングデータの最初の数行を表示します\n",
    "train.head()  # トレーニングデータの先頭行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd4fabf",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# 4. Feature Engineering\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 4. 特徴エンジニアリング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b66678",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class Preprocessor:\n",
    "\n",
    "    # Calculate cosine similarity between two texts\n",
    "    def cosine_sim(self, text1: str, text2: str):\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # Create a TF-IDF vectorizer (word-importance) with n-grams from 1 to 3\n",
    "            vectorizer.fit([text1, text2])  # Fit the vectorizer on both texts\n",
    "            output = vectorizer.transform([text1, text2]).toarray()  # Transform texts to TF-IDF vectors\n",
    "            cos_sim = cosine_similarity(output)  # Calculate cosine similarity between vectors\n",
    "            return cos_sim[0][1]  # Return the similarity score between text1 and text2\n",
    "        except:\n",
    "            print(f\"cosine_sim exception with '{text1}' and '{text2}'\")\n",
    "            return np.nan  # Return NaN in case of an exception\n",
    "\n",
    "    # Calculate Jaccard similarity between two texts\n",
    "    def jaccard_sim(self, text1: str, text2: str):\n",
    "        set1 = set(text1.split())  # Split text1 into set of words\n",
    "        set2 = set(text2.split())  # Split text2 into set of words\n",
    "        intersection = set1.intersection(set2)  # Find intersection of both sets\n",
    "        union = set1.union(set2)  # Find union of both sets\n",
    "        return len(intersection) / len(union)  # Return Jaccard similarity score\n",
    "    \n",
    "    # Count the number of quoted segments in a text\n",
    "    def count_quotes(self, text: str) -> int:\n",
    "        single_quote_pattern = r\"'(.*?)'\"  # Pattern for single quotes\n",
    "        double_quote_pattern = r'\"(.*?)\"'  # Pattern for double quotes\n",
    "        single_quotes = re.findall(single_quote_pattern, text)  # Find all single-quoted segments\n",
    "        double_quotes = re.findall(double_quote_pattern, text)  # Find all double-quoted segments\n",
    "        total_quotes = len(single_quotes) + len(double_quotes)  # Sum the counts of both types of quotes\n",
    "        return total_quotes  # Return the total count of quoted segments\n",
    "    \n",
    "    # Count the number of new-lines in a text\n",
    "    def count_new_lines(self, text: str) -> int:\n",
    "        return text.count('\\\\n')  # Return the count of newline characters in the text\n",
    "    \n",
    "    # Count the number of bulleted lists in the text\n",
    "    def count_bulleted_lists(self, text: str) -> int:\n",
    "        bullet_pattern = r'(\\\\n|^)[\\*\\-\\+]\\s'  # Pattern for bulleted list items\n",
    "        return len(re.findall(bullet_pattern, text))  # Return the count of bulleted list items\n",
    "    \n",
    "    # Tokenize text into lowercase words\n",
    "    def tokenize(self, text: str):\n",
    "        return nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # Generate n-grams from the tokenized text\n",
    "    def generate_ngrams(self, text: str, n: int):\n",
    "        tokens = self.tokenize(text)  # Tokenize the text\n",
    "        return list(ngrams(tokens, n))  # Generate n-grams from tokens\n",
    "\n",
    "    # Count overlapping n-grams between two texts\n",
    "    def count_ngram_overlaps(self, text1: str, text2: str, n: int) -> int:\n",
    "        try:\n",
    "            ngrams1 = self.generate_ngrams(text1, n)  # Generate n-grams for text1\n",
    "            ngrams2 = self.generate_ngrams(text2, n)  # Generate n-grams for text2\n",
    "            counter1 = Counter(ngrams1)  # Count n-grams in text1\n",
    "            counter2 = Counter(ngrams2)  # Count n-grams in text2\n",
    "            overlap = counter1 & counter2  # Find the overlap between the two counters\n",
    "            overlap_count = sum(overlap.values())  # Sum the counts of overlapping n-grams\n",
    "            return overlap_count  # Return the overlap count\n",
    "        except:\n",
    "            return 0  # Return 0 in case of an exception\n",
    "        \n",
    "    # Run preprocessing on the data\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # Calculate unigram, bigram, and trigram overlaps between response_a and response_b\n",
    "        data[\"respa_respb_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 1), axis=1)\n",
    "        data[\"respa_respb_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 2), axis=1)\n",
    "        data[\"respa_respb_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 3), axis=1)\n",
    "\n",
    "        # Calculate unigram, bigram, and trigram overlaps between response_a and prompt\n",
    "        data[\"respa_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respa_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respa_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 3), axis=1)\n",
    "\n",
    "        # Calculate unigram, bigram, and trigram overlaps between response_b and prompt\n",
    "        data[\"respb_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respb_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respb_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 3), axis=1)\n",
    "        \n",
    "        # Calculate the length of tokenized texts\n",
    "        data[\"respa_len\"] = data[\"response_a\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        data[\"respb_len\"] = data[\"response_b\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        data[\"prompt_len\"] = data[\"prompt\"].apply(lambda x: len(self.tokenize(x)))\n",
    "        \n",
    "        # Calculate length ratios between response_a, response_b, and prompt\n",
    "        data[\"respa_prompt_len_ratio\"] = data[\"respa_len\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_len_ratio\"] = data[\"respb_len\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_respb_len_ratio\"] = data[\"respa_len\"] / data[\"respb_len\"]\n",
    "        \n",
    "        # Calculate length differences between response_a, response_b, and prompt\n",
    "        data[\"respa_respb_len_diff\"] = data[\"respa_len\"] - data[\"respb_len\"]\n",
    "        data[\"respa_prompt_len_diff\"] = data[\"respa_len\"] - data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_len_diff\"] = data[\"respb_len\"] - data[\"prompt_len\"]\n",
    "        \n",
    "        # Calculate overlap ratios for unigrams, bigrams, and trigrams between response_a and prompt\n",
    "        data[\"respa_prompt_overlap_unigram_ratio\"] = data[\"respa_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_prompt_overlap_bigram_ratio\"] = data[\"respa_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respa_prompt_overlap_trigram_ratio\"] = data[\"respa_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
    "\n",
    "        # Calculate overlap ratios for unigrams, bigrams, and trigrams between response_b and prompt\n",
    "        data[\"respb_prompt_overlap_unigram_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_overlap_bigram_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"prompt_len\"]\n",
    "        data[\"respb_prompt_overlap_trigram_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"prompt_len\"]\n",
    "        \n",
    "        # Count the number of quotes in response_a, response_b, and prompt\n",
    "        data[\"respa_quotes\"] = data[\"response_a\"].apply(lambda x: self.count_quotes(x))\n",
    "        data[\"respb_quotes\"] = data[\"response_b\"].apply(lambda x: self.count_quotes(x))\n",
    "        data[\"prompt_quotes\"] = data[\"prompt\"].apply(lambda x: self.count_quotes(x))\n",
    "\n",
    "        # Count the number of new-lines in response_a, response_b, and prompt\n",
    "        data[\"respa_new_lines\"] = data[\"response_a\"].apply(lambda x: self.count_new_lines(x))\n",
    "        data[\"respb_new_lines\"] = data[\"response_b\"].apply(lambda x: self.count_new_lines(x))\n",
    "        data[\"prompt_new_lines\"] = data[\"prompt\"].apply(lambda x: self.count_new_lines(x))\n",
    "\n",
    "        # Count the number of bulleted lists in response_a, response_b, and prompt\n",
    "        data[\"respa_bullets\"] = data[\"response_a\"].apply(lambda x: self.count_bulleted_lists(x))\n",
    "        data[\"respb_bullets\"] = data[\"response_b\"].apply(lambda x: self.count_bulleted_lists(x))\n",
    "        data[\"prompt_bullets\"] = data[\"prompt\"].apply(lambda x: self.count_bulleted_lists(x))\n",
    "        \n",
    "        # Calculate cosine and Jaccard similarities between response_a and response_b\n",
    "        data[\"respa_respb_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)\n",
    "        data[\"respa_respb_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)\n",
    "        \n",
    "        # Calculate cosine and Jaccard similarities between response_a and prompt\n",
    "        data[\"respa_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)\n",
    "        data[\"respa_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)\n",
    "        \n",
    "        # Calculate cosine and Jaccard similarities between response_b and prompt\n",
    "        data[\"respb_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)\n",
    "        data[\"respb_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)\n",
    "        \n",
    "        return data  # Return the processed dataframe\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class Preprocessor:\n",
    "\n",
    "    # 2つのテキスト間のコサイン類似度を計算します\n",
    "    def cosine_sim(self, text1: str, text2: str):\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # n-gramを1から3まで考慮したTF-IDFベクトライザを作成します\n",
    "            vectorizer.fit([text1, text2])  # 2つのテキストにベクトライザをフィットさせます\n",
    "            output = vectorizer.transform([text1, text2]).toarray()  # テキストをTF-IDFベクトルに変換します\n",
    "            cos_sim = cosine_similarity(output)  # ベクトル間のコサイン類似度を計算します\n",
    "            return cos_sim[0][1]  # text1とtext2の類似度スコアを返します\n",
    "        except:\n",
    "            print(f\"cosine_sim exception with '{text1}' and '{text2}'\")\n",
    "            return np.nan  # 例外が発生した場合はNaNを返します\n",
    "\n",
    "    # 2つのテキスト間のジャッカード類似度を計算します\n",
    "    def jaccard_sim(self, text1: str, text2: str):\n",
    "        set1 = set(text1.split())  # text1を単語の集合に分割します\n",
    "        set2 = set(text2.split())  # text2を単語の集合に分割します\n",
    "        intersection = set1.intersection(set2)  # 2つの集合の共通部分を見つけます\n",
    "        union = set1.union(set2)  # 2つの集合の和を見つけます\n",
    "        return len(intersection) / len(union)  # ジャッカード類似度スコアを返します\n",
    "    \n",
    "    # テキスト内の引用されたセグメントの数をカウントします\n",
    "    def count_quotes(self, text: str) -> int:\n",
    "        single_quote_pattern = r\"'(.*?)'\"  # 単一引用符のパターン\n",
    "        double_quote_pattern = r'\"(.*?)\"'  # 二重引用符のパターン\n",
    "        single_quotes = re.findall(single_quote_pattern, text)  # 単一引用符で囲まれた部分をすべて見つけます\n",
    "        double_quotes = re.findall(double_quote_pattern, text)  # 二重引用符で囲まれた部分をすべて見つけます\n",
    "        total_quotes = len(single_quotes) + len(double_quotes)  # 両方のカウントを合計します\n",
    "        return total_quotes  # 引用されたセグメントの合計数を返します\n",
    "    \n",
    "    # テキスト内の改行の数をカウントします\n",
    "    def count_new_lines(self, text: str) -> int:\n",
    "        return text.count('\\\\n')  # テキスト内の改行文字の数を返します\n",
    "    \n",
    "    # テキスト内の箇条書きリストの数をカウントします\n",
    "    def count_bulleted_lists(self, text: str) -> int:\n",
    "        bullet_pattern = r'(\\\\n|^)[\\*\\-\\+]\\s'  # 箇条書き項目のパターン\n",
    "        return len(re.findall(bullet_pattern, text))  # 箇条書き項目の数を返します\n",
    "    \n",
    "    # テキストを小文字の単語にトークン化します\n",
    "    def tokenize(self, text: str):\n",
    "        return nltk.word_tokenize(text.lower())  # テキストをトークン化し、小文字に変換します\n",
    "\n",
    "    # トークン化されたテキストからn-gramを生成します\n",
    "    def generate_ngrams(self, text: str, n: int):\n",
    "        tokens = self.tokenize(text)  # テキストをトークン化します\n",
    "        return list(ngrams(tokens, n))  # トークンからn-gramを生成して返します\n",
    "\n",
    "    # 2つのテキスト間のオーバーラップn-gramの数をカウントします\n",
    "    def count_ngram_overlaps(self, text1: str, text2: str, n: int) -> int:\n",
    "        try:\n",
    "            ngrams1 = self.generate_ngrams(text1, n)  # text1のn-gramを生成します\n",
    "            ngrams2 = self.generate_ngrams(text2, n)  # text2のn-gramを生成します\n",
    "            counter1 = Counter(ngrams1)  # text1のn-gramをカウントします\n",
    "            counter2 = Counter(ngrams2)  # text2のn-gramをカウントします\n",
    "            overlap = counter1 & counter2  # 2つのカウンタのオーバーラップを見つけます\n",
    "            overlap_count = sum(overlap.values())  # オーバーラップしたn-gramのカウントを合計します\n",
    "            return overlap_count  # オーバーラップの数を返します\n",
    "        except:\n",
    "            return 0  # 例外が発生した場合は0を返します\n",
    "        \n",
    "    # データに対する前処理を実行します\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # response_aとresponse_b間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respa_respb_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 1), axis=1)\n",
    "        data[\"respa_respb_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 2), axis=1)\n",
    "        data[\"respa_respb_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 3), axis=1)\n",
    "\n",
    "        # response_aとプロンプト間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respa_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respa_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respa_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 3), axis=1)\n",
    "\n",
    "        # response_bとプロンプト間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respb_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respb_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respb_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 3), axis=1)\n",
    "        \n",
    "        # トークン化されたテキストの長さを計算します\n",
    "        data[\"respa_len\"] = data[\"response_a\"].apply(lambda x: len(self.tokenize(x)))  # response_aのトークン数を計算します\n",
    "        data[\"respb_len\"] = data[\"response_b\"].apply(lambda x: len(self.tokenize(x)))  # response_bのトークン数を計算します\n",
    "        data[\"prompt_len\"] = data[\"prompt\"].apply(lambda x: len(self.tokenize(x)))  # プロンプトのトークン数を計算します\n",
    "        \n",
    "        # response_a、response_b、プロンプト間の長さ比を計算します\n",
    "        data[\"respa_prompt_len_ratio\"] = data[\"respa_len\"] / data[\"prompt_len\"]  # response_aとプロンプトの長さ比\n",
    "        data[\"respb_prompt_len_ratio\"] = data[\"respb_len\"] / data[\"prompt_len\"]  # response_bとプロンプトの長さ比\n",
    "        data[\"respa_respb_len_ratio\"] = data[\"respa_len\"] / data[\"respb_len\"]  # response_aとresponse_bの長さ比\n",
    "        \n",
    "        # response_a、response_b、プロンプト間の長さの差を計算します\n",
    "        data[\"respa_respb_len_diff\"] = data[\"respa_len\"] - data[\"respb_len\"]  # response_aとresponse_bの長さの差\n",
    "        data[\"respa_prompt_len_diff\"] = data[\"respa_len\"] - data[\"prompt_len\"]  # response_aとプロンプトの長さの差\n",
    "        data[\"respb_prompt_len_diff\"] = data[\"respb_len\"] - data[\"prompt_len\"]  # response_bとプロンプトの長さの差\n",
    "        \n",
    "        # response_aとプロンプト間のユニグラム、バイグラム、トライグラムのオーバーラップ比を計算します\n",
    "        data[\"respa_prompt_overlap_unigram_ratio\"] = data[\"respa_prompt_overlap_unigram\"] / data[\"prompt_len\"]  # ユニグラムのオーバーラップ比\n",
    "        data[\"respa_prompt_overlap_bigram_ratio\"] = data[\"respa_prompt_overlap_bigram\"] / data[\"prompt_len\"]  # バイグラムのオーバーラップ比\n",
    "        data[\"respa_prompt_overlap_trigram_ratio\"] = data[\"respa_prompt_overlap_trigram\"] / data[\"prompt_len\"]  # トライグラムのオーバーラップ比\n",
    "\n",
    "        # response_bとプロンプト間のユニグラム、バイグラム、トライグラムのオーバーラップ比を計算します\n",
    "        data[\"respb_prompt_overlap_unigram_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"prompt_len\"]  # ユニグラムのオーバーラップ比\n",
    "        data[\"respb_prompt_overlap_bigram_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"prompt_len\"]  # バイグラムのオーバーラップ比\n",
    "        data[\"respb_prompt_overlap_trigram_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"prompt_len\"]  # トライグラムのオーバーラップ比\n",
    "        \n",
    "        # response_a、response_b、プロンプト内の引用の数をカウントします\n",
    "        data[\"respa_quotes\"] = data[\"response_a\"].apply(lambda x: self.count_quotes(x))  # response_aの引用数\n",
    "        data[\"respb_quotes\"] = data[\"response_b\"].apply(lambda x: self.count_quotes(x))  # response_bの引用数\n",
    "        data[\"prompt_quotes\"] = data[\"prompt\"].apply(lambda x: self.count_quotes(x))  # プロンプトの引用数\n",
    "\n",
    "        # response_a、response_b、プロンプト内の改行の数をカウントします\n",
    "        data[\"respa_new_lines\"] = data[\"response_a\"].apply(lambda x: self.count_new_lines(x))  # response_aの改行数\n",
    "        data[\"respb_new_lines\"] = data[\"response_b\"].apply(lambda x: self.count_new_lines(x))  # response_bの改行数\n",
    "        data[\"prompt_new_lines\"] = data[\"prompt\"].apply(lambda x: self.count_new_lines(x))  # プロンプトの改行数\n",
    "\n",
    "        # response_a、response_b、プロンプト内の箇条書きリストの数をカウントします\n",
    "        data[\"respa_bullets\"] = data[\"response_a\"].apply(lambda x: self.count_bulleted_lists(x))  # response_aの箇条書き数\n",
    "        data[\"respb_bullets\"] = data[\"response_b\"].apply(lambda x: self.count_bulleted_lists(x))  # response_bの箇条書き数\n",
    "        data[\"prompt_bullets\"] = data[\"prompt\"].apply(lambda x: self.count_bulleted_lists(x))  # プロンプトの箇条書き数\n",
    "        \n",
    "        # response_aとresponse_b間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respa_respb_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respa_respb_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        # response_aとプロンプト間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respa_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respa_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        # response_bとプロンプト間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respb_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respb_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        return data  # 処理されたデータフレームを返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:05:22.146047Z",
     "iopub.status.busy": "2024-07-14T21:05:22.145693Z",
     "iopub.status.idle": "2024-07-14T21:05:22.181055Z",
     "shell.execute_reply": "2024-07-14T21:05:22.180186Z",
     "shell.execute_reply.started": "2024-07-14T21:05:22.146017Z"
    }
   },
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "\n",
    "    # 2つのテキスト間のコサイン類似度を計算します\n",
    "    def cosine_sim(self, text1: str, text2: str):\n",
    "        try:\n",
    "            vectorizer = TfidfVectorizer(ngram_range=(1, 3))  # n-gramを1から3まで考慮したTF-IDFベクトライザを作成します\n",
    "            vectorizer.fit([text1, text2])  # 2つのテキストにベクトライザをフィットさせます\n",
    "            output = vectorizer.transform([text1, text2]).toarray()  # テキストをTF-IDFベクトルに変換します\n",
    "            cos_sim = cosine_similarity(output)  # ベクトル間のコサイン類似度を計算します\n",
    "            return cos_sim[0][1]  # text1とtext2の類似度スコアを返します\n",
    "        except:\n",
    "            print(f\"cosine_sim exception with '{text1}' and '{text2}'\")\n",
    "            return np.nan  # 例外が発生した場合はNaNを返します\n",
    "\n",
    "    # 2つのテキスト間のジャッカード類似度を計算します\n",
    "    def jaccard_sim(self, text1: str, text2: str):\n",
    "        set1 = set(text1.split())  # text1を単語の集合に分割します\n",
    "        set2 = set(text2.split())  # text2を単語の集合に分割します\n",
    "        intersection = set1.intersection(set2)  # 2つの集合の共通部分を見つけます\n",
    "        union = set1.union(set2)  # 2つの集合の和を見つけます\n",
    "        return len(intersection) / len(union)  # ジャッカード類似度スコアを返します\n",
    "    \n",
    "    # テキスト内の引用されたセグメントの数をカウントします\n",
    "    def count_quotes(self, text: str) -> int:\n",
    "        single_quote_pattern = r\"'(.*?)'\"  # 単一引用符のパターン\n",
    "        double_quote_pattern = r'\"(.*?)\"'  # 二重引用符のパターン\n",
    "        single_quotes = re.findall(single_quote_pattern, text)  # 単一引用符で囲まれた部分をすべて見つけます\n",
    "        double_quotes = re.findall(double_quote_pattern, text)  # 二重引用符で囲まれた部分をすべて見つけます\n",
    "        total_quotes = len(single_quotes) + len(double_quotes)  # 両方のカウントを合計します\n",
    "        return total_quotes  # 引用されたセグメントの合計数を返します\n",
    "    \n",
    "    # テキスト内の改行の数をカウントします\n",
    "    def count_new_lines(self, text: str) -> int:\n",
    "        return text.count('\\\\n')  # テキスト内の改行文字の数を返します\n",
    "    \n",
    "    # テキスト内の箇条書きリストの数をカウントします\n",
    "    def count_bulleted_lists(self, text: str) -> int:\n",
    "        bullet_pattern = r'(\\\\n|^)[\\*\\-\\+]\\s'  # 箇条書き項目のパターン\n",
    "        return len(re.findall(bullet_pattern, text))  # 箇条書き項目の数を返します\n",
    "    \n",
    "    # テキストを小文字の単語にトークン化します\n",
    "    def tokenize(self, text: str):\n",
    "        return nltk.word_tokenize(text.lower())  # テキストをトークン化し、小文字に変換します\n",
    "\n",
    "    # トークン化されたテキストからn-gramを生成します\n",
    "    def generate_ngrams(self, text: str, n: int):\n",
    "        tokens = self.tokenize(text)  # テキストをトークン化します\n",
    "        return list(ngrams(tokens, n))  # トークンからn-gramを生成して返します\n",
    "\n",
    "    # 2つのテキスト間のオーバーラップn-gramの数をカウントします\n",
    "    def count_ngram_overlaps(self, text1: str, text2: str, n: int) -> int:\n",
    "        try:\n",
    "            ngrams1 = self.generate_ngrams(text1, n)  # text1のn-gramを生成します\n",
    "            ngrams2 = self.generate_ngrams(text2, n)  # text2のn-gramを生成します\n",
    "            counter1 = Counter(ngrams1)  # text1のn-gramをカウントします\n",
    "            counter2 = Counter(ngrams2)  # text2のn-gramをカウントします\n",
    "            overlap = counter1 & counter2  # 2つのカウンタのオーバーラップを見つけます\n",
    "            overlap_count = sum(overlap.values())  # オーバーラップしたn-gramのカウントを合計します\n",
    "            return overlap_count  # オーバーラップの数を返します\n",
    "        except:\n",
    "            return 0  # 例外が発生した場合は0を返します\n",
    "        \n",
    "    # データに対する前処理を実行します\n",
    "    def run(self, data: pd.DataFrame) -> pd.DataFrame:\n",
    "        \n",
    "        # response_aとresponse_b間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respa_respb_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 1), axis=1)\n",
    "        data[\"respa_respb_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 2), axis=1)\n",
    "        data[\"respa_respb_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"response_b\"], 3), axis=1)\n",
    "\n",
    "        # response_aとプロンプト間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respa_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respa_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respa_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_a\"], x[\"prompt\"], 3), axis=1)\n",
    "\n",
    "        # response_bとプロンプト間のユニグラム、バイグラム、およびトライグラムのオーバーラップを計算します\n",
    "        data[\"respb_prompt_overlap_unigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 1), axis=1)\n",
    "        data[\"respb_prompt_overlap_bigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 2), axis=1)\n",
    "        data[\"respb_prompt_overlap_trigram\"] = data.apply(lambda x: self.count_ngram_overlaps(x[\"response_b\"], x[\"prompt\"], 3), axis=1)\n",
    "        \n",
    "        # トークン化されたテキストの長さを計算します\n",
    "        data[\"respa_len\"] = data[\"response_a\"].apply(lambda x: len(self.tokenize(x)))  # response_aのトークン数を計算します\n",
    "        data[\"respb_len\"] = data[\"response_b\"].apply(lambda x: len(self.tokenize(x)))  # response_bのトークン数を計算します\n",
    "        data[\"prompt_len\"] = data[\"prompt\"].apply(lambda x: len(self.tokenize(x)))  # プロンプトのトークン数を計算します\n",
    "        \n",
    "        # response_a、response_b、プロンプト間の長さ比を計算します\n",
    "        data[\"respa_prompt_len_ratio\"] = data[\"respa_len\"] / data[\"prompt_len\"]  # response_aとプロンプトの長さ比\n",
    "        data[\"respb_prompt_len_ratio\"] = data[\"respb_len\"] / data[\"prompt_len\"]  # response_bとプロンプトの長さ比\n",
    "        data[\"respa_respb_len_ratio\"] = data[\"respa_len\"] / data[\"respb_len\"]  # response_aとresponse_bの長さ比\n",
    "        \n",
    "        # response_a、response_b、プロンプト間の長さの差を計算します\n",
    "        data[\"respa_respb_len_diff\"] = data[\"respa_len\"] - data[\"respb_len\"]  # response_aとresponse_bの長さの差\n",
    "        data[\"respa_prompt_len_diff\"] = data[\"respa_len\"] - data[\"prompt_len\"]  # response_aとプロンプトの長さの差\n",
    "        data[\"respb_prompt_len_diff\"] = data[\"respb_len\"] - data[\"prompt_len\"]  # response_bとプロンプトの長さの差\n",
    "        \n",
    "        # response_aとプロンプト間のユニグラム、バイグラム、トライグラムのオーバーラップ比を計算します\n",
    "        data[\"respa_prompt_overlap_unigram_ratio\"] = data[\"respa_prompt_overlap_unigram\"] / data[\"prompt_len\"]  # ユニグラムのオーバーラップ比\n",
    "        data[\"respa_prompt_overlap_bigram_ratio\"] = data[\"respa_prompt_overlap_bigram\"] / data[\"prompt_len\"]  # バイグラムのオーバーラップ比\n",
    "        data[\"respa_prompt_overlap_trigram_ratio\"] = data[\"respa_prompt_overlap_trigram\"] / data[\"prompt_len\"]  # トライグラムのオーバーラップ比\n",
    "\n",
    "        # response_bとプロンプト間のユニグラム、バイグラム、トライグラムのオーバーラップ比を計算します\n",
    "        data[\"respb_prompt_overlap_unigram_ratio\"] = data[\"respb_prompt_overlap_unigram\"] / data[\"prompt_len\"]  # ユニグラムのオーバーラップ比\n",
    "        data[\"respb_prompt_overlap_bigram_ratio\"] = data[\"respb_prompt_overlap_bigram\"] / data[\"prompt_len\"]  # バイグラムのオーバーラップ比\n",
    "        data[\"respb_prompt_overlap_trigram_ratio\"] = data[\"respb_prompt_overlap_trigram\"] / data[\"prompt_len\"]  # トライグラムのオーバーラップ比\n",
    "        \n",
    "        # response_a、response_b、プロンプト内の引用の数をカウントします\n",
    "        data[\"respa_quotes\"] = data[\"response_a\"].apply(lambda x: self.count_quotes(x))  # response_aの引用数\n",
    "        data[\"respb_quotes\"] = data[\"response_b\"].apply(lambda x: self.count_quotes(x))  # response_bの引用数\n",
    "        data[\"prompt_quotes\"] = data[\"prompt\"].apply(lambda x: self.count_quotes(x))  # プロンプトの引用数\n",
    "\n",
    "        # response_a、response_b、プロンプト内の改行の数をカウントします\n",
    "        data[\"respa_new_lines\"] = data[\"response_a\"].apply(lambda x: self.count_new_lines(x))  # response_aの改行数\n",
    "        data[\"respb_new_lines\"] = data[\"response_b\"].apply(lambda x: self.count_new_lines(x))  # response_bの改行数\n",
    "        data[\"prompt_new_lines\"] = data[\"prompt\"].apply(lambda x: self.count_new_lines(x))  # プロンプトの改行数\n",
    "\n",
    "        # response_a、response_b、プロンプト内の箇条書きリストの数をカウントします\n",
    "        data[\"respa_bullets\"] = data[\"response_a\"].apply(lambda x: self.count_bulleted_lists(x))  # response_aの箇条書き数\n",
    "        data[\"respb_bullets\"] = data[\"response_b\"].apply(lambda x: self.count_bulleted_lists(x))  # response_bの箇条書き数\n",
    "        data[\"prompt_bullets\"] = data[\"prompt\"].apply(lambda x: self.count_bulleted_lists(x))  # プロンプトの箇条書き数\n",
    "        \n",
    "        # response_aとresponse_b間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respa_respb_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respa_respb_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"response_b\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        # response_aとプロンプト間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respa_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respa_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_a\"], x[\"prompt\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        # response_bとプロンプト間のコサインとジャッカードの類似度を計算します\n",
    "        data[\"respb_prompt_cosine_sim\"] = data.apply(lambda x: self.cosine_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)  # コサイン類似度\n",
    "        data[\"respb_prompt_jaccard_sim\"] = data.apply(lambda x: self.jaccard_sim(x[\"response_b\"], x[\"prompt\"]), axis=1)  # ジャッカード類似度\n",
    "        \n",
    "        return data  # 処理されたデータフレームを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a710ffd2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "preprocessor = Preprocessor()\n",
    "train = preprocessor.run(train)\n",
    "test = preprocessor.run(test)\n",
    "train.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%%time  # 処理にかかる時間を計測します\n",
    "\n",
    "preprocessor = Preprocessor()  # Preprocessorクラスのインスタンスを作成します\n",
    "train = preprocessor.run(train)  # トレーニングデータに対して前処理を実行します\n",
    "test = preprocessor.run(test)  # テストデータに対して前処理を実行します\n",
    "train.head()  # トレーニングデータの先頭行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:05:41.99047Z",
     "iopub.status.busy": "2024-07-14T21:05:41.98966Z",
     "iopub.status.idle": "2024-07-14T21:16:22.019971Z",
     "shell.execute_reply": "2024-07-14T21:16:22.019142Z",
     "shell.execute_reply.started": "2024-07-14T21:05:41.99042Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time  # 処理にかかる時間を計測します\n",
    "\n",
    "preprocessor = Preprocessor()  # Preprocessorクラスのインスタンスを作成します\n",
    "train = preprocessor.run(train)  # トレーニングデータに対して前処理を実行します\n",
    "test = preprocessor.run(test)  # テストデータに対して前処理を実行します\n",
    "train.head()  # トレーニングデータの先頭行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523bc96b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# List of columns to drop from the dataset\n",
    "drop_cols = [\"id\", \"response_a\", \"response_b\", \"prompt\"]\n",
    "\n",
    "# List of target columns indicating the winner\n",
    "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "\n",
    "# Name of the final target column\n",
    "target = \"target\"\n",
    "\n",
    "# Initialize the target column with NaN values\n",
    "train[target] = np.nan\n",
    "\n",
    "# Iterate over the target columns and set the corresponding index in the target column\n",
    "for idx, t in enumerate(target_cols):\n",
    "    train.loc[train[t] == 1, target] = idx  # Set target column to the index where target column value is 1\n",
    "\n",
    "# Convert the target column to integer type\n",
    "train[target] = train[target].astype(\"int32\")\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "train.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットから削除する列のリスト\n",
    "drop_cols = [\"id\", \"response_a\", \"response_b\", \"prompt\"]  # 不要な列を指定します\n",
    "\n",
    "# 勝者を示すターゲット列のリスト\n",
    "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]  # 勝者に関する列を指定します\n",
    "\n",
    "# 最終的なターゲット列の名前\n",
    "target = \"target\"  # ターゲット列の名前を設定します\n",
    "\n",
    "# ターゲット列をNaNで初期化します\n",
    "train[target] = np.nan  # ターゲット列を初期化します\n",
    "\n",
    "# ターゲット列をループして、対応するインデックスをターゲット列に設定します\n",
    "for idx, t in enumerate(target_cols):\n",
    "    train.loc[train[t] == 1, target] = idx  # ターゲット列の値が1のインデックスを設定します\n",
    "\n",
    "# ターゲット列を整数型に変換します\n",
    "train[target] = train[target].astype(\"int32\")  # ターゲット列をint32型に変換します\n",
    "\n",
    "# 更新されたデータフレームの最初の数行を表示します\n",
    "train.head()  # データフレームの先頭行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:16:53.578669Z",
     "iopub.status.busy": "2024-07-14T21:16:53.57794Z",
     "iopub.status.idle": "2024-07-14T21:16:53.609194Z",
     "shell.execute_reply": "2024-07-14T21:16:53.608166Z",
     "shell.execute_reply.started": "2024-07-14T21:16:53.578632Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットから削除する列のリスト\n",
    "drop_cols = [\"id\", \"response_a\", \"response_b\", \"prompt\"]  # 不要な列を指定します\n",
    "\n",
    "# 勝者を示すターゲット列のリスト\n",
    "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]  # 勝者に関する列を指定します\n",
    "\n",
    "# 最終的なターゲット列の名前\n",
    "target = \"target\"  # ターゲット列の名前を設定します\n",
    "\n",
    "# ターゲット列をNaNで初期化します\n",
    "train[target] = np.nan  # ターゲット列を初期化します\n",
    "\n",
    "# ターゲット列をループして、対応するインデックスをターゲット列に設定します\n",
    "for idx, t in enumerate(target_cols):\n",
    "    train.loc[train[t] == 1, target] = idx  # ターゲット列の値が1のインデックスを設定します\n",
    "\n",
    "# ターゲット列を整数型に変換します\n",
    "train[target] = train[target].astype(\"int32\")  # ターゲット列をint32型に変換します\n",
    "\n",
    "# 更新されたデータフレームの最初の数行を表示します\n",
    "train.head()  # データフレームの先頭行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6009aa6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# 5. Modeling\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 5. モデリング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8d4f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Drop specified columns from the training dataset and assign the result to X\n",
    "X = train.drop(columns=target_cols + drop_cols + [target] + [\"model_a\", \"model_b\"], axis=1)\n",
    "\n",
    "# Assign the target column to y\n",
    "y = train[target]\n",
    "\n",
    "# Drop specified columns from the test dataset and assign the result to X_test\n",
    "X_test = test.drop(columns=drop_cols, axis=1)\n",
    "\n",
    "# Replace infinite values (-inf and inf) with NaN in the training feature set\n",
    "X = X.replace([-np.inf, np.inf], np.nan)\n",
    "\n",
    "# Replace infinite values (-inf and inf) with NaN in the test feature set\n",
    "X_test = X_test.replace([-np.inf, np.inf], np.nan)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータセットから指定した列を削除し、結果をXに割り当てます\n",
    "X = train.drop(columns=target_cols + drop_cols + [target] + [\"model_a\", \"model_b\"], axis=1)  # 不要な列を削除します\n",
    "\n",
    "# ターゲット列をyに割り当てます\n",
    "y = train[target]  # ターゲット列をyに設定します\n",
    "\n",
    "# テストデータセットから指定した列を削除し、結果をX_testに割り当てます\n",
    "X_test = test.drop(columns=drop_cols, axis=1)  # 不要な列を削除してテストデータを準備します\n",
    "\n",
    "# トレーニング特徴セットの無限大の値（-infとinf）をNaNに置き換えます\n",
    "X = X.replace([-np.inf, np.inf], np.nan)  # 無限大の値をNaNに置き換えます\n",
    "\n",
    "# テスト特徴セットの無限大の値（-infとinf）をNaNに置き換えます\n",
    "X_test = X_test.replace([-np.inf, np.inf], np.nan)  # 無限大の値をNaNに置き換えます\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:17:33.095261Z",
     "iopub.status.busy": "2024-07-14T21:17:33.094902Z",
     "iopub.status.idle": "2024-07-14T21:17:33.117348Z",
     "shell.execute_reply": "2024-07-14T21:17:33.116641Z",
     "shell.execute_reply.started": "2024-07-14T21:17:33.095232Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータセットから指定した列を削除し、結果をXに割り当てます\n",
    "X = train.drop(columns=target_cols + drop_cols + [target] + [\"model_a\", \"model_b\"], axis=1)  # 不要な列を削除します\n",
    "\n",
    "# ターゲット列をyに割り当てます\n",
    "y = train[target]  # ターゲット列をyに設定します\n",
    "\n",
    "# テストデータセットから指定した列を削除し、結果をX_testに割り当てます\n",
    "X_test = test.drop(columns=drop_cols, axis=1)  # 不要な列を削除してテストデータを準備します\n",
    "\n",
    "# トレーニング特徴セットの無限大の値（-infとinf）をNaNに置き換えます\n",
    "X = X.replace([-np.inf, np.inf], np.nan)  # 無限大の値をNaNに置き換えます\n",
    "\n",
    "# テスト特徴セットの無限大の値（-infとinf）をNaNに置き換えます\n",
    "X_test = X_test.replace([-np.inf, np.inf], np.nan)  # 無限大の値をNaNに置き換えます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02a282",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Set up stratified cross-validation with the specified number of splits, shuffle, and seed\n",
    "cv = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)\n",
    "\n",
    "# Initialize an array to store the average predictions for the test set\n",
    "test_preds = np.zeros(shape=(X_test.shape[0], y.nunique()))\n",
    "\n",
    "# Initialize a list to store cross-validation scores (log loss) for each fold\n",
    "cv_scores = list()\n",
    "\n",
    "# Get the list of feature names\n",
    "features = X.columns.tolist()\n",
    "\n",
    "# Prepare a DataFrame to store feature importances for each fold\n",
    "feat_imp_df = pd.DataFrame({\"feature\": features})\n",
    "\n",
    "# Loop over each fold in the cross-validation\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"| Fold {idx+1} |\".center(90, \"=\"))  # Print the fold number\n",
    "\n",
    "    # Split the data into training and validation sets for the current fold\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]\n",
    "    X_val, y_val = X.loc[val_idx], y.loc[val_idx]\n",
    "\n",
    "    # Print the shapes of the training and validation sets\n",
    "    print(f'train: {X_train.shape}')\n",
    "    print(f'val: {X_val.shape}')\n",
    "    \n",
    "    # Initialize the XGBoost classifier with specified hyperparameters\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        num_class=3,\n",
    "        eval_metric='mlogloss',\n",
    "        subsample=0.8,\n",
    "        n_estimators=650,\n",
    "        learning_rate=0.045,\n",
    "        max_depth=5,\n",
    "        random_state=config.seed,\n",
    "        device=\"gpu\"\n",
    "    )\n",
    "    \n",
    "    # Train the model with early stopping on the validation set\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        early_stopping_rounds=75,\n",
    "        verbose=75\n",
    "    )\n",
    "    \n",
    "    # Predict probabilities on the validation set\n",
    "    val_preds = model.predict_proba(X_val)\n",
    "\n",
    "    # Calculate the log loss for the validation set\n",
    "    val_log_loss = log_loss(y_val, val_preds, eps=\"auto\")\n",
    "    print(f\"val log loss: {val_log_loss:.5f}\")\n",
    "\n",
    "    # Append the log loss to the list of cross-validation scores\n",
    "    cv_scores.append(val_log_loss)\n",
    "    \n",
    "    # Update test predictions with the current fold's predictions, averaged over all folds\n",
    "    test_preds += model.predict_proba(X_test) / cv.get_n_splits()\n",
    "    \n",
    "    # Merge the current fold's feature importances into the DataFrame\n",
    "    feat_imp_df = feat_imp_df.merge(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": features,\n",
    "                f\"fold_{idx+1}_feat_imp\": model.feature_importances_,\n",
    "            }\n",
    "        ),\n",
    "        on=[\"feature\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "# Print a separator line and the average cross-validated log loss\n",
    "print(\"=\"*90)\n",
    "print(f\"CV: {np.mean(cv_scores):.5f}\")\n",
    "\n",
    "# Calculate the average feature importance across all folds\n",
    "feat_imp_df[\"avg_importance\"] = feat_imp_df.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "# Plot the top 50 features by average importance\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(\n",
    "    data=feat_imp_df.sort_values(by=\"avg_importance\", ascending=False).iloc[\n",
    "        :50\n",
    "    ],\n",
    "    x=\"avg_importance\",\n",
    "    y=\"feature\",\n",
    "    color=\"royalblue\",\n",
    "    width=0.75,\n",
    ")\n",
    "plt.title(\"Average Feature Importances for All Folds\", size=12)\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 指定された分割数、シャッフルオプション、シードを使って層化交差検証を設定します\n",
    "cv = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)  # 層化Kフォールドの初期化\n",
    "\n",
    "# テストセットの平均予測を格納するための配列を初期化します\n",
    "test_preds = np.zeros(shape=(X_test.shape[0], y.nunique()))  # テスト予測用の配列を生成します\n",
    "\n",
    "# 各フォールドの交差検証スコア（ログ損失）を格納するためのリストを初期化します\n",
    "cv_scores = list()  # ログ損失スコアを格納するリスト\n",
    "\n",
    "# 特徴量名のリストを取得します\n",
    "features = X.columns.tolist()  # 特徴量のリストを作成します\n",
    "\n",
    "# 各フォールドの特徴量の重要度を格納するためのデータフレームを準備します\n",
    "feat_imp_df = pd.DataFrame({\"feature\": features})  # 特徴量の重要度を格納するデータフレームを初期化します\n",
    "\n",
    "# 交差検証の各フォールドをループします\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"| Fold {idx+1} |\".center(90, \"=\"))  # フォールド番号を表示します\n",
    "\n",
    "    # 現在のフォールドのトレーニングおよびバリデーションセットにデータを分割します\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]  # トレーニングデータを分割します\n",
    "    X_val, y_val = X.loc[val_idx], y.loc[val_idx]  # バリデーションデータを分割します\n",
    "\n",
    "    # トレーニングセットとバリデーションセットの形状を表示します\n",
    "    print(f'train: {X_train.shape}')  # トレーニングデータの形状\n",
    "    print(f'val: {X_val.shape}')  # バリデーションデータの形状\n",
    "    \n",
    "    # 指定されたハイパーパラメータでXGBoost分類器を初期化します\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',  # マルチクラス確率を取得する目的\n",
    "        num_class=3,  # クラス数\n",
    "        eval_metric='mlogloss',  # 評価指標としてのマルチクラスログ損失\n",
    "        subsample=0.8,  # サブサンプリングの割合\n",
    "        n_estimators=650,  # 使用する木の数\n",
    "        learning_rate=0.045,  # 学習率\n",
    "        max_depth=5,  # 木の最大深さ\n",
    "        random_state=config.seed,  # 乱数シード\n",
    "        device=\"gpu\"  # GPUを使用するための設定\n",
    "    )\n",
    "    \n",
    "    # バリデーションセットに対して早期停止を設定してモデルを訓練します\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # トレーニングおよびバリデーションセット\n",
    "        early_stopping_rounds=75,  # 75ラウンドで早期停止\n",
    "        verbose=75  # 詳細出力の設定\n",
    "    )\n",
    "    \n",
    "    # バリデーションセットの確率を予測します\n",
    "    val_preds = model.predict_proba(X_val)  # バリデーションセットに対する予測確率\n",
    "\n",
    "    # バリデーションセットのログ損失を計算します\n",
    "    val_log_loss = log_loss(y_val, val_preds, eps=\"auto\")  # ログ損失の計算\n",
    "    print(f\"val log loss: {val_log_loss:.5f}\")  # バリデーションログ損失を表示します\n",
    "\n",
    "    # 交差検証スコアのリストにログ損失を追加します\n",
    "    cv_scores.append(val_log_loss)  # スコアを追加します\n",
    "    \n",
    "    # 現在のフォールドの予測でテスト予測を更新します（すべてのフォールドの平均）\n",
    "    test_preds += model.predict_proba(X_test) / cv.get_n_splits()  # テスト予測を更新します\n",
    "    \n",
    "    # 現在のフォールドの特徴量の重要度をデータフレームに統合します\n",
    "    feat_imp_df = feat_imp_df.merge(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": features,  # 特徴量名\n",
    "                f\"fold_{idx+1}_feat_imp\": model.feature_importances_,  # 特徴量の重要度\n",
    "            }\n",
    "        ),\n",
    "        on=[\"feature\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "# セパレータ行を印刷し、交差検証されたログ損失の平均を表示します\n",
    "print(\"=\"*90)\n",
    "print(f\"CV: {np.mean(cv_scores):.5f}\")  # 交差検証のスコアの平均を表示します\n",
    "\n",
    "# すべてのフォールドの平均特徴量重要度を計算します\n",
    "feat_imp_df[\"avg_importance\"] = feat_imp_df.iloc[:, 1:].mean(axis=1)  # 各特徴量の平均重要度を計算\n",
    "\n",
    "# 平均重要度が最も高い上位50の特徴量をプロットします\n",
    "plt.figure(figsize=(12, 10))  # プロットのサイズを設定します\n",
    "sns.barplot(\n",
    "    data=feat_imp_df.sort_values(by=\"avg_importance\", ascending=False).iloc[\n",
    "        :50  # 上位50の特徴量を選択します\n",
    "    ],\n",
    "    x=\"avg_importance\",  # x軸に平均重要度\n",
    "    y=\"feature\",  # y軸に特徴量\n",
    "    color=\"royalblue\",  # バーの色\n",
    "    width=0.75,  # バーの幅\n",
    ")\n",
    "plt.title(\"Average Feature Importances for All Folds\", size=12)  # プロットタイトル\n",
    "plt.show()  # プロットを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:18:48.99339Z",
     "iopub.status.busy": "2024-07-14T21:18:48.993015Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定された分割数、シャッフルオプション、シードを使って層化交差検証を設定します\n",
    "cv = StratifiedKFold(n_splits=config.n_splits, shuffle=True, random_state=config.seed)  # 層化Kフォールドの初期化\n",
    "\n",
    "# テストセットの平均予測を格納するための配列を初期化します\n",
    "test_preds = np.zeros(shape=(X_test.shape[0], y.nunique()))  # テスト予測用の配列を生成します\n",
    "\n",
    "# 各フォールドの交差検証スコア（ログ損失）を格納するためのリストを初期化します\n",
    "cv_scores = list()  # ログ損失スコアを格納するリスト\n",
    "\n",
    "# 特徴量名のリストを取得します\n",
    "features = X.columns.tolist()  # 特徴量のリストを作成します\n",
    "\n",
    "# 各フォールドの特徴量の重要度を格納するためのデータフレームを準備します\n",
    "feat_imp_df = pd.DataFrame({\"feature\": features})  # 特徴量の重要度を格納するデータフレームを初期化します\n",
    "\n",
    "# 交差検証の各フォールドをループします\n",
    "for idx, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "    print(f\"| Fold {idx+1} |\".center(90, \"=\"))  # フォールド番号を表示します\n",
    "\n",
    "    # 現在のフォールドのトレーニングおよびバリデーションセットにデータを分割します\n",
    "    X_train, y_train = X.loc[train_idx], y.loc[train_idx]  # トレーニングデータを分割します\n",
    "    X_val, y_val = X.loc[val_idx], y.loc[val_idx]  # バリデーションデータを分割します\n",
    "\n",
    "    # トレーニングセットとバリデーションセットの形状を表示します\n",
    "    print(f'train: {X_train.shape}')  # トレーニングデータの形状\n",
    "    print(f'val: {X_val.shape}')  # バリデーションデータの形状\n",
    "    \n",
    "    # 指定されたハイパーパラメータでXGBoost分類器を初期化します\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='multi:softprob',  # マルチクラス確率を取得する目的\n",
    "        num_class=3,  # クラス数\n",
    "        eval_metric='mlogloss',  # 評価指標としてのマルチクラスログ損失\n",
    "        subsample=0.8,  # サブサンプリングの割合\n",
    "        n_estimators=650,  # 使用する木の数\n",
    "        learning_rate=0.045,  # 学習率\n",
    "        max_depth=5,  # 木の最大深さ\n",
    "        random_state=config.seed,  # 乱数シード\n",
    "        device=\"gpu\"  # GPUを使用するための設定\n",
    "    )\n",
    "    \n",
    "    # バリデーションセットに対して早期停止を設定してモデルを訓練します\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],  # トレーニングおよびバリデーションセット\n",
    "        early_stopping_rounds=75,  # 75ラウンドで早期停止\n",
    "        verbose=75  # 詳細出力の設定\n",
    "    )\n",
    "    \n",
    "    # バリデーションセットの確率を予測します\n",
    "    val_preds = model.predict_proba(X_val)  # バリデーションセットに対する予測確率\n",
    "\n",
    "    # バリデーションセットのログ損失を計算します\n",
    "    val_log_loss = log_loss(y_val, val_preds, eps=\"auto\")  # ログ損失の計算\n",
    "    print(f\"val log loss: {val_log_loss:.5f}\")  # バリデーションログ損失を表示します\n",
    "\n",
    "    # 交差検証スコアのリストにログ損失を追加します\n",
    "    cv_scores.append(val_log_loss)  # スコアを追加します\n",
    "    \n",
    "    # 現在のフォールドの予測でテスト予測を更新します（すべてのフォールドの平均）\n",
    "    test_preds += model.predict_proba(X_test) / cv.get_n_splits()  # テスト予測を更新します\n",
    "    \n",
    "    # 現在のフォールドの特徴量の重要度をデータフレームに統合します\n",
    "    feat_imp_df = feat_imp_df.merge(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"feature\": features,  # 特徴量名\n",
    "                f\"fold_{idx+1}_feat_imp\": model.feature_importances_,  # 特徴量の重要度\n",
    "            }\n",
    "        ),\n",
    "        on=[\"feature\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "# セパレータ行を印刷し、交差検証されたログ損失の平均を表示します\n",
    "print(\"=\"*90)\n",
    "print(f\"CV: {np.mean(cv_scores):.5f}\")  # 交差検証のスコアの平均を表示します\n",
    "\n",
    "# すべてのフォールドの平均特徴量重要度を計算します\n",
    "feat_imp_df[\"avg_importance\"] = feat_imp_df.iloc[:, 1:].mean(axis=1)  # 各特徴量の平均重要度を計算\n",
    "\n",
    "# 平均重要度が最も高い上位50の特徴量をプロットします\n",
    "plt.figure(figsize=(12, 10))  # プロットのサイズを設定します\n",
    "sns.barplot(\n",
    "    data=feat_imp_df.sort_values(by=\"avg_importance\", ascending=False).iloc[\n",
    "        :50  # 上位50の特徴量を選択します\n",
    "    ],\n",
    "    x=\"avg_importance\",  # x軸に平均重要度\n",
    "    y=\"feature\",  # y軸に特徴量\n",
    "    color=\"royalblue\",  # バーの色\n",
    "    width=0.75,  # バーの幅\n",
    ")\n",
    "plt.title(\"Average Feature Importances for All Folds\", size=12)  # プロットタイトル\n",
    "plt.show()  # プロットを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ede51",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# 6. Saving Submission\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 6. 提出ファイルの保存\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1836382c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "for idx, t in enumerate(target_cols):\n",
    "    sample_submission[t] = test_preds[:, idx]\n",
    "sample_submission.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "for idx, t in enumerate(target_cols):\n",
    "    sample_submission[t] = test_preds[:, idx]  # テスト予測をサンプル提出ファイルに割り当てます\n",
    "sample_submission.head()  # サンプル提出ファイルの先頭行を表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:19:29.815185Z",
     "iopub.status.busy": "2024-07-14T21:19:29.814539Z",
     "iopub.status.idle": "2024-07-14T21:19:29.825732Z",
     "shell.execute_reply": "2024-07-14T21:19:29.824857Z",
     "shell.execute_reply.started": "2024-07-14T21:19:29.815156Z"
    }
   },
   "outputs": [],
   "source": [
    "for idx, t in enumerate(target_cols):\n",
    "    sample_submission[t] = test_preds[:, idx]  # テスト予測をサンプル提出ファイルに割り当てます\n",
    "sample_submission.head()  # サンプル提出ファイルの先頭行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7546de64",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "sample_submission.to_csv(\"submission.csv\", index=False)  # サンプル提出ファイルをCSV形式で保存します（インデックスなし）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-14T21:19:35.805085Z",
     "iopub.status.busy": "2024-07-14T21:19:35.804732Z",
     "iopub.status.idle": "2024-07-14T21:19:35.811097Z",
     "shell.execute_reply": "2024-07-14T21:19:35.810075Z",
     "shell.execute_reply.started": "2024-07-14T21:19:35.805058Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False)  # サンプル提出ファイルをCSV形式で保存します（インデックスなし）"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
