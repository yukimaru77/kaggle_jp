{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93216ff9",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、Kaggleコンペティション「LMSYS - Chatbot Arena」における人間による好みの予測を行うためのモデルを構築することを目的としています。具体的には、ユーザーが生成したプロンプトに対する2つの異なる応答から、どちらがより好まれるかを予測します。\n",
    "\n",
    "ノートブックでは、以下の手法とライブラリが活用されています。\n",
    "\n",
    "1. **ライブラリのインストールおよびインポート**：\n",
    "   - `bitsandbytes`、`transformers`、`tokenizers`、`peft`など、モデルのトレーニングや推論を効率化するためのライブラリを使用しています。\n",
    "   - PyTorch（`torch`）、scikit-learn（`sklearn`）、pandas（`pd`）、numpy（`np`）などの一般的なデータ処理および機械学習ライブラリもインポートされています。\n",
    "\n",
    "2. **データ処理**：\n",
    "   - テストデータを読み込み、プロンプトやレスポンスの前処理を行います。具体的には、null値の処理やトークン化を行い、モデルの入力として使用するフォーマットに整えています。\n",
    "\n",
    "3. **トークナイゼーションとモデルの設定**：\n",
    "   - Hugging FaceのTransformersを利用して、`Gemma2ForSequenceClassification`モデルを使用し、トークナイザーを設定しています。これにより、テキストデータをモデルが理解できる形式に変換します。\n",
    "\n",
    "4. **推論の実施**：\n",
    "   - 2つの異なるGPUを用いて並行処理を行い、それぞれのモデルからの出力や確率を計算します。これにより、各モデルがどの程度の確率でユーザーの好みを予測するかを評価します。\n",
    "\n",
    "5. **特徴量エンジニアリングとLightGBMの統合**：\n",
    "   - `CountVectorizer`を利用して特徴量を抽出し、LightGBMを使った予測も組み合わせています。これにより、異なるアルゴリズムを統合した予測を可能にしています。\n",
    "\n",
    "6. **結果のブレンド**：\n",
    "   - LightGBMによる予測とLLMの予測を重み付けしてブレンドし、最終的な出力を生成します。この出力は、ユーザーの好みと応答の優劣を示す確率として出されます。\n",
    "\n",
    "最終的に、生成された予測結果はCSVファイルに保存され、Kaggleに提出するための形式に整えられます。このノートブックは、複数の技術やモデルを駆使しながら、ユーザーの好みをより正確に推測するための包括的なアプローチを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d0aec2",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの中で初心者がつまずきそうな専門用語の簡単な解説です。特にマイナーな用語や実務経験がなければ馴染みが薄いと思われるものに焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **bitsandbytes**:\n",
    "   - メモリ効率の良いオペレーションを提供するライブラリ。特に大規模なモデルを扱う際のメモリ管理や演算を最適化するために使用される。\n",
    "\n",
    "2. **tokenizers**:\n",
    "   - 自然言語処理でテキストをトークン化（語や文を分割）するためのライブラリ。トークン化は、機械学習モデルが理解できる形式にテキストを変換するために重要。\n",
    "\n",
    "3. **PEFT (Parameter-Efficient Fine-Tuning)**:\n",
    "   - モデルの微調整手法の一つ。より少ないパラメータを更新して、性能を最大化することを目指す手法で、特にメモリ使用効率を高めるために利用される。\n",
    "\n",
    "4. **LoraConfig**:\n",
    "   - LoRA（Low-Rank Adaptation）に関する設定。深層学習モデルをより効率的に訓練するためのテクニックで、モデルの一部のパラメータを低ランクの形式で調整する手法。\n",
    "\n",
    "5. **mixed precision (自動混合精度)**:\n",
    "   - 計算の精度を動的に調整する手法。通常、モデルの訓練を効率化し、GPUのメモリ使用量を削減するために使用されます。\n",
    "\n",
    "6. **attention mask**:\n",
    "   - トークン化された入力に対して、どのトークンが意味を持ち（注意を払われるべき）どのトークンが無視できるかを示すマスク。トランスフォーマーモデルで入力の効果的な処理を助ける。\n",
    "\n",
    "7. **pad_without_fast_tokenizer_warning**:\n",
    "   - 自動的に入力をパディング（同じ長さにすること）する関数であり、トークンの数が異なる入力を処理する際に使われます。この関数は、パディングに関する警告を避けるために設計されています。\n",
    "\n",
    "8. **symlog (シンメトリックログ変換)**:\n",
    "   - 数値の符号に応じて異なる変換を施す方法。正の値は通常のログ変換、負の値にはマイナスの符号を付けることで、データ分布を整えるために用います。\n",
    "\n",
    "9. **dense (疎行列をDense行列に変換)**:\n",
    "   - 疎行列（多くのゼロ要素を持つ行列）を密行列（ゼロ以外の要素が多数ある行列）に変換すること。計算の効率性向上に寄与します。\n",
    "\n",
    "10. **StratifiedKFold**:\n",
    "    - 層化K-Foldクロスバリデーションを行うためのクラス。データを異なるカテゴリーに均等に分割して、よりバランスの取れた訓練と検証を行う方法。\n",
    "\n",
    "これらの用語は、実務に慣れていないと留意しないかもしれないものですが、特に深層学習や自然言語処理の分野においては非常に重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d45c42c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# bitsandbytesをインストールします。これは、メモリ効率の良いモデルやオペレーションを提供するライブラリです。\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "# transformersライブラリをインストールします。これは、さまざまな事前学習済みモデルを使用するためのライブラリです。\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "# tokenizersライブラリをインストールします。これは、トークン化処理を効率的に行うためのライブラリです。\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "# peftライブラリをインストールします。これは、学習のためのフレームワークであり、通常はメモリの使用効率を改善するために使用されます。\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-14T20:08:01.740841Z"
    }
   },
   "outputs": [],
   "source": [
    "# bitsandbytesをインストールします。これは、メモリ効率の良いモデルやオペレーションを提供するライブラリです。\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "# transformersライブラリをインストールします。これは、さまざまな事前学習済みモデルを使用するためのライブラリです。\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "# tokenizersライブラリをインストールします。これは、トークン化処理を効率的に行うためのライブラリです。\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "# peftライブラリをインストールします。これは、学習のためのフレームワークであり、通常はメモリの使用効率を改善するために使用されます。\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9302715f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install transformers peft accelerate bitsandbytes \\\n",
    "    -U --no-index --find-links /kaggle/input/lmsys-wheel-files\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# transformers、peft、accelerate、bitsandbytesの各ライブラリをインストールします。\n",
    "# これらは、モデルを簡単に使用するための重要なライブラリです。\n",
    "# インストールは最新バージョンにアップグレードし、特定のローカルリンクから行います。\n",
    "!pip install transformers peft accelerate bitsandbytes \\\n",
    "    -U --no-index --find-links /kaggle/input/lmsys-wheel-files\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers、peft、accelerate、bitsandbytesの各ライブラリをインストールします。\n",
    "# これらは、モデルを簡単に使用するための重要なライブラリです。\n",
    "# インストールは最新バージョンにアップグレードし、特定のローカルリンクから行います。\n",
    "!pip install transformers peft accelerate bitsandbytes \\\n",
    "    -U --no-index --find-links /kaggle/input/lmsys-wheel-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927fe487",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "The work in this notebook is inspired by these notebooks:\n",
    "* https://www.kaggle.com/code/ivanvybornov/llama3-8b-lgbm-tfidf\n",
    "* https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "このノートブックの作業は、以下のノートブックに触発されています。\n",
    "* https://www.kaggle.com/code/ivanvybornov/llama3-8b-lgbm-tfidf\n",
    "* https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd0e7d7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from peft import PeftModel\n",
    "import os\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートします。\n",
    "# timeライブラリは、時間の計測を行うために使用します。\n",
    "import time\n",
    "# dataclassを使用することで、簡単にデータ構造を定義できます。\n",
    "from dataclasses import dataclass\n",
    "# ThreadPoolExecutorを使って、スレッドプールを管理し並行処理を実行します。\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# torchライブラリは、PyTorchフレームワークの主要な部分で、テンソル計算を行います。\n",
    "import torch\n",
    "# sklearnライブラリは、機械学習のためのツールセットを提供します。\n",
    "import sklearn\n",
    "# numpyは、高速な数値計算のためのライブラリです。\n",
    "import numpy as np\n",
    "# pandasは、データ操作と解析のためのライブラリです。\n",
    "import pandas as pd\n",
    "# Gemma2ForSequenceClassificationは、テキストの分類を実行するためのモデルです。\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "# データコラトを使用して、データを適切な形に整形します。\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "# PeftModelは、モデルの微調整用のライブラリです。\n",
    "from peft import PeftModel\n",
    "# osライブラリは、オペレーティングシステムとのインターフェースを提供します。\n",
    "import os\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします。\n",
    "# timeライブラリは、時間の計測を行うために使用します。\n",
    "import time\n",
    "# dataclassを使用することで、簡単にデータ構造を定義できます。\n",
    "from dataclasses import dataclass\n",
    "# ThreadPoolExecutorを使って、スレッドプールを管理し並行処理を実行します。\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# torchライブラリは、PyTorchフレームワークの主要な部分で、テンソル計算を行います。\n",
    "import torch\n",
    "# sklearnライブラリは、機械学習のためのツールセットを提供します。\n",
    "import sklearn\n",
    "# numpyは、高速な数値計算のためのライブラリです。\n",
    "import numpy as np\n",
    "# pandasは、データ操作と解析のためのライブラリです。\n",
    "import pandas as pd\n",
    "# Gemma2ForSequenceClassificationは、テキストの分類を実行するためのモデルです。\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "# データコラトを使用して、データを適切な形に整形します。\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "# PeftModelは、モデルの微調整用のライブラリです。\n",
    "from peft import PeftModel\n",
    "# osライブラリは、オペレーティングシステムとのインターフェースを提供します。\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c9ce6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from threading import Thread\n",
    "import gc\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import zipfile\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from torch.cuda.amp import autocast\n",
    "from IPython.display import display\n",
    "import torch.nn.functional as F\n",
    "import tokenizers\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# さらに必要なライブラリをインポートします。\n",
    "# Threadを使って、独立したスレッドを作成して並列処理を行います。\n",
    "from threading import Thread\n",
    "# gcライブラリでは、ガベージコレクションを手動で管理できます。\n",
    "import gc\n",
    "# osライブラリは、オペレーティングシステムとのファイルシステムにアクセスするための関数を提供します。\n",
    "import os\n",
    "# ioライブラリは、入出力操作をサポートします。\n",
    "import io\n",
    "# jsonライブラリは、JSONデータを扱うための機能を提供します。\n",
    "import json\n",
    "# randomライブラリは、ランダム数の生成を行います。\n",
    "import random\n",
    "# pickleライブラリは、Pythonオブジェクトのシリアライズ（保存）とデシリアライズ（読み込み）を行います。\n",
    "import pickle\n",
    "# zipfileライブラリは、ZIPファイルの読み書きをサポートします。\n",
    "import zipfile\n",
    "# datetimeライブラリは、日付と時刻を扱うための機能を提供します。\n",
    "import datetime\n",
    "# timeライブラリは、時間に関する操作を行います。\n",
    "import time\n",
    "\n",
    "# torchライブラリは、PyTorchフレームワークの主要な部分で、テンソル計算を行います。\n",
    "import torch\n",
    "# numpyは、高速な数値計算のためのライブラリです。\n",
    "import numpy as np\n",
    "# pandasは、データ操作と解析のためのライブラリです。\n",
    "import pandas as pd\n",
    "# AutoTokenizerは、様々なモデルのトークナイザーを自動的に読み込むことができます。\n",
    "# LlamaModelおよびLlamaForSequenceClassificationは、Llamaモデルとその分類用のフレームワークです。\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# PEFT関連のモデルと設定を管理するためのライブラリです。\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# CUDAの自動キャストを使用して、計算の精度を調整します。\n",
    "from torch.cuda.amp import autocast\n",
    "# IPython.displayを使用して、Jupyter Notebook上での表示操作を行います。\n",
    "from IPython.display import display\n",
    "# Fは、PyTorchの関数を含むモジュールで、特に損失関数や活性化関数を利用するために使います。\n",
    "import torch.nn.functional as F\n",
    "# tokenizersライブラリは、トークン化を効率的に行うためのライブラリです。\n",
    "import tokenizers\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# さらに必要なライブラリをインポートします。\n",
    "# Threadを使って、独立したスレッドを作成して並列処理を行います。\n",
    "from threading import Thread\n",
    "# gcライブラリでは、ガベージコレクションを手動で管理できます。\n",
    "import gc\n",
    "# osライブラリは、オペレーティングシステムとのファイルシステムにアクセスするための関数を提供します。\n",
    "import os\n",
    "# ioライブラリは、入出力操作をサポートします。\n",
    "import io\n",
    "# jsonライブラリは、JSONデータを扱うための機能を提供します。\n",
    "import json\n",
    "# randomライブラリは、ランダム数の生成を行います。\n",
    "import random\n",
    "# pickleライブラリは、Pythonオブジェクトのシリアライズ（保存）とデシリアライズ（読み込み）を行います。\n",
    "import pickle\n",
    "# zipfileライブラリは、ZIPファイルの読み書きをサポートします。\n",
    "import zipfile\n",
    "# datetimeライブラリは、日付と時刻を扱うための機能を提供します。\n",
    "import datetime\n",
    "# timeライブラリは、時間に関する操作を行います。\n",
    "import time\n",
    "\n",
    "# torchライブラリは、PyTorchフレームワークの主要な部分で、テンソル計算を行います。\n",
    "import torch\n",
    "# numpyは、高速な数値計算のためのライブラリです。\n",
    "import numpy as np\n",
    "# pandasは、データ操作と解析のためのライブラリです。\n",
    "import pandas as pd\n",
    "# AutoTokenizerは、様々なモデルのトークナイザーを自動的に読み込むことができます。\n",
    "# LlamaModelおよびLlamaForSequenceClassificationは、Llamaモデルとその分類用のフレームワークです。\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# PEFT関連のモデルと設定を管理するためのライブラリです。\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# CUDAの自動キャストを使用して、計算の精度を調整します。\n",
    "from torch.cuda.amp import autocast\n",
    "# IPython.displayを使用して、Jupyter Notebook上での表示操作を行います。\n",
    "from IPython.display import display\n",
    "# Fは、PyTorchの関数を含むモジュールで、特に損失関数や活性化関数を利用するために使います。\n",
    "import torch.nn.functional as F\n",
    "# tokenizersライブラリは、トークン化を効率的に行うためのライブラリです。\n",
    "import tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe40e73",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "assert torch.cuda.device_count() == 2\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 使用可能なCUDAデバイスの数が2であることを確認します。\n",
    "# これは、GPUが2つある場合に正しく動作することを保証します。\n",
    "assert torch.cuda.device_count() == 2\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用可能なCUDAデバイスの数が2であることを確認します。\n",
    "# これは、GPUが2つある場合に正しく動作することを保証します。\n",
    "assert torch.cuda.device_count() == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa676dab",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# infer\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# 推論\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34985f9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5600'\n",
    "    max_length = 2048\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "cfg = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 設定を格納するためのデータクラスを定義します。\n",
    "@dataclass\n",
    "class Config:\n",
    "    # gemma_dirは、Gemmaモデルのディレクトリのパスです。\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
    "    # lora_dirは、LoRAモデルのチェックポイントのパスです。\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5600'\n",
    "    # max_lengthは、入力シーケンスの最大長を定義します。\n",
    "    max_length = 2048\n",
    "    # batch_sizeは、一度に処理するデータのバッチサイズです。\n",
    "    batch_size = 4\n",
    "    # deviceは、モデルが使用するデバイス（GPU）を指定します。\n",
    "    device = torch.device(\"cuda\")    \n",
    "    # ttaは、テスト時のデータ拡張を有効にするオプションです。\n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    # spread_max_lengthは、各入力にmax_length//3を適用するか、それとも連結された入力にmax_lengthを適用するかを決定します。\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "# Configインスタンスを作成します。\n",
    "cfg = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定を格納するためのデータクラスを定義します。\n",
    "@dataclass\n",
    "class Config:\n",
    "    # gemma_dirは、Gemmaモデルのディレクトリのパスです。\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
    "    # lora_dirは、LoRAモデルのチェックポイントのパスです。\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5600'\n",
    "    # max_lengthは、入力シーケンスの最大長を定義します。\n",
    "    max_length = 2048\n",
    "    # batch_sizeは、一度に処理するデータのバッチサイズです。\n",
    "    batch_size = 4\n",
    "    # deviceは、モデルが使用するデバイス（GPU）を指定します。\n",
    "    device = torch.device(\"cuda\")    \n",
    "    # ttaは、テスト時のデータ拡張を有効にするオプションです。\n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    # spread_max_lengthは、各入力にmax_length//3を適用するか、それとも連結された入力にmax_lengthを適用するかを決定します。\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "# Configインスタンスを作成します。\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04c8dc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# test.csvファイルを読み込み、テストデータをDataFrameとして格納します。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test.csvファイルを読み込み、テストデータをDataFrameとして格納します。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad0db4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process_text(text: str) -> str:\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
    "\n",
    "display(test.head(5))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストを処理する関数を定義します。\n",
    "# この関数は、文字列を評価し、nullを空文字列に置き換えます。\n",
    "def process_text(text: str) -> str:\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "# テストデータフレームの'prompt'列の各テキストをprocess_text関数を使用して処理します。\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
    "# 'response_a'列の各テキストも同様に処理します。\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
    "# 'response_b'列の各テキストも同様に処理します。\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
    "\n",
    "# 処理したテストデータの最初の5行を表示します。\n",
    "display(test.head(5))\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テキストを処理する関数を定義します。\n",
    "# この関数は、文字列を評価し、nullを空文字列に置き換えます。\n",
    "def process_text(text: str) -> str:\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "# テストデータフレームの'prompt'列の各テキストをprocess_text関数を使用して処理します。\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
    "# 'response_a'列の各テキストも同様に処理します。\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
    "# 'response_b'列の各テキストも同様に処理します。\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
    "\n",
    "# 処理したテストデータの最初の5行を表示します。\n",
    "display(test.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35b78c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "    return input_ids, attention_mask\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーを使用してテキストをトークン化する関数を定義します。\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    # 各プロンプトに\"<prompt>:\"を追加します。\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    # 各レスポンスに\"\\n\\n<response_a>:\"または\"\\n\\n<response_b>:\"を追加します。\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    \n",
    "    # spread_max_lengthがTrueの場合、各入力に対して最大長を3で割った長さを適用します。\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        # 各プロンプト、レスポンスA、レスポンスBの入力IDを連結します。\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        # 入力IDに対応するアテンションマスクを生成します。\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        # プロンプト、レスポンスA、レスポンスBを連結します。\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        # トークナイザーを使用してテキストをトークン化します。\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "        \n",
    "    return input_ids, attention_mask  # トークン化された入力IDとアテンションマスクを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーを使用してテキストをトークン化する関数を定義します。\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    # 各プロンプトに\"<prompt>:\"を追加します。\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    # 各レスポンスに\"\\n\\n<response_a>:\"または\"\\n\\n<response_b>:\"を追加します。\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    \n",
    "    # spread_max_lengthがTrueの場合、各入力に対して最大長を3で割った長さを適用します。\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        # 各プロンプト、レスポンスA、レスポンスBの入力IDを連結します。\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        # 入力IDに対応するアテンションマスクを生成します。\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        # プロンプト、レスポンスA、レスポンスBを連結します。\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        # トークナイザーを使用してテキストをトークン化します。\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "        \n",
    "    return input_ids, attention_mask  # トークン化された入力IDとアテンションマスクを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619870c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このセルの実行時間を計測します。\n",
    "%%time\n",
    "\n",
    "# GemmaTokenizerFastを指定したディレクトリからロードします。\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "# トークナイザーにEOSトークンを追加する設定を行います。\n",
    "tokenizer.add_eos_token = True\n",
    "# パディングの方向を右に設定します。\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 新しいデータフレームを作成します。\n",
    "data = pd.DataFrame()\n",
    "# 元のテストデータからIDをコピーします。\n",
    "data[\"id\"] = test[\"id\"]\n",
    "# トークナイザーを使用して、入力IDとアテンションマスクを生成します。\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "# 各入力IDの長さを計算して新しい列に追加します。\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "# 拡張データのための新しいデータフレームを作成します。\n",
    "aug_data = pd.DataFrame()\n",
    "# 元のテストデータからIDをコピーします。\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# response_aとresponse_bを入れ替えたトークナイゼーションを実行します。\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "# 各入力IDの長さを計算して新しい列に追加します。\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このセルの実行時間を計測します。\n",
    "%%time\n",
    "\n",
    "# GemmaTokenizerFastを指定したディレクトリからロードします。\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "# トークナイザーにEOSトークンを追加する設定を行います。\n",
    "tokenizer.add_eos_token = True\n",
    "# パディングの方向を右に設定します。\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 新しいデータフレームを作成します。\n",
    "data = pd.DataFrame()\n",
    "# 元のテストデータからIDをコピーします。\n",
    "data[\"id\"] = test[\"id\"]\n",
    "# トークナイザーを使用して、入力IDとアテンションマスクを生成します。\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "# 各入力IDの長さを計算して新しい列に追加します。\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "# 拡張データのための新しいデータフレームを作成します。\n",
    "aug_data = pd.DataFrame()\n",
    "# 元のテストデータからIDをコピーします。\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# response_aとresponse_bを入れ替えたトークナイゼーションを実行します。\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "# 各入力IDの長さを計算して新しい列に追加します。\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96256384",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load base model on GPU 0\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_0,\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "# Load base model on GPU 1\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_1,\n",
    "    use_cache=False,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPU 0にベースモデルをロードします。\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_0,  # モデルをGPU 0にマッピングします。\n",
    "    use_cache=False,  # キャッシュを使用しない設定です。\n",
    ")\n",
    "\n",
    "# GPU 1にベースモデルをロードします。\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_1,  # モデルをGPU 1にマッピングします。\n",
    "    use_cache=False,  # キャッシュを使用しない設定です。\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 0にベースモデルをロードします。\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_0,  # モデルをGPU 0にマッピングします。\n",
    "    use_cache=False,  # キャッシュを使用しない設定です。\n",
    ")\n",
    "\n",
    "# GPU 1にベースモデルをロードします。\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_1,  # モデルをGPU 1にマッピングします。\n",
    "    use_cache=False,  # キャッシュを使用しない設定です。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7fec9b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoRAモデルをベースモデルに適用します。\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)  # GPU 0のモデルにLoRA設定を適用します。\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)  # GPU 1のモデルにLoRA設定を適用します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRAモデルをベースモデルに適用します。\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)  # GPU 0のモデルにLoRA設定を適用します。\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)  # GPU 1のモデルにLoRA設定を適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caeef6e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()\n",
    "        \n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行う関数を定義します。この関数は、指定されたデータフレームに基づいてモデルに対して推論を行います。\n",
    "@torch.no_grad()  # 勾配計算を無効にします。推論時には不要です。\n",
    "@torch.cuda.amp.autocast()  # 自動混合精度を使用して、計算を効率化します。\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []  # 各モデルの勝率を格納するリストを初期化します。\n",
    "    \n",
    "    # データフレームをバッチ処理で処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終了インデックスを決定します。\n",
    "        tmp = df.iloc[start_idx:end_idx]  # 現在のバッチを取得します。\n",
    "        input_ids = tmp[\"input_ids\"].to_list()  # 入力IDをリストに変換します。\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()  # アテンションマスクをリストに変換します。\n",
    "\n",
    "        # 入力をパディングしてテンソル形式に変換します。\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # モデルに対して推論を実行します。\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # 出力のロジットをソフトマックス関数で確率に変換します。\n",
    "        \n",
    "        # 各モデルの勝率をリストに追加します。\n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    # データフレームに勝率の結果を追加します。\n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df  # 更新されたデータフレームを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論を行う関数を定義します。この関数は、指定されたデータフレームに基づいてモデルに対して推論を行います。\n",
    "@torch.no_grad()  # 勾配計算を無効にします。推論時には不要です。\n",
    "@torch.cuda.amp.autocast()  # 自動混合精度を使用して、計算を効率化します。\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []  # 各モデルの勝率を格納するリストを初期化します。\n",
    "    \n",
    "    # データフレームをバッチ処理で処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終了インデックスを決定します。\n",
    "        tmp = df.iloc[start_idx:end_idx]  # 現在のバッチを取得します。\n",
    "        input_ids = tmp[\"input_ids\"].to_list()  # 入力IDをリストに変換します。\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()  # アテンションマスクをリストに変換します。\n",
    "\n",
    "        # 入力をパディングしてテンソル形式に変換します。\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        # モデルに対して推論を実行します。\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # 出力のロジットをソフトマックス関数で確率に変換します。\n",
    "        \n",
    "        # 各モデルの勝率をリストに追加します。\n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    # データフレームに勝率の結果を追加します。\n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df  # 更新されたデータフレームを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bef7006",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "# sort by input length to fully leverage dynaminc padding\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 処理の開始時間を記録します。\n",
    "st = time.time()\n",
    "\n",
    "# 入力の長さでソートし、動的パディングを最大限に活用します。\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "\n",
    "# データを2つのサブセットに分割します。これにより、トークン数がほぼ同じになることを期待します。\n",
    "sub_1 = data.iloc[0::2].copy()  # 偶数のインデックスを持つ行をサブセット1にコピーします。\n",
    "sub_2 = data.iloc[1::2].copy()  # 奇数のインデックスを持つ行をサブセット2にコピーします。\n",
    "\n",
    "# スレッドプールを使用して並行処理を実行します。\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # inference関数をサブセット1とサブセット2のそれぞれにモデルを適用して実行します。\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "# 結果を結合して新しいデータフレームを作成します。\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "\n",
    "# 勝率の確率を取得します。\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "# 処理が完了するまでの経過時間を表示します。\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理の開始時間を記録します。\n",
    "st = time.time()\n",
    "\n",
    "# 入力の長さでソートし、動的パディングを最大限に活用します。\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "\n",
    "# データを2つのサブセットに分割します。これにより、トークン数がほぼ同じになることを期待します。\n",
    "sub_1 = data.iloc[0::2].copy()  # 偶数のインデックスを持つ行をサブセット1にコピーします。\n",
    "sub_2 = data.iloc[1::2].copy()  # 奇数のインデックスを持つ行をサブセット2にコピーします。\n",
    "\n",
    "# スレッドプールを使用して並行処理を実行します。\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    # inference関数をサブセット1とサブセット2のそれぞれにモデルを適用して実行します。\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "# 結果を結合して新しいデータフレームを作成します。\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "\n",
    "# 勝率の確率を取得します。\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "# 処理が完了するまでの経過時間を表示します。\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a198041a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # recall TTA's order is flipped\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # average original result and TTA result.\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 処理の開始時間を記録します。\n",
    "st = time.time()\n",
    "\n",
    "# テスト時データ拡張（TTA）が有効な場合の処理を行います。\n",
    "if cfg.tta:\n",
    "    # 入力の長さでソートし、処理速度を向上させます。\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)\n",
    "    # データを2つのサブセットに分割します。\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    # スレッドプールを使用して並行処理を実行します。\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # inference関数をサブセット1とサブセット2のそれぞれにモデルを適用して実行します。\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    # 結果を結合して新しいデータフレームを作成します。\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # TTAの結果の順序が反転しているため、winner_model_bを先にし、winner_model_aを後にします。\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # 元の結果とTTAの結果を平均します。\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "# 処理が完了するまでの経過時間を表示します。\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理の開始時間を記録します。\n",
    "st = time.time()\n",
    "\n",
    "# テスト時データ拡張（TTA）が有効な場合の処理を行います。\n",
    "if cfg.tta:\n",
    "    # 入力の長さでソートし、処理速度を向上させます。\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)\n",
    "    # データを2つのサブセットに分割します。\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    # スレッドプールを使用して並行処理を実行します。\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        # inference関数をサブセット1とサブセット2のそれぞれにモデルを適用して実行します。\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    # 結果を結合して新しいデータフレームを作成します。\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # TTAの結果の順序が反転しているため、winner_model_bを先にし、winner_model_aを後にします。\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # 元の結果とTTAの結果を平均します。\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "# 処理が完了するまでの経過時間を表示します。\n",
    "print(f\"elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef4af49",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結果データフレームに勝率の確率を追加します。\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # モデルAの勝率を設定します。\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # モデルBの勝率を設定します。\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]  # 引き分けの勝率を設定します。\n",
    "\n",
    "# 提出用のデータフレームを作成します。\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "# データフレームをCSVファイルにエクスポートします。\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 提出用データフレームの内容を表示します。\n",
    "display(submission_df)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果データフレームに勝率の確率を追加します。\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # モデルAの勝率を設定します。\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # モデルBの勝率を設定します。\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]  # 引き分けの勝率を設定します。\n",
    "\n",
    "# 提出用のデータフレームを作成します。\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "# データフレームをCSVファイルにエクスポートします。\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n",
    "# 提出用データフレームの内容を表示します。\n",
    "display(submission_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e984bc",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bbdfb4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータとサンプル提出ファイルをCSV形式で読み込みます。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込みます。\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # サンプル提出ファイルを読み込みます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータとサンプル提出ファイルをCSV形式で読み込みます。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込みます。\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # サンプル提出ファイルを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f532b3f3",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "## Load model \n",
    "> We load 1 model on each gpu.  \n",
    "\n",
    "## Inference\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイズ\n",
    "\n",
    "## モデルの読み込み \n",
    "> 各GPUに1つのモデルを読み込みます。  \n",
    "\n",
    "## 推論\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90abcc7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "sample_sub[TARGETS] = result_df[TARGETS]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# サンプル提出データフレームに結果データフレームから勝率の確率を追加します。\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']  # 対象列を定義します。\n",
    "\n",
    "# 結果データフレームの対象列をサンプル提出データフレームにコピーします。\n",
    "sample_sub[TARGETS] = result_df[TARGETS]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル提出データフレームに結果データフレームから勝率の確率を追加します。\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']  # 対象列を定義します。\n",
    "\n",
    "# 結果データフレームの対象列をサンプル提出データフレームにコピーします。\n",
    "sample_sub[TARGETS] = result_df[TARGETS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36db3af",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "llama_preds = result_df[TARGETS].values\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結果データフレームから対象列の予測をNumPy配列として取得します。\n",
    "llama_preds = result_df[TARGETS].values  # モデルの予測結果を配列に格納します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果データフレームから対象列の予測をNumPy配列として取得します。\n",
    "llama_preds = result_df[TARGETS].values  # モデルの予測結果を配列に格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f96a9e7",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## LGBM + tfidf\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## LGBM + TF-IDF\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94189555",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "RUNPOD = os.path.exists('/workspace/')\n",
    "KAGGLE = not RUNPOD\n",
    "if KAGGLE: \n",
    "    print('kaggle')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 実行環境を確認します。\n",
    "TAG = 'lmsys-chatbot-arena'  # タグを定義します。\n",
    "RUNPOD = os.path.exists('/workspace/')  # 実行環境がRunPodかどうかを確認します。\n",
    "KAGGLE = not RUNPOD  # Kaggleで実行しているかどうかを判断します。\n",
    "\n",
    "# Kaggleで実行している場合、メッセージを表示します。\n",
    "if KAGGLE: \n",
    "    print('kaggle')  # Kaggle環境であることを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実行環境を確認します。\n",
    "TAG = 'lmsys-chatbot-arena'  # タグを定義します。\n",
    "RUNPOD = os.path.exists('/workspace/')  # 実行環境がRunPodかどうかを確認します。\n",
    "KAGGLE = not RUNPOD  # Kaggleで実行しているかどうかを判断します。\n",
    "\n",
    "# Kaggleで実行している場合、メッセージを表示します。\n",
    "if KAGGLE: \n",
    "    print('kaggle')  # Kaggle環境であることを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc5216",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    !pip install -q kaggle\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm \n",
    "    !pip install -q protobuf \n",
    "    !pip install -q numba\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# pandasライブラリをインポートします。失敗した場合は必要なライブラリをインストールします。\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    # Kaggle環境に必要なパッケージをインストールします。\n",
    "    !pip install -q kaggle  # Kaggle APIをインストールします。\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理と可視化のためのライブラリをインストールします。\n",
    "    !pip install -q protobuf  # Protobufライブラリをインストールします。\n",
    "    !pip install -q numba  # Numbaライブラリをインストールします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandasライブラリをインポートします。失敗した場合は必要なライブラリをインストールします。\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    # Kaggle環境に必要なパッケージをインストールします。\n",
    "    !pip install -q kaggle  # Kaggle APIをインストールします。\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理と可視化のためのライブラリをインストールします。\n",
    "    !pip install -q protobuf  # Protobufライブラリをインストールします。\n",
    "    !pip install -q numba  # Numbaライブラリをインストールします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96867200",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)\n",
    "\n",
    "if RUNPOD:\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json\n",
    "        !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/ \n",
    "        \n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')    \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データのパスを設定します。実行環境に応じて異なるパスを指定します。\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)  # Kaggle環境であれば、競技用のデータパスを指定します。\n",
    "\n",
    "# RunPod環境で実行している場合の設定を行います。\n",
    "if RUNPOD:\n",
    "    # Kaggle APIの設定ファイルが存在しない場合、作成しコピーします。\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # Kaggle用のディレクトリを作成します。\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # Kaggle APIの設定ファイルをコピーします。\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # アクセス権を設定します。\n",
    "\n",
    "    # データがまだダウンロードされていない場合、Kaggleからコンペティションデータをダウンロードします。\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleのコンペティションデータをダウンロードします。\n",
    "        \n",
    "    # データディレクトリが存在しない場合、ZIPファイルを解凍します。\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データのパスを設定します。実行環境に応じて異なるパスを指定します。\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)  # Kaggle環境であれば、競技用のデータパスを指定します。\n",
    "\n",
    "# RunPod環境で実行している場合の設定を行います。\n",
    "if RUNPOD:\n",
    "    # Kaggle APIの設定ファイルが存在しない場合、作成しコピーします。\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # Kaggle用のディレクトリを作成します。\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # Kaggle APIの設定ファイルをコピーします。\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # アクセス権を設定します。\n",
    "\n",
    "    # データがまだダウンロードされていない場合、Kaggleからコンペティションデータをダウンロードします。\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleのコンペティションデータをダウンロードします。\n",
    "        \n",
    "    # データディレクトリが存在しない場合、ZIPファイルを解凍します。\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a397331",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "INPUT_PATH = '/kaggle/input/'  \n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "print(MODEL_PATH)\n",
    "\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 入力データとモデルのパスを設定します。\n",
    "INPUT_PATH = '/kaggle/input/'  # Kaggleの入力データパス\n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'  # モデルとロジットの保存先\n",
    "\n",
    "# Kaggle環境の場合、モデルのパスを設定します。lsys-modelsを含むディレクトリを探索します。\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "print(MODEL_PATH)  # モデルのパスを表示します。\n",
    "\n",
    "# コードの保存先を設定します。\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "# 保存先を設定します。\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''  # Kaggle環境では保存先を空に設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力データとモデルのパスを設定します。\n",
    "INPUT_PATH = '/kaggle/input/'  # Kaggleの入力データパス\n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'  # モデルとロジットの保存先\n",
    "\n",
    "# Kaggle環境の場合、モデルのパスを設定します。lsys-modelsを含むディレクトリを探索します。\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "print(MODEL_PATH)  # モデルのパスを表示します。\n",
    "\n",
    "# コードの保存先を設定します。\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "# 保存先を設定します。\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''  # Kaggle環境では保存先を空に設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d0d6a8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーの並列処理を無効にするための環境変数を設定します。\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーの並列処理を無効にするための環境変数を設定します。\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3fb053",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')\n",
    "print(len(train), len(test))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 訓練データ、テストデータ、サンプル提出データをCSV形式で読み込みます。\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # 訓練データを読み込みます。\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))    # テストデータを読み込みます。\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込みます。\n",
    "\n",
    "# 訓練データとテストデータの行数を表示します。\n",
    "print(len(train), len(test))  # 訓練データとテストデータの長さを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータ、サンプル提出データをCSV形式で読み込みます。\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # 訓練データを読み込みます。\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))    # テストデータを読み込みます。\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込みます。\n",
    "\n",
    "# 訓練データとテストデータの行数を表示します。\n",
    "print(len(train), len(test))  # 訓練データとテストデータの長さを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f556a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "params = {}\n",
    "if False: \n",
    "    pass;\n",
    "    params['subsample'] = 30\n",
    "else:\n",
    "    params['fold'] = -1\n",
    "\n",
    "\n",
    "params['n_epochs'] = 1\n",
    "params['n_lgb'] = 1\n",
    "params['model'] = 'microsoft/deberta-v3-small'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルのパラメータを設定します。\n",
    "params = {}\n",
    "# 条件に応じてパラメータを設定します。このブロックは実行されないため、何も設定しません。\n",
    "if False: \n",
    "    pass;\n",
    "    params['subsample'] = 30\n",
    "else:\n",
    "    params['fold'] = -1  # foldの値を-1に設定します。\n",
    "\n",
    "# モデルの訓練に関するその他のパラメータを設定します。\n",
    "params['n_epochs'] = 1  # 訓練のエポック数を1に設定します。\n",
    "params['n_lgb'] = 1  # LightGBMのモデル数を1に設定します。\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルをDeBERTaに設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのパラメータを設定します。\n",
    "params = {}\n",
    "# 条件に応じてパラメータを設定します。このブロックは実行されないため、何も設定しません。\n",
    "if False: \n",
    "    pass;\n",
    "    params['subsample'] = 30\n",
    "else:\n",
    "    params['fold'] = -1  # foldの値を-1に設定します。\n",
    "\n",
    "# モデルの訓練に関するその他のパラメータを設定します。\n",
    "params['n_epochs'] = 1  # 訓練のエポック数を1に設定します。\n",
    "params['n_lgb'] = 1  # LightGBMのモデル数を1に設定します。\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルをDeBERTaに設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6120ed9f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# params = {}\n",
    "FULL = params.get('fold', 0) < 0\n",
    "N_FOLDS = int(params.get('n_folds', 3)); \n",
    "FOLD = int(params.get('fold', 0))\n",
    "SEED = int(params.get('seed', 3))\n",
    "SS = int(params.get('subsample', 1))\n",
    "\n",
    "print(N_FOLDS, FOLD, SEED, SS)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# パラメータに基づいて各種設定を行います。\n",
    "# foldが0未満の場合、FULLをTrueに設定します。\n",
    "FULL = params.get('fold', 0) < 0\n",
    "# n_foldsの数を取得します。デフォルトは3です。\n",
    "N_FOLDS = int(params.get('n_folds', 3))  \n",
    "# foldの値を取得します。デフォルトは0です。\n",
    "FOLD = int(params.get('fold', 0))\n",
    "# seed値を取得します。デフォルトは3です。\n",
    "SEED = int(params.get('seed', 3))\n",
    "# subsample値を取得します。デフォルトは1です。\n",
    "SS = int(params.get('subsample', 1))\n",
    "\n",
    "# 設定した値を表示します。\n",
    "print(N_FOLDS, FOLD, SEED, SS)  # N_FOLDS、FOLD、SEED、SSの値を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータに基づいて各種設定を行います。\n",
    "# foldが0未満の場合、FULLをTrueに設定します。\n",
    "FULL = params.get('fold', 0) < 0\n",
    "# n_foldsの数を取得します。デフォルトは3です。\n",
    "N_FOLDS = int(params.get('n_folds', 3))  \n",
    "# foldの値を取得します。デフォルトは0です。\n",
    "FOLD = int(params.get('fold', 0))\n",
    "# seed値を取得します。デフォルトは3です。\n",
    "SEED = int(params.get('seed', 3))\n",
    "# subsample値を取得します。デフォルトは1です。\n",
    "SS = int(params.get('subsample', 1))\n",
    "\n",
    "# 設定した値を表示します。\n",
    "print(N_FOLDS, FOLD, SEED, SS)  # N_FOLDS、FOLD、SEED、SSの値を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a28f8b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state = SEED, shuffle = True)\\\n",
    "                    .split(X = np.zeros(len(train)), y = train.iloc[:, -3:].idxmax(1)))\n",
    "\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "if SS > 1:\n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "print(len(train_ids), len(test_ids));  assert set(train_ids) & set(test_ids) == set() \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# StratifiedKFoldをインポートします。これは層化K-Foldクロスバリデーションを実施するためのクラスです。\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# K-Foldのインデックスを取得する関数を定義します。\n",
    "def get_folds(train): \n",
    "    # StratifiedKFoldを使用して、訓練データの分割を行い、インデックスを返します。\n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)\\\n",
    "                    .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # 最後の3列のインデックスが最大のものをラベルとして使用します。\n",
    "\n",
    "# 指定されたFOLDまたはFULLを考慮して、訓練データとテストデータのIDを取得します。\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# subsampleが1より大きい場合、IDを間引いたリストにします。\n",
    "if SS > 1:\n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# 訓練データとテストデータのIDの長さを表示します。\n",
    "print(len(train_ids), len(test_ids))\n",
    "# 訓練データとテストデータのIDで重複がないことを確認します。\n",
    "assert set(train_ids) & set(test_ids) == set()  # 重複がある場合、エラーを出力します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StratifiedKFoldをインポートします。これは層化K-Foldクロスバリデーションを実施するためのクラスです。\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# K-Foldのインデックスを取得する関数を定義します。\n",
    "def get_folds(train): \n",
    "    # StratifiedKFoldを使用して、訓練データの分割を行い、インデックスを返します。\n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)\\\n",
    "                    .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # 最後の3列のインデックスが最大のものをラベルとして使用します。\n",
    "\n",
    "# 指定されたFOLDまたはFULLを考慮して、訓練データとテストデータのIDを取得します。\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# subsampleが1より大きい場合、IDを間引いたリストにします。\n",
    "if SS > 1:\n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# 訓練データとテストデータのIDの長さを表示します。\n",
    "print(len(train_ids), len(test_ids))\n",
    "# 訓練データとテストデータのIDで重複がないことを確認します。\n",
    "assert set(train_ids) & set(test_ids) == set()  # 重複がある場合、エラーを出力します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ddca52",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)\n",
    "random.seed(datetime.datetime.now().microsecond)\n",
    "np.random.seed(datetime.datetime.now().microsecond)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 乱数のシードを設定します。これにより、毎回の実行が再現可能になります。\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定します。\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定します。\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱数のシードを設定します。これにより、毎回の実行が再現可能になります。\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定します。\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定します。\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa393140",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "TRAIN = False\n",
    "INFER = True \n",
    "SAVE = False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モードの設定を行います。\n",
    "TRAIN = False  # 訓練モードを無効にします。\n",
    "INFER = True   # 推論モードを有効にします。\n",
    "SAVE = False   # 保存モードを無効にします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モードの設定を行います。\n",
    "TRAIN = False  # 訓練モードを無効にします。\n",
    "INFER = True   # 推論モードを有効にします。\n",
    "SAVE = False   # 保存モードを無効にします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64520be",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMライブラリと、テキストデータの前処理を行うためのCountVectorizerをインポートします。\n",
    "import lightgbm as lgb  # LightGBMライブラリをインポートします。これは高速な決定木アルゴリズムです。\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータをベクトル化するためのクラスをインポートします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMライブラリと、テキストデータの前処理を行うためのCountVectorizerをインポートします。\n",
    "import lightgbm as lgb  # LightGBMライブラリをインポートします。これは高速な決定木アルゴリズムです。\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータをベクトル化するためのクラスをインポートします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227b5beb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "LGB = True\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0\n",
    "INFER_LGB = not TRAIN and LGB\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMの利用設定を行います。\n",
    "LGB = True  # LightGBMを使用する設定をTrueにします。\n",
    "# 訓練時のLightGBMの実行設定を決定します。\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # 訓練中にLightGBMを実行すべきかどうかを決定します。\n",
    "# 推論時のLightGBMの実行設定を決定します。\n",
    "INFER_LGB = not TRAIN and LGB  # 訓練中でない場合にLightGBMを使用する設定を決定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMの利用設定を行います。\n",
    "LGB = True  # LightGBMを使用する設定をTrueにします。\n",
    "# 訓練時のLightGBMの実行設定を決定します。\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # 訓練中にLightGBMを実行すべきかどうかを決定します。\n",
    "# 推論時のLightGBMの実行設定を決定します。\n",
    "INFER_LGB = not TRAIN and LGB  # 訓練中でない場合にLightGBMを使用する設定を決定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dbda4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 学習済みのCountVectorizerオブジェクトをファイルから読み込みます。\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # CountVectorizerを読み込みます。\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # 別のCountVectorizerを読み込みます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みのCountVectorizerオブジェクトをファイルから読み込みます。\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # CountVectorizerを読み込みます。\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # 別のCountVectorizerを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3d0e97",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def symlog(x):\n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)\n",
    "\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())\n",
    "    x = symlog(x)\n",
    "    return x\n",
    "\n",
    "def get_features(df):\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    v = np.hstack([\n",
    "          afeat - bfeat, np.abs(afeat - bfeat), \n",
    "        ])\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)\n",
    "            \n",
    "    extras.append(df[c].str.len())\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))\n",
    "    \n",
    "    extras = np.stack(extras, axis = 1)\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])\n",
    "    return np.hstack([v, extras])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# シンメトリックログ変換を行う関数を定義します。\n",
    "def symlog(x):\n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # xのシンメトリックログを計算します。\n",
    "\n",
    "# 疎行列をDense行列に変換し、シンメトリックログ変換を適用する関数を定義します。\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 疎行列をDense行列に変換します。\n",
    "    x = symlog(x)  # シンメトリックログ変換を適用します。\n",
    "    return x\n",
    "\n",
    "# 特徴量を取得するための関数を定義します。\n",
    "def get_features(df):\n",
    "    # プロンプトから生成される特徴量\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])  # CountVectorizerを使用して特徴量を抽出します。\n",
    "\n",
    "    # レスポンスAから生成される特徴量\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # レスポンスBから生成される特徴量\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # AとBのレスポンスの比較特徴量を作成します。\n",
    "    v = np.hstack([\n",
    "          afeat - bfeat, np.abs(afeat - bfeat),  # レスポンスAとレスポンスBの差分を含む特徴量\n",
    "        ])\n",
    "    \n",
    "    # モデル数によってvを調整します。\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 追加の特徴量を生成します。\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']  # 特徴量を生成するための追加項目\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # 特定の文字の出現回数をカウントします。\n",
    "            \n",
    "    extras.append(df[c].str.len())  # 各列の文字数を追加します。\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 各列の単語数を追加します。\n",
    "    \n",
    "    extras = np.stack(extras, axis=1)  # 追加特徴量を1つの配列にまとめます。\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # 追加特徴量を変換します。\n",
    "    \n",
    "    return np.hstack([v, extras])  # 最後に全ての特徴量を結合して返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンメトリックログ変換を行う関数を定義します。\n",
    "def symlog(x):\n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # xのシンメトリックログを計算します。\n",
    "\n",
    "# 疎行列をDense行列に変換し、シンメトリックログ変換を適用する関数を定義します。\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 疎行列をDense行列に変換します。\n",
    "    x = symlog(x)  # シンメトリックログ変換を適用します。\n",
    "    return x\n",
    "\n",
    "# 特徴量を取得するための関数を定義します。\n",
    "def get_features(df):\n",
    "    # プロンプトから生成される特徴量\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])  # CountVectorizerを使用して特徴量を抽出します。\n",
    "\n",
    "    # レスポンスAから生成される特徴量\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # レスポンスBから生成される特徴量\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # AとBのレスポンスの比較特徴量を作成します。\n",
    "    v = np.hstack([\n",
    "          afeat - bfeat, np.abs(afeat - bfeat),  # レスポンスAとレスポンスBの差分を含む特徴量\n",
    "        ])\n",
    "    \n",
    "    # モデル数によってvを調整します。\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # 追加の特徴量を生成します。\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']  # 特徴量を生成するための追加項目\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # 特定の文字の出現回数をカウントします。\n",
    "            \n",
    "    extras.append(df[c].str.len())  # 各列の文字数を追加します。\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 各列の単語数を追加します。\n",
    "    \n",
    "    extras = np.stack(extras, axis=1)  # 追加特徴量を1つの配列にまとめます。\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # 追加特徴量を変換します。\n",
    "    \n",
    "    return np.hstack([v, extras])  # 最後に全ての特徴量を結合して返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6943e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 学習済みのLightGBMモデルをファイルから読み込みます。\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込みます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みのLightGBMモデルをファイルから読み込みます。\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込みます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c2be06",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test\n",
    "    yps = []; b = 1000\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])\n",
    "        ypms = []\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))\n",
    "        yps.append(np.stack(ypms).mean(0))\n",
    "        print('.', end = '')\n",
    "        \n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()\n",
    "    print()\n",
    "\n",
    "    yp = np.concatenate(yps)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論が有効で、LightGBMモデルの数が0より大きい場合の処理を行います。\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータフレームをdfに設定します。\n",
    "    yps = []  # 複数の予測結果を格納するリストを初期化します。\n",
    "    b = 1000  # 一度に処理するデータのバッチサイズを設定します。\n",
    "    \n",
    "    # データをバッチ処理で推論します。\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得します。\n",
    "        ypms = []  # 各モデルの予測結果を格納するリストを初期化します。\n",
    "        \n",
    "        # 全てのLightGBMモデルに対して予測を行います。\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))  # モデルからの予測確率を取得します。\n",
    "        \n",
    "        # 各モデルの予測確率を平均化してypsに追加します。\n",
    "        yps.append(np.stack(ypms).mean(0))\n",
    "        print('.', end = '')  # 進行状況を表示します。\n",
    "        \n",
    "        # 2バッチごとにガベージコレクションを実行します。\n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()\n",
    "    print()  # 改行します。\n",
    "\n",
    "    # すべての予測結果を連結します。\n",
    "    yp = np.concatenate(yps)  # 最終的な予測結果を取得します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論が有効で、LightGBMモデルの数が0より大きい場合の処理を行います。\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータフレームをdfに設定します。\n",
    "    yps = []  # 複数の予測結果を格納するリストを初期化します。\n",
    "    b = 1000  # 一度に処理するデータのバッチサイズを設定します。\n",
    "    \n",
    "    # データをバッチ処理で推論します。\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得します。\n",
    "        ypms = []  # 各モデルの予測結果を格納するリストを初期化します。\n",
    "        \n",
    "        # 全てのLightGBMモデルに対して予測を行います。\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))  # モデルからの予測確率を取得します。\n",
    "        \n",
    "        # 各モデルの予測確率を平均化してypsに追加します。\n",
    "        yps.append(np.stack(ypms).mean(0))\n",
    "        print('.', end = '')  # 進行状況を表示します。\n",
    "        \n",
    "        # 2バッチごとにガベージコレクションを実行します。\n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()\n",
    "    print()  # 改行します。\n",
    "\n",
    "    # すべての予測結果を連結します。\n",
    "    yp = np.concatenate(yps)  # 最終的な予測結果を取得します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31a71ef",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_preds = yp\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMモデルからの最終的な予測結果をlgb_predsに格納します。\n",
    "lgb_preds = yp  # 推論結果をlgb_predsに設定します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMモデルからの最終的な予測結果をlgb_predsに格納します。\n",
    "lgb_preds = yp  # 推論結果をlgb_predsに設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddbd8b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Blend predictions\n",
    "\n",
    "$\\operatorname{preds} = 0.12 \\cdot \\operatorname{lgbm boosting preds} + 0.8 \\cdot \\operatorname{llama preds}$\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 予測のブレンド\n",
    "\n",
    "$\\operatorname{preds} = 0.12 \\cdot \\operatorname{LGBMブースティング予測} + 0.8 \\cdot \\operatorname{Llama予測}$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b128196",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_wt = 0.6\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LGBMの重みを設定し、予測をブレンドします。\n",
    "lgb_wt = 0.6  # LGBMモデルの重みを設定します。\n",
    "# LGBM予測とLlama予測を重み付けして加算し、最終的な予測を得ます。\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # 予測のブレンドを実行します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMの重みを設定し、予測をブレンドします。\n",
    "lgb_wt = 0.6  # LGBMモデルの重みを設定します。\n",
    "# LGBM予測とLlama予測を重み付けして加算し、最終的な予測を得ます。\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # 予測のブレンドを実行します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30034bf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out = pd.DataFrame(preds, index=df.id, columns=train.columns[-3:])\n",
    "display(out.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終的な予測結果をDataFrameとして作成します。\n",
    "out = pd.DataFrame(preds, index=df.id, columns=train.columns[-3:])  # 予測値をDataFrameに格納します。\n",
    "# 最初の数行を表示します。\n",
    "display(out.head())  # 生成したDataFrameの先頭を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な予測結果をDataFrameとして作成します。\n",
    "out = pd.DataFrame(preds, index=df.id, columns=train.columns[-3:])  # 予測値をDataFrameに格納します。\n",
    "# 最初の数行を表示します。\n",
    "display(out.head())  # 生成したDataFrameの先頭を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657735b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out.to_csv('submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終的な予測結果をCSVファイルとして保存します。\n",
    "out.to_csv('submission.csv')  # 生成したDataFrameを'submission.csv'として出力します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的な予測結果をCSVファイルとして保存します。\n",
    "out.to_csv('submission.csv')  # 生成したDataFrameを'submission.csv'として出力します。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4946449,
     "sourceId": 8330401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5034873,
     "sourceId": 8449074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369301,
     "sourceId": 8926343,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 187768984,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 63082,
     "sourceId": 75103,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
