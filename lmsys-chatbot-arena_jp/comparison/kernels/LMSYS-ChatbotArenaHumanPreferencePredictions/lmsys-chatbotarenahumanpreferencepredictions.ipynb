{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a83bd54",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」において、チャットボット応答の好みを予測するための機械学習モデルを構築するためのものです。具体的には、提供されたデータセットを使用して、モデルA、モデルB、または引き分けとしてどの応答がユーザーに好まれるかを分類します。\n",
    "\n",
    "### 主要な手法とライブラリ\n",
    "1. **ライブラリの使用**:\n",
    "   - `pandas`と`numpy`: データ操作や数値計算のために使用。\n",
    "   - `matplotlib`と`seaborn`: データの可視化を行うために利用。\n",
    "   - `scikit-learn`: データの分割や評価指標の計算に使用。\n",
    "   - `tensorflow.keras`: ニューラルネットワークモデルの構築に使用します。\n",
    "\n",
    "2. **データの前処理**:\n",
    "   - 訓練データとテストデータをCSVファイルから読み込み、データフレームに格納。\n",
    "   - プロンプトと応答を結合し、テキストデータをトークン化します。この作業では`Tokenizer`を使用し、シーケンスをパディングすることで、全ての入力データが同じ長さになるように整形します。\n",
    "   - ターゲットラベル（勝者モデル）を数値形式からワンホットエンコーディングに変換します。\n",
    "\n",
    "3. **モデル構築**:\n",
    "   - Kerasの`Sequential`モデルを使用し、埋め込み層、LSTM層、および全結合層を組み合わせて、テキストデータを処理するモデルを構築します。\n",
    "   - モデルは、3つのクラスに対する確率を出力するように設計されています（モデルA、モデルB、引き分け）。\n",
    "   - 損失関数には`categorical_crossentropy`を使用し、最適化アルゴリズムには`adam`を設定しています。\n",
    "\n",
    "4. **モデルの訓練**:\n",
    "   - 訓練データを用いて10エポックの間モデルを学習させ、訓練過程の損失と精度を可視化します。\n",
    "   - 訓練セットと検証セットに分けることで、モデルの過学習を防ぎつつ性能を評価します。\n",
    "\n",
    "5. **予測と提出ファイルの作成**:\n",
    "   - テストデータに対してモデルを用いて予測を実施し、結果はバイナリカラムとしてテストデータフレームに追加します。\n",
    "   - 最終的に、予測結果を「submission.csv」というCSVファイルに保存し、Kaggleコンペティションに投稿可能な形式に整えます。\n",
    "\n",
    "このNotebookは、与えられたデータセットをもとに、言語モデルの応答の好みを効果的に予測する機械学習フレームワークを実装するための全体的なプロセスを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3019e92",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、初心者がつまずくかもしれない専門用語の解説を列挙します。このリストは、与えられたJupyter Notebookの内容に基づいています。\n",
    "\n",
    "1. **トークン化 (Tokenization)**: テキストを単語やフレーズといった小さな単位に分割するプロセス。これにより、言語モデルがテキストデータを数値的に処理できるようになります。\n",
    "\n",
    "2. **パディング (Padding)**: シーケンスデータの長さを揃えるプロセス。異なる長さのシーケンスを持つデータを、モデルに入力できるように同じ長さにするために、短いシーケンスには特定の値（通常はゼロ）を追加します。\n",
    "\n",
    "3. **LSTM (Long Short-Term Memory)**: 従来のRNN（再帰的ニューラルネットワーク）の問題点を克服するために設計された特別なタイプのニューラルネットワーク。長期的な依存関係を学習する能力があり、特に時系列データや言語処理において優れた性能を発揮します。\n",
    "\n",
    "4. **埋め込み層 (Embedding Layer)**: テキストデータをベクトル表現に変換するための層。単語を密なベクトル空間にマッピングし、意味的に類似した単語同士が近くに配置されるように学習します。\n",
    "\n",
    "5. **ドロップアウト (Dropout)**: ニューラルネットワークの訓練中に特定のニューロンをランダムに無効化する手法。過学習を防ぐ手段として広く利用されています。\n",
    "\n",
    "6. **ワンホットエンコーディング (One-hot Encoding)**: カテゴリカルデータをベクトル化する手法の一つで、各クラスを0と1の配列で表現します。例えば、クラスが3つある場合は、[1,0,0]、[0,1,0]、[0,0,1]のように表現します。\n",
    "\n",
    "7. **マルチクラス分類 (Multiclass Classification)**: 複数のクラスからひとつのクラスを予測するタスク。多くの機械学習アルゴリズムが対応しており、これにはソフトマックス関数がよく使用されます。\n",
    "\n",
    "8. **バリデーションセット (Validation Set)**: モデルのトレーニング中に、モデルの性能を評価するために使用されるデータセット。訓練セットとは異なるデータを使用し、モデルが新しいデータに対してどれだけ一般化できるかを評価します。\n",
    "\n",
    "9. **混同行列 (Confusion Matrix)**: 分類モデルの予測性能を示す行列で、実際のクラスと予測されたクラスの正例/誤例の数をまとめたもの。復習や調整のために有用です。\n",
    "\n",
    "10. **対数損失 (Log Loss)**: 分類モデルの性能を評価するための損失関数の一つ。予測された確率が正しいクラスとどれだけ相違しているかを示し、確率を用いたモデル評価に特に適しています。\n",
    "\n",
    "これらの用語は、初心者が受ける可能性のある混乱を解消するために役立つ基礎的かつ特定の知識です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ae4b23",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートします\n",
    "import pandas as pd  # データ操作用のライブラリ\n",
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のライブラリ\n",
    "import seaborn as sns  # より美しいグラフを描くためのライブラリ\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用とテスト用に分割するための関数\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # 評価指標の計算に使う関数\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # テキストデータのトークン化を行うクラス\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # シーケンスデータを同じ長さにパディングするための関数\n",
    "from tensorflow.keras.models import Sequential  # シーケンシャルモデルを作成するためのクラス\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout  # ニューラルネットワークのレイヤーをインポート\n",
    "from tensorflow.keras.utils import to_categorical  # クラスラベルをカテゴリカルに変換するための関数\n",
    "\n",
    "# これらのライブラリはデータの前処理やモデルの構築に使われます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-22T13:14:42.061318Z",
     "iopub.status.busy": "2024-07-22T13:14:42.060926Z",
     "iopub.status.idle": "2024-07-22T13:14:46.817539Z",
     "shell.execute_reply": "2024-07-22T13:14:46.81639Z",
     "shell.execute_reply.started": "2024-07-22T13:14:42.061281Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします\n",
    "import pandas as pd  # データ操作用のライブラリ\n",
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のライブラリ\n",
    "import seaborn as sns  # より美しいグラフを描くためのライブラリ\n",
    "from sklearn.model_selection import train_test_split  # データを訓練用とテスト用に分割するための関数\n",
    "from sklearn.metrics import confusion_matrix, classification_report  # 評価指標の計算に使う関数\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # テキストデータのトークン化を行うクラス\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # シーケンスデータを同じ長さにパディングするための関数\n",
    "from tensorflow.keras.models import Sequential  # シーケンシャルモデルを作成するためのクラス\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout  # ニューラルネットワークのレイヤーをインポート\n",
    "from tensorflow.keras.utils import to_categorical  # クラスラベルをカテゴリカルに変換するための関数\n",
    "\n",
    "# これらのライブラリはデータの前処理やモデルの構築に使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b35114",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load the data\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データを読み込みます\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データのCSVファイルを読み込み、train_dfに格納します\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータのCSVファイルを読み込み、test_dfに格納します\n",
    "\n",
    "# 読み込んだデータフレームには、訓練用とテスト用のデータがそれぞれ格納されています。これらのデータはモデルの学習や評価に使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:14:56.082925Z",
     "iopub.status.busy": "2024-07-22T13:14:56.082539Z",
     "iopub.status.idle": "2024-07-22T13:14:58.171616Z",
     "shell.execute_reply": "2024-07-22T13:14:58.170031Z",
     "shell.execute_reply.started": "2024-07-22T13:14:56.082893Z"
    }
   },
   "outputs": [],
   "source": [
    "# データを読み込みます\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データのCSVファイルを読み込み、train_dfに格納します\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータのCSVファイルを読み込み、test_dfに格納します\n",
    "\n",
    "# 読み込んだデータフレームには、訓練用とテスト用のデータがそれぞれ格納されています。これらのデータはモデルの学習や評価に使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1530d6f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Check the column names\n",
    "print(\"Train Data Columns:\", train_df.columns)\n",
    "print(\"\\nTest Data Columns:\", test_df.columns)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# カラム名を確認します\n",
    "print(\"Train Data Columns:\", train_df.columns)  # 訓練データのカラム名を表示します\n",
    "print(\"\\nTest Data Columns:\", test_df.columns)  # テストデータのカラム名を表示します\n",
    "\n",
    "# ここでは、訓練データとテストデータの各カラム名を確認して、データの構造を理解します。これにより、どの特徴量（フィーチャー）が使用されるかを把握することができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:14:58.174595Z",
     "iopub.status.busy": "2024-07-22T13:14:58.174072Z",
     "iopub.status.idle": "2024-07-22T13:14:58.181972Z",
     "shell.execute_reply": "2024-07-22T13:14:58.18047Z",
     "shell.execute_reply.started": "2024-07-22T13:14:58.174551Z"
    }
   },
   "outputs": [],
   "source": [
    "# カラム名を確認します\n",
    "print(\"Train Data Columns:\", train_df.columns)  # 訓練データのカラム名を表示します\n",
    "print(\"\\nTest Data Columns:\", test_df.columns)  # テストデータのカラム名を表示します\n",
    "\n",
    "# ここでは、訓練データとテストデータの各カラム名を確認して、データの構造を理解します。これにより、どの特徴量（フィーチャー）が使用されるかを把握することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158597b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Use a smaller subset of data\n",
    "train_df = train_df.head(2000)\n",
    "test_df = test_df.head(2000)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データの小さなサブセットを使用します\n",
    "train_df = train_df.head(2000)  # 訓練データから最初の2000行を抽出し、train_dfに格納します\n",
    "test_df = test_df.head(2000)  # テストデータから最初の2000行を抽出し、test_dfに格納します\n",
    "\n",
    "# これにより、データセットが小さくなり、処理時間を短縮し、モデルの実験を迅速に行うことができます。最初は限られたデータでテストし、その後、必要に応じて全体のデータを使用することが推奨されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:02.401503Z",
     "iopub.status.busy": "2024-07-22T13:15:02.400447Z",
     "iopub.status.idle": "2024-07-22T13:15:02.406866Z",
     "shell.execute_reply": "2024-07-22T13:15:02.405558Z",
     "shell.execute_reply.started": "2024-07-22T13:15:02.401438Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの小さなサブセットを使用します\n",
    "train_df = train_df.head(2000)  # 訓練データから最初の2000行を抽出し、train_dfに格納します\n",
    "test_df = test_df.head(2000)  # テストデータから最初の2000行を抽出し、test_dfに格納します\n",
    "\n",
    "# これにより、データセットが小さくなり、処理時間を短縮し、モデルの実験を迅速に行うことができます。最初は限られたデータでテストし、その後、必要に応じて全体のデータを使用することが推奨されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dec3f4c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Combine the winner columns into a single target column\n",
    "train_df['winner'] = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 勝者のカラムを一つのターゲットカラムに統合します\n",
    "train_df['winner'] = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  \n",
    "# winner_model_a、winner_model_b、winner_tieの各カラムで値が最大のインデックスを取得し、それを新しいwinnerカラムに格納します。\n",
    "\n",
    "# これにより、勝者の情報が1つのカラムに集約され、モデルの学習や評価が容易になります。winnerカラムには、どのモデルが選ばれたかを示す数値が入ります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:05.058391Z",
     "iopub.status.busy": "2024-07-22T13:15:05.057957Z",
     "iopub.status.idle": "2024-07-22T13:15:05.071014Z",
     "shell.execute_reply": "2024-07-22T13:15:05.069648Z",
     "shell.execute_reply.started": "2024-07-22T13:15:05.058357Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者のカラムを一つのターゲットカラムに統合します\n",
    "train_df['winner'] = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  \n",
    "# winner_model_a、winner_model_b、winner_tieの各カラムで値が最大のインデックスを取得し、それを新しいwinnerカラムに格納します。\n",
    "\n",
    "# これにより、勝者の情報が1つのカラムに集約され、モデルの学習や評価が容易になります。winnerカラムには、どのモデルが選ばれたかを示す数値が入ります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be3ae49",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Combine all text data for tokenization\n",
    "all_text = pd.concat([train_df['prompt'], train_df['response_a'], train_df['response_b'],\n",
    "                      test_df['prompt'], test_df['response_a'], test_df['response_b']])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークン化のためにすべてのテキストデータを結合します\n",
    "all_text = pd.concat([train_df['prompt'], train_df['response_a'], train_df['response_b'],  # 訓練データのプロンプトと応答を結合\n",
    "                      test_df['prompt'], test_df['response_a'], test_df['response_b']])  # テストデータのプロンプトと応答も結合します\n",
    "\n",
    "# これにより、トークン化の処理を一度に行うためにすべてのテキストデータが一つのシリーズにまとめられます。この操作は、モデルが自然言語を理解するための前処理において重要なステップとなります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:07.761271Z",
     "iopub.status.busy": "2024-07-22T13:15:07.760899Z",
     "iopub.status.idle": "2024-07-22T13:15:07.768252Z",
     "shell.execute_reply": "2024-07-22T13:15:07.766897Z",
     "shell.execute_reply.started": "2024-07-22T13:15:07.761245Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン化のためにすべてのテキストデータを結合します\n",
    "all_text = pd.concat([train_df['prompt'], train_df['response_a'], train_df['response_b'],  # 訓練データのプロンプトと応答を結合\n",
    "                      test_df['prompt'], test_df['response_a'], test_df['response_b']])  # テストデータのプロンプトと応答も結合します\n",
    "\n",
    "# これにより、トークン化の処理を一度に行うためにすべてのテキストデータが一つのシリーズにまとめられます。この操作は、モデルが自然言語を理解するための前処理において重要なステップとなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2585f45",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストデータをトークン化します\n",
    "tokenizer = Tokenizer()  # Tokenizerオブジェクトを初期化します\n",
    "tokenizer.fit_on_texts(all_text)  # 結合したテキストデータに基づいて単語のインデックスを作成します\n",
    "vocab_size = len(tokenizer.word_index) + 1  # 語彙のサイズを取得します（インデックスが0から始まるので1を加えます）\n",
    "\n",
    "# トークン化は、テキストデータを数値の配列に変換するプロセスです。これにより、機械学習モデルがテキストを理解し、処理できるようになります。vocab_sizeは使用する単語の総数を示し、モデルを構築する際に必要な情報となります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:35.270694Z",
     "iopub.status.busy": "2024-07-22T13:15:35.270118Z",
     "iopub.status.idle": "2024-07-22T13:15:36.222699Z",
     "shell.execute_reply": "2024-07-22T13:15:36.221458Z",
     "shell.execute_reply.started": "2024-07-22T13:15:35.270652Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストデータをトークン化します\n",
    "tokenizer = Tokenizer()  # Tokenizerオブジェクトを初期化します\n",
    "tokenizer.fit_on_texts(all_text)  # 結合したテキストデータに基づいて単語のインデックスを作成します\n",
    "vocab_size = len(tokenizer.word_index) + 1  # 語彙のサイズを取得します（インデックスが0から始まるので1を加えます）\n",
    "\n",
    "# トークン化は、テキストデータを数値の配列に変換するプロセスです。これにより、機械学習モデルがテキストを理解し、処理できるようになります。vocab_sizeは使用する単語の総数を示し、モデルを構築する際に必要な情報となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0f80b4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def tokenize_and_pad(text_series, tokenizer, max_len):\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)\n",
    "    padded_sequences = pad_sequences(sequences,maxlen=max_len)\n",
    "    return padded_sequences\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def tokenize_and_pad(text_series, tokenizer, max_len):\n",
    "    # テキストシリーズをトークン化し、パディングを行う関数\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)  # テキストデータを数値のシーケンスに変換します\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len)  # シーケンスの長さをmax_lenに揃えます\n",
    "    return padded_sequences  # パディングされたシーケンスを返します\n",
    "\n",
    "# この関数は、与えられたテキストデータをトークン化し、指定された長さにパディングを行います。これにより、すべてのシーケンスが同じ長さになり、ニューラルネットワークに入力する際に扱いやすくなります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:37.798892Z",
     "iopub.status.busy": "2024-07-22T13:15:37.798503Z",
     "iopub.status.idle": "2024-07-22T13:15:37.806056Z",
     "shell.execute_reply": "2024-07-22T13:15:37.804242Z",
     "shell.execute_reply.started": "2024-07-22T13:15:37.798865Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize_and_pad(text_series, tokenizer, max_len):\n",
    "    # テキストシリーズをトークン化し、パディングを行う関数\n",
    "    sequences = tokenizer.texts_to_sequences(text_series)  # テキストデータを数値のシーケンスに変換します\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=max_len)  # シーケンスの長さをmax_lenに揃えます\n",
    "    return padded_sequences  # パディングされたシーケンスを返します\n",
    "\n",
    "# この関数は、与えられたテキストデータをトークン化し、指定された長さにパディングを行います。これにより、すべてのシーケンスが同じ長さになり、ニューラルネットワークに入力する際に扱いやすくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbc05d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Define maximum sequence length\n",
    "max_len = 100\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最大シーケンス長を定義します\n",
    "max_len = 100  # トークン化されたテキストシーケンスの最大長を100に設定します\n",
    "\n",
    "# この設定により、全てのシーケンスは長さ100に揃えられ、短いシーケンスにはパディングが追加されます。長すぎるシーケンスは切り捨てられます。これにより、一貫した入力サイズが確保され、モデルのトレーニングが容易になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:40.147403Z",
     "iopub.status.busy": "2024-07-22T13:15:40.146696Z",
     "iopub.status.idle": "2024-07-22T13:15:40.152285Z",
     "shell.execute_reply": "2024-07-22T13:15:40.150813Z",
     "shell.execute_reply.started": "2024-07-22T13:15:40.147349Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最大シーケンス長を定義します\n",
    "max_len = 100  # トークン化されたテキストシーケンスの最大長を100に設定します\n",
    "\n",
    "# この設定により、全てのシーケンスは長さ100に揃えられ、短いシーケンスにはパディングが追加されます。長すぎるシーケンスは切り捨てられます。これにより、一貫した入力サイズが確保され、モデルのトレーニングが容易になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ca7bb9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Tokenize and pad the training data\n",
    "x_prompt = tokenize_and_pad(train_df['prompt'],tokenizer, max_len)\n",
    "x_response_a = tokenize_and_pad(train_df['response_a'],tokenizer, max_len)\n",
    "x_response_b = tokenize_and_pad(train_df['response_b'],tokenizer, max_len)\n",
    "x_train = np.concatenate([x_prompt,x_response_a,x_response_b],axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 訓練データをトークン化し、パディングを行います\n",
    "x_prompt = tokenize_and_pad(train_df['prompt'], tokenizer, max_len)  # プロンプトをトークン化してパディングする\n",
    "x_response_a = tokenize_and_pad(train_df['response_a'], tokenizer, max_len)  # 応答Aをトークン化してパディングする\n",
    "x_response_b = tokenize_and_pad(train_df['response_b'], tokenizer, max_len)  # 応答Bをトークン化してパディングする\n",
    "x_train = np.concatenate([x_prompt, x_response_a, x_response_b], axis=1)  # トークン化されたプロンプトと応答を結合して訓練データを作成する\n",
    "\n",
    "# この処理により、プロンプトとそれに対する2つの応答（response_aおよびresponse_b）が一つの特徴行列としてまとめられ、モデルの入力データとして利用できるようになります。次のステップでモデルを構築する際に、これらのデータが必要になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:42.292099Z",
     "iopub.status.busy": "2024-07-22T13:15:42.291739Z",
     "iopub.status.idle": "2024-07-22T13:15:42.895288Z",
     "shell.execute_reply": "2024-07-22T13:15:42.894009Z",
     "shell.execute_reply.started": "2024-07-22T13:15:42.292074Z"
    }
   },
   "outputs": [],
   "source": [
    "# 訓練データをトークン化し、パディングを行います\n",
    "x_prompt = tokenize_and_pad(train_df['prompt'], tokenizer, max_len)  # プロンプトをトークン化してパディングする\n",
    "x_response_a = tokenize_and_pad(train_df['response_a'], tokenizer, max_len)  # 応答Aをトークン化してパディングする\n",
    "x_response_b = tokenize_and_pad(train_df['response_b'], tokenizer, max_len)  # 応答Bをトークン化してパディングする\n",
    "x_train = np.concatenate([x_prompt, x_response_a, x_response_b], axis=1)  # トークン化されたプロンプトと応答を結合して訓練データを作成する\n",
    "\n",
    "# この処理により、プロンプトとそれに対する2つの応答（response_aおよびresponse_b）が一つの特徴行列としてまとめられ、モデルの入力データとして利用できるようになります。次のステップでモデルを構築する際に、これらのデータが必要になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb49f0ee",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Encode the target variable\n",
    "y_train = to_categorical(train_df['winner'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ターゲット変数をエンコードします\n",
    "y_train = to_categorical(train_df['winner'])  # winnerカラムをカテゴリカル形式に変換します\n",
    "\n",
    "# to_categorical関数を使用することで、ターゲット変数（勝者）が整数ラベルからワンホットエンコーディング形式に変換されます。これにより、モデルがマルチクラスの分類タスクを適切に学習できるようになります。各クラスは、ベクトルの中で関連するインデックスに1が設定されている形式で表現されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:52.00097Z",
     "iopub.status.busy": "2024-07-22T13:15:52.000548Z",
     "iopub.status.idle": "2024-07-22T13:15:52.007496Z",
     "shell.execute_reply": "2024-07-22T13:15:52.006268Z",
     "shell.execute_reply.started": "2024-07-22T13:15:52.000939Z"
    }
   },
   "outputs": [],
   "source": [
    "# ターゲット変数をエンコードします\n",
    "y_train = to_categorical(train_df['winner'])  # winnerカラムをカテゴリカル形式に変換します\n",
    "\n",
    "# to_categorical関数を使用することで、ターゲット変数（勝者）が整数ラベルからワンホットエンコーディング形式に変換されます。これにより、モデルがマルチクラスの分類タスクを適切に学習できるようになります。各クラスは、ベクトルの中で関連するインデックスに1が設定されている形式で表現されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a5297a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データを訓練セットと検証セットに分割します\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)  \n",
    "# 訓練データを80%の訓練セットと20%の検証セットに分割します。random_stateを指定することで、再現性のある分割が行われます。\n",
    "\n",
    "# この分割により、訓練セットはモデルの学習に、検証セットはモデルの性能を評価するために使用されます。検証セットを用いて過学習を防ぐための調整も行います。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:54.546283Z",
     "iopub.status.busy": "2024-07-22T13:15:54.545898Z",
     "iopub.status.idle": "2024-07-22T13:15:54.554313Z",
     "shell.execute_reply": "2024-07-22T13:15:54.553124Z",
     "shell.execute_reply.started": "2024-07-22T13:15:54.546257Z"
    }
   },
   "outputs": [],
   "source": [
    "# データを訓練セットと検証セットに分割します\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)  \n",
    "# 訓練データを80%の訓練セットと20%の検証セットに分割します。random_stateを指定することで、再現性のある分割が行われます。\n",
    "\n",
    "# この分割により、訓練セットはモデルの学習に、検証セットはモデルの性能を評価するために使用されます。検証セットを用いて過学習を防ぐための調整も行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fbdc61",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Build the Keras model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,128))\n",
    "model.add(LSTM(64,return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(3,activation='softmax'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Kerasモデルを構築します\n",
    "model = Sequential()  # シーケンシャルモデルを初期化します\n",
    "model.add(Embedding(vocab_size, 128))  # 埋め込みレイヤーを追加し、語彙サイズに基づいて128次元のベクトルを生成します\n",
    "model.add(LSTM(64, return_sequences=True))  # LSTMレイヤーを追加し、64ユニットの出力を生成します（シーケンスを持つため、return_sequences=True）\n",
    "model.add(Dropout(0.5))  # ドロップアウトレイヤーを追加し、50%の確率でニューロンを無効化します\n",
    "model.add(LSTM(64))  # もう一つのLSTMレイヤーを追加し、最後の64ユニットの出力を生成します\n",
    "model.add(Dense(3, activation='softmax'))  # 出力層を追加し、3クラスの確率を出力します（softmax活性化関数を使用）\n",
    "\n",
    "# このモデルは、埋め込み、LSTM、ドロップアウト層を利用して、テキストデータからパターンを学習し、最終的に3つのクラス（モデルA、モデルB、引き分け）のいずれかを予測します。構築した後にモデルをコンパイルして学習させます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:15:57.016503Z",
     "iopub.status.busy": "2024-07-22T13:15:57.016103Z",
     "iopub.status.idle": "2024-07-22T13:15:57.071352Z",
     "shell.execute_reply": "2024-07-22T13:15:57.070332Z",
     "shell.execute_reply.started": "2024-07-22T13:15:57.016458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasモデルを構築します\n",
    "model = Sequential()  # シーケンシャルモデルを初期化します\n",
    "model.add(Embedding(vocab_size, 128))  # 埋め込みレイヤーを追加し、語彙サイズに基づいて128次元のベクトルを生成します\n",
    "model.add(LSTM(64, return_sequences=True))  # LSTMレイヤーを追加し、64ユニットの出力を生成します（シーケンスを持つため、return_sequences=True）\n",
    "model.add(Dropout(0.5))  # ドロップアウトレイヤーを追加し、50%の確率でニューロンを無効化します\n",
    "model.add(LSTM(64))  # もう一つのLSTMレイヤーを追加し、最後の64ユニットの出力を生成します\n",
    "model.add(Dense(3, activation='softmax'))  # 出力層を追加し、3クラスの確率を出力します（softmax活性化関数を使用）\n",
    "\n",
    "# このモデルは、埋め込み、LSTM、ドロップアウト層を利用して、テキストデータからパターンを学習し、最終的に3つのクラス（モデルA、モデルB、引き分け）のいずれかを予測します。構築した後にモデルをコンパイルして学習させます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ea4508",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルをコンパイルします\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "# 最適化アルゴリズムとしてAdamを使用し、損失関数にはカテゴリカルクロスエントロピーを指定します。また、モデルの評価指標として精度（accuracy）を使用します。\n",
    "\n",
    "# モデルをコンパイルすることで、学習プロセスを開始する準備が整います。この設定により、モデルは訓練データに対して学習を行い、誤差を最小化するように調整されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:16:00.056549Z",
     "iopub.status.busy": "2024-07-22T13:16:00.05614Z",
     "iopub.status.idle": "2024-07-22T13:16:00.079938Z",
     "shell.execute_reply": "2024-07-22T13:16:00.078747Z",
     "shell.execute_reply.started": "2024-07-22T13:16:00.056519Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルをコンパイルします\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  \n",
    "# 最適化アルゴリズムとしてAdamを使用し、損失関数にはカテゴリカルクロスエントロピーを指定します。また、モデルの評価指標として精度（accuracy）を使用します。\n",
    "\n",
    "# モデルをコンパイルすることで、学習プロセスを開始する準備が整います。この設定により、モデルは訓練データに対して学習を行い、誤差を最小化するように調整されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af59b6c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルを訓練します\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))  \n",
    "# 訓練データ（x_train, y_train）を使用してモデルを10エポック（epoch）学習させます。バッチサイズは32に設定され、検証データ（x_val, y_val）も指定して、検証精度を確認します。\n",
    "\n",
    "# このプロセスでは、モデルは訓練データから学習し、逐次エポックごとにパフォーマンスを向上させることを目指します。検証データを使って、過学習を避けつつモデルの性能を評価します。訓練の進行状況は、historyオブジェクトに保持され、後で可視化や分析に使用できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:16:03.871163Z",
     "iopub.status.busy": "2024-07-22T13:16:03.87076Z",
     "iopub.status.idle": "2024-07-22T13:18:26.729764Z",
     "shell.execute_reply": "2024-07-22T13:18:26.728544Z",
     "shell.execute_reply.started": "2024-07-22T13:16:03.871131Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルを訓練します\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))  \n",
    "# 訓練データ（x_train, y_train）を使用してモデルを10エポック（epoch）学習させます。バッチサイズは32に設定され、検証データ（x_val, y_val）も指定して、検証精度を確認します。\n",
    "\n",
    "# このプロセスでは、モデルは訓練データから学習し、逐次エポックごとにパフォーマンスを向上させることを目指します。検証データを使って、過学習を避けつつモデルの性能を評価します。訓練の進行状況は、historyオブジェクトに保持され、後で可視化や分析に使用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f297057",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Create a figure and a set of subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax1.plot(history.history['loss'], label='Train')\n",
    "ax1.plot(history.history['val_loss'], label='Validation')\n",
    "ax1.set_title('Model Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend(loc='upper right')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "ax2.plot(history.history['accuracy'], label='Train')\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation')\n",
    "ax2.set_title('Model Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend(loc='upper left')\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 図とサブプロットのセットを作成します\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))  # 1行2列のサブプロットを作成し、サイズを指定します\n",
    "\n",
    "# 訓練および検証の損失値をプロットします\n",
    "ax1.plot(history.history['loss'], label='Train')  # 訓練データの損失をプロット\n",
    "ax1.plot(history.history['val_loss'], label='Validation')  # 検証データの損失をプロット\n",
    "ax1.set_title('Model Loss')  # グラフのタイトルを設定\n",
    "ax1.set_xlabel('Epoch')  # x軸のラベルを設定\n",
    "ax1.set_ylabel('Loss')  # y軸のラベルを設定\n",
    "ax1.legend(loc='upper right')  # 凡例を右上に配置\n",
    "\n",
    "# 訓練および検証の精度値をプロットします\n",
    "ax2.plot(history.history['accuracy'], label='Train')  # 訓練データの精度をプロット\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation')  # 検証データの精度をプロット\n",
    "ax2.set_title('Model Accuracy')  # グラフのタイトルを設定\n",
    "ax2.set_xlabel('Epoch')  # x軸のラベルを設定\n",
    "ax2.set_ylabel('Accuracy')  # y軸のラベルを設定\n",
    "ax2.legend(loc='upper left')  # 凡例を左上に配置\n",
    "\n",
    "# レイアウトを調整して重なりを防ぎます\n",
    "plt.tight_layout()  # 自動的にレイアウトを調整します\n",
    "plt.show()  # グラフを表示します\n",
    "\n",
    "# これにより、訓練中のモデルの損失と精度の推移が可視化され、トレーニングの進行状況を確認することができます。訓練と検証の結果を比較することで、モデルの過学習や性能の適切性を評価する手助けになります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:18:33.627234Z",
     "iopub.status.busy": "2024-07-22T13:18:33.626834Z",
     "iopub.status.idle": "2024-07-22T13:18:34.312903Z",
     "shell.execute_reply": "2024-07-22T13:18:34.311353Z",
     "shell.execute_reply.started": "2024-07-22T13:18:33.627203Z"
    }
   },
   "outputs": [],
   "source": [
    "# 図とサブプロットのセットを作成します\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))  # 1行2列のサブプロットを作成し、サイズを指定します\n",
    "\n",
    "# 訓練および検証の損失値をプロットします\n",
    "ax1.plot(history.history['loss'], label='Train')  # 訓練データの損失をプロット\n",
    "ax1.plot(history.history['val_loss'], label='Validation')  # 検証データの損失をプロット\n",
    "ax1.set_title('Model Loss')  # グラフのタイトルを設定\n",
    "ax1.set_xlabel('Epoch')  # x軸のラベルを設定\n",
    "ax1.set_ylabel('Loss')  # y軸のラベルを設定\n",
    "ax1.legend(loc='upper right')  # 凡例を右上に配置\n",
    "\n",
    "# 訓練および検証の精度値をプロットします\n",
    "ax2.plot(history.history['accuracy'], label='Train')  # 訓練データの精度をプロット\n",
    "ax2.plot(history.history['val_accuracy'], label='Validation')  # 検証データの精度をプロット\n",
    "ax2.set_title('Model Accuracy')  # グラフのタイトルを設定\n",
    "ax2.set_xlabel('Epoch')  # x軸のラベルを設定\n",
    "ax2.set_ylabel('Accuracy')  # y軸のラベルを設定\n",
    "ax2.legend(loc='upper left')  # 凡例を左上に配置\n",
    "\n",
    "# レイアウトを調整して重なりを防ぎます\n",
    "plt.tight_layout()  # 自動的にレイアウトを調整します\n",
    "plt.show()  # グラフを表示します\n",
    "\n",
    "# これにより、訓練中のモデルの損失と精度の推移が可視化され、トレーニングの進行状況を確認することができます。訓練と検証の結果を比較することで、モデルの過学習や性能の適切性を評価する手助けになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042527b4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Prepare the test data\n",
    "x_test_prompt = tokenize_and_pad(test_df['prompt'],tokenizer, max_len)\n",
    "x_test_response_a = tokenize_and_pad(test_df['response_a'],tokenizer, max_len)\n",
    "x_test_response_b = tokenize_and_pad(test_df['response_b'],tokenizer, max_len)\n",
    "x_test = np.concatenate([x_test_prompt,x_test_response_a,x_test_response_b],axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータを準備します\n",
    "x_test_prompt = tokenize_and_pad(test_df['prompt'], tokenizer, max_len)  # テストデータのプロンプトをトークン化してパディング\n",
    "x_test_response_a = tokenize_and_pad(test_df['response_a'], tokenizer, max_len)  # テストデータの応答Aをトークン化してパディング\n",
    "x_test_response_b = tokenize_and_pad(test_df['response_b'], tokenizer, max_len)  # テストデータの応答Bをトークン化してパディング\n",
    "x_test = np.concatenate([x_test_prompt, x_test_response_a, x_test_response_b], axis=1)  # トークン化されたプロンプトと応答を結合してテストデータを作成\n",
    "\n",
    "# この処理により、テストデータも訓練データと同様の方法で前処理され、モデルに入力できる形式になります。モデルの推論を行うための準備が整います。テストデータは、最終的にモデルの性能を評価するために使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:18:45.064274Z",
     "iopub.status.busy": "2024-07-22T13:18:45.063845Z",
     "iopub.status.idle": "2024-07-22T13:18:45.073243Z",
     "shell.execute_reply": "2024-07-22T13:18:45.071753Z",
     "shell.execute_reply.started": "2024-07-22T13:18:45.06424Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータを準備します\n",
    "x_test_prompt = tokenize_and_pad(test_df['prompt'], tokenizer, max_len)  # テストデータのプロンプトをトークン化してパディング\n",
    "x_test_response_a = tokenize_and_pad(test_df['response_a'], tokenizer, max_len)  # テストデータの応答Aをトークン化してパディング\n",
    "x_test_response_b = tokenize_and_pad(test_df['response_b'], tokenizer, max_len)  # テストデータの応答Bをトークン化してパディング\n",
    "x_test = np.concatenate([x_test_prompt, x_test_response_a, x_test_response_b], axis=1)  # トークン化されたプロンプトと応答を結合してテストデータを作成\n",
    "\n",
    "# この処理により、テストデータも訓練データと同様の方法で前処理され、モデルに入力できる形式になります。モデルの推論を行うための準備が整います。テストデータは、最終的にモデルの性能を評価するために使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46a2f5f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Predict on the test data\n",
    "y_test_pred = model.predict(x_test)\n",
    "y_test_pred_labels = np.argmax(y_test_pred,axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータに対して予測を行います\n",
    "y_test_pred = model.predict(x_test)  # テストデータに対してモデルを用いて予測を行います\n",
    "y_test_pred_labels = np.argmax(y_test_pred, axis=1)  # 各サンプルの最大値のインデックスを取得し、予測ラベルを決定します\n",
    "\n",
    "# この予測により、テストデータに対するモデルの出力が得られ、予測されるクラス（勝者）がラベルとして取得されます。このラベルは、その後の評価や結果の分析に使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:18:48.344657Z",
     "iopub.status.busy": "2024-07-22T13:18:48.344222Z",
     "iopub.status.idle": "2024-07-22T13:18:48.755229Z",
     "shell.execute_reply": "2024-07-22T13:18:48.753979Z",
     "shell.execute_reply.started": "2024-07-22T13:18:48.344617Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに対して予測を行います\n",
    "y_test_pred = model.predict(x_test)  # テストデータに対してモデルを用いて予測を行います\n",
    "y_test_pred_labels = np.argmax(y_test_pred, axis=1)  # 各サンプルの最大値のインデックスを取得し、予測ラベルを決定します\n",
    "\n",
    "# この予測により、テストデータに対するモデルの出力が得られ、予測されるクラス（勝者）がラベルとして取得されます。このラベルは、その後の評価や結果の分析に使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54728e4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Convert predictions to binary columns\n",
    "test_df['winner_model_a'] = (y_test_pred_labels == 0).astype(float)\n",
    "test_df['winner_model_b'] = (y_test_pred_labels == 1).astype(float)\n",
    "test_df['winner_tie'] = (y_test_pred_labels == 2).astype(float)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測をバイナリカラムに変換します\n",
    "test_df['winner_model_a'] = (y_test_pred_labels == 0).astype(float)  # モデルAの予測が当たった場合は1、そうでなければ0を設定\n",
    "test_df['winner_model_b'] = (y_test_pred_labels == 1).astype(float)  # モデルBの予測が当たった場合は1、そうでなければ0を設定\n",
    "test_df['winner_tie'] = (y_test_pred_labels == 2).astype(float)  # 引き分けの予測が当たった場合は1、そうでなければ0を設定\n",
    "\n",
    "# ここでは、各モデルの勝者としての予測結果を表すバイナリカラムがtest_dfに追加されます。これにより、最終的な結果を容易に解釈できる形式となり、各モデルが選ばれた確率が明確に示されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:19:02.688609Z",
     "iopub.status.busy": "2024-07-22T13:19:02.688137Z",
     "iopub.status.idle": "2024-07-22T13:19:02.695314Z",
     "shell.execute_reply": "2024-07-22T13:19:02.694012Z",
     "shell.execute_reply.started": "2024-07-22T13:19:02.688574Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測をバイナリカラムに変換します\n",
    "test_df['winner_model_a'] = (y_test_pred_labels == 0).astype(float)  # モデルAの予測が当たった場合は1、そうでなければ0を設定\n",
    "test_df['winner_model_b'] = (y_test_pred_labels == 1).astype(float)  # モデルBの予測が当たった場合は1、そうでなければ0を設定\n",
    "test_df['winner_tie'] = (y_test_pred_labels == 2).astype(float)  # 引き分けの予測が当たった場合は1、そうでなければ0を設定\n",
    "\n",
    "# ここでは、各モデルの勝者としての予測結果を表すバイナリカラムがtest_dfに追加されます。これにより、最終的な結果を容易に解釈できる形式となり、各モデルが選ばれた確率が明確に示されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc9c80",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Save the predictions to submission.csv\n",
    "submission_df = test_df[['id','winner_model_a','winner_model_b','winner_tie']]\n",
    "submission_df.to_csv('submission.csv',index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測結果をsubmission.csvに保存します\n",
    "submission_df = test_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 提出用のデータフレームを作成\n",
    "submission_df.to_csv('submission.csv', index=False)  # CSVファイルとして保存（インデックスは含めない）\n",
    "\n",
    "# ここでは、テストデータのIDと予測された勝者モデルを含む予測結果をsubmission.csvというファイルに保存します。このファイルは、コンペティションに提出するためのフォーマットとして使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T13:19:05.10427Z",
     "iopub.status.busy": "2024-07-22T13:19:05.103861Z",
     "iopub.status.idle": "2024-07-22T13:19:05.117545Z",
     "shell.execute_reply": "2024-07-22T13:19:05.116362Z",
     "shell.execute_reply.started": "2024-07-22T13:19:05.104237Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測結果をsubmission.csvに保存します\n",
    "submission_df = test_df[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 提出用のデータフレームを作成\n",
    "submission_df.to_csv('submission.csv', index=False)  # CSVファイルとして保存（インデックスは含めない）\n",
    "\n",
    "# ここでは、テストデータのIDと予測された勝者モデルを含む予測結果をsubmission.csvというファイルに保存します。このファイルは、コンペティションに提出するためのフォーマットとして使用されます。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
