{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bafad64c",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」における人間の好み予測タスクに取り組んでいます。主な目的は、ユーザーが異なるチャットボットからの応答の中でどちらを選ぶかを予測するためのモデルを開発することです。ノートブックではトレーニングデータのサイズが大きいため、そのわずか0.5%のみを使用して、データのクリーニングと特徴量エンジニアリングを行います。\n",
    "\n",
    "### 使用される手法やライブラリ\n",
    "1. **データ処理と分析**:\n",
    "   - `pandas`, `numpy`: データフレームの操作や数値計算。\n",
    "   - `textstat`: テキストの読みやすさや統計分析。\n",
    "   - `SweetViz`: データ分析と視覚化。\n",
    "\n",
    "2. **自然言語処理**:\n",
    "   - `nltk`: ストップワードの取得やテキストの分析。\n",
    "   - `transformers`: BERTモデルを用いたトークン化と埋め込み生成。\n",
    "\n",
    "3. **機械学習**:\n",
    "   - `scikit-learn`: データの分割、モデル評価、さまざまな分類器（ランダムフォレスト、勾配ブースティング、サポートベクターマシンなど）の実装。\n",
    "   - `tensorflow`: ニューラルネットワークモデルの構築とトレーニング。\n",
    "\n",
    "### 主な工程\n",
    "- **データの読み込みと前処理**: トレーニングデータとテストデータをCSVから読み込み、クリーニングを実施（特殊文字の削除、正規化など）。\n",
    "- **特徴量エンジニアリング**: テキストの単語数、文字数、感情分析、およびBERTを用いた埋め込み生成を含む多様な特徴量を抽出。\n",
    "- **モデルの構築と評価**: 複数の機械学習モデルをトレーニングし、その性能を精度やログ損失を用いて評価。最良のモデルを選択します。\n",
    "- **テストデータに対する予測**: 最良モデルを用いてテストデータに対する予測を実施し、提出用フォーマットでCSVファイルを生成。\n",
    "\n",
    "このノートブックは、機械学習や自然言語処理を用いて実際の問題にアプローチし、チャットボットの応答のユーザー選好を予測するための包括的なフレームワークを提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fcca75",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookにおいて初心者がつまずきそうな専門用語の簡単な解説です。特にこのノートブック特有のドメイン知識や、実務未経験者にはなじみが薄い用語に焦点を当てています。\n",
    "\n",
    "1. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが設計した特化型ハードウェアで、特に機械学習のために最適化されているプロセッサです。通常のGPUよりも大規模なモデルを高速にトレーニングできます。\n",
    "\n",
    "2. **埋め込み (Embedding)**:\n",
    "   - 単語や文などの高次元のデータを低次元のベクトルに変換する手法です。意味情報を保持しつつ、計算効率を向上させるために使います。BERTのような言語モデルでは、言語の意味を理解するために重要です。\n",
    "\n",
    "3. **VADER (Valence Aware Dictionary and sEntiment Reasoner)**:\n",
    "   - 主にソーシャルメディアでの感情分析に対応した辞書およびルールベースの手法です。ポジティブやネガティブな感情をスコアとして評価し、特に短いテキストや感情的な表現に効果的です。\n",
    "\n",
    "4. **Flesch Reading Easeスコア**:\n",
    "   - テキストの読みやすさを数値化した指標で、高いスコアほど読みやすいことを示します。文の長さや音節数を考慮して計算されます。\n",
    "\n",
    "5. **コサイン類似度 (Cosine Similarity)**:\n",
    "   - 二つのベクトルのコサインの角度を基準にした類似度指標です。1に近いほど似ていることを示し、主に情報検索や自然言語処理で使用されます。\n",
    "\n",
    "6. **ドロップアウト (Dropout)**:\n",
    "   - ニューラルネットワークの訓練中に、過学習を防ぐためにランダムに一定の割合のニューロンを「ドロップ」する手法です。これにより、モデルの一般化能力が向上します。\n",
    "\n",
    "7. **ログ損失 (Log Loss)**:\n",
    "   - 分類問題におけるモデルの性能を評価するための指標で、確率的な予測に対する損失を計算します。モデルが予測した確率と実際のラベルとの違いを反映します。\n",
    "\n",
    "8. **シーケンス (Sequence)**:\n",
    "   - 一連のデータポイントの配列で、通常は時系列データやテキストのように順序が重要なデータに使用されます。\n",
    "\n",
    "9. **トークン化 (Tokenization)**:\n",
    "   - テキストを単語やフレーズといった「トークン」に分割する過程です。機械学習モデルがテキストを理解するために不可欠な第一歩です。\n",
    "\n",
    "10. **特徴量エンジニアリング (Feature Engineering)**:\n",
    "    - 生データから機械学習モデルが有用な情報を引き出すための特徴量を生成、選択、変換するプロセスです。モデル性能に大きく影響します。\n",
    "\n",
    "この解説リストが、ノートブックを理解するのに役立つことを願っています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cfad1b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# LMSYS - Chatbot Arena Human Preference Predictions\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# LMSYS - Chatbot Arenaでの人間の好み予測\n",
    "\n",
    "\n",
    "\n",
    "**トレーニングデータのサイズが大きいため、私はトレーニングデータのわずか0.5%のみを使用しています！**\n",
    "\n",
    "作業中：TPUを使用して別のノートブックで埋め込みを計算し、フルトレーニングデータを使用した後、ここに埋め込みをロードします！\n",
    "\n",
    "## ライブラリのインストールと読み込み\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8292d5c4",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "**Due to the size of the train data, and I only using 0.5% of the train data!**\n",
    "\n",
    "WIP: Compute embeddings using TPU in a differente notebook to use the full train data and then load the embeddings here!\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "!pip install textstat SweetViz  # textstatとSweetVizをインストールします。\n",
    "\n",
    "# textstatはテキストの統計情報を分析するためのライブラリで、例えば読みやすさのスコアを計算することができます。\n",
    "# SweetVizはデータの可視化を提供するライブラリで、データセットの探索に役立ちます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42759bf",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Install and load libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "import warnings  # 警告を表示しないように設定します。\n",
    "warnings.filterwarnings('ignore')  # すべての警告を無視します。\n",
    "\n",
    "import pandas as pd  # データ操作のためのライブラリ\n",
    "import numpy as np  # 数値計算のためのライブラリ\n",
    "\n",
    "import seaborn as sns  # データの可視化に役立つライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフを描画するためのライブラリ\n",
    "import plotly.express as px  # インタラクティブなグラフを描画するためのライブラリ\n",
    "import sweetviz as sv  # データセットの探索に役立つ可視化ライブラリ\n",
    "\n",
    "import re  # 正規表現を扱うためのライブラリ\n",
    "import string  # 文字列操作のためのライブラリ\n",
    "import nltk  # 自然言語処理のためのライブラリ\n",
    "from nltk.corpus import stopwords  # ストップワード（意味を持たない単語）のリストを取得するためのモジュール\n",
    "\n",
    "import tensorflow as tf  # 機械学習と深層学習のフレームワーク\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # テキストのトークン化を行うためのクラス\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # シーケンスを一定の長さにパディングするための関数\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer  # 感情分析を行うためのモジュール\n",
    "\n",
    "import textstat  # テキストの統計情報を計算するためのライブラリ\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータを数値に変換するためのクラス\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # データセットをトレーニングとテストに分割するための関数\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # コサイン類似度を計算するための関数\n",
    "from transformers import BertTokenizer, TFBertModel  # BERTトークン化とBERTモデルを使用するためのライブラリ\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # ランダムフォレストと勾配ブースティングのクラス\n",
    "from sklearn.svm import SVC  # サポートベクターマシンのクラス\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # Kerasのシーケンシャルモデル\n",
    "from tensorflow.keras.layers import Dense, Dropout  # 全結合層とドロップアウト層\n",
    "from tensorflow.keras.optimizers import Adam  # Adamオプティマイザ\n",
    "\n",
    "from sklearn.metrics import accuracy_score, \\  # 精度を評価するための関数\n",
    "                            log_loss, \\  # ログ損失を評価するための関数\n",
    "                            confusion_matrix, \\  # 混同行列を計算するための関数\n",
    "                            classification_report  # 分類結果のレポートを生成するための関数\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b9b36",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install textstat SweetViz\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "nltk.download('stopwords')  # NLTKライブラリからストップワードのリストをダウンロードします。\n",
    "stop_words = set(stopwords.words('english'))  # 英語のストップワードを取得し、セットとして格納します。\n",
    "\n",
    "# ストップワードとは、テキストデータの中で特に意味を持たない単語のことであり、\n",
    "# これを除外することで、テキスト分析の精度を向上させることができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:26.629331Z",
     "iopub.status.busy": "2024-07-15T10:34:26.628304Z",
     "iopub.status.idle": "2024-07-15T10:34:26.705902Z",
     "shell.execute_reply": "2024-07-15T10:34:26.704543Z",
     "shell.execute_reply.started": "2024-07-15T10:34:26.629283Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')  # NLTKライブラリからストップワードのリストをダウンロードします。\n",
    "stop_words = set(stopwords.words('english'))  # 英語のストップワードを取得し、セットとして格納します。\n",
    "\n",
    "# ストップワードとは、テキストデータの中で特に意味を持たない単語のことであり、\n",
    "# これを除外することで、テキスト分析の精度を向上させることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62556be",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import sweetviz as sv\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "import textstat\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import accuracy_score, \\\n",
    "                            log_loss, \\\n",
    "                            confusion_matrix, \\\n",
    "                            classification_report\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "## データの読み込み\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1e9ed",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4341d7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込みます。\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "\n",
    "# pd.read_csv関数は、指定されたファイルパスからCSV形式のデータを読み込むための関数です。\n",
    "# 読み込まれたデータはpandasのDataFrame形式で格納され、データの操作や分析に利用できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:26.709185Z",
     "iopub.status.busy": "2024-07-15T10:34:26.708734Z",
     "iopub.status.idle": "2024-07-15T10:34:30.485346Z",
     "shell.execute_reply": "2024-07-15T10:34:30.483633Z",
     "shell.execute_reply.started": "2024-07-15T10:34:26.709137Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込みます。\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "\n",
    "# pd.read_csv関数は、指定されたファイルパスからCSV形式のデータを読み込むための関数です。\n",
    "# 読み込まれたデータはpandasのDataFrame形式で格納され、データの操作や分析に利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7c4b5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Loading data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 探索的データ分析（EDA）\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309d43a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_analysis = sv.analyze(train_data)  # トレーニングデータに対してSweetVizを用いて分析を行います。\n",
    "\n",
    "# sv.analyze関数は、指定されたデータセットに関する詳細なレポートを生成し、\n",
    "# データの特性や分布を視覚的に示すための情報を提供します。 \n",
    "# このレポートは、データの概要を把握するのに役立ちます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:30.487034Z",
     "iopub.status.busy": "2024-07-15T10:34:30.486668Z",
     "iopub.status.idle": "2024-07-15T10:34:39.325863Z",
     "shell.execute_reply": "2024-07-15T10:34:39.32424Z",
     "shell.execute_reply.started": "2024-07-15T10:34:30.487001Z"
    }
   },
   "outputs": [],
   "source": [
    "train_analysis = sv.analyze(train_data)  # トレーニングデータに対してSweetVizを用いて分析を行います。\n",
    "\n",
    "# sv.analyze関数は、指定されたデータセットに関する詳細なレポートを生成し、\n",
    "# データの特性や分布を視覚的に示すための情報を提供します。 \n",
    "# このレポートは、データの概要を把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987873cf",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "train_analysis.show_html('train_analysis.html')  # SweetVizによるトレーニングデータの分析結果をHTMLファイルとして保存します。\n",
    "\n",
    "# show_html関数は、分析結果をHTML形式で出力し、指定されたファイル名で保存します。\n",
    "# このHTMLファイルは、データの可視化や分析結果をブラウザで確認するのに便利です。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b6eb03",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_analysis = sv.analyze(train_data)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data.head()  # トレーニングデータの最初の5行を表示します。\n",
    "\n",
    "# head()関数は、DataFrameの最初の数行を表示するための関数で、\n",
    "# データの構造や内容をすばやく確認するのに役立ちます。\n",
    "# 引数を指定することで、表示する行数を変更することも可能です。デフォルトでは5行表示されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.679353Z",
     "iopub.status.busy": "2024-07-15T10:34:39.678987Z",
     "iopub.status.idle": "2024-07-15T10:34:39.700291Z",
     "shell.execute_reply": "2024-07-15T10:34:39.699087Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.679322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()  # トレーニングデータの最初の5行を表示します。\n",
    "\n",
    "# head()関数は、DataFrameの最初の数行を表示するための関数で、\n",
    "# データの構造や内容をすばやく確認するのに役立ちます。\n",
    "# 引数を指定することで、表示する行数を変更することも可能です。デフォルトでは5行表示されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8537945",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_analysis.show_html('train_analysis.html')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "print(\"Training Data -\", train_data.shape)  # トレーニングデータの形状（行数と列数）を表示します。\n",
    "print(\"Test Data -\", test_data.shape)  # テストデータの形状（行数と列数）を表示します。\n",
    "\n",
    "# shape属性は、データフレームの行数と列数をタプル形式で返します。\n",
    "# これにより、データセットのサイズを簡単に把握することができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.702126Z",
     "iopub.status.busy": "2024-07-15T10:34:39.701764Z",
     "iopub.status.idle": "2024-07-15T10:34:39.708363Z",
     "shell.execute_reply": "2024-07-15T10:34:39.707161Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.702092Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Data -\", train_data.shape)  # トレーニングデータの形状（行数と列数）を表示します。\n",
    "print(\"Test Data -\", test_data.shape)  # テストデータの形状（行数と列数）を表示します。\n",
    "\n",
    "# shape属性は、データフレームの行数と列数をタプル形式で返します。\n",
    "# これにより、データセットのサイズを簡単に把握することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2ea95e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data.describe(include=['O'])  # トレーニングデータのオブジェクト型（文字列）の列に関する要約統計量を表示します。\n",
    "\n",
    "# describe()関数は、データフレームの基本的な統計情報を提供します。\n",
    "# include=['O']を指定することで、オブジェクト型の列（通常は文字列データ）のみを対象にした要約が取得できます。\n",
    "# 出力には、ユニークな値の数や最頻値などが含まれ、データの特徴を把握するのに役立ちます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.710466Z",
     "iopub.status.busy": "2024-07-15T10:34:39.709973Z",
     "iopub.status.idle": "2024-07-15T10:34:39.979519Z",
     "shell.execute_reply": "2024-07-15T10:34:39.977988Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.710412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.describe(include=['O'])  # トレーニングデータのオブジェクト型（文字列）の列に関する要約統計量を表示します。\n",
    "\n",
    "# describe()関数は、データフレームの基本的な統計情報を提供します。\n",
    "# include=['O']を指定することで、オブジェクト型の列（通常は文字列データ）のみを対象にした要約が取得できます。\n",
    "# 出力には、ユニークな値の数や最頻値などが含まれ、データの特徴を把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d38f76",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(\"Training Data -\", train_data.shape)\n",
    "print(\"Test Data -\", test_data.shape)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "print(train_data.info())  # トレーニングデータの情報を表示します。\n",
    "\n",
    "# info()関数は、データフレームの構造に関する詳細情報を提供します。\n",
    "# 出力には、各列のデータ型、非NULL値のカウント、メモリの使用量などが含まれます。\n",
    "# これにより、データセットの各列の状態を簡単に確認することができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.985526Z",
     "iopub.status.busy": "2024-07-15T10:34:39.985109Z",
     "iopub.status.idle": "2024-07-15T10:34:40.039905Z",
     "shell.execute_reply": "2024-07-15T10:34:40.038678Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.985495Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data.info())  # トレーニングデータの情報を表示します。\n",
    "\n",
    "# info()関数は、データフレームの構造に関する詳細情報を提供します。\n",
    "# 出力には、各列のデータ型、非NULL値のカウント、メモリの使用量などが含まれます。\n",
    "# これにより、データセットの各列の状態を簡単に確認することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2015b847",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.describe(include=['O'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data.drop(\"id\", axis=1).duplicated().sum()  # \"id\"列を除いたトレーニングデータの重複行の数をカウントします。\n",
    "\n",
    "# drop(\"id\", axis=1)は、\"id\"という列をデータフレームから削除します。\n",
    "# duplicated()メソッドは、重複している行を検出し、重複行に対してTrueを返します。\n",
    "# sum()は、Trueの合計を計算し、重複行の総数を返します。 \n",
    "# これにより、データセット内の重複するデータの有無を確認できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:40.041517Z",
     "iopub.status.busy": "2024-07-15T10:34:40.041135Z",
     "iopub.status.idle": "2024-07-15T10:34:40.551835Z",
     "shell.execute_reply": "2024-07-15T10:34:40.550554Z",
     "shell.execute_reply.started": "2024-07-15T10:34:40.041484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(\"id\", axis=1).duplicated().sum()  # \"id\"列を除いたトレーニングデータの重複行の数をカウントします。\n",
    "\n",
    "# drop(\"id\", axis=1)は、\"id\"という列をデータフレームから削除します。\n",
    "# duplicated()メソッドは、重複している行を検出し、重複行に対してTrueを返します。\n",
    "# sum()は、Trueの合計を計算し、重複行の総数を返します。 \n",
    "# これにより、データセット内の重複するデータの有無を確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334a254",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(train_data.info())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "14行の重複が存在し、7つのグループを形成しています。私は各グループごとに1行のみを保持します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abad8c",
   "metadata": {},
   "source": [
    "14行の重複が存在し、7つのグループを形成しています。私は各グループごとに1行のみを保持します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6807b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.drop(\"id\", axis=1).duplicated().sum()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data = train_data.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、先頭の行を保持します。\n",
    "\n",
    "# drop_duplicates()メソッドは、データフレーム内の重複行を削除します。\n",
    "# 引数keep=\"first\"は、最初の出現を保持し、他の重複行を削除することを指定します。\n",
    "# ignore_index=Trueを指定することで、インデックスをリセットし、新たな連続したインデックスを付与します。\n",
    "# これにより、重複行が削除された後でも、インデックスが整然とした状態になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:40.55393Z",
     "iopub.status.busy": "2024-07-15T10:34:40.553437Z",
     "iopub.status.idle": "2024-07-15T10:34:41.059542Z",
     "shell.execute_reply": "2024-07-15T10:34:41.058435Z",
     "shell.execute_reply.started": "2024-07-15T10:34:40.553889Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、先頭の行を保持します。\n",
    "\n",
    "# drop_duplicates()メソッドは、データフレーム内の重複行を削除します。\n",
    "# 引数keep=\"first\"は、最初の出現を保持し、他の重複行を削除することを指定します。\n",
    "# ignore_index=Trueを指定することで、インデックスをリセットし、新たな連続したインデックスを付与します。\n",
    "# これにより、重複行が削除された後でも、インデックスが整然とした状態になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18be71",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "There exist 14 duplicated rows forming 7 groups, I will just keep one row per group.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "`id`列に関してトレーニングデータの品質を確認します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67ba73",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = train_data.drop_duplicates(keep=\"first\", ignore_index=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data.nunique()  # トレーニングデータの各列におけるユニークな値の数を表示します。\n",
    "\n",
    "# nunique()メソッドは、データフレーム内の各列においてユニークな値の個数を計算します。\n",
    "# この情報は、各列のデータにどれだけのバリエーションがあるかを把握するのに役立ちます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.061181Z",
     "iopub.status.busy": "2024-07-15T10:34:41.060808Z",
     "iopub.status.idle": "2024-07-15T10:34:41.60334Z",
     "shell.execute_reply": "2024-07-15T10:34:41.602224Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.061135Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.nunique()  # トレーニングデータの各列におけるユニークな値の数を表示します。\n",
    "\n",
    "# nunique()メソッドは、データフレーム内の各列においてユニークな値の個数を計算します。\n",
    "# この情報は、各列のデータにどれだけのバリエーションがあるかを把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec9602",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Checking the quality of the train data with respect the `id` column.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "assert train_data[\"id\"].nunique() == len(train_data)  # `id`列のユニークな値の数がトレーニングデータの行数と等しいことを確認します。\n",
    "\n",
    "# assert文は、指定された条件がTrueであることをチェックします。\n",
    "# もし条件が満たされない場合、エラーが発生し、プログラムの実行が停止します。\n",
    "# この条件により、`id`列に重複がないこと（すなわち、全ての`id`がユニークであること）を確認しています。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff41942",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.nunique()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data.isna().sum()  # トレーニングデータの各列における欠損値（NaN）の合計を表示します。\n",
    "\n",
    "# isna()メソッドは、データフレームの各セルが欠損値であるかどうかを確認し、ブーリアン値（TrueまたはFalse）を返します。\n",
    "# sum()関数を使用することで、各列に含まれる欠損値の合計を計算し、結果を表示します。\n",
    "# この情報は、データのクリーニングや前処理において欠損値の処理を行う前に確認するのに役立ちます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.615433Z",
     "iopub.status.busy": "2024-07-15T10:34:41.615071Z",
     "iopub.status.idle": "2024-07-15T10:34:41.666185Z",
     "shell.execute_reply": "2024-07-15T10:34:41.664758Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.615402Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.isna().sum()  # トレーニングデータの各列における欠損値（NaN）の合計を表示します。\n",
    "\n",
    "# isna()メソッドは、データフレームの各セルが欠損値であるかどうかを確認し、ブーリアン値（TrueまたはFalse）を返します。\n",
    "# sum()関数を使用することで、各列に含まれる欠損値の合計を計算し、結果を表示します。\n",
    "# この情報は、データのクリーニングや前処理において欠損値の処理を行う前に確認するのに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb60954",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "assert train_data[\"id\"].nunique() == len(train_data)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "### 分布\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab10f6",
   "metadata": {},
   "source": [
    "### 分布"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c26cae",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data.isna().sum()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model_df = pd.concat([train_data.model_a, train_data.model_b])  # model_aとmodel_bの列を結合します。\n",
    "counts = model_df.value_counts().reset_index()  # 各モデルの出現回数をカウントし、データフレームにリセットします。\n",
    "counts.columns = ['LLM', 'Count']  # カラム名を設定します。\n",
    "\n",
    "# Plotlyを使用してカスタムスタイルの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='モデルの分布',\n",
    "             color='Count')  # モデルに応じた色を設定します。\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # x軸のラベルを45度回転させて見やすくします。\n",
    "\n",
    "fig.show()  # グラフを表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.668356Z",
     "iopub.status.busy": "2024-07-15T10:34:41.667864Z",
     "iopub.status.idle": "2024-07-15T10:34:43.90637Z",
     "shell.execute_reply": "2024-07-15T10:34:43.905165Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.668315Z"
    }
   },
   "outputs": [],
   "source": [
    "model_df = pd.concat([train_data.model_a, train_data.model_b])  # model_aとmodel_bの列を結合します。\n",
    "counts = model_df.value_counts().reset_index()  # 各モデルの出現回数をカウントし、データフレームにリセットします。\n",
    "counts.columns = ['LLM', 'Count']  # カラム名を設定します。\n",
    "\n",
    "# Plotlyを使用してカスタムスタイルの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='モデルの分布',\n",
    "             color='Count')  # モデルに応じた色を設定します。\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # x軸のラベルを45度回転させて見やすくします。\n",
    "\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb22e69c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Distribution\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "counts_a = train_data['winner_model_a'].value_counts().reset_index()  # モデルAの勝利数をカウントします。\n",
    "counts_b = train_data['winner_model_b'].value_counts().reset_index()  # モデルBの勝利数をカウントします。\n",
    "counts_tie = train_data['winner_tie'].value_counts().reset_index()  # 引き分けの数をカウントします。\n",
    "\n",
    "# 分かりやすくするためにカラム名を変更します。\n",
    "counts_a.columns = ['Winner', 'Count']\n",
    "counts_b.columns = ['Winner', 'Count']\n",
    "counts_tie.columns = ['Winner', 'Count']\n",
    "\n",
    "# モデルを識別するためのカラムを追加します。\n",
    "counts_a['Model'] = 'Model A'\n",
    "counts_b['Model'] = 'Model B'\n",
    "counts_tie['Model'] = 'Tie'\n",
    "\n",
    "# すべてのカウントを結合します。\n",
    "counts = pd.concat([counts_a, counts_b, counts_tie])\n",
    "\n",
    "# カスタムスタイルの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='Model', y='Count', \n",
    "             color='Model',\n",
    "             title='トレーニングデータの勝者分布',\n",
    "             labels={'Model': 'モデル', 'Count': '勝利数', 'Winner': '勝者'})\n",
    "\n",
    "fig.update_layout(xaxis_title=\"モデル\", yaxis_title=\"勝利数\")  # x軸とy軸のタイトルを設定します。\n",
    "\n",
    "fig.show()  # グラフを表示します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4716d65",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_df = pd.concat([train_data.model_a, train_data.model_b])\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Create a bar plot with custom styling using Plotly\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='Distribution of LLMs',\n",
    "             color='Count')\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # Rotate x-axis labels for better readability\n",
    "\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "結論:\n",
    "\n",
    "* トレーニングデータは57,477行、テストデータは3行です。\n",
    "    * 注: スコアリングフェーズ中にテストデータは完全なテストセット（約25,000行、70%はプライベートLB用）に置き換えられます。\n",
    "* `id`列には重複値がありません。\n",
    "* モデルの識別子はテストセットでは明らかにされていません。\n",
    "* `prompt`、`response_a`、`response_b`の各列の文字列はリストにラップされています。\n",
    "    * これは、各チャットが複数のプロンプト/レスポンスのペアを含む可能性があるためです。\n",
    "* `id`列を削除した後、14行の重複が存在し、7つのグループを形成しています。各グループごとに1行だけを保持した結果、トレーニングデータフレームの形状は(57,470, 8)になります。\n",
    "\n",
    "## データ準備と特徴量エンジニアリング\n",
    "\n",
    "* データのクリーニング: 特殊文字を削除し、小文字に正規化し、ストップワードを削除し、トークン化するなどのテキストをクリーンアップします。\n",
    "* 入力のトークン化: トレーニングデータに基づいてTensorFlow/Kerasのトークナイザーを使用し、トレーニングデータとテストデータの両方にフィットさせます。\n",
    "* シーケンスを`max_len`にパディングします。\n",
    "* BERT埋め込みを作成します。\n",
    "* 各モデルのプロンプトとレスポンス間でBERTを使用した類似度特徴量を計算します。\n",
    "* 各レスポンスについて、単語数、文字数、語彙の多様性を計算します。\n",
    "* BERTモデル用にテキスト入力をトークン化します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5bebf",
   "metadata": {},
   "source": [
    "結論:\n",
    "\n",
    "* トレーニングデータは57,477行、テストデータは3行です。\n",
    "    * 注: スコアリングフェーズ中にテストデータは完全なテストセット（約25,000行、70%はプライベートLB用）に置き換えられます。\n",
    "* `id`列には重複値がありません。\n",
    "* モデルの識別子はテストセットでは明らかにされていません。\n",
    "* `prompt`、`response_a`、`response_b`の各列の文字列はリストにラップされています。\n",
    "    * これは、各チャットが複数のプロンプト/レスポンスのペアを含む可能性があるためです。\n",
    "* `id`列を削除した後、14行の重複が存在し、7つのグループを形成しています。各グループごとに1行だけを保持した結果、トレーニングデータフレームの形状は(57,470, 8)になります。\n",
    "\n",
    "## データ準備と特徴量エンジニアリング\n",
    "\n",
    "* データのクリーニング: 特殊文字を削除し、小文字に正規化し、ストップワードを削除し、トークン化するなどのテキストをクリーンアップします。\n",
    "* 入力のトークン化: トレーニングデータに基づいてTensorFlow/Kerasのトークナイザーを使用し、トレーニングデータとテストデータの両方にフィットさせます。\n",
    "* シーケンスを`max_len`にパディングします。\n",
    "* BERT埋め込みを作成します。\n",
    "* 各モデルのプロンプトとレスポンス間でBERTを使用した類似度特徴量を計算します。\n",
    "* 各レスポンスについて、単語数、文字数、語彙の多様性を計算します。\n",
    "* BERTモデル用にテキスト入力をトークン化します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005c796e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "counts_a = train_data['winner_model_a'].value_counts().reset_index()\n",
    "counts_b = train_data['winner_model_b'].value_counts().reset_index()\n",
    "counts_tie = train_data['winner_tie'].value_counts().reset_index()\n",
    "\n",
    "# Renaming columns for convinience\n",
    "counts_a.columns = ['Winner', 'Count']\n",
    "counts_b.columns = ['Winner', 'Count']\n",
    "counts_tie.columns = ['Winner', 'Count']\n",
    "\n",
    "# Adding column to identify the model\n",
    "counts_a['Model'] = 'Model A'\n",
    "counts_b['Model'] = 'Model B'\n",
    "counts_tie['Model'] = 'Tie'\n",
    "\n",
    "counts = pd.concat([counts_a, counts_b, counts_tie])\n",
    "\n",
    "fig = px.bar(counts, x='Model', y='Count', \n",
    "             color='Model',\n",
    "             title='Winner Distribution for Train Data',\n",
    "             labels={'Model': 'Model', 'Count': 'Win Count', 'Winner': 'Winner'})\n",
    "\n",
    "fig.update_layout(xaxis_title=\"Model\", yaxis_title=\"Win Count\")\n",
    "\n",
    "fig.show()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv').sample(frac=0.001)  # トレーニングデータをCSVファイルから読み込み、全体の0.1%をサンプリングします。\n",
    "\n",
    "# read_csv()関数は、指定されたファイルパスからCSV形式のデータを読み込みます。\n",
    "# sample(frac=0.001)は、データフレームから全体の0.1%（0.001）のランダムなサンプルを抽出します。\n",
    "# これにより、大規模なデータセットの一部を使用して迅速に実験や分析を行うことができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:44.037769Z",
     "iopub.status.busy": "2024-07-15T10:34:44.037333Z",
     "iopub.status.idle": "2024-07-15T10:34:46.277777Z",
     "shell.execute_reply": "2024-07-15T10:34:46.276634Z",
     "shell.execute_reply.started": "2024-07-15T10:34:44.037729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv').sample(frac=0.001)  # トレーニングデータをCSVファイルから読み込み、全体の0.1%をサンプリングします。\n",
    "\n",
    "# read_csv()関数は、指定されたファイルパスからCSV形式のデータを読み込みます。\n",
    "# sample(frac=0.001)は、データフレームから全体の0.1%（0.001）のランダムなサンプルを抽出します。\n",
    "# これにより、大規模なデータセットの一部を使用して迅速に実験や分析を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130545d8",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Conclusions:\n",
    "\n",
    "* There are 57477 training rows and 3 test rows.\n",
    "    * Note: Test data will be replaced with the full test set (~25k rows, 70% for private LB) during scoring phase.\n",
    "* The column `id` has no duplicated values.\n",
    "* Model identities aren't revealed in the test set.\n",
    "* Strings in columns prompt, `response_a`, and `response_a` are wrapped in a list. \n",
    "    * The reason is that each chat can contains more than one prompt/response pairs.\n",
    "* After dropping `id` column, there exist 14 duplicated rows forming 7 groups, we just keep one row per group and shape of the training DataFrame becomes (57470, 8).\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### データのクリーニング\n",
    "\n",
    "特殊文字を削除し、小文字に正規化し、ストップワードを削除するなどのクリーンなテキストを作成します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187c316",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Data preparation and Feature Engineering\n",
    "\n",
    "* Cleaning data: clean text, such as removing special characters, normalizing to lowercase, removing stopwords and tokenizing.\n",
    "* Tokenize Inputs: using the TensorFlow/Kerar tokenizer by training on training data and fitting on both training and test data.\n",
    "* Padding sequences to `max_len`.\n",
    "* Create BERT embeddings.\n",
    "* Compute Similarity Features using BERT between the prompt and responses for each model. \n",
    "* Compute word count, character count, and lexical diversity for each response.\n",
    "* Tokenize the text inputs for the BERT model.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "def clean_text(text):  # テキストをクリーンアップするための関数を定義します。\n",
    "    text = text.lower()  # テキストを小文字に変換します。\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # 括弧内の内容を削除します。\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # URLを削除します。\n",
    "    text = re.sub(r'<.*?>+', '', text)  # HTMLタグを削除します。\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # 句読点を削除します。\n",
    "    text = re.sub(r'\\n', '', text)  # 改行を削除します。\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # 数字を含む単語を削除します。\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)  # ストップワードを削除し、単語を再結合します。\n",
    "    return text  # クリーンアップされたテキストを返します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40f6c5d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv').sample(frac=0.001)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストのクリーニングを行います。\n",
    "train_data['prompt_clean'] = train_data['prompt'].apply(clean_text)  # 'prompt'列にclean_text関数を適用し、クリーニングした結果を'prompt_clean'列に格納します。\n",
    "train_data['response_a_clean'] = train_data['response_a'].apply(clean_text)  # 'response_a'列にclean_text関数を適用し、クリーニングした結果を'response_a_clean'列に格納します。\n",
    "train_data['response_b_clean'] = train_data['response_b'].apply(clean_text)  # 'response_b'列にclean_text関数を適用し、クリーニングした結果を'response_b_clean'列に格納します。\n",
    "\n",
    "# apply()メソッドは、指定した関数をデータフレームの各要素に適用し、新しいシリーズを返します。\n",
    "# これにより、元のテキストデータがクリーニングされ、分析やモデルの入力に適した形式へと変換されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.290769Z",
     "iopub.status.busy": "2024-07-15T10:34:46.290311Z",
     "iopub.status.idle": "2024-07-15T10:34:46.316756Z",
     "shell.execute_reply": "2024-07-15T10:34:46.315617Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.290725Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストのクリーニングを行います。\n",
    "train_data['prompt_clean'] = train_data['prompt'].apply(clean_text)  # 'prompt'列にclean_text関数を適用し、クリーニングした結果を'prompt_clean'列に格納します。\n",
    "train_data['response_a_clean'] = train_data['response_a'].apply(clean_text)  # 'response_a'列にclean_text関数を適用し、クリーニングした結果を'response_a_clean'列に格納します。\n",
    "train_data['response_b_clean'] = train_data['response_b'].apply(clean_text)  # 'response_b'列にclean_text関数を適用し、クリーニングした結果を'response_b_clean'列に格納します。\n",
    "\n",
    "# apply()メソッドは、指定した関数をデータフレームの各要素に適用し、新しいシリーズを返します。\n",
    "# これにより、元のテキストデータがクリーニングされ、分析やモデルの入力に適した形式へと変換されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662d4a6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Cleaning data\n",
    "\n",
    "Clean text, such as removing special characters, normalizing to lowercase and removing stopwords.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### 入力のトークン化\n",
    "\n",
    "TensorFlow/Kerasのトークナイザーを使用して、トレーニングデータとテストデータの両方に対してトークン化を行います。シーケンスを`max_len`にパディングします。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea014a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'<.*?>+', '', text)\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "max_len = 512  # シーケンスの最大長を512に設定します。\n",
    "\n",
    "# max_lenは、BERTなどのトランスフォーマーモデルで処理できる入力シーケンスの最大の長さを指定します。\n",
    "# これにより、すべての入力が均一な長さになるようにパディングやカットが適用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.319341Z",
     "iopub.status.busy": "2024-07-15T10:34:46.318825Z",
     "iopub.status.idle": "2024-07-15T10:34:46.326669Z",
     "shell.execute_reply": "2024-07-15T10:34:46.325432Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.319296Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 512  # シーケンスの最大長を512に設定します。\n",
    "\n",
    "# max_lenは、BERTなどのトランスフォーマーモデルで処理できる入力シーケンスの最大の長さを指定します。\n",
    "# これにより、すべての入力が均一な長さになるようにパディングやカットが適用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3348ac09",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Cleaning texts\n",
    "train_data['prompt_clean'] = train_data['prompt'].apply(clean_text)\n",
    "train_data['response_a_clean'] = train_data['response_a'].apply(clean_text)\n",
    "train_data['response_b_clean'] = train_data['response_b'].apply(clean_text)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer = Tokenizer(num_words=20000)  # 語彙サイズを20,000語に制限したトークナイザーを初期化します。\n",
    "\n",
    "# Tokenizerクラスは、テキストを数値のトークンに変換するためのもので、num_words引数は使用する語彙の最大数を指定します。\n",
    "# これにより、頻出の単語を保持し、あまり使われない単語は除外されるため、モデルの効率が向上します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.328517Z",
     "iopub.status.busy": "2024-07-15T10:34:46.328108Z",
     "iopub.status.idle": "2024-07-15T10:34:46.336728Z",
     "shell.execute_reply": "2024-07-15T10:34:46.335637Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.328475Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)  # 語彙サイズを20,000語に制限したトークナイザーを初期化します。\n",
    "\n",
    "# Tokenizerクラスは、テキストを数値のトークンに変換するためのもので、num_words引数は使用する語彙の最大数を指定します。\n",
    "# これにより、頻出の単語を保持し、あまり使われない単語は除外されるため、モデルの効率が向上します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6736ab68",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Tokenize Inputs\n",
    "\n",
    "Using the TensorFlow/Kerar tokenizer on both training and test data. Padding sequences to `max_len`.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "tokenizer.fit_on_texts(pd.concat([train_data['prompt_clean'], train_data['response_a_clean'], train_data['response_b_clean']]))  # トークナイザーをトレーニングデータのクリーニングされたプロンプトとレスポンスでフィットさせます。\n",
    "\n",
    "# fit_on_texts()メソッドは、指定されたテキストデータから単語の頻度に基づいて語彙を構築します。\n",
    "# pd.concat()を使用して、プロンプトとレスポンスを結合し、一緒にトークン化することで、すべてのテキストに基づいた語彙を作成します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166f26d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "max_len = 512\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['prompt_clean'])  # クリーニングされたプロンプトを数値のシーケンスに変換します。\n",
    "response_a_sequences = tokenizer.texts_to_sequences(train_data['response_a_clean'])  # クリーニングされたレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_sequences = tokenizer.texts_to_sequences(train_data['response_b_clean'])  # クリーニングされたレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドは、テキストを数値のシーケンスに変換し、各単語を対応するインデックスに置き換えます。\n",
    "# これにより、モデルに入力できる形式のデータが得られ、後の処理や学習のために準備されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.357828Z",
     "iopub.status.busy": "2024-07-15T10:34:46.357412Z",
     "iopub.status.idle": "2024-07-15T10:34:46.36959Z",
     "shell.execute_reply": "2024-07-15T10:34:46.36843Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.357793Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_data['prompt_clean'])  # クリーニングされたプロンプトを数値のシーケンスに変換します。\n",
    "response_a_sequences = tokenizer.texts_to_sequences(train_data['response_a_clean'])  # クリーニングされたレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_sequences = tokenizer.texts_to_sequences(train_data['response_b_clean'])  # クリーニングされたレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドは、テキストを数値のシーケンスに変換し、各単語を対応するインデックスに置き換えます。\n",
    "# これにより、モデルに入力できる形式のデータが得られ、後の処理や学習のために準備されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccdcd63",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# パディングを行います。\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')  # プロンプトのシーケンスを最大長にパディングします。シーケンスの末尾にパディングを追加します。\n",
    "response_a_sequences = pad_sequences(response_a_sequences, maxlen=max_len, padding='post')  # レスポンスAのシーケンスを最大長にパディングします。\n",
    "response_b_sequences = pad_sequences(response_b_sequences, maxlen=max_len, padding='post')  # レスポンスBのシーケンスを最大長にパディングします。\n",
    "\n",
    "# pad_sequences()は、すべてのシーケンスを指定した最大長に整形し、短いシーケンスにはゼロや指定したパディング値を追加します。\n",
    "# padding='post'を指定することで、シーケンスの後ろにパディングを追加し、長さを統一します。これにより、モデルの入力データが整った形式になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.371665Z",
     "iopub.status.busy": "2024-07-15T10:34:46.37117Z",
     "iopub.status.idle": "2024-07-15T10:34:46.382058Z",
     "shell.execute_reply": "2024-07-15T10:34:46.380991Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.371623Z"
    }
   },
   "outputs": [],
   "source": [
    "# パディングを行います。\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')  # プロンプトのシーケンスを最大長にパディングします。シーケンスの末尾にパディングを追加します。\n",
    "response_a_sequences = pad_sequences(response_a_sequences, maxlen=max_len, padding='post')  # レスポンスAのシーケンスを最大長にパディングします。\n",
    "response_b_sequences = pad_sequences(response_b_sequences, maxlen=max_len, padding='post')  # レスポンスBのシーケンスを最大長にパディングします。\n",
    "\n",
    "# pad_sequences()は、すべてのシーケンスを指定した最大長に整形し、短いシーケンスにはゼロや指定したパディング値を追加します。\n",
    "# padding='post'を指定することで、シーケンスの後ろにパディングを追加し、長さを統一します。これにより、モデルの入力データが整った形式になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15800ee",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer.fit_on_texts(pd.concat([train_data['prompt_clean'], train_data['response_a_clean'], train_data['response_b_clean']]))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "### 感情分析\n",
    "\n",
    "`vaderSentiment`を使用した感情分析。VADER（Valence Aware Dictionary and sEntiment Reasoner）は、特にソーシャルメディアで表現される感情に調整された、辞書およびルールベースの感情分析ツールです。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2606a9b",
   "metadata": {},
   "source": [
    "### 感情分析\n",
    "\n",
    "`vaderSentiment`を使用した感情分析。VADER（Valence Aware Dictionary and sEntiment Reasoner）は、特にソーシャルメディアで表現される感情に調整された、辞書およびルールベースの感情分析ツールです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de66ba96",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['prompt_clean'])\n",
    "response_a_sequences = tokenizer.texts_to_sequences(train_data['response_a_clean'])\n",
    "response_b_sequences = tokenizer.texts_to_sequences(train_data['response_b_clean'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "analyzer = SentimentIntensityAnalyzer()  # 感情分析のためのSentimentIntensityAnalyzerを初期化します。\n",
    "\n",
    "# SentimentIntensityAnalyzerは、テキストの感情を評価するための便利なツールで、\n",
    "# 各テキストに対してポジティブ、ネガティブ、ニュートラルなスコアを生成し、\n",
    "# 全体的な感情の強度を示すコンパウンドスコアも計算します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.38392Z",
     "iopub.status.busy": "2024-07-15T10:34:46.383538Z",
     "iopub.status.idle": "2024-07-15T10:34:46.410086Z",
     "shell.execute_reply": "2024-07-15T10:34:46.40907Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.383888Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()  # 感情分析のためのSentimentIntensityAnalyzerを初期化します。\n",
    "\n",
    "# SentimentIntensityAnalyzerは、テキストの感情を評価するための便利なツールで、\n",
    "# 各テキストに対してポジティブ、ネガティブ、ニュートラルなスコアを生成し、\n",
    "# 全体的な感情の強度を示すコンパウンドスコアも計算します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01780e9d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Padding\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')\n",
    "response_a_sequences = pad_sequences(response_a_sequences, maxlen=max_len, padding='post')\n",
    "response_b_sequences = pad_sequences(response_b_sequences, maxlen=max_len, padding='post')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def sentiment_analysis(text):  # 感情分析を行う関数を定義します。\n",
    "    return analyzer.polarity_scores(text)['compound']  # テキストの感情スコアを計算し、コンパウンドスコアを返します。\n",
    "\n",
    "# polarity_scores()メソッドは、入力テキストに対して感情のポジティブ、ネガティブ、ニュートラル、およびコンパウンドスコアを計算します。\n",
    "# コンパウンドスコアは、全体的な感情の強度を示し、-1（非常にネガティブ）から1（非常にポジティブ）の範囲で評価されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.411742Z",
     "iopub.status.busy": "2024-07-15T10:34:46.411397Z",
     "iopub.status.idle": "2024-07-15T10:34:46.41693Z",
     "shell.execute_reply": "2024-07-15T10:34:46.41562Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.411701Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):  # 感情分析を行う関数を定義します。\n",
    "    return analyzer.polarity_scores(text)['compound']  # テキストの感情スコアを計算し、コンパウンドスコアを返します。\n",
    "\n",
    "# polarity_scores()メソッドは、入力テキストに対して感情のポジティブ、ネガティブ、ニュートラル、およびコンパウンドスコアを計算します。\n",
    "# コンパウンドスコアは、全体的な感情の強度を示し、-1（非常にネガティブ）から1（非常にポジティブ）の範囲で評価されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62c3d9",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Sentiment Analysis\n",
    "\n",
    "Sentiment analysis using `vaderSentiment`. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "train_data['sentiment_prompt'] = train_data['prompt_clean'].apply(sentiment_analysis)  # クリーニングされたプロンプトに対して感情分析を行い、結果を'sentiment_prompt'列に格納します。\n",
    "train_data['sentiment_response_a'] = train_data['response_a_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスAに対して感情分析を行い、結果を'sentiment_response_a'列に格納します。\n",
    "train_data['sentiment_response_b'] = train_data['response_b_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスBに対して感情分析を行い、結果を'sentiment_response_b'列に格納します。\n",
    "\n",
    "# apply()メソッドを使用して、各クリーニングされたテキストにsentiment_analysis関数を適用することで、\n",
    "# 各テキストの感情スコアを計算し、新しい列としてデータフレームに追加します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49a68e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "### テキスト特徴量\n",
    "\n",
    "単語数、文字数、語彙の多様性、音節数、文の数、各レスポンスの読みやすさを定量的に測定するFlesch Reading Easeスコアなどのテキスト特徴量を計算します。\n",
    "\n",
    "テキスト統計を分析するために`textstat`ライブラリを使用しています。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5279bc",
   "metadata": {},
   "source": [
    "### テキスト特徴量\n",
    "\n",
    "単語数、文字数、語彙の多様性、音節数、文の数、各レスポンスの読みやすさを定量的に測定するFlesch Reading Easeスコアなどのテキスト特徴量を計算します。\n",
    "\n",
    "テキスト統計を分析するために`textstat`ライブラリを使用しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c15ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def sentiment_analysis(text):\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def word_count(text):  # 単語数を計算する関数を定義します。\n",
    "    return len(text.split())  # テキストをスペースで分割し、単語数を返します。\n",
    "\n",
    "def char_count(text):  # 文字数を計算する関数を定義します。\n",
    "    return len(text)  # テキストの全体の長さ（文字数）を返します。\n",
    "\n",
    "def lexical_diversity(text):  # 語彙の多様性を計算する関数を定義します。\n",
    "    words = text.split()  # テキストを単語に分割します。\n",
    "    return len(set(words)) / len(words) if words else 0  # ユニークな単語の数を全単語数で割り、語彙の多様性を計算します。\n",
    "\n",
    "def syllable_count(text):  # 音節数を計算する関数を定義します。\n",
    "    return textstat.syllable_count(text)  # textstatライブラリを使用して音節数を返します。\n",
    "\n",
    "def sentence_count(text):  # 文の数を計算する関数を定義します。\n",
    "    return textstat.sentence_count(text)  # textstatライブラリを使用して文の数を返します。\n",
    "\n",
    "def flesch_reading_ease(text):  # Flesch Reading Easeスコアを計算する関数を定義します。\n",
    "    return textstat.flesch_reading_ease(text)  # textstatライブラリを使用してFlesch Reading Easeスコアを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.469188Z",
     "iopub.status.busy": "2024-07-15T10:34:46.468702Z",
     "iopub.status.idle": "2024-07-15T10:34:46.479754Z",
     "shell.execute_reply": "2024-07-15T10:34:46.478069Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.46913Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_count(text):  # 単語数を計算する関数を定義します。\n",
    "    return len(text.split())  # テキストをスペースで分割し、単語数を返します。\n",
    "\n",
    "def char_count(text):  # 文字数を計算する関数を定義します。\n",
    "    return len(text)  # テキストの全体の長さ（文字数）を返します。\n",
    "\n",
    "def lexical_diversity(text):  # 語彙の多様性を計算する関数を定義します。\n",
    "    words = text.split()  # テキストを単語に分割します。\n",
    "    return len(set(words)) / len(words) if words else 0  # ユニークな単語の数を全単語数で割り、語彙の多様性を計算します。\n",
    "\n",
    "def syllable_count(text):  # 音節数を計算する関数を定義します。\n",
    "    return textstat.syllable_count(text)  # textstatライブラリを使用して音節数を返します。\n",
    "\n",
    "def sentence_count(text):  # 文の数を計算する関数を定義します。\n",
    "    return textstat.sentence_count(text)  # textstatライブラリを使用して文の数を返します。\n",
    "\n",
    "def flesch_reading_ease(text):  # Flesch Reading Easeスコアを計算する関数を定義します。\n",
    "    return textstat.flesch_reading_ease(text)  # textstatライブラリを使用してFlesch Reading Easeスコアを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d1e42",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data['sentiment_prompt'] = train_data['prompt_clean'].apply(sentiment_analysis)\n",
    "train_data['sentiment_response_a'] = train_data['response_a_clean'].apply(sentiment_analysis)\n",
    "train_data['sentiment_response_b'] = train_data['response_b_clean'].apply(sentiment_analysis)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data['word_count_prompt'] = train_data['prompt_clean'].apply(word_count)  # クリーニングされたプロンプトに対して単語数を計算し、'word_count_prompt'列に格納します。\n",
    "train_data['word_count_response_a'] = train_data['response_a_clean'].apply(word_count)  # クリーニングされたレスポンスAに対して単語数を計算し、'word_count_response_a'列に格納します。\n",
    "train_data['word_count_response_b'] = train_data['response_b_clean'].apply(word_count)  # クリーニングされたレスポンスBに対して単語数を計算し、'word_count_response_b'列に格納します。\n",
    "train_data['char_count_prompt'] = train_data['prompt_clean'].apply(char_count)  # クリーニングされたプロンプトに対して文字数を計算し、'char_count_prompt'列に格納します。\n",
    "train_data['char_count_response_a'] = train_data['response_a_clean'].apply(char_count)  # クリーニングされたレスポンスAに対して文字数を計算し、'char_count_response_a'列に格納します。\n",
    "train_data['char_count_response_b'] = train_data['response_b_clean'].apply(char_count)  # クリーニングされたレスポンスBに対して文字数を計算し、'char_count_response_b'列に格納します。\n",
    "train_data['lexical_diversity_prompt'] = train_data['prompt_clean'].apply(lexical_diversity)  # クリーニングされたプロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "train_data['lexical_diversity_response_a'] = train_data['response_a_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "train_data['lexical_diversity_response_b'] = train_data['response_b_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "train_data['syllable_count_prompt'] = train_data['prompt_clean'].apply(syllable_count)  # クリーニングされたプロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "train_data['syllable_count_response_a'] = train_data['response_a_clean'].apply(syllable_count)  # クリーニングされたレスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "train_data['syllable_count_response_b'] = train_data['response_b_clean'].apply(syllable_count)  # クリーニングされたレスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "train_data['sentence_count_prompt'] = train_data['prompt_clean'].apply(sentence_count)  # クリーニングされたプロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "train_data['sentence_count_response_a'] = train_data['response_a_clean'].apply(sentence_count)  # クリーニングされたレスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "train_data['sentence_count_response_b'] = train_data['response_b_clean'].apply(sentence_count)  # クリーニングされたレスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "train_data['flesch_reading_ease_prompt'] = train_data['prompt_clean'].apply(flesch_reading_ease)  # クリーニングされたプロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "train_data['flesch_reading_ease_response_a'] = train_data['response_a_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "train_data['flesch_reading_ease_response_b'] = train_data['response_b_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.481803Z",
     "iopub.status.busy": "2024-07-15T10:34:46.481399Z",
     "iopub.status.idle": "2024-07-15T10:34:46.555079Z",
     "shell.execute_reply": "2024-07-15T10:34:46.553915Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.481769Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['word_count_prompt'] = train_data['prompt_clean'].apply(word_count)  # クリーニングされたプロンプトに対して単語数を計算し、'word_count_prompt'列に格納します。\n",
    "train_data['word_count_response_a'] = train_data['response_a_clean'].apply(word_count)  # クリーニングされたレスポンスAに対して単語数を計算し、'word_count_response_a'列に格納します。\n",
    "train_data['word_count_response_b'] = train_data['response_b_clean'].apply(word_count)  # クリーニングされたレスポンスBに対して単語数を計算し、'word_count_response_b'列に格納します。\n",
    "train_data['char_count_prompt'] = train_data['prompt_clean'].apply(char_count)  # クリーニングされたプロンプトに対して文字数を計算し、'char_count_prompt'列に格納します。\n",
    "train_data['char_count_response_a'] = train_data['response_a_clean'].apply(char_count)  # クリーニングされたレスポンスAに対して文字数を計算し、'char_count_response_a'列に格納します。\n",
    "train_data['char_count_response_b'] = train_data['response_b_clean'].apply(char_count)  # クリーニングされたレスポンスBに対して文字数を計算し、'char_count_response_b'列に格納します。\n",
    "train_data['lexical_diversity_prompt'] = train_data['prompt_clean'].apply(lexical_diversity)  # クリーニングされたプロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "train_data['lexical_diversity_response_a'] = train_data['response_a_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "train_data['lexical_diversity_response_b'] = train_data['response_b_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "train_data['syllable_count_prompt'] = train_data['prompt_clean'].apply(syllable_count)  # クリーニングされたプロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "train_data['syllable_count_response_a'] = train_data['response_a_clean'].apply(syllable_count)  # クリーニングされたレスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "train_data['syllable_count_response_b'] = train_data['response_b_clean'].apply(syllable_count)  # クリーニングされたレスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "train_data['sentence_count_prompt'] = train_data['prompt_clean'].apply(sentence_count)  # クリーニングされたプロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "train_data['sentence_count_response_a'] = train_data['response_a_clean'].apply(sentence_count)  # クリーニングされたレスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "train_data['sentence_count_response_b'] = train_data['response_b_clean'].apply(sentence_count)  # クリーニングされたレスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "train_data['flesch_reading_ease_prompt'] = train_data['prompt_clean'].apply(flesch_reading_ease)  # クリーニングされたプロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "train_data['flesch_reading_ease_response_a'] = train_data['response_a_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "train_data['flesch_reading_ease_response_b'] = train_data['response_b_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27369bc5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Text Features\n",
    "\n",
    "Calculate text features such as word count, character count, \n",
    "lexical diversity, syllable count, sentence count and \n",
    "calculating the Flesch Reading Ease score (quantitative \n",
    "measurement of how readable a piece of text is) for each response. \n",
    "\n",
    "I am using `textstat` library that analyze text statistics.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "### BERT埋め込みの作成\n",
    "\n",
    "トレーニングデータおよびテストデータのプロンプトとレスポンスに対してBERT埋め込みを計算します。また、各モデルのプロンプトとレスポンス間でBERTを使用したコサイン類似度特徴量も計算します。\n",
    "\n",
    "効率的なパイプラインを作成するために`tf.data.Dataset`を使用し、GPUを利用してバッチで特徴量を処理します。また、`joblib`ライブラリを使用して中間埋め込みを保存する予定です。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48a132",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def word_count(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def char_count(text):\n",
    "    return len(text)\n",
    "\n",
    "def lexical_diversity(text):\n",
    "    words = text.split()\n",
    "    return len(set(words)) / len(words) if words else 0\n",
    "\n",
    "def syllable_count(text):\n",
    "    return textstat.syllable_count(text)\n",
    "\n",
    "def sentence_count(text):\n",
    "    return textstat.sentence_count(text)\n",
    "\n",
    "def flesch_reading_ease(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# BERTモデルをロードします。\n",
    "bert_model_name = 'bert-base-uncased'  # 使用するBERTモデルの名前を指定します。\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)  # BERTトークナイザーを事前学習済みモデルから初期化します。\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)  # BERTモデルを事前学習済みモデルから初期化します。\n",
    "\n",
    "# BertTokenizerはテキストをBERTモデル用にトークン化するためのもので、\n",
    "# TFBertModelはTensorFlowで動作するBERTモデル本体を提供します。\n",
    "# これにより、自然言語処理タスクにおいてBERTを利用できるようになります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.557088Z",
     "iopub.status.busy": "2024-07-15T10:34:46.556727Z",
     "iopub.status.idle": "2024-07-15T10:34:52.940246Z",
     "shell.execute_reply": "2024-07-15T10:34:52.939065Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.557055Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERTモデルをロードします。\n",
    "bert_model_name = 'bert-base-uncased'  # 使用するBERTモデルの名前を指定します。\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)  # BERTトークナイザーを事前学習済みモデルから初期化します。\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)  # BERTモデルを事前学習済みモデルから初期化します。\n",
    "\n",
    "# BertTokenizerはテキストをBERTモデル用にトークン化するためのもので、\n",
    "# TFBertModelはTensorFlowで動作するBERTモデル本体を提供します。\n",
    "# これにより、自然言語処理タスクにおいてBERTを利用できるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c0fd1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data['word_count_prompt'] = train_data['prompt_clean'].apply(word_count)\n",
    "train_data['word_count_response_a'] = train_data['response_a_clean'].apply(word_count)\n",
    "train_data['word_count_response_b'] = train_data['response_b_clean'].apply(word_count)\n",
    "train_data['char_count_prompt'] = train_data['prompt_clean'].apply(char_count)\n",
    "train_data['char_count_response_a'] = train_data['response_a_clean'].apply(char_count)\n",
    "train_data['char_count_response_b'] = train_data['response_b_clean'].apply(char_count)\n",
    "train_data['lexical_diversity_prompt'] = train_data['prompt_clean'].apply(lexical_diversity)\n",
    "train_data['lexical_diversity_response_a'] = train_data['response_a_clean'].apply(lexical_diversity)\n",
    "train_data['lexical_diversity_response_b'] = train_data['response_b_clean'].apply(lexical_diversity)\n",
    "train_data['syllable_count_prompt'] = train_data['prompt_clean'].apply(syllable_count)\n",
    "train_data['syllable_count_response_a'] = train_data['response_a_clean'].apply(syllable_count)\n",
    "train_data['syllable_count_response_b'] = train_data['response_b_clean'].apply(syllable_count)\n",
    "train_data['sentence_count_prompt'] = train_data['prompt_clean'].apply(sentence_count)\n",
    "train_data['sentence_count_response_a'] = train_data['response_a_clean'].apply(sentence_count)\n",
    "train_data['sentence_count_response_b'] = train_data['response_b_clean'].apply(sentence_count)\n",
    "train_data['flesch_reading_ease_prompt'] = train_data['prompt_clean'].apply(flesch_reading_ease)\n",
    "train_data['flesch_reading_ease_response_a'] = train_data['response_a_clean'].apply(flesch_reading_ease)\n",
    "train_data['flesch_reading_ease_response_b'] = train_data['response_b_clean'].apply(flesch_reading_ease)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "@tf.function  # TensorFlowの関数として最適化されることを示します。\n",
    "def get_bert_embeddings(texts):  # テキストに対してBERT埋め込みを取得する関数を定義します。\n",
    "    inputs = bert_tokenizer(texts,  # テキストをトークナイズします。\n",
    "                       return_tensors='tf',  # TensorFlowテンソルとして返します。\n",
    "                       padding=True,  # パディングを有効にします。\n",
    "                       truncation=True,  # テキストがmax_lengthを超える場合は切り捨てます。\n",
    "                       max_length=512)  # 最大入力長を512に設定します。\n",
    "    outputs = bert_model(inputs)  # BERTモデルを使用して埋め込みを生成します。\n",
    "    return outputs.last_hidden_state[:, 0, :]  # 最後の隠れ層の出力の最初のトークン（[CLS]トークン）の埋め込みを返します。\n",
    "\n",
    "# この関数は、与えられたテキストからBERT埋め込みを効率的に計算し、\n",
    "# 特に分類タスクなどで重要な役割を果たす[CLS]トークンの埋め込みを取得します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.942183Z",
     "iopub.status.busy": "2024-07-15T10:34:52.941823Z",
     "iopub.status.idle": "2024-07-15T10:34:52.949586Z",
     "shell.execute_reply": "2024-07-15T10:34:52.948307Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.942133Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function  # TensorFlowの関数として最適化されることを示します。\n",
    "def get_bert_embeddings(texts):  # テキストに対してBERT埋め込みを取得する関数を定義します。\n",
    "    inputs = bert_tokenizer(texts,  # テキストをトークナイズします。\n",
    "                       return_tensors='tf',  # TensorFlowテンソルとして返します。\n",
    "                       padding=True,  # パディングを有効にします。\n",
    "                       truncation=True,  # テキストがmax_lengthを超える場合は切り捨てます。\n",
    "                       max_length=512)  # 最大入力長を512に設定します。\n",
    "    outputs = bert_model(inputs)  # BERTモデルを使用して埋め込みを生成します。\n",
    "    return outputs.last_hidden_state[:, 0, :]  # 最後の隠れ層の出力の最初のトークン（[CLS]トークン）の埋め込みを返します。\n",
    "\n",
    "# この関数は、与えられたテキストからBERT埋め込みを効率的に計算し、\n",
    "# 特に分類タスクなどで重要な役割を果たす[CLS]トークンの埋め込みを取得します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bc62a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Create BERT embeddings\n",
    "\n",
    "Compute BERT embeddings for prompt and response for both train and test data.\n",
    "Also compute Cosine Similarity features using BERT between the prompt and responses for each model. \n",
    "\n",
    "I will use `tf.data.Dataset` to create an efficient pipeline, and process the features in batches using GPU. Also I am going to save the intermediate embeddings using `joblib` library\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "def process_column(column_data):  # 指定された列のデータを処理する関数を定義します。\n",
    "    column_data = column_data.dropna().tolist()  # 欠損値を削除し、リストに変換します。\n",
    "    column_data = [str(text) for text in column_data]  # 各テキストを文字列に変換します。  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(column_data)  # リストからTensorFlowデータセットを作成します。\n",
    "    dataset = dataset.batch(8)  # バッチサイズを8に設定します。\n",
    "\n",
    "    embeddings = []  # 埋め込みを格納するリストを初期化します。\n",
    "    for batch in dataset:  # データセットの各バッチに対してループします。\n",
    "        batch_list = [str(text) for text in batch.numpy().tolist()]  # バッチ内のテキストをリストに変換します。\n",
    "        batch_embeddings = get_bert_embeddings(batch_list)  # BERT埋め込みを取得します。\n",
    "        embeddings.append(batch_embeddings)  # 埋め込みをリストに追加します。\n",
    "    \n",
    "    return np.concatenate(embeddings, axis=0)  # 埋め込みを結合し、1つのNumPy配列として返します。\n",
    "\n",
    "# この関数は、与えられた列のテキストデータを処理し、BERTを使用して埋め込みを生成します。\n",
    "# バッチ処理を使用することで、メモリ使用量を最適化し、GPUを効率的に活用できます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf20277c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load BERT\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def add_embeddings_to_dataframe(df, column_names):  # データフレームに埋め込みを追加する関数を定義します。\n",
    "    for column in column_names:  # 各指定された列に対してループします。\n",
    "        print(f\"Processing column: {column}\")  # 現在処理中の列を表示します。\n",
    "        embeddings = process_column(df[column])  # 指定された列に対して埋め込みを生成します。\n",
    "        df[f'{column}_embedding'] = list(embeddings)  # 生成された埋め込みを新しい列としてデータフレームに追加します。\n",
    "    return df  # 更新されたデータフレームを返します。\n",
    "\n",
    "# この関数は、指定された列の埋め込みを計算し、それらを元のデータフレームに追加します。\n",
    "# これにより、元のデータとその埋め込み表現を一緒に保持することができます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.975178Z",
     "iopub.status.busy": "2024-07-15T10:34:52.974743Z",
     "iopub.status.idle": "2024-07-15T10:34:52.983785Z",
     "shell.execute_reply": "2024-07-15T10:34:52.982354Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.975124Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_embeddings_to_dataframe(df, column_names):  # データフレームに埋め込みを追加する関数を定義します。\n",
    "    for column in column_names:  # 各指定された列に対してループします。\n",
    "        print(f\"Processing column: {column}\")  # 現在処理中の列を表示します。\n",
    "        embeddings = process_column(df[column])  # 指定された列に対して埋め込みを生成します。\n",
    "        df[f'{column}_embedding'] = list(embeddings)  # 生成された埋め込みを新しい列としてデータフレームに追加します。\n",
    "    return df  # 更新されたデータフレームを返します。\n",
    "\n",
    "# この関数は、指定された列の埋め込みを計算し、それらを元のデータフレームに追加します。\n",
    "# これにより、元のデータとその埋め込み表現を一緒に保持することができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce003aa3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@tf.function\n",
    "def get_bert_embeddings(texts):\n",
    "    inputs = bert_tokenizer(texts, \n",
    "                       return_tensors='tf', \n",
    "                       padding=True, \n",
    "                       truncation=True, \n",
    "                       max_length=512)\n",
    "    outputs = bert_model(inputs)\n",
    "    return outputs.last_hidden_state[:, 0, :]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "columns_to_embed = ['prompt_clean', 'response_a_clean', 'response_b_clean']  # 埋め込みを計算する列のリストを定義します。\n",
    "\n",
    "# このリストには、クリーンなプロンプトおよびレスポンスのテキストデータが含まれており、\n",
    "# 後でこれらの列に対してBERT埋め込みを生成するために使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.985878Z",
     "iopub.status.busy": "2024-07-15T10:34:52.985495Z",
     "iopub.status.idle": "2024-07-15T10:34:52.99625Z",
     "shell.execute_reply": "2024-07-15T10:34:52.994963Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.985846Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_embed = ['prompt_clean', 'response_a_clean', 'response_b_clean']  # 埋め込みを計算する列のリストを定義します。\n",
    "\n",
    "# このリストには、クリーンなプロンプトおよびレスポンスのテキストデータが含まれており、\n",
    "# 後でこれらの列に対してBERT埋め込みを生成するために使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e122a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process_column(column_data):\n",
    "    column_data = column_data.dropna().tolist()\n",
    "    column_data = [str(text) for text in column_data]  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(column_data)\n",
    "    dataset = dataset.batch(8)  \n",
    "    \n",
    "    embeddings = []\n",
    "    for batch in dataset:\n",
    "        batch_list = [str(text) for text in batch.numpy().tolist()]  \n",
    "        batch_embeddings = get_bert_embeddings(batch_list)\n",
    "        embeddings.append(batch_embeddings)\n",
    "    \n",
    "    return np.concatenate(embeddings, axis=0)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data = add_embeddings_to_dataframe(train_data, columns_to_embed)  # 指定された列に対して埋め込みを追加し、更新されたデータフレームを保存します。\n",
    "\n",
    "# add_embeddings_to_dataframe関数を呼び出すことで、トレーニングデータに埋め込みを計算し、\n",
    "# 新たに生成された埋め込みがデータフレームに追加されます。これにより、元のテキストデータとその埋め込みが一緒に使用できる状態になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.998794Z",
     "iopub.status.busy": "2024-07-15T10:34:52.997849Z",
     "iopub.status.idle": "2024-07-15T10:39:58.701392Z",
     "shell.execute_reply": "2024-07-15T10:39:58.700299Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.998754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = add_embeddings_to_dataframe(train_data, columns_to_embed)  # 指定された列に対して埋め込みを追加し、更新されたデータフレームを保存します。\n",
    "\n",
    "# add_embeddings_to_dataframe関数を呼び出すことで、トレーニングデータに埋め込みを計算し、\n",
    "# 新たに生成された埋め込みがデータフレームに追加されます。これにより、元のテキストデータとその埋め込みが一緒に使用できる状態になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915cadc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def add_embeddings_to_dataframe(df, column_names):\n",
    "    for column in column_names:\n",
    "        print(f\"Processing column: {column}\")\n",
    "        embeddings = process_column(df[column])\n",
    "        df[f'{column}_embedding'] = list(embeddings)\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train_data['similarity_prompt_response_a'] = train_data.apply(  # プロンプトとレスポンスAのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "train_data['similarity_prompt_response_b'] = train_data.apply(  # プロンプトとレスポンスBのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.7034Z",
     "iopub.status.busy": "2024-07-15T10:39:58.702927Z",
     "iopub.status.idle": "2024-07-15T10:39:58.780638Z",
     "shell.execute_reply": "2024-07-15T10:39:58.779496Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.703357Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['similarity_prompt_response_a'] = train_data.apply(  # プロンプトとレスポンスAのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "train_data['similarity_prompt_response_b'] = train_data.apply(  # プロンプトとレスポンスBのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcedbf39",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "columns_to_embed = ['prompt_clean', 'response_a_clean', 'response_b_clean']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "### データの準備\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2afbe9",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96cd006",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data = add_embeddings_to_dataframe(train_data, columns_to_embed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "X = train_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、モデルの入力に使用する特徴量（X）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# 学習に用いるデータとして後で利用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.782321Z",
     "iopub.status.busy": "2024-07-15T10:39:58.78195Z",
     "iopub.status.idle": "2024-07-15T10:39:58.791644Z",
     "shell.execute_reply": "2024-07-15T10:39:58.790528Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.782289Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、モデルの入力に使用する特徴量（X）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# 学習に用いるデータとして後で利用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407bfd24",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_data['similarity_prompt_response_a'] = train_data.apply(\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n",
    "\n",
    "train_data['similarity_prompt_response_b'] = train_data.apply(\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 目標列を定義します。\n",
    "train_data['winner'] = train_data.apply(lambda x: 0 if x['winner_model_a'] == 1 else (1 if x['winner_model_b'] == 1 else 2), axis=1)  # モデルAの勝利を0、モデルBの勝利を1、引き分けを2として設定します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対して条件に基づいて勝者のラベルを決定します。\n",
    "# これにより、モデルの出力として使用される目標変数（winner）が作成されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.793424Z",
     "iopub.status.busy": "2024-07-15T10:39:58.793015Z",
     "iopub.status.idle": "2024-07-15T10:39:58.809536Z",
     "shell.execute_reply": "2024-07-15T10:39:58.807975Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.793392Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目標列を定義します。\n",
    "train_data['winner'] = train_data.apply(lambda x: 0 if x['winner_model_a'] == 1 else (1 if x['winner_model_b'] == 1 else 2), axis=1)  # モデルAの勝利を0、モデルBの勝利を1、引き分けを2として設定します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対して条件に基づいて勝者のラベルを決定します。\n",
    "# これにより、モデルの出力として使用される目標変数（winner）が作成されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d71ed",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Prepare Data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "y = train_data['winner']  # 目標変数（勝者）をyとして定義します。\n",
    "\n",
    "# このコードにより、トレーニングデータにおける各サンプルの勝者ラベルを含むシリーズが作成され、学習用モデルのターゲットとして使用されます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a5c905",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "X = train_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',\n",
    "                'char_count_prompt', 'char_count_response_a', 'char_count_response_b',\n",
    "                'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',\n",
    "                'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',\n",
    "                'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',\n",
    "                'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',\n",
    "                'similarity_prompt_response_a', 'similarity_prompt_response_b', \n",
    "                'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "### トレーニングデータとバリデーションデータの分割\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127a53b",
   "metadata": {},
   "source": [
    "### トレーニングデータとバリデーションデータの分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771b8b09",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Definindo a coluna alvo\n",
    "train_data['winner'] = train_data.apply(lambda x: 0 if x['winner_model_a'] == 1 else (1 if x['winner_model_b'] == 1 else 2), axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,  # データをトレーニングセットとバリデーションセットに分割します。\n",
    "                                                  random_state=42)  # テストサイズを20%に設定し、乱数シードを42にします。\n",
    "\n",
    "# train_test_split()関数は、指定されたデータ（特徴量Xとターゲットy）をトレーニングデータとバリデーションデータに分割します。\n",
    "# random_stateを設定することで、分割結果を再現可能にします。これにより、毎回同じデータが分割されることが保証されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.82304Z",
     "iopub.status.busy": "2024-07-15T10:39:58.822473Z",
     "iopub.status.idle": "2024-07-15T10:39:58.835465Z",
     "shell.execute_reply": "2024-07-15T10:39:58.834233Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.822995Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,  # データをトレーニングセットとバリデーションセットに分割します。\n",
    "                                                  random_state=42)  # テストサイズを20%に設定し、乱数シードを42にします。\n",
    "\n",
    "# train_test_split()関数は、指定されたデータ（特徴量Xとターゲットy）をトレーニングデータとバリデーションデータに分割します。\n",
    "# random_stateを設定することで、分割結果を再現可能にします。これにより、毎回同じデータが分割されることが保証されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448c5bcc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "y = train_data['winner']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "## モデルの定義\n",
    "\n",
    "* ランダムフォレスト\n",
    "* ロジスティック回帰\n",
    "* サポートベクターマシン\n",
    "* 勾配ブースティング\n",
    "* ニューラルネットワーク\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbe2aa",
   "metadata": {},
   "source": [
    "## モデルの定義\n",
    "\n",
    "* ランダムフォレスト\n",
    "* ロジスティック回帰\n",
    "* サポートベクターマシン\n",
    "* 勾配ブースティング\n",
    "* ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5d5d5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "### Splitting training and validation data\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "models = {  # モデルの辞書を定義します。\n",
    "    'Random Forest': RandomForestClassifier(),  # ランダムフォレスト分類器を追加します。\n",
    "    'SVM': SVC(probability=True),  # サポートベクターマシンを追加し、確率予測を有効にします。\n",
    "    'Gradient Boosting': GradientBoostingClassifier()  # 勾配ブースティング分類器を追加します。\n",
    "}\n",
    "\n",
    "# この辞書は、後で使用するための異なるモデルを格納し、\n",
    "# モデルのトレーニングや評価を簡単に行えるようにします。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44d1b7f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, \n",
    "                                                  random_state=42)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ニューラルネットワークを作成します。\n",
    "def create_nn_model(input_shape):  # 入力形状を受け取る関数を定義します。\n",
    "    model = Sequential()  # シーケンシャルモデルを初期化します。\n",
    "    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))  # 入力層と128のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # ドロップアウト層を追加し、過学習を防ぎます。\n",
    "    model.add(Dense(64, activation='relu'))  # 64のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # 再度ドロップアウト層を追加します。\n",
    "    model.add(Dense(3, activation='softmax'))  # 出力層を追加し、3つのクラスの確率を出力します。\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # モデルをコンパイルします。\n",
    "    return model  # 定義したモデルを返します。\n",
    "\n",
    "# この関数は、指定された入力形状を持つニューラルネットワークモデルを構築し、\n",
    "# トレーニングに使用するための準備を行います。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.848381Z",
     "iopub.status.busy": "2024-07-15T10:39:58.847872Z",
     "iopub.status.idle": "2024-07-15T10:39:58.857714Z",
     "shell.execute_reply": "2024-07-15T10:39:58.856626Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.848339Z"
    }
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークを作成します。\n",
    "def create_nn_model(input_shape):  # 入力形状を受け取る関数を定義します。\n",
    "    model = Sequential()  # シーケンシャルモデルを初期化します。\n",
    "    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))  # 入力層と128のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # ドロップアウト層を追加し、過学習を防ぎます。\n",
    "    model.add(Dense(64, activation='relu'))  # 64のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # 再度ドロップアウト層を追加します。\n",
    "    model.add(Dense(3, activation='softmax'))  # 出力層を追加し、3つのクラスの確率を出力します。\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # モデルをコンパイルします。\n",
    "    return model  # 定義したモデルを返します。\n",
    "\n",
    "# この関数は、指定された入力形状を持つニューラルネットワークモデルを構築し、\n",
    "# トレーニングに使用するための準備を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ed8ec",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Defining Models\n",
    "\n",
    "* Random Forest\n",
    "* Logistic Regression\n",
    "* Support Vector Machin\n",
    "* Gradient Boosting\n",
    "* Neural Network\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "nn_model = create_nn_model(X_train.shape[1])  # トレーニングデータの特徴量の数に基づいてニューラルネットワークモデルを作成します。\n",
    "models['Neural Network'] = nn_model  # 作成したニューラルネットワークモデルをモデルの辞書に追加します。\n",
    "\n",
    "# これにより、ニューラルネットワークモデルが定義されたモデルのリストに追加され、\n",
    "# 他のモデルと同様にトレーニングや評価が可能になります。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af475070",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'SVM': SVC(probability=True),\n",
    "    'Gradient Boosting': GradientBoostingClassifier()\n",
    "}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "モデルのトレーニングと評価:\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a4e41",
   "metadata": {},
   "source": [
    "モデルのトレーニングと評価:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6e8005",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Creating Neural Network\n",
    "def create_nn_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "results = {}  # モデルの評価結果を格納する辞書を初期化します。\n",
    "\n",
    "for name, model in models.items():  # 定義されたすべてのモデルに対してループします。\n",
    "    print(f\"トレーニングと評価を行っています: {name}...\")\n",
    "    \n",
    "    if name == 'Neural Network':  # ニューラルネットワークの場合\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)  # モデルをフィットし、検証データを使用します。\n",
    "        y_pred = np.argmax(model.predict(X_val), axis=1)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict(X_val)  # 予測確率を取得します。\n",
    "    else:  # その他のモデルの場合\n",
    "        model.fit(X_train, y_train)  # モデルをフィットします。\n",
    "        y_pred = model.predict(X_val)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict_proba(X_val)  # 予測確率を取得します。\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)  # 精度を計算します。\n",
    "    logloss = log_loss(y_val, y_pred_proba)  # ログ損失を計算します。\n",
    "\n",
    "    results[name] = {  # 結果を辞書に格納します。\n",
    "        '精度': accuracy,\n",
    "        'ログ損失': logloss,\n",
    "        '分類レポート': classification_report(y_val, y_pred),\n",
    "        '混同行列': confusion_matrix(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"{name}の精度: {accuracy}\")  # モデルの精度を表示します。\n",
    "    print(f\"{name}のログ損失: {logloss}\")  # モデルのログ損失を表示します。\n",
    "    print(f\"{name}の分類レポート:\\n{classification_report(y_val, y_pred)}\")  # 分類レポートを表示します。\n",
    "    print(f\"{name}の混同行列:\\n{confusion_matrix(y_val, y_pred)}\\n\")  # 混同行列を表示します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.951637Z",
     "iopub.status.busy": "2024-07-15T10:39:58.951172Z",
     "iopub.status.idle": "2024-07-15T10:40:02.02086Z",
     "shell.execute_reply": "2024-07-15T10:40:02.019202Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.951595Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}  # モデルの評価結果を格納する辞書を初期化します。\n",
    "\n",
    "for name, model in models.items():  # 定義されたすべてのモデルに対してループします。\n",
    "    print(f\"トレーニングと評価を行っています: {name}...\")\n",
    "    \n",
    "    if name == 'Neural Network':  # ニューラルネットワークの場合\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)  # モデルをフィットし、検証データを使用します。\n",
    "        y_pred = np.argmax(model.predict(X_val), axis=1)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict(X_val)  # 予測確率を取得します。\n",
    "    else:  # その他のモデルの場合\n",
    "        model.fit(X_train, y_train)  # モデルをフィットします。\n",
    "        y_pred = model.predict(X_val)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict_proba(X_val)  # 予測確率を取得します。\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)  # 精度を計算します。\n",
    "    logloss = log_loss(y_val, y_pred_proba)  # ログ損失を計算します。\n",
    "\n",
    "    results[name] = {  # 結果を辞書に格納します。\n",
    "        '精度': accuracy,\n",
    "        'ログ損失': logloss,\n",
    "        '分類レポート': classification_report(y_val, y_pred),\n",
    "        '混同行列': confusion_matrix(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"{name}の精度: {accuracy}\")  # モデルの精度を表示します。\n",
    "    print(f\"{name}のログ損失: {logloss}\")  # モデルのログ損失を表示します。\n",
    "    print(f\"{name}の分類レポート:\\n{classification_report(y_val, y_pred)}\")  # 分類レポートを表示します。\n",
    "    print(f\"{name}の混同行列:\\n{confusion_matrix(y_val, y_pred)}\\n\")  # 混同行列を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf071ea",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "nn_model = create_nn_model(X_train.shape[1])\n",
    "models['Neural Network'] = nn_model\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "ログ損失に基づいて最良のモデルを選択しています。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e06943",
   "metadata": {},
   "source": [
    "ログ損失に基づいて最良のモデルを選択しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b9574",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Training models and evaluating:\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "best_model_name = max(results, key=lambda name: results[name]['Log Loss'])  # 最小のログ損失を持つモデル名を取得します。\n",
    "best_model = models[best_model_name]  # 最良のモデルを辞書から取得します。\n",
    "\n",
    "# これにより、ログ損失が最も小さいモデルを選択し、\n",
    "# そのモデルを後で使用するための変数best_modelに格納します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69016e5c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando e avaliando {name}...\")\n",
    "    \n",
    "    if name == 'Neural Network':\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)\n",
    "        y_pred = np.argmax(model.predict(X_val), axis=1)\n",
    "        y_pred_proba = model.predict(X_val)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_proba = model.predict_proba(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    logloss = log_loss(y_val, y_pred_proba)\n",
    "\n",
    "    results[name] = {\n",
    "        'Acurácia': accuracy,\n",
    "        'Log Loss': logloss,\n",
    "        'Relatório de Classificação': classification_report(y_val, y_pred),\n",
    "        'Matriz de Confusão': confusion_matrix(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"Acurácia de {name}: {accuracy}\")\n",
    "    print(f\"Log Loss de {name}: {logloss}\")\n",
    "    print(f\"Relatório de Classificação de {name}:\\n{classification_report(y_val, y_pred)}\")\n",
    "    print(f\"Matriz de Confusão de {name}:\\n{confusion_matrix(y_val, y_pred)}\\n\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "## 予測と提出\n",
    "\n",
    "テストデータの準備、テストデータに対する予測、および提出用データの作成を行います。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f61bd0",
   "metadata": {},
   "source": [
    "## 予測と提出\n",
    "\n",
    "テストデータの準備、テストデータに対する予測、および提出用データの作成を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5805f404",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "Selecting the best model with respect the Log Loss\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# テストデータのテキストをクリーンアップします。\n",
    "test_data['prompt_clean'] = test_data['prompt'].apply(clean_text)  # 'prompt'列にclean_text関数を適用し、クリーンアップした結果を'prompt_clean'列に格納します。\n",
    "test_data['response_a_clean'] = test_data['response_a'].apply(clean_text)  # 'response_a'列にclean_text関数を適用し、クリーンアップした結果を'response_a_clean'列に格納します。\n",
    "test_data['response_b_clean'] = test_data['response_b'].apply(clean_text)  # 'response_b'列にclean_text関数を適用し、クリーンアップした結果を'response_b_clean'列に格納します。\n",
    "\n",
    "# このコードにより、テストデータのテキストが前処理され、モデルへの入力に適した形式になります。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9b913",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "best_model_name = max(results, key=lambda name: results[name]['Log Loss'])\n",
    "best_model = models[best_model_name]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータのテキストをトークン化します。\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['prompt_clean'])  # クリーンなプロンプトを数値のシーケンスに変換します。\n",
    "response_a_test_sequences = tokenizer.texts_to_sequences(test_data['response_a_clean'])  # クリーンなレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_test_sequences = tokenizer.texts_to_sequences(test_data['response_b_clean'])  # クリーンなレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドを使用することで、テキストをトークンに変換し、\n",
    "# モデルの入力として使用できる形式に準備します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.04956Z",
     "iopub.status.busy": "2024-07-15T10:40:02.048561Z",
     "iopub.status.idle": "2024-07-15T10:40:02.060016Z",
     "shell.execute_reply": "2024-07-15T10:40:02.058788Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.049512Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのテキストをトークン化します。\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['prompt_clean'])  # クリーンなプロンプトを数値のシーケンスに変換します。\n",
    "response_a_test_sequences = tokenizer.texts_to_sequences(test_data['response_a_clean'])  # クリーンなレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_test_sequences = tokenizer.texts_to_sequences(test_data['response_b_clean'])  # クリーンなレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドを使用することで、テキストをトークンに変換し、\n",
    "# モデルの入力として使用できる形式に準備します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad981ee5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Prediction and Submission\n",
    "\n",
    "Preparing test data, predicting on test data and creating submission data.\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# テストデータのシーケンスにパディングを行います。\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post')  # プロンプトのシーケンスを最大長にパディングします。\n",
    "response_a_test_sequences = pad_sequences(response_a_test_sequences, maxlen=max_len, padding='post')  # レスポンスAのシーケンスを最大長にパディングします。\n",
    "response_b_test_sequences = pad_sequences(response_b_test_sequences, maxlen=max_len, padding='post')  # レスポンスBのシーケンスを最大長にパディングします。\n",
    "\n",
    "# pad_sequences()を使用することで、すべてのシーケンスを指定した最大長に整形し、\n",
    "# 短いシーケンスにはゼロパディングを追加して、モデルに入力できる形式にします。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502d2af2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Cleaning text from test data\n",
    "test_data['prompt_clean'] = test_data['prompt'].apply(clean_text)\n",
    "test_data['response_a_clean'] = test_data['response_a'].apply(clean_text)\n",
    "test_data['response_b_clean'] = test_data['response_b'].apply(clean_text)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータに対して感情分析を行います。\n",
    "test_data['sentiment_prompt'] = test_data['prompt_clean'].apply(sentiment_analysis)  # クリーニングされたプロンプトに感情分析を適用し、結果を'sentiment_prompt'列に格納します。\n",
    "test_data['sentiment_response_a'] = test_data['response_a_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスAに感情分析を適用し、結果を'sentiment_response_a'列に格納します。\n",
    "test_data['sentiment_response_b'] = test_data['response_b_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスBに感情分析を適用し、結果を'sentiment_response_b'列に格納します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストの感情スコアが計算され、\n",
    "# 後のモデルに対する入力として使用できるようになります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.073651Z",
     "iopub.status.busy": "2024-07-15T10:40:02.073274Z",
     "iopub.status.idle": "2024-07-15T10:40:02.087868Z",
     "shell.execute_reply": "2024-07-15T10:40:02.086574Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.073619Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに対して感情分析を行います。\n",
    "test_data['sentiment_prompt'] = test_data['prompt_clean'].apply(sentiment_analysis)  # クリーニングされたプロンプトに感情分析を適用し、結果を'sentiment_prompt'列に格納します。\n",
    "test_data['sentiment_response_a'] = test_data['response_a_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスAに感情分析を適用し、結果を'sentiment_response_a'列に格納します。\n",
    "test_data['sentiment_response_b'] = test_data['response_b_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスBに感情分析を適用し、結果を'sentiment_response_b'列に格納します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストの感情スコアが計算され、\n",
    "# 後のモデルに対する入力として使用できるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2737e73",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Tokenize text from test data\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['prompt_clean'])\n",
    "response_a_test_sequences = tokenizer.texts_to_sequences(test_data['response_a_clean'])\n",
    "response_b_test_sequences = tokenizer.texts_to_sequences(test_data['response_b_clean'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータからテキスト構造の特徴量を作成します。\n",
    "test_data['word_count_prompt'] = test_data['prompt_clean'].apply(word_count)  # プロンプトの単語数を計算し、'word_count_prompt'列に格納します。\n",
    "test_data['word_count_response_a'] = test_data['response_a_clean'].apply(word_count)  # レスポンスAの単語数を計算し、'word_count_response_a'列に格納します。\n",
    "test_data['word_count_response_b'] = test_data['response_b_clean'].apply(word_count)  # レスポンスBの単語数を計算し、'word_count_response_b'列に格納します。\n",
    "test_data['char_count_prompt'] = test_data['prompt_clean'].apply(char_count)  # プロンプトの文字数を計算し、'char_count_prompt'列に格納します。\n",
    "test_data['char_count_response_a'] = test_data['response_a_clean'].apply(char_count)  # レスポンスAの文字数を計算し、'char_count_response_a'列に格納します。\n",
    "test_data['char_count_response_b'] = test_data['response_b_clean'].apply(char_count)  # レスポンスBの文字数を計算し、'char_count_response_b'列に格納します。\n",
    "test_data['lexical_diversity_prompt'] = test_data['prompt_clean'].apply(lexical_diversity)  # プロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "test_data['lexical_diversity_response_a'] = test_data['response_a_clean'].apply(lexical_diversity)  # レスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "test_data['lexical_diversity_response_b'] = test_data['response_b_clean'].apply(lexical_diversity)  # レスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "test_data['syllable_count_prompt'] = test_data['prompt_clean'].apply(syllable_count)  # プロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "test_data['syllable_count_response_a'] = test_data['response_a_clean'].apply(syllable_count)  # レスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "test_data['syllable_count_response_b'] = test_data['response_b_clean'].apply(syllable_count)  # レスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "test_data['sentence_count_prompt'] = test_data['prompt_clean'].apply(sentence_count)  # プロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "test_data['sentence_count_response_a'] = test_data['response_a_clean'].apply(sentence_count)  # レスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "test_data['sentence_count_response_b'] = test_data['response_b_clean'].apply(sentence_count)  # レスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "test_data['flesch_reading_ease_prompt'] = test_data['prompt_clean'].apply(flesch_reading_ease)  # プロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "test_data['flesch_reading_ease_response_a'] = test_data['response_a_clean'].apply(flesch_reading_ease)  # レスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "test_data['flesch_reading_ease_response_b'] = test_data['response_b_clean'].apply(flesch_reading_ease)  # レスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.089988Z",
     "iopub.status.busy": "2024-07-15T10:40:02.089469Z",
     "iopub.status.idle": "2024-07-15T10:40:02.117195Z",
     "shell.execute_reply": "2024-07-15T10:40:02.115839Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.089945Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータからテキスト構造の特徴量を作成します。\n",
    "test_data['word_count_prompt'] = test_data['prompt_clean'].apply(word_count)  # プロンプトの単語数を計算し、'word_count_prompt'列に格納します。\n",
    "test_data['word_count_response_a'] = test_data['response_a_clean'].apply(word_count)  # レスポンスAの単語数を計算し、'word_count_response_a'列に格納します。\n",
    "test_data['word_count_response_b'] = test_data['response_b_clean'].apply(word_count)  # レスポンスBの単語数を計算し、'word_count_response_b'列に格納します。\n",
    "test_data['char_count_prompt'] = test_data['prompt_clean'].apply(char_count)  # プロンプトの文字数を計算し、'char_count_prompt'列に格納します。\n",
    "test_data['char_count_response_a'] = test_data['response_a_clean'].apply(char_count)  # レスポンスAの文字数を計算し、'char_count_response_a'列に格納します。\n",
    "test_data['char_count_response_b'] = test_data['response_b_clean'].apply(char_count)  # レスポンスBの文字数を計算し、'char_count_response_b'列に格納します。\n",
    "test_data['lexical_diversity_prompt'] = test_data['prompt_clean'].apply(lexical_diversity)  # プロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "test_data['lexical_diversity_response_a'] = test_data['response_a_clean'].apply(lexical_diversity)  # レスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "test_data['lexical_diversity_response_b'] = test_data['response_b_clean'].apply(lexical_diversity)  # レスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "test_data['syllable_count_prompt'] = test_data['prompt_clean'].apply(syllable_count)  # プロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "test_data['syllable_count_response_a'] = test_data['response_a_clean'].apply(syllable_count)  # レスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "test_data['syllable_count_response_b'] = test_data['response_b_clean'].apply(syllable_count)  # レスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "test_data['sentence_count_prompt'] = test_data['prompt_clean'].apply(sentence_count)  # プロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "test_data['sentence_count_response_a'] = test_data['response_a_clean'].apply(sentence_count)  # レスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "test_data['sentence_count_response_b'] = test_data['response_b_clean'].apply(sentence_count)  # レスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "test_data['flesch_reading_ease_prompt'] = test_data['prompt_clean'].apply(flesch_reading_ease)  # プロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "test_data['flesch_reading_ease_response_a'] = test_data['response_a_clean'].apply(flesch_reading_ease)  # レスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "test_data['flesch_reading_ease_response_b'] = test_data['response_b_clean'].apply(flesch_reading_ease)  # レスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420978f3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Padding sequences from test data\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post')\n",
    "response_a_test_sequences = pad_sequences(response_a_test_sequences, maxlen=max_len, padding='post')\n",
    "response_b_test_sequences = pad_sequences(response_b_test_sequences, maxlen=max_len, padding='post')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータに埋め込みを追加します。\n",
    "test_data = add_embeddings_to_dataframe(test_data, columns_to_embed)  # 定義した列に対して埋め込みを生成し、テストデータフレームに追加します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストに対してBERT埋め込みが計算され、\n",
    "# 他の特徴量と一緒に保持されるようになります。これによって、モデルに対する入力が整います。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.119023Z",
     "iopub.status.busy": "2024-07-15T10:40:02.118583Z",
     "iopub.status.idle": "2024-07-15T10:40:12.682698Z",
     "shell.execute_reply": "2024-07-15T10:40:12.681274Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.11899Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに埋め込みを追加します。\n",
    "test_data = add_embeddings_to_dataframe(test_data, columns_to_embed)  # 定義した列に対して埋め込みを生成し、テストデータフレームに追加します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストに対してBERT埋め込みが計算され、\n",
    "# 他の特徴量と一緒に保持されるようになります。これによって、モデルに対する入力が整います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c588d889",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Sentiment analysis for test data\n",
    "test_data['sentiment_prompt'] = test_data['prompt_clean'].apply(sentiment_analysis)\n",
    "test_data['sentiment_response_a'] = test_data['response_a_clean'].apply(sentiment_analysis)\n",
    "test_data['sentiment_response_b'] = test_data['response_b_clean'].apply(sentiment_analysis)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータのコサイン類似度を計算します。\n",
    "test_data['similarity_prompt_response_a'] = test_data.apply(  # プロンプト埋め込みとレスポンスA埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "test_data['similarity_prompt_response_b'] = test_data.apply(  # プロンプト埋め込みとレスポンスB埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.684691Z",
     "iopub.status.busy": "2024-07-15T10:40:12.684291Z",
     "iopub.status.idle": "2024-07-15T10:40:12.702179Z",
     "shell.execute_reply": "2024-07-15T10:40:12.700706Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.684656Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのコサイン類似度を計算します。\n",
    "test_data['similarity_prompt_response_a'] = test_data.apply(  # プロンプト埋め込みとレスポンスA埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "test_data['similarity_prompt_response_b'] = test_data.apply(  # プロンプト埋め込みとレスポンスB埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fc0212",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Creating features of text structure from test data\n",
    "test_data['word_count_prompt'] = test_data['prompt_clean'].apply(word_count)\n",
    "test_data['word_count_response_a'] = test_data['response_a_clean'].apply(word_count)\n",
    "test_data['word_count_response_b'] = test_data['response_b_clean'].apply(word_count)\n",
    "test_data['char_count_prompt'] = test_data['prompt_clean'].apply(char_count)\n",
    "test_data['char_count_response_a'] = test_data['response_a_clean'].apply(char_count)\n",
    "test_data['char_count_response_b'] = test_data['response_b_clean'].apply(char_count)\n",
    "test_data['lexical_diversity_prompt'] = test_data['prompt_clean'].apply(lexical_diversity)\n",
    "test_data['lexical_diversity_response_a'] = test_data['response_a_clean'].apply(lexical_diversity)\n",
    "test_data['lexical_diversity_response_b'] = test_data['response_b_clean'].apply(lexical_diversity)\n",
    "test_data['syllable_count_prompt'] = test_data['prompt_clean'].apply(syllable_count)\n",
    "test_data['syllable_count_response_a'] = test_data['response_a_clean'].apply(syllable_count)\n",
    "test_data['syllable_count_response_b'] = test_data['response_b_clean'].apply(syllable_count)\n",
    "test_data['sentence_count_prompt'] = test_data['prompt_clean'].apply(sentence_count)\n",
    "test_data['sentence_count_response_a'] = test_data['response_a_clean'].apply(sentence_count)\n",
    "test_data['sentence_count_response_b'] = test_data['response_b_clean'].apply(sentence_count)\n",
    "test_data['flesch_reading_ease_prompt'] = test_data['prompt_clean'].apply(flesch_reading_ease)\n",
    "test_data['flesch_reading_ease_response_a'] = test_data['response_a_clean'].apply(flesch_reading_ease)\n",
    "test_data['flesch_reading_ease_response_b'] = test_data['response_b_clean'].apply(flesch_reading_ease)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "X_test = test_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                    'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                    'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                    'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                    'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                    'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                    'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                    'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、テストデータの特徴量（X_test）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# モデルによる予測のために使用されます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.703966Z",
     "iopub.status.busy": "2024-07-15T10:40:12.703587Z",
     "iopub.status.idle": "2024-07-15T10:40:12.72027Z",
     "shell.execute_reply": "2024-07-15T10:40:12.718688Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.703935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                    'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                    'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                    'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                    'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                    'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                    'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                    'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、テストデータの特徴量（X_test）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# モデルによる予測のために使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809282ac",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Embedding from test data\n",
    "test_data = add_embeddings_to_dataframe(test_data, columns_to_embed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "test_pred_proba = best_model.predict(X_test)  # 最良のモデルを使用してテストデータに対する予測確率を計算します。\n",
    "\n",
    "# このコードにより、テストデータに対して最良のモデルが予測を行い、\n",
    "# 各クラスに対する確率が'test_pred_proba'に格納されます。これにより、後でクラスラベルを決定するために使用できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.722607Z",
     "iopub.status.busy": "2024-07-15T10:40:12.722101Z",
     "iopub.status.idle": "2024-07-15T10:40:12.855745Z",
     "shell.execute_reply": "2024-07-15T10:40:12.854613Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.722567Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred_proba = best_model.predict(X_test)  # 最良のモデルを使用してテストデータに対する予測確率を計算します。\n",
    "\n",
    "# このコードにより、テストデータに対して最良のモデルが予測を行い、\n",
    "# 各クラスに対する確率が'test_pred_proba'に格納されます。これにより、後でクラスラベルを決定するために使用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bb9dd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Cosine similarity from test data\n",
    "test_data['similarity_prompt_response_a'] = test_data.apply(\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n",
    "\n",
    "test_data['similarity_prompt_response_b'] = test_data.apply(\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "submission = pd.DataFrame(test_data['id'])  # テストデータの'id'列を含む新しいデータフレームを作成します。\n",
    "submission['winner_model_a'] = test_pred_proba[:, 0]  # モデルAの勝率を追加します。\n",
    "submission['winner_model_b'] = test_pred_proba[:, 1]  # モデルBの勝率を追加します。\n",
    "submission['winner_tie'] = test_pred_proba[:, 2]  # 引き分けの勝率を追加します。\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)  # 提出用データフレームをCSVファイルに保存します。\n",
    "\n",
    "# このコードにより、予測結果を含む提出ファイルが作成され、コンペティションへの提出に利用できます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.857957Z",
     "iopub.status.busy": "2024-07-15T10:40:12.85759Z",
     "iopub.status.idle": "2024-07-15T10:40:12.870832Z",
     "shell.execute_reply": "2024-07-15T10:40:12.8695Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.857926Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_data['id'])  # テストデータの'id'列を含む新しいデータフレームを作成します。\n",
    "submission['winner_model_a'] = test_pred_proba[:, 0]  # モデルAの勝率を追加します。\n",
    "submission['winner_model_b'] = test_pred_proba[:, 1]  # モデルBの勝率を追加します。\n",
    "submission['winner_tie'] = test_pred_proba[:, 2]  # 引き分けの勝率を追加します。\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)  # 提出用データフレームをCSVファイルに保存します。\n",
    "\n",
    "# このコードにより、予測結果を含む提出ファイルが作成され、コンペティションへの提出に利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e132cebc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "X_test = test_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',\n",
    "                    'char_count_prompt', 'char_count_response_a', 'char_count_response_b',\n",
    "                    'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',\n",
    "                    'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',\n",
    "                    'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',\n",
    "                    'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',\n",
    "                    'similarity_prompt_response_a', 'similarity_prompt_response_b', \n",
    "                    'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "submission  # 作成した提出用データフレームを表示します。\n",
    "\n",
    "# これにより、提出ファイルに含まれる内容を確認できます。各行にはテストデータのIDと、その勝者モデルに対する予測確率が含まれています。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.872888Z",
     "iopub.status.busy": "2024-07-15T10:40:12.872415Z",
     "iopub.status.idle": "2024-07-15T10:40:12.887076Z",
     "shell.execute_reply": "2024-07-15T10:40:12.88578Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.87285Z"
    }
   },
   "outputs": [],
   "source": [
    "submission  # 作成した提出用データフレームを表示します。\n",
    "\n",
    "# これにより、提出ファイルに含まれる内容を確認できます。各行にはテストデータのIDと、その勝者モデルに対する予測確率が含まれています。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
