{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "595c538a",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookでは、「LMSYS - Chatbot Arena」コンペティションに参加するためのモデルを構築しています。具体的には、大規模言語モデル（LLM）を用いて、異なるチャットボットの応答を比較し、どちらの応答が好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "### 問題に取り組んでいる内容\n",
    "Notebookは、人間によるチャットボットの応答の選択に基づいて、どのモデルがより好ましいかを予測するために設計されています。トレーニングデータには、ユーザーが選んだ応答が含まれています。そのため、各応答が勝つ確率を計算し、それに基づいて予測を行います。\n",
    "\n",
    "### 使用している手法やライブラリ\n",
    "1. **ライブラリ**\n",
    "   - `transformers`: Hugging Faceのライブラリを使用し、DeBERTa V3モデルを含む事前学習済みモデルを利用してシーケンス分類タスクを処理。\n",
    "   - `datasets`: データを簡単に処理するためのライブラリ。\n",
    "   - `sklearn`: モデル評価とデータ処理に利用。\n",
    "   - `torch`: PyTorchを使用してニューラルネットワークを構築し、訓練します。\n",
    "\n",
    "2. **主要な手法**\n",
    "   - **データ前処理**: トークナイゼーションを行い、モデルが理解できる形式にデータを変換します。\n",
    "   - **モデル構築**: DeBERTa V3モデルを使用して、分類タスクとして設定。\n",
    "   - **トレーニング**: Stratified K-Fold交差検証を用いて、モデルの訓練と検証を行い、最良モデルを選択します。\n",
    "   - **評価指標**: ログ損失(log loss)と精度(accuracy)を用いてモデルのパフォーマンスを評価します。\n",
    "\n",
    "3. **訓練および推論設定**\n",
    "   - 訓練と評価のためのハイパーパラメータ（学習率やバッチサイズなど）を設定し、混合精度訓練を行います。\n",
    "   - 実際のデータでトレーニングを行った後、テストデータを使ってモデルが生成した予測を取得し、結果をCSVファイルとして保存します。\n",
    "\n",
    "このNotebookは、データの読み込みからモデルの訓練、推論、結果の保存までの全過程をカバーしており、コンペティション参加者が迅速にモデルを構築し、提出できるようになっています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472acaa",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebook内のコードやドキュメントに出てくる専門用語の解説です。特に初心者がつまずきそうな部分や、このノートブック特有の用語に焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **StratifiedKFold**:\n",
    "   - クロスバリデーションの一手法で、データセットのラベル分布がそれぞれのフォールドに均等に分配されるように訓練データを分ける方法。クラスの不均衡問題を軽減するのに役立つ。\n",
    "\n",
    "2. **AutoTokenizer**:\n",
    "   - Hugging FaceのTransformersライブラリにおけるクラスで、事前学習済みのトークナイザーを自動で読み込むためのもの。テキストをトークン（数値の列）に変換するために使われる。\n",
    "\n",
    "3. **attention_mask**:\n",
    "   - トークン化された入力データに含まれる、どのトークンが意味を持ち、どれがパディングであるかを示すバイナリマスク。1は有効なトークン、0はパディングトークンを示す。\n",
    "\n",
    "4. **DataCollatorWithPadding**:\n",
    "   - データローダの一部で、バッチ内のデータの長さを揃えるためにパディングを適用する役割を持つコンポーネント。これにより、ミニバッチが同じ形状を持つようになる。\n",
    "\n",
    "5. **log_loss**:\n",
    "   - モデルの出力確率と実際のラベルとの間の誤差を測る指標。特にクラス確率のモデル評価に使われる。値が小さいほどモデルの予測が良いことを示す。\n",
    "\n",
    "6. **fp16 (半精度浮動小数点)**:\n",
    "   - モデルの訓練において使用されるデータ型の一つで、通常の32ビット浮動小数点数（fp32）よりもメモリを少なくすることができ、計算速度も向上する。一部のハードウェアでは特に効率的。\n",
    "\n",
    "7. **EarlyStoppingCallback**:\n",
    "   - モデルの訓練中に、指定された回数（patience）で評価メトリックが改善しない場合に訓練を停止するための仕組み。オーバーフィッティングを防ぐのに役立つ。\n",
    "\n",
    "8. **num_labels**:\n",
    "   - モデルのアウトプット層において予測可能なクラスの数を指定するためのパラメータ。バイナリ分類や多クラス分類の場合に、それぞれのクラス数に設定される。\n",
    "\n",
    "9. **weight_decay**:\n",
    "   - モデルを訓練する際に、重みの大きさを抑え、過学習を防ぐためのペナルティの設定。L2正則化とも呼ばれ、設定された値に比例して重みを減衰させる。\n",
    "\n",
    "10. **train_fraction**:\n",
    "    - データセット全体の中で、トレーニングに使用するデータの割合を指定するパラメータ。バリデーションやテストデータとの適切な分割を行うために使われる。\n",
    "\n",
    "これらの用語が理解できるようになると、Notebookの内容をより良く把握し、実践的な機械学習モデルの開発に役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0108271",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch\n",
    "from functools import partial\n",
    "import warnings\n",
    "from transformers import logging as transformers_logging\n",
    "from transformers import EarlyStoppingCallback\n",
    "import json\n",
    "from pprint import pformat\n",
    "from tqdm import trange\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "TYPE = \"large\"\n",
    "VER= 14\n",
    "DATE = \"0717\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# Set up logging\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.basicConfig(level=logging.INFO, filename=f'logs_v{VER}.log', filemode='a',\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class PATHS:\n",
    "    train_path = '/kaggle/input/lmsys-chatbot-arena/train.csv'\n",
    "    test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'\n",
    "    sub_path = '/kaggle/input/lmsys-chatbot-arena/sample_submission.csv'\n",
    "    model_name = f\"deberta-v3-{TYPE}\"\n",
    "    model_path = f\"/root/autodl-tmp/ase2/huggingfacedebertav3variants/{model_name}\"\n",
    "    tokenizer_path = f\"/kaggle/input/lmsys-{TYPE}{VER}-{DATE}/fold_0/tokenizer\"\n",
    "    general_tokenizer = \"/kaggle/input/lmsys-base4-0704/fold_0/tokenizer\"\n",
    "\n",
    "class CFG:\n",
    "    seed = 42\n",
    "    max_length = 512\n",
    "    lr = 5e-5  # 学习率\n",
    "    weight_decay = 0.01  # 权重衰减\n",
    "    warmup_ratio = 0 # 学习率预热比例\n",
    "    max_grad_norm = 1000  # 梯度裁剪最大范数\n",
    "    lr_scheduler_type = 'linear'  # 学习率调度类型\n",
    "    frozen_embedding = False # 冻结前面的层\n",
    "    frozen_num = 6\n",
    "    train_batch_size = 32  # 训练批量大小\n",
    "    eval_batch_size = 64  # 评估批量大小\n",
    "    evaluation_strategy = 'steps'  # 更改为 steps 评估策略\n",
    "    metric_for_best_model = \"eval_log_loss\"  # 用于选择最佳模型的度量标准\n",
    "    save_strategy = 'steps'  # 更改为 steps 保存策略\n",
    "    save_steps = 200  # 每 步保存一次模型\n",
    "    save_total_limit = 1  # 保存检查点总数限制\n",
    "    train_epochs = 5  # 训练周期数\n",
    "    num_labels = 6\n",
    "    output_dir = f'/kaggle/input/lmsys-{TYPE}{VER}-{DATE}'  # 输出目录\n",
    "    fp16 = True  # 使用混合精度训练\n",
    "    load_best_model_at_end = True  # 训练结束时加载最佳模型\n",
    "    report_to = 'none'  # 不报告训练日志到外部工具\n",
    "    optim = 'adamw_torch'  # 优化器类型\n",
    "    logging_first_step = True  # 记录第一步的日志\n",
    "    logging_steps = 200  # 每 步记录一次日志\n",
    "    logging_dir =f'logs_v{VER}'  # 日志保存目录\n",
    "    n_splits = 5\n",
    "    model_name = PATHS.model_name\n",
    "    greater_is_better = False\n",
    "    early_stop = False\n",
    "    early_stopping_patience = 3  # Number of evaluation calls with no improvement after which training will be stopped\n",
    "    early_stopping_threshold = 0.001  # Minimum change to qualify as an improvement\n",
    "\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=CFG.seed)\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(PATHS.tokenizer_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATHS.general_tokenizer)\n",
    "sep_token = tokenizer.sep_token_id\n",
    "\n",
    "def log_parameters(logger):\n",
    "    \"\"\"Log all parameters from PATHS and CFG classes.\"\"\"\n",
    "    logger.info(\"=== Parameter Settings ===\")\n",
    "    \n",
    "    logger.info(\"PATHS:\")\n",
    "    for key, value in PATHS.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")\n",
    "    \n",
    "    logger.info(\"CFG:\")\n",
    "    for key, value in CFG.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")\n",
    "    \n",
    "    logger.info(\"=*100\")\n",
    "\n",
    "def tokenize_function(row, tokenizer):\n",
    "    max_len = CFG.max_length - 2 # We need 2 separator tokens\n",
    "    tokens_prompt = tokenizer(row['prompt'], truncation=True, max_length=max_len//4, add_special_tokens=False)['input_ids']\n",
    "    remaining_length = max_len - len(tokens_prompt)\n",
    "    \n",
    "    tokens_response_a = tokenizer(row['response_a'], truncation=True, max_length=remaining_length//2, add_special_tokens=False)['input_ids']\n",
    "    remaining_length -= len(tokens_response_a)\n",
    "    tokens_response_b = tokenizer(row['response_b'], truncation=True, max_length=remaining_length, add_special_tokens=False)['input_ids']\n",
    "    \n",
    "    input_ids = [tokenizer.cls_token_id] + tokens_prompt + [sep_token] + tokens_response_a + [sep_token] + tokens_response_b\n",
    "    token_type_ids = [0] * (len(tokens_prompt) + 2) + [1] * (len(tokens_response_a) + 1) + [2] * len(tokens_response_b)\n",
    "    attention_mask = [1] * len(input_ids)\n",
    "    \n",
    "    padding_length = CFG.max_length - len(input_ids)\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length\n",
    "        token_type_ids = token_type_ids + [0] * padding_length\n",
    "        attention_mask = attention_mask + [0] * padding_length\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids[:CFG.max_length],\n",
    "        'token_type_ids': token_type_ids[:CFG.max_length],\n",
    "        'attention_mask': attention_mask[:CFG.max_length],\n",
    "    }\n",
    "\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)\n",
    "    labels[df['winner_model_a'] == 1] = 0\n",
    "    labels[df['winner_model_b'] == 1] = 1\n",
    "    labels[df['winner_tie'] == 1] = 2\n",
    "    df['labels'] = labels\n",
    "    return df\n",
    "\n",
    "def process_data(df, mode='train'):\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    tokenized_dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=False)\n",
    "    remove_cols = ['id', 'prompt', 'response_a', 'response_b']\n",
    "    if mode == 'train':\n",
    "        remove_cols += ['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(remove_cols)\n",
    "    return tokenized_dataset\n",
    "\n",
    "def split_train_val(dataset, train_fraction):\n",
    "    np.random.seed(0)\n",
    "    ixs = np.arange(len(dataset))\n",
    "    cutoff = int(len(ixs) * train_fraction)\n",
    "    np.random.shuffle(ixs)\n",
    "    ixs_train = ixs[:cutoff]\n",
    "    ixs_val = ixs[cutoff:]\n",
    "    fit_train = dataset.select(ixs_train)\n",
    "    fit_val = dataset.select(ixs_val)\n",
    "    return fit_train, fit_val\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()\n",
    "    }\n",
    "    \n",
    "def train_model():\n",
    "    log_parameters(logger)\n",
    "    train_df = pd.read_csv(PATHS.train_path)\n",
    "    train_df = add_label(train_df)\n",
    "    train_tokenized = process_data(train_df, mode='train')\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_tokenized, train_tokenized['labels'])):\n",
    "        print(f\"Training fold {fold + 1}\")\n",
    "        logger.info(f\"Training fold {fold + 1}\")\n",
    "        \n",
    "        fit_train = train_tokenized.select(train_idx)\n",
    "        fit_val = train_tokenized.select(val_idx)\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            PATHS.model_path,\n",
    "            num_labels=3,\n",
    "            problem_type=\"single_label_classification\"\n",
    "        )\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=f\"{CFG.output_dir}/fold_{fold}\",  # 模型和检查点的输出目录\n",
    "            fp16=CFG.fp16,  # 使用混合精度训练\n",
    "            learning_rate=CFG.lr,  # 学习率\n",
    "            per_device_train_batch_size=CFG.train_batch_size,  # 每个设备上的训练批量大小\n",
    "            per_device_eval_batch_size=CFG.eval_batch_size,  # 每个设备上的评估批量大小\n",
    "            num_train_epochs=CFG.train_epochs,  # 训练的总周期数\n",
    "            weight_decay=CFG.weight_decay,  # 权重衰减（L2正则化）\n",
    "            evaluation_strategy=CFG.evaluation_strategy,  # 评估策略\n",
    "            metric_for_best_model=CFG.metric_for_best_model,  # 用于选择最佳模型的度量标准\n",
    "            save_strategy=CFG.save_strategy,  # 保存策略\n",
    "            save_total_limit=CFG.save_total_limit,  # 保存的检查点总数限制\n",
    "            load_best_model_at_end=CFG.load_best_model_at_end,  # 在训练结束时加载最佳模型\n",
    "            report_to=CFG.report_to,  # 不报告训练日志到外部工具\n",
    "            warmup_ratio=CFG.warmup_ratio,  # 学习率预热比例\n",
    "            lr_scheduler_type=CFG.lr_scheduler_type,  # 学习率调度类型\n",
    "            optim=CFG.optim,  # 使用的优化器类型\n",
    "            logging_first_step=CFG.logging_first_step,  # 记录第一步的日志\n",
    "            greater_is_better=CFG.greater_is_better,\n",
    "            \n",
    "            # max_grad_norm=CFG.max_grad_norm,  # 设置梯度裁剪\n",
    "            \n",
    "            logging_steps=CFG.logging_steps,  # 每 500 步记录一次日志\n",
    "            logging_dir=CFG.logging_dir,  # 日志保存目录\n",
    "        \n",
    "            save_steps=CFG.save_steps,  # 每  步保存一次模型\n",
    "            eval_steps=CFG.save_steps,  # 添加 eval_steps 参数,与 save_steps 保持一致\n",
    "        )\n",
    "\n",
    "         # Log training arguments\n",
    "        logger.info(\"Training arguments:\")\n",
    "        logger.info(pformat(training_args.to_dict()))\n",
    "\n",
    "        if CFG.frozen_embedding:\n",
    "            n = CFG.frozen_num\n",
    "            # 冻结嵌入层\n",
    "            for i, layer in enumerate(model.deberta.encoder.layer[:n]):\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False # True False\n",
    "            for param in model.deberta.embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # 初始化 tokenizer\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "        # Create EarlyStoppingCallback\n",
    "        if CFG.early_stop:\n",
    "            early_stopping_callback = EarlyStoppingCallback(\n",
    "                early_stopping_patience=CFG.early_stopping_patience,\n",
    "                early_stopping_threshold=CFG.early_stopping_threshold,\n",
    "            )\n",
    "        \n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,\n",
    "                data_collator=data_collator,\n",
    "                eval_dataset=fit_val,\n",
    "                compute_metrics=compute_metrics,\n",
    "                callbacks=[early_stopping_callback],  # Add the early stopping callback\n",
    "            )\n",
    "        else:\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,\n",
    "                data_collator=data_collator,\n",
    "                eval_dataset=fit_val,\n",
    "                compute_metrics=compute_metrics,\n",
    "            )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        # Save the model\n",
    "        trainer.save_model(f\"{CFG.output_dir}/fold_{fold}/best_model\")\n",
    "        tokenizer.save_pretrained(f\"{CFG.output_dir}/fold_{fold}/tokenizer\")\n",
    "        \n",
    "        # Log the results\n",
    "        eval_result = trainer.evaluate()\n",
    "        logger.info(f\"Fold {fold + 1} - Evaluation result: {eval_result}\")\n",
    "        logger.info(\"=*100\")\n",
    "\n",
    "def predict_test():\n",
    "    test_df = pd.read_csv(PATHS.test_path)\n",
    "    test_tokenized = process_data(test_df, mode='test')\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for fold in trange(CFG.n_splits):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f\"{CFG.output_dir}/fold_{fold}/best_model\")\n",
    "        model.eval()\n",
    "        \n",
    "        trainer = Trainer(model=model)\n",
    "        fold_preds = trainer.predict(test_tokenized).predictions\n",
    "        fold_preds = np.exp(fold_preds) / np.sum(np.exp(fold_preds), axis=1, keepdims=True)\n",
    "        predictions.append(fold_preds)\n",
    "    \n",
    "    # Average predictions across folds\n",
    "    final_preds = np.mean(predictions, axis=0)\n",
    "    display(predictions)\n",
    "    logger.info(f\"Final_preds: {final_preds}\")\n",
    "    \n",
    "    # Create submission file\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],\n",
    "        'winner_model_a': final_preds[:, 0],\n",
    "        'winner_model_b': final_preds[:, 1],\n",
    "        'winner_tie': final_preds[:, 2]\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    display(submission)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch\n",
    "from functools import partial\n",
    "import warnings\n",
    "from transformers import logging as transformers_logging\n",
    "from transformers import EarlyStoppingCallback\n",
    "import json\n",
    "from pprint import pformat\n",
    "from tqdm import trange\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "TYPE = \"large\"\n",
    "VER= 14\n",
    "DATE = \"0717\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# ロギングの設定\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.basicConfig(level=logging.INFO, filename=f'logs_v{VER}.log', filemode='a',\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class PATHS:\n",
    "    train_path = '/kaggle/input/lmsys-chatbot-arena/train.csv'  # トレーニングデータのパス\n",
    "    test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'    # テストデータのパス\n",
    "    sub_path = '/kaggle/input/lmsys-chatbot-arena/sample_submission.csv'  # 提出サンプルのパス\n",
    "    model_name = f\"deberta-v3-{TYPE}\"  # モデル名\n",
    "    model_path = f\"/root/autodl-tmp/ase2/huggingfacedebertav3variants/{model_name}\"  # モデルの保存パス\n",
    "    tokenizer_path = f\"/kaggle/input/lmsys-{TYPE}{VER}-{DATE}/fold_0/tokenizer\"  # トークナイザーのパス\n",
    "    general_tokenizer = \"/kaggle/input/lmsys-base4-0704/fold_0/tokenizer\"  # 一般的なトークナイザーのパス\n",
    "\n",
    "class CFG:\n",
    "    seed = 42  # 乱数シード\n",
    "    max_length = 512  # 最大入力長\n",
    "    lr = 5e-5  # 学習率\n",
    "    weight_decay = 0.01  # 重み減衰\n",
    "    warmup_ratio = 0 # 学習率ウォームアップ比率\n",
    "    max_grad_norm = 1000  # 最大勾配ノルム\n",
    "    lr_scheduler_type = 'linear'  # 学習率スケジュールタイプ\n",
    "    frozen_embedding = False # 埋め込み層を凍結するかどうか\n",
    "    frozen_num = 6  # 凍結する層の数\n",
    "    train_batch_size = 32  # 訓練バッチサイズ\n",
    "    eval_batch_size = 64  # 評価バッチサイズ\n",
    "    evaluation_strategy = 'steps'  # 評価戦略をステップに設定\n",
    "    metric_for_best_model = \"eval_log_loss\"  # 最良モデル選択のためのメトリック\n",
    "    save_strategy = 'steps'  # ステップごとに保存\n",
    "    save_steps = 200  # 200ステップごとにモデルを保存\n",
    "    save_total_limit = 1  # 保存されるチェックポイントの合計数制限\n",
    "    train_epochs = 5  # 訓練エポック数\n",
    "    num_labels = 6  # ラベルの数\n",
    "    output_dir = f'/kaggle/input/lmsys-{TYPE}{VER}-{DATE}'  # 出力ディレクトリ\n",
    "    fp16 = True  # 混合精度訓練を使用\n",
    "    load_best_model_at_end = True  # 訓練終了時に最良モデルをロード\n",
    "    report_to = 'none'  # 外部ツールに訓練ログを報告しない\n",
    "    optim = 'adamw_torch'  # オプティマイザタイプ\n",
    "    logging_first_step = True  # 最初のステップのログを記録する\n",
    "    logging_steps = 200  # 200ステップごとにログを記録\n",
    "    logging_dir =f'logs_v{VER}'  # ログ保存ディレクトリ\n",
    "    n_splits = 5  # クロスバリデーションの分割数\n",
    "    model_name = PATHS.model_name  # モデル名\n",
    "    greater_is_better = False  # メトリックが大きいほど良いかどうか\n",
    "    early_stop = False  # 早期停止を使用するか\n",
    "    early_stopping_patience = 3  # 改善なしでモデルの訓練を停止する評価の呼び出し回数\n",
    "    early_stopping_threshold = 0.001  # 改善と見なすための最小変化量\n",
    "\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)  # Pythonの乱数シードを設定\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # ハッシュシードを設定\n",
    "    np.random.seed(seed)  # NumPyの乱数シードを設定\n",
    "    torch.manual_seed(seed)  # PyTorchの乱数シードを設定\n",
    "    torch.cuda.manual_seed(seed)  # CUDAの乱数シードを設定\n",
    "    torch.backends.cudnn.deterministic = True  # 再現性を持たせる\n",
    "\n",
    "seed_everything(seed=CFG.seed)  # 乱数シードの設定\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(PATHS.tokenizer_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATHS.general_tokenizer)  # トークナイザーの初期化\n",
    "sep_token = tokenizer.sep_token_id  # セパレータトークンのIDを取得\n",
    "\n",
    "def log_parameters(logger):\n",
    "    \"\"\"PATHSとCFGクラスからすべてのパラメータをログに記録します。\"\"\"\n",
    "    logger.info(\"=== パラメータ設定 ===\")\n",
    "    \n",
    "    logger.info(\"PATHS:\")\n",
    "    for key, value in PATHS.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")  # 各パラメータをログに記録\n",
    "    \n",
    "    logger.info(\"CFG:\")\n",
    "    for key, value in CFG.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")  # 各パラメータをログに記録\n",
    "    \n",
    "    logger.info(\"=*100\")\n",
    "\n",
    "def tokenize_function(row, tokenizer):\n",
    "    max_len = CFG.max_length - 2  # セパレータトークンのために2を引く\n",
    "    tokens_prompt = tokenizer(row['prompt'], truncation=True, max_length=max_len//4, add_special_tokens=False)['input_ids']  # プロンプトをトークン化\n",
    "    remaining_length = max_len - len(tokens_prompt)  # 残りの長さを計算\n",
    "    \n",
    "    tokens_response_a = tokenizer(row['response_a'], truncation=True, max_length=remaining_length//2, add_special_tokens=False)['input_ids']  # 応答Aをトークン化\n",
    "    remaining_length -= len(tokens_response_a)  # 残りの長さを更新\n",
    "    tokens_response_b = tokenizer(row['response_b'], truncation=True, max_length=remaining_length, add_special_tokens=False)['input_ids']  # 応答Bをトークン化\n",
    "    \n",
    "    input_ids = [tokenizer.cls_token_id] + tokens_prompt + [sep_token] + tokens_response_a + [sep_token] + tokens_response_b  # 入力IDを作成\n",
    "    token_type_ids = [0] * (len(tokens_prompt) + 2) + [1] * (len(tokens_response_a) + 1) + [2] * len(tokens_response_b)  # トークンタイプIDsを作成\n",
    "    attention_mask = [1] * len(input_ids)  # アテンションマスクを作成\n",
    "    \n",
    "    padding_length = CFG.max_length - len(input_ids)  # パディングの長さを計算\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length  # パディングを追加\n",
    "        token_type_ids = token_type_ids + [0] * padding_length  # パディングを追加\n",
    "        attention_mask = attention_mask + [0] * padding_length  # パディングを追加\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids[:CFG.max_length],  # 最大長に制限する\n",
    "        'token_type_ids': token_type_ids[:CFG.max_length],  # 最大長に制限する\n",
    "        'attention_mask': attention_mask[:CFG.max_length],  # 最大長に制限する\n",
    "    }\n",
    "\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)  # ラベルの配列を作成\n",
    "    labels[df['winner_model_a'] == 1] = 0  # モデルAが勝った場合のラベル\n",
    "    labels[df['winner_model_b'] == 1] = 1  # モデルBが勝った場合のラベル\n",
    "    labels[df['winner_tie'] == 1] = 2  # 引き分けの場合のラベル\n",
    "    df['labels'] = labels  # データフレームにラベルを追加\n",
    "    return df\n",
    "\n",
    "def process_data(df, mode='train'):\n",
    "    dataset = Dataset.from_pandas(df)  # データフレームからデータセットを作成\n",
    "    tokenized_dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=False)  # データセットをトークン化\n",
    "    remove_cols = ['id', 'prompt', 'response_a', 'response_b']  # 削除する列を指定\n",
    "    if mode == 'train':\n",
    "        remove_cols += ['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie']  # トレーニングモードの場合、さらに列を削除\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(remove_cols)  # 指定した列を削除\n",
    "    return tokenized_dataset\n",
    "\n",
    "def split_train_val(dataset, train_fraction):\n",
    "    np.random.seed(0)  # 乱数シードを設定\n",
    "    ixs = np.arange(len(dataset))  # データセットのインデックスを生成\n",
    "    cutoff = int(len(ixs) * train_fraction)  # 訓練データのカットオフポイント\n",
    "    np.random.shuffle(ixs)  # インデックスをシャッフル\n",
    "    ixs_train = ixs[:cutoff]  # 訓練用インデックス\n",
    "    ixs_val = ixs[cutoff:]  # 検証用インデックス\n",
    "    fit_train = dataset.select(ixs_train)  # 訓練データを選択\n",
    "    fit_val = dataset.select(ixs_val)  # 検証データを選択\n",
    "    return fit_train, fit_val\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # 評価予測からロジットとラベルを取得\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)  # 確率を計算\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),  # ログ損失を計算\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()  # 精度を計算\n",
    "    }\n",
    "    \n",
    "def train_model():\n",
    "    log_parameters(logger)  # パラメータをログに記録\n",
    "    train_df = pd.read_csv(PATHS.train_path)  # トレーニングデータを読み込み\n",
    "    train_df = add_label(train_df)  # ラベルを追加\n",
    "    train_tokenized = process_data(train_df, mode='train')  # トークン化されたデータを取得\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)  # ストラティファイドKフォールドを作成\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_tokenized, train_tokenized['labels'])):  # 各フォールドでトレーニングと検証インデックスを分割\n",
    "        print(f\"フォールド {fold + 1} のトレーニング\")  # フォールド番号を出力\n",
    "        logger.info(f\"フォールド {fold + 1} のトレーニング\")  # フォールド番号をログに記録\n",
    "        \n",
    "        fit_train = train_tokenized.select(train_idx)  # 訓練データを選択\n",
    "        fit_val = train_tokenized.select(val_idx)  # 検証データを選択\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(  # 事前学習済みモデルを読み込み\n",
    "            PATHS.model_path,\n",
    "            num_labels=3,  # ラベル数を指定\n",
    "            problem_type=\"single_label_classification\"  # 問題タイプを指定\n",
    "        )\n",
    "        \n",
    "        training_args = TrainingArguments(  # 訓練引数を設定\n",
    "            output_dir=f\"{CFG.output_dir}/fold_{fold}\",  # モデルとチェックポイントの出力ディレクトリ\n",
    "            fp16=CFG.fp16,  # 混合精度訓練を使用\n",
    "            learning_rate=CFG.lr,  # 学習率\n",
    "            per_device_train_batch_size=CFG.train_batch_size,  # 各デバイスでの訓練バッチサイズ\n",
    "            per_device_eval_batch_size=CFG.eval_batch_size,  # 各デバイスでの評価バッチサイズ\n",
    "            num_train_epochs=CFG.train_epochs,  # トレーニングのエポック数\n",
    "            weight_decay=CFG.weight_decay,  # 重み減衰\n",
    "            evaluation_strategy=CFG.evaluation_strategy,  # 評価戦略\n",
    "            metric_for_best_model=CFG.metric_for_best_model,  # 最良モデルを選択するためのメトリック\n",
    "            save_strategy=CFG.save_strategy,  # 保存戦略\n",
    "            save_total_limit=CFG.save_total_limit,  # チェックポイントの総保存数制限\n",
    "            load_best_model_at_end=CFG.load_best_model_at_end,  # 最良モデルを訓練終了時にロード\n",
    "            report_to=CFG.report_to,  # ログを外部ツールに報告しない\n",
    "            warmup_ratio=CFG.warmup_ratio,  # 学習率のウォームアップ比率\n",
    "            lr_scheduler_type=CFG.lr_scheduler_type,  # 学習率スケジューラーのタイプ\n",
    "            optim=CFG.optim,  # 使用するオプティマイザのタイプ\n",
    "            logging_first_step=CFG.logging_first_step,  # 最初のステップのログを記録\n",
    "            greater_is_better=CFG.greater_is_better,  # メトリックが大きいほど良いかどうか\n",
    "            \n",
    "            # max_grad_norm=CFG.max_grad_norm,  # 勾配クリッピングの設定\n",
    "            \n",
    "            logging_steps=CFG.logging_steps,  # 200ステップごとにログを記録\n",
    "            logging_dir =f'logs_v{VER}',  # ログ保存ディレクトリ\n",
    "        \n",
    "            save_steps=CFG.save_steps,  # 200ステップごとにモデルを保存\n",
    "            eval_steps=CFG.save_steps,  # eval_stepsパラメータを追加、save_stepsと一致させる\n",
    "        )\n",
    "\n",
    "         # 訓練引数をログに記録\n",
    "        logger.info(\"訓練引数:\")\n",
    "        logger.info(pformat(training_args.to_dict()))\n",
    "\n",
    "        if CFG.frozen_embedding:  # 埋め込み層を凍結する設定の場合\n",
    "            n = CFG.frozen_num\n",
    "            # 埋め込み層を凍結\n",
    "            for i, layer in enumerate(model.deberta.encoder.layer[:n]):\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False  # 訓練から除外\n",
    "            for param in model.deberta.embeddings.parameters():\n",
    "                param.requires_grad = False  # 訓練から除外\n",
    "\n",
    "        # トークナイザーの初期化\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)  # データコラトレーターの初期化\n",
    "\n",
    "        # EarlyStoppingCallbackの作成\n",
    "        if CFG.early_stop:  # 早期停止を使用する設定の場合\n",
    "            early_stopping_callback = EarlyStoppingCallback(\n",
    "                early_stopping_patience=CFG.early_stopping_patience,  # 訓練停止の耐久期間\n",
    "                early_stopping_threshold=CFG.early_stopping_threshold,  # 改善と見なす最小変化\n",
    "            )\n",
    "        \n",
    "            trainer = Trainer(  # トレーナーの初期化\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,  # 訓練データセット\n",
    "                data_collator=data_collator,  # データコラトレーター\n",
    "                eval_dataset=fit_val,  # 検証データセット\n",
    "                compute_metrics=compute_metrics,  # メトリックの計算関数\n",
    "                callbacks=[early_stopping_callback],  # 早期停止コールバックを追加\n",
    "            )\n",
    "        else:\n",
    "            trainer = Trainer(  # トレーナーの初期化\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,  # 訓練データセット\n",
    "                data_collator=data_collator,  # データコラトレーター\n",
    "                eval_dataset=fit_val,  # 検証データセット\n",
    "                compute_metrics=compute_metrics,  # メトリックの計算関数\n",
    "            )\n",
    "        \n",
    "        trainer.train()  # モデルの訓練を開始\n",
    "        \n",
    "        # モデルを保存\n",
    "        trainer.save_model(f\"{CFG.output_dir}/fold_{fold}/best_model\")  # 最良モデルを保存\n",
    "        tokenizer.save_pretrained(f\"{CFG.output_dir}/fold_{fold}/tokenizer\")  # トークナイザーを保存\n",
    "        \n",
    "        # 結果をログに記録\n",
    "        eval_result = trainer.evaluate()  # 評価を実施\n",
    "        logger.info(f\"フォールド {fold + 1} - 評価結果: {eval_result}\")  # 評価結果をログに記録\n",
    "        logger.info(\"=*100\")\n",
    "\n",
    "def predict_test():\n",
    "    test_df = pd.read_csv(PATHS.test_path)  # テストデータを読み込み\n",
    "    test_tokenized = process_data(test_df, mode='test')  # トークン化されたテストデータを取得\n",
    "    \n",
    "    predictions = []  # 予測結果を格納するリスト\n",
    "    \n",
    "    for fold in trange(CFG.n_splits):  # 各フォールドで予測を行う\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f\"{CFG.output_dir}/fold_{fold}/best_model\")  # 最良モデルを読み込み\n",
    "        model.eval()  # 評価モードに設定\n",
    "        \n",
    "        trainer = Trainer(model=model)  # トレーナーの初期化\n",
    "        fold_preds = trainer.predict(test_tokenized).predictions  # テストデータに対する予測を取得\n",
    "        fold_preds = np.exp(fold_preds) / np.sum(np.exp(fold_preds), axis=1, keepdims=True)  # 確率に変換\n",
    "        predictions.append(fold_preds)  # フォールドの予測結果を追加\n",
    "    \n",
    "    # フォールド間の予測を平均化\n",
    "    final_preds = np.mean(predictions, axis=0)  # 最終予測を計算\n",
    "    display(predictions)  # 予測結果を表示\n",
    "    logger.info(f\"最終予測: {final_preds}\")  # 最終予測をログに記録\n",
    "    \n",
    "    # 提出ファイルの作成\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],  # テストデータのID\n",
    "        'winner_model_a': final_preds[:, 0],  # モデルAの勝者確率\n",
    "        'winner_model_b': final_preds[:, 1],  # モデルBの勝者確率\n",
    "        'winner_tie': final_preds[:, 2]  # 引き分け確率\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)  # 提出ファイルをCSV形式で保存\n",
    "    display(submission)  # 提出結果を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-06T16:45:31.260392Z",
     "iopub.status.busy": "2024-07-06T16:45:31.260005Z",
     "iopub.status.idle": "2024-07-06T16:45:31.582586Z",
     "shell.execute_reply": "2024-07-06T16:45:31.581769Z",
     "shell.execute_reply.started": "2024-07-06T16:45:31.26036Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import log_loss\n",
    "import torch\n",
    "from functools import partial\n",
    "import warnings\n",
    "from transformers import logging as transformers_logging\n",
    "from transformers import EarlyStoppingCallback\n",
    "import json\n",
    "from pprint import pformat\n",
    "from tqdm import trange\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "TYPE = \"large\"\n",
    "VER= 14\n",
    "DATE = \"0717\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# ロギングの設定\n",
    "transformers_logging.set_verbosity_error()\n",
    "logging.basicConfig(level=logging.INFO, filename=f'logs_v{VER}.log', filemode='a',\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class PATHS:\n",
    "    train_path = '/kaggle/input/lmsys-chatbot-arena/train.csv'  # トレーニングデータのパス\n",
    "    test_path = '/kaggle/input/lmsys-chatbot-arena/test.csv'    # テストデータのパス\n",
    "    sub_path = '/kaggle/input/lmsys-chatbot-arena/sample_submission.csv'  # 提出サンプルのパス\n",
    "    model_name = f\"deberta-v3-{TYPE}\"  # モデル名\n",
    "    model_path = f\"/root/autodl-tmp/ase2/huggingfacedebertav3variants/{model_name}\"  # モデルの保存パス\n",
    "    tokenizer_path = f\"/kaggle/input/lmsys-{TYPE}{VER}-{DATE}/fold_0/tokenizer\"  # トークナイザーのパス\n",
    "    general_tokenizer = \"/kaggle/input/lmsys-base4-0704/fold_0/tokenizer\"  # 一般的なトークナイザーのパス\n",
    "\n",
    "class CFG:\n",
    "    seed = 42  # 乱数シード\n",
    "    max_length = 512  # 最大入力長\n",
    "    lr = 5e-5  # 学習率\n",
    "    weight_decay = 0.01  # 重み減衰\n",
    "    warmup_ratio = 0 # 学習率ウォームアップ比率\n",
    "    max_grad_norm = 1000  # 最大勾配ノルム\n",
    "    lr_scheduler_type = 'linear'  # 学習率スケジュールタイプ\n",
    "    frozen_embedding = False # 埋め込み層を凍結するかどうか\n",
    "    frozen_num = 6  # 凍結する層の数\n",
    "    train_batch_size = 32  # 訓練バッチサイズ\n",
    "    eval_batch_size = 64  # 評価バッチサイズ\n",
    "    evaluation_strategy = 'steps'  # 評価戦略をステップに設定\n",
    "    metric_for_best_model = \"eval_log_loss\"  # 最良モデル選択のためのメトリック\n",
    "    save_strategy = 'steps'  # ステップごとに保存\n",
    "    save_steps = 200  # 200ステップごとにモデルを保存\n",
    "    save_total_limit = 1  # 保存されるチェックポイントの合計数制限\n",
    "    train_epochs = 5  # 訓練エポック数\n",
    "    num_labels = 6  # ラベルの数\n",
    "    output_dir = f'/kaggle/input/lmsys-{TYPE}{VER}-{DATE}'  # 出力ディレクトリ\n",
    "    fp16 = True  # 混合精度訓練を使用\n",
    "    load_best_model_at_end = True  # 訓練終了時に最良モデルをロード\n",
    "    report_to = 'none'  # 外部ツールに訓練ログを報告しない\n",
    "    optim = 'adamw_torch'  # オプティマイザタイプ\n",
    "    logging_first_step = True  # 最初のステップのログを記録する\n",
    "    logging_steps = 200  # 200ステップごとにログを記録\n",
    "    logging_dir =f'logs_v{VER}'  # ログ保存ディレクトリ\n",
    "    n_splits = 5  # クロスバリデーションの分割数\n",
    "    model_name = PATHS.model_name  # モデル名\n",
    "    greater_is_better = False  # メトリックが大きいほど良いかどうか\n",
    "    early_stop = False  # 早期停止を使用するか\n",
    "    early_stopping_patience = 3  # 改善なしでモデルの訓練を停止する評価の呼び出し回数\n",
    "    early_stopping_threshold = 0.001  # 改善と見なすための最小変化量\n",
    "\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)  # Pythonの乱数シードを設定\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # ハッシュシードを設定\n",
    "    np.random.seed(seed)  # NumPyの乱数シードを設定\n",
    "    torch.manual_seed(seed)  # PyTorchの乱数シードを設定\n",
    "    torch.cuda.manual_seed(seed)  # CUDAの乱数シードを設定\n",
    "    torch.backends.cudnn.deterministic = True  # 再現性を持たせる\n",
    "\n",
    "seed_everything(seed=CFG.seed)  # 乱数シードの設定\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(PATHS.tokenizer_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(PATHS.general_tokenizer)  # トークナイザーの初期化\n",
    "sep_token = tokenizer.sep_token_id  # セパレータトークンのIDを取得\n",
    "\n",
    "def log_parameters(logger):\n",
    "    \"\"\"PATHSとCFGクラスからすべてのパラメータをログに記録します。\"\"\"\n",
    "    logger.info(\"=== パラメータ設定 ===\")\n",
    "    \n",
    "    logger.info(\"PATHS:\")\n",
    "    for key, value in PATHS.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")  # 各パラメータをログに記録\n",
    "    \n",
    "    logger.info(\"CFG:\")\n",
    "    for key, value in CFG.__dict__.items():\n",
    "        if not key.startswith('__'):\n",
    "            logger.info(f\"  {key}: {value}\")  # 各パラメータをログに記録\n",
    "    \n",
    "    logger.info(\"=*100\")\n",
    "\n",
    "def tokenize_function(row, tokenizer):\n",
    "    max_len = CFG.max_length - 2  # セパレータトークンのために2を引く\n",
    "    tokens_prompt = tokenizer(row['prompt'], truncation=True, max_length=max_len//4, add_special_tokens=False)['input_ids']  # プロンプトをトークン化\n",
    "    remaining_length = max_len - len(tokens_prompt)  # 残りの長さを計算\n",
    "    \n",
    "    tokens_response_a = tokenizer(row['response_a'], truncation=True, max_length=remaining_length//2, add_special_tokens=False)['input_ids']  # 応答Aをトークン化\n",
    "    remaining_length -= len(tokens_response_a)  # 残りの長さを更新\n",
    "    tokens_response_b = tokenizer(row['response_b'], truncation=True, max_length=remaining_length, add_special_tokens=False)['input_ids']  # 応答Bをトークン化\n",
    "    \n",
    "    input_ids = [tokenizer.cls_token_id] + tokens_prompt + [sep_token] + tokens_response_a + [sep_token] + tokens_response_b  # 入力IDを作成\n",
    "    token_type_ids = [0] * (len(tokens_prompt) + 2) + [1] * (len(tokens_response_a) + 1) + [2] * len(tokens_response_b)  # トークンタイプIDsを作成\n",
    "    attention_mask = [1] * len(input_ids)  # アテンションマスクを作成\n",
    "    \n",
    "    padding_length = CFG.max_length - len(input_ids)  # パディングの長さを計算\n",
    "    if padding_length > 0:\n",
    "        input_ids = input_ids + [tokenizer.pad_token_id] * padding_length  # パディングを追加\n",
    "        token_type_ids = token_type_ids + [0] * padding_length  # パディングを追加\n",
    "        attention_mask = attention_mask + [0] * padding_length  # パディングを追加\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids[:CFG.max_length],  # 最大長に制限する\n",
    "        'token_type_ids': token_type_ids[:CFG.max_length],  # 最大長に制限する\n",
    "        'attention_mask': attention_mask[:CFG.max_length],  # 最大長に制限する\n",
    "    }\n",
    "\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)  # ラベルの配列を作成\n",
    "    labels[df['winner_model_a'] == 1] = 0  # モデルAが勝った場合のラベル\n",
    "    labels[df['winner_model_b'] == 1] = 1  # モデルBが勝った場合のラベル\n",
    "    labels[df['winner_tie'] == 1] = 2  # 引き分けの場合のラベル\n",
    "    df['labels'] = labels  # データフレームにラベルを追加\n",
    "    return df\n",
    "\n",
    "def process_data(df, mode='train'):\n",
    "    dataset = Dataset.from_pandas(df)  # データフレームからデータセットを作成\n",
    "    tokenized_dataset = dataset.map(partial(tokenize_function, tokenizer=tokenizer), batched=False)  # データセットをトークン化\n",
    "    remove_cols = ['id', 'prompt', 'response_a', 'response_b']  # 削除する列を指定\n",
    "    if mode == 'train':\n",
    "        remove_cols += ['model_a', 'model_b', 'winner_model_a', 'winner_model_b', 'winner_tie']  # トレーニングモードの場合、さらに列を削除\n",
    "    tokenized_dataset = tokenized_dataset.remove_columns(remove_cols)  # 指定した列を削除\n",
    "    return tokenized_dataset\n",
    "\n",
    "def split_train_val(dataset, train_fraction):\n",
    "    np.random.seed(0)  # 乱数シードを設定\n",
    "    ixs = np.arange(len(dataset))  # データセットのインデックスを生成\n",
    "    cutoff = int(len(ixs) * train_fraction)  # 訓練データのカットオフポイント\n",
    "    np.random.shuffle(ixs)  # インデックスをシャッフル\n",
    "    ixs_train = ixs[:cutoff]  # 訓練用インデックス\n",
    "    ixs_val = ixs[cutoff:]  # 検証用インデックス\n",
    "    fit_train = dataset.select(ixs_train)  # 訓練データを選択\n",
    "    fit_val = dataset.select(ixs_val)  # 検証データを選択\n",
    "    return fit_train, fit_val\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # 評価予測からロジットとラベルを取得\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)  # 確率を計算\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),  # ログ損失を計算\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()  # 精度を計算\n",
    "    }\n",
    "    \n",
    "def train_model():\n",
    "    log_parameters(logger)  # パラメータをログに記録\n",
    "    train_df = pd.read_csv(PATHS.train_path)  # トレーニングデータを読み込み\n",
    "    train_df = add_label(train_df)  # ラベルを追加\n",
    "    train_tokenized = process_data(train_df, mode='train')  # トークン化されたデータを取得\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=CFG.n_splits, shuffle=True, random_state=CFG.seed)  # ストラティファイドKフォールドを作成\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_tokenized, train_tokenized['labels'])):  # 各フォールドでトレーニングと検証インデックスを分割\n",
    "        print(f\"フォールド {fold + 1} のトレーニング\")  # フォールド番号を出力\n",
    "        logger.info(f\"フォールド {fold + 1} のトレーニング\")  # フォールド番号をログに記録\n",
    "        \n",
    "        fit_train = train_tokenized.select(train_idx)  # 訓練データを選択\n",
    "        fit_val = train_tokenized.select(val_idx)  # 検証データを選択\n",
    "        \n",
    "        model = AutoModelForSequenceClassification.from_pretrained(  # 事前学習済みモデルを読み込み\n",
    "            PATHS.model_path,\n",
    "            num_labels=3,  # ラベル数を指定\n",
    "            problem_type=\"single_label_classification\"  # 問題タイプを指定\n",
    "        )\n",
    "        \n",
    "        training_args = TrainingArguments(  # 訓練引数を設定\n",
    "            output_dir=f\"{CFG.output_dir}/fold_{fold}\",  # モデルとチェックポイントの出力ディレクトリ\n",
    "            fp16=CFG.fp16,  # 混合精度訓練を使用\n",
    "            learning_rate=CFG.lr,  # 学習率\n",
    "            per_device_train_batch_size=CFG.train_batch_size,  # 各デバイスでの訓練バッチサイズ\n",
    "            per_device_eval_batch_size=CFG.eval_batch_size,  # 各デバイスでの評価バッチサイズ\n",
    "            num_train_epochs=CFG.train_epochs,  # トレーニングのエポック数\n",
    "            weight_decay=CFG.weight_decay,  # 重み減衰\n",
    "            evaluation_strategy=CFG.evaluation_strategy,  # 評価戦略\n",
    "            metric_for_best_model=CFG.metric_for_best_model,  # 最良モデルを選択するためのメトリック\n",
    "            save_strategy=CFG.save_strategy,  # 保存戦略\n",
    "            save_total_limit=CFG.save_total_limit,  # チェックポイントの総保存数制限\n",
    "            load_best_model_at_end=CFG.load_best_model_at_end,  # 最良モデルを訓練終了時にロード\n",
    "            report_to=CFG.report_to,  # ログを外部ツールに報告しない\n",
    "            warmup_ratio=CFG.warmup_ratio,  # 学習率のウォームアップ比率\n",
    "            lr_scheduler_type=CFG.lr_scheduler_type,  # 学習率スケジューラーのタイプ\n",
    "            optim=CFG.optim,  # 使用するオプティマイザのタイプ\n",
    "            logging_first_step=CFG.logging_first_step,  # 最初のステップのログを記録\n",
    "            greater_is_better=CFG.greater_is_better,  # メトリックが大きいほど良いかどうか\n",
    "            \n",
    "            # max_grad_norm=CFG.max_grad_norm,  # 勾配クリッピングの設定\n",
    "            \n",
    "            logging_steps=CFG.logging_steps,  # 200ステップごとにログを記録\n",
    "            logging_dir =f'logs_v{VER}',  # ログ保存ディレクトリ\n",
    "        \n",
    "            save_steps=CFG.save_steps,  # 200ステップごとにモデルを保存\n",
    "            eval_steps=CFG.save_steps,  # eval_stepsパラメータを追加、save_stepsと一致させる\n",
    "        )\n",
    "\n",
    "         # 訓練引数をログに記録\n",
    "        logger.info(\"訓練引数:\")\n",
    "        logger.info(pformat(training_args.to_dict()))\n",
    "\n",
    "        if CFG.frozen_embedding:  # 埋め込み層を凍結する設定の場合\n",
    "            n = CFG.frozen_num\n",
    "            # 埋め込み層を凍結\n",
    "            for i, layer in enumerate(model.deberta.encoder.layer[:n]):\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False  # 訓練から除外\n",
    "            for param in model.deberta.embeddings.parameters():\n",
    "                param.requires_grad = False  # 訓練から除外\n",
    "\n",
    "        # トークナイザーの初期化\n",
    "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)  # データコラトレーターの初期化\n",
    "\n",
    "        # EarlyStoppingCallbackの作成\n",
    "        if CFG.early_stop:  # 早期停止を使用する設定の場合\n",
    "            early_stopping_callback = EarlyStoppingCallback(\n",
    "                early_stopping_patience=CFG.early_stopping_patience,  # 訓練停止の耐久期間\n",
    "                early_stopping_threshold=CFG.early_stopping_threshold,  # 改善と見なす最小変化\n",
    "            )\n",
    "        \n",
    "            trainer = Trainer(  # トレーナーの初期化\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,  # 訓練データセット\n",
    "                data_collator=data_collator,  # データコラトレーター\n",
    "                eval_dataset=fit_val,  # 検証データセット\n",
    "                compute_metrics=compute_metrics,  # メトリックの計算関数\n",
    "                callbacks=[early_stopping_callback],  # 早期停止コールバックを追加\n",
    "            )\n",
    "        else:\n",
    "            trainer = Trainer(  # トレーナーの初期化\n",
    "                model=model,\n",
    "                args=training_args,\n",
    "                train_dataset=fit_train,  # 訓練データセット\n",
    "                data_collator=data_collator,  # データコラトレーター\n",
    "                eval_dataset=fit_val,  # 検証データセット\n",
    "                compute_metrics=compute_metrics,  # メトリックの計算関数\n",
    "            )\n",
    "        \n",
    "        trainer.train()  # モデルの訓練を開始\n",
    "        \n",
    "        # モデルを保存\n",
    "        trainer.save_model(f\"{CFG.output_dir}/fold_{fold}/best_model\")  # 最良モデルを保存\n",
    "        tokenizer.save_pretrained(f\"{CFG.output_dir}/fold_{fold}/tokenizer\")  # トークナイザーを保存\n",
    "        \n",
    "        # 結果をログに記録\n",
    "        eval_result = trainer.evaluate()  # 評価を実施\n",
    "        logger.info(f\"フォールド {fold + 1} - 評価結果: {eval_result}\")  # 評価結果をログに記録\n",
    "        logger.info(\"=*100\")\n",
    "\n",
    "def predict_test():\n",
    "    test_df = pd.read_csv(PATHS.test_path)  # テストデータを読み込み\n",
    "    test_tokenized = process_data(test_df, mode='test')  # トークン化されたテストデータを取得\n",
    "    \n",
    "    predictions = []  # 予測結果を格納するリスト\n",
    "    \n",
    "    for fold in trange(CFG.n_splits):  # 各フォールドで予測を行う\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(f\"{CFG.output_dir}/fold_{fold}/best_model\")  # 最良モデルを読み込み\n",
    "        model.eval()  # 評価モードに設定\n",
    "        \n",
    "        trainer = Trainer(model=model)  # トレーナーの初期化\n",
    "        fold_preds = trainer.predict(test_tokenized).predictions  # テストデータに対する予測を取得\n",
    "        fold_preds = np.exp(fold_preds) / np.sum(np.exp(fold_preds), axis=1, keepdims=True)  # 確率に変換\n",
    "        predictions.append(fold_preds)  # フォールドの予測結果を追加\n",
    "    \n",
    "    # フォールド間の予測を平均化\n",
    "    final_preds = np.mean(predictions, axis=0)  # 最終予測を計算\n",
    "    display(predictions)  # 予測結果を表示\n",
    "    logger.info(f\"最終予測: {final_preds}\")  # 最終予測をログに記録\n",
    "    \n",
    "    # 提出ファイルの作成\n",
    "    submission = pd.DataFrame({\n",
    "        'id': test_df['id'],  # テストデータのID\n",
    "        'winner_model_a': final_preds[:, 0],  # モデルAの勝者確率\n",
    "        'winner_model_b': final_preds[:, 1],  # モデルBの勝者確率\n",
    "        'winner_tie': final_preds[:, 2]  # 引き分け確率\n",
    "    })\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)  # 提出ファイルをCSV形式で保存\n",
    "    display(submission)  # 提出結果を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8f2ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%time\n",
    "if __name__ == \"__main__\":\n",
    "#     train_model()\n",
    "    predict_test()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "%time  # コードの実行時間を計測します\n",
    "if __name__ == \"__main__\":  # このスクリプトがメインプログラムとして実行されている場合\n",
    "#     train_model()  # モデルを訓練する関数を呼び出す（コメントアウト中）\n",
    "    predict_test()  # テストデータに対する予測を行う関数を呼び出す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T16:45:31.584644Z",
     "iopub.status.busy": "2024-07-06T16:45:31.584158Z",
     "iopub.status.idle": "2024-07-06T16:45:35.020468Z",
     "shell.execute_reply": "2024-07-06T16:45:35.019751Z",
     "shell.execute_reply.started": "2024-07-06T16:45:31.584608Z"
    }
   },
   "outputs": [],
   "source": [
    "%time  # コードの実行時間を計測します\n",
    "if __name__ == \"__main__\":  # このスクリプトがメインプログラムとして実行されている場合\n",
    "#     train_model()  # モデルを訓練する関数を呼び出す（コメントアウト中）\n",
    "    predict_test()  # テストデータに対する予測を行う関数を呼び出す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a1b515",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# import tokenizers\n",
    "# print(tokenizers.__version__)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーライブラリをインポートします\n",
    "# print(tokenizers.__version__)  # トークナイザーライブラリのバージョンを出力します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T14:28:38.542344Z",
     "iopub.status.busy": "2024-07-04T14:28:38.541923Z",
     "iopub.status.idle": "2024-07-04T14:28:38.547292Z",
     "shell.execute_reply": "2024-07-04T14:28:38.546354Z",
     "shell.execute_reply.started": "2024-07-04T14:28:38.542313Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーライブラリをインポートします\n",
    "# print(tokenizers.__version__)  # トークナイザーライブラリのバージョンを出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ddbb4b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5333407,
     "sourceId": 8859017,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5342754,
     "sourceId": 8875732,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5345416,
     "sourceId": 8882976,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5331941,
     "sourceId": 8857082,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5349810,
     "sourceId": 8898264,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5349807,
     "sourceId": 8898258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5349814,
     "sourceId": 8898272,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5352224,
     "sourceId": 8902791,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5352375,
     "sourceId": 8902994,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5363851,
     "sourceId": 8918757,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369514,
     "sourceId": 8926669,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5404689,
     "sourceId": 8976237,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 177816615,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
