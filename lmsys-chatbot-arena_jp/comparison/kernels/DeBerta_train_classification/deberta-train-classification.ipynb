{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae89d653",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、選好予測のためのモデルを構築することを目的としています。具体的には、大規模言語モデル（LLM）を使用し、ユーザーの好みに基づいて2つの応答からどちらが好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "Notebookでは、以下の手法やライブラリが使用されています：\n",
    "\n",
    "1. **ライブラリのインストールとインポート**：\n",
    "   - `peft`と`bitsandbytes`を利用し、特定のモデルやデータ処理に必要な機能を提供しています。\n",
    "   - `pandas`を使用してデータを操作し、`datasets`ライブラリからデータを読み込んでいます。\n",
    "   - `transformers`ライブラリからの様々なクラス（`AutoTokenizer`, `AutoModelForSequenceClassification`, `TrainingArguments`, `Trainer`など）を用いてモデルの構築とトレーニングを行っています。\n",
    "   - `scikit-learn`から`log_loss`をインポートし、モデルの性能評価に使用しています。\n",
    "\n",
    "2. **データ準備**：\n",
    "   - トレーニングデータとして`train.csv`を読み込み、ベースとなるデータフレームを作成します。\n",
    "   - 各サンプルに最も高い値を持つ応答をラベルとして追加し、データセットを必要な列のみに整理します。\n",
    "   - データセットを5%の割合でトレーニングセットとテストセットに分割します。\n",
    "\n",
    "3. **モデルの設定**：\n",
    "   - `DeBERTa`モデルのファインチューニングに使用するチェックポイントを指定し、トークナイザーを初期化します。\n",
    "   - `LoRa`（Low-Rank Adaptation）を利用して、効率的にモデルを訓練する設定を行います。\n",
    "\n",
    "4. **トークナイゼーション**：\n",
    "   - 各サンプルのプロンプトと応答をトークン化し、モデルが受け取れる形式に変換します。\n",
    "\n",
    "5. **トレーニング**：\n",
    "   - `TrainingArguments`を設定し、トレーニングの実行を管理する`Trainer`オブジェクトを初期化します。\n",
    "   - ログロスや精度を評価指標として計算する関数を定義し、トレーニングを実行します。\n",
    "   - トレーニング終了後、モデルとトークナイザーを保存します。\n",
    "\n",
    "このNotebookは、LLMの強化学習タスクにおけるユーザーの選好を予測する機械学習モデルを構築し、データ準備からトレーニングまでの一連の流れを示しています。重要なポイントとして、再現性を考慮したシード値の設定や、最適化されたトレーニング戦略を採用していることが挙げられます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff4d8e",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、初心者がつまずきそうな専門用語の簡単な解説です。ノートブック特有の用語や実務経験がないと馴染みが薄いかもしれないものに焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **peft (Parameter-Efficient Fine-Tuning)**\n",
    "   - モデルの微調整が必要な場合に、全てのパラメータを更新するのではなく、一部のパラメータだけを効率的に調整するための手法。特に巨大なモデルの微調整において、有用性がある。\n",
    "\n",
    "2. **Lora (Low-Rank Adaptation)**\n",
    "   - モデルの特定の部分（例えば、重み行列）を低ランクの行列で近似することにより、微調整を行う手法。これにより、パラメータ数を減らし、計算リソースを節約することができる。\n",
    "\n",
    "3. **LoftQ**\n",
    "   - モデルの量子化技術の一つ。通常、大きなモデルを小型化し、限られたリソース環境でのトレーニングや推論を可能にするために利用されます。LoftQは特に4ビットの量子化設定に言及しています。\n",
    "\n",
    "4. **EarlyStoppingCallback**\n",
    "   - モデルのトレーニング中に、監視している評価指標が改善しない場合にトレーニングを早期に停止するための機能。過学習を防ぎ、トレーニング時間を短縮するのに役立ちます。\n",
    "\n",
    "5. **log_loss (対数損失)**\n",
    "   - 分類モデルの性能を評価する指標の一つ。モデルが出す確率と実際のラベルとの間の対数的な差を測定します。小さい値が良いモデルを示す。特に確率的な出力を行うモデルで重要な評価基準です。\n",
    "\n",
    "6. **DataCollatorWithPadding**\n",
    "   - 異なる長さの入力シーケンスを持つバッチを整理し、モデルに入力する際に必要なパディングを追加するツール。これにより、バッチ内のすべての例が同じ長さを持つことが保証され、効率的に処理されます。\n",
    "\n",
    "7. **Trainer**\n",
    "   - Hugging FaceのTransformersライブラリにおけるトレーニングの高レベルAPI。モデル、データセット、トレーニング引数を渡すことにより、トレーニングプロセスを簡単に管理、実行できます。訓練フェーズの多くの複雑さを抽象化します。\n",
    "\n",
    "8. **wandb (Weights and Biases)**\n",
    "   - 機械学習の実験管理ツール。モデルのトレーニングプロセスの監視、ハイパーパラメータの管理、視覚化を行うために使用され、実験の再現性を高めるのに役立ちます。\n",
    "\n",
    "これらは、ノートブックの内容を理解するにあたり、初心者が注意を向けるべき専門用語です。これにより、各用語が持つ意味とその用途が具体的に理解できるようになることを目指しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da95cc9a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# ライブラリ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9014cdea",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install peft bitsandbytes\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# peftとbitsandbytesというライブラリをインストールします。\n",
    "# これらのライブラリは、特定のモデルやデータ処理に必要な機能を提供します。\n",
    "!pip install peft bitsandbytes\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-30T08:43:22.08222Z",
     "iopub.status.busy": "2024-07-30T08:43:22.081641Z",
     "iopub.status.idle": "2024-07-30T08:43:41.079506Z",
     "shell.execute_reply": "2024-07-30T08:43:41.078354Z",
     "shell.execute_reply.started": "2024-07-30T08:43:22.082173Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# peftとbitsandbytesというライブラリをインストールします。\n",
    "# これらのライブラリは、特定のモデルやデータ処理に必要な機能を提供します。\n",
    "!pip install peft bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8c53b4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from datasets import Dataset, load_metric, load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig, LoraConfig, TaskType, LoftQConfig\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# pandasライブラリをインポートします。データの操作や分析を行うために使用します。\n",
    "import pandas as pd\n",
    "\n",
    "# datasetsライブラリから、Dataset、load_metric、load_datasetをインポートします。\n",
    "# これらはデータの読み込みと評価指標の計算に使います。\n",
    "from datasets import Dataset, load_metric, load_dataset\n",
    "\n",
    "# transformersライブラリから、いくつかの重要なクラスをインポートします。\n",
    "# AutoTokenizerはトークナイザーを自動的にロードするため、AutoModelForSequenceClassificationはシーケンス分類のモデルをロードするために使います。\n",
    "# TrainingArgumentsはトレーニング設定を格納し、Trainerはトレーニングの実行を管理します。\n",
    "# DataCollatorWithPaddingはバッチ内のデータを整形するために、EarlyStoppingCallbackはトレーニングの早期停止を設定します。\n",
    "# AutoConfigはモデルの設定を自動的に取得するために使います。\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# pathlibライブラリをインポートします。ファイルパスの操作を簡単に行うために使用します。\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn.metricsからlog_lossをインポートします。予測の精度を評価するために使用します。\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# numpyライブラリをインポートします。数値計算を行うために使います。\n",
    "import numpy as np\n",
    "\n",
    "# jsonライブラリをインポートします。JSONデータの読み書きに使用します。\n",
    "import json\n",
    "\n",
    "# peftライブラリから、複数のクラスをインポートします。\n",
    "# これらは特定のモデル設定やトレーニングを行うために使います。\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig, LoraConfig, TaskType, LoftQConfig\n",
    "\n",
    "# bitsandbytesライブラリをインポートします。効率的な計算を行うために利用します。\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# tqdmライブラリを自動的にインポートします。プログレスバーを表示するために使います。\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# randomライブラリをインポートします。ランダムな数値生成を行うために使います。\n",
    "import random\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:43:41.082913Z",
     "iopub.status.busy": "2024-07-30T08:43:41.081945Z",
     "iopub.status.idle": "2024-07-30T08:43:59.112435Z",
     "shell.execute_reply": "2024-07-30T08:43:59.111439Z",
     "shell.execute_reply.started": "2024-07-30T08:43:41.082872Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandasライブラリをインポートします。データの操作や分析を行うために使用します。\n",
    "import pandas as pd\n",
    "\n",
    "# datasetsライブラリから、Dataset、load_metric、load_datasetをインポートします。\n",
    "# これらはデータの読み込みと評価指標の計算に使います。\n",
    "from datasets import Dataset, load_metric, load_dataset\n",
    "\n",
    "# transformersライブラリから、いくつかの重要なクラスをインポートします。\n",
    "# AutoTokenizerはトークナイザーを自動的にロードするため、AutoModelForSequenceClassificationはシーケンス分類のモデルをロードするために使います。\n",
    "# TrainingArgumentsはトレーニング設定を格納し、Trainerはトレーニングの実行を管理します。\n",
    "# DataCollatorWithPaddingはバッチ内のデータを整形するために、EarlyStoppingCallbackはトレーニングの早期停止を設定します。\n",
    "# AutoConfigはモデルの設定を自動的に取得するために使います。\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback,\n",
    "    AutoConfig\n",
    ")\n",
    "\n",
    "# pathlibライブラリをインポートします。ファイルパスの操作を簡単に行うために使用します。\n",
    "from pathlib import Path\n",
    "\n",
    "# sklearn.metricsからlog_lossをインポートします。予測の精度を評価するために使用します。\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# numpyライブラリをインポートします。数値計算を行うために使います。\n",
    "import numpy as np\n",
    "\n",
    "# jsonライブラリをインポートします。JSONデータの読み書きに使用します。\n",
    "import json\n",
    "\n",
    "# peftライブラリから、複数のクラスをインポートします。\n",
    "# これらは特定のモデル設定やトレーニングを行うために使います。\n",
    "from peft import get_peft_config, get_peft_model, PeftModel, PeftConfig, LoraConfig, TaskType, LoftQConfig\n",
    "\n",
    "# bitsandbytesライブラリをインポートします。効率的な計算を行うために利用します。\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "# tqdmライブラリを自動的にインポートします。プログレスバーを表示するために使います。\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# randomライブラリをインポートします。ランダムな数値生成を行うために使います。\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f832870",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import wandb\n",
    "user_secrets = UserSecretsClient()\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "wandb.login(key=my_secret)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# kaggle_secretsライブラリからUserSecretsClientをインポートします。\n",
    "# これにより、Kaggleのユーザーシークレットにアクセスできるようになります。\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# wandbライブラリをインポートします。これはWeights and Biasesを使用して実験を管理するためのライブラリです。\n",
    "import wandb\n",
    "\n",
    "# UserSecretsClientのインスタンスを作成します。このクライアントを使ってシークレット情報にアクセスします。\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# \"wandb_api_key\"という名前のシークレット情報を取得します。これにはWandBのAPIキーが保存されています。\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "\n",
    "# 取得したAPIキーを使用してWandBにログインします。このステップが成功すると、WandBの機能が利用可能になります。\n",
    "wandb.login(key=my_secret)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:43:59.114547Z",
     "iopub.status.busy": "2024-07-30T08:43:59.113738Z",
     "iopub.status.idle": "2024-07-30T08:44:02.966546Z",
     "shell.execute_reply": "2024-07-30T08:44:02.965556Z",
     "shell.execute_reply.started": "2024-07-30T08:43:59.11451Z"
    }
   },
   "outputs": [],
   "source": [
    "# kaggle_secretsライブラリからUserSecretsClientをインポートします。\n",
    "# これにより、Kaggleのユーザーシークレットにアクセスできるようになります。\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# wandbライブラリをインポートします。これはWeights and Biasesを使用して実験を管理するためのライブラリです。\n",
    "import wandb\n",
    "\n",
    "# UserSecretsClientのインスタンスを作成します。このクライアントを使ってシークレット情報にアクセスします。\n",
    "user_secrets = UserSecretsClient()\n",
    "\n",
    "# \"wandb_api_key\"という名前のシークレット情報を取得します。これにはWandBのAPIキーが保存されています。\n",
    "my_secret = user_secrets.get_secret(\"wandb_api_key\") \n",
    "\n",
    "# 取得したAPIキーを使用してWandBにログインします。このステップが成功すると、WandBの機能が利用可能になります。\n",
    "wandb.login(key=my_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1276de",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%env WANDB_LOG_MODEL=\"checkpoint\"\n",
    "%env WANDB_PROJECT=LMSYS\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 環境変数WANDB_LOG_MODELを\"checkpoint\"に設定します。\n",
    "# これはWandB（Weights and Biases）がモデルのチェックポイントをログに記録することを指示します。\n",
    "%env WANDB_LOG_MODEL=\"checkpoint\"\n",
    "\n",
    "# 環境変数WANDB_PROJECTを\"LMSYS\"に設定します。\n",
    "# これはWandBでのプロジェクト名を指定し、実験をこのプロジェクトに関連付けます。\n",
    "%env WANDB_PROJECT=LMSYS\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:02.969336Z",
     "iopub.status.busy": "2024-07-30T08:44:02.968628Z",
     "iopub.status.idle": "2024-07-30T08:44:02.974646Z",
     "shell.execute_reply": "2024-07-30T08:44:02.973785Z",
     "shell.execute_reply.started": "2024-07-30T08:44:02.969308Z"
    }
   },
   "outputs": [],
   "source": [
    "# 環境変数WANDB_LOG_MODELを\"checkpoint\"に設定します。\n",
    "# これはWandB（Weights and Biases）がモデルのチェックポイントをログに記録することを指示します。\n",
    "%env WANDB_LOG_MODEL=\"checkpoint\"\n",
    "\n",
    "# 環境変数WANDB_PROJECTを\"LMSYS\"に設定します。\n",
    "# これはWandBでのプロジェクト名を指定し、実験をこのプロジェクトに関連付けます。\n",
    "%env WANDB_PROJECT=LMSYS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c0020b",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Data & Configs\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# データと設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b387f86",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def seed_everything(seed):\n",
    "    import random\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(2024)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# すべてのランダム数生成器に同じシード値を設定する関数を定義します。\n",
    "# この関数を使用することで、結果を再現可能にし、実験の一貫性を保ちます。\n",
    "def seed_everything(seed):\n",
    "    # randomライブラリをインポートします。Pythonのランダム生成器を操作するために使用します。\n",
    "    import random\n",
    "    # osライブラリをインポートします。オペレーティングシステムの機能にアクセスするために使用します。\n",
    "    import os\n",
    "    # numpyライブラリをインポートします。数値計算の際に使用します。\n",
    "    import numpy as np\n",
    "    # torchライブラリをインポートします。PyTorchを使った深層学習のために使用します。\n",
    "    import torch\n",
    "    \n",
    "    # Pythonのランダム生成器のシード値を設定します。\n",
    "    random.seed(seed)\n",
    "    # 環境変数PYTHONHASHSEEDをシード値に設定します。これにより、ハッシュの一貫性が保たれます。\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # numpyのランダム生成器のシード値を設定します。\n",
    "    np.random.seed(seed)\n",
    "    # PyTorchのCPU用のランダム生成器のシード値を設定します。\n",
    "    torch.manual_seed(seed)\n",
    "    # PyTorchのGPU用のランダム生成器のシード値を設定します。\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # cuDNNの決定論的モードを有効にします。これにより、同じ入力に対して常に同じ出力が得られます。\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# 2024をシード値にして、seed_everything関数を呼び出します。これによってランダム生成器が初期化されます。\n",
    "seed_everything(2024)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:02.975958Z",
     "iopub.status.busy": "2024-07-30T08:44:02.975672Z",
     "iopub.status.idle": "2024-07-30T08:44:02.985833Z",
     "shell.execute_reply": "2024-07-30T08:44:02.985031Z",
     "shell.execute_reply.started": "2024-07-30T08:44:02.975934Z"
    }
   },
   "outputs": [],
   "source": [
    "# すべてのランダム数生成器に同じシード値を設定する関数を定義します。\n",
    "# この関数を使用することで、結果を再現可能にし、実験の一貫性を保ちます。\n",
    "def seed_everything(seed):\n",
    "    # randomライブラリをインポートします。Pythonのランダム生成器を操作するために使用します。\n",
    "    import random\n",
    "    # osライブラリをインポートします。オペレーティングシステムの機能にアクセスするために使用します。\n",
    "    import os\n",
    "    # numpyライブラリをインポートします。数値計算の際に使用します。\n",
    "    import numpy as np\n",
    "    # torchライブラリをインポートします。PyTorchを使った深層学習のために使用します。\n",
    "    import torch\n",
    "    \n",
    "    # Pythonのランダム生成器のシード値を設定します。\n",
    "    random.seed(seed)\n",
    "    # 環境変数PYTHONHASHSEEDをシード値に設定します。これにより、ハッシュの一貫性が保たれます。\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # numpyのランダム生成器のシード値を設定します。\n",
    "    np.random.seed(seed)\n",
    "    # PyTorchのCPU用のランダム生成器のシード値を設定します。\n",
    "    torch.manual_seed(seed)\n",
    "    # PyTorchのGPU用のランダム生成器のシード値を設定します。\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # cuDNNの決定論的モードを有効にします。これにより、同じ入力に対して常に同じ出力が得られます。\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "# 2024をシード値にして、seed_everything関数を呼び出します。これによってランダム生成器が初期化されます。\n",
    "seed_everything(2024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064da48f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "max_len = 1024\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最大長（max_len）を1024に設定します。\n",
    "# これは、モデルに入力するシーケンスの最大トークン数を指定します。\n",
    "# この長さを超えるトークンは切り捨てられるか、適切な処理が行われます。\n",
    "max_len = 1024\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:02.987248Z",
     "iopub.status.busy": "2024-07-30T08:44:02.986933Z",
     "iopub.status.idle": "2024-07-30T08:44:02.995254Z",
     "shell.execute_reply": "2024-07-30T08:44:02.994368Z",
     "shell.execute_reply.started": "2024-07-30T08:44:02.987192Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最大長（max_len）を1024に設定します。\n",
    "# これは、モデルに入力するシーケンスの最大トークン数を指定します。\n",
    "# この長さを超えるトークンは切り捨てられるか、適切な処理が行われます。\n",
    "max_len = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542788e3",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Generate label & remove columns\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## ラベルの生成と列の削除\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1639b9bb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "folder_path = Path('/kaggle/input/lmsys-chatbot-arena')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# フォルダーパスを設定します。\n",
    "# '/kaggle/input/lmsys-chatbot-arena'はデータが格納されているディレクトリのパスです。\n",
    "folder_path = Path('/kaggle/input/lmsys-chatbot-arena')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:02.997291Z",
     "iopub.status.busy": "2024-07-30T08:44:02.996527Z",
     "iopub.status.idle": "2024-07-30T08:44:03.004809Z",
     "shell.execute_reply": "2024-07-30T08:44:03.003947Z",
     "shell.execute_reply.started": "2024-07-30T08:44:02.997259Z"
    }
   },
   "outputs": [],
   "source": [
    "# フォルダーパスを設定します。\n",
    "# '/kaggle/input/lmsys-chatbot-arena'はデータが格納されているディレクトリのパスです。\n",
    "folder_path = Path('/kaggle/input/lmsys-chatbot-arena')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457de622",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_df = load_dataset('csv', data_files=str(folder_path / 'train.csv'))\n",
    "# train_df = load_dataset('csv', data_files='external_train.csv')\n",
    "# train_df = load_dataset('csv', data_files='/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k-deduplicated.csv')\n",
    "test_df = load_dataset('csv', data_files=str(folder_path / 'test.csv'))\n",
    "sample_df = load_dataset('csv', data_files=str(folder_path / 'sample_submission.csv'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 'train.csv'ファイルを読み込み、データセットとしてtrain_dfに格納します。\n",
    "# load_dataset関数を使ってCSV形式でデータを読み込みます。\n",
    "train_df = load_dataset('csv', data_files=str(folder_path / 'train.csv'))\n",
    "\n",
    "# 以下の行は以前のデータセットを読み込むためのコメントアウトされた例です。\n",
    "# 'external_train.csv'という別のトレーニングデータを読み込む場合。\n",
    "# train_df = load_dataset('csv', data_files='external_train.csv')\n",
    "# '/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k-deduplicated.csv'からのデータを読み込む場合。\n",
    "# train_df = load_dataset('csv', data_files='/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k-deduplicated.csv')\n",
    "\n",
    "# 'test.csv'ファイルを読み込み、データセットとしてtest_dfに格納します。\n",
    "test_df = load_dataset('csv', data_files=str(folder_path / 'test.csv'))\n",
    "\n",
    "# 'sample_submission.csv'ファイルを読み込み、データセットとしてsample_dfに格納します。\n",
    "sample_df = load_dataset('csv', data_files=str(folder_path / 'sample_submission.csv'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:03.00634Z",
     "iopub.status.busy": "2024-07-30T08:44:03.005971Z",
     "iopub.status.idle": "2024-07-30T08:44:07.552624Z",
     "shell.execute_reply": "2024-07-30T08:44:07.551633Z",
     "shell.execute_reply.started": "2024-07-30T08:44:03.006306Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'train.csv'ファイルを読み込み、データセットとしてtrain_dfに格納します。\n",
    "# load_dataset関数を使ってCSV形式でデータを読み込みます。\n",
    "train_df = load_dataset('csv', data_files=str(folder_path / 'train.csv'))\n",
    "\n",
    "# 以下の行は以前のデータセットを読み込むためのコメントアウトされた例です。\n",
    "# 'external_train.csv'という別のトレーニングデータを読み込む場合。\n",
    "# train_df = load_dataset('csv', data_files='external_train.csv')\n",
    "# '/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k-deduplicated.csv'からのデータを読み込む場合。\n",
    "# train_df = load_dataset('csv', data_files='/kaggle/input/lmsys-additional-33k-labelled-conversations/lmsys-33k-deduplicated.csv')\n",
    "\n",
    "# 'test.csv'ファイルを読み込み、データセットとしてtest_dfに格納します。\n",
    "test_df = load_dataset('csv', data_files=str(folder_path / 'test.csv'))\n",
    "\n",
    "# 'sample_submission.csv'ファイルを読み込み、データセットとしてsample_dfに格納します。\n",
    "sample_df = load_dataset('csv', data_files=str(folder_path / 'sample_submission.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd4a2f9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def get_label(sample):\n",
    "    sample['label'] = np.argmax([sample['winner_model_a'], sample['winner_model_b'], sample['winner_tie']])\n",
    "    return sample\n",
    "train_df = train_df.map(get_label)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ラベルを生成する関数get_labelを定義します。\n",
    "# この関数は、各サンプルに対して最も高い値を持つインデックスをラベルとして追加します。\n",
    "def get_label(sample):\n",
    "    # winner_model_a、winner_model_b、winner_tieの値の中で最大値を持つインデックスを取得し、labelとして設定します。\n",
    "    sample['label'] = np.argmax([sample['winner_model_a'], sample['winner_model_b'], sample['winner_tie']])\n",
    "    return sample\n",
    "\n",
    "# train_dfデータセットにget_label関数を適用します。\n",
    "# これにより、各サンプルにラベルが追加されます。\n",
    "train_df = train_df.map(get_label)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:07.554029Z",
     "iopub.status.busy": "2024-07-30T08:44:07.553744Z",
     "iopub.status.idle": "2024-07-30T08:44:19.413083Z",
     "shell.execute_reply": "2024-07-30T08:44:19.412081Z",
     "shell.execute_reply.started": "2024-07-30T08:44:07.554005Z"
    }
   },
   "outputs": [],
   "source": [
    "# ラベルを生成する関数get_labelを定義します。\n",
    "# この関数は、各サンプルに対して最も高い値を持つインデックスをラベルとして追加します。\n",
    "def get_label(sample):\n",
    "    # winner_model_a、winner_model_b、winner_tieの値の中で最大値を持つインデックスを取得し、labelとして設定します。\n",
    "    sample['label'] = np.argmax([sample['winner_model_a'], sample['winner_model_b'], sample['winner_tie']])\n",
    "    return sample\n",
    "\n",
    "# train_dfデータセットにget_label関数を適用します。\n",
    "# これにより、各サンプルにラベルが追加されます。\n",
    "train_df = train_df.map(get_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f9644",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train_df = train_df.select_columns(['prompt', 'response_a', 'response_b', 'label'])\n",
    "train_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# train_dfデータセットから必要な列だけを選択し、新しいデータフレームを作成します。\n",
    "# ここでは、'prompt'、'response_a'、'response_b'、'label'の4つの列を選択します。\n",
    "train_df = train_df.select_columns(['prompt', 'response_a', 'response_b', 'label'])\n",
    "\n",
    "# 現在のtrain_dfデータセットを表示します。\n",
    "# これにより、選択した列のみが含まれるデータフレームが確認できます。\n",
    "train_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:19.416062Z",
     "iopub.status.busy": "2024-07-30T08:44:19.41573Z",
     "iopub.status.idle": "2024-07-30T08:44:19.426071Z",
     "shell.execute_reply": "2024-07-30T08:44:19.42507Z",
     "shell.execute_reply.started": "2024-07-30T08:44:19.416036Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dfデータセットから必要な列だけを選択し、新しいデータフレームを作成します。\n",
    "# ここでは、'prompt'、'response_a'、'response_b'、'label'の4つの列を選択します。\n",
    "train_df = train_df.select_columns(['prompt', 'response_a', 'response_b', 'label'])\n",
    "\n",
    "# 現在のtrain_dfデータセットを表示します。\n",
    "# これにより、選択した列のみが含まれるデータフレームが確認できます。\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d665ec9b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "dataset = train_df['train'].train_test_split(0.05)\n",
    "dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# train_dfデータセットを5%の割合でトレーニングセットとテストセットに分割します。\n",
    "# train_test_split関数を使用して、データセットをシャッフルし、指定した割合で分割を行います。\n",
    "dataset = train_df['train'].train_test_split(0.05)\n",
    "\n",
    "# 現在のデータセットの分割結果を表示します。\n",
    "# これにより、トレーニングセットとテストセットの構造を確認できます。\n",
    "dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:19.428143Z",
     "iopub.status.busy": "2024-07-30T08:44:19.427564Z",
     "iopub.status.idle": "2024-07-30T08:44:20.143628Z",
     "shell.execute_reply": "2024-07-30T08:44:20.142646Z",
     "shell.execute_reply.started": "2024-07-30T08:44:19.428106Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dfデータセットを5%の割合でトレーニングセットとテストセットに分割します。\n",
    "# train_test_split関数を使用して、データセットをシャッフルし、指定した割合で分割を行います。\n",
    "dataset = train_df['train'].train_test_split(0.05)\n",
    "\n",
    "# 現在のデータセットの分割結果を表示します。\n",
    "# これにより、トレーニングセットとテストセットの構造を確認できます。\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2df4cef",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Models\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# モデル\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd772733",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "adapther_tokenizer_path = \"/kaggle/input/deberta-finetuned/DeBerta-base-5\"\n",
    "model_name = \"/kaggle/input/deberta-finetuned/LMSYS/checkpoint-2980\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 使用するモデルの名前を指定するための変数model_nameを定義します。\n",
    "# このコメントアウトされた行は、microsoftのDeBERTa V3ベースモデルを指定するための例です。\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# アダプタートークナイザーのパスを指定します。\n",
    "# このパスは、事前にファインチューニングされたDeBERTaモデルのトークナイザーが保存されている場所です。\n",
    "adapther_tokenizer_path = \"/kaggle/input/deberta-finetuned/DeBerta-base-5\"\n",
    "\n",
    "# 使用するモデルのチェックポイントのパスを指定します。\n",
    "# これは、ファインチューニングされたモデルの保存場所を示しています。\n",
    "model_name = \"/kaggle/input/deberta-finetuned/LMSYS/checkpoint-2980\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:44:35.798396Z",
     "iopub.status.busy": "2024-07-30T08:44:35.797674Z",
     "iopub.status.idle": "2024-07-30T08:44:35.802678Z",
     "shell.execute_reply": "2024-07-30T08:44:35.801693Z",
     "shell.execute_reply.started": "2024-07-30T08:44:35.798366Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用するモデルの名前を指定するための変数model_nameを定義します。\n",
    "# このコメントアウトされた行は、microsoftのDeBERTa V3ベースモデルを指定するための例です。\n",
    "# model_name = \"microsoft/deberta-v3-base\"\n",
    "\n",
    "# アダプタートークナイザーのパスを指定します。\n",
    "# このパスは、事前にファインチューニングされたDeBERTaモデルのトークナイザーが保存されている場所です。\n",
    "adapther_tokenizer_path = \"/kaggle/input/deberta-finetuned/DeBerta-base-5\"\n",
    "\n",
    "# 使用するモデルのチェックポイントのパスを指定します。\n",
    "# これは、ファインチューニングされたモデルの保存場所を示しています。\n",
    "model_name = \"/kaggle/input/deberta-finetuned/LMSYS/checkpoint-2980\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d6a6b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapther_tokenizer_path, model_max_length=max_len)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 指定したアダプタートークナイザーのパスからトークナイザーを初期化します。\n",
    "# max_lenで定義した最大長に基づいて、トークナイザーが設定されます。\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapther_tokenizer_path, model_max_length=max_len)\n",
    "\n",
    "# 指定したモデル名からシーケンス分類モデルを初期化します。\n",
    "# num_labelsは分類するラベルの数を示し、ここでは3つのラベルがあることを指定します。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:45.70817Z",
     "iopub.status.busy": "2024-07-30T08:45:45.707804Z",
     "iopub.status.idle": "2024-07-30T08:45:48.652294Z",
     "shell.execute_reply": "2024-07-30T08:45:48.651507Z",
     "shell.execute_reply.started": "2024-07-30T08:45:45.708141Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定したアダプタートークナイザーのパスからトークナイザーを初期化します。\n",
    "# max_lenで定義した最大長に基づいて、トークナイザーが設定されます。\n",
    "tokenizer = AutoTokenizer.from_pretrained(adapther_tokenizer_path, model_max_length=max_len)\n",
    "\n",
    "# 指定したモデル名からシーケンス分類モデルを初期化します。\n",
    "# num_labelsは分類するラベルの数を示し、ここでは3つのラベルがあることを指定します。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1666f2fb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "loftq_config = LoftQConfig(loftq_bits=4)\n",
    "peft_config = LoraConfig(\n",
    "#     target_modules=['query_proj', 'value_proj', 'key_proj'],\n",
    "    use_rslora=True,\n",
    "    r=16,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.1,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    init_lora_weights='loftq',\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoftQConfigを使用して、LoftQのビット数を4に設定します。\n",
    "# これは、モデルの量子化設定に関連します。\n",
    "loftq_config = LoftQConfig(loftq_bits=4)\n",
    "\n",
    "# LoraConfigを初期化し、モデルのトレーニング設定を指定します。\n",
    "peft_config = LoraConfig(\n",
    "    # target_modulesには、特定のターゲットモジュールを指定することができますが、ここではコメントアウトされています。\n",
    "    # target_modules=['query_proj', 'value_proj', 'key_proj'],\n",
    "    \n",
    "    # RSLORAを使用するかどうかを指定します。ここでは使用することを選択しています。\n",
    "    use_rslora=True,\n",
    "    \n",
    "    # LoRAのランクを設定します。この場合は16です。\n",
    "    r=16,\n",
    "    \n",
    "    # LoRAのスケーリングファクターを指定します。この場合は8です。\n",
    "    lora_alpha=8,\n",
    "    \n",
    "    # LoRAによるドロップアウト率を指定します。ここでは0.1です。\n",
    "    lora_dropout=0.1,\n",
    "    \n",
    "    # タスクのタイプをSEQ_CLS（シーケンス分類）に設定します。\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    \n",
    "    # 初期LoRAウェイトの設定を'loftq'とします。\n",
    "    init_lora_weights='loftq',\n",
    ")\n",
    "\n",
    "# モデルにPEFT設定を適用します。\n",
    "# これにより、トレーニングのためにモデルが更新されます。\n",
    "model = get_peft_model(model, peft_config)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:49.300351Z",
     "iopub.status.busy": "2024-07-30T08:45:49.299606Z",
     "iopub.status.idle": "2024-07-30T08:45:49.468876Z",
     "shell.execute_reply": "2024-07-30T08:45:49.468068Z",
     "shell.execute_reply.started": "2024-07-30T08:45:49.300321Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoftQConfigを使用して、LoftQのビット数を4に設定します。\n",
    "# これは、モデルの量子化設定に関連します。\n",
    "loftq_config = LoftQConfig(loftq_bits=4)\n",
    "\n",
    "# LoraConfigを初期化し、モデルのトレーニング設定を指定します。\n",
    "peft_config = LoraConfig(\n",
    "    # target_modulesには、特定のターゲットモジュールを指定することができますが、ここではコメントアウトされています。\n",
    "    # target_modules=['query_proj', 'value_proj', 'key_proj'],\n",
    "    \n",
    "    # RSLORAを使用するかどうかを指定します。ここでは使用することを選択しています。\n",
    "    use_rslora=True,\n",
    "    \n",
    "    # LoRAのランクを設定します。この場合は16です。\n",
    "    r=16,\n",
    "    \n",
    "    # LoRAのスケーリングファクターを指定します。この場合は8です。\n",
    "    lora_alpha=8,\n",
    "    \n",
    "    # LoRAによるドロップアウト率を指定します。ここでは0.1です。\n",
    "    lora_dropout=0.1,\n",
    "    \n",
    "    # タスクのタイプをSEQ_CLS（シーケンス分類）に設定します。\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    \n",
    "    # 初期LoRAウェイトの設定を'loftq'とします。\n",
    "    init_lora_weights='loftq',\n",
    ")\n",
    "\n",
    "# モデルにPEFT設定を適用します。\n",
    "# これにより、トレーニングのためにモデルが更新されます。\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92e7b2b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "    \n",
    "print_trainable_parameters(model)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルのトレーニング可能なパラメータを表示する関数を定義します。\n",
    "# この関数は、トレーニング可能なパラメータの数と全パラメータの数、およびトレーニング可能な割合を計算して表示します。\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0  # トレーニング可能なパラメータの初期値\n",
    "    all_param = 0  # 全パラメータの初期値\n",
    "    \n",
    "    # モデルの各パラメータをイテレートします。\n",
    "    for _, param in model.named_parameters():\n",
    "        # 全パラメータの合計を更新します。\n",
    "        all_param += param.numel()\n",
    "        # パラメータがトレーニング可能な場合、そのカウントを増やします。\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    # トレーニング可能なパラメータ、全パラメータ、トレーニング可能な割合を出力します。\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "# モデルのトレーニング可能なパラメータを表示するために関数を呼び出します。\n",
    "print_trainable_parameters(model)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:50.880166Z",
     "iopub.status.busy": "2024-07-30T08:45:50.879399Z",
     "iopub.status.idle": "2024-07-30T08:45:50.888407Z",
     "shell.execute_reply": "2024-07-30T08:45:50.887362Z",
     "shell.execute_reply.started": "2024-07-30T08:45:50.880136Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのトレーニング可能なパラメータを表示する関数を定義します。\n",
    "# この関数は、トレーニング可能なパラメータの数と全パラメータの数、およびトレーニング可能な割合を計算して表示します。\n",
    "def print_trainable_parameters(model):\n",
    "    trainable_params = 0  # トレーニング可能なパラメータの初期値\n",
    "    all_param = 0  # 全パラメータの初期値\n",
    "    \n",
    "    # モデルの各パラメータをイテレートします。\n",
    "    for _, param in model.named_parameters():\n",
    "        # 全パラメータの合計を更新します。\n",
    "        all_param += param.numel()\n",
    "        # パラメータがトレーニング可能な場合、そのカウントを増やします。\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    # トレーニング可能なパラメータ、全パラメータ、トレーニング可能な割合を出力します。\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
    "    )\n",
    "\n",
    "# モデルのトレーニング可能なパラメータを表示するために関数を呼び出します。\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4137a44f",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイズ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934037ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "sep_token = tokenizer.sep_token_id\n",
    "cls_token = tokenizer.cls_token_id\n",
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "len_to_each = max_len // 3 - 3\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーからセパレータトークンとクラスストークンのIDを取得します。\n",
    "sep_token = tokenizer.sep_token_id  # セパレータトークンのIDを取得\n",
    "cls_token = tokenizer.cls_token_id  # クラスストークンのIDを取得\n",
    "\n",
    "# トークナイザーにパディングトークンを追加します。\n",
    "# ここでは、'<pad>'という文字列をパディングトークンとして追加します。\n",
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "\n",
    "# モデルのトークン埋め込みのサイズをトークナイザーのトークン数の長さに合わせて調整することができますが、\n",
    "# その行はコメントアウトされています。これを有効にすることで、トークン数に応じてモデルの埋め込み層が再調整されます。\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 各トークンの最大長を決定します。\n",
    "# ここでは、max_lenを3で割って3を引き、各トークンが保持できる最大長を計算します。\n",
    "len_to_each = max_len // 3 - 3\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:53.595666Z",
     "iopub.status.busy": "2024-07-30T08:45:53.595317Z",
     "iopub.status.idle": "2024-07-30T08:45:53.60088Z",
     "shell.execute_reply": "2024-07-30T08:45:53.599764Z",
     "shell.execute_reply.started": "2024-07-30T08:45:53.595642Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーからセパレータトークンとクラスストークンのIDを取得します。\n",
    "sep_token = tokenizer.sep_token_id  # セパレータトークンのIDを取得\n",
    "cls_token = tokenizer.cls_token_id  # クラスストークンのIDを取得\n",
    "\n",
    "# トークナイザーにパディングトークンを追加します。\n",
    "# ここでは、'<pad>'という文字列をパディングトークンとして追加します。\n",
    "tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "\n",
    "# モデルのトークン埋め込みのサイズをトークナイザーのトークン数の長さに合わせて調整することができますが、\n",
    "# その行はコメントアウトされています。これを有効にすることで、トークン数に応じてモデルの埋め込み層が再調整されます。\n",
    "# model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 各トークンの最大長を決定します。\n",
    "# ここでは、max_lenを3で割って3を引き、各トークンが保持できる最大長を計算します。\n",
    "len_to_each = max_len // 3 - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45751741",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def tokenize_function(sample):\n",
    "    prompt =  tokenizer(sample['prompt'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    response_a = tokenizer(sample['response_a'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    response_b = tokenizer(sample['response_b'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    sample['input_ids'] = [cls_token] + prompt + [sep_token] + response_a + [sep_token] + response_b\n",
    "    return sample\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーを使用して入力データをトークナイズする関数を定義します。\n",
    "# この関数は、各サンプルのプロンプトと応答をトークン化し、モデルに適した形式に変換します。\n",
    "def tokenize_function(sample):\n",
    "    # プロンプトをトークナイズし、最大長len_to_eachに制限し、トランケーションとパディングを適用します。\n",
    "    # ここでは、入力IDとしてトークンのIDリストを取得します。\n",
    "    prompt = tokenizer(sample['prompt'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # 応答Aをトークナイズし、同様の処理を行います。\n",
    "    response_a = tokenizer(sample['response_a'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # 応答Bをトークナイズし、同様の処理を行います。\n",
    "    response_b = tokenizer(sample['response_b'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # トークンIDを結合し、モデルの入力形式を作成します。\n",
    "    # ここでは、クラスストークン、プロンプト、セパレータトークン、応答A、セパレータトークン、応答Bを結合しています。\n",
    "    sample['input_ids'] = [cls_token] + prompt + [sep_token] + response_a + [sep_token] + response_b\n",
    "    return sample\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:54.285259Z",
     "iopub.status.busy": "2024-07-30T08:45:54.284858Z",
     "iopub.status.idle": "2024-07-30T08:45:54.292751Z",
     "shell.execute_reply": "2024-07-30T08:45:54.291502Z",
     "shell.execute_reply.started": "2024-07-30T08:45:54.28522Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーを使用して入力データをトークナイズする関数を定義します。\n",
    "# この関数は、各サンプルのプロンプトと応答をトークン化し、モデルに適した形式に変換します。\n",
    "def tokenize_function(sample):\n",
    "    # プロンプトをトークナイズし、最大長len_to_eachに制限し、トランケーションとパディングを適用します。\n",
    "    # ここでは、入力IDとしてトークンのIDリストを取得します。\n",
    "    prompt = tokenizer(sample['prompt'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # 応答Aをトークナイズし、同様の処理を行います。\n",
    "    response_a = tokenizer(sample['response_a'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # 応答Bをトークナイズし、同様の処理を行います。\n",
    "    response_b = tokenizer(sample['response_b'], max_length=len_to_each, truncation=True, padding=True).input_ids\n",
    "    \n",
    "    # トークンIDを結合し、モデルの入力形式を作成します。\n",
    "    # ここでは、クラスストークン、プロンプト、セパレータトークン、応答A、セパレータトークン、応答Bを結合しています。\n",
    "    sample['input_ids'] = [cls_token] + prompt + [sep_token] + response_a + [sep_token] + response_b\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15f741",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "dataset = dataset.map(tokenize_function)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 定義したtokenize_functionを使用して、dataset内の各サンプルに対してトークナイズ処理を適用します。\n",
    "# このmap関数により、各サンプルがトークン化され、モデルに適した形式に変換されます。\n",
    "dataset = dataset.map(tokenize_function)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:45:59.675863Z",
     "iopub.status.busy": "2024-07-30T08:45:59.675465Z",
     "iopub.status.idle": "2024-07-30T08:48:54.333472Z",
     "shell.execute_reply": "2024-07-30T08:48:54.332427Z",
     "shell.execute_reply.started": "2024-07-30T08:45:59.675833Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定義したtokenize_functionを使用して、dataset内の各サンプルに対してトークナイズ処理を適用します。\n",
    "# このmap関数により、各サンプルがトークン化され、モデルに適した形式に変換されます。\n",
    "dataset = dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6ca93",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 現在のdatasetデータセットを表示します。\n",
    "# これにより、トークナイズ処理が適用された後のサンプルの構造を確認できます。\n",
    "dataset\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.335517Z",
     "iopub.status.busy": "2024-07-30T08:48:54.335168Z",
     "iopub.status.idle": "2024-07-30T08:48:54.341248Z",
     "shell.execute_reply": "2024-07-30T08:48:54.340368Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.335482Z"
    }
   },
   "outputs": [],
   "source": [
    "# 現在のdatasetデータセットを表示します。\n",
    "# これにより、トークナイズ処理が適用された後のサンプルの構造を確認できます。\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b264544",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "dataset = dataset.select_columns(['input_ids', 'label'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# datasetから必要な列だけを選択し、新しいデータセットを作成します。\n",
    "# ここでは、'input_ids'と'label'の2つの列を選択します。\n",
    "dataset = dataset.select_columns(['input_ids', 'label'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.34257Z",
     "iopub.status.busy": "2024-07-30T08:48:54.342316Z",
     "iopub.status.idle": "2024-07-30T08:48:54.442386Z",
     "shell.execute_reply": "2024-07-30T08:48:54.44142Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.342548Z"
    }
   },
   "outputs": [],
   "source": [
    "# datasetから必要な列だけを選択し、新しいデータセットを作成します。\n",
    "# ここでは、'input_ids'と'label'の2つの列を選択します。\n",
    "dataset = dataset.select_columns(['input_ids', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ea3ad",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Train\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トレーニング\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9d07d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "args = TrainingArguments(\n",
    "    \"LMSYS\",\n",
    "    eval_strategy = \"steps\",\n",
    "    save_strategy = \"steps\",\n",
    "    save_steps=500,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim='adamw_hf',\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit = 2,\n",
    "    metric_for_best_model='accuracy',\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"DeBerta-base-train-data\",\n",
    "    eval_steps=500,\n",
    "    logging_strategy=\"steps\", \n",
    "    logging_steps=100,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングの引数を設定するためのTrainingArgumentsを初期化します。\n",
    "args = TrainingArguments(\n",
    "    \"LMSYS\",  # トレーニング結果の出力先ディレクトリ名\n",
    "    eval_strategy=\"steps\",  # 評価の実行戦略をステップごとに設定します。\n",
    "    save_strategy=\"steps\",  # モデルの保存戦略をステップごとに設定します。\n",
    "    save_steps=500,  # 500ステップごとにモデルを保存します。\n",
    "    learning_rate=3e-4,  # 学習率を設定します。\n",
    "    fp16=True,  # 16ビット浮動小数点でトレーニングを行うかどうかを指定します。\n",
    "    per_device_train_batch_size=4,  # 各デバイスのトレーニングバッチサイズを4に設定します。\n",
    "    per_device_eval_batch_size=16,  # 各デバイスの評価バッチサイズを16に設定します。\n",
    "    gradient_accumulation_steps=4,  # 勾配の累積ステップを4に設定します。\n",
    "    optim='adamw_hf',  # 最適化アルゴリズムをAdamWに設定します。\n",
    "    num_train_epochs=3,  # トレーニングエポック数を3に設定します。\n",
    "    weight_decay=0.01,  # 重みの減衰を設定します。\n",
    "    load_best_model_at_end=True,  # トレーニングの最後に最良のモデルをロードするかどうかを指定します。\n",
    "    save_total_limit=2,  # 保存するモデルの最大数を2に設定します。\n",
    "    metric_for_best_model='accuracy',  # 最良のモデルの評価基準を精度に設定します。\n",
    "    report_to=\"wandb\",  # 結果をWandBに報告します。\n",
    "    run_name=\"DeBerta-base-train-data\",  # 実行の名前を指定します。\n",
    "    eval_steps=500,  # 評価を行うステップを500に設定します。\n",
    "    logging_strategy=\"steps\",  # ロギングの戦略をステップごとに指定します。\n",
    "    logging_steps=100,  # 100ステップごとにログを出力します。\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.444707Z",
     "iopub.status.busy": "2024-07-30T08:48:54.444377Z",
     "iopub.status.idle": "2024-07-30T08:48:54.482108Z",
     "shell.execute_reply": "2024-07-30T08:48:54.481232Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.444683Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングの引数を設定するためのTrainingArgumentsを初期化します。\n",
    "args = TrainingArguments(\n",
    "    \"LMSYS\",  # トレーニング結果の出力先ディレクトリ名\n",
    "    eval_strategy=\"steps\",  # 評価の実行戦略をステップごとに設定します。\n",
    "    save_strategy=\"steps\",  # モデルの保存戦略をステップごとに設定します。\n",
    "    save_steps=500,  # 500ステップごとにモデルを保存します。\n",
    "    learning_rate=3e-4,  # 学習率を設定します。\n",
    "    fp16=True,  # 16ビット浮動小数点でトレーニングを行うかどうかを指定します。\n",
    "    per_device_train_batch_size=4,  # 各デバイスのトレーニングバッチサイズを4に設定します。\n",
    "    per_device_eval_batch_size=16,  # 各デバイスの評価バッチサイズを16に設定します。\n",
    "    gradient_accumulation_steps=4,  # 勾配の累積ステップを4に設定します。\n",
    "    optim='adamw_hf',  # 最適化アルゴリズムをAdamWに設定します。\n",
    "    num_train_epochs=3,  # トレーニングエポック数を3に設定します。\n",
    "    weight_decay=0.01,  # 重みの減衰を設定します。\n",
    "    load_best_model_at_end=True,  # トレーニングの最後に最良のモデルをロードするかどうかを指定します。\n",
    "    save_total_limit=2,  # 保存するモデルの最大数を2に設定します。\n",
    "    metric_for_best_model='accuracy',  # 最良のモデルの評価基準を精度に設定します。\n",
    "    report_to=\"wandb\",  # 結果をWandBに報告します。\n",
    "    run_name=\"DeBerta-base-train-data\",  # 実行の名前を指定します。\n",
    "    eval_steps=500,  # 評価を行うステップを500に設定します。\n",
    "    logging_strategy=\"steps\",  # ロギングの戦略をステップごとに指定します。\n",
    "    logging_steps=100,  # 100ステップごとにログを出力します。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b00815",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()\n",
    "    }\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 評価のためのメトリックを計算する関数を定義します。\n",
    "# この関数は、モデルの出力とラベルを使用して評価指標を計算します。\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # 評価予測からロジットとラベルを取得します。\n",
    "    \n",
    "    # ソフトマックス関数を適用して、ロジットを確率に変換します。\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    \n",
    "    # 評価指標を辞書形式で返します。\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),  # ログロスを計算します。\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()  # 精度を計算します。\n",
    "    }\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.483605Z",
     "iopub.status.busy": "2024-07-30T08:48:54.48326Z",
     "iopub.status.idle": "2024-07-30T08:48:54.489491Z",
     "shell.execute_reply": "2024-07-30T08:48:54.488498Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.483574Z"
    }
   },
   "outputs": [],
   "source": [
    "# 評価のためのメトリックを計算する関数を定義します。\n",
    "# この関数は、モデルの出力とラベルを使用して評価指標を計算します。\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred  # 評価予測からロジットとラベルを取得します。\n",
    "    \n",
    "    # ソフトマックス関数を適用して、ロジットを確率に変換します。\n",
    "    probabilities = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    \n",
    "    # 評価指標を辞書形式で返します。\n",
    "    return {\n",
    "        'eval_log_loss': log_loss(labels, probabilities),  # ログロスを計算します。\n",
    "        'eval_accuracy': (np.argmax(logits, axis=1) == labels).mean()  # 精度を計算します。\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5676bc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データのバッチ処理を行うためのDataCollatorWithPaddingを初期化します。\n",
    "# これにより、入力シーケンスが同じ長さにパディングされ、モデルへの入力形式が整えられます。\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.490773Z",
     "iopub.status.busy": "2024-07-30T08:48:54.490516Z",
     "iopub.status.idle": "2024-07-30T08:48:54.500377Z",
     "shell.execute_reply": "2024-07-30T08:48:54.499563Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.490745Z"
    }
   },
   "outputs": [],
   "source": [
    "# データのバッチ処理を行うためのDataCollatorWithPaddingを初期化します。\n",
    "# これにより、入力シーケンスが同じ長さにパディングされ、モデルへの入力形式が整えられます。\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2021d4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングを実行するためのTrainerを初期化します。\n",
    "trainer = Trainer(\n",
    "    model=model,  # トレーニングするモデルを指定します。\n",
    "    args=args,  # 設定したトレーニング引数を指定します。\n",
    "    train_dataset=dataset['train'],  # トレーニングデータセットを指定します。\n",
    "    eval_dataset=dataset['test'],  # 評価データセットを指定します。\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算する関数を指定します。\n",
    "    data_collator=data_collator,  # データのバッチ処理を行うコラレーターを指定します。\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # 早期停止のコールバックを設定します。\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.501758Z",
     "iopub.status.busy": "2024-07-30T08:48:54.501432Z",
     "iopub.status.idle": "2024-07-30T08:48:54.720625Z",
     "shell.execute_reply": "2024-07-30T08:48:54.719791Z",
     "shell.execute_reply.started": "2024-07-30T08:48:54.501736Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングを実行するためのTrainerを初期化します。\n",
    "trainer = Trainer(\n",
    "    model=model,  # トレーニングするモデルを指定します。\n",
    "    args=args,  # 設定したトレーニング引数を指定します。\n",
    "    train_dataset=dataset['train'],  # トレーニングデータセットを指定します。\n",
    "    eval_dataset=dataset['test'],  # 評価データセットを指定します。\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算する関数を指定します。\n",
    "    data_collator=data_collator,  # データのバッチ処理を行うコラレーターを指定します。\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],  # 早期停止のコールバックを設定します。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff4aed2",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer.train()\n",
    "wandb.finish()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングを開始します。\n",
    "# これにより、指定された設定に従ってモデルのトレーニングが実行されます。\n",
    "trainer.train()\n",
    "\n",
    "# トレーニングが完了したら、WandBのログを終了します。\n",
    "# これにより、現在の実行の情報が保存されます。\n",
    "wandb.finish()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T08:48:54.721979Z",
     "iopub.status.busy": "2024-07-30T08:48:54.721691Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングを開始します。\n",
    "# これにより、指定された設定に従ってモデルのトレーニングが実行されます。\n",
    "trainer.train()\n",
    "\n",
    "# トレーニングが完了したら、WandBのログを終了します。\n",
    "# これにより、現在の実行の情報が保存されます。\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a430bec",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "save_folder = 'DeBerta-base-trained'\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(save_folder)\n",
    "tokenizer.save_pretrained(save_folder)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニング済みモデルとトークナイザーを保存するためのフォルダー名を設定します。\n",
    "save_folder = 'DeBerta-base-trained'\n",
    "\n",
    "# モデルをマージしてメモリからアンロードします。\n",
    "# これにより、モデルの重みが最適化され、次のステップで保存できる状態になります。\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 保存先フォルダーにモデルの重みを保存します。\n",
    "model.save_pretrained(save_folder)\n",
    "\n",
    "# 保存先フォルダーにトークナイザーの設定を保存します。\n",
    "tokenizer.save_pretrained(save_folder)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング済みモデルとトークナイザーを保存するためのフォルダー名を設定します。\n",
    "save_folder = 'DeBerta-base-trained'\n",
    "\n",
    "# モデルをマージしてメモリからアンロードします。\n",
    "# これにより、モデルの重みが最適化され、次のステップで保存できる状態になります。\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 保存先フォルダーにモデルの重みを保存します。\n",
    "model.save_pretrained(save_folder)\n",
    "\n",
    "# 保存先フォルダーにトークナイザーの設定を保存します。\n",
    "tokenizer.save_pretrained(save_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cd5e3b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer.save_model(f\"{save_folder}-trainer\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Trainerオブジェクトを使用して、トレーニング済みモデルを指定したフォルダーに保存します。\n",
    "# ここでは、フォルダー名に\"-trainer\"を追加して保存先を指定します。\n",
    "trainer.save_model(f\"{save_folder}-trainer\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainerオブジェクトを使用して、トレーニング済みモデルを指定したフォルダーに保存します。\n",
    "# ここでは、フォルダー名に\"-trainer\"を追加して保存先を指定します。\n",
    "trainer.save_model(f\"{save_folder}-trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a475b281",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# コードセルが空のため、何も実行しません。必要に応じてコードを記述してください。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コードセルが空のため、何も実行しません。必要に応じてコードを記述してください。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4927617,
     "sourceId": 8297557,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4959805,
     "sourceId": 8377405,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5438018,
     "sourceId": 9065155,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
