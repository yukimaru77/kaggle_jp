{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6478d30",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookでは、Metaの**Llama3**（8Bモデル）をファインチューニングする方法を示しています。具体的には、**QLoRA**や**trl**ライブラリの**SFTTrainer**を使用して、大規模言語モデル（LLM）のパラメータ効率の高い調整（PEFT）を行うプロセスに取り組んでいます。\n",
    "\n",
    "### 問題の対象\n",
    "ノートブックは主に、Chatbot Arenaコンペティションに関連するデータセットを用いて、どのモデルの応答がユーザーに好まれるかを予測する問題に取り組んでいます。具体的には、2つの異なるモデル（応答Aと応答B）からの出力に基づき、どちらが好まれるかを分類するタスクです。\n",
    "\n",
    "### 使用している手法\n",
    "- **QLoRA**: Low-Rank Adaptation（LoRA）に基づき、ファインチューニング中のメモリ使用量を削減しつつ、モデルのパフォーマンスを維持または向上させる手法です。これにより、大規模モデルを少ないGPUで効率的に訓練できます。\n",
    "- **SFTTrainer**: Hugging Faceの**trl**ライブラリによって提供されるシンプルなAPIを用いており、ファインチューニングプロセスを容易にします。\n",
    "- **PEFT**: 事前訓練済みモデルのパラメータを再利用することで、計算資源と時間を節約しながら、タスク特有の性能を引き上げる技術です。\n",
    "\n",
    "### 利用ライブラリ\n",
    "- **Transformers**: 自然言語処理のための高度なモデルを提供し、モデルのロードやファインチューニングが可能です。\n",
    "- **Torch**: ディープラーニングフレームワークとして使用され、モデルの構築や訓練に利用されています。\n",
    "- **PEFT**: パラメータ効率の良いファインチューニングを行うためのライブラリです。\n",
    "\n",
    "このノートブックは、事前データ処理、モデルの設定、学習のトレーニングを行い、最後にはモデルのパフォーマンスを評価することで完了します。最終的に、予測結果をサンプルとして表示することも含まれており、コンペティションの要件に従ったデータサイエンスプロジェクトの構築に役立つ内容となっています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b011617",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、初心者がつまずきそうな専門用語に関する簡単な解説です。特に、実務経験のない方には馴染みが薄く、ノートブック特有のドメイン知識が関連する用語に焦点を当てています。\n",
    "\n",
    "1. **QLoRA（Quantized LoRA）**:\n",
    "   QLoRAは、LoRA（Low-Rank Adaptation）のアプローチに基づき、モデルの性能を維持または向上させつつ、メモリ使用量を効率的に削減する手法です。量子化を組み合わせることで、少ないGPUリソースでも大規模モデルをファインチューニングできるようになります。特にQA（質問応答）タスクでの応用が期待されています。\n",
    "\n",
    "2. **PEFT（Parameter-Efficient Fine-Tuning）**:\n",
    "   PEFTは、特定の下流タスクについて事前訓練したモデルの性能を向上させるための方法です。これを実現するために、全体のモデルをゼロから訓練するのではなく、小規模なデータセットを使用して特定の部分だけを調整します。計算資源の節約やトレーニング時間の短縮が可能です。\n",
    "\n",
    "3. **SFTTrainer**:\n",
    "   SFTTrainerは、Social Fine-Tuning（SFT）のためのTrainerクラスです。Hugging Faceのtrlライブラリに含まれ、モデルをファインチューニングするための簡単かつ効率的なAPIを提供します。このクラスを利用することで、複雑な設定を簡略化し、ファインチューニングを容易に行えます。\n",
    "\n",
    "4. **UltraChat200k**:\n",
    "   UltraChat200kは、大規模な対話データセットであり、約140万の対話を含みます。自然言語理解や生成、対話システムの研究にとって貴重なリソースです。異なるフォーマットが提供され、実験やモデル評価に利用があります。\n",
    "\n",
    "5. **ロギング（Logging）**:\n",
    "   機械学習におけるロギングは、訓練過程や評価結果を記録することを指します。トレーニングのパラメータや状態を追跡し、後の解析やモデルのチューニングに役立てます。\n",
    "\n",
    "6. **二重量子化（Double Quantization）**:\n",
    "   量子化は、モデルのサイズを圧縮する手法ですが、二重量子化は複数の段階で量子化を行うことでさらなる圧縮を実現します。この結果、メモリ使用量が削減され、計算効率が向上します。\n",
    "\n",
    "7. **ドロップアウト（Dropout）**:\n",
    "   ドロップアウトは、過学習を防ぐためのテクニックで、トレーニング中に一定の確率でニューロンを無効化します。これにより、モデルは特定のパターンに依存することが難しくなり、汎化能力が向上します。\n",
    "\n",
    "8. **ガーベジコレクション（Garbage Collection）**:\n",
    "   プログラミングにおいて、使用しなくなったメモリを自動的に解放する仕組みを指します。特に、Pythonなどの言語で無駄なメモリを掃除し、リソースを効率的に管理します。\n",
    "\n",
    "9. **クラス重み（Class Weights）**:\n",
    "   クラス重みは、モデルの損失関数において特定のクラスの重要度を調整するために使用されます。データセットが不均衡な場合に、少数派クラスの影響を強化するためによく用いられます。\n",
    "\n",
    "これらの専門用語に精通することは、ノートブックや深層学習モデルの理解を深める上で重要です。特に、BERTやGPTなどの大規模言語モデルに関連する技術とその効率的な活用方法は、今日のAI開発において非常に価値があります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc56cc",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Introduction\n",
    "\n",
    "\n",
    "In this notebook we demostrate how to finetune **Llama3** (8B) model from Meta using **QLoRA** and **SFTTrainer** from **tlr**.\n",
    "\n",
    "## What is Llama3?\n",
    "\n",
    "Llama3 is the latest release of open-source LLMs from Meta, with features pretrained and instruction-fine-tuned language models with 8B and 70B parameters.\n",
    "\n",
    "## What is LoRA?\n",
    "\n",
    "LoRA stands for Low-Rank Adaptation. It is a method used to fine-tune large language models (LLMs) by freezing the weights of the LLM and injecting trainable rank-decomposition matrices. The number of trainable parameters during fine-tunning will decrease therefore considerably. According to LoRA paper, this number decreases 10,000 times, and the computational resources size decreases 3 times.\n",
    "\n",
    "\n",
    "## What is QLoRA?\n",
    "\n",
    "QLoRA builds on LoRA by incorporating quantization techniques to further reduce memory usage while maintaining, or even enhancing, model performance. With QLoRA it is possible to finetune a 70B parameter model that requires 36 GPUs with only 2!\n",
    "\n",
    "\n",
    "## What is PEFT?\n",
    "\n",
    "Parameter-efficient Fine-tuning (PEFT) is a technique used in Natural Language Processing (NLP) to improve the performance of pre-trained language models on specific downstream tasks. It involves reusing the pre-trained model’s parameters and fine-tuning them on a smaller dataset, which saves computational resources and time compared to training the entire model from scratch. PEFT achieves this efficiency by freezing some of the layers of the pre-trained model and only fine-tuning the last few layers that are specific to the downstream task.\n",
    "\n",
    "## What is SFTTrainer?\n",
    "\n",
    "SFT in SFTTrainer stands for supervised fine-tuning. The **trl** (Transformer Reinforcement Learning) library from HuggingFace provides a simple API to fine-tune models using SFTTrainer.\n",
    "\n",
    "## What is UltraChat200k?  \n",
    "\n",
    "UltraChat-200k is an invaluable resource for natural language understanding, generation and dialog system research. With 1.4 million dialogues spanning a variety of topics, this parquet-formatted dataset offers researchers four distinct formats to aid in their studies: test_sft, train_sft, train_gen and test_gen. More details [here](https://www.kaggle.com/datasets/thedevastator/ultrachat-200k-nlp-dataset).\n",
    "\n",
    "## Inspiration\n",
    "\n",
    "For this notebook, I took inspiration from several sources:\n",
    "* [Efficiently fine-tune Llama 3 with PyTorch FSDP and Q-Lora](https://www.philschmid.de/fsdp-qlora-llama3)  \n",
    "* [Fine-tuning LLMs using LoRA](https://medium.com/@rajatsharma_33357/fine-tuning-llama-using-lora-fb3f48a557d5)  \n",
    "* [Fine-tuning Llama-3–8B-Instruct QLORA using low cost resources](https://medium.com/@avishekpaul31/fine-tuning-llama-3-8b-instruct-qlora-using-low-cost-resources-89075e0dfa04)  \n",
    "* [Llama2 Fine-Tuning with Low-Rank Adaptations (LoRA) on Gaudi 2 Processors](https://eduand-alvarez.medium.com/llama2-fine-tuning-with-low-rank-adaptations-lora-on-gaudi-2-processors-52cf1ee6ce11)  \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# はじめに\n",
    "\n",
    "このノートブックでは、**QLoRA** と **tlr** の **SFTTrainer** を使用して、Meta の **Llama3** (8B) モデルをファインチューニングする方法を示します。\n",
    "\n",
    "## Llama3 とは？\n",
    "\n",
    "Llama3 は、Meta が提供するオープンソースの最新の大規模言語モデル（LLM）で、8B および 70B パラメータを持つ事前訓練済みおよび指示に基づいてファインチューニングされた言語モデルを特徴としています。\n",
    "\n",
    "## LoRA とは？\n",
    "\n",
    "LoRA は Low-Rank Adaptation の略です。これは、大規模言語モデル（LLMs）をファインチューニングするための方法で、LLM の重みを固定し、トレーニング可能なランク分解行列を注入します。ファインチューニング中のトレーニング可能なパラメータの数は、かなり減少します。LoRA の論文によると、この数は 10,000 倍減少し、計算資源のサイズは 3 倍減少するとされています。\n",
    "\n",
    "## QLoRA とは？\n",
    "\n",
    "QLoRA は LoRA に基づいて、モデルの性能を維持または向上させながらメモリ使用量をさらに削減するために量子化手法を組み合わせたものです。QLoRA を使用すると、36 台の GPU が必要な 70B パラメータモデルをわずか 2 台の GPU でファインチューニングすることが可能になります！\n",
    "\n",
    "## PEFT とは？\n",
    "\n",
    "パラメータ効率の良いファインチューニング（PEFT）は、特定の下流タスクにおいて事前訓練した言語モデルの性能を向上させるための技術です。これは、事前訓練済みモデルのパラメータを再利用し、より小さなデータセットでファインチューニングすることで、全モデルをゼロからトレーニングするのに比べて、計算資源と時間を節約します。PEFT は、事前訓練済みモデルのいくつかの層を固定し、下流タスクに特有の最後の数層だけをファインチューニングすることによって、この効率が実現されます。\n",
    "\n",
    "## SFTTrainer とは？\n",
    "\n",
    "SFTTrainer の SFT はフォローアップのファインチューニングを指します。HuggingFace の **trl** (Transformer Reinforcement Learning) ライブラリは、SFTTrainer を使用してモデルをファインチューニングするためのシンプルな API を提供します。\n",
    "\n",
    "## UltraChat200k とは？\n",
    "\n",
    "UltraChat-200k は、自然言語理解、生成、および対話システム研究にとって非常に貴重なリソースです。多数のトピックにわたる 1.4 百万の対話を含み、この parquet 形式のデータセットは、研究者が研究を支援するために 4 つの異なるフォーマットを提供します: test_sft, train_sft, train_gen, test_gen。詳細は [こちら](https://www.kaggle.com/datasets/thedevastator/ultrachat-200k-nlp-dataset)をご覧ください。\n",
    "\n",
    "## インスピレーション\n",
    "\n",
    "このノートブックでは、いくつかの情報源からインスピレーションを得ました：\n",
    "* [PyTorch FSDP と Q-Lora を使用して Llama 3 を効率的にファインチューニングする](https://www.philschmid.de/fsdp-qlora-llama3)  \n",
    "* [LoRA を使用した LLM のファインチューニング](https://medium.com/@rajatsharma_33357/fine-tuning-llama-using-lora-fb3f48a557d5)  \n",
    "* [低コストリソースを使用した Llama-3–8B–Instruct QLORA のファインチューニング](https://medium.com/@avishekpaul31/fine-tuning-llama-3-8b-instruct-qlora-using-low-cost-resources-89075e0dfa04)  \n",
    "* [Gaudi 2 プロセッサ上での Low-Rank Adaptations (LoRA) を用いた Llama2 のファインチューニング](https://eduand-alvarez.medium.com/llama2-fine-tuning-with-low-rank-adaptations-lora-on-gaudi-2-processors-52cf1ee6ce11)  \n",
    "\n",
    "# ライブラリのインストールとインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e30920a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Install and import libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "!pip install -q -U bitsandbytes  # bitsandbytesライブラリをインストールします。これは、低ランクモデルのファインチューニングに役立つツールです。\n",
    "!pip install -q -U transformers  # transformersライブラリをインストールします。このライブラリは、自然言語処理のための高度な機械学習モデルを提供します。\n",
    "!pip install -q -U peft  # パラメータ効率の良いファインチューニングを行うためのpeftライブラリをインストールします。\n",
    "!pip install -q -U accelerate  # accelerateライブラリをインストールします。これは、訓練の高速化や効率的な実行を支援します。\n",
    "!pip install -q -U datasets  # データセットライブラリをインストールします。さまざまなデータセットにアクセスして利用するためのライブラリです。\n",
    "!pip install -q -U trl  # トランスフォーマーの強化学習ライブラリであるtrlをインストールします。モデルの強化学習に役立ちます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7b37e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U transformers\n",
    "!pip install -q -U peft\n",
    "!pip install -q -U accelerate\n",
    "!pip install -q -U datasets\n",
    "!pip install -q -U trl\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import pandas as pd  # データ操作を容易にするためのpandasライブラリをインポートします。これはデータフレームの作成や操作に役立ちます。\n",
    "from torch.utils.data import Dataset  # PyTorchのデータセットクラスをインポートします。カスタムデータセットを作成するために使用します。\n",
    "from torch.utils.data import DataLoader  # PyTorchのデータローダークラスをインポートします。バッチ処理やデータのシャッフルをサポートします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:37:02.767377Z",
     "iopub.status.busy": "2024-07-06T02:37:02.767069Z",
     "iopub.status.idle": "2024-07-06T02:37:06.467674Z",
     "shell.execute_reply": "2024-07-06T02:37:06.466776Z",
     "shell.execute_reply.started": "2024-07-06T02:37:02.767349Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  # データ操作を容易にするためのpandasライブラリをインポートします。これはデータフレームの作成や操作に役立ちます。\n",
    "from torch.utils.data import Dataset  # PyTorchのデータセットクラスをインポートします。カスタムデータセットを作成するために使用します。\n",
    "from torch.utils.data import DataLoader  # PyTorchのデータローダークラスをインポートします。バッチ処理やデータのシャッフルをサポートします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d12ab3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# from kaggle_secrets import UserSecretsClient  # Kaggleの秘密情報にアクセスするためのUserSecretsClientをインポートします。\n",
    "# user_secrets = UserSecretsClient()  # UserSecretsClientのインスタンスを作成します。\n",
    "# wandb_key = user_secrets.get_secret(\"wandb_api\")  # WandB（Weights & Biases）APIキーを取得します。このキーはWandBの機能を利用するために必要です。\n",
    "# import wandb  # WandBライブラリをインポートします。これは、実験の追跡や可視化に役立ちます。\n",
    "# ! wandb login $wandb_key  # 取得したWandB APIキーを使ってWandBにログインします。これにより、実験データをWandBにアップロードできるようになります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T01:48:13.893775Z",
     "iopub.status.busy": "2024-07-06T01:48:13.893506Z",
     "iopub.status.idle": "2024-07-06T01:48:13.897497Z",
     "shell.execute_reply": "2024-07-06T01:48:13.896594Z",
     "shell.execute_reply.started": "2024-07-06T01:48:13.893754Z"
    }
   },
   "outputs": [],
   "source": [
    "# from kaggle_secrets import UserSecretsClient  # Kaggleの秘密情報にアクセスするためのUserSecretsClientをインポートします。\n",
    "# user_secrets = UserSecretsClient()  # UserSecretsClientのインスタンスを作成します。\n",
    "# wandb_key = user_secrets.get_secret(\"wandb_api\")  # WandB（Weights & Biases）APIキーを取得します。このキーはWandBの機能を利用するために必要です。\n",
    "# import wandb  # WandBライブラリをインポートします。これは、実験の追跡や可視化に役立ちます。\n",
    "# ! wandb login $wandb_key  # 取得したWandB APIキーを使ってWandBにログインします。これにより、実験データをWandBにアップロードできるようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804b2ae7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# from kaggle_secrets import UserSecretsClient\n",
    "# user_secrets = UserSecretsClient()\n",
    "# wandb_key = user_secrets.get_secret(\"wandb_api\")\n",
    "# import wandb\n",
    "# ! wandb login $wandb_key\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import os  # オペレーティングシステムの機能を提供するosライブラリをインポートします。ファイルパスなどの操作に使用します。\n",
    "import torch  # PyTorchライブラリをインポートします。ディープラーニングモデルの構築とトレーニングに使用します。\n",
    "from time import time  # 現在の時刻を取得するためのtime関数をインポートします。トレーニング時間の計測に使用します。\n",
    "from datasets import load_dataset  # datasetsライブラリからload_dataset関数をインポートします。データセットを簡単に読み込むために使用します。\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training  # PEFT（パラメータ効率の良いファインチューニング）に関連するクラスや関数をインポートします。\n",
    "from transformers import (  # transformersライブラリから様々なクラスや関数をインポートします。\n",
    "    AutoConfig,  # モデルの自動設定を行うためのクラスをインポートします。\n",
    "    AutoModelForCausalLM,  # 自然言語生成用の因果モデルを自動で取得するためのクラスをインポートします。\n",
    "    AutoTokenizer,  # モデルに適したトークナイザーを自動で取得するためのクラスをインポートします。\n",
    "    BitsAndBytesConfig,  # メモリ効率化のためのビットおよびバイト設定を管理するクラスをインポートします。\n",
    "    AutoTokenizer,  # トークナイザーを再度インポート（重複）していますが、必要に応じて実際のインポートを行います。\n",
    "    TrainingArguments,  # トレーニングの際の引数を設定するためのクラスをインポートします。\n",
    "    AutoModelForSequenceClassification,  # シーケンス分類用のモデルを自動で取得するためのクラスをインポートします。\n",
    "    Trainer  # モデルのトレーニングを管理するための教師クラスをインポートします。\n",
    ")\n",
    "from trl import SFTTrainer, setup_chat_format  # SFTTrainerクラスとチャット形式を設定する関数をインポートします。ファインチューニングに使用します。\n",
    "import numpy as np  # 数値計算を効率的に行うためのnumpyライブラリをインポートします。配列や行列の操作に便利です。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-06T02:45:53.928208Z",
     "iopub.status.busy": "2024-07-06T02:45:53.927153Z",
     "iopub.status.idle": "2024-07-06T02:45:53.933768Z",
     "shell.execute_reply": "2024-07-06T02:45:53.932674Z",
     "shell.execute_reply.started": "2024-07-06T02:45:53.928173Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # オペレーティングシステムの機能を提供するosライブラリをインポートします。ファイルパスなどの操作に使用します。\n",
    "import torch  # PyTorchライブラリをインポートします。ディープラーニングモデルの構築とトレーニングに使用します。\n",
    "from time import time  # 現在の時刻を取得するためのtime関数をインポートします。トレーニング時間の計測に使用します。\n",
    "from datasets import load_dataset  # datasetsライブラリからload_dataset関数をインポートします。データセットを簡単に読み込むために使用します。\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training  # PEFT（パラメータ効率の良いファインチューニング）に関連するクラスや関数をインポートします。\n",
    "from transformers import (  # transformersライブラリから様々なクラスや関数をインポートします。\n",
    "    AutoConfig,  # モデルの自動設定を行うためのクラスをインポートします。\n",
    "    AutoModelForCausalLM,  # 自然言語生成用の因果モデルを自動で取得するためのクラスをインポートします。\n",
    "    AutoTokenizer,  # モデルに適したトークナイザーを自動で取得するためのクラスをインポートします。\n",
    "    BitsAndBytesConfig,  # メモリ効率化のためのビットおよびバイト設定を管理するクラスをインポートします。\n",
    "    AutoTokenizer,  # トークナイザーを再度インポート（重複）していますが、必要に応じて実際のインポートを行います。\n",
    "    TrainingArguments,  # トレーニングの際の引数を設定するためのクラスをインポートします。\n",
    "    AutoModelForSequenceClassification,  # シーケンス分類用のモデルを自動で取得するためのクラスをインポートします。\n",
    "    Trainer  # モデルのトレーニングを管理するための教師クラスをインポートします。\n",
    ")\n",
    "from trl import SFTTrainer, setup_chat_format  # SFTTrainerクラスとチャット形式を設定する関数をインポートします。ファインチューニングに使用します。\n",
    "import numpy as np  # 数値計算を効率的に行うためのnumpyライブラリをインポートします。配列や行列の操作に便利です。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb69d9a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import os\n",
    "import torch\n",
    "from time import time\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer\n",
    ")\n",
    "from trl import SFTTrainer,setup_chat_format\n",
    "import numpy as np\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "class CFG:  # コンフィグレーションクラスを定義します。モデルのトレーニングに関連する設定を保持します。\n",
    "    NUM_EPOCHS = 1  # エポック数を設定します。モデルの学習を何回繰り返すかを決定します。\n",
    "    BATCH_SIZE = 16  # バッチサイズを設定します。一度に処理するサンプルの数です。\n",
    "    DROPOUT = 0.05  # ドロップアウト率を設定します。過学習を防ぐために、一部のニューロンの出力を確率的に無効にします。\n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # 使用するモデルのパスを定義します。\n",
    "\n",
    "    SEED = 2024  # ランダムシードを設定します。再現性のある結果を得るために使用します。\n",
    "    MAX_LENGTH = 1024  # 最大入力長を設定します。モデルへの入力として受け入れる最大トークン数です。\n",
    "    NUM_WARMUP_STEPS = 128  # ウォームアップステップの数を設定します。学習率を徐々に増加させるステップ数です。\n",
    "    LR_MAX = 5e-5  # 学習率の最大値を設定します。これにより、モデルが効果的に学習できるようになります。\n",
    "    NUM_LABELS = 3  # 分類タスクにおけるラベルの数を設定します。\n",
    "    LORA_RANK = 4  # LoRAのランクを設定します。モデルのランク近似の次元を決定します。\n",
    "    LORA_ALPHA = 8  # LoRAで使用するスケーリング係数を設定します。\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモデルのモジュール名をリストとして定義します。ここでは出力プロジェクションとバリュー仮想プロジェクションを指定しています。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:37:25.014169Z",
     "iopub.status.busy": "2024-07-06T02:37:25.013904Z",
     "iopub.status.idle": "2024-07-06T02:37:25.019686Z",
     "shell.execute_reply": "2024-07-06T02:37:25.018662Z",
     "shell.execute_reply.started": "2024-07-06T02:37:25.014147Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:  # コンフィグレーションクラスを定義します。モデルのトレーニングに関連する設定を保持します。\n",
    "    NUM_EPOCHS = 1  # エポック数を設定します。モデルの学習を何回繰り返すかを決定します。\n",
    "    BATCH_SIZE = 16  # バッチサイズを設定します。一度に処理するサンプルの数です。\n",
    "    DROPOUT = 0.05  # ドロップアウト率を設定します。過学習を防ぐために、一部のニューロンの出力を確率的に無効にします。\n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # 使用するモデルのパスを定義します。\n",
    "\n",
    "    SEED = 2024  # ランダムシードを設定します。再現性のある結果を得るために使用します。\n",
    "    MAX_LENGTH = 1024  # 最大入力長を設定します。モデルへの入力として受け入れる最大トークン数です。\n",
    "    NUM_WARMUP_STEPS = 128  # ウォームアップステップの数を設定します。学習率を徐々に増加させるステップ数です。\n",
    "    LR_MAX = 5e-5  # 学習率の最大値を設定します。これにより、モデルが効果的に学習できるようになります。\n",
    "    NUM_LABELS = 3  # 分類タスクにおけるラベルの数を設定します。\n",
    "    LORA_RANK = 4  # LoRAのランクを設定します。モデルのランク近似の次元を決定します。\n",
    "    LORA_ALPHA = 8  # LoRAで使用するスケーリング係数を設定します。\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモデルのモジュール名をリストとして定義します。ここでは出力プロジェクションとバリュー仮想プロジェクションを指定しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c35ea5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "class CFG:\n",
    "    NUM_EPOCHS = 1\n",
    "    BATCH_SIZE = 16\n",
    "    DROPOUT = 0.05 \n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "    \n",
    "    SEED = 2024 \n",
    "    MAX_LENGTH = 1024 \n",
    "    NUM_WARMUP_STEPS = 128\n",
    "    LR_MAX = 5e-5 \n",
    "    NUM_LABELS = 3 \n",
    "    LORA_RANK = 4\n",
    "    LORA_ALPHA = 8\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットの準備\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab57831",
   "metadata": {},
   "source": [
    "# データセットの準備"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8d929",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Prepare Dataset\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータセットをCSVファイルから読み込みます。\n",
    "\n",
    "def process(input_str):  # 入力文字列を処理する関数を定義します。\n",
    "    stripped_str = input_str.strip('[]')  # 文字列の前後の角括弧を取り除きます。\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文字列を分割し、余分な引用符を取り除きます。\n",
    "    return  ' '.join(sentences)  # 分割した文を空白で結合して返します。\n",
    "\n",
    "# 'prompt'、'response_a'、'response_b' 列に対して process 関数を適用します。\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # プロンプト列の処理。\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # モデルAの応答を処理。\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # モデルBの応答を処理。\n",
    "\n",
    "# トレーニング用に 'Null' をドロップします。\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index  # 応答Aと応答Bが両方とも'null'である行のインデックスを取得します。\n",
    "train.drop(indexes, inplace=True)  # その行をデータフレームから削除します。\n",
    "train.reset_index(inplace=True, drop=True)  # インデックスをリセットします。\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)  # 各行に対して勝者モデルのラベルを計算して追加します。\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")  # ドロップした行数を表示します。\n",
    "print('Total train samples: ', len(train))  # 残りのトレーニングサンプル数を表示します。\n",
    "\n",
    "# テキスト形式にデータを整形します。\n",
    "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(train['text'][4])  # フォーマットされたテキストの5番目のサンプルを表示します。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf2a02",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Null' for training\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")\n",
    "print('Total train samples: ', len(train))\n",
    "\n",
    "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(train['text'][4])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルの初期化\n",
    "\n",
    "使用されるモデルは以下の通りです：\n",
    "\n",
    "* **モデル**: Llama3  \n",
    "* **フレームワーク**: Transformers  \n",
    "* **サイズ**: 8B  \n",
    "* **タイプ**: 8b-chat-hf (hfはHuggingFaceを指します)  \n",
    "* **バージョン**: V1  \n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c38b7c0",
   "metadata": {},
   "source": [
    "# モデルの初期化\n",
    "\n",
    "使用されるモデルは以下の通りです：\n",
    "\n",
    "* **モデル**: Llama3  \n",
    "* **フレームワーク**: Transformers  \n",
    "* **サイズ**: 8B  \n",
    "* **タイプ**: 8b-chat-hf (hfはHuggingFaceを指します)  \n",
    "* **バージョン**: V1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbe1caa",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Initialize model\n",
    "\n",
    "\n",
    "The model used is:\n",
    "\n",
    "* **Model**: Llama3  \n",
    "* **Framework**: Transformers   \n",
    "* **Size**: 8B   \n",
    "* **Type**: 8b-chat-hf (hf stands for HuggingFace). \n",
    "* **Version**: V1  \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification  # ビットおよびバイトの設定とシーケンス分類用のモデルをインポートします。\n",
    "\n",
    "# 量子化設定を定義します。\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4ビットでモデルをロードするように設定します。\n",
    "    bnb_4bit_quant_type='nf4',  # 4ビット量子化のタイプを設定します。ここでは「nf4」を指定します。\n",
    "    bnb_4bit_use_double_quant=True,  # 二重量子化を使用する設定です。これにより、さらにメモリを節約します。\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # 計算時に使用するデータ型をtorchのbfloat16に設定します。これにより、計算効率が向上します。\n",
    ")\n",
    "\n",
    "model_name = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"  # 使用するモデルの名前とパスを指定します。\n",
    "\n",
    "# 特徴を持つモデルを事前訓練済みから読み込みます。\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,  # 読み込むモデルの名前。\n",
    "    quantization_config=quantization_config,  # 量子化設定を適用します。\n",
    "    num_labels=4,  # モデルで扱うラベルの数を設定します。\n",
    "    device_map='auto'  # デバイスマップを自動で設定し、利用可能なGPUを使用します。\n",
    ")\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b0df40",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from transformers import BitsAndBytesConfig, AutoModelForSequenceClassification\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True, \n",
    "    bnb_4bit_quant_type = 'nf4',\n",
    "    bnb_4bit_use_double_quant = True, \n",
    "    bnb_4bit_compute_dtype = torch.bfloat16 \n",
    ")\n",
    "\n",
    "model_name = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quantization_config,\n",
    "    num_labels=4,\n",
    "    device_map='auto'\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model  # LoRA関連のクラスと関数をインポートします。\n",
    "\n",
    "# LoRAの設定を定義します。\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRAのランクを設定します。ここでは16を指定します。\n",
    "    lora_alpha=8,  # LoRAで使用するスケーリング係数を設定します。\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],  # LoRAを適用するターゲットモジュールを指定します。ここでは、クエリ、キー、バリュー、および出力プロジェクションを指定します。\n",
    "    lora_dropout=0.05,  # LoRAのドロップアウト率を設定します。これにより、過学習を防ぎます。\n",
    "    bias='none',  # バイアスの設定をしていません。バイアスを使用しないことを示します。\n",
    "    task_type='SEQ_CLS'  # タスクのタイプをシーケンス分類に設定します。\n",
    ")\n",
    "\n",
    "# モデルをkbitトレーニング用に準備します。\n",
    "model = prepare_model_for_kbit_training(model)  \n",
    "# LoRA設定を使用してモデルを取得（適用）します。\n",
    "model = get_peft_model(model, lora_config)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:41:28.760355Z",
     "iopub.status.busy": "2024-07-06T02:41:28.76007Z",
     "iopub.status.idle": "2024-07-06T02:41:29.156629Z",
     "shell.execute_reply": "2024-07-06T02:41:29.155721Z",
     "shell.execute_reply.started": "2024-07-06T02:41:28.760331Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model  # LoRA関連のクラスと関数をインポートします。\n",
    "\n",
    "# LoRAの設定を定義します。\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # LoRAのランクを設定します。ここでは16を指定します。\n",
    "    lora_alpha=8,  # LoRAで使用するスケーリング係数を設定します。\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj'],  # LoRAを適用するターゲットモジュールを指定します。ここでは、クエリ、キー、バリュー、および出力プロジェクションを指定します。\n",
    "    lora_dropout=0.05,  # LoRAのドロップアウト率を設定します。これにより、過学習を防ぎます。\n",
    "    bias='none',  # バイアスの設定をしていません。バイアスを使用しないことを示します。\n",
    "    task_type='SEQ_CLS'  # タスクのタイプをシーケンス分類に設定します。\n",
    ")\n",
    "\n",
    "# モデルをkbitトレーニング用に準備します。\n",
    "model = prepare_model_for_kbit_training(model)  \n",
    "# LoRA設定を使用してモデルを取得（適用）します。\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565548ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r = 16, \n",
    "    lora_alpha = 8,\n",
    "    target_modules = ['q_proj', 'k_proj', 'v_proj', 'o_proj'],\n",
    "    lora_dropout = 0.05, \n",
    "    bias = 'none',\n",
    "    task_type = 'SEQ_CLS'\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer  # トークナイザーを自動で取得するためのクラスをインポートします。\n",
    "\n",
    "# 事前訓練済みのトークナイザーをモデル名から読み込みます。このとき、トークンの前にスペースを追加する設定をします。\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "# パディングトークンIDを終了トークンIDに設定します。これにより、パディング時に同じトークンを使用します。\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# パディングトークンを終了トークンに設定します。これにより、パディング時に使用するトークンを明示的に指定します。\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:41:29.158084Z",
     "iopub.status.busy": "2024-07-06T02:41:29.157753Z",
     "iopub.status.idle": "2024-07-06T02:41:29.602672Z",
     "shell.execute_reply": "2024-07-06T02:41:29.601879Z",
     "shell.execute_reply.started": "2024-07-06T02:41:29.158057Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer  # トークナイザーを自動で取得するためのクラスをインポートします。\n",
    "\n",
    "# 事前訓練済みのトークナイザーをモデル名から読み込みます。このとき、トークンの前にスペースを追加する設定をします。\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "# パディングトークンIDを終了トークンIDに設定します。これにより、パディング時に同じトークンを使用します。\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "# パディングトークンを終了トークンに設定します。これにより、パディング時に使用するトークンを明示的に指定します。\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b38abb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # モデルの設定にパディングトークンIDを追加します。\n",
    "model.config.use_cache = False  # キャッシュの使用を無効にします。これにより、メモリ使用量が削減されます。\n",
    "model.config.pretraining_tp = 1  # 事前訓練時のテンソル並列処理の設定を1にします。これはモデルの並列処理に影響します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:41:29.604578Z",
     "iopub.status.busy": "2024-07-06T02:41:29.604292Z",
     "iopub.status.idle": "2024-07-06T02:41:29.608971Z",
     "shell.execute_reply": "2024-07-06T02:41:29.608015Z",
     "shell.execute_reply.started": "2024-07-06T02:41:29.604553Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.pad_token_id = tokenizer.pad_token_id  # モデルの設定にパディングトークンIDを追加します。\n",
    "model.config.use_cache = False  # キャッシュの使用を無効にします。これにより、メモリ使用量が削減されます。\n",
    "model.config.pretraining_tp = 1  # 事前訓練時のテンソル並列処理の設定を1にします。これはモデルの並列処理に影響します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cf014c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from datasets import DatasetDict, Dataset  # データセットに関連するクラスをインポートします。\n",
    "\n",
    "def data_preprocesing(row):  # 各行に対してデータ前処理を行う関数を定義します。\n",
    "    return tokenizer(row['text'], padding='max_length', truncation=True, max_length=CFG.MAX_LENGTH, return_tensors='np')  # テキストをトークン化し、パディング、切り捨て、トーチテンソルで返します。\n",
    "\n",
    "# pandasデータフレームからデータセットを作成します。\n",
    "dataset = Dataset.from_pandas(train)  \n",
    "# データセットをトークン化し、'text'列を削除します。\n",
    "tokenized_data = dataset.map(data_preprocesing, batched=True, remove_columns=['text'])  \n",
    "# トークン化されたデータのフォーマットをtorchに設定します。\n",
    "tokenized_data.set_format(\"torch\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:48:50.284166Z",
     "iopub.status.busy": "2024-07-06T02:48:50.283453Z",
     "iopub.status.idle": "2024-07-06T02:49:58.185042Z",
     "shell.execute_reply": "2024-07-06T02:49:58.184137Z",
     "shell.execute_reply.started": "2024-07-06T02:48:50.284134Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset  # データセットに関連するクラスをインポートします。\n",
    "\n",
    "def data_preprocesing(row):  # 各行に対してデータ前処理を行う関数を定義します。\n",
    "    return tokenizer(row['text'], padding='max_length', truncation=True, max_length=CFG.MAX_LENGTH, return_tensors='np')  # テキストをトークン化し、パディング、切り捨て、トーチテンソルで返します。\n",
    "\n",
    "# pandasデータフレームからデータセットを作成します。\n",
    "dataset = Dataset.from_pandas(train)  \n",
    "# データセットをトークン化し、'text'列を削除します。\n",
    "tokenized_data = dataset.map(data_preprocesing, batched=True, remove_columns=['text'])  \n",
    "# トークン化されたデータのフォーマットをtorchに設定します。\n",
    "tokenized_data.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca23a9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from datasets import DatasetDict, Dataset\n",
    "\n",
    "def data_preprocesing(row):\n",
    "    return tokenizer(row['text'], padding='max_length', truncation=True, max_length=CFG.MAX_LENGTH, return_tensors='np')\n",
    "\n",
    "dataset = Dataset.from_pandas(train)\n",
    "tokenized_data = dataset.map(data_preprocesing, batched=True, remove_columns=['text'])\n",
    "tokenized_data.set_format(\"torch\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import gc  # ガーベジコレクションを管理するためのgcライブラリをインポートします。\n",
    "\n",
    "del train  # メモリ使用量を削減するために、trainデータフレームを削除します。\n",
    "gc.collect()  # ガーベジコレクションを手動で実行し、不要なメモリを解放します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:49:58.186681Z",
     "iopub.status.busy": "2024-07-06T02:49:58.186425Z",
     "iopub.status.idle": "2024-07-06T02:49:58.589252Z",
     "shell.execute_reply": "2024-07-06T02:49:58.58825Z",
     "shell.execute_reply.started": "2024-07-06T02:49:58.186659Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc  # ガーベジコレクションを管理するためのgcライブラリをインポートします。\n",
    "\n",
    "del train  # メモリ使用量を削減するために、trainデータフレームを削除します。\n",
    "gc.collect()  # ガーベジコレクションを手動で実行し、不要なメモリを解放します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75c697",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import gc\n",
    "\n",
    "del train\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from transformers import DataCollatorWithPadding  # パディングを扱うためのデータコレレーターをインポートします。\n",
    "\n",
    "# トークナイザーを使ってパディングを行うデータコレーション関数を作成します。\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)  # データコレレーターを初期化します。これにより、バッチ内のすべてのサンプルが同じ長さになるようにパディングされます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:43:04.460816Z",
     "iopub.status.busy": "2024-07-06T02:43:04.460125Z",
     "iopub.status.idle": "2024-07-06T02:43:04.466942Z",
     "shell.execute_reply": "2024-07-06T02:43:04.46592Z",
     "shell.execute_reply.started": "2024-07-06T02:43:04.460787Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding  # パディングを扱うためのデータコレレーターをインポートします。\n",
    "\n",
    "# トークナイザーを使ってパディングを行うデータコレーション関数を作成します。\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)  # データコレレーターを初期化します。これにより、バッチ内のすべてのサンプルが同じ長さになるようにパディングされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba26b4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "def compute_metrics(evaluations):  # 評価指標を計算する関数を定義します。\n",
    "    predictions, labels = evaluations  # 評価から予測値とラベルを取得します。\n",
    "    predictions = np.argmax(predictions, axis=1)  # 予測結果から最大値のインデックスを取得し、クラスラベルに変換します。\n",
    "    # バランス精度と通常の精度を計算し、辞書形式で返します。\n",
    "    return {\n",
    "        'balanced_accuracy': balanced_accuracy_score(predictions, labels),  # バランス精度を計算します。\n",
    "        'accuracy': accuracy_score(predictions, labels)  # 通常の精度を計算します。\n",
    "    }\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:43:25.021317Z",
     "iopub.status.busy": "2024-07-06T02:43:25.020424Z",
     "iopub.status.idle": "2024-07-06T02:43:25.026141Z",
     "shell.execute_reply": "2024-07-06T02:43:25.025203Z",
     "shell.execute_reply.started": "2024-07-06T02:43:25.021287Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(evaluations):  # 評価指標を計算する関数を定義します。\n",
    "    predictions, labels = evaluations  # 評価から予測値とラベルを取得します。\n",
    "    predictions = np.argmax(predictions, axis=1)  # 予測結果から最大値のインデックスを取得し、クラスラベルに変換します。\n",
    "    # バランス精度と通常の精度を計算し、辞書形式で返します。\n",
    "    return {\n",
    "        'balanced_accuracy': balanced_accuracy_score(predictions, labels),  # バランス精度を計算します。\n",
    "        'accuracy': accuracy_score(predictions, labels)  # 通常の精度を計算します。\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8c1a71",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def compute_metrics(evaluations):\n",
    "    predictions, labels = evaluations\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {'balanced_accuracy' : balanced_accuracy_score(predictions, labels),\n",
    "    'accuracy':accuracy_score(predictions,labels)}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "import torch.nn.functional as F  # PyTorchの関数型APIから機能をインポートします。\n",
    "\n",
    "class CustomTrainer(Trainer):  # Trainerクラスを拡張したカスタムトレーナークラスを定義します。\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):  # コンストラクタを定義し、クラス重みを受け取ります。\n",
    "        super().__init__(*args, **kwargs)  # 親クラスのコンストラクタを呼び出します。\n",
    "        if class_weights is not None:  # クラス重みが指定されている場合\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)  # テンソルとしてクラス重みを作成し、デバイスに移動します。\n",
    "        else:\n",
    "            self.class_weights = None  # クラス重みが指定されていない場合はNoneに設定します。\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):  # 損失を計算するメソッドを定義します。\n",
    "#         print(inputs)  # デバッグ用に入力値を表示（コメントアウトされています）。\n",
    "        labels = inputs.pop(\"labels\").long()  # 入力からラベルを取り出し、long型に変換します。\n",
    "\n",
    "        outputs = model(**inputs)  # モデルを入力して予測を得ます。\n",
    "\n",
    "        logits = outputs.get('logits')  # モデルの出力からロジットを取得します。\n",
    "\n",
    "        if self.class_weights is not None:  # クラス重みが指定されている場合\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)  # 重み付きの交差エントロピー損失を計算します。\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)  # 通常の交差エントロピー損失を計算します。\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss  # 出力を返すか、損失のみを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:56:47.34782Z",
     "iopub.status.busy": "2024-07-06T02:56:47.346937Z",
     "iopub.status.idle": "2024-07-06T02:56:47.356087Z",
     "shell.execute_reply": "2024-07-06T02:56:47.354928Z",
     "shell.execute_reply.started": "2024-07-06T02:56:47.347789Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # PyTorchの関数型APIから機能をインポートします。\n",
    "\n",
    "class CustomTrainer(Trainer):  # Trainerクラスを拡張したカスタムトレーナークラスを定義します。\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):  # コンストラクタを定義し、クラス重みを受け取ります。\n",
    "        super().__init__(*args, **kwargs)  # 親クラスのコンストラクタを呼び出します。\n",
    "        if class_weights is not None:  # クラス重みが指定されている場合\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)  # テンソルとしてクラス重みを作成し、デバイスに移動します。\n",
    "        else:\n",
    "            self.class_weights = None  # クラス重みが指定されていない場合はNoneに設定します。\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):  # 損失を計算するメソッドを定義します。\n",
    "#         print(inputs)  # デバッグ用に入力値を表示（コメントアウトされています）。\n",
    "        labels = inputs.pop(\"labels\").long()  # 入力からラベルを取り出し、long型に変換します。\n",
    "\n",
    "        outputs = model(**inputs)  # モデルを入力して予測を得ます。\n",
    "\n",
    "        logits = outputs.get('logits')  # モデルの出力からロジットを取得します。\n",
    "\n",
    "        if self.class_weights is not None:  # クラス重みが指定されている場合\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)  # 重み付きの交差エントロピー損失を計算します。\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)  # 通常の交差エントロピー損失を計算します。\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss  # 出力を返すか、損失のみを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8619f3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.args.device)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "#         print(inputs)\n",
    "        labels = inputs.pop(\"labels\").long()\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        logits = outputs.get('logits')\n",
    "\n",
    "        if self.class_weights is not None:\n",
    "            loss = F.cross_entropy(logits, labels, weight=self.class_weights)\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(  # トレーニングの引数を設定するためのTrainingArgumentsオブジェクトを作成します。\n",
    "    output_dir='sentiment_classification',  # モデルの出力先ディレクトリを指定します。\n",
    "    learning_rate=1e-4,  # 学習率を設定します。\n",
    "    per_device_train_batch_size=8,  # 各デバイスでのトレーニングバッチサイズを設定します。\n",
    "    per_device_eval_batch_size=8,  # 各デバイスでの評価バッチサイズを設定します。\n",
    "    num_train_epochs=1,  # トレーニングのエポック数を設定します。\n",
    "    logging_steps=1,  # ロギングを行うステップ間隔を設定します。\n",
    "    weight_decay=0.01,  # 重み減衰率を設定します。これにより過学習を防ぎます。\n",
    "    evaluation_strategy='epoch',  # 評価の戦略としてエポック毎に評価を設定します。\n",
    "    save_strategy='epoch',  # モデルの保存戦略としてエポック毎に保存を設定します。\n",
    "    load_best_model_at_end=True,  # トレーニングの終了時に最良のモデルを読み込む設定です。\n",
    "    report_to=\"none\"  # ロギングを行わない設定です。\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:56:48.086406Z",
     "iopub.status.busy": "2024-07-06T02:56:48.085674Z",
     "iopub.status.idle": "2024-07-06T02:56:48.121806Z",
     "shell.execute_reply": "2024-07-06T02:56:48.120877Z",
     "shell.execute_reply.started": "2024-07-06T02:56:48.086375Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(  # トレーニングの引数を設定するためのTrainingArgumentsオブジェクトを作成します。\n",
    "    output_dir='sentiment_classification',  # モデルの出力先ディレクトリを指定します。\n",
    "    learning_rate=1e-4,  # 学習率を設定します。\n",
    "    per_device_train_batch_size=8,  # 各デバイスでのトレーニングバッチサイズを設定します。\n",
    "    per_device_eval_batch_size=8,  # 各デバイスでの評価バッチサイズを設定します。\n",
    "    num_train_epochs=1,  # トレーニングのエポック数を設定します。\n",
    "    logging_steps=1,  # ロギングを行うステップ間隔を設定します。\n",
    "    weight_decay=0.01,  # 重み減衰率を設定します。これにより過学習を防ぎます。\n",
    "    evaluation_strategy='epoch',  # 評価の戦略としてエポック毎に評価を設定します。\n",
    "    save_strategy='epoch',  # モデルの保存戦略としてエポック毎に保存を設定します。\n",
    "    load_best_model_at_end=True,  # トレーニングの終了時に最良のモデルを読み込む設定です。\n",
    "    report_to=\"none\"  # ロギングを行わない設定です。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd6d415",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = 'sentiment_classification',\n",
    "    learning_rate = 1e-4,\n",
    "    per_device_train_batch_size = 8,\n",
    "    per_device_eval_batch_size = 8,\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps=1,\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = 'epoch',\n",
    "    save_strategy = 'epoch',\n",
    "    load_best_model_at_end = True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "trainer = CustomTrainer(  # カスタムトレーナーのインスタンスを作成します。\n",
    "    model=model,  # 使用するモデルを指定します。\n",
    "    args=training_args,  # トレーニング引数を指定します。\n",
    "    train_dataset=tokenized_data,  # トレーニングデータセットを指定します。\n",
    "    tokenizer=tokenizer,  # 使用するトークナイザーを指定します。\n",
    "    data_collator=collate_fn,  # データコレーターを指定します。バッチのパディングを行います。\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算する関数を指定します。\n",
    "#     class_weights=class_weights,  # ここでクラス重みを使用する場合は、コメントを外します。\n",
    ")\n",
    "\n",
    "train_result = trainer.train()  # トレーニングを開始し、結果を取得します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T02:56:49.480493Z",
     "iopub.status.busy": "2024-07-06T02:56:49.480104Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = CustomTrainer(  # カスタムトレーナーのインスタンスを作成します。\n",
    "    model=model,  # 使用するモデルを指定します。\n",
    "    args=training_args,  # トレーニング引数を指定します。\n",
    "    train_dataset=tokenized_data,  # トレーニングデータセットを指定します。\n",
    "    tokenizer=tokenizer,  # 使用するトークナイザーを指定します。\n",
    "    data_collator=collate_fn,  # データコレーターを指定します。バッチのパディングを行います。\n",
    "    compute_metrics=compute_metrics,  # 評価指標を計算する関数を指定します。\n",
    "#     class_weights=class_weights,  # ここでクラス重みを使用する場合は、コメントを外します。\n",
    ")\n",
    "\n",
    "train_result = trainer.train()  # トレーニングを開始し、結果を取得します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93149eeb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "trainer = CustomTrainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_data,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metrics,\n",
    "#     class_weights=class_weights,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4484051,
     "sourceId": 7711309,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
