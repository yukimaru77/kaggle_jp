{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ca66463",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena Human Preference Predictions」コンペティションに参加するためのモデルを構築するプロセスを示しています。主な目的は、異なる大規模言語モデル（LLM）が生成した応答に対するユーザーの好みを予測することです。\n",
    "\n",
    "### 問題\n",
    "ノートブックは、ユーザーが2つの異なる応答のどちらを好むかを予測する、マルチクラス分類問題に取り組んでいます。具体的には、相手にどのモデルの応答が好まれるかを分析し、結果を予測するモデリングを行います。\n",
    "\n",
    "### 手法\n",
    "このプロジェクトでは、以下の手法とライブラリが使用されています。\n",
    "- **PandasおよびNumpy**: データの操作と数値計算を行うために使用されています。\n",
    "- **Scikit-learn**: データの分割やTF-IDFベクトル化、評価指標（対数損失）の計算に用いられています。\n",
    "- **LightGBM**: 勾配ブースティングフレームワークを用いて、マルチクラス分類モデルのトレーニングに使用しています。\n",
    "- **Optuna**: ハイパーパラメータの最適化に使用され、最適なモデル性能を導くための試行が実施されています。\n",
    "\n",
    "### プロセス\n",
    "1. データの読み込み: トレーニングデータとテストデータをCSVファイルから取得します。\n",
    "2. データ前処理: 欠損値の処理や応答文の結合を行い、モデルに入力できる形式に整形します。\n",
    "3. テキストのベクトル化: TF-IDFを使用して、テキストデータを数値的な特徴量に変換します。\n",
    "4. データ分割: トレーニングデータをトレーニングセットとバリデーションセットに分けます。\n",
    "5. モデルのトレーニング: LightGBMを使用してモデルを構築し、Optunaでハイパーパラメータチューニングを行います。\n",
    "6. テストセットの予測: 最終モデルを用いてテストデータの予測確率を計算します。\n",
    "7. 提出ファイルの作成: 予測結果を基にCSV形式の提出ファイルを生成します。\n",
    "\n",
    "このノートブックは、予測のための機械学習モデルの構築と評価、そして最終的な提出ファイルの作成という一連の流れを包括的にカバーしています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d38c0e",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に基づいて、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説を列挙します。これらは初心者が馴染みづらい用語や、このノートブック特有のドメイン知識に関連するものです。\n",
    "\n",
    "1. **TfidfVectorizer**:\n",
    "    - TF-IDF（Term Frequency-Inverse Document Frequency）ベクトルライザーは、テキストを数値ベクトルに変換する手法です。文書内の特定の単語の出現頻度と、それがどの程度他の文書に出現するかを考慮して重みを付けるため、重要度の高い単語を強調できます。これにより、機械学習モデルがテキストを理解しやすくなります。\n",
    "\n",
    "2. **multiclass**:\n",
    "    - マルチクラス分類とは、入力データを3つ以上のクラスに分類するタスクのことです。このノートブックでは、応答の勝者を特定するために、モデルが3つの可能なクラス（モデルAの勝ち、モデルBの勝ち、引き分け）を予測します。\n",
    "\n",
    "3. **log_loss**:\n",
    "    - 対数損失は、モデルの予測が正確であるかどうかを評価する指標です。特に確率的な出力を持つモデルに対して使用され、予測確率と実際のクラスとの間の不一致を数値化します。値が小さいほどモデルの予測が良いことを示します。\n",
    "\n",
    "4. **LightGBM (Light Gradient Boosting Machine)**:\n",
    "    - LightGBMは、Microsoftによって開発された勾配ブースティングのフレームワークの一つで、大規模データのトレーニングに迅速かつ効率的に対応できるよう設計されています。他の勾配ブースティングアルゴリズムに比べてメモリ使用量が少なく、高速な学習が可能です。\n",
    "\n",
    "5. **Optuna**:\n",
    "    - Optunaは、ハイパーパラメータのチューニングを自動化するためのオープンソースのライブラリです。適応的にハイパーパラメータを探索し、最適な組み合わせを見つけるための効率的なアルゴリズムを提供します。このノートブックでは、モデルの性能を最大化するために使用されています。\n",
    "\n",
    "6. **num_leaves**:\n",
    "    - LightGBMにおける「葉の数」を設定するためのハイパーパラメータです。葉の数が多いほど、モデルはより複雑になりますが、過学習のリスクも高まります。\n",
    "\n",
    "7. **feature_fraction**:\n",
    "    - LightGBMで使用されるハイパーパラメータの一つで、モデル作成に使用する特徴量の割合を指定します。これにより、異なる特徴の組み合わせを試すことができ、モデルの一般化能力が向上することがあります。\n",
    "\n",
    "8. **bagging_fraction**:\n",
    "    - バギング時に使用するサンプルの割合を指定するハイパーパラメータです。このパラメータは、モデルの過学習を防ぐために用いられることがあります。\n",
    "\n",
    "9. **early_stopping**:\n",
    "    - モデルのトレーニング中に、検証データにおけるパフォーマンスの改善が見られない場合にトレーニングを早期に停止する手法です。これにより過学習を防ぎ、計算時間を短縮することができます。\n",
    "\n",
    "10. **bagging_freq**:\n",
    "    - LightGBMでのバギングの頻度を設定するハイパーパラメータで、どれくらいの頻度でバギングを行うかを指定します。バギングは、モデルの多様性を与え、汎化性能を向上させる手法です。\n",
    "\n",
    "これらの用語は、特に実務経験が少ない初心者にとって混乱を招く可能性があるため、注意が必要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cca4d9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-29T07:24:09.157264Z",
     "iopub.status.busy": "2024-07-29T07:24:09.156433Z",
     "iopub.status.idle": "2024-07-29T07:24:12.884535Z",
     "shell.execute_reply": "2024-07-29T07:24:12.883096Z",
     "shell.execute_reply.started": "2024-07-29T07:24:09.157223Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e192a3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load the data\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "print(train_data.head())\n",
    "print(train_data.info())\n",
    "print(train_data.describe())\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データの読み込み\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込む\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む\n",
    "\n",
    "print(train_data.head())  # トレーニングデータの最初の数行を表示\n",
    "print(train_data.info())  # トレーニングデータの情報を表示\n",
    "print(train_data.describe())  # トレーニングデータの統計情報を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:24:12.887848Z",
     "iopub.status.busy": "2024-07-29T07:24:12.886621Z",
     "iopub.status.idle": "2024-07-29T07:24:16.942582Z",
     "shell.execute_reply": "2024-07-29T07:24:16.941473Z",
     "shell.execute_reply.started": "2024-07-29T07:24:12.887807Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込む\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む\n",
    "\n",
    "print(train_data.head())  # トレーニングデータの最初の数行を表示\n",
    "print(train_data.info())  # トレーニングデータの情報を表示\n",
    "print(train_data.describe())  # トレーニングデータの統計情報を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42119d3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Preprocessing data\n",
    "# Handling missing values if any\n",
    "train_data.fillna('', inplace=True)\n",
    "test_data.fillna('', inplace=True)\n",
    "\n",
    "# Combine text data for vectorization\n",
    "train_data['combined_text'] = train_data['prompt'] + ' ' + train_data['response_a'] + ' ' + train_data['response_b']\n",
    "test_data['combined_text'] = test_data['prompt'] + ' ' + test_data['response_a'] + ' ' + test_data['response_b']\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train = vectorizer.fit_transform(train_data['combined_text'])\n",
    "X_test = vectorizer.transform(test_data['combined_text'])\n",
    "\n",
    "# Extract the target variable\n",
    "train_data['winner'] = np.where(train_data['winner_model_a'] == 1, 0, np.where(train_data['winner_model_b'] == 1, 1, 2))\n",
    "y_train = train_data['winner']\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データの前処理\n",
    "# 欠損値があれば処理する\n",
    "train_data.fillna('', inplace=True)  # トレーニングデータの欠損値を空文字で埋める\n",
    "test_data.fillna('', inplace=True)  # テストデータの欠損値を空文字で埋める\n",
    "\n",
    "# テキストデータを結合してベクトル化のための準備をする\n",
    "train_data['combined_text'] = train_data['prompt'] + ' ' + train_data['response_a'] + ' ' + train_data['response_b']  # プロンプトと応答を結合\n",
    "test_data['combined_text'] = test_data['prompt'] + ' ' + test_data['response_a'] + ' ' + test_data['response_b']  # 同様にテストデータも結合\n",
    "\n",
    "# テキストデータをベクトル化する\n",
    "vectorizer = TfidfVectorizer(max_features=10000)  # TF-IDFベクトルライザーを初期化（最大10,000特徴）\n",
    "X_train = vectorizer.fit_transform(train_data['combined_text'])  # トレーニングデータをフィッティングして変換\n",
    "X_test = vectorizer.transform(test_data['combined_text'])  # テストデータを変換\n",
    "\n",
    "# 目的変数を抽出する\n",
    "train_data['winner'] = np.where(train_data['winner_model_a'] == 1, 0, np.where(train_data['winner_model_b'] == 1, 1, 2))  # 勝者モデルを設定\n",
    "y_train = train_data['winner']  # 勝者ラベルをターゲット変数として抽出\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:24:16.94433Z",
     "iopub.status.busy": "2024-07-29T07:24:16.943898Z",
     "iopub.status.idle": "2024-07-29T07:24:39.394286Z",
     "shell.execute_reply": "2024-07-29T07:24:39.393157Z",
     "shell.execute_reply.started": "2024-07-29T07:24:16.944292Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "# 欠損値があれば処理する\n",
    "train_data.fillna('', inplace=True)  # トレーニングデータの欠損値を空文字で埋める\n",
    "test_data.fillna('', inplace=True)  # テストデータの欠損値を空文字で埋める\n",
    "\n",
    "# テキストデータを結合してベクトル化のための準備をする\n",
    "train_data['combined_text'] = train_data['prompt'] + ' ' + train_data['response_a'] + ' ' + train_data['response_b']  # プロンプトと応答を結合\n",
    "test_data['combined_text'] = test_data['prompt'] + ' ' + test_data['response_a'] + ' ' + test_data['response_b']  # 同様にテストデータも結合\n",
    "\n",
    "# テキストデータをベクトル化する\n",
    "vectorizer = TfidfVectorizer(max_features=10000)  # TF-IDFベクトルライザーを初期化（最大10,000特徴）\n",
    "X_train = vectorizer.fit_transform(train_data['combined_text'])  # トレーニングデータをフィッティングして変換\n",
    "X_test = vectorizer.transform(test_data['combined_text'])  # テストデータを変換\n",
    "\n",
    "# 目的変数を抽出する\n",
    "train_data['winner'] = np.where(train_data['winner_model_a'] == 1, 0, np.where(train_data['winner_model_b'] == 1, 1, 2))  # 勝者モデルを設定\n",
    "y_train = train_data['winner']  # 勝者ラベルをターゲット変数として抽出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0936bf5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Split the data into training and validation sets\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to LightGBM Dataset\n",
    "train_data_lgb = lgb.Dataset(X_train_split, label=y_train_split)\n",
    "val_data_lgb = lgb.Dataset(X_val, label=y_val, reference=train_data_lgb)\n",
    "\n",
    "# Optuna objective function for tuning\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'feature_pre_filter': False,\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.25),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 30, 100),\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])\n",
    "    \n",
    "    y_val_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)\n",
    "    loss = log_loss(y_val, y_val_pred_proba)\n",
    "    return loss\n",
    "\n",
    "# Run Optuna for hyperparameter tuning\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Retrieve the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "best_params.update({'objective': 'multiclass', 'num_class': 3, 'metric': 'multi_logloss', 'boosting': 'gbdt'})\n",
    "\n",
    "# Train the final model with the best hyperparameters\n",
    "final_model = lgb.train(best_params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データをトレーニングセットとバリデーションセットに分割する\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 80:20で分割\n",
    "\n",
    "# LightGBM用のデータセットに変換する\n",
    "train_data_lgb = lgb.Dataset(X_train_split, label=y_train_split)  # トレーニングデータセットを作成\n",
    "val_data_lgb = lgb.Dataset(X_val, label=y_val, reference=train_data_lgb)  # バリデーションデータセットを作成\n",
    "\n",
    "# Optunaの目的関数（ハイパーパラメータチューニング用）\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'feature_pre_filter': False,  # 特徴の事前フィルタリングを無効にする\n",
    "        'objective': 'multiclass',  # マルチクラス分類を指定\n",
    "        'num_class': 3,  # クラス数\n",
    "        'metric': 'multi_logloss',  # 評価指標にマルチクラス対数損失を指定\n",
    "        'boosting': 'gbdt',  # 勾配ブースティング\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),  # 葉の数のハイパーパラメータ\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.25),  # 学習率のハイパーパラメータ\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),  # 特徴の一部を使用する割合\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),  # バギング時のサンプルの割合\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),  # バギングの頻度\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),  # 木の最大深さ\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 30, 100),  # 葉に必要な最小データ数\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])  # モデルをトレーニング\n",
    "    \n",
    "    y_val_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)  # バリデーションセットの予測確率を取得\n",
    "    loss = log_loss(y_val, y_val_pred_proba)  # 対数損失を計算\n",
    "    return loss  # 損失を返す\n",
    "\n",
    "# Optunaでハイパーパラメータチューニングを実行する\n",
    "study = optuna.create_study(direction='minimize')  # スタディを作成\n",
    "study.optimize(objective, n_trials=20)  # 20回の試行で最適化\n",
    "\n",
    "# ベストハイパーパラメータを取得する\n",
    "best_params = study.best_trial.params  # ベストな試行のパラメータを取得\n",
    "best_params.update({'objective': 'multiclass', 'num_class': 3, 'metric': 'multi_logloss', 'boosting': 'gbdt'})  # 追加情報を更新\n",
    "\n",
    "# 最終モデルをベストハイパーパラメータでトレーニング\n",
    "final_model = lgb.train(best_params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])  # 最終モデルをトレーニング\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-07-29T07:24:39.397161Z",
     "iopub.status.busy": "2024-07-29T07:24:39.396739Z",
     "iopub.status.idle": "2024-07-29T07:38:52.792464Z",
     "shell.execute_reply": "2024-07-29T07:38:52.791446Z",
     "shell.execute_reply.started": "2024-07-29T07:24:39.397125Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# データをトレーニングセットとバリデーションセットに分割する\n",
    "X_train_split, X_val, y_train_split, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)  # 80:20で分割\n",
    "\n",
    "# LightGBM用のデータセットに変換する\n",
    "train_data_lgb = lgb.Dataset(X_train_split, label=y_train_split)  # トレーニングデータセットを作成\n",
    "val_data_lgb = lgb.Dataset(X_val, label=y_val, reference=train_data_lgb)  # バリデーションデータセットを作成\n",
    "\n",
    "# Optunaの目的関数（ハイパーパラメータチューニング用）\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'feature_pre_filter': False,  # 特徴の事前フィルタリングを無効にする\n",
    "        'objective': 'multiclass',  # マルチクラス分類を指定\n",
    "        'num_class': 3,  # クラス数\n",
    "        'metric': 'multi_logloss',  # 評価指標にマルチクラス対数損失を指定\n",
    "        'boosting': 'gbdt',  # 勾配ブースティング\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),  # 葉の数のハイパーパラメータ\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.25),  # 学習率のハイパーパラメータ\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.7, 1.0),  # 特徴の一部を使用する割合\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.7, 1.0),  # バギング時のサンプルの割合\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),  # バギングの頻度\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),  # 木の最大深さ\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 30, 100),  # 葉に必要な最小データ数\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])  # モデルをトレーニング\n",
    "    \n",
    "    y_val_pred_proba = model.predict(X_val, num_iteration=model.best_iteration)  # バリデーションセットの予測確率を取得\n",
    "    loss = log_loss(y_val, y_val_pred_proba)  # 対数損失を計算\n",
    "    return loss  # 損失を返す\n",
    "\n",
    "# Optunaでハイパーパラメータチューニングを実行する\n",
    "study = optuna.create_study(direction='minimize')  # スタディを作成\n",
    "study.optimize(objective, n_trials=20)  # 20回の試行で最適化\n",
    "\n",
    "# ベストハイパーパラメータを取得する\n",
    "best_params = study.best_trial.params  # ベストな試行のパラメータを取得\n",
    "best_params.update({'objective': 'multiclass', 'num_class': 3, 'metric': 'multi_logloss', 'boosting': 'gbdt'})  # 追加情報を更新\n",
    "\n",
    "# 最終モデルをベストハイパーパラメータでトレーニング\n",
    "final_model = lgb.train(best_params, train_data_lgb, valid_sets=[val_data_lgb], callbacks=[lgb.early_stopping(stopping_rounds=10), lgb.log_evaluation(10)])  # 最終モデルをトレーニング"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5ac693",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Predict probabilities for test set\n",
    "test_pred_proba = final_model.predict(X_test, num_iteration=final_model.best_iteration)\n",
    "\n",
    "# Create a submission file\n",
    "submission = pd.DataFrame(test_pred_proba, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "submission['id'] = test_data['id']\n",
    "submission = submission[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストセットの予測確率を計算する\n",
    "test_pred_proba = final_model.predict(X_test, num_iteration=final_model.best_iteration)  # テストセットの予測確率を取得\n",
    "\n",
    "# 提出ファイルを作成する\n",
    "submission = pd.DataFrame(test_pred_proba, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])  # データフレームを作成\n",
    "submission['id'] = test_data['id']  # ID列を追加\n",
    "submission = submission[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 列の順序を整える\n",
    "submission.to_csv('submission.csv', index=False)  # CSVファイルとして保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:38:52.793929Z",
     "iopub.status.busy": "2024-07-29T07:38:52.79362Z",
     "iopub.status.idle": "2024-07-29T07:38:52.806983Z",
     "shell.execute_reply": "2024-07-29T07:38:52.805921Z",
     "shell.execute_reply.started": "2024-07-29T07:38:52.793902Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストセットの予測確率を計算する\n",
    "test_pred_proba = final_model.predict(X_test, num_iteration=final_model.best_iteration)  # テストセットの予測確率を取得\n",
    "\n",
    "# 提出ファイルを作成する\n",
    "submission = pd.DataFrame(test_pred_proba, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])  # データフレームを作成\n",
    "submission['id'] = test_data['id']  # ID列を追加\n",
    "submission = submission[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 列の順序を整える\n",
    "submission.to_csv('submission.csv', index=False)  # CSVファイルとして保存"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
