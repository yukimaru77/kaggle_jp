{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53900cc9",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」コンペティションにおいて、チャットボットの応答がどちらのモデルに好まれるかを予測する問題に取り組んでいます。具体的には、異なる大規模言語モデル（LLM）による応答の比較を行い、どちらの応答がユーザーに受け入れられるかを予測するための機械学習モデルを構築しています。\n",
    "\n",
    "### 問題へのアプローチ\n",
    "1. **データ準備**:\n",
    "   - テストデータとサンプル提出ファイルをCSVから読み込み、必要なデータを整形します。\n",
    "   - ユーザープロンプトおよびモデルの応答を連結し、モデルの入力形式に適したテキストを準備します。\n",
    "\n",
    "2. **ライブラリの使用**:\n",
    "   - `torch` (深層学習フレームワーク) と `sklearn` (機械学習ツール) のほか、`transformers`ライブラリを利用して、LLMのベースモデル（Llama）を読み込んでいます。\n",
    "   - `peft` (Parameter-Efficient Fine-Tuning)ライブラリを用いてモデルを効率的にファインチューニングします。\n",
    "\n",
    "3. **トークナイズ**:\n",
    "   - `AutoTokenizer`を使用して、モデルへの入力データをトークン化し、適切な形状にパディングします。\n",
    "\n",
    "4. **モデルの構築と推論**:\n",
    "   - Chatbot Arenaでの競争用に、大規模なLLMをモデルとして設定し、複数のGPUを用いて並列処理を行います。\n",
    "   - `LoraConfig`を通じてLoRA（Low-Rank Adaptation）によるパラメータの効率的な微調整を行います。\n",
    "   - 推論関数を定義し、入力データに対してモデルの出力を早く計算します。\n",
    "\n",
    "5. **LightGBMの使用**:\n",
    "   - LightGBMを用いた新たな特徴量抽出と分類モデルによって、応答の選好予測も行います。\n",
    "   - 以前に保存されたモデルを用いて推論を実施し、各応答のクラス確率を出力します。\n",
    "\n",
    "6. **予測のブレンド**:\n",
    "   - 最後に、LGBMモデルトとLLMモデルの予測を重み付けしてブレンドし、最終的な予測結果を生成します。\n",
    "\n",
    "### 使用ライブラリ\n",
    "- `torch`: 深層学習モデルのライブラリ。\n",
    "- `transformers`: LLMの読み込みやトークナイズ用ライブラリ。\n",
    "- `peft`: モデルのファインチューニングを効率化するためのライブラリ。\n",
    "- `pandas`: データ処理ライブラリ。\n",
    "- `sklearn`: 機械学習用ライブラリ（モデル評価、データ処理）。\n",
    "- `lightgbm`: 勾配ブースティングフレームワーク。\n",
    "- `matplotlib`: グラフ描画ライブラリ（必要に応じて使用）。\n",
    "\n",
    "このノートブックは、最新の機械学習手法を用いて、ユーザーが最も好むチャットボットの応答を的確に予測するモデルを構築するプロセスを詳細に示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b544bce",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に基づいて、機械学習・深層学習の初心者がつまずく可能性がある専門用語の簡単な解説です。\n",
    "\n",
    "1. **bitsandbytes**: これは、モデルのメモリ使用量を削減し、効率的な計算を可能にするためのライブラリで、量子化技術を利用してモデルを軽量化します。特に、深層学習フレームワークで大規模なモデルを扱う際に役立ちます。\n",
    "\n",
    "2. **PEFT (Parameter-Efficient Fine-Tuning)**: 自然言語処理モデルを効率的に微調整する技術の一つです。PEFTでは、モデル全体をトレーニングするのではなく、軽微なパラメータ（例: LoRA）だけを学習させることで、計算リソースを節約しながら性能を向上させるアプローチです。\n",
    "\n",
    "3. **LoRa (Low-Rank Adaptation)**: PEFTの一種で、モデルの重みを低ランクの行列で approximating し、さらにドロップアウトを加えることで、特定のタスクに適したモデルに微調整します。この方法は、学習を早め、少ないデータでの性能向上を目指します。\n",
    "\n",
    "4. **autocast**: 自動混合精度を使用して、計算の精度を動的に調整するための機能です。高精度の計算を必要としない部分では、計算を16ビット浮動小数点（float16）で行うことで、メモリ使用量を減らし、速度を向上させることができます。\n",
    "\n",
    "5. **attention mask**: トランスフォーマーモデルにおける入力データの一部を制御するためのマスクです。通常、パディングトークンの部分には0、実際のデータの部分には1が割り当てられ、モデルが無関係な情報を無視するのに使われます。\n",
    "\n",
    "6. **softmax**: 出力の値を0〜1の範囲に変換し、合計が1になるように正規化する関数です。主に多クラス分類問題で使用され、各クラスが選ばれる確率を示します。\n",
    "\n",
    "7. **ガベージコレクション (Garbage Collection)**: 使用されなくなったメモリを自動的に解放するプロセスです。Pythonの動的メモリ管理機能の一部で、メモリリークを防ぐために重要です。\n",
    "\n",
    "8. **シンメトリック対数変換 (Symmetric Log Transformation)**: 数値のスケーリングに使用される手法で、ゼロまたは負の値を持つ場合でも適用できるように、数値の符号を考慮して対数変換を行います。データの分布を正規分布に近づけるためによく使われます。\n",
    "\n",
    "9. **CountVectorizer**: 文書中の単語の出現回数をカウントし、特長をベクトル形式で表現するための手法です。自然言語処理で一般的に使用され、テキストデータを数値データに変換する際に役立ちます。\n",
    "\n",
    "10. **StratifiedKFold**: 機械学習の交差検証手法の一つで、各フォールドにおいてクラスの分布が訓練データ全体と均等になるようにデータを分割します。これにより、特に不均衡なデータセットでのモデル評価がより信頼性のあるものになります。\n",
    "\n",
    "これらの用語は、それぞれ特定の技術やアプローチを示しており、初心者が理解する上での難所となることが多いです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a4e86a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# bitsandbytesを最新バージョンにアップグレードしてインストールします。\n",
    "# インデックスを使用せず、指定したリンクからパッケージを探します。\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# transformersライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# tokenizersライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# peftライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T06:57:34.819548Z",
     "iopub.status.busy": "2024-05-30T06:57:34.818704Z",
     "iopub.status.idle": "2024-05-30T06:58:29.941218Z",
     "shell.execute_reply": "2024-05-30T06:58:29.939869Z",
     "shell.execute_reply.started": "2024-05-30T06:57:34.819497Z"
    }
   },
   "outputs": [],
   "source": [
    "# bitsandbytesを最新バージョンにアップグレードしてインストールします。\n",
    "# インデックスを使用せず、指定したリンクからパッケージを探します。\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# transformersライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# tokenizersライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "\n",
    "# peftライブラリを最新バージョンにアップグレードしてインストールします。\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b1b6d5",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "The work in this notebook is inspired by these notebooks:\n",
    "* https://www.kaggle.com/code/ivanvybornov/llama3-8b-lgbm-tfidf\n",
    "* https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b\n",
    "\n",
    "## Importing Libraries\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "このノートブックの作業は、以下のノートブックにインスパイアされています：\n",
    "* https://www.kaggle.com/code/ivanvybornov/llama3-8b-lgbm-tfidf\n",
    "* https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b\n",
    "\n",
    "## ライブラリのインポート\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2b8a97",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from torch.cuda.amp import autocast\n",
    "from threading import Thread\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import zipfile\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "import tokenizers\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートします。\n",
    "import torch  # PyTorchをインポートして、深層学習モデルの構築に使用します。\n",
    "import sklearn  # 機械学習のためのツールを提供するライブラリ\n",
    "import numpy as np  # 数値計算を行うためのライブラリ\n",
    "import pandas as pd  # データ操作と解析のためのライブラリ\n",
    "import time  # 時間に関連する機能を扱うライブラリ\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# Transformersライブラリからトークナイザーやモデルをインポートします。\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# PEFT（Parameter-Efficient Fine-Tuning）ライブラリから必要なクラスや関数をインポートします。\n",
    "\n",
    "from torch.cuda.amp import autocast  # 自動混合精度トレーニングのための機能をインポートします。\n",
    "from threading import Thread  # スレッド処理のためのライブラリをインポートします。\n",
    "\n",
    "import gc  # ガベージコレクションを管理するためのライブラリ\n",
    "import os  # オペレーティングシステムの機能を操作するライブラリ\n",
    "import io  # 入出力関連の操作を行うライブラリ\n",
    "import time  # 時間操作のためのライブラリ\n",
    "import json  # JSONデータの操作を行うためのライブラリ\n",
    "import random  # 乱数生成のためのライブラリ\n",
    "import pickle  # オブジェクトのシリアライズを行うためのライブラリ\n",
    "import zipfile  # ZIPアーカイブの読み書きを扱うライブラリ\n",
    "import datetime  # 日付と時間の操作を行うためのライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフ作成のためのライブラリ\n",
    "from IPython.display import display  # Jupyter Notebookでの表示を管理するための機能をインポートします。\n",
    "from collections import Counter  # 頻度計算を行うためのクラス\n",
    "from collections import defaultdict  # デフォルト値の付いた辞書を作成するためのクラス\n",
    "import torch  # もう一度PyTorchをインポートします。\n",
    "from torch import nn  # PyTorchのニューラルネットワーク関連モジュールをインポートします。\n",
    "import torch.nn.functional as F  # ニューラルネットワークの機能的な操作を提供します。\n",
    "import pytorch_lightning as pl  # PyTorchを使った機械学習モデルの訓練を簡素化するライブラリ\n",
    "from torch.utils.data import Dataset, DataLoader  # データセットとデータローダーのクラスをインポートします。\n",
    "from sklearn.metrics import log_loss  # ログ損失を計算するための関数をインポートします。\n",
    "import tokenizers  # トークナイザー関連の機能を提供するライブラリ\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします。\n",
    "import torch  # PyTorchをインポートして、深層学習モデルの構築に使用します。\n",
    "import sklearn  # 機械学習のためのツールを提供するライブラリ\n",
    "import numpy as np  # 数値計算を行うためのライブラリ\n",
    "import pandas as pd  # データ操作と解析のためのライブラリ\n",
    "import time  # 時間に関連する機能を扱うライブラリ\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# Transformersライブラリからトークナイザーやモデルをインポートします。\n",
    "\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# PEFT（Parameter-Efficient Fine-Tuning）ライブラリから必要なクラスや関数をインポートします。\n",
    "\n",
    "from torch.cuda.amp import autocast  # 自動混合精度トレーニングのための機能をインポートします。\n",
    "from threading import Thread  # スレッド処理のためのライブラリをインポートします。\n",
    "\n",
    "import gc  # ガベージコレクションを管理するためのライブラリ\n",
    "import os  # オペレーティングシステムの機能を操作するライブラリ\n",
    "import io  # 入出力関連の操作を行うライブラリ\n",
    "import time  # 時間操作のためのライブラリ\n",
    "import json  # JSONデータの操作を行うためのライブラリ\n",
    "import random  # 乱数生成のためのライブラリ\n",
    "import pickle  # オブジェクトのシリアライズを行うためのライブラリ\n",
    "import zipfile  # ZIPアーカイブの読み書きを扱うライブラリ\n",
    "import datetime  # 日付と時間の操作を行うためのライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフ作成のためのライブラリ\n",
    "from IPython.display import display  # Jupyter Notebookでの表示を管理するための機能をインポートします。\n",
    "from collections import Counter  # 頻度計算を行うためのクラス\n",
    "from collections import defaultdict  # デフォルト値の付いた辞書を作成するためのクラス\n",
    "import torch  # もう一度PyTorchをインポートします。\n",
    "from torch import nn  # PyTorchのニューラルネットワーク関連モジュールをインポートします。\n",
    "import torch.nn.functional as F  # ニューラルネットワークの機能的な操作を提供します。\n",
    "import pytorch_lightning as pl  # PyTorchを使った機械学習モデルの訓練を簡素化するライブラリ\n",
    "from torch.utils.data import Dataset, DataLoader  # データセットとデータローダーのクラスをインポートします。\n",
    "from sklearn.metrics import log_loss  # ログ損失を計算するための関数をインポートします。\n",
    "import tokenizers  # トークナイザー関連の機能を提供するライブラリ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfba4cae",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'\n",
    "MAX_LENGTH = 1284\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device(\"cuda\")    \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# メモリ効率の良い分散処理およびフラッシュ分散処理を無効にします。\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# GPUが利用可能であるか確認し、利用できない場合はメッセージを表示します。\n",
    "if (not torch.cuda.is_available()): \n",
    "    print(\"申し訳ありません - GPUが必要です！\")\n",
    "\n",
    "# モデル名、重みのパス、最大シーケンス長、バッチサイズ、デバイスの設定を定義します。\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのディレクトリ\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'  # モデルの重みが保存されているパス\n",
    "MAX_LENGTH = 1284  # 最大シーケンス長を1284に設定\n",
    "BATCH_SIZE = 8  # 訓練時に使用するバッチサイズを8に設定\n",
    "DEVICE = torch.device(\"cuda\")  # 使用するデバイスとしてGPUを指定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# メモリ効率の良い分散処理およびフラッシュ分散処理を無効にします。\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# GPUが利用可能であるか確認し、利用できない場合はメッセージを表示します。\n",
    "if (not torch.cuda.is_available()): \n",
    "    print(\"申し訳ありません - GPUが必要です！\")\n",
    "\n",
    "# モデル名、重みのパス、最大シーケンス長、バッチサイズ、デバイスの設定を定義します。\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのディレクトリ\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'  # モデルの重みが保存されているパス\n",
    "MAX_LENGTH = 1284  # 最大シーケンス長を1284に設定\n",
    "BATCH_SIZE = 8  # 訓練時に使用するバッチサイズを8に設定\n",
    "DEVICE = torch.device(\"cuda\")  # 使用するデバイスとしてGPUを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10026f77",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Prepare Data \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## データの準備\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92516a44",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータをCSVファイルから読み込みます。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータのデータフレームを作成\n",
    "# サンプルの提出ファイルをCSVファイルから読み込みます。\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # 提出サンプルデータのデータフレームを作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータをCSVファイルから読み込みます。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータのデータフレームを作成\n",
    "# サンプルの提出ファイルをCSVファイルから読み込みます。\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # 提出サンプルデータのデータフレームを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f95c95",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# concatenate strings in list\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "display(sample_sub)\n",
    "display(test.head(5))\n",
    "\n",
    "# Prepare text for model\n",
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + test['response_b']\n",
    "print(test['text'][0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 文字列のリストを連結するための関数を定義します。\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 最初と最後の角括弧を取り除く\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 各文を処理し、余分な引用符を取り除く\n",
    "    return ' '.join(sentences)  # 文を空白で結合して返す\n",
    "\n",
    "# テストデータの各カラムに対してprocess関数を適用します。\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # 'prompt'カラムを処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # 'response_a'カラムを処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # 'response_b'カラムを処理\n",
    "\n",
    "# サンプル提出データとテストデータの先頭5行を表示します。\n",
    "display(sample_sub)  # サンプル提出データを表示\n",
    "display(test.head(5))  # 処理後のテストデータの最初の5行を表示\n",
    "\n",
    "# モデル用にテキストを準備します。\n",
    "test['text'] = 'User prompt: ' + test['prompt'] + '\\n\\nModel A :\\n' + test['response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + test['response_b']\n",
    "# 処理されたテキストの最初の要素を出力します。\n",
    "print(test['text'][0])  # 最初のテキストを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文字列のリストを連結するための関数を定義します。\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 最初と最後の角括弧を取り除く\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 各文を処理し、余分な引用符を取り除く\n",
    "    return ' '.join(sentences)  # 文を空白で結合して返す\n",
    "\n",
    "# テストデータの各カラムに対してprocess関数を適用します。\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # 'prompt'カラムを処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # 'response_a'カラムを処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # 'response_b'カラムを処理\n",
    "\n",
    "# サンプル提出データとテストデータの先頭5行を表示します。\n",
    "display(sample_sub)  # サンプル提出データを表示\n",
    "display(test.head(5))  # 処理後のテストデータの最初の5行を表示\n",
    "\n",
    "# モデル用にテキストを準備します。\n",
    "test['text'] = 'User prompt: ' + test['prompt'] + '\\n\\nModel A :\\n' + test['response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + test['response_b']\n",
    "# 処理されたテキストの最初の要素を出力します。\n",
    "print(test['text'][0])  # 最初のテキストを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b1299",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイズ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2834da2a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# Move tensors to CPU and convert them to lists\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu\n",
    "data[:2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーを指定したパスから読み込みます。\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "# テキストデータをトークン化し、最大長さでパディングします。\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "# トークンの入力IDとアテンションマスクをデバイスに移動し、データ型をint32に設定します。\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# テンソルをCPUに移動し、リストに変換します。\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]  # 入力IDをリストに変換\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]  # アテンションマスクをリストに変換\n",
    "\n",
    "# 新しいデータフレームを作成し、INPUT_IDSとATTENTION_MASKSカラムを追加します。\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu  # 入力IDをDataFrameに追加\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu  # アテンションマスクをDataFrameに追加\n",
    "\n",
    "# 最初の2行を表示します。\n",
    "data[:2]  # データフレームの最初の2行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーを指定したパスから読み込みます。\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "# テキストデータをトークン化し、最大長さでパディングします。\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "# トークンの入力IDとアテンションマスクをデバイスに移動し、データ型をint32に設定します。\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# テンソルをCPUに移動し、リストに変換します。\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]  # 入力IDをリストに変換\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]  # アテンションマスクをリストに変換\n",
    "\n",
    "# 新しいデータフレームを作成し、INPUT_IDSとATTENTION_MASKSカラムを追加します。\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu  # 入力IDをDataFrameに追加\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu  # アテンションマスクをDataFrameに追加\n",
    "\n",
    "# 最初の2行を表示します。\n",
    "data[:2]  # データフレームの最初の2行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a416a6b0",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load model \n",
    "> We load 1 model on each gpu.  \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルの読み込み\n",
    "> 各GPUに1つのモデルを読み込みます。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0217f5b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# BitsAndBytes configuration\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False)\n",
    "\n",
    "# Load base model on GPU 0\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# BitsAndBytesの設定を行います。\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでモデルを読み込む設定\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 8ビット計算のデータ型をfloat16に設定\n",
    "    bnb_8bit_use_double_quant=False)  # ダブル量子化を使用しない設定\n",
    "\n",
    "# GPU 0にベースモデルを読み込みます。\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定で読み込みます。\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類タスクのラベル数を3に設定\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型をfloat16に設定\n",
    "    quantization_config=bnb_config,  # 量子化の設定を適用\n",
    "    device_map='cuda:0')  # モデルをGPU 0に割り当て\n",
    "\n",
    "# パディングトークンのIDをトークナイザーから取得し、モデルの設定に適用します。\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンのIDを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BitsAndBytesの設定を行います。\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでモデルを読み込む設定\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 8ビット計算のデータ型をfloat16に設定\n",
    "    bnb_8bit_use_double_quant=False)  # ダブル量子化を使用しない設定\n",
    "\n",
    "# GPU 0にベースモデルを読み込みます。\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定で読み込みます。\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類タスクのラベル数を3に設定\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型をfloat16に設定\n",
    "    quantization_config=bnb_config,  # 量子化の設定を適用\n",
    "    device_map='cuda:0')  # モデルをGPU 0に割り当て\n",
    "\n",
    "# パディングトークンのIDをトークナイザーから取得し、モデルの設定に適用します。\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンのIDを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47f550a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load base model on GPU 1\n",
    "device1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPU 1にベースモデルを読み込みます。\n",
    "device1 = torch.device('cuda:1')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定で読み込みます。\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類タスクのラベル数を3に設定\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型をfloat16に設定\n",
    "    quantization_config=bnb_config,  # 量子化の設定を適用\n",
    "    device_map='cuda:1')  # モデルをGPU 1に割り当て\n",
    "\n",
    "# パディングトークンのIDをトークナイザーから取得し、モデルの設定に適用します。\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンのIDを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 1にベースモデルを読み込みます。\n",
    "device1 = torch.device('cuda:1')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定で読み込みます。\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類タスクのラベル数を3に設定\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型をfloat16に設定\n",
    "    quantization_config=bnb_config,  # 量子化の設定を適用\n",
    "    device_map='cuda:1')  # モデルをGPU 1に割り当て\n",
    "\n",
    "# パディングトークンのIDをトークナイザーから取得し、モデルの設定に適用します。\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンのIDを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37549198",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load weights \n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 重みの読み込み\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd7b474",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# LoRa configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    inference_mode=True,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=['o_proj', 'v_proj'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoRaの設定を行います。\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # LoRaのランク\n",
    "    lora_alpha=32,  # LoRaのスケーリング係数\n",
    "    lora_dropout=0.10,  # ドロップアウト率\n",
    "    bias='none',  # バイアスの使用設定\n",
    "    inference_mode=True,  # 推論モードの設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクの種類をシーケンス分類に設定\n",
    "    target_modules=['o_proj', 'v_proj']  # 対象とするモジュール\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRaの設定を行います。\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # LoRaのランク\n",
    "    lora_alpha=32,  # LoRaのスケーリング係数\n",
    "    lora_dropout=0.10,  # ドロップアウト率\n",
    "    bias='none',  # バイアスの使用設定\n",
    "    inference_mode=True,  # 推論モードの設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクの種類をシーケンス分類に設定\n",
    "    target_modules=['o_proj', 'v_proj']  # 対象とするモジュール\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de6ff13",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Get peft\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0) \n",
    "#Load weights\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)\n",
    "model_0.eval()\n",
    "\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)\n",
    "model_1.eval()\n",
    "\n",
    "#Trainable Parameters\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# PEFTモデルを取得し、GPU 0に移動します。\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0) \n",
    "# 重みを読み込みます。\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # モデルに重みを適用\n",
    "model_0.eval()  # 評価モードに設定\n",
    "\n",
    "# GPU 1に対して同様の処理を行います。\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # モデルに重みを適用\n",
    "model_1.eval()  # 評価モードに設定\n",
    "\n",
    "# 学習可能なパラメータを表示します。\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()  # 各モデルの学習可能なパラメータを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEFTモデルを取得し、GPU 0に移動します。\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0) \n",
    "# 重みを読み込みます。\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # モデルに重みを適用\n",
    "model_0.eval()  # 評価モードに設定\n",
    "\n",
    "# GPU 1に対して同様の処理を行います。\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # モデルに重みを適用\n",
    "model_1.eval()  # 評価モードに設定\n",
    "\n",
    "# 学習可能なパラメータを表示します。\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()  # 各モデルの学習可能なパラメータを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32854376",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ガベージコレクションを実行して、メモリを解放します。\n",
    "gc.collect()  # 未使用のメモリを整理して、システムの効率を向上させるために呼び出します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ガベージコレクションを実行して、メモリを解放します。\n",
    "gc.collect()  # 未使用のメモリを整理して、システムの効率を向上させるために呼び出します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d207e51",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Inference\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 推論\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc16bc5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    generated_class_a = []\n",
    "    generated_class_b = []\n",
    "    generated_class_c = []\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask\n",
    "                )\n",
    "        \n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        generated_class_a.extend(probabilities[:, 0])\n",
    "        generated_class_b.extend(probabilities[:, 1])\n",
    "        generated_class_c.extend(probabilities[:, 2])\n",
    "    \n",
    "    df['winner_model_a'] = generated_class_a\n",
    "    df['winner_model_b'] = generated_class_b\n",
    "    df['winner_tie'] = generated_class_c\n",
    "\n",
    "    torch.cuda.empty_cache()  \n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行う関数を定義します。\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    # DataFrameから入力IDとアテンションマスクをテンソルとして取得します。\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    # 各クラスの生成結果を保持するリストを初期化します。\n",
    "    generated_class_a = []  # モデルAの結果を格納\n",
    "    generated_class_b = []  # モデルBの結果を格納\n",
    "    generated_class_c = []  # 引き分けの結果を格納\n",
    "\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    \n",
    "    # バッチ処理でデータを処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終わりを計算\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # バッチの入力IDをデバイスに転送\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # バッチのアテンションマスクをデバイスに転送\n",
    "        \n",
    "        with torch.no_grad():  # 勾配計算を無効にします。\n",
    "            with autocast():  # 自動混合精度を使用して計算を行います。\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,  # バッチの入力IDをモデルに渡す\n",
    "                    attention_mask=batch_attention_mask  # バッチのアテンションマスクをモデルに渡す\n",
    "                )\n",
    "        \n",
    "        # モデルの出力をソフトマックス関数を用いて確率に変換します。\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        # 各クラスの確率をリストに追加します。\n",
    "        generated_class_a.extend(probabilities[:, 0])  # クラスAの確率を拡張\n",
    "        generated_class_b.extend(probabilities[:, 1])  # クラスBの確率を拡張\n",
    "        generated_class_c.extend(probabilities[:, 2])  # 引き分けの確率を拡張\n",
    "    \n",
    "    # DataFrameに生成した結果を追加します。\n",
    "    df['winner_model_a'] = generated_class_a  # モデルAの勝者確率を追加\n",
    "    df['winner_model_b'] = generated_class_b  # モデルBの勝者確率を追加\n",
    "    df['winner_tie'] = generated_class_c  # 引き分け確率を追加\n",
    "\n",
    "    torch.cuda.empty_cache()  # GPUのキャッシュをクリアしてメモリを解放\n",
    "\n",
    "    return df  # 結果を含むDataFrameを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論を行う関数を定義します。\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    # DataFrameから入力IDとアテンションマスクをテンソルとして取得します。\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    # 各クラスの生成結果を保持するリストを初期化します。\n",
    "    generated_class_a = []  # モデルAの結果を格納\n",
    "    generated_class_b = []  # モデルBの結果を格納\n",
    "    generated_class_c = []  # 引き分けの結果を格納\n",
    "\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    \n",
    "    # バッチ処理でデータを処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終わりを計算\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # バッチの入力IDをデバイスに転送\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # バッチのアテンションマスクをデバイスに転送\n",
    "        \n",
    "        with torch.no_grad():  # 勾配計算を無効にします。\n",
    "            with autocast():  # 自動混合精度を使用して計算を行います。\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,  # バッチの入力IDをモデルに渡す\n",
    "                    attention_mask=batch_attention_mask  # バッチのアテンションマスクをモデルに渡す\n",
    "                )\n",
    "        \n",
    "        # モデルの出力をソフトマックス関数を用いて確率に変換します。\n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        # 各クラスの確率をリストに追加します。\n",
    "        generated_class_a.extend(probabilities[:, 0])  # クラスAの確率を拡張\n",
    "        generated_class_b.extend(probabilities[:, 1])  # クラスBの確率を拡張\n",
    "        generated_class_c.extend(probabilities[:, 2])  # 引き分けの確率を拡張\n",
    "    \n",
    "    # DataFrameに生成した結果を追加します。\n",
    "    df['winner_model_a'] = generated_class_a  # モデルAの勝者確率を追加\n",
    "    df['winner_model_b'] = generated_class_b  # モデルBの勝者確率を追加\n",
    "    df['winner_tie'] = generated_class_c  # 引き分け確率を追加\n",
    "\n",
    "    torch.cuda.empty_cache()  # GPUのキャッシュをクリアしてメモリを解放\n",
    "\n",
    "    return df  # 結果を含むDataFrameを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c6160",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "N_SAMPLES = len(data)\n",
    "\n",
    "# Split the data into two subsets\n",
    "half = round(N_SAMPLES / 2)\n",
    "sub1 = data.iloc[0:half].copy()\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()\n",
    "\n",
    "# Function to run inference in a thread\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)\n",
    "\n",
    "# Dictionary to store results from threads\n",
    "results = {}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 時間計測を開始します。\n",
    "st = time.time()\n",
    "\n",
    "# データのサンプル数を取得します。\n",
    "N_SAMPLES = len(data)\n",
    "\n",
    "# データを2つのサブセットに分割します。\n",
    "half = round(N_SAMPLES / 2)  # サンプル数の半分を計算\n",
    "sub1 = data.iloc[0:half].copy()  # 最初の半分のデータをコピー\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 残りのデータをコピー\n",
    "\n",
    "# スレッドで推論を実行するための関数を定義します。\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)  # 指定したインデックスに推論結果を保存\n",
    "\n",
    "# スレッドからの結果を格納するための辞書を初期化します。\n",
    "results = {}  # 結果を格納する空の辞書を作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 時間計測を開始します。\n",
    "st = time.time()\n",
    "\n",
    "# データのサンプル数を取得します。\n",
    "N_SAMPLES = len(data)\n",
    "\n",
    "# データを2つのサブセットに分割します。\n",
    "half = round(N_SAMPLES / 2)  # サンプル数の半分を計算\n",
    "sub1 = data.iloc[0:half].copy()  # 最初の半分のデータをコピー\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 残りのデータをコピー\n",
    "\n",
    "# スレッドで推論を実行するための関数を定義します。\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)  # 指定したインデックスに推論結果を保存\n",
    "\n",
    "# スレッドからの結果を格納するための辞書を初期化します。\n",
    "results = {}  # 結果を格納する空の辞書を作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be810dd5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# start threads\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))\n",
    "\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# Combine results back into the original DataFrame\n",
    "data = pd.concat([results[0], results[1]], axis=0)\n",
    "\n",
    "print(f\"Processing complete. Total time: {time.time() - st}\")\n",
    "\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "sample_sub[TARGETS] = data[TARGETS]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# スレッドを開始します。\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # スレッド0を初期化\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # スレッド1を初期化\n",
    "\n",
    "t0.start()  # スレッド0を開始\n",
    "t1.start()  # スレッド1を開始\n",
    "\n",
    "# すべてのスレッドが終了するのを待ちます。\n",
    "t0.join()  # スレッド0の終了を待機\n",
    "t1.join()  # スレッド1の終了を待機\n",
    "\n",
    "# 結果を元のDataFrameに結合します。\n",
    "data = pd.concat([results[0], results[1]], axis=0)  # 2つの結果を縦に結合\n",
    "\n",
    "# 処理が完了したことを表示し、所要時間を出力します。\n",
    "print(f\"処理が完了しました。総時間: {time.time() - st}\")\n",
    "\n",
    "# ターゲットとするカラムをリスト化します。\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# サンプル提出データに推論結果を追加します。\n",
    "sample_sub[TARGETS] = data[TARGETS]  # ターゲットの結果を提出サンプルに追加\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スレッドを開始します。\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # スレッド0を初期化\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # スレッド1を初期化\n",
    "\n",
    "t0.start()  # スレッド0を開始\n",
    "t1.start()  # スレッド1を開始\n",
    "\n",
    "# すべてのスレッドが終了するのを待ちます。\n",
    "t0.join()  # スレッド0の終了を待機\n",
    "t1.join()  # スレッド1の終了を待機\n",
    "\n",
    "# 結果を元のDataFrameに結合します。\n",
    "data = pd.concat([results[0], results[1]], axis=0)  # 2つの結果を縦に結合\n",
    "\n",
    "# 処理が完了したことを表示し、所要時間を出力します。\n",
    "print(f\"処理が完了しました。総時間: {time.time() - st}\")\n",
    "\n",
    "# ターゲットとするカラムをリスト化します。\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# サンプル提出データに推論結果を追加します。\n",
    "sample_sub[TARGETS] = data[TARGETS]  # ターゲットの結果を提出サンプルに追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f6a109",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "llama_preds = data[TARGETS].values\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ターゲットカラムから予測結果を抽出し、NumPy配列に変換します。\n",
    "llama_preds = data[TARGETS].values  # 推論結果をNumPy配列として取得\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T07:00:50.825959Z",
     "iopub.status.busy": "2024-05-30T07:00:50.825683Z",
     "iopub.status.idle": "2024-05-30T07:00:50.831376Z"
    }
   },
   "outputs": [],
   "source": [
    "# ターゲットカラムから予測結果を抽出し、NumPy配列に変換します。\n",
    "llama_preds = data[TARGETS].values  # 推論結果をNumPy配列として取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73351e19",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## LGBM + tfidf\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## LGBM + TF-IDF\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e12878",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os\n",
    "RUNPOD = os.path.exists('/workspace/')\n",
    "KAGGLE = not RUNPOD\n",
    "if KAGGLE: print('kaggle')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# コンペティションのタグを設定します。\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "\n",
    "# 実行環境がRUNPODかどうかをチェックします。\n",
    "RUNPOD = os.path.exists('/workspace/')  # '/workspace/'が存在するか確認\n",
    "KAGGLE = not RUNPOD  # RUNPODでない場合はKAGGLE環境とする\n",
    "if KAGGLE: \n",
    "    print('kaggle')  # KAGGLE環境であればメッセージを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T07:00:50.832861Z",
     "iopub.status.busy": "2024-05-30T07:00:50.832506Z",
     "iopub.status.idle": "2024-05-30T07:00:50.853311Z"
    }
   },
   "outputs": [],
   "source": [
    "# コンペティションのタグを設定します。\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "\n",
    "# 実行環境がRUNPODかどうかをチェックします。\n",
    "RUNPOD = os.path.exists('/workspace/')  # '/workspace/'が存在するか確認\n",
    "KAGGLE = not RUNPOD  # RUNPODでない場合はKAGGLE環境とする\n",
    "if KAGGLE: \n",
    "    print('kaggle')  # KAGGLE環境であればメッセージを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6052bf5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    !pip install -q kaggle\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm \n",
    "    !pip install -q protobuf \n",
    "    !pip install -q numba\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# pandasをインポートしてみます。\n",
    "try:\n",
    "    import pandas as pd  # pandasをインポート\n",
    "except:  # インポートに失敗した場合\n",
    "    # Kaggle APIと必要なライブラリをインストールします。\n",
    "    !pip install -q kaggle  # Kaggle APIをインストール\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理ライブラリをインストール\n",
    "    !pip install -q protobuf  # protobufライブラリをインストール\n",
    "    !pip install -q numba  # numbaライブラリをインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T07:00:50.854384Z",
     "iopub.status.busy": "2024-05-30T07:00:50.854159Z",
     "iopub.status.idle": "2024-05-30T07:00:50.86715Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandasをインポートしてみます。\n",
    "try:\n",
    "    import pandas as pd  # pandasをインポート\n",
    "except:  # インポートに失敗した場合\n",
    "    # Kaggle APIと必要なライブラリをインストールします。\n",
    "    !pip install -q kaggle  # Kaggle APIをインストール\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理ライブラリをインストール\n",
    "    !pip install -q protobuf  # protobufライブラリをインストール\n",
    "    !pip install -q numba  # numbaライブラリをインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6c481",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)\n",
    "\n",
    "import os\n",
    "\n",
    "if RUNPOD:\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json\n",
    "        !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/ \n",
    "        \n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')    \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データのパスを設定します。\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)  # 環境に応じてデータのパスを決定\n",
    "\n",
    "import os  # osモジュールを再度インポートします。\n",
    "\n",
    "# 実行環境がRUNPODの場合の処理\n",
    "if RUNPOD:\n",
    "    # Kaggle認証ファイルが存在しない場合\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # .kaggleディレクトリを作成\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # kaggle.jsonをコピー\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # 権限を設定\n",
    "    \n",
    "    # コンペティションのZIPファイルが存在しない場合\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleからデータをダウンロード\n",
    "        \n",
    "    # データを格納するディレクトリが存在しない場合\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile  # zipファイル処理用のライブラリをインポート\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍してデータを/data/に展開\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T07:00:50.86901Z",
     "iopub.status.busy": "2024-05-30T07:00:50.86863Z",
     "iopub.status.idle": "2024-05-30T07:00:50.88384Z"
    }
   },
   "outputs": [],
   "source": [
    "# データのパスを設定します。\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)  # 環境に応じてデータのパスを決定\n",
    "\n",
    "import os  # osモジュールを再度インポートします。\n",
    "\n",
    "# 実行環境がRUNPODの場合の処理\n",
    "if RUNPOD:\n",
    "    # Kaggle認証ファイルが存在しない場合\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # .kaggleディレクトリを作成\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # kaggle.jsonをコピー\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # 権限を設定\n",
    "    \n",
    "    # コンペティションのZIPファイルが存在しない場合\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleからデータをダウンロード\n",
    "        \n",
    "    # データを格納するディレクトリが存在しない場合\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile  # zipファイル処理用のライブラリをインポート\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍してデータを/data/に展開"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8106fa5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "INPUT_PATH = '/kaggle/input/'  \n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "# MODEL_PATH = MODEL_PATH if not KAGGLE else ''#MODEL_PATH + os.listdir(MODEL_PATH)[0] + '/'\n",
    "print(MODEL_PATH)\n",
    "\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 入力、モデル、ログ用のパスを設定します。\n",
    "INPUT_PATH = '/kaggle/input/'  # Kaggleの入力データパス\n",
    "MODEL_PATH = '/workspace/models/'  # モデル保存用のパス\n",
    "LOGITS_PATH = '/workspace/logits/'  # ログ保存用のパス\n",
    "\n",
    "# モデルパスをKAGGLE環境に応じて設定します。\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'  # 'lsys-models'を含むディレクトリを見つけてそのパスを設定\n",
    "\n",
    "# MODEL_PATHを表示します。\n",
    "print(MODEL_PATH)\n",
    "\n",
    "# コードのパスを設定します。KAGGLE環境によって異なります。\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'  # コードパス\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''  # 保存パス\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力、モデル、ログ用のパスを設定します。\n",
    "INPUT_PATH = '/kaggle/input/'  # Kaggleの入力データパス\n",
    "MODEL_PATH = '/workspace/models/'  # モデル保存用のパス\n",
    "LOGITS_PATH = '/workspace/logits/'  # ログ保存用のパス\n",
    "\n",
    "# モデルパスをKAGGLE環境に応じて設定します。\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'  # 'lsys-models'を含むディレクトリを見つけてそのパスを設定\n",
    "\n",
    "# MODEL_PATHを表示します。\n",
    "print(MODEL_PATH)\n",
    "\n",
    "# コードのパスを設定します。KAGGLE環境によって異なります。\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'  # コードパス\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''  # 保存パス"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff343597",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーの並列処理を無効にします。\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # 複数のトークナイザーの並列処理を無効にして、競合を防ぎます。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トークナイザーの並列処理を無効にします。\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'  # 複数のトークナイザーの並列処理を無効にして、競合を防ぎます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327a3fe4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')\n",
    "\n",
    "print(len(train), len(test))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 訓練データ、テストデータ、サンプル提出ファイルをCSVから読み込みます。\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # 訓練データを読み込み\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))  # テストデータを読み込み\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込み\n",
    "\n",
    "# 訓練データとテストデータのサンプル数を表示します。\n",
    "print(len(train), len(test))  # 訓練データとテストデータの行数を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練データ、テストデータ、サンプル提出ファイルをCSVから読み込みます。\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # 訓練データを読み込み\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))  # テストデータを読み込み\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込み\n",
    "\n",
    "# 訓練データとテストデータのサンプル数を表示します。\n",
    "print(len(train), len(test))  # 訓練データとテストデータの行数を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca562617",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "params = {}\n",
    "if False:#len(test) < 10: \n",
    "    pass;\n",
    "    params['subsample'] = 30\n",
    "else:\n",
    "    # params['subsample'] = 2\n",
    "    params['fold'] = -1\n",
    "\n",
    "\n",
    "params['n_epochs'] = 1\n",
    "params['n_lgb'] = 1\n",
    "params['model'] = 'microsoft/deberta-v3-small'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# パラメータの辞書を初期化します。\n",
    "params = {}\n",
    "if False:#len(test) < 10: \n",
    "    pass;  # 条件がFalseの場合は何もしない\n",
    "    params['subsample'] = 30  # サブサンプル数を30に設定\n",
    "else:\n",
    "    # サブサンプル数を設定しない\n",
    "    params['fold'] = -1  # フォールドの設定を-1にする\n",
    "\n",
    "# その他のモデルに関するパラメータを設定します。\n",
    "params['n_epochs'] = 1  # エポック数を1に設定\n",
    "params['n_lgb'] = 1  # LightGBMのモデル数を1に設定\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルをDeBERTaに設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータの辞書を初期化します。\n",
    "params = {}\n",
    "if False:#len(test) < 10: \n",
    "    pass;  # 条件がFalseの場合は何もしない\n",
    "    params['subsample'] = 30  # サブサンプル数を30に設定\n",
    "else:\n",
    "    # サブサンプル数を設定しない\n",
    "    params['fold'] = -1  # フォールドの設定を-1にする\n",
    "\n",
    "# その他のモデルに関するパラメータを設定します。\n",
    "params['n_epochs'] = 1  # エポック数を1に設定\n",
    "params['n_lgb'] = 1  # LightGBMのモデル数を1に設定\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルをDeBERTaに設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8891aa53",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# params = {}\n",
    "FULL = params.get('fold', 0) < 0\n",
    "N_FOLDS = int(params.get('n_folds', 3)); \n",
    "FOLD = int(params.get('fold', 0))\n",
    "SEED = int(params.get('seed', 3))\n",
    "SS = int(params.get('subsample', 1))\n",
    "\n",
    "print(N_FOLDS, FOLD, SEED, SS)\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# フォールド数、シード値、サブサンプルサイズを設定します。\n",
    "FULL = params.get('fold', 0) < 0  # フォールドが-1未満の場合はFULLをTrueに設定\n",
    "N_FOLDS = int(params.get('n_folds', 3))  # フォールドの数を取得、デフォルトは3\n",
    "FOLD = int(params.get('fold', 0))  # 現在のフォールドを取得、デフォルトは0\n",
    "SEED = int(params.get('seed', 3))  # シードの値を取得、デフォルトは3\n",
    "SS = int(params.get('subsample', 1))  # サブサンプル数を取得、デフォルトは1\n",
    "\n",
    "# 設定されたフォールド数、現在のフォールド、シード、サブサンプルサイズを表示します。\n",
    "print(N_FOLDS, FOLD, SEED, SS)  # 各設定値を出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# フォールド数、シード値、サブサンプルサイズを設定します。\n",
    "FULL = params.get('fold', 0) < 0  # フォールドが-1未満の場合はFULLをTrueに設定\n",
    "N_FOLDS = int(params.get('n_folds', 3))  # フォールドの数を取得、デフォルトは3\n",
    "FOLD = int(params.get('fold', 0))  # 現在のフォールドを取得、デフォルトは0\n",
    "SEED = int(params.get('seed', 3))  # シードの値を取得、デフォルトは3\n",
    "SS = int(params.get('subsample', 1))  # サブサンプル数を取得、デフォルトは1\n",
    "\n",
    "# 設定されたフォールド数、現在のフォールド、シード、サブサンプルサイズを表示します。\n",
    "print(N_FOLDS, FOLD, SEED, SS)  # 各設定値を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9127f7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state = SEED, shuffle = True)\\\n",
    "                    .split(X = np.zeros(len(train)), y = train.iloc[:, -3:].idxmax(1)))\n",
    "\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "if SS > 1: train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "print(len(train_ids), len(test_ids));  assert set(train_ids) & set(test_ids) == set() \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldをインポート\n",
    "\n",
    "# フォールドを取得するための関数を定義します。\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)  # StratifiedKFoldを使用してフォールドを生成\n",
    "                .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # ラベルのインデックスを用いて分割\n",
    "\n",
    "# 現在のフォールドに応じて訓練データとテストデータのIDを取得します。\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# サブサンプル数が1より大きい場合、IDをサブサンプリングします。\n",
    "if SS > 1: \n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# 訓練データとテストデータのIDの数を表示し、重複していないことを確認します。\n",
    "print(len(train_ids), len(test_ids))  # 訓練IDとテストIDの数を表示\n",
    "assert set(train_ids) & set(test_ids) == set()  # 訓練とテストIDに重複がないことを確認\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldをインポート\n",
    "\n",
    "# フォールドを取得するための関数を定義します。\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)  # StratifiedKFoldを使用してフォールドを生成\n",
    "                .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # ラベルのインデックスを用いて分割\n",
    "\n",
    "# 現在のフォールドに応じて訓練データとテストデータのIDを取得します。\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# サブサンプル数が1より大きい場合、IDをサブサンプリングします。\n",
    "if SS > 1: \n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# 訓練データとテストデータのIDの数を表示し、重複していないことを確認します。\n",
    "print(len(train_ids), len(test_ids))  # 訓練IDとテストIDの数を表示\n",
    "assert set(train_ids) & set(test_ids) == set()  # 訓練とテストIDに重複がないことを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6f380e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def join_strings(x, ):\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x\n",
    "    return x\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# リスト内の文字列を結合するための関数を定義します。\n",
    "def join_strings(x):\n",
    "    # xがリストである場合、要素を結合します。Noneの場合は空文字に置き換えます。\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x  # リストをスペースで結合\n",
    "    return x  # 結合した文字列を返します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト内の文字列を結合するための関数を定義します。\n",
    "def join_strings(x):\n",
    "    # xがリストである場合、要素を結合します。Noneの場合は空文字に置き換えます。\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x  # リストをスペースで結合\n",
    "    return x  # 結合した文字列を返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c3938e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def len_join_strings(x, ):\n",
    "    return len(join_strings(x).split())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結合された文字列の長さを返す関数を定義します。\n",
    "def len_join_strings(x):\n",
    "    # join_strings関数を使用して文字列を結合し、その結果をスペースで分割して単語数を返します。\n",
    "    return len(join_strings(x).split())  # 結合した文字列の単語数を返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結合された文字列の長さを返す関数を定義します。\n",
    "def len_join_strings(x):\n",
    "    # join_strings関数を使用して文字列を結合し、その結果をスペースで分割して単語数を返します。\n",
    "    return len(join_strings(x).split())  # 結合した文字列の単語数を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2066b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def len_join_strings_j(x):\n",
    "    x = json.loads(x)\n",
    "    return len_join_strings(x)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# JSON形式の文字列を解析し、結合された文字列の長さを返す関数を定義します。\n",
    "def len_join_strings_j(x):\n",
    "    x = json.loads(x)  # JSON文字列をPythonオブジェクトに変換\n",
    "    return len_join_strings(x)  # 結合された文字列の長さを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON形式の文字列を解析し、結合された文字列の長さを返す関数を定義します。\n",
    "def len_join_strings_j(x):\n",
    "    x = json.loads(x)  # JSON文字列をPythonオブジェクトに変換\n",
    "    return len_join_strings(x)  # 結合された文字列の長さを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fede84",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)\n",
    "random.seed(datetime.datetime.now().microsecond)\n",
    "np.random.seed(datetime.datetime.now().microsecond)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# シードを設定して再現性を確保します。\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シードを設定して再現性を確保します。\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eaad657",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# TRAIN = True and not KAGGLE\n",
    "TRAIN = False\n",
    "INFER = True # or KAGGLE \n",
    "SAVE = False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 学習モードや推論モード、保存モードを設定します。\n",
    "# TRAINはTrueかつKAGGLEでない場合に学習を行うかを示します。\n",
    "TRAIN = False  # 学習を行うかどうかを設定（現在はFalse）\n",
    "INFER = True  # 推論を行うかどうかを設定（現在はTrue、KAGGLE環境でも使用可能）\n",
    "SAVE = False  # モデルや結果を保存するかどうかを設定（現在はFalse）\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モードや推論モード、保存モードを設定します。\n",
    "# TRAINはTrueかつKAGGLEでない場合に学習を行うかを示します。\n",
    "TRAIN = False  # 学習を行うかどうかを設定（現在はFalse）\n",
    "INFER = True  # 推論を行うかどうかを設定（現在はTrue、KAGGLE環境でも使用可能）\n",
    "SAVE = False  # モデルや結果を保存するかどうかを設定（現在はFalse）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b9793",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMとカウントベクトライザーをインポートします。\n",
    "import lightgbm as lgb  # LightGBMライブラリをインポート\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータの特徴量抽出に使用するカウントベクトライザーをインポート\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMとカウントベクトライザーをインポートします。\n",
    "import lightgbm as lgb  # LightGBMライブラリをインポート\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータの特徴量抽出に使用するカウントベクトライザーをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b8d3a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "LGB = True\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0\n",
    "INFER_LGB = not TRAIN and LGB\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMを使用するかどうかを設定します。\n",
    "LGB = True  # LightGBMを使用するかどうかのフラグを設定\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # 学習モードでLightGBMを使用するかのフラグ\n",
    "INFER_LGB = not TRAIN and LGB  # 学習していない場合にLightGBMによる推論を行うかのフラグ\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMを使用するかどうかを設定します。\n",
    "LGB = True  # LightGBMを使用するかどうかのフラグを設定\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # 学習モードでLightGBMを使用するかのフラグ\n",
    "INFER_LGB = not TRAIN and LGB  # 学習していない場合にLightGBMによる推論を行うかのフラグ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad13bd5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 事前に保存したカウントベクトライザーを読み込みます。\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # cvecモデルを読み込む\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # ccvecモデルを読み込む\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前に保存したカウントベクトライザーを読み込みます。\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # cvecモデルを読み込む\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # ccvecモデルを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6dc0d0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def symlog(x): return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)\n",
    "\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())\n",
    "    x = symlog(x)\n",
    "    return x\n",
    "\n",
    "def get_features(df):\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    v = np.hstack([\n",
    "    # pfeat, \n",
    "          afeat - bfeat, np.abs(afeat - bfeat), \n",
    "    # afeat + bfeat\n",
    "        ])\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)\n",
    "    except: pass\n",
    "\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)\n",
    "            \n",
    "    extras.append(df[c].str.len())\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))\n",
    "    \n",
    "    extras = np.stack(extras, axis = 1)\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])\n",
    "    return np.hstack([v, extras])\n",
    "    # return v\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# シンメトリック対数変換を行う関数を定義します。\n",
    "def symlog(x): \n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # 対数変換と符号付き変換を行う\n",
    "\n",
    "# 密な行列を変換する関数を定義します。\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 行列を密な形式に変換し、float32型にする\n",
    "    x = symlog(x)  # シンメトリック対数変換を適用\n",
    "    return x  # 変換した値を返す\n",
    "\n",
    "# 特徴量を取得するための関数を定義します。\n",
    "def get_features(df):\n",
    "    # プロンプトに対する特徴を取得\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])  # cvecとccvecを用いてtransform\n",
    "\n",
    "    # モデルAに対する特徴を取得\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ] \n",
    "                    for v in [cvec, ccvec]\n",
    "                ])  # response_aに対してtransform\n",
    "\n",
    "    # モデルBに対する特徴を取得\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ] \n",
    "                    for v in [cvec, ccvec]\n",
    "                ])  # response_bに対してtransform\n",
    "    \n",
    "    # 特徴量を計算\n",
    "    v = np.hstack([\n",
    "    # pfeat, \n",
    "          afeat - bfeat, np.abs(afeat - bfeat), \n",
    "    # afeat + bfeat\n",
    "        ])\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)  # 投票モデルが存在する場合、特徴量を正規化\n",
    "    except: \n",
    "        pass  # エラーが発生しても何もしない\n",
    "\n",
    "    # 追加の特徴量を計算\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']  # 確認したい追加の文字列\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # それぞれのカラムで指定した文字列の出現回数をカウント\n",
    "            \n",
    "    extras.append(df[c].str.len())  # 各カラムの文字列長を追加\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 各カラムの単語数を取得及び追加\n",
    "    \n",
    "    extras = np.stack(extras, axis=1)  # 追加特徴量をスタック\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # 特徴量を根号と対数変換\n",
    "\n",
    "    return np.hstack([v, extras])  # すべての特徴量を結合して返す\n",
    "    # return v  # vだけを返す選択肢もある\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンメトリック対数変換を行う関数を定義します。\n",
    "def symlog(x): \n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # 対数変換と符号付き変換を行う\n",
    "\n",
    "# 密な行列を変換する関数を定義します。\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 行列を密な形式に変換し、float32型にする\n",
    "    x = symlog(x)  # シンメトリック対数変換を適用\n",
    "    return x  # 変換した値を返す\n",
    "\n",
    "# 特徴量を取得するための関数を定義します。\n",
    "def get_features(df):\n",
    "    # プロンプトに対する特徴を取得\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])  # cvecとccvecを用いてtransform\n",
    "\n",
    "    # モデルAに対する特徴を取得\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ] \n",
    "                    for v in [cvec, ccvec]\n",
    "                ])  # response_aに対してtransform\n",
    "\n",
    "    # モデルBに対する特徴を取得\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ] \n",
    "                    for v in [cvec, ccvec]\n",
    "                ])  # response_bに対してtransform\n",
    "    \n",
    "    # 特徴量を計算\n",
    "    v = np.hstack([\n",
    "    # pfeat, \n",
    "          afeat - bfeat, np.abs(afeat - bfeat), \n",
    "    # afeat + bfeat\n",
    "        ])\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)  # 投票モデルが存在する場合、特徴量を正規化\n",
    "    except: \n",
    "        pass  # エラーが発生しても何もしない\n",
    "\n",
    "    # 追加の特徴量を計算\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']  # 確認したい追加の文字列\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # それぞれのカラムで指定した文字列の出現回数をカウント\n",
    "            \n",
    "    extras.append(df[c].str.len())  # 各カラムの文字列長を追加\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 各カラムの単語数を取得及び追加\n",
    "    \n",
    "    extras = np.stack(extras, axis=1)  # 追加特徴量をスタック\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # 特徴量を根号と対数変換\n",
    "\n",
    "    return np.hstack([v, extras])  # すべての特徴量を結合して返す\n",
    "    # return v  # vだけを返す選択肢もある"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f30946",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 事前に保存したLightGBMモデルを読み込みます。\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込む\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 事前に保存したLightGBMモデルを読み込みます。\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd268c5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test\n",
    "    yps = []; b = 1000\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])\n",
    "        ypms = []\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))\n",
    "        yps.append(np.stack(ypms).mean(0))\n",
    "        # break;\n",
    "        print('.', end = '')\n",
    "        \n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()\n",
    "    print()\n",
    "\n",
    "    yp = np.concatenate(yps)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行うための処理を実行します。\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータをdfに設定\n",
    "    yps = []  # モデルの予測結果を格納するリストを初期化\n",
    "    b = 1000  # バッチサイズを設定\n",
    "    \n",
    "    # テストデータをバッチ処理で繰り返す\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得\n",
    "        ypms = []  # 個々のモデルの予測結果を格納するリストを初期化\n",
    "        \n",
    "        # 各LightGBMモデルについて推論を実施\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))  # 各モデルの予測確率を追加\n",
    "        \n",
    "        # 平均を取った確率をypsに追加\n",
    "        yps.append(np.stack(ypms).mean(0))  # 各モデルの予測をスタックし、平均を計算\n",
    "        # break;  # デバッグのためにループを中断する行（コメントアウト）\n",
    "\n",
    "        print('.', end='')  # 進行状況の表示\n",
    "        \n",
    "        # ypsの長さが偶数のときにガベージコレクションを実行\n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()  # メモリを整理\n",
    "    print()  # 改行\n",
    "\n",
    "    # すべての予測結果を結合\n",
    "    yp = np.concatenate(yps)  # 予測確率を一つの配列に結合\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論を行うための処理を実行します。\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータをdfに設定\n",
    "    yps = []  # モデルの予測結果を格納するリストを初期化\n",
    "    b = 1000  # バッチサイズを設定\n",
    "    \n",
    "    # テストデータをバッチ処理で繰り返す\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得\n",
    "        ypms = []  # 個々のモデルの予測結果を格納するリストを初期化\n",
    "        \n",
    "        # 各LightGBMモデルについて推論を実施\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))  # 各モデルの予測確率を追加\n",
    "        \n",
    "        # 平均を取った確率をypsに追加\n",
    "        yps.append(np.stack(ypms).mean(0))  # 各モデルの予測をスタックし、平均を計算\n",
    "        # break;  # デバッグのためにループを中断する行（コメントアウト）\n",
    "\n",
    "        print('.', end='')  # 進行状況の表示\n",
    "        \n",
    "        # ypsの長さが偶数のときにガベージコレクションを実行\n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()  # メモリを整理\n",
    "    print()  # 改行\n",
    "\n",
    "    # すべての予測結果を結合\n",
    "    yp = np.concatenate(yps)  # 予測確率を一つの配列に結合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435e772e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_preds = yp\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMモデルからの予測結果をlgb_predsに格納します。\n",
    "lgb_preds = yp  # 推論結果をlgb_predsに設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMモデルからの予測結果をlgb_predsに格納します。\n",
    "lgb_preds = yp  # 推論結果をlgb_predsに設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2480b6cc",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Blend predictions\n",
    "\n",
    "$\\operatorname{preds} = 0.2 \\cdot \\operatorname{lgbm boosting preds} + 0.8 \\cdot \\operatorname{llama preds}$\n",
    "\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 予測のブレンド\n",
    "\n",
    "$\\operatorname{preds} = 0.2 \\cdot \\operatorname{LGBMブースティング予測} + 0.8 \\cdot \\operatorname{ラマ予測}$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580686c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_wt = 0.2 \n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LGBMモデルとラマモデルの予測をブレンドします。\n",
    "lgb_wt = 0.2  # LGBMモデルの重みを設定\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # ブレンドした予測結果を計算\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBMモデルとラマモデルの予測をブレンドします。\n",
    "lgb_wt = 0.2  # LGBMモデルの重みを設定\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # ブレンドした予測結果を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab447c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out = pd.DataFrame(preds, \n",
    "                index = df.id, \n",
    "                    columns = train.columns[-3:])\n",
    "display(out.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ブレンドした予測結果をデータフレームに変換します。\n",
    "out = pd.DataFrame(preds, \n",
    "                index=df.id,  # データフレームのインデックスとしてIDを設定\n",
    "                columns=train.columns[-3:])  # カラム名として訓練データの最後の3カラムを設定\n",
    "display(out.head())  # データフレームの先頭5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブレンドした予測結果をデータフレームに変換します。\n",
    "out = pd.DataFrame(preds, \n",
    "                index=df.id,  # データフレームのインデックスとしてIDを設定\n",
    "                columns=train.columns[-3:])  # カラム名として訓練データの最後の3カラムを設定\n",
    "display(out.head())  # データフレームの先頭5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afba8a56",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out.to_csv('submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測結果をCSVファイルとして保存します。\n",
    "out.to_csv('submission.csv')  # 予測結果を'submission.csv'という名前で保存\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測結果をCSVファイルとして保存します。\n",
    "out.to_csv('submission.csv')  # 予測結果を'submission.csv'という名前で保存"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4946449,
     "sourceId": 8330401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5034873,
     "sourceId": 8449074,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
