{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6bfa34a",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このノートブックは、LMSYS - Chatbot Arenaコンペティションにおける人間による好み予測のためのDeberta-v3 xsmallモデルを使用したスターターコードです。以下に、取り組んでいる問題や使用している手法、ライブラリについての要約を示します。\n",
    "\n",
    "### 問題\n",
    "このノートブックでは、異なる分岐によるLLMの応答の優劣を予測することを目的としています。具体的には、与えられたプロンプトに対して生成された応答のうち、どちらのモデルが優れているか（または引き分けか）を予測するモデルを訓練します。\n",
    "\n",
    "### 手法\n",
    "1. **モデルの選定**: Deberta-v3 xsmallモデルを使用しています。このモデルは、テキストの埋め込みを計算するために利用され、文脈情報を捉えるのに効果的です。\n",
    "\n",
    "2. **データ処理**: プロンプトと応答を含むデータセットを処理し、必要なラベルを追加する処理を行っています。「winner_model_a」「winner_model_b」「winner_tie」に基づいてターゲットラベルを生成します。\n",
    "\n",
    "3. **トークナイジング**: Hugging Faceの`AutoTokenizer`を使用してテキストをトークナイズし、特殊トークンを追加して、応答形式を整えています。\n",
    "\n",
    "4. **データセットとデータローダー**: `TrainDataset`クラスを定義し、`DataLoader`を利用してミニバッチ処理を行います。\n",
    "\n",
    "5. **モデルの定義**: `CustomModel`クラスを定義し、Deberta-v3モデルの出力を平均プーリングし、最終的な出力を得るための全結合層を追加しています。\n",
    "\n",
    "6. **訓練と評価**: 訓練ループを設け、訓練データとバリデーションデータを使用してモデルを訓練しています。損失関数にはクロスエントロピーを使用し、訓練及び評価時にログを取るように設定されています。\n",
    "\n",
    "### 使用ライブラリ\n",
    "- **PyTorch**: モデルの構築、訓練、評価に主要に使用。\n",
    "- **Transformers**: Hugging Faceのライブラリを使用してトークナイジングとモデルを利用。\n",
    "- **NumPy**および**Pandas**: データ処理や操作に使用。\n",
    "- **Scikit-learn**: 評価指標としてログロスを計算するために使用。\n",
    "\n",
    "### 結論\n",
    "本ノートブックは、自然言語モデルに基づいたチャットボットの応答を比較し、人間の好みに基づく優劣を予測するための基盤を提供しています。Deberta-v3を用いたアプローチは、対応するプロンプトと応答を効果的に処理し、最終的に人間の選好を学習するモデル作りのための重要なステップとされています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c049d6c",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、示されたJupyter Notebook内で機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説です。\n",
    "\n",
    "1. **gradient_checkpointing（勾配チェックポイント）**:\n",
    "   - メモリ使用量を削減するためのテクニック。大きなモデルでバックプロパゲーションを行う際、すべての中間結果を保存するのではなく、一部を計算して必要なときに再計算することで、GPUメモリを節約する。\n",
    "\n",
    "2. **mean pooling（平均プーリング）**:\n",
    "   - 畳み込みニューラルネットワークやトランスフォーマーモデルで、情報を集約する手法。入力の各特徴ベクトルの平均を取ることで、固定長の出力を得る。特に、注意マスクを使用して、特定の入力位置を考慮することが重要。\n",
    "\n",
    "3. **pretrained model（事前学習済みモデル）**:\n",
    "   - 大規模なデータセットであらかじめトレーニングされたモデル。他のタスクに転用することができる。これにより、モデルをゼロから訓練する必要がなく、少ないデータで効果的な結果を得られる。\n",
    "\n",
    "4. **log_loss（対数損失）**:\n",
    "   - 確率的な予測の質を測るための指標。分類問題において、実際のラベルと予測の確率分布との間の差異を示し、小さいほど良い。特にマルチクラス問題で有効。\n",
    "\n",
    "5. **optimizer（オプティマイザ）**:\n",
    "   - モデルのパラメータを更新するためのアルゴリズム。損失関数を最小化することを目的として、勾配降下法やその変種（例: Adam、SGDなど）を利用する。\n",
    "\n",
    "6. **scheduler（学習率スケジューラ）**:\n",
    "   - 学習率を訓練の進捗に応じて調整する仕組み。これにより、モデルの収束を改善したり過学習を防いだりすることができる。例として、線形スケジュールやコサインスケジュールがある。\n",
    "\n",
    "7. **DataLoader（データローダー）**:\n",
    "   - バッチ単位でデータを効率的に読み込むためのPyTorchのクラス。データをシャッフルしたり、ミニバッチを作成したりする機能がある。\n",
    "\n",
    "8. **torch.Tensor（トーチテンソル）**:\n",
    "   - PyTorchのデータ構造で、NumPy配列に似ているが、GPU上で計算を行う能力を備えている。テンソルの演算は、GPUを使用することで高速化される。\n",
    "\n",
    "9. **target label（ターゲットラベル）**:\n",
    "   - モデルが予測を行う際の正解ラベル。または、モデルの学習中に学習データの出力として用いるラベルを指す。\n",
    "\n",
    "10. **attention mask（注意マスク）**:\n",
    "    - トランスフォーマーモデルにおいて、入力シーケンスのどの部分に注意を払うべきかを指定するためのもの。特に、パディングされたトークンを無視するために使用される。\n",
    "\n",
    "これらの用語は、より深く理解するためには、それぞれのコンセプトに関連する背景知識や実装理解も必要になる場合があります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39ed29",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# About this notebook\n",
    "- Deberta-v3 xsmall starter code\n",
    "- Original notebook is [here](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train)\n",
    "- Inference notebook will be updated a little later.\n",
    "- In this notebook, I just use only prompt so you can use response_a, response_a, etc.\n",
    "\n",
    "\n",
    "\n",
    "If this notebook is helpful, feel free to upvote.\n",
    "\n",
    "And please upvote the original notebook :)\n",
    "\n",
    "`V1` - Run debug mode for test\n",
    "- only used prompt, you can add more texts\n",
    "\n",
    "`V2` - Remove existing preprocessing (this part needs more ideas)\n",
    "- please see [this](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832)\n",
    "- changed `max_length = 1024` and `lr = 1e-5`\n",
    "\n",
    "`V3` - Will be updated for all texts or HuggingFace, etc. \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# このノートブックについて\n",
    "- Deberta-v3 xsmallのスターターコード\n",
    "- 元のノートブックは[こちら](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train)\n",
    "- 推論ノートブックは後ほど更新されます。\n",
    "- このノートブックでは、プロンプトのみを使用していますので、response_a、response_bなどを使用できます。\n",
    "\n",
    "このノートブックが役立った場合は、自由にアップボートしてください。\n",
    "\n",
    "そして、元のノートブックにもアップボートしてください :)\n",
    "\n",
    "`V1` - テスト用のデバッグモードを実行\n",
    "- プロンプトのみを使用しています。さらにテキストを追加できます。\n",
    "\n",
    "`V2` - 既存の前処理を削除（この部分にはさらなるアイデアが必要です）\n",
    "- [こちら](https://www.kaggle.com/competitions/learning-agency-lab-automated-essay-scoring-2/discussion/497832)を参照してください。\n",
    "- `max_length = 1024`と`lr = 1e-5`に変更しました。\n",
    "\n",
    "`V3` - すべてのテキストまたはHuggingFaceなどに対して更新されます。\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9faed8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# ディレクトリ設定\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-09T06:58:55.463651Z",
     "iopub.status.busy": "2024-07-09T06:58:55.463249Z",
     "iopub.status.idle": "2024-07-09T06:58:55.475081Z",
     "shell.execute_reply": "2024-07-09T06:58:55.474326Z",
     "shell.execute_reply.started": "2024-07-09T06:58:55.46362Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# ディレクトリ設定\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR = './'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58700a43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:58:56.536416Z",
     "iopub.status.busy": "2024-07-09T06:58:56.536039Z",
     "iopub.status.idle": "2024-07-09T06:58:57.570451Z",
     "shell.execute_reply": "2024-07-09T06:58:57.569342Z",
     "shell.execute_reply.started": "2024-07-09T06:58:56.536381Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109f821",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=False\n",
    "    competition='LMSYS'\n",
    "    _wandb_kernel='test'\n",
    "    debug=True\n",
    "    apex=True\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-v3-xsmall\" # [\"microsoft/deberta-v3-small, microsoft/deberta-v3-base\"]\n",
    "    gradient_checkpointing=False\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr=1e-5\n",
    "    decoder_lr=1e-5\n",
    "    min_lr=1e-5\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=4\n",
    "    max_len=2048\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_label=['target']\n",
    "    target_cols=['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "    seed=42\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0, 1]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=False\n",
    "    competition='LMSYS'\n",
    "    _wandb_kernel='test'\n",
    "    debug=True\n",
    "    apex=True\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-v3-xsmall\" # [\"microsoft/deberta-v3-small\", \"microsoft/deberta-v3-base\"]\n",
    "    gradient_checkpointing=False\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr=1e-5\n",
    "    decoder_lr=1e-5\n",
    "    min_lr=1e-5\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=4\n",
    "    max_len=2048\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_label=['target']\n",
    "    target_cols=['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "    seed=42\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0, 1]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:58:58.627691Z",
     "iopub.status.busy": "2024-07-09T06:58:58.627299Z",
     "iopub.status.idle": "2024-07-09T06:58:58.635897Z",
     "shell.execute_reply": "2024-07-09T06:58:58.634873Z",
     "shell.execute_reply.started": "2024-07-09T06:58:58.627658Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    wandb=False\n",
    "    competition='LMSYS'\n",
    "    _wandb_kernel='test'\n",
    "    debug=True\n",
    "    apex=True\n",
    "    print_freq=20\n",
    "    num_workers=4\n",
    "    model=\"microsoft/deberta-v3-xsmall\" # [\"microsoft/deberta-v3-small\", \"microsoft/deberta-v3-base\"]\n",
    "    gradient_checkpointing=False\n",
    "    scheduler='cosine' # ['linear', 'cosine']\n",
    "    batch_scheduler=True\n",
    "    num_cycles=0.5\n",
    "    num_warmup_steps=0\n",
    "    epochs=4\n",
    "    encoder_lr=1e-5\n",
    "    decoder_lr=1e-5\n",
    "    min_lr=1e-5\n",
    "    eps=1e-6\n",
    "    betas=(0.9, 0.999)\n",
    "    batch_size=4\n",
    "    max_len=2048\n",
    "    weight_decay=0.01\n",
    "    gradient_accumulation_steps=1\n",
    "    max_grad_norm=1000\n",
    "    target_label=['target']\n",
    "    target_cols=['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "    seed=42\n",
    "    train=True\n",
    "    \n",
    "if CFG.debug:\n",
    "    CFG.epochs = 2\n",
    "    CFG.trn_fold = [0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc5165",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels tokenizers')\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# ライブラリ\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels tokenizers')\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:58:59.006094Z",
     "iopub.status.busy": "2024-07-09T06:58:59.005748Z",
     "iopub.status.idle": "2024-07-09T06:59:24.868855Z",
     "shell.execute_reply": "2024-07-09T06:59:24.867891Z",
     "shell.execute_reply.started": "2024-07-09T06:58:59.006068Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# ライブラリ\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import ast\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import string\n",
    "import pickle\n",
    "import random\n",
    "import joblib\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels transformers')\n",
    "os.system('python -m pip install --no-index --find-links=../input/lmsys-pip-wheels tokenizers')\n",
    "\n",
    "import tokenizers\n",
    "import transformers\n",
    "print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n",
    "print(f\"transformers.__version__: {transformers.__version__}\")\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n",
    "%env TOKENIZERS_PARALLELISM=true\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8def07",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    score = log_loss(y_trues, y_preds, labels=[0, 1, 2])\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=CFG.seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# ユーティリティ\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    # ログロスを計算します\n",
    "    score = log_loss(y_trues, y_preds, labels=[0, 1, 2])\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler() \n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))  # コンソールに出力されるフォーマット\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")  # ファイルに出力されるフォーマット\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    # シード値を設定して再現性を持たせるための関数\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=CFG.seed)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:59:24.871886Z",
     "iopub.status.busy": "2024-07-09T06:59:24.870897Z",
     "iopub.status.idle": "2024-07-09T06:59:24.882112Z",
     "shell.execute_reply": "2024-07-09T06:59:24.881235Z",
     "shell.execute_reply.started": "2024-07-09T06:59:24.871848Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# ユーティリティ\n",
    "# ====================================================\n",
    "def get_score(y_trues, y_preds):\n",
    "    # ログロスを計算します\n",
    "    score = log_loss(y_trues, y_preds, labels=[0, 1, 2])\n",
    "    return score\n",
    "\n",
    "\n",
    "def get_logger(filename=OUTPUT_DIR+'train'):\n",
    "    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler() \n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))  # コンソールに出力されるフォーマット\n",
    "    handler2 = FileHandler(filename=f\"{filename}.log\")  # ファイルに出力されるフォーマット\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "LOGGER = get_logger()\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    # シード値を設定して再現性を持たせるための関数\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1311fcf5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# =====================================\n",
    "# We will add targets in dataframs\n",
    "# =====================================\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)\n",
    "    labels[df['winner_model_a'] == 1] = 0\n",
    "    labels[df['winner_model_b'] == 1] = 1\n",
    "    labels[df['winner_tie'] == 1] = 2\n",
    "    df['target'] = labels\n",
    "    return df\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# =====================================\n",
    "# データフレームにターゲットを追加します\n",
    "# =====================================\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)  # ラベル用の配列を初期化\n",
    "    labels[df['winner_model_a'] == 1] = 0  # モデルAが勝った場合のラベル\n",
    "    labels[df['winner_model_b'] == 1] = 1  # モデルBが勝った場合のラベル\n",
    "    labels[df['winner_tie'] == 1] = 2  # 引き分けの場合のラベル\n",
    "    df['target'] = labels  # データフレームにターゲット列を追加\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:59:24.884076Z",
     "iopub.status.busy": "2024-07-09T06:59:24.883213Z",
     "iopub.status.idle": "2024-07-09T06:59:24.895171Z",
     "shell.execute_reply": "2024-07-09T06:59:24.894197Z",
     "shell.execute_reply.started": "2024-07-09T06:59:24.884042Z"
    }
   },
   "outputs": [],
   "source": [
    "# =====================================\n",
    "# データフレームにターゲットを追加します\n",
    "# =====================================\n",
    "def add_label(df):\n",
    "    labels = np.zeros(len(df), dtype=np.int32)  # ラベル用の配列を初期化\n",
    "    labels[df['winner_model_a'] == 1] = 0  # モデルAが勝った場合のラベル\n",
    "    labels[df['winner_model_b'] == 1] = 1  # モデルBが勝った場合のラベル\n",
    "    labels[df['winner_tie'] == 1] = 2  # 引き分けの場合のラベル\n",
    "    df['target'] = labels  # データフレームにターゲット列を追加\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ce34ec",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return sentences\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# Drop 'Null' for training\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")\n",
    "print('Total train samples: ', len(train))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データを読み込む\n",
    "def process(input_str):\n",
    "    # 入力文字列を処理する関数\n",
    "    stripped_str = input_str.strip('[]')  # 先頭と末尾の[]を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 各文を抽出\n",
    "    return sentences\n",
    "\n",
    "# プロンプトと応答を処理する\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# 訓練用に'Null'を削除\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)  # Nullインデックスを削除\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")  # 削除されたNull行の数を表示\n",
    "print('Total train samples: ', len(train))  # 訓練サンプルの合計数を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:59:24.897516Z",
     "iopub.status.busy": "2024-07-09T06:59:24.897163Z",
     "iopub.status.idle": "2024-07-09T06:59:27.478172Z",
     "shell.execute_reply": "2024-07-09T06:59:27.477222Z",
     "shell.execute_reply.started": "2024-07-09T06:59:24.897483Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データを読み込む\n",
    "def process(input_str):\n",
    "    # 入力文字列を処理する関数\n",
    "    stripped_str = input_str.strip('[]')  # 先頭と末尾の[]を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 各文を抽出\n",
    "    return sentences\n",
    "\n",
    "# プロンプトと応答を処理する\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)\n",
    "\n",
    "# 訓練用に'Null'を削除\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index\n",
    "train.drop(indexes, inplace=True)  # Nullインデックスを削除\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(f\"Total {len(indexes)} Null response rows dropped\")  # 削除されたNull行の数を表示\n",
    "print('Total train samples: ', len(train))  # 訓練サンプルの合計数を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f486d129",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "add_label(train).head(5)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "add_label(train).head(5)  # ターゲットを追加した訓練データの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:59:27.481442Z",
     "iopub.status.busy": "2024-07-09T06:59:27.481103Z",
     "iopub.status.idle": "2024-07-09T06:59:27.504675Z",
     "shell.execute_reply": "2024-07-09T06:59:27.503731Z",
     "shell.execute_reply.started": "2024-07-09T06:59:27.481415Z"
    }
   },
   "outputs": [],
   "source": [
    "add_label(train).head(5)  # ターゲットを追加した訓練データの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1b761",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Tokenizer\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# トークナイザー\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074177d4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# tokenizer\n",
    "# ====================================================\n",
    "# Define special tokens\n",
    "special_tokens = ['[R_STRAT]', '[R_END]', '<PROMPT>', '<RESPONSE>', '[NL]', '[NLNL]']\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.replace('\\n\\n', ' [NLNL] ')\n",
    "    text = text.replace('\\n', ' [NL] ')\n",
    "    return text\n",
    "\n",
    "def format_conversation(row):\n",
    "    conversations = []\n",
    "    num_turns = min(len(row['prompt']), len(row['response_a']), len(row['response_b']))\n",
    "    \n",
    "    for i in range(num_turns):\n",
    "        prompt = f\"<PROMPT> {row['prompt'][i]}\"\n",
    "        response_a = f\"<RESPONSE> [R_STRAT] {preprocess_text(row['response_a'][i])} [R_END]\"\n",
    "        response_b = f\"[R_STRAT] {preprocess_text(row['response_b'][i])} [R_END]\"\n",
    "        conversations.append(f\"{prompt} {response_a} {response_b}\")\n",
    "        \n",
    "    return ' [NLNL] '.join(conversations)\n",
    "\n",
    "train['text'] = train.apply(format_conversation, axis=1)\n",
    "\n",
    "# Add special tokens to tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "CFG.tokenizer = tokenizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# トークナイザー\n",
    "# ====================================================\n",
    "# 特殊トークンを定義\n",
    "special_tokens = ['[R_STRAT]', '[R_END]', '<PROMPT>', '<RESPONSE>', '[NL]', '[NLNL]']\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # テキストを前処理する関数\n",
    "    text = text.replace('\\n\\n', ' [NLNL] ')  # 2つの改行を[nl NL]に変換\n",
    "    text = text.replace('\\n', ' [NL] ')  # 1つの改行を[nl]に変換\n",
    "    return text\n",
    "\n",
    "def format_conversation(row):\n",
    "    # 会話形式にフォーマットする関数\n",
    "    conversations = []\n",
    "    num_turns = min(len(row['prompt']), len(row['response_a']), len(row['response_b']))  # 最小のターン数を取得\n",
    "    \n",
    "    for i in range(num_turns):\n",
    "        # プロンプトと応答をフォーマット\n",
    "        prompt = f\"<PROMPT> {row['prompt'][i]}\"\n",
    "        response_a = f\"<RESPONSE> [R_STRAT] {preprocess_text(row['response_a'][i])} [R_END]\"\n",
    "        response_b = f\"[R_STRAT] {preprocess_text(row['response_b'][i])} [R_END]\"\n",
    "        conversations.append(f\"{prompt} {response_a} {response_b}\")  # 会話を追加\n",
    "        \n",
    "    return ' [NLNL] '.join(conversations)  # 会話を連結して返す\n",
    "\n",
    "# 訓練データに形式を適用\n",
    "train['text'] = train.apply(format_conversation, axis=1)\n",
    "\n",
    "# トークナイザーに特殊トークンを追加\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)  # 特殊トークンをトークナイザーに追加\n",
    "CFG.tokenizer = tokenizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T06:59:27.506251Z",
     "iopub.status.busy": "2024-07-09T06:59:27.505934Z",
     "iopub.status.idle": "2024-07-09T06:59:31.41029Z",
     "shell.execute_reply": "2024-07-09T06:59:31.409262Z",
     "shell.execute_reply.started": "2024-07-09T06:59:27.506227Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# トークナイザー\n",
    "# ====================================================\n",
    "# 特殊トークンを定義\n",
    "special_tokens = ['[R_STRAT]', '[R_END]', '<PROMPT>', '<RESPONSE>', '[NL]', '[NLNL]']\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # テキストを前処理する関数\n",
    "    text = text.replace('\\n\\n', ' [NLNL] ')  # 2つの改行を[nl NL]に変換\n",
    "    text = text.replace('\\n', ' [NL] ')  # 1つの改行を[nl]に変換\n",
    "    return text\n",
    "\n",
    "def format_conversation(row):\n",
    "    # 会話形式にフォーマットする関数\n",
    "    conversations = []\n",
    "    num_turns = min(len(row['prompt']), len(row['response_a']), len(row['response_b']))  # 最小のターン数を取得\n",
    "    \n",
    "    for i in range(num_turns):\n",
    "        # プロンプトと応答をフォーマット\n",
    "        prompt = f\"<PROMPT> {row['prompt'][i]}\"\n",
    "        response_a = f\"<RESPONSE> [R_STRAT] {preprocess_text(row['response_a'][i])} [R_END]\"\n",
    "        response_b = f\"[R_STRAT] {preprocess_text(row['response_b'][i])} [R_END]\"\n",
    "        conversations.append(f\"{prompt} {response_a} {response_b}\")  # 会話を追加\n",
    "        \n",
    "    return ' [NLNL] '.join(conversations)  # 会話を連結して返す\n",
    "\n",
    "# 訓練データに形式を適用\n",
    "train['text'] = train.apply(format_conversation, axis=1)\n",
    "\n",
    "# トークナイザーに特殊トークンを追加\n",
    "tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n",
    "special_tokens_dict = {'additional_special_tokens': special_tokens}\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)  # 特殊トークンをトークナイザーに追加\n",
    "CFG.tokenizer = tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01581ea1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer.decode(\n",
    "    tokenizer(\n",
    "        train['text'][1]\n",
    "    ).input_ids\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "tokenizer.decode(\n",
    "    tokenizer(\n",
    "        train['text'][1]\n",
    "    ).input_ids\n",
    ")  # トークン化されたテキストをデコードして表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:00:32.948998Z",
     "iopub.status.busy": "2024-07-09T07:00:32.948342Z",
     "iopub.status.idle": "2024-07-09T07:00:42.993187Z",
     "shell.execute_reply": "2024-07-09T07:00:42.992286Z",
     "shell.execute_reply.started": "2024-07-09T07:00:32.948966Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(\n",
    "    tokenizer(\n",
    "        train['text'][1]\n",
    "    ).input_ids\n",
    ")  # トークン化されたテキストをデコードして表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27bae69",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Dataset\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=CFG.max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values # only use prompt, please feel free add other texts\n",
    "        self.labels = df[cfg.target_label].values.squeeze().tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.long)\n",
    "        return inputs, label\n",
    "    \n",
    "    \n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]\n",
    "    return inputs\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# データセット\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    # 入力を準備する関数\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=CFG.max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)  # テンソルに変換\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values  # テキストを取得\n",
    "        self.labels = df[cfg.target_label].values.squeeze().tolist()  # ラベルを取得\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)  # テキストの長さを返す\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])  # 入力を準備\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.long)  # ラベルをテンソルに変換\n",
    "        return inputs, label  # 入力とラベルを返す\n",
    "    \n",
    "    \n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())  # 最大のマスク長を取得\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]  # マスク長に合わせて切り詰める\n",
    "    return inputs\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:04:29.894591Z",
     "iopub.status.busy": "2024-07-09T07:04:29.893136Z",
     "iopub.status.idle": "2024-07-09T07:04:29.904438Z",
     "shell.execute_reply": "2024-07-09T07:04:29.903354Z",
     "shell.execute_reply.started": "2024-07-09T07:04:29.894554Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# データセット\n",
    "# ====================================================\n",
    "def prepare_input(cfg, text):\n",
    "    # 入力を準備する関数\n",
    "    inputs = cfg.tokenizer.encode_plus(\n",
    "        text, \n",
    "        return_tensors=None, \n",
    "        add_special_tokens=True, \n",
    "        max_length=CFG.max_len,\n",
    "        pad_to_max_length=True,\n",
    "        truncation=True\n",
    "    )\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = torch.tensor(v, dtype=torch.long)  # テンソルに変換\n",
    "    return inputs\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, cfg, df):\n",
    "        self.cfg = cfg\n",
    "        self.texts = df['text'].values  # テキストを取得\n",
    "        self.labels = df[cfg.target_label].values.squeeze().tolist()  # ラベルを取得\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)  # テキストの長さを返す\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inputs = prepare_input(self.cfg, self.texts[item])  # 入力を準備\n",
    "        label = torch.tensor(self.labels[item], dtype=torch.long)  # ラベルをテンソルに変換\n",
    "        return inputs, label  # 入力とラベルを返す\n",
    "    \n",
    "    \n",
    "def collate(inputs):\n",
    "    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())  # 最大のマスク長を取得\n",
    "    for k, v in inputs.items():\n",
    "        inputs[k] = inputs[k][:,:mask_len]  # マスク長に合わせて切り詰める\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a815aeb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Model\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.\n",
    "            self.config.hidden_dropout_prob = 0.\n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            LOGGER.info(self.config)\n",
    "        else:\n",
    "            self.config = torch.load(config_path)\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()\n",
    "        self.pool = MeanPooling()\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)\n",
    "        self._init_weights(self.fc)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        outputs = self.model(**inputs)\n",
    "        last_hidden_states = outputs[0]\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        feature = self.feature(inputs)\n",
    "        output = self.fc(feature)\n",
    "        return output\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# モデル\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        # 最後の隠れ状態を平均プーリングする関数\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()  # マスクを拡張\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)  # 重み付きの埋め込みを合計\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)  # マスクの合計を制限\n",
    "        mean_embeddings = sum_embeddings / sum_mask  # 平均埋め込みを計算\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            # モデルの設定を読み込む\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.  # ドロップアウトを無効にする\n",
    "            self.config.hidden_dropout_prob = 0. \n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            LOGGER.info(self.config) \n",
    "        else:\n",
    "            self.config = torch.load(config_path)  # 設定をファイルから読み込む\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)  # 事前学習済みモデルを読み込む\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)  # 新しいモデルを作成\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()  # 勾配チェックポイントを有効にする\n",
    "        self.pool = MeanPooling()  # 平均プーリングの定義\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)  # 出力層の定義\n",
    "        self._init_weights(self.fc)  # 重みを初期化\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        # モデルの重みを初期化するメソッド\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)  # 初期化を設定\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        # 特徴を抽出するメソッド\n",
    "        outputs = self.model(**inputs)  # モデルを実行\n",
    "        last_hidden_states = outputs[0]  # 最後の隠れ状態を取得\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])  # 平均プーリングを行う\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # フォワードパスを実行するメソッド\n",
    "        feature = self.feature(inputs)  # 特徴を抽出\n",
    "        output = self.fc(feature)  # 出力を計算\n",
    "        return output  # 出力を返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:04:31.984379Z",
     "iopub.status.busy": "2024-07-09T07:04:31.983904Z",
     "iopub.status.idle": "2024-07-09T07:04:32.000184Z",
     "shell.execute_reply": "2024-07-09T07:04:31.999079Z",
     "shell.execute_reply.started": "2024-07-09T07:04:31.984348Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# モデル\n",
    "# ====================================================\n",
    "class MeanPooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MeanPooling, self).__init__()\n",
    "        \n",
    "    def forward(self, last_hidden_state, attention_mask):\n",
    "        # 最後の隠れ状態を平均プーリングする関数\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()  # マスクを拡張\n",
    "        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)  # 重み付きの埋め込みを合計\n",
    "        sum_mask = input_mask_expanded.sum(1)\n",
    "        sum_mask = torch.clamp(sum_mask, min=1e-9)  # マスクの合計を制限\n",
    "        mean_embeddings = sum_embeddings / sum_mask  # 平均埋め込みを計算\n",
    "        return mean_embeddings\n",
    "    \n",
    "\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, cfg, config_path=None, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        if config_path is None:\n",
    "            # モデルの設定を読み込む\n",
    "            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n",
    "            self.config.hidden_dropout = 0.  # ドロップアウトを無効にする\n",
    "            self.config.hidden_dropout_prob = 0. \n",
    "            self.config.attention_dropout = 0.\n",
    "            self.config.attention_probs_dropout_prob = 0.\n",
    "            LOGGER.info(self.config) \n",
    "        else:\n",
    "            self.config = torch.load(config_path)  # 設定をファイルから読み込む\n",
    "        if pretrained:\n",
    "            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)  # 事前学習済みモデルを読み込む\n",
    "        else:\n",
    "            self.model = AutoModel(self.config)  # 新しいモデルを作成\n",
    "        if self.cfg.gradient_checkpointing:\n",
    "            self.model.gradient_checkpointing_enable()  # 勾配チェックポイントを有効にする\n",
    "        self.pool = MeanPooling()  # 平均プーリングの定義\n",
    "        self.fc = nn.Linear(self.config.hidden_size, 3)  # 出力層の定義\n",
    "        self._init_weights(self.fc)  # 重みを初期化\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        # モデルの重みを初期化するメソッド\n",
    "        if isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)  # 初期化を設定\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n",
    "            if module.padding_idx is not None:\n",
    "                module.weight.data[module.padding_idx].zero_()\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        \n",
    "    def feature(self, inputs):\n",
    "        # 特徴を抽出するメソッド\n",
    "        outputs = self.model(**inputs)  # モデルを実行\n",
    "        last_hidden_states = outputs[0]  # 最後の隠れ状態を取得\n",
    "        feature = self.pool(last_hidden_states, inputs['attention_mask'])  # 平均プーリングを行う\n",
    "        return feature\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # フォワードパスを実行するメソッド\n",
    "        feature = self.feature(inputs)  # 特徴を抽出\n",
    "        output = self.fc(feature)  # 出力を計算\n",
    "        return output  # 出力を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce9696",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# Helper functions\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    model.train()\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n",
    "    losses = AverageMeter()\n",
    "    start = end = time.time()\n",
    "    global_step = 0\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        scaler.scale(loss).backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    losses = AverageMeter()\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    start = end = time.time()\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = labels.size(0)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n",
    "    predictions = np.concatenate(preds)\n",
    "    return losses.avg, predictions\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# ヘルパー関数\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"平均と現在の値を計算し、保存します\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0  # 現在の値\n",
    "        self.avg = 0  # 平均値\n",
    "        self.sum = 0  # 合計\n",
    "        self.count = 0  # カウント\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val  # 現在の値を更新\n",
    "        self.sum += val * n  # 合計を更新\n",
    "        self.count += n  # カウントを更新\n",
    "        self.avg = self.sum / self.count  # 平均を再計算\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    # 秒を分と秒に変換します\n",
    "    m = math.floor(s / 60)  # 分を計算\n",
    "    s -= m * 60  # 残りの秒を計算\n",
    "    return '%dm %ds' % (m, s)  # 形式を返します\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    # 経過時間と残り時間を計算します\n",
    "    now = time.time()\n",
    "    s = now - since  # 経過時間\n",
    "    es = s / (percent)  # 予想される経過時間\n",
    "    rs = es - s  # 残り時間\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))  # 結果を返します\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    # 訓練を実行する関数\n",
    "    model.train()  # モデルを訓練モードに設定\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)  # 自動混合精度のスケーラー\n",
    "    losses = AverageMeter()  # 損失を追跡\n",
    "    start = end = time.time()  # 時間を記録\n",
    "    global_step = 0  # グローバルステップ\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)  # 入力をコラテート\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)  # デバイスに移動\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "        batch_size = labels.size(0)  # バッチサイズを取得\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)  # モデルの予測を取得\n",
    "            loss = criterion(y_preds, labels)  # 損失を計算\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps  # 勾配蓄積の場合、損失をスケーリング\n",
    "        losses.update(loss.item(), batch_size)  # 損失を更新\n",
    "        scaler.scale(loss).backward()  # 後方伝播\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)  # 勾配のクリッピング\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:  # 勾配の更新条件\n",
    "            scaler.step(optimizer)  # オプティマイザのステップ\n",
    "            scaler.update()  # スケーラーを更新\n",
    "            optimizer.zero_grad()  # 勾配をゼロに\n",
    "            global_step += 1  # グローバルステップを増加\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()  # スケジューラをステップ\n",
    "                \n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):  # ログ出力の条件\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))  # ログ出力\n",
    "    return losses.avg  # 平均損失を返す\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    # 評価を実行する関数\n",
    "    losses = AverageMeter()  # 損失を追跡\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    preds = []  # 予測を保存\n",
    "    start = end = time.time()  # 時間を記録\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)  # 入力をコラテート\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)  # デバイスに移動\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "        batch_size = labels.size(0)  # バッチサイズを取得\n",
    "        with torch.no_grad():  # 勾配計算を無効に\n",
    "            y_preds = model(inputs)  # モデルの予測を取得\n",
    "            loss = criterion(y_preds, labels)  # 損失を計算\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps  # 勾配蓄積の場合、損失をスケーリング\n",
    "        losses.update(loss.item(), batch_size)  # 損失を更新\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())  # ソフトマックスの予測を保存\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):  # ログ出力の条件\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))  # ログ出力\n",
    "    predictions = np.concatenate(preds)  # すべての予測を連結\n",
    "    return losses.avg, predictions  # 平均損失と予測を返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:04:33.040851Z",
     "iopub.status.busy": "2024-07-09T07:04:33.040151Z",
     "iopub.status.idle": "2024-07-09T07:04:33.062703Z",
     "shell.execute_reply": "2024-07-09T07:04:33.061709Z",
     "shell.execute_reply.started": "2024-07-09T07:04:33.040821Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# ヘルパー関数\n",
    "# ====================================================\n",
    "class AverageMeter(object):\n",
    "    \"\"\"平均と現在の値を計算し、保存します\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0  # 現在の値\n",
    "        self.avg = 0  # 平均値\n",
    "        self.sum = 0  # 合計\n",
    "        self.count = 0  # カウント\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val  # 現在の値を更新\n",
    "        self.sum += val * n  # 合計を更新\n",
    "        self.count += n  # カウントを更新\n",
    "        self.avg = self.sum / self.count  # 平均を再計算\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    # 秒を分と秒に変換します\n",
    "    m = math.floor(s / 60)  # 分を計算\n",
    "    s -= m * 60  # 残りの秒を計算\n",
    "    return '%dm %ds' % (m, s)  # 形式を返します\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    # 経過時間と残り時間を計算します\n",
    "    now = time.time()\n",
    "    s = now - since  # 経過時間\n",
    "    es = s / (percent)  # 予想される経過時間\n",
    "    rs = es - s  # 残り時間\n",
    "    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))  # 結果を返します\n",
    "\n",
    "\n",
    "def train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n",
    "    # 訓練を実行する関数\n",
    "    model.train()  # モデルを訓練モードに設定\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)  # 自動混合精度のスケーラー\n",
    "    losses = AverageMeter()  # 損失を追跡\n",
    "    start = end = time.time()  # 時間を記録\n",
    "    global_step = 0  # グローバルステップ\n",
    "    for step, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = collate(inputs)  # 入力をコラテート\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)  # デバイスに移動\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "        batch_size = labels.size(0)  # バッチサイズを取得\n",
    "        with torch.cuda.amp.autocast(enabled=CFG.apex):\n",
    "            y_preds = model(inputs)  # モデルの予測を取得\n",
    "            loss = criterion(y_preds, labels)  # 損失を計算\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps  # 勾配蓄積の場合、損失をスケーリング\n",
    "        losses.update(loss.item(), batch_size)  # 損失を更新\n",
    "        scaler.scale(loss).backward()  # 後方伝播\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)  # 勾配のクリッピング\n",
    "        if (step + 1) % CFG.gradient_accumulation_steps == 0:  # 勾配の更新条件\n",
    "            scaler.step(optimizer)  # オプティマイザのステップ\n",
    "            scaler.update()  # スケーラーを更新\n",
    "            optimizer.zero_grad()  # 勾配をゼロに\n",
    "            global_step += 1  # グローバルステップを増加\n",
    "            if CFG.batch_scheduler:\n",
    "                scheduler.step()  # スケジューラをステップ\n",
    "                \n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):  # ログ出力の条件\n",
    "            print('Epoch: [{0}][{1}/{2}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  'Grad: {grad_norm:.4f}  '\n",
    "                  'LR: {lr:.8f}  '\n",
    "                  .format(epoch+1, step, len(train_loader), \n",
    "                          remain=timeSince(start, float(step+1)/len(train_loader)),\n",
    "                          loss=losses,\n",
    "                          grad_norm=grad_norm,\n",
    "                          lr=scheduler.get_lr()[0]))  # ログ出力\n",
    "    return losses.avg  # 平均損失を返す\n",
    "\n",
    "\n",
    "def valid_fn(valid_loader, model, criterion, device):\n",
    "    # 評価を実行する関数\n",
    "    losses = AverageMeter()  # 損失を追跡\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    preds = []  # 予測を保存\n",
    "    start = end = time.time()  # 時間を記録\n",
    "    for step, (inputs, labels) in enumerate(valid_loader):\n",
    "        inputs = collate(inputs)  # 入力をコラテート\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)  # デバイスに移動\n",
    "        labels = labels.to(device)  # ラベルをデバイスに移動\n",
    "        batch_size = labels.size(0)  # バッチサイズを取得\n",
    "        with torch.no_grad():  # 勾配計算を無効に\n",
    "            y_preds = model(inputs)  # モデルの予測を取得\n",
    "            loss = criterion(y_preds, labels)  # 損失を計算\n",
    "        if CFG.gradient_accumulation_steps > 1:\n",
    "            loss = loss / CFG.gradient_accumulation_steps  # 勾配蓄積の場合、損失をスケーリング\n",
    "        losses.update(loss.item(), batch_size)  # 損失を更新\n",
    "        preds.append(y_preds.softmax(1).to('cpu').numpy())  # ソフトマックスの予測を保存\n",
    "        end = time.time()\n",
    "        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):  # ログ出力の条件\n",
    "            print('EVAL: [{0}/{1}] '\n",
    "                  'Elapsed {remain:s} '\n",
    "                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n",
    "                  .format(step, len(valid_loader),\n",
    "                          loss=losses,\n",
    "                          remain=timeSince(start, float(step+1)/len(valid_loader))))  # ログ出力\n",
    "    predictions = np.concatenate(preds)  # すべての予測を連結\n",
    "    return losses.avg, predictions  # 平均損失と予測を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9328cf",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# train loop\n",
    "# ====================================================\n",
    "def train_loop(train_df, valid_df):\n",
    "    \n",
    "    LOGGER.info(f\"========== training ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # loader\n",
    "    # ====================================================\n",
    "    valid_labels = valid_df[CFG.target_label].values\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_df)\n",
    "    valid_dataset = TrainDataset(CFG, valid_df)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n",
    "\n",
    "    # ====================================================\n",
    "    # model & optimizer\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')\n",
    "    model.to(device)\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n",
    "    \n",
    "    # ====================================================\n",
    "    # scheduler\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_df) / CFG.batch_size * CFG.epochs)\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n",
    "\n",
    "    # ====================================================\n",
    "    # loop\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_score = np.inf\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # train\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n",
    "\n",
    "        # eval\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n",
    "        \n",
    "        # scoring\n",
    "        score = get_score(valid_labels, predictions)\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n",
    "        if CFG.wandb:\n",
    "            wandb.log({\"epoch\": epoch+1, \n",
    "                       \"avg_train_loss\": avg_loss, \n",
    "                       \"avg_val_loss\": avg_val_loss,\n",
    "                       \"score\": score})\n",
    "        \n",
    "        if best_score > score:\n",
    "            best_score = score\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\")\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']\n",
    "    valid_df[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    return valid_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ====================================================\n",
    "# 訓練ループ\n",
    "# ====================================================\n",
    "def train_loop(train_df, valid_df):\n",
    "    \n",
    "    LOGGER.info(f\"========== 訓練 ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # ローダー\n",
    "    # ====================================================\n",
    "    valid_labels = valid_df[CFG.target_label].values  # バリデーションラベルを取得\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_df)  # 訓練データセットを準備\n",
    "    valid_dataset = TrainDataset(CFG, valid_df)  # バリデーションデータセットを準備\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)  # 訓練ローダー\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)  # バリデーションローダー\n",
    "\n",
    "    # ====================================================\n",
    "    # モデルとオプティマイザ\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)  # モデルを初期化\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')  # モデルの設定を保存\n",
    "    model.to(device)  # モデルをデバイスに移動\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        # オプティマイザのパラメータを取得する関数\n",
    "        param_optimizer = list(model.named_parameters())  # パラメータをリストに格納\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)  # オプティマイザのパラメータを取得\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)  # オプティマイザの初期化\n",
    "    \n",
    "    # ====================================================\n",
    "    # スケジューラ\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        # スケジューラを取得する関数\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_df) / CFG.batch_size * CFG.epochs)  # トレーニングステップ数を計算\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)  # スケジューラの初期化\n",
    "\n",
    "    # ====================================================\n",
    "    # ループ\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()  # 損失関数を定義\n",
    "    \n",
    "    best_score = np.inf  # 最良スコアを無限大で初期化\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()  # 開始時間を記録\n",
    "\n",
    "        # 訓練\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)  # 訓練を実行\n",
    "\n",
    "        # 評価\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)  # バリデーションを実行\n",
    "        \n",
    "        # スコアリング\n",
    "        score = get_score(valid_labels, predictions)  # スコアを計算\n",
    "\n",
    "        elapsed = time.time() - start_time  # 経過時間を計算\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')  # ログ出力\n",
    "        if CFG.wandb:\n",
    "            wandb.log({\"epoch\": epoch+1, \n",
    "                       \"avg_train_loss\": avg_loss, \n",
    "                       \"avg_val_loss\": avg_val_loss,\n",
    "                       \"score\": score})  # wandbにログを記録\n",
    "            \n",
    "        if best_score > score:  # 新しいベストスコアかどうか\n",
    "            best_score = score  # ベストスコアを更新\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')  # モデルを保存\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},  # モデルの状態を保存\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\")  # 最良モデルを保存\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']  # 最良モデルの予測をロード\n",
    "    valid_df[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions  # バリデーションデータフレームに予測を追加\n",
    "\n",
    "    torch.cuda.empty_cache()  # CUDAメモリを空に\n",
    "    gc.collect()  # ガーベジコレクションを実行\n",
    "    \n",
    "    return valid_df  # バリデーションデータフレームを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:04:33.073729Z",
     "iopub.status.busy": "2024-07-09T07:04:33.073316Z",
     "iopub.status.idle": "2024-07-09T07:04:33.092545Z",
     "shell.execute_reply": "2024-07-09T07:04:33.091657Z",
     "shell.execute_reply.started": "2024-07-09T07:04:33.073702Z"
    }
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# 訓練ループ\n",
    "# ====================================================\n",
    "def train_loop(train_df, valid_df):\n",
    "    \n",
    "    LOGGER.info(f\"========== 訓練 ==========\")\n",
    "\n",
    "    # ====================================================\n",
    "    # ローダー\n",
    "    # ====================================================\n",
    "    valid_labels = valid_df[CFG.target_label].values  # バリデーションラベルを取得\n",
    "    \n",
    "    train_dataset = TrainDataset(CFG, train_df)  # 訓練データセットを準備\n",
    "    valid_dataset = TrainDataset(CFG, valid_df)  # バリデーションデータセットを準備\n",
    "\n",
    "    train_loader = DataLoader(train_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)  # 訓練ローダー\n",
    "    valid_loader = DataLoader(valid_dataset,\n",
    "                              batch_size=CFG.batch_size * 2,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)  # バリデーションローダー\n",
    "\n",
    "    # ====================================================\n",
    "    # モデルとオプティマイザ\n",
    "    # ====================================================\n",
    "    model = CustomModel(CFG, config_path=None, pretrained=True)  # モデルを初期化\n",
    "    torch.save(model.config, OUTPUT_DIR+'config.pth')  # モデルの設定を保存\n",
    "    model.to(device)  # モデルをデバイスに移動\n",
    "    \n",
    "    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n",
    "        # オプティマイザのパラメータを取得する関数\n",
    "        param_optimizer = list(model.named_parameters())  # パラメータをリストに格納\n",
    "        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "        optimizer_parameters = [\n",
    "            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'lr': encoder_lr, 'weight_decay': 0.0},\n",
    "            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n",
    "             'lr': decoder_lr, 'weight_decay': 0.0}\n",
    "        ]\n",
    "        return optimizer_parameters\n",
    "\n",
    "    optimizer_parameters = get_optimizer_params(model,\n",
    "                                                encoder_lr=CFG.encoder_lr, \n",
    "                                                decoder_lr=CFG.decoder_lr,\n",
    "                                                weight_decay=CFG.weight_decay)  # オプティマイザのパラメータを取得\n",
    "    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)  # オプティマイザの初期化\n",
    "    \n",
    "    # ====================================================\n",
    "    # スケジューラ\n",
    "    # ====================================================\n",
    "    def get_scheduler(cfg, optimizer, num_train_steps):\n",
    "        # スケジューラを取得する関数\n",
    "        if cfg.scheduler == 'linear':\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n",
    "            )\n",
    "        elif cfg.scheduler == 'cosine':\n",
    "            scheduler = get_cosine_schedule_with_warmup(\n",
    "                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n",
    "            )\n",
    "        return scheduler\n",
    "    \n",
    "    num_train_steps = int(len(train_df) / CFG.batch_size * CFG.epochs)  # トレーニングステップ数を計算\n",
    "    scheduler = get_scheduler(CFG, optimizer, num_train_steps)  # スケジューラの初期化\n",
    "\n",
    "    # ====================================================\n",
    "    # ループ\n",
    "    # ====================================================\n",
    "    criterion = nn.CrossEntropyLoss()  # 損失関数を定義\n",
    "    \n",
    "    best_score = np.inf  # 最良スコアを無限大で初期化\n",
    "\n",
    "    for epoch in range(CFG.epochs):\n",
    "\n",
    "        start_time = time.time()  # 開始時間を記録\n",
    "\n",
    "        # 訓練\n",
    "        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)  # 訓練を実行\n",
    "\n",
    "        # 評価\n",
    "        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)  # バリデーションを実行\n",
    "        \n",
    "        # スコアリング\n",
    "        score = get_score(valid_labels, predictions)  # スコアを計算\n",
    "\n",
    "        elapsed = time.time() - start_time  # 経過時間を計算\n",
    "\n",
    "        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n",
    "        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')  # ログ出力\n",
    "        if CFG.wandb:\n",
    "            wandb.log({\"epoch\": epoch+1, \n",
    "                       \"avg_train_loss\": avg_loss, \n",
    "                       \"avg_val_loss\": avg_val_loss,\n",
    "                       \"score\": score})  # wandbにログを記録\n",
    "            \n",
    "        if best_score > score:  # 新しいベストスコアかどうか\n",
    "            best_score = score  # ベストスコアを更新\n",
    "            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')  # モデルを保存\n",
    "            torch.save({'model': model.state_dict(),\n",
    "                        'predictions': predictions},  # モデルの状態を保存\n",
    "                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\")  # 最良モデルを保存\n",
    "\n",
    "    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_best.pth\", \n",
    "                             map_location=torch.device('cpu'))['predictions']  # 最良モデルの予測をロード\n",
    "    valid_df[[f\"pred_{c}\" for c in CFG.target_cols]] = predictions  # バリデーションデータフレームに予測を追加\n",
    "\n",
    "    torch.cuda.empty_cache()  # CUDAメモリを空に\n",
    "    gc.collect()  # ガーベジコレクションを実行\n",
    "    \n",
    "    return valid_df  # バリデーションデータフレームを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87711b0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        labels = oof_df[CFG.target_cols].values\n",
    "        labels = np.argmax(labels, axis=1)\n",
    "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\n",
    "        score = get_score(labels, preds)\n",
    "        LOGGER.info(f'Score: {score:<.4f}')\n",
    "    \n",
    "    if CFG.train:\n",
    "        # Split data into train and validation (80% train, 20% validation)\n",
    "        train_df = train.sample(frac=0.8, random_state=CFG.seed).reset_index(drop=True)\n",
    "        valid_df = train.drop(train_df.index).reset_index(drop=True)\n",
    "\n",
    "        _oof_df = train_loop(train_df, valid_df)\n",
    "        LOGGER.info(f\"========== result ==========\")\n",
    "        get_result(_oof_df)\n",
    "        _oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        # 結果を取得する関数\n",
    "        labels = oof_df[CFG.target_cols].values  # ラベルを取得\n",
    "        labels = np.argmax(labels, axis=1)  # ラベルの最大値のインデックスを取得\n",
    "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values  # 予測を取得\n",
    "        score = get_score(labels, preds)  # スコアを計算\n",
    "        LOGGER.info(f'Score: {score:<.4f}')  # ログ出力\n",
    "    \n",
    "    if CFG.train:\n",
    "        # データを訓練とバリデーションに分割（80%訓練、20%バリデーション）\n",
    "        train_df = train.sample(frac=0.8, random_state=CFG.seed).reset_index(drop=True)  # 訓練データをサンプリング\n",
    "        valid_df = train.drop(train_df.index).reset_index(drop=True)  # 残りをバリデーションデータに設定\n",
    "\n",
    "        _oof_df = train_loop(train_df, valid_df)  # 訓練ループを実行\n",
    "        LOGGER.info(f\"========== 結果 ==========\")\n",
    "        get_result(_oof_df)  # 結果を取得\n",
    "        _oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')  # 結果を保存\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()  # wandbの終了\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T07:04:33.309636Z",
     "iopub.status.busy": "2024-07-09T07:04:33.309303Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def get_result(oof_df):\n",
    "        # 結果を取得する関数\n",
    "        labels = oof_df[CFG.target_cols].values  # ラベルを取得\n",
    "        labels = np.argmax(labels, axis=1)  # ラベルの最大値のインデックスを取得\n",
    "        preds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values  # 予測を取得\n",
    "        score = get_score(labels, preds)  # スコアを計算\n",
    "        LOGGER.info(f'Score: {score:<.4f}')  # ログ出力\n",
    "    \n",
    "    if CFG.train:\n",
    "        # データを訓練とバリデーションに分割（80%訓練、20%バリデーション）\n",
    "        train_df = train.sample(frac=0.8, random_state=CFG.seed).reset_index(drop=True)  # 訓練データをサンプリング\n",
    "        valid_df = train.drop(train_df.index).reset_index(drop=True)  # 残りをバリデーションデータに設定\n",
    "\n",
    "        _oof_df = train_loop(train_df, valid_df)  # 訓練ループを実行\n",
    "        LOGGER.info(f\"========== 結果 ==========\")\n",
    "        get_result(_oof_df)  # 結果を取得\n",
    "        _oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')  # 結果を保存\n",
    "        \n",
    "    if CFG.wandb:\n",
    "        wandb.finish()  # wandbの終了"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 175528871,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
