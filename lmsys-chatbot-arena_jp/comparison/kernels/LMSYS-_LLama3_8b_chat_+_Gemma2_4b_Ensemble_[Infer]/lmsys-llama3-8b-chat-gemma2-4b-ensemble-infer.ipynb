{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaaa3098",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、異なる大規模言語モデル（LLM）の生成した応答の中から、どちらがより好まれるかを予測するための問題に取り組んでいます。Notebookでは、主に以下の流れで問題解決が行われています。\n",
    "\n",
    "### 問題の背景\n",
    "コンペティションでは、ユーザーが2つの匿名化されたチャットボットの応答から好みのものを選ぶタスクに基づいて、どちらの応答が選ばれるかを予測するモデルの構築が求められています。これに対して、いくつかのアプローチとモデルが提案されています。\n",
    "\n",
    "### 使用している手法とライブラリ\n",
    "1. **ライブラリのインストールとインポート**: \n",
    "   - `transformers`, `peft`, `accelerate`, `bitsandbytes` などのライブラリを利用して、深層学習と自然言語処理のタスクを行います。\n",
    "   - `torch` (PyTorch)や`sklearn` (Scikit-learn)なども使用されています。\n",
    "\n",
    "2. **トークナイザーの設定とデータ処理**:\n",
    "   - 入力データの前処理として、テキストをトークナイズし、モデルが扱いやすい形式に変換します。\n",
    "   - `AutoTokenizer`や`GemmaTokenizerFast`を使用して、テキストデータをトークナイズし、アテンションマスクを生成します。\n",
    "\n",
    "3. **モデルの設定と学習**:\n",
    "   - `LlamaForSequenceClassification`や`Gemma2ForSequenceClassification`などの事前訓練済みモデルをロードし、それぞれ異なるGPUで推論を行う設定をしています。\n",
    "   - LoRA (Low-Rank Adaptation)技術を使用することで、モデルの重みを効率的に調整し、推論の精度を上げています。\n",
    "\n",
    "4. **推論の実行**:\n",
    "   - スレッドを利用して並列処理を行い、モデルの出力から各応答の勝率を計算します。\n",
    "   - 結果はDataFrameに格納され、最終的な予測を得るために統合されます。\n",
    "\n",
    "5. **最終予測の算出**:\n",
    "   - LlamaモデルとLightGBMを組み合わせたアンサンブル学習により、より robust な予測を実現しています。\n",
    "   - `submission.csv`として結果を出力するためのデータフレームを準備し、最終的な提出用ファイルが生成されています。\n",
    "\n",
    "このノートブックは、LLMを活用した人間の好みの予測という複雑なタスクに対して、最先端の技術を利用し、モデルのパフォーマンスを最大限に引き出すための包括的なアプローチを採用しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3eceb88",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容において、初心者がつまずきそうな専門用語や概念の解説を提供します。特にマイナーなものや実務経験がないと馴染みのないものに焦点を合わせています。\n",
    "\n",
    "### 専門用語解説\n",
    "\n",
    "1. **PEFT（Parameter-Efficient Fine-Tuning）**:\n",
    "   - 事前学習済みモデルのファインチューニングを効率的に行うための手法。モデル全体を再学習することなく、一部のパラメータのみを調整することで、計算リソースを節約しやすくなります。\n",
    "\n",
    "2. **LoRA（Low-Rank Adaptation）**:\n",
    "   - PEFTの一種で、低ランク行列を用いて事前学習済みモデルの重みを適応的に調整します。少ないパラメータ変更で性能を向上させることを目的とし、より効率的にトレーニングが可能になります。\n",
    "\n",
    "3. **BitsAndBytes**:\n",
    "   - 大規模言語モデルを効率的に運用するためのライブラリで、重みの圧縮や量子化技術を提供します。特に8ビット計算を用いることで、メモリ使用量を削減しつつ推論速度を向上させることを目的としています。\n",
    "\n",
    "4. **AutoMixedPrecision (自動混合精度)**:\n",
    "   - モデルの学習や推論時に、計算精度を自動的に調整する機能です。特に、16ビットと32ビットの浮動小数点数を組み合わせて使用することで、メモリの節約と計算の高速化を実現します。\n",
    "\n",
    "5. **アテンションマスク**:\n",
    "   - トランスフォーマーモデルにおいて、どのトークンを参照するべきかを示すためのマスクです。特に、パディングされた部分（無効なトークン）は無視されるように設定されます。\n",
    "\n",
    "6. **トークナイザー**:\n",
    "   - 自然言語処理において、文書を単語やサブワードに分割するためのコンポーネントです。トークナイザーは、モデルが理解できる形式でデータを整形するために使用されます。\n",
    "\n",
    "7. **パディング（Padding）**:\n",
    "   - シーケンスデータの長さを揃えるために、短いシーケンスの末尾に特定のトークン（通常はゼロトークン）を追加する処理です。モデルは固定長の入力を必要とするため、パディングが役立ちます。\n",
    "\n",
    "8. **GitOpsやCI/CDパイプライン**:\n",
    "   - 通常はソフトウェア開発に関連する用語ですが、機械学習モデルのデプロイや管理においても適用されることがあります。例えば、MLのモデルの更新フローを自動化することで、迅速かつ安定したリリースが可能になります。\n",
    "\n",
    "9. **シャーディング（Sharding）**:\n",
    "   - 大きなモデルを複数のデバイスに分けて並行処理する手法です。GPUのメモリ制限を克服しつつ、モデルの推論やトレーニングを効率化します。\n",
    "\n",
    "10. **ダイナミックバッチング（Dynamic Batching）**:\n",
    "   - リアルタイム推論中にリクエストをまとめて処理することで、より効率的に計算を行う手法です。リクエストの長さや数によってバッチサイズを変更します。\n",
    "\n",
    "これらの用語や概念は、特に機械学習・深層学習初心者が理解する際に、注意が必要です。理解を深めるためには、関連する文献やオンラインリソースを活用することも良いでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942097c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install transformers peft accelerate bitsandbytes \\-U --no-index --find-links /kaggle/input/lmsys-wheel-files\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインストールする\n",
    "# transformers、peft、accelerate、bitsandbytesを最新バージョンでインストールします。\n",
    "!pip install transformers peft accelerate bitsandbytes \\-U --no-index --find-links /kaggle/input/lmsys-wheel-files\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-26T08:18:49.996957Z",
     "iopub.status.busy": "2024-07-26T08:18:49.996574Z",
     "iopub.status.idle": "2024-07-26T08:19:06.27664Z",
     "shell.execute_reply": "2024-07-26T08:19:06.275735Z",
     "shell.execute_reply.started": "2024-07-26T08:18:49.996928Z"
    },
    "papermill": {
     "duration": 31.479497,
     "end_time": "2024-07-10T01:13:41.690971",
     "exception": false,
     "start_time": "2024-07-10T01:13:10.211474",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストールする\n",
    "# transformers、peft、accelerate、bitsandbytesを最新バージョンでインストールします。\n",
    "!pip install transformers peft accelerate bitsandbytes \\-U --no-index --find-links /kaggle/input/lmsys-wheel-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc4ffd8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# bitsandbytesライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "# transformersライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "# tokenizersライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "# peftライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T08:19:10.515174Z",
     "iopub.status.busy": "2024-07-26T08:19:10.51481Z",
     "iopub.status.idle": "2024-07-26T08:19:59.863019Z",
     "shell.execute_reply": "2024-07-26T08:19:59.861931Z",
     "shell.execute_reply.started": "2024-07-26T08:19:10.515142Z"
    }
   },
   "outputs": [],
   "source": [
    "# bitsandbytesライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
    "# transformersライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
    "# tokenizersライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U tokenizers --no-index --find-links ../input/llm-detect-pip/\n",
    "# peftライブラリをインストールする（-qで出力を抑制）\n",
    "!pip install -q -U peft --no-index --find-links ../input/llm-detect-pip/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ffc952",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# PART 1 (LLama 3 8b Chat)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# パート 1 (LLama 3 8b チャット)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e66f4f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "from torch.cuda.amp import autocast\n",
    "from threading import Thread\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pickle\n",
    "import zipfile\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import log_loss\n",
    "import tokenizers\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートする\n",
    "import torch  # PyTorchライブラリをインポート\n",
    "import sklearn  # scikit-learnライブラリをインポート\n",
    "import numpy as np  # NumPyライブラリをインポート\n",
    "import pandas as pd  # Pandasライブラリをインポート\n",
    "import time  # 時間関連の機能を使用するためにtimeモジュールをインポート\n",
    "\n",
    "# Transformersライブラリから必要なモデルやトークナイザーをインポート\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# PEFTライブラリから必要なモジュールをインポート\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# 自動混合精度を使用するためにautocastをインポート\n",
    "from torch.cuda.amp import autocast\n",
    "# スレッドを使用するためにThreadをインポート\n",
    "from threading import Thread\n",
    "\n",
    "# ガベージコレクションを制御するためにgcモジュールをインポート\n",
    "import gc\n",
    "import os  # オペレーティングシステム関連の機能を使用するためにosモジュールをインポート\n",
    "import io  # 入出力操作を行うためにioモジュールをインポート\n",
    "import time  # 時間関連の機能を使用するためにtimeモジュールを再度インポート\n",
    "import json  # JSONデータを扱うためにjsonモジュールをインポート\n",
    "import random  # ランダム数生成のためにrandomモジュールをインポート\n",
    "import pickle  # Pythonオブジェクトのシリアル化のためにpickleモジュールをインポート\n",
    "import zipfile  # ZIPファイルを扱うためにzipfileモジュールをインポート\n",
    "import datetime  # 日付と時刻を扱うためにdatetimeモジュールをインポート\n",
    "import matplotlib.pyplot as plt  # データの可視化のためにMatplotlibをインポート\n",
    "from IPython.display import display  # IPython環境での出力を行うためにdisplay関数をインポート\n",
    "from collections import Counter  # 要素のカウントのためのCounterクラスをインポート\n",
    "from collections import defaultdict  # デフォルト値を持つ辞書を作成するためのdefaultdictクラスをインポート\n",
    "import torch  # PyTorchライブラリを再度インポート\n",
    "from torch import nn  # ニューラルネットワーク関連モジュールをインポート\n",
    "import torch.nn.functional as F  # ニューラルネットワークの関数をインポート\n",
    "import pytorch_lightning as pl  # PyTorch Lightningをインポート\n",
    "from torch.utils.data import Dataset, DataLoader  # データセットとデータローダーをインポート\n",
    "from sklearn.metrics import log_loss  # ログ損失の計算のためにインポート\n",
    "import tokenizers  # トークナイザーを扱うためにtokenizersライブラリをインポート\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:08:53.562705Z",
     "iopub.status.busy": "2024-07-24T12:08:53.562325Z",
     "iopub.status.idle": "2024-07-24T12:09:03.686073Z",
     "shell.execute_reply": "2024-07-24T12:09:03.685309Z",
     "shell.execute_reply.started": "2024-07-24T12:08:53.562667Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートする\n",
    "import torch  # PyTorchライブラリをインポート\n",
    "import sklearn  # scikit-learnライブラリをインポート\n",
    "import numpy as np  # NumPyライブラリをインポート\n",
    "import pandas as pd  # Pandasライブラリをインポート\n",
    "import time  # 時間関連の機能を使用するためにtimeモジュールをインポート\n",
    "\n",
    "# Transformersライブラリから必要なモデルやトークナイザーをインポート\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "# PEFTライブラリから必要なモジュールをインポート\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n",
    "# 自動混合精度を使用するためにautocastをインポート\n",
    "from torch.cuda.amp import autocast\n",
    "# スレッドを使用するためにThreadをインポート\n",
    "from threading import Thread\n",
    "\n",
    "# ガベージコレクションを制御するためにgcモジュールをインポート\n",
    "import gc\n",
    "import os  # オペレーティングシステム関連の機能を使用するためにosモジュールをインポート\n",
    "import io  # 入出力操作を行うためにioモジュールをインポート\n",
    "import time  # 時間関連の機能を使用するためにtimeモジュールを再度インポート\n",
    "import json  # JSONデータを扱うためにjsonモジュールをインポート\n",
    "import random  # ランダム数生成のためにrandomモジュールをインポート\n",
    "import pickle  # Pythonオブジェクトのシリアル化のためにpickleモジュールをインポート\n",
    "import zipfile  # ZIPファイルを扱うためにzipfileモジュールをインポート\n",
    "import datetime  # 日付と時刻を扱うためにdatetimeモジュールをインポート\n",
    "import matplotlib.pyplot as plt  # データの可視化のためにMatplotlibをインポート\n",
    "from IPython.display import display  # IPython環境での出力を行うためにdisplay関数をインポート\n",
    "from collections import Counter  # 要素のカウントのためのCounterクラスをインポート\n",
    "from collections import defaultdict  # デフォルト値を持つ辞書を作成するためのdefaultdictクラスをインポート\n",
    "import torch  # PyTorchライブラリを再度インポート\n",
    "from torch import nn  # ニューラルネットワーク関連モジュールをインポート\n",
    "import torch.nn.functional as F  # ニューラルネットワークの関数をインポート\n",
    "import pytorch_lightning as pl  # PyTorch Lightningをインポート\n",
    "from torch.utils.data import Dataset, DataLoader  # データセットとデータローダーをインポート\n",
    "from sklearn.metrics import log_loss  # ログ損失の計算のためにインポート\n",
    "import tokenizers  # トークナイザーを扱うためにtokenizersライブラリをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ede8d17",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from peft import PeftModel\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データクラスを使用するためにdataclassをインポート\n",
    "from dataclasses import dataclass\n",
    "# スレッドプールを使用するためにThreadPoolExecutorをインポート\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# TransformersライブラリからGemmaモデルとトークナイザーをインポート\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "# トークナイザーの警告を抑制しながらパディングを行うためのデータコレーターをインポート\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "# PEFTライブラリからPeftModelをインポート\n",
    "from peft import PeftModel\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:03.688537Z",
     "iopub.status.busy": "2024-07-24T12:09:03.688058Z",
     "iopub.status.idle": "2024-07-24T12:09:15.236577Z",
     "shell.execute_reply": "2024-07-24T12:09:15.235721Z",
     "shell.execute_reply.started": "2024-07-24T12:09:03.688508Z"
    },
    "papermill": {
     "duration": 19.200405,
     "end_time": "2024-07-10T01:14:00.90474",
     "exception": false,
     "start_time": "2024-07-10T01:13:41.704335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データクラスを使用するためにdataclassをインポート\n",
    "from dataclasses import dataclass\n",
    "# スレッドプールを使用するためにThreadPoolExecutorをインポート\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# TransformersライブラリからGemmaモデルとトークナイザーをインポート\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "# トークナイザーの警告を抑制しながらパディングを行うためのデータコレーターをインポート\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "# PEFTライブラリからPeftModelをインポート\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28c3a86",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'\n",
    "MAX_LENGTH = 1284\n",
    "BATCH_SIZE = 8\n",
    "DEVICE = torch.device(\"cuda\")    \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# メモリ効率の良いシステムダイナミクスプログラミング（SDP）を無効にする\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "# フラッシュSDPを無効にする\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# GPUが利用可能でない場合の警告メッセージ\n",
    "if (not torch.cuda.is_available()): \n",
    "    print(\"申し訳ありませんが、GPUが必要です！\")\n",
    "\n",
    "# モデルと重みのパスを設定\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'\n",
    "\n",
    "# モデルの最大入力長とバッチサイズを設定\n",
    "MAX_LENGTH = 1284  # 最大入力長を1284に設定\n",
    "BATCH_SIZE = 8  # バッチサイズを8に設定\n",
    "\n",
    "# 計算デバイスを指定（GPUを使用）\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:15.238201Z",
     "iopub.status.busy": "2024-07-24T12:09:15.237656Z",
     "iopub.status.idle": "2024-07-24T12:09:15.273581Z",
     "shell.execute_reply": "2024-07-24T12:09:15.272685Z",
     "shell.execute_reply.started": "2024-07-24T12:09:15.238174Z"
    }
   },
   "outputs": [],
   "source": [
    "# メモリ効率の良いシステムダイナミクスプログラミング（SDP）を無効にする\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "# フラッシュSDPを無効にする\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# GPUが利用可能でない場合の警告メッセージ\n",
    "if (not torch.cuda.is_available()): \n",
    "    print(\"申し訳ありませんが、GPUが必要です！\")\n",
    "\n",
    "# モデルと重みのパスを設定\n",
    "MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'\n",
    "WEIGHTS_PATH = '/kaggle/input/lmsys-model/model'\n",
    "\n",
    "# モデルの最大入力長とバッチサイズを設定\n",
    "MAX_LENGTH = 1284  # 最大入力長を1284に設定\n",
    "BATCH_SIZE = 8  # バッチサイズを8に設定\n",
    "\n",
    "# 計算デバイスを指定（GPUを使用）\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79debc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータセットをCSVファイルから読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "# 提出サンプルをCSVファイルから読み込む\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:15.274901Z",
     "iopub.status.busy": "2024-07-24T12:09:15.274624Z",
     "iopub.status.idle": "2024-07-24T12:09:15.294576Z",
     "shell.execute_reply": "2024-07-24T12:09:15.293899Z",
     "shell.execute_reply.started": "2024-07-24T12:09:15.274875Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータセットをCSVファイルから読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "# 提出サンプルをCSVファイルから読み込む\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f400f4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# concatenate strings in list\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "display(sample_sub)\n",
    "display(test.head(5))\n",
    "\n",
    "# Prepare text for model\n",
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + test['response_b']\n",
    "print(test['text'][0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# リスト内の文字列を結合する関数を定義\n",
    "def process(input_str):\n",
    "    # 入力文字列の両端のブラケットを削除\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # カンマで区切った部分をリストに分割し、余分な引用符を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    # リストの要素を空白で結合して一つの文字列にする\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "# データフレームの各列に対してprocess関数を適用\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "# 提出サンプルとテストデータの最初の5行を表示\n",
    "display(sample_sub)\n",
    "display(test.head(5))\n",
    "\n",
    "# モデル用にテキストを準備\n",
    "test['text'] = 'ユーザープロンプト: ' + test['prompt'] +  '\\n\\nモデル A:\\n' + test['response_a'] +'\\n\\n--------\\n\\nモデル B:\\n'  + test['response_b']\n",
    "# 最初のテキストを表示\n",
    "print(test['text'][0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:15.295891Z",
     "iopub.status.busy": "2024-07-24T12:09:15.295592Z",
     "iopub.status.idle": "2024-07-24T12:09:15.327817Z",
     "shell.execute_reply": "2024-07-24T12:09:15.326985Z",
     "shell.execute_reply.started": "2024-07-24T12:09:15.295861Z"
    }
   },
   "outputs": [],
   "source": [
    "# リスト内の文字列を結合する関数を定義\n",
    "def process(input_str):\n",
    "    # 入力文字列の両端のブラケットを削除\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # カンマで区切った部分をリストに分割し、余分な引用符を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    # リストの要素を空白で結合して一つの文字列にする\n",
    "    return  ' '.join(sentences)\n",
    "\n",
    "# データフレームの各列に対してprocess関数を適用\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "# 提出サンプルとテストデータの最初の5行を表示\n",
    "display(sample_sub)\n",
    "display(test.head(5))\n",
    "\n",
    "# モデル用にテキストを準備\n",
    "test['text'] = 'ユーザープロンプト: ' + test['prompt'] +  '\\n\\nモデル A:\\n' + test['response_a'] +'\\n\\n--------\\n\\nモデル B:\\n'  + test['response_b']\n",
    "# 最初のテキストを表示\n",
    "print(test['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c82912",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイズ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515724d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# Move tensors to CPU and convert them to lists\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu\n",
    "data[:2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーを指定したパスからロードする\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "# テキストをトークナイズし、パディング、トランケーションを行う\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "# 入力IDとアテンションマスクを指定したデバイスに移動し、データ型を整数32ビットに指定\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# テンソルをCPUに移動させ、リストに変換\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]\n",
    "\n",
    "# データフレームを作成し、入力IDとアテンションマスクを格納\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu\n",
    "# 最初の2行を表示\n",
    "data[:2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:15.329386Z",
     "iopub.status.busy": "2024-07-24T12:09:15.329081Z",
     "iopub.status.idle": "2024-07-24T12:09:16.0095Z",
     "shell.execute_reply": "2024-07-24T12:09:16.008542Z",
     "shell.execute_reply.started": "2024-07-24T12:09:15.329361Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーを指定したパスからロードする\n",
    "tokenizer = AutoTokenizer.from_pretrained('/kaggle/input/lmsys-model/tokenizer')\n",
    "\n",
    "# テキストをトークナイズし、パディング、トランケーションを行う\n",
    "tokens = tokenizer(test['text'].tolist(), padding='max_length',\n",
    "                   max_length=MAX_LENGTH, truncation=True, return_tensors='pt')\n",
    "\n",
    "# 入力IDとアテンションマスクを指定したデバイスに移動し、データ型を整数32ビットに指定\n",
    "INPUT_IDS = tokens['input_ids'].to(DEVICE, dtype=torch.int32)\n",
    "ATTENTION_MASKS = tokens['attention_mask'].to(DEVICE, dtype=torch.int32)\n",
    "\n",
    "# テンソルをCPUに移動させ、リストに変換\n",
    "input_ids_cpu = [tensor.cpu().tolist() for tensor in INPUT_IDS]\n",
    "attention_masks_cpu = [tensor.cpu().tolist() for tensor in ATTENTION_MASKS]\n",
    "\n",
    "# データフレームを作成し、入力IDとアテンションマスクを格納\n",
    "data = pd.DataFrame()\n",
    "data['INPUT_IDS'] = input_ids_cpu\n",
    "data['ATTENTION_MASKS'] = attention_masks_cpu\n",
    "# 最初の2行を表示\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187f0d8",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load model \n",
    "> We load 1 model on each gpu.  \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルのロード\n",
    "> 各GPUに1つのモデルをロードします。  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f575bac",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# BitsAndBytes configuration\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False)\n",
    "\n",
    "# Load base model on GPU 0\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# BitsAndBytesの設定を行う\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでのロードを指定\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 計算に使用する8ビットのデータ型をfloat16に指定\n",
    "    bnb_8bit_use_double_quant=False  # ダブル量子化を使用しない場合はFalse\n",
    ")\n",
    "\n",
    "# GPU 0にベースモデルをロード\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定でロード\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # ラベルの数を3に指定\n",
    "    torch_dtype=torch.float16,  # モデルパラメータのデータ型をfloat16に指定\n",
    "    quantization_config=bnb_config,  # 量子化設定を適用\n",
    "    device_map='cuda:0'  # モデルをGPU 0にマップ\n",
    ")\n",
    "# パディングトークンIDを設定\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:09:16.01138Z",
     "iopub.status.busy": "2024-07-24T12:09:16.010948Z",
     "iopub.status.idle": "2024-07-24T12:10:53.114572Z",
     "shell.execute_reply": "2024-07-24T12:10:53.113618Z",
     "shell.execute_reply.started": "2024-07-24T12:09:16.011331Z"
    }
   },
   "outputs": [],
   "source": [
    "# BitsAndBytesの設定を行う\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでのロードを指定\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 計算に使用する8ビットのデータ型をfloat16に指定\n",
    "    bnb_8bit_use_double_quant=False  # ダブル量子化を使用しない場合はFalse\n",
    ")\n",
    "\n",
    "# GPU 0にベースモデルをロード\n",
    "device0 = torch.device('cuda:0')\n",
    "\n",
    "# LlamaForSequenceClassificationモデルを指定した設定でロード\n",
    "base_model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # ラベルの数を3に指定\n",
    "    torch_dtype=torch.float16,  # モデルパラメータのデータ型をfloat16に指定\n",
    "    quantization_config=bnb_config,  # 量子化設定を適用\n",
    "    device_map='cuda:0'  # モデルをGPU 0にマップ\n",
    ")\n",
    "# パディングトークンIDを設定\n",
    "base_model_0.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bbf8c4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load base model on GPU 1\n",
    "device1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPU 1にベースモデルをロード\n",
    "device1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # ラベルの数を3に指定\n",
    "    torch_dtype=torch.float16,  # モデルパラメータのデータ型をfloat16に指定\n",
    "    quantization_config=bnb_config,  # 量子化設定を適用\n",
    "    device_map='cuda:1'  # モデルをGPU 1にマップ\n",
    ")\n",
    "# パディングトークンIDを設定\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:31.153653Z",
     "iopub.status.busy": "2024-07-24T12:11:31.153247Z",
     "iopub.status.idle": "2024-07-24T12:11:45.396074Z",
     "shell.execute_reply": "2024-07-24T12:11:45.395106Z",
     "shell.execute_reply.started": "2024-07-24T12:11:31.153622Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPU 1にベースモデルをロード\n",
    "device1 = torch.device('cuda:1')\n",
    "base_model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # ラベルの数を3に指定\n",
    "    torch_dtype=torch.float16,  # モデルパラメータのデータ型をfloat16に指定\n",
    "    quantization_config=bnb_config,  # 量子化設定を適用\n",
    "    device_map='cuda:1'  # モデルをGPU 1にマップ\n",
    ")\n",
    "# パディングトークンIDを設定\n",
    "base_model_1.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa03469",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# LoRa configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.10,\n",
    "    bias='none',\n",
    "    inference_mode=True,\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    target_modules=['o_proj', 'v_proj'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoRa（Low-Rank Adaptation）の設定を行う\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # ランクを16に設定\n",
    "    lora_alpha=32,  # LoRaのスケーリングファクターを32に設定\n",
    "    lora_dropout=0.10,  # LoRaのドロップアウト率を10%に設定\n",
    "    bias='none',  # バイアスの設定をなしに指定\n",
    "    inference_mode=True,  # 推論モードを有効にする\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプを列分類に設定\n",
    "    target_modules=['o_proj', 'v_proj']  # 対象モジュールを指定\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:10:53.118235Z",
     "iopub.status.busy": "2024-07-24T12:10:53.117943Z",
     "iopub.status.idle": "2024-07-24T12:10:53.123104Z",
     "shell.execute_reply": "2024-07-24T12:10:53.122302Z",
     "shell.execute_reply.started": "2024-07-24T12:10:53.118209Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoRa（Low-Rank Adaptation）の設定を行う\n",
    "peft_config = LoraConfig(\n",
    "    r=16,  # ランクを16に設定\n",
    "    lora_alpha=32,  # LoRaのスケーリングファクターを32に設定\n",
    "    lora_dropout=0.10,  # LoRaのドロップアウト率を10%に設定\n",
    "    bias='none',  # バイアスの設定をなしに指定\n",
    "    inference_mode=True,  # 推論モードを有効にする\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプを列分類に設定\n",
    "    target_modules=['o_proj', 'v_proj']  # 対象モジュールを指定\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8788c796",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Get peft\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0) \n",
    "#Load weights\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)\n",
    "model_0.eval()\n",
    "\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)\n",
    "model_1.eval()\n",
    "\n",
    "#Trainable Parameters\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# PEFTモデルを取得し、GPU 0に配置\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0)\n",
    "# 重みをロード\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # 重みを指定したパスから読み込み\n",
    "model_0.eval()  # 評価モードに設定\n",
    "\n",
    "# PEFTモデルを取得し、GPU 1に配置\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # 重みを指定したパスから読み込み\n",
    "model_1.eval()  # 評価モードに設定\n",
    "\n",
    "# 学習可能なパラメータを表示\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:45.397943Z",
     "iopub.status.busy": "2024-07-24T12:11:45.397643Z",
     "iopub.status.idle": "2024-07-24T12:11:45.913842Z",
     "shell.execute_reply": "2024-07-24T12:11:45.912826Z",
     "shell.execute_reply.started": "2024-07-24T12:11:45.397917Z"
    }
   },
   "outputs": [],
   "source": [
    "# PEFTモデルを取得し、GPU 0に配置\n",
    "model_0 = get_peft_model(base_model_0, peft_config).to(device0)\n",
    "# 重みをロード\n",
    "model_0.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # 重みを指定したパスから読み込み\n",
    "model_0.eval()  # 評価モードに設定\n",
    "\n",
    "# PEFTモデルを取得し、GPU 1に配置\n",
    "model_1 = get_peft_model(base_model_1, peft_config).to(device1)\n",
    "model_1.load_state_dict(torch.load(WEIGHTS_PATH), strict=False)  # 重みを指定したパスから読み込み\n",
    "model_1.eval()  # 評価モードに設定\n",
    "\n",
    "# 学習可能なパラメータを表示\n",
    "model_0.print_trainable_parameters(), model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c965e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ガベージコレクションを実行して、使用されていないメモリを解放\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:45.915588Z",
     "iopub.status.busy": "2024-07-24T12:11:45.915194Z",
     "iopub.status.idle": "2024-07-24T12:11:46.223001Z",
     "shell.execute_reply": "2024-07-24T12:11:46.222145Z",
     "shell.execute_reply.started": "2024-07-24T12:11:45.915555Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガベージコレクションを実行して、使用されていないメモリを解放\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5883759",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Inference\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 推論\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d8854",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    generated_class_a = []\n",
    "    generated_class_b = []\n",
    "    generated_class_c = []\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask\n",
    "                )\n",
    "        \n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        \n",
    "        generated_class_a.extend(probabilities[:, 0])\n",
    "        generated_class_b.extend(probabilities[:, 1])\n",
    "        generated_class_c.extend(probabilities[:, 2])\n",
    "    \n",
    "    df['winner_model_a'] = generated_class_a\n",
    "    df['winner_model_b'] = generated_class_b\n",
    "    df['winner_tie'] = generated_class_c\n",
    "\n",
    "    torch.cuda.empty_cache()  \n",
    "\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行う関数を定義\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    # データフレームから入力IDとアテンションマスクを取得\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    # 各クラスの生成された確率を格納するリストを初期化\n",
    "    generated_class_a = []\n",
    "    generated_class_b = []\n",
    "    generated_class_c = []\n",
    "\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    \n",
    "    # データをバッチ処理で推論\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終わりのインデックスを計算\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # 現在のバッチの入力IDをデバイスに移動\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # 現在のバッチのアテンションマスクをデバイスに移動\n",
    "        \n",
    "        with torch.no_grad():  # 勾配計算を無効にする\n",
    "            with autocast():  # 自動混合精度を使用\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,  # モデルに入力IDを渡す\n",
    "                    attention_mask=batch_attention_mask  # モデルにアテンションマスクを渡す\n",
    "                )\n",
    "        \n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()  # 出力のロジットをソフトマックス関数で確率に変換\n",
    "        \n",
    "        # 各クラスの確率をリストに追加\n",
    "        generated_class_a.extend(probabilities[:, 0])  # クラスAの確率を追加\n",
    "        generated_class_b.extend(probabilities[:, 1])  # クラスBの確率を追加\n",
    "        generated_class_c.extend(probabilities[:, 2])  # 引き分けの確率を追加\n",
    "    \n",
    "    # データフレームに生成された確率を追加\n",
    "    df['winner_model_a'] = generated_class_a\n",
    "    df['winner_model_b'] = generated_class_b\n",
    "    df['winner_tie'] = generated_class_c\n",
    "\n",
    "    torch.cuda.empty_cache()  # GPUのキャッシュメモリを解放\n",
    "\n",
    "    return df  # 推論結果が含まれたデータフレームを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:46.225558Z",
     "iopub.status.busy": "2024-07-24T12:11:46.225199Z",
     "iopub.status.idle": "2024-07-24T12:11:46.235248Z",
     "shell.execute_reply": "2024-07-24T12:11:46.234307Z",
     "shell.execute_reply.started": "2024-07-24T12:11:46.225521Z"
    }
   },
   "outputs": [],
   "source": [
    "# 推論を行う関数を定義\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    # データフレームから入力IDとアテンションマスクを取得\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "    \n",
    "    # 各クラスの生成された確率を格納するリストを初期化\n",
    "    generated_class_a = []\n",
    "    generated_class_b = []\n",
    "    generated_class_c = []\n",
    "\n",
    "    model.eval()  # モデルを評価モードに設定\n",
    "    \n",
    "    # データをバッチ処理で推論\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終わりのインデックスを計算\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # 現在のバッチの入力IDをデバイスに移動\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # 現在のバッチのアテンションマスクをデバイスに移動\n",
    "        \n",
    "        with torch.no_grad():  # 勾配計算を無効にする\n",
    "            with autocast():  # 自動混合精度を使用\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,  # モデルに入力IDを渡す\n",
    "                    attention_mask=batch_attention_mask  # モデルにアテンションマスクを渡す\n",
    "                )\n",
    "        \n",
    "        probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()  # 出力のロジットをソフトマックス関数で確率に変換\n",
    "        \n",
    "        # 各クラスの確率をリストに追加\n",
    "        generated_class_a.extend(probabilities[:, 0])  # クラスAの確率を追加\n",
    "        generated_class_b.extend(probabilities[:, 1])  # クラスBの確率を追加\n",
    "        generated_class_c.extend(probabilities[:, 2])  # 引き分けの確率を追加\n",
    "    \n",
    "    # データフレームに生成された確率を追加\n",
    "    df['winner_model_a'] = generated_class_a\n",
    "    df['winner_model_b'] = generated_class_b\n",
    "    df['winner_tie'] = generated_class_c\n",
    "\n",
    "    torch.cuda.empty_cache()  # GPUのキャッシュメモリを解放\n",
    "\n",
    "    return df  # 推論結果が含まれたデータフレームを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf7c481",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "N_SAMPLES = len(data)\n",
    "\n",
    "# Split the data into two subsets\n",
    "half = round(N_SAMPLES / 2)\n",
    "sub1 = data.iloc[0:half].copy()\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()\n",
    "\n",
    "# Function to run inference in a thread\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)\n",
    "\n",
    "# Dictionary to store results from threads\n",
    "results = {}\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "N_SAMPLES = len(data)  # サンプルの総数を取得\n",
    "\n",
    "# データを2つのサブセットに分割\n",
    "half = round(N_SAMPLES / 2)  # サンプル数の半分を計算\n",
    "sub1 = data.iloc[0:half].copy()  # 最初の半分をコピー\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 残りの半分をコピー\n",
    "\n",
    "# スレッドで推論を実行する関数を定義\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)  # 指定したインデックスに推論結果を格納\n",
    "\n",
    "# スレッドからの結果を格納する辞書を初期化\n",
    "results = {}\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:46.236656Z",
     "iopub.status.busy": "2024-07-24T12:11:46.236384Z",
     "iopub.status.idle": "2024-07-24T12:11:46.253432Z",
     "shell.execute_reply": "2024-07-24T12:11:46.252574Z",
     "shell.execute_reply.started": "2024-07-24T12:11:46.236634Z"
    }
   },
   "outputs": [],
   "source": [
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "N_SAMPLES = len(data)  # サンプルの総数を取得\n",
    "\n",
    "# データを2つのサブセットに分割\n",
    "half = round(N_SAMPLES / 2)  # サンプル数の半分を計算\n",
    "sub1 = data.iloc[0:half].copy()  # 最初の半分をコピー\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 残りの半分をコピー\n",
    "\n",
    "# スレッドで推論を実行する関数を定義\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)  # 指定したインデックスに推論結果を格納\n",
    "\n",
    "# スレッドからの結果を格納する辞書を初期化\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81daf940",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# start threads\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))\n",
    "\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# Combine results back into the original DataFrame\n",
    "data = pd.concat([results[0], results[1]], axis=0)\n",
    "\n",
    "print(f\"Processing complete. Total time: {time.time() - st}\")\n",
    "\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "sample_sub[TARGETS] = data[TARGETS]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# スレッドを開始\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # サブセット1の推論を実行するスレッド\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # サブセット2の推論を実行するスレッド\n",
    "\n",
    "t0.start()  # スレッド0を開始\n",
    "t1.start()  # スレッド1を開始\n",
    "\n",
    "# すべてのスレッドが終了するのを待機\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 推論結果を元のデータフレームに統合\n",
    "data = pd.concat([results[0], results[1]], axis=0)\n",
    "\n",
    "# 処理が完了したことを出力\n",
    "print(f\"処理が完了しました。総時間: {time.time() - st}\")\n",
    "\n",
    "# 提出ファイル用のターゲットを設定\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# サンプル提出データフレームに結果を追加\n",
    "sample_sub[TARGETS] = data[TARGETS]\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:46.254967Z",
     "iopub.status.busy": "2024-07-24T12:11:46.254637Z",
     "iopub.status.idle": "2024-07-24T12:11:49.096809Z",
     "shell.execute_reply": "2024-07-24T12:11:49.095876Z",
     "shell.execute_reply.started": "2024-07-24T12:11:46.254942Z"
    }
   },
   "outputs": [],
   "source": [
    "# スレッドを開始\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # サブセット1の推論を実行するスレッド\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # サブセット2の推論を実行するスレッド\n",
    "\n",
    "t0.start()  # スレッド0を開始\n",
    "t1.start()  # スレッド1を開始\n",
    "\n",
    "# すべてのスレッドが終了するのを待機\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 推論結果を元のデータフレームに統合\n",
    "data = pd.concat([results[0], results[1]], axis=0)\n",
    "\n",
    "# 処理が完了したことを出力\n",
    "print(f\"処理が完了しました。総時間: {time.time() - st}\")\n",
    "\n",
    "# 提出ファイル用のターゲットを設定\n",
    "TARGETS = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# サンプル提出データフレームに結果を追加\n",
    "sample_sub[TARGETS] = data[TARGETS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f7df1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "llama_preds = data[TARGETS].values\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ターゲットの結果をNumPy配列に変換\n",
    "llama_preds = data[TARGETS].values  # 予測結果を取得し、NumPy配列に格納\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:49.098847Z",
     "iopub.status.busy": "2024-07-24T12:11:49.098545Z",
     "iopub.status.idle": "2024-07-24T12:11:49.103965Z",
     "shell.execute_reply": "2024-07-24T12:11:49.103005Z",
     "shell.execute_reply.started": "2024-07-24T12:11:49.098822Z"
    }
   },
   "outputs": [],
   "source": [
    "# ターゲットの結果をNumPy配列に変換\n",
    "llama_preds = data[TARGETS].values  # 予測結果を取得し、NumPy配列に格納"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38bd257",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## LGBM + tfidf\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## LGBM + TF-IDF\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4871f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os\n",
    "RUNPOD = os.path.exists('/workspace/')\n",
    "KAGGLE = not RUNPOD\n",
    "if KAGGLE: print('kaggle')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# コンペティションのタグを設定\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "# RUNPOD 環境であるかをチェック\n",
    "RUNPOD = os.path.exists('/workspace/')  \n",
    "# Kaggle 環境かどうかを設定\n",
    "KAGGLE = not RUNPOD  \n",
    "if KAGGLE: \n",
    "    print('kaggle')  # Kaggle環境の場合、メッセージを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:51.044986Z",
     "iopub.status.busy": "2024-07-24T12:11:51.044554Z",
     "iopub.status.idle": "2024-07-24T12:11:51.050748Z",
     "shell.execute_reply": "2024-07-24T12:11:51.04996Z",
     "shell.execute_reply.started": "2024-07-24T12:11:51.044954Z"
    }
   },
   "outputs": [],
   "source": [
    "# コンペティションのタグを設定\n",
    "TAG = 'lmsys-chatbot-arena'\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "# RUNPOD 環境であるかをチェック\n",
    "RUNPOD = os.path.exists('/workspace/')  \n",
    "# Kaggle 環境かどうかを設定\n",
    "KAGGLE = not RUNPOD  \n",
    "if KAGGLE: \n",
    "    print('kaggle')  # Kaggle環境の場合、メッセージを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64211417",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    !pip install -q kaggle\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm \n",
    "    !pip install -q protobuf \n",
    "    !pip install -q numba\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# pandasライブラリをインポートを試みる\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    # pandasがインポートできなかった場合は、必要なライブラリをインストール\n",
    "    !pip install -q kaggle  # Kaggleライブラリをインストール\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理と可視化に必要なライブラリをインストール\n",
    "    !pip install -q protobuf  # protobufライブラリをインストール\n",
    "    !pip install -q numba  # numbaライブラリをインストール\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:52.15405Z",
     "iopub.status.busy": "2024-07-24T12:11:52.153451Z",
     "iopub.status.idle": "2024-07-24T12:11:52.161817Z",
     "shell.execute_reply": "2024-07-24T12:11:52.160899Z",
     "shell.execute_reply.started": "2024-07-24T12:11:52.154018Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandasライブラリをインポートを試みる\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    # pandasがインポートできなかった場合は、必要なライブラリをインストール\n",
    "    !pip install -q kaggle  # Kaggleライブラリをインストール\n",
    "    !pip install -q pandas matplotlib scipy joblib scikit-learn lightgbm  # データ処理と可視化に必要なライブラリをインストール\n",
    "    !pip install -q protobuf  # protobufライブラリをインストール\n",
    "    !pip install -q numba  # numbaライブラリをインストール"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461b0c9b",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)\n",
    "\n",
    "import os\n",
    "\n",
    "if RUNPOD:\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json\n",
    "        !chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/ \n",
    "        \n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')    \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データのパスを設定\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "\n",
    "# RUNPOD環境での処理\n",
    "if RUNPOD:\n",
    "    # Kaggleの認証ファイルが存在しない場合\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # kaggleディレクトリを作成\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # kaggle.jsonをコピー\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # ファイルのアクセス権を設定\n",
    "\n",
    "    # Kaggleのデータセットが存在しない場合\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleからデータセットをダウンロード\n",
    "        \n",
    "    # データがまだ存在しない場合\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile  # zipfileモジュールをインポート\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:53.202169Z",
     "iopub.status.busy": "2024-07-24T12:11:53.200992Z",
     "iopub.status.idle": "2024-07-24T12:11:53.216958Z",
     "shell.execute_reply": "2024-07-24T12:11:53.216098Z",
     "shell.execute_reply.started": "2024-07-24T12:11:53.202129Z"
    }
   },
   "outputs": [],
   "source": [
    "# データのパスを設定\n",
    "DATA = '/data/' if RUNPOD else 'data/' \\\n",
    "        if not os.path.exists('/kaggle/') \\\n",
    "            else '/kaggle/input/{}/'.format(TAG)\n",
    "\n",
    "import os  # osモジュールをインポート\n",
    "\n",
    "# RUNPOD環境での処理\n",
    "if RUNPOD:\n",
    "    # Kaggleの認証ファイルが存在しない場合\n",
    "    if not os.path.exists('~/.kaggle/kaggle.json'):\n",
    "        !mkdir -p ~/.kaggle  # kaggleディレクトリを作成\n",
    "        !cp /workspace/kaggle.json ~/.kaggle/kaggle.json  # kaggle.jsonをコピー\n",
    "        !chmod 600 /root/.kaggle/kaggle.json  # ファイルのアクセス権を設定\n",
    "\n",
    "    # Kaggleのデータセットが存在しない場合\n",
    "    if not os.path.exists('/workspace/' + TAG + '.zip'):\n",
    "        !kaggle competitions download $TAG -p /workspace/  # Kaggleからデータセットをダウンロード\n",
    "        \n",
    "    # データがまだ存在しない場合\n",
    "    if not os.path.exists('/data/'):\n",
    "        import zipfile  # zipfileモジュールをインポート\n",
    "        zipfile.ZipFile('/workspace/' + TAG + '.zip').extractall('/data/')  # ZIPファイルを解凍"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64845fc8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "INPUT_PATH = '/kaggle/input/'  \n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "# MODEL_PATH = MODEL_PATH if not KAGGLE else ''#MODEL_PATH + os.listdir(MODEL_PATH)[0] + '/'\n",
    "print(MODEL_PATH)\n",
    "\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 入力パス、モデルパス、ロジットパスを設定\n",
    "INPUT_PATH = '/kaggle/input/'  \n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'\n",
    "\n",
    "# Kaggle環境の場合のモデルパスの設定\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "\n",
    "# モデルパスを出力\n",
    "print(MODEL_PATH)\n",
    "\n",
    "# コードパスと保存パスの設定\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:54.208891Z",
     "iopub.status.busy": "2024-07-24T12:11:54.208239Z",
     "iopub.status.idle": "2024-07-24T12:11:54.215323Z",
     "shell.execute_reply": "2024-07-24T12:11:54.214327Z",
     "shell.execute_reply.started": "2024-07-24T12:11:54.20886Z"
    }
   },
   "outputs": [],
   "source": [
    "# 入力パス、モデルパス、ロジットパスを設定\n",
    "INPUT_PATH = '/kaggle/input/'  \n",
    "MODEL_PATH = '/workspace/models/'; LOGITS_PATH = '/workspace/logits/'\n",
    "\n",
    "# Kaggle環境の場合のモデルパスの設定\n",
    "MODEL_PATH = MODEL_PATH if not KAGGLE else '/kaggle/input/' \\\n",
    "                + [e for e in os.listdir('/kaggle/input') if 'lsys-models' in e][0] + '/'\n",
    "\n",
    "# モデルパスを出力\n",
    "print(MODEL_PATH)\n",
    "\n",
    "# コードパスと保存パスの設定\n",
    "CODE_PATH = MODEL_PATH if KAGGLE else '/workspace/'\n",
    "SAVE_PATH = MODEL_PATH if not KAGGLE else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37973a7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーの並列処理を無効にするための環境変数を設定\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:55.364878Z",
     "iopub.status.busy": "2024-07-24T12:11:55.364195Z",
     "iopub.status.idle": "2024-07-24T12:11:55.369156Z",
     "shell.execute_reply": "2024-07-24T12:11:55.368236Z",
     "shell.execute_reply.started": "2024-07-24T12:11:55.364845Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーの並列処理を無効にするための環境変数を設定\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91901a53",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')\n",
    "\n",
    "print(len(train), len(test))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニングデータ、テストデータ、サンプル提出ファイルをCSVから読み込む\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # トレーニングデータを読み込む\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))    # テストデータを読み込む\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込む\n",
    "\n",
    "# トレーニングデータとテストデータのサンプル数を出力\n",
    "print(len(train), len(test))\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:56.363914Z",
     "iopub.status.busy": "2024-07-24T12:11:56.363142Z",
     "iopub.status.idle": "2024-07-24T12:11:59.61088Z",
     "shell.execute_reply": "2024-07-24T12:11:59.609557Z",
     "shell.execute_reply.started": "2024-07-24T12:11:56.36388Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータ、テストデータ、サンプル提出ファイルをCSVから読み込む\n",
    "train = pd.read_csv(open(DATA + 'train.csv', 'r'))  # トレーニングデータを読み込む\n",
    "test = pd.read_csv(open(DATA + 'test.csv', 'r'))    # テストデータを読み込む\n",
    "sample = pd.read_csv(DATA + 'sample_submission.csv')  # サンプル提出データを読み込む\n",
    "\n",
    "# トレーニングデータとテストデータのサンプル数を出力\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211e8d7f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "params = {}\n",
    "if False:#len(test) < 10: \n",
    "    pass;\n",
    "    params['subsample'] = 30\n",
    "else:\n",
    "    # params['subsample'] = 2\n",
    "    params['fold'] = -1\n",
    "\n",
    "\n",
    "params['n_epochs'] = 1\n",
    "params['n_lgb'] = 1\n",
    "params['model'] = 'microsoft/deberta-v3-small'\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルのパラメータを設定\n",
    "params = {}\n",
    "if False:  # テストデータの長さが10未満でない限り\n",
    "    pass;\n",
    "    params['subsample'] = 30  # サブサンプルサイズを30に設定\n",
    "else:\n",
    "    # params['subsample'] = 2  # サブサンプルサイズを2に設定（コメントアウト）\n",
    "    params['fold'] = -1  # フォールド設定を-1に設定\n",
    "\n",
    "# エポック数とLightGBMのモデル数を設定\n",
    "params['n_epochs'] = 1  # エポック数を1に設定\n",
    "params['n_lgb'] = 1  # 使用するLightGBMのモデル数を1に設定\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルを指定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:59.613705Z",
     "iopub.status.busy": "2024-07-24T12:11:59.612829Z",
     "iopub.status.idle": "2024-07-24T12:11:59.618275Z",
     "shell.execute_reply": "2024-07-24T12:11:59.617456Z",
     "shell.execute_reply.started": "2024-07-24T12:11:59.613677Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのパラメータを設定\n",
    "params = {}\n",
    "if False:  # テストデータの長さが10未満でない限り\n",
    "    pass;\n",
    "    params['subsample'] = 30  # サブサンプルサイズを30に設定\n",
    "else:\n",
    "    # params['subsample'] = 2  # サブサンプルサイズを2に設定（コメントアウト）\n",
    "    params['fold'] = -1  # フォールド設定を-1に設定\n",
    "\n",
    "# エポック数とLightGBMのモデル数を設定\n",
    "params['n_epochs'] = 1  # エポック数を1に設定\n",
    "params['n_lgb'] = 1  # 使用するLightGBMのモデル数を1に設定\n",
    "params['model'] = 'microsoft/deberta-v3-small'  # 使用するモデルを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0ff62",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# params = {}\n",
    "FULL = params.get('fold', 0) < 0\n",
    "N_FOLDS = int(params.get('n_folds', 3)); \n",
    "FOLD = int(params.get('fold', 0))\n",
    "SEED = int(params.get('seed', 3))\n",
    "SS = int(params.get('subsample', 1))\n",
    "\n",
    "print(N_FOLDS, FOLD, SEED, SS)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# パラメータの設定を確認\n",
    "FULL = params.get('fold', 0) < 0  # フォールドの値が0未満ならFULLをTrueに設定\n",
    "N_FOLDS = int(params.get('n_folds', 3))  # フォールド数を取得（デフォルトは3）\n",
    "FOLD = int(params.get('fold', 0))  # 現在のフォールドを取得（デフォルトは0）\n",
    "SEED = int(params.get('seed', 3))  # シード値を取得（デフォルトは3）\n",
    "SS = int(params.get('subsample', 1))  # サブサンプルサイズを取得（デフォルトは1）\n",
    "\n",
    "# 設定したパラメータを出力\n",
    "print(N_FOLDS, FOLD, SEED, SS)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:59.620886Z",
     "iopub.status.busy": "2024-07-24T12:11:59.620596Z",
     "iopub.status.idle": "2024-07-24T12:11:59.632249Z",
     "shell.execute_reply": "2024-07-24T12:11:59.631398Z",
     "shell.execute_reply.started": "2024-07-24T12:11:59.620852Z"
    }
   },
   "outputs": [],
   "source": [
    "# パラメータの設定を確認\n",
    "FULL = params.get('fold', 0) < 0  # フォールドの値が0未満ならFULLをTrueに設定\n",
    "N_FOLDS = int(params.get('n_folds', 3))  # フォールド数を取得（デフォルトは3）\n",
    "FOLD = int(params.get('fold', 0))  # 現在のフォールドを取得（デフォルトは0）\n",
    "SEED = int(params.get('seed', 3))  # シード値を取得（デフォルトは3）\n",
    "SS = int(params.get('subsample', 1))  # サブサンプルサイズを取得（デフォルトは1）\n",
    "\n",
    "# 設定したパラメータを出力\n",
    "print(N_FOLDS, FOLD, SEED, SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605d9db6",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state = SEED, shuffle = True)\\\n",
    "                    .split(X = np.zeros(len(train)), y = train.iloc[:, -3:].idxmax(1)))\n",
    "\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "if SS > 1: train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "print(len(train_ids), len(test_ids));  assert set(train_ids) & set(test_ids) == set() \n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldをインポート\n",
    "\n",
    "# フォールドを生成する関数を定義\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)\\\n",
    "                    .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # StratifiedKFoldで分割\n",
    "\n",
    "# 現在のフォールドに基づいてトレーニングIDとテストIDを取得\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# サブサンプルサイズが1より大きい場合、インデックスをサンプリング\n",
    "if SS > 1: \n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# トレーニングIDとテストIDの長さを出力し、重複がないことを確認\n",
    "print(len(train_ids), len(test_ids));  \n",
    "assert set(train_ids) & set(test_ids) == set()  # トレーニングIDとテストIDに重複がないことを確認\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:59.634137Z",
     "iopub.status.busy": "2024-07-24T12:11:59.633871Z",
     "iopub.status.idle": "2024-07-24T12:11:59.66221Z",
     "shell.execute_reply": "2024-07-24T12:11:59.661402Z",
     "shell.execute_reply.started": "2024-07-24T12:11:59.634113Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold  # StratifiedKFoldをインポート\n",
    "\n",
    "# フォールドを生成する関数を定義\n",
    "def get_folds(train): \n",
    "    return list(StratifiedKFold(N_FOLDS, random_state=SEED, shuffle=True)\\\n",
    "                    .split(X=np.zeros(len(train)), y=train.iloc[:, -3:].idxmax(1)))  # StratifiedKFoldで分割\n",
    "\n",
    "# 現在のフォールドに基づいてトレーニングIDとテストIDを取得\n",
    "train_ids, test_ids = get_folds(train)[FOLD] if not FULL else [list(range(len(train))), []]\n",
    "# サブサンプルサイズが1より大きい場合、インデックスをサンプリング\n",
    "if SS > 1: \n",
    "    train_ids, test_ids = train_ids[::SS], test_ids[::SS]\n",
    "\n",
    "# トレーニングIDとテストIDの長さを出力し、重複がないことを確認\n",
    "print(len(train_ids), len(test_ids));  \n",
    "assert set(train_ids) & set(test_ids) == set()  # トレーニングIDとテストIDに重複がないことを確認"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e225f5f1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def join_strings(x, ):\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x\n",
    "    return x\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# リスト内の文字列を結合する関数を定義\n",
    "def join_strings(x):\n",
    "    # xがリストの場合、要素を結合して1つの文字列にする\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x\n",
    "    return x  # 結合された文字列またはそのままのxを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:11:59.976431Z",
     "iopub.status.busy": "2024-07-24T12:11:59.976092Z",
     "iopub.status.idle": "2024-07-24T12:11:59.981269Z",
     "shell.execute_reply": "2024-07-24T12:11:59.980159Z",
     "shell.execute_reply.started": "2024-07-24T12:11:59.976405Z"
    }
   },
   "outputs": [],
   "source": [
    "# リスト内の文字列を結合する関数を定義\n",
    "def join_strings(x):\n",
    "    # xがリストの場合、要素を結合して1つの文字列にする\n",
    "    x = ' '.join(['' if e is None else e for e in x]) if isinstance(x, list) else x\n",
    "    return x  # 結合された文字列またはそのままのxを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5dfe7e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def len_join_strings(x, ):\n",
    "    return len(join_strings(x).split())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結合された文字列の単語数を返す関数を定義\n",
    "def len_join_strings(x):\n",
    "    # join_strings関数を使って文字列を結合し、単語数をカウントして返す\n",
    "    return len(join_strings(x).split())  # 結合された文字列を空白で分割し、その長さを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:01.098757Z",
     "iopub.status.busy": "2024-07-24T12:12:01.09814Z",
     "iopub.status.idle": "2024-07-24T12:12:01.105381Z",
     "shell.execute_reply": "2024-07-24T12:12:01.104535Z",
     "shell.execute_reply.started": "2024-07-24T12:12:01.098727Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結合された文字列の単語数を返す関数を定義\n",
    "def len_join_strings(x):\n",
    "    # join_strings関数を使って文字列を結合し、単語数をカウントして返す\n",
    "    return len(join_strings(x).split())  # 結合された文字列を空白で分割し、その長さを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda48ffd",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def len_join_strings_j(x):\n",
    "    x = json.loads(x)\n",
    "    return len_join_strings(x)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# JSON形式の文字列を読み込み、結合された文字列の単語数を返す関数を定義\n",
    "def len_join_strings_j(x):\n",
    "    # JSON文字列をPythonオブジェクトに変換\n",
    "    x = json.loads(x)\n",
    "    # len_join_strings関数を使用して単語数を返す\n",
    "    return len_join_strings(x)  # 結合された文字列の単語数を返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:02.038287Z",
     "iopub.status.busy": "2024-07-24T12:12:02.037941Z",
     "iopub.status.idle": "2024-07-24T12:12:02.042755Z",
     "shell.execute_reply": "2024-07-24T12:12:02.041845Z",
     "shell.execute_reply.started": "2024-07-24T12:12:02.038241Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSON形式の文字列を読み込み、結合された文字列の単語数を返す関数を定義\n",
    "def len_join_strings_j(x):\n",
    "    # JSON文字列をPythonオブジェクトに変換\n",
    "    x = json.loads(x)\n",
    "    # len_join_strings関数を使用して単語数を返す\n",
    "    return len_join_strings(x)  # 結合された文字列の単語数を返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215d6b5a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)\n",
    "random.seed(datetime.datetime.now().microsecond)\n",
    "np.random.seed(datetime.datetime.now().microsecond)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ランダムシードを設定\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:02.903973Z",
     "iopub.status.busy": "2024-07-24T12:12:02.903114Z",
     "iopub.status.idle": "2024-07-24T12:12:02.909451Z",
     "shell.execute_reply": "2024-07-24T12:12:02.908312Z",
     "shell.execute_reply.started": "2024-07-24T12:12:02.903938Z"
    }
   },
   "outputs": [],
   "source": [
    "# ランダムシードを設定\n",
    "torch.manual_seed(datetime.datetime.now().microsecond)  # PyTorchのシードを設定\n",
    "random.seed(datetime.datetime.now().microsecond)  # Pythonのrandomモジュールのシードを設定\n",
    "np.random.seed(datetime.datetime.now().microsecond)  # NumPyのシードを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dadd43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# TRAIN = True and not KAGGLE\n",
    "TRAIN = False\n",
    "INFER = True # or KAGGLE \n",
    "SAVE = False\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トレーニング、推論、保存のフラグを設定\n",
    "# TRAIN = True and not KAGGLE  # 学習を行うかどうかのフラグ（Kaggleでは行わない場合はTrue）\n",
    "TRAIN = False  # トレーニングを行わない設定\n",
    "INFER = True  # 推論を行う設定（Kaggleでは行う場合もTrue）\n",
    "SAVE = False  # 保存を行わない設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:03.970416Z",
     "iopub.status.busy": "2024-07-24T12:12:03.96976Z",
     "iopub.status.idle": "2024-07-24T12:12:03.975137Z",
     "shell.execute_reply": "2024-07-24T12:12:03.974274Z",
     "shell.execute_reply.started": "2024-07-24T12:12:03.970382Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニング、推論、保存のフラグを設定\n",
    "# TRAIN = True and not KAGGLE  # 学習を行うかどうかのフラグ（Kaggleでは行わない場合はTrue）\n",
    "TRAIN = False  # トレーニングを行わない設定\n",
    "INFER = True  # 推論を行う設定（Kaggleでは行う場合もTrue）\n",
    "SAVE = False  # 保存を行わない設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203b343",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMライブラリとテキストのカウントベクタイザーをインポート\n",
    "import lightgbm as lgb  # LightGBMをインポート\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # CountVectorizerをインポート\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:04.865127Z",
     "iopub.status.busy": "2024-07-24T12:12:04.864772Z",
     "iopub.status.idle": "2024-07-24T12:12:07.509471Z",
     "shell.execute_reply": "2024-07-24T12:12:07.508461Z",
     "shell.execute_reply.started": "2024-07-24T12:12:04.865099Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBMライブラリとテキストのカウントベクタイザーをインポート\n",
    "import lightgbm as lgb  # LightGBMをインポート\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # CountVectorizerをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efca8af",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "LGB = True\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0\n",
    "INFER_LGB = not TRAIN and LGB\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMのトレーニングおよび推論フラグを設定\n",
    "LGB = True  # LightGBMを使用する設定\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # トレーニングの条件を満たすかどうか\n",
    "INFER_LGB = not TRAIN and LGB  # 推論を行う条件を設定\n",
    "\n",
    "# 保存されたカウントベクタイザーを読み込む\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # 通常のカウントベクタイザーを読み込む\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # クリーンカウントベクタイザーを読み込む\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:07.512598Z",
     "iopub.status.busy": "2024-07-24T12:12:07.511426Z",
     "iopub.status.idle": "2024-07-24T12:12:17.245555Z",
     "shell.execute_reply": "2024-07-24T12:12:17.244657Z",
     "shell.execute_reply.started": "2024-07-24T12:12:07.512563Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBMのトレーニングおよび推論フラグを設定\n",
    "LGB = True  # LightGBMを使用する設定\n",
    "TRAIN_LGB = TRAIN and LGB and params.get('n_lgb', 1) > 0  # トレーニングの条件を満たすかどうか\n",
    "INFER_LGB = not TRAIN and LGB  # 推論を行う条件を設定\n",
    "\n",
    "# 保存されたカウントベクタイザーを読み込む\n",
    "cvec  = pickle.load(open(MODEL_PATH + 'cvec.pkl', 'rb'))  # 通常のカウントベクタイザーを読み込む\n",
    "ccvec = pickle.load(open(MODEL_PATH + 'ccvec.pkl', 'rb'))  # クリーンカウントベクタイザーを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05061002",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def symlog(x): return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)\n",
    "\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())\n",
    "    x = symlog(x)\n",
    "    return x\n",
    "\n",
    "def get_features(df):\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    v = np.hstack([\n",
    "    # pfeat, \n",
    "          afeat - bfeat, np.abs(afeat - bfeat), \n",
    "    # afeat + bfeat\n",
    "        ])\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)\n",
    "    except: pass\n",
    "\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)\n",
    "            \n",
    "    extras.append(df[c].str.len())\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))\n",
    "    \n",
    "    extras = np.stack(extras, axis = 1)\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])\n",
    "    return np.hstack([v, extras])\n",
    "    # return v\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# シンログ変換を行う関数を定義\n",
    "def symlog(x): \n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # シンログ変換を適用\n",
    "\n",
    "# 密な行列に変換してシンログ変換を行う関数を定義\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 密な行列に変換\n",
    "    x = symlog(x)  # シンログ変換を適用\n",
    "    return x  # 変換後の行列を返す\n",
    "\n",
    "# 特徴量を取得するための関数を定義\n",
    "def get_features(df):\n",
    "    # プロンプトの特徴量を取得\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])\n",
    "    \n",
    "    # 応答Aの特徴量を取得\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # 応答Bの特徴量を取得\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # 特徴量を結合\n",
    "    v = np.hstack([\n",
    "          # pfeat,  # プロンプトの特徴量を含める場合のコメント\n",
    "          afeat - bfeat,  # 応答Aと応答Bの差分\n",
    "          np.abs(afeat - bfeat),  # 応答Aと応答Bの絶対差\n",
    "          # afeat + bfeat  # 応答Aと応答Bの和を含める場合のコメント\n",
    "        ])\n",
    "    \n",
    "    # 全投票モデルの数で正規化\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)  # データフレームの長さに基づいて正規化\n",
    "    except: \n",
    "        pass  # エラーが発生した場合は無視\n",
    "\n",
    "    # 追加の特徴量を取得\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # 各文字列の出現回数をカウント\n",
    "            \n",
    "    # 文字列の長さと単語数を追加\n",
    "    extras.append(df[c].str.len())  # 文字列の長さ\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 単語数\n",
    "    \n",
    "    # 追加の特徴量をスタックして変換\n",
    "    extras = np.stack(extras, axis=1)  # 新たに追加された特徴量を結合\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # ルートとログ変換を適用\n",
    "    \n",
    "    # 結合した特徴量を返す\n",
    "    return np.hstack([v, extras])  # 基本特徴量と追加特徴量を結合して返す\n",
    "    # return v  # 基本特徴量のみを返す場合のコメント\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:17.247059Z",
     "iopub.status.busy": "2024-07-24T12:12:17.246735Z",
     "iopub.status.idle": "2024-07-24T12:12:18.471764Z",
     "shell.execute_reply": "2024-07-24T12:12:18.470786Z",
     "shell.execute_reply.started": "2024-07-24T12:12:17.247034Z"
    }
   },
   "outputs": [],
   "source": [
    "# シンログ変換を行う関数を定義\n",
    "def symlog(x): \n",
    "    return (np.sign(x) * np.log1p(np.abs(x))).astype(np.float32)  # シンログ変換を適用\n",
    "\n",
    "# 密な行列に変換してシンログ変換を行う関数を定義\n",
    "def dense(x):\n",
    "    x = np.asarray(x.astype(np.float32).todense())  # 密な行列に変換\n",
    "    x = symlog(x)  # シンログ変換を適用\n",
    "    return x  # 変換後の行列を返す\n",
    "\n",
    "# 特徴量を取得するための関数を定義\n",
    "def get_features(df):\n",
    "    # プロンプトの特徴量を取得\n",
    "    pfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for v in [cvec, ccvec]\n",
    "                    for c in ['prompt', ]])\n",
    "    \n",
    "    # 応答Aの特徴量を取得\n",
    "    afeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_a', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # 応答Bの特徴量を取得\n",
    "    bfeat = np.hstack([dense(v.transform(df[c])) \n",
    "                for c in ['response_b', ]\n",
    "                    for v in [cvec, ccvec]\n",
    "                ])\n",
    "    \n",
    "    # 特徴量を結合\n",
    "    v = np.hstack([\n",
    "          # pfeat,  # プロンプトの特徴量を含める場合のコメント\n",
    "          afeat - bfeat,  # 応答Aと応答Bの差分\n",
    "          np.abs(afeat - bfeat),  # 応答Aと応答Bの絶対差\n",
    "          # afeat + bfeat  # 応答Aと応答Bの和を含める場合のコメント\n",
    "        ])\n",
    "    \n",
    "    # 全投票モデルの数で正規化\n",
    "    try: \n",
    "        v = v / (len(all_vote_models) if len(df) < len(train) else 1)  # データフレームの長さに基づいて正規化\n",
    "    except: \n",
    "        pass  # エラーが発生した場合は無視\n",
    "\n",
    "    # 追加の特徴量を取得\n",
    "    extras = []\n",
    "    EXTRAS = ['\\n', '\\n\\n', '.', ' ', '\",\"']\n",
    "    for e in EXTRAS:\n",
    "        for c in ['prompt', 'response_a', 'response_b']:\n",
    "            extras.append(df[c].str.count(e).values)  # 各文字列の出現回数をカウント\n",
    "            \n",
    "    # 文字列の長さと単語数を追加\n",
    "    extras.append(df[c].str.len())  # 文字列の長さ\n",
    "    extras.append(df[c].str.split().apply(lambda x: len(x)))  # 単語数\n",
    "    \n",
    "    # 追加の特徴量をスタックして変換\n",
    "    extras = np.stack(extras, axis=1)  # 新たに追加された特徴量を結合\n",
    "    extras = np.hstack([extras ** 0.5, np.log1p(extras)])  # ルートとログ変換を適用\n",
    "    \n",
    "    # 結合した特徴量を返す\n",
    "    return np.hstack([v, extras])  # 基本特徴量と追加特徴量を結合して返す\n",
    "    # return v  # 基本特徴量のみを返す場合のコメント"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebaaf59",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 保存されたLightGBMモデルを読み込む\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込んで変数に格納\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:18.474527Z",
     "iopub.status.busy": "2024-07-24T12:12:18.474066Z",
     "iopub.status.idle": "2024-07-24T12:12:18.598137Z",
     "shell.execute_reply": "2024-07-24T12:12:18.597093Z",
     "shell.execute_reply.started": "2024-07-24T12:12:18.474494Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存されたLightGBMモデルを読み込む\n",
    "lgb_models = pickle.load(open(MODEL_PATH + 'lgb_models.pkl', 'rb'))  # LightGBMモデルを読み込んで変数に格納"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020a4dfe",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test\n",
    "    yps = []; b = 1000\n",
    "    for i in range(0, len(df), b):\n",
    "        arr = get_features(df.iloc[i: i + b])\n",
    "        ypms = []\n",
    "        for model in lgb_models:\n",
    "            ypms.append(model.predict_proba(arr))\n",
    "        yps.append(np.stack(ypms).mean(0))\n",
    "        # break;\n",
    "        print('.', end = '')\n",
    "        \n",
    "        if len(yps) % 2 == 0:\n",
    "            gc.collect()\n",
    "    print()\n",
    "\n",
    "    yp = np.concatenate(yps)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行う条件が満たされている場合\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータをdfに設定\n",
    "    yps = []  # 予測結果を格納するリストを初期化\n",
    "    b = 1000  # バッチサイズを設定\n",
    "    for i in range(0, len(df), b):  # バッチ処理でデータを処理\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得\n",
    "        ypms = []  # 各モデルの予測値を格納するリストを初期化\n",
    "        for model in lgb_models:  # 各LightGBMモデルに対して予測\n",
    "            ypms.append(model.predict_proba(arr))  # 予測確率を取得\n",
    "            \n",
    "        yps.append(np.stack(ypms).mean(0))  # モデルの予測値を平均してリストに追加\n",
    "        # break;  # ループを中断する場合のコメント\n",
    "        print('.', end = '')  # 進行状況を表示\n",
    "        \n",
    "        # 指定した条件ごとにガベージコレクションを実行\n",
    "        if len(yps) % 2 == 0:  \n",
    "            gc.collect()  # メモリを解放\n",
    "    print()\n",
    "\n",
    "    # すべての予測結果を連結\n",
    "    yp = np.concatenate(yps)  # 予測値を一つの配列にまとめる\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:18.599906Z",
     "iopub.status.busy": "2024-07-24T12:12:18.599368Z",
     "iopub.status.idle": "2024-07-24T12:12:19.862494Z",
     "shell.execute_reply": "2024-07-24T12:12:19.861488Z",
     "shell.execute_reply.started": "2024-07-24T12:12:18.599877Z"
    }
   },
   "outputs": [],
   "source": [
    "# 推論を行う条件が満たされている場合\n",
    "if INFER and params.get('n_lgb', 1) > 0:\n",
    "    df = test  # テストデータをdfに設定\n",
    "    yps = []  # 予測結果を格納するリストを初期化\n",
    "    b = 1000  # バッチサイズを設定\n",
    "    for i in range(0, len(df), b):  # バッチ処理でデータを処理\n",
    "        arr = get_features(df.iloc[i: i + b])  # 特徴量を取得\n",
    "        ypms = []  # 各モデルの予測値を格納するリストを初期化\n",
    "        for model in lgb_models:  # 各LightGBMモデルに対して予測\n",
    "            ypms.append(model.predict_proba(arr))  # 予測確率を取得\n",
    "            \n",
    "        yps.append(np.stack(ypms).mean(0))  # モデルの予測値を平均してリストに追加\n",
    "        # break;  # ループを中断する場合のコメント\n",
    "        print('.', end = '')  # 進行状況を表示\n",
    "        \n",
    "        # 指定した条件ごとにガベージコレクションを実行\n",
    "        if len(yps) % 2 == 0:  \n",
    "            gc.collect()  # メモリを解放\n",
    "    print()\n",
    "\n",
    "    # すべての予測結果を連結\n",
    "    yp = np.concatenate(yps)  # 予測値を一つの配列にまとめる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b9a4ca",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_preds = yp\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMモデルによる予測結果を変数に格納\n",
    "lgb_preds = yp  # 予測値をlgb_predsに設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:19.863785Z",
     "iopub.status.busy": "2024-07-24T12:12:19.863509Z",
     "iopub.status.idle": "2024-07-24T12:12:19.868043Z",
     "shell.execute_reply": "2024-07-24T12:12:19.866995Z",
     "shell.execute_reply.started": "2024-07-24T12:12:19.86376Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBMモデルによる予測結果を変数に格納\n",
    "lgb_preds = yp  # 予測値をlgb_predsに設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c2843",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "lgb_wt = 0.2 \n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LightGBMの予測とLLamaの予測を組み合わせて最終予測を計算\n",
    "lgb_wt = 0.2  # LightGBMの重みを設定\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # 重み付き平均を計算して最終予測を生成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:19.869933Z",
     "iopub.status.busy": "2024-07-24T12:12:19.869318Z",
     "iopub.status.idle": "2024-07-24T12:12:19.878749Z",
     "shell.execute_reply": "2024-07-24T12:12:19.877971Z",
     "shell.execute_reply.started": "2024-07-24T12:12:19.869899Z"
    }
   },
   "outputs": [],
   "source": [
    "# LightGBMの予測とLLamaの予測を組み合わせて最終予測を計算\n",
    "lgb_wt = 0.2  # LightGBMの重みを設定\n",
    "preds = lgb_wt * lgb_preds + (1 - lgb_wt) * llama_preds  # 重み付き平均を計算して最終予測を生成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76efb554",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out = pd.DataFrame(preds, \n",
    "                index = df.id, \n",
    "                    columns = train.columns[-3:])\n",
    "display(out.head())\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終予測結果をデータフレームに変換\n",
    "out = pd.DataFrame(preds, \n",
    "                index=df.id,  # データフレームのインデックスをテストデータのIDに設定\n",
    "                columns=train.columns[-3:])  # 列名をトレーニングデータの最後の3列に設定\n",
    "\n",
    "# 最初の5行を表示\n",
    "display(out.head())  # 予測結果データフレームの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:19.880127Z",
     "iopub.status.busy": "2024-07-24T12:12:19.879866Z",
     "iopub.status.idle": "2024-07-24T12:12:19.897318Z",
     "shell.execute_reply": "2024-07-24T12:12:19.89637Z",
     "shell.execute_reply.started": "2024-07-24T12:12:19.880105Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最終予測結果をデータフレームに変換\n",
    "out = pd.DataFrame(preds, \n",
    "                index=df.id,  # データフレームのインデックスをテストデータのIDに設定\n",
    "                columns=train.columns[-3:])  # 列名をトレーニングデータの最後の3列に設定\n",
    "\n",
    "# 最初の5行を表示\n",
    "display(out.head())  # 予測結果データフレームの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3945b6",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "# Part 2 (Gemma 2 4b QLora)\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "# パート 2 (Gemma 2 4b QLora)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca85205",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "assert torch.cuda.device_count() == 2\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 使用可能なCUDAデバイスの数が2であることを確認\n",
    "assert torch.cuda.device_count() == 2  # CUDAデバイスが2つであることを確認するアサーション\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:22.985184Z",
     "iopub.status.busy": "2024-07-24T12:12:22.98444Z",
     "iopub.status.idle": "2024-07-24T12:12:22.989426Z",
     "shell.execute_reply": "2024-07-24T12:12:22.988307Z",
     "shell.execute_reply.started": "2024-07-24T12:12:22.985155Z"
    },
    "papermill": {
     "duration": 0.047799,
     "end_time": "2024-07-10T01:14:00.965921",
     "exception": false,
     "start_time": "2024-07-10T01:14:00.918122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用可能なCUDAデバイスの数が2であることを確認\n",
    "assert torch.cuda.device_count() == 2  # CUDAデバイスが2つであることを確認するアサーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4ba23",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Configurations\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 設定\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5825c5a",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Config:\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5748'\n",
    "    max_length = 2048\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False \n",
    "    spread_max_length = False \n",
    "\n",
    "cfg = Config()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 設定を格納するためのデータクラスを定義\n",
    "@dataclass\n",
    "class Config:\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'  # Gemmaモデルのディレクトリ\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5748'  # LoRaモデルのチェックポイントディレクトリ\n",
    "    max_length = 2048  # 最大入力長を2048に設定\n",
    "    batch_size = 4  # バッチサイズを4に設定\n",
    "    device = torch.device(\"cuda\")  # 使用するデバイスをCUDAに設定\n",
    "    tta = False  # テストタイムデータ拡張を無効にするフラグ\n",
    "    spread_max_length = False  # 最大長の分散を無効にするフラグ\n",
    "\n",
    "cfg = Config()  # 設定のインスタンスを作成\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:25.513642Z",
     "iopub.status.busy": "2024-07-24T12:12:25.513303Z",
     "iopub.status.idle": "2024-07-24T12:12:25.51911Z",
     "shell.execute_reply": "2024-07-24T12:12:25.518107Z",
     "shell.execute_reply.started": "2024-07-24T12:12:25.513611Z"
    },
    "papermill": {
     "duration": 0.021338,
     "end_time": "2024-07-10T01:14:01.000606",
     "exception": false,
     "start_time": "2024-07-10T01:14:00.979268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 設定を格納するためのデータクラスを定義\n",
    "@dataclass\n",
    "class Config:\n",
    "    gemma_dir = '/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit'  # Gemmaモデルのディレクトリ\n",
    "    lora_dir = '/kaggle/input/73zap2gx/checkpoint-5748'  # LoRaモデルのチェックポイントディレクトリ\n",
    "    max_length = 2048  # 最大入力長を2048に設定\n",
    "    batch_size = 4  # バッチサイズを4に設定\n",
    "    device = torch.device(\"cuda\")  # 使用するデバイスをCUDAに設定\n",
    "    tta = False  # テストタイムデータ拡張を無効にするフラグ\n",
    "    spread_max_length = False  # 最大長の分散を無効にするフラグ\n",
    "\n",
    "cfg = Config()  # 設定のインスタンスを作成"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e0c339",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load & pre-process Data \n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## データのロードと前処理\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cc753",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テストデータをCSVファイルから読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:27.335823Z",
     "iopub.status.busy": "2024-07-24T12:12:27.335459Z",
     "iopub.status.idle": "2024-07-24T12:12:27.344047Z",
     "shell.execute_reply": "2024-07-24T12:12:27.343061Z",
     "shell.execute_reply.started": "2024-07-24T12:12:27.335794Z"
    },
    "papermill": {
     "duration": 0.02967,
     "end_time": "2024-07-10T01:14:01.06946",
     "exception": false,
     "start_time": "2024-07-10T01:14:01.03979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テストデータをCSVファイルから読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7828f43",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def process_text(text: str) -> str:\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
    "\n",
    "display(test.head(5))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストを処理する関数を定義\n",
    "def process_text(text: str) -> str:\n",
    "    # テキストを評価し、空白で結合して返す\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "# 各列に対してprocess_text関数を適用\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)  # プロンプトの処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)  # 応答Aの処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)  # 応答Bの処理\n",
    "\n",
    "# 最初の5行を表示\n",
    "display(test.head(5))  # 処理後のテストデータの最初の5行を表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:28.12208Z",
     "iopub.status.busy": "2024-07-24T12:12:28.121735Z",
     "iopub.status.idle": "2024-07-24T12:12:28.136224Z",
     "shell.execute_reply": "2024-07-24T12:12:28.135461Z",
     "shell.execute_reply.started": "2024-07-24T12:12:28.122052Z"
    },
    "papermill": {
     "duration": 0.040127,
     "end_time": "2024-07-10T01:14:01.12241",
     "exception": false,
     "start_time": "2024-07-10T01:14:01.082283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テキストを処理する関数を定義\n",
    "def process_text(text: str) -> str:\n",
    "    # テキストを評価し、空白で結合して返す\n",
    "    return \" \".join(eval(text, {\"null\": \"\"}))\n",
    "\n",
    "# 各列に対してprocess_text関数を適用\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)  # プロンプトの処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)  # 応答Aの処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)  # 応答Bの処理\n",
    "\n",
    "# 最初の5行を表示\n",
    "display(test.head(5))  # 処理後のテストデータの最初の5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a7f20a",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Tokenize\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## トークナイズ\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e26788",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    # TODO: change prompt\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "    return input_ids, attention_mask\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# テキストをトークナイズする関数を定義\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    # プロンプトにプレフィックスを追加\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]  # 応答Aにプレフィックスを追加\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]  # 応答Bにプレフィックスを追加\n",
    "    \n",
    "    if spread_max_length:\n",
    "        # 最大長を分散させてトークナイズ\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # 入力IDを結合\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]  # アテンションマスクを作成\n",
    "    else:\n",
    "        # 通常のトークナイズ\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # テキストを結合\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)  # トークナイズ\n",
    "        input_ids = tokenized.input_ids  # 入力IDを取得\n",
    "        attention_mask = tokenized.attention_mask  # アテンションマスクを取得\n",
    "        \n",
    "    return input_ids, attention_mask  # 入力IDとアテンションマスクを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:29.725952Z",
     "iopub.status.busy": "2024-07-24T12:12:29.72561Z",
     "iopub.status.idle": "2024-07-24T12:12:29.734604Z",
     "shell.execute_reply": "2024-07-24T12:12:29.733731Z",
     "shell.execute_reply.started": "2024-07-24T12:12:29.725928Z"
    },
    "papermill": {
     "duration": 0.030237,
     "end_time": "2024-07-10T01:14:01.194318",
     "exception": false,
     "start_time": "2024-07-10T01:14:01.164081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# テキストをトークナイズする関数を定義\n",
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    # プロンプトにプレフィックスを追加\n",
    "    prompt = [\"<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]  # 応答Aにプレフィックスを追加\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]  # 応答Bにプレフィックスを追加\n",
    "    \n",
    "    if spread_max_length:\n",
    "        # 最大長を分散させてトークナイズ\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # 入力IDを結合\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]  # アテンションマスクを作成\n",
    "    else:\n",
    "        # 通常のトークナイズ\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]  # テキストを結合\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)  # トークナイズ\n",
    "        input_ids = tokenized.input_ids  # 入力IDを取得\n",
    "        attention_mask = tokenized.attention_mask  # アテンションマスクを取得\n",
    "        \n",
    "    return input_ids, attention_mask  # 入力IDとアテンションマスクを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b10177",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "%%time\n",
    "\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# トークナイザーの初期化とデータ処理の計測\n",
    "%%time\n",
    "\n",
    "# Gemmaトークナイザーを指定したディレクトリからロード\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加\n",
    "tokenizer.padding_side = \"right\"  # パディングを右側に設定\n",
    "\n",
    "# データフレームを初期化\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]  # テストデータのIDを設定\n",
    "# トークナイズして入力IDとアテンションマスクを取得\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)  # 入力IDの長さを取得\n",
    "\n",
    "# データの拡張用データフレームを初期化\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]  # 拡張データのIDを設定\n",
    "# 応答Aと応答Bを入れ替えてトークナイズ\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)  # 入力IDの長さを取得\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:30.52816Z",
     "iopub.status.busy": "2024-07-24T12:12:30.527078Z",
     "iopub.status.idle": "2024-07-24T12:12:31.43597Z",
     "shell.execute_reply": "2024-07-24T12:12:31.435031Z",
     "shell.execute_reply.started": "2024-07-24T12:12:30.528126Z"
    },
    "papermill": {
     "duration": 1.169844,
     "end_time": "2024-07-10T01:14:02.377579",
     "exception": false,
     "start_time": "2024-07-10T01:14:01.207735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# トークナイザーの初期化とデータ処理の計測\n",
    "%%time\n",
    "\n",
    "# Gemmaトークナイザーを指定したディレクトリからロード\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加\n",
    "tokenizer.padding_side = \"right\"  # パディングを右側に設定\n",
    "\n",
    "# データフレームを初期化\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]  # テストデータのIDを設定\n",
    "# トークナイズして入力IDとアテンションマスクを取得\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)  # 入力IDの長さを取得\n",
    "\n",
    "# データの拡張用データフレームを初期化\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]  # 拡張データのIDを設定\n",
    "# 応答Aと応答Bを入れ替えてトークナイズ\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)  # 入力IDの長さを取得"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868cae0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(tokenizer.decode(data[\"input_ids\"][0]))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最初の入力IDをデコードして人間が読める形式に変換し、表示\n",
    "print(tokenizer.decode(data[\"input_ids\"][0]))  # 最初の入力IDをデコードして出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:32.184013Z",
     "iopub.status.busy": "2024-07-24T12:12:32.183193Z",
     "iopub.status.idle": "2024-07-24T12:12:32.190035Z",
     "shell.execute_reply": "2024-07-24T12:12:32.189059Z",
     "shell.execute_reply.started": "2024-07-24T12:12:32.183978Z"
    },
    "papermill": {
     "duration": 0.024759,
     "end_time": "2024-07-10T01:14:02.419091",
     "exception": false,
     "start_time": "2024-07-10T01:14:02.394332",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 最初の入力IDをデコードして人間が読める形式に変換し、表示\n",
    "print(tokenizer.decode(data[\"input_ids\"][0]))  # 最初の入力IDをデコードして出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad34e1",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 拡張データの最初の入力IDをデコードして人間が読める形式に変換し、表示\n",
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))  # 拡張データの最初の入力IDをデコードして出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:32.955751Z",
     "iopub.status.busy": "2024-07-24T12:12:32.955045Z",
     "iopub.status.idle": "2024-07-24T12:12:32.961638Z",
     "shell.execute_reply": "2024-07-24T12:12:32.960556Z",
     "shell.execute_reply.started": "2024-07-24T12:12:32.95572Z"
    },
    "papermill": {
     "duration": 0.021982,
     "end_time": "2024-07-10T01:14:02.454045",
     "exception": false,
     "start_time": "2024-07-10T01:14:02.432063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 拡張データの最初の入力IDをデコードして人間が読める形式に変換し、表示\n",
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))  # 拡張データの最初の入力IDをデコードして出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6281c7a1",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Load model\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## モデルのロード\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75dda4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# Load base model on GPU 0\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_0,\n",
    "    use_cache=False,\n",
    ")\n",
    "\n",
    "# Load base model on GPU 1\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_1,\n",
    "    use_cache=False,\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPU 0にベースモデルをロード\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,  # 指定したディレクトリからモデルをロード\n",
    "    device_map=device_0,  # モデルをGPU 0に配置\n",
    "    use_cache=False,  # キャッシュを無効にする\n",
    ")\n",
    "\n",
    "# GPU 1にベースモデルをロード\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,  # 指定したディレクトリからモデルをロード\n",
    "    device_map=device_1,  # モデルをGPU 1に配置\n",
    "    use_cache=False,  # キャッシュを無効にする\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:12:34.573593Z",
     "iopub.status.busy": "2024-07-24T12:12:34.572774Z",
     "iopub.status.idle": "2024-07-24T12:13:59.726653Z",
     "shell.execute_reply": "2024-07-24T12:13:59.725835Z",
     "shell.execute_reply.started": "2024-07-24T12:12:34.573558Z"
    },
    "papermill": {
     "duration": 83.919146,
     "end_time": "2024-07-10T01:15:26.412583",
     "exception": false,
     "start_time": "2024-07-10T01:14:02.493437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# GPU 0にベースモデルをロード\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,  # 指定したディレクトリからモデルをロード\n",
    "    device_map=device_0,  # モデルをGPU 0に配置\n",
    "    use_cache=False,  # キャッシュを無効にする\n",
    ")\n",
    "\n",
    "# GPU 1にベースモデルをロード\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,  # 指定したディレクトリからモデルをロード\n",
    "    device_map=device_1,  # モデルをGPU 1に配置\n",
    "    use_cache=False,  # キャッシュを無効にする\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1f86c",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "#### Load LoRA adapter\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "#### LoRAアダプターのロード\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05bbff9",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# LoRAアダプターをモデルにロード\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)  # GPU 0のモデルにLoRAアダプターをロード\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)  # GPU 1のモデルにLoRAアダプターをロード\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:13:59.728541Z",
     "iopub.status.busy": "2024-07-24T12:13:59.728223Z",
     "iopub.status.idle": "2024-07-24T12:14:00.740309Z",
     "shell.execute_reply": "2024-07-24T12:14:00.739503Z",
     "shell.execute_reply.started": "2024-07-24T12:13:59.728515Z"
    },
    "papermill": {
     "duration": 1.265087,
     "end_time": "2024-07-10T01:15:27.719297",
     "exception": false,
     "start_time": "2024-07-10T01:15:26.45421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LoRAアダプターをモデルにロード\n",
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)  # GPU 0のモデルにLoRAアダプターをロード\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)  # GPU 1のモデルにLoRAアダプターをロード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076818bb",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "## Inference\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "## 推論\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d2407",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))\n",
    "        proba = outputs.logits.softmax(-1).cpu()\n",
    "        \n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を行う関数を定義\n",
    "@torch.no_grad()  # 勾配計算を無効にするデコレーター\n",
    "@torch.cuda.amp.autocast()  # 自動混合精度を有効にするデコレーター\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []  # 各モデルの勝利確率を格納するリストを初期化\n",
    "    \n",
    "    # データをバッチ処理で推論\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # 現在のバッチの終わりのインデックスを計算\n",
    "        tmp = df.iloc[start_idx:end_idx]  # 現在のバッチを取得\n",
    "        input_ids = tmp[\"input_ids\"].to_list()  # 入力IDをリストに変換\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()  # アテンションマスクをリストに変換\n",
    "        \n",
    "        # パディングを適用してテンソルを準備\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",  # 最も長いシーケンスに合わせてパディング\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",  # PyTorchテンソルとして返す\n",
    "        )\n",
    "        \n",
    "        # モデルによる推論を実行\n",
    "        outputs = model(**inputs.to(device))  # 入力を指定したデバイスに移動\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # ロジットにソフトマックス関数を適用して確率を計算\n",
    "        \n",
    "        # 各勝利確率をリストに追加\n",
    "        a_win.extend(proba[:, 0].tolist())  # モデルAの勝利確率を追加\n",
    "        b_win.extend(proba[:, 1].tolist())  # モデルBの勝利確率を追加\n",
    "        tie.extend(proba[:, 2].tolist())  # 引き分けの確率を追加\n",
    "    \n",
    "    # データフレームに結果を追加\n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df  # 結果が追加されたデータフレームを返す\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:00.741702Z",
     "iopub.status.busy": "2024-07-24T12:14:00.741429Z",
     "iopub.status.idle": "2024-07-24T12:14:00.750854Z",
     "shell.execute_reply": "2024-07-24T12:14:00.74998Z",
     "shell.execute_reply.started": "2024-07-24T12:14:00.741679Z"
    },
    "papermill": {
     "duration": 0.026726,
     "end_time": "2024-07-10T01:15:27.838497",
     "exception": false,
     "start_time": "2024-07-10T01:15:27.811771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 推論を行う関数を定義\n",
    "@torch.no_grad()  # 勾配計算を無効にするデコレーター\n",
    "@torch.cuda.amp.autocast()  # 自動混合精度を有効にするデコレーター\n",
    "def inference(df, model, device, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    a_win, b_win, tie = [], [], []  # 各モデルの勝利確率を格納するリストを初期化\n",
    "    \n",
    "    # データをバッチ処理で推論\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # 現在のバッチの終わりのインデックスを計算\n",
    "        tmp = df.iloc[start_idx:end_idx]  # 現在のバッチを取得\n",
    "        input_ids = tmp[\"input_ids\"].to_list()  # 入力IDをリストに変換\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()  # アテンションマスクをリストに変換\n",
    "        \n",
    "        # パディングを適用してテンソルを準備\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",  # 最も長いシーケンスに合わせてパディング\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",  # PyTorchテンソルとして返す\n",
    "        )\n",
    "        \n",
    "        # モデルによる推論を実行\n",
    "        outputs = model(**inputs.to(device))  # 入力を指定したデバイスに移動\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # ロジットにソフトマックス関数を適用して確率を計算\n",
    "        \n",
    "        # 各勝利確率をリストに追加\n",
    "        a_win.extend(proba[:, 0].tolist())  # モデルAの勝利確率を追加\n",
    "        b_win.extend(proba[:, 1].tolist())  # モデルBの勝利確率を追加\n",
    "        tie.extend(proba[:, 2].tolist())  # 引き分けの確率を追加\n",
    "    \n",
    "    # データフレームに結果を追加\n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    df[\"winner_tie\"] = tie\n",
    "    \n",
    "    return df  # 結果が追加されたデータフレームを返す"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9a2c7",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "# sort by input length to fully leverage dynaminc padding\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# the total #tokens in sub_1 and sub_2 should be more or less the same\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "# 入力の長さでソートして動的パディングを最大限活用\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# サブセット1とサブセット2のトークン数がほぼ同じになるようにする\n",
    "sub_1 = data.iloc[0::2].copy()  # 偶数インデックスのデータをサブセット1にコピー\n",
    "sub_2 = data.iloc[1::2].copy()  # 奇数インデックスのデータをサブセット2にコピー\n",
    "\n",
    "# スレッドプールを使用して同時に推論を実行\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))  # 並列処理を実行\n",
    "\n",
    "# 結果をデータフレームとして結合\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values  # 各モデルの勝利確率を取得\n",
    "\n",
    "# 経過時間を表示\n",
    "print(f\"経過時間: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:00.753594Z",
     "iopub.status.busy": "2024-07-24T12:14:00.753162Z",
     "iopub.status.idle": "2024-07-24T12:14:05.056001Z",
     "shell.execute_reply": "2024-07-24T12:14:05.055038Z",
     "shell.execute_reply.started": "2024-07-24T12:14:00.753563Z"
    },
    "papermill": {
     "duration": 4.598663,
     "end_time": "2024-07-10T01:15:32.45234",
     "exception": false,
     "start_time": "2024-07-10T01:15:27.853677",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "# 入力の長さでソートして動的パディングを最大限活用\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "# サブセット1とサブセット2のトークン数がほぼ同じになるようにする\n",
    "sub_1 = data.iloc[0::2].copy()  # 偶数インデックスのデータをサブセット1にコピー\n",
    "sub_2 = data.iloc[1::2].copy()  # 奇数インデックスのデータをサブセット2にコピー\n",
    "\n",
    "# スレッドプールを使用して同時に推論を実行\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))  # 並列処理を実行\n",
    "\n",
    "# 結果をデータフレームとして結合\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values  # 各モデルの勝利確率を取得\n",
    "\n",
    "# 経過時間を表示\n",
    "print(f\"経過時間: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1568df",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "st = time.time()\n",
    "\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # sort by input length to boost speed\n",
    "    sub_1 = data.iloc[0::2].copy()\n",
    "    sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)\n",
    "    # recall TTA's order is flipped\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values \n",
    "    # average original result and TTA result.\n",
    "    proba = (proba + tta_proba) / 2\n",
    "\n",
    "print(f\"elapsed time: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "# テストタイムデータ拡張（TTA）が有効な場合\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # 入力の長さでソートして速度を向上\n",
    "    sub_1 = data.iloc[0::2].copy()  # 偶数インデックスのデータをサブセット1にコピー\n",
    "    sub_2 = data.iloc[1::2].copy()  # 奇数インデックスのデータをサブセット2にコピー\n",
    "\n",
    "    # スレッドプールを使用して同時に推論を実行\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))  # 並列処理を実行\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)  # TTAの結果をデータフレームとして結合\n",
    "    # TTAの順序を反転する\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values  \n",
    "    # 元の結果とTTA結果を平均化\n",
    "    proba = (proba + tta_proba) / 2  # 平均を取る\n",
    "\n",
    "# 経過時間を表示\n",
    "print(f\"経過時間: {time.time() - st}\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:05.058092Z",
     "iopub.status.busy": "2024-07-24T12:14:05.057356Z",
     "iopub.status.idle": "2024-07-24T12:14:05.065824Z",
     "shell.execute_reply": "2024-07-24T12:14:05.064951Z",
     "shell.execute_reply.started": "2024-07-24T12:14:05.058053Z"
    },
    "papermill": {
     "duration": 0.024559,
     "end_time": "2024-07-10T01:15:32.491283",
     "exception": false,
     "start_time": "2024-07-10T01:15:32.466724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 計測開始時刻を記録\n",
    "st = time.time()\n",
    "\n",
    "# テストタイムデータ拡張（TTA）が有効な場合\n",
    "if cfg.tta:\n",
    "    data = aug_data.sort_values(\"length\", ascending=False)  # 入力の長さでソートして速度を向上\n",
    "    sub_1 = data.iloc[0::2].copy()  # 偶数インデックスのデータをサブセット1にコピー\n",
    "    sub_2 = data.iloc[1::2].copy()  # 奇数インデックスのデータをサブセット2にコピー\n",
    "\n",
    "    # スレッドプールを使用して同時に推論を実行\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        results = executor.map(inference, (sub_1, sub_2), (model_0, model_1), (device_0, device_1))  # 並列処理を実行\n",
    "\n",
    "    tta_result_df = pd.concat(list(results), axis=0)  # TTAの結果をデータフレームとして結合\n",
    "    # TTAの順序を反転する\n",
    "    tta_proba = tta_result_df[[\"winner_model_b\", \"winner_model_a\", \"winner_tie\"]].values  \n",
    "    # 元の結果とTTA結果を平均化\n",
    "    proba = (proba + tta_proba) / 2  # 平均を取る\n",
    "\n",
    "# 経過時間を表示\n",
    "print(f\"経過時間: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1dff1d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームに勝利確率を設定\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # モデルAの勝利確率を追加\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # モデルBの勝利確率を追加\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]  # 引き分けの確率を追加\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:09.437377Z",
     "iopub.status.busy": "2024-07-24T12:14:09.436537Z",
     "iopub.status.idle": "2024-07-24T12:14:09.442595Z",
     "shell.execute_reply": "2024-07-24T12:14:09.441623Z",
     "shell.execute_reply.started": "2024-07-24T12:14:09.437343Z"
    },
    "papermill": {
     "duration": 0.034664,
     "end_time": "2024-07-10T01:15:32.539974",
     "exception": false,
     "start_time": "2024-07-10T01:15:32.50531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# データフレームに勝利確率を設定\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # モデルAの勝利確率を追加\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # モデルBの勝利確率を追加\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]  # 引き分けの確率を追加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac6a2c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "result_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終的な結果データフレームを表示\n",
    "result_df  # 予測結果を含むデータフレームを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:13.111682Z",
     "iopub.status.busy": "2024-07-24T12:14:13.110893Z",
     "iopub.status.idle": "2024-07-24T12:14:13.12977Z",
     "shell.execute_reply": "2024-07-24T12:14:13.128762Z",
     "shell.execute_reply.started": "2024-07-24T12:14:13.111637Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最終的な結果データフレームを表示\n",
    "result_df  # 予測結果を含むデータフレームを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce63377d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "out\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測結果データフレームを表示\n",
    "out  # 最初の出力結果を含むデータフレームを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:14:44.823637Z",
     "iopub.status.busy": "2024-07-24T12:14:44.823197Z",
     "iopub.status.idle": "2024-07-24T12:14:44.834115Z",
     "shell.execute_reply": "2024-07-24T12:14:44.833171Z",
     "shell.execute_reply.started": "2024-07-24T12:14:44.82361Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測結果データフレームを表示\n",
    "out  # 最初の出力結果を含むデータフレームを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59021d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "merged_df = pd.merge(out, result_df, on='id')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 予測結果データフレームを結合\n",
    "merged_df = pd.merge(out, result_df, on='id')  # ID列を基にoutデータフレームとresult_dfを結合\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:18:34.915568Z",
     "iopub.status.busy": "2024-07-24T12:18:34.911504Z",
     "iopub.status.idle": "2024-07-24T12:18:34.937622Z",
     "shell.execute_reply": "2024-07-24T12:18:34.936588Z",
     "shell.execute_reply.started": "2024-07-24T12:18:34.915526Z"
    }
   },
   "outputs": [],
   "source": [
    "# 予測結果データフレームを結合\n",
    "merged_df = pd.merge(out, result_df, on='id')  # ID列を基にoutデータフレームとresult_dfを結合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e0185d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "merged_df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結合したデータフレームを表示\n",
    "merged_df  # 結合結果を含むデータフレームを出力\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:21:10.389271Z",
     "iopub.status.busy": "2024-07-24T12:21:10.388546Z",
     "iopub.status.idle": "2024-07-24T12:21:10.412403Z",
     "shell.execute_reply": "2024-07-24T12:21:10.411424Z",
     "shell.execute_reply.started": "2024-07-24T12:21:10.389223Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結合したデータフレームを表示\n",
    "merged_df  # 結合結果を含むデータフレームを出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e154a3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "merged_df['winner_model_a']= (0.7*merged_df['winner_model_a_y']) + (0.3*merged_df['winner_model_a_x'])\n",
    "merged_df['winner_model_b']= (0.7*merged_df['winner_model_b_y']) + (0.3*merged_df['winner_model_b_x'])\n",
    "merged_df['winner_tie']= (0.7*merged_df['winner_tie_y']) + (0.3*merged_df['winner_tie_x'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルA、モデルB、および引き分けの勝利確率を加重平均して計算\n",
    "merged_df['winner_model_a'] = (0.7 * merged_df['winner_model_a_y']) + (0.3 * merged_df['winner_model_a_x'])  # モデルAの加重平均\n",
    "merged_df['winner_model_b'] = (0.7 * merged_df['winner_model_b_y']) + (0.3 * merged_df['winner_model_b_x'])  # モデルBの加重平均\n",
    "merged_df['winner_tie'] = (0.7 * merged_df['winner_tie_y']) + (0.3 * merged_df['winner_tie_x'])  # 引き分けの加重平均\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:21:07.31789Z",
     "iopub.status.busy": "2024-07-24T12:21:07.317231Z",
     "iopub.status.idle": "2024-07-24T12:21:07.326201Z",
     "shell.execute_reply": "2024-07-24T12:21:07.32519Z",
     "shell.execute_reply.started": "2024-07-24T12:21:07.317858Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルA、モデルB、および引き分けの勝利確率を加重平均して計算\n",
    "merged_df['winner_model_a'] = (0.7 * merged_df['winner_model_a_y']) + (0.3 * merged_df['winner_model_a_x'])  # モデルAの加重平均\n",
    "merged_df['winner_model_b'] = (0.7 * merged_df['winner_model_b_y']) + (0.3 * merged_df['winner_model_b_x'])  # モデルBの加重平均\n",
    "merged_df['winner_tie'] = (0.7 * merged_df['winner_tie_y']) + (0.3 * merged_df['winner_tie_x'])  # 引き分けの加重平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f86a3",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "submission_df = merged_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 提出用データフレームを作成\n",
    "submission_df = merged_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 必要な列を選択\n",
    "\n",
    "# CSVファイルとして保存\n",
    "submission_df.to_csv('submission.csv', index=False)  # インデックスなしでCSVに保存\n",
    "\n",
    "# 提出データフレームを表示\n",
    "display(submission_df)  # 提出用データを表示\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-24T12:21:19.307437Z",
     "iopub.status.busy": "2024-07-24T12:21:19.306809Z",
     "iopub.status.idle": "2024-07-24T12:21:19.322251Z",
     "shell.execute_reply": "2024-07-24T12:21:19.321347Z",
     "shell.execute_reply.started": "2024-07-24T12:21:19.307407Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用データフレームを作成\n",
    "submission_df = merged_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]  # 必要な列を選択\n",
    "\n",
    "# CSVファイルとして保存\n",
    "submission_df.to_csv('submission.csv', index=False)  # インデックスなしでCSVに保存\n",
    "\n",
    "# 提出データフレームを表示\n",
    "display(submission_df)  # 提出用データを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b58ef",
   "metadata": {},
   "source": [
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "credits: https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "クレジット: [https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora](https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora)\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4946449,
     "sourceId": 8330401,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5034873,
     "sourceId": 8449074,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5369301,
     "sourceId": 8926343,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 86587,
     "modelInstanceId": 63082,
     "sourceId": 75103,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 148.347272,
   "end_time": "2024-07-10T01:15:35.655682",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-10T01:13:07.30841",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f59addf0d2f40309e025976c382cad8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_268e3946106b4e41849bf11c5a375dac",
       "placeholder": "​",
       "style": "IPY_MODEL_5bb130c471af4927a6644f932ae47523",
       "value": " 2/2 [00:03&lt;00:00,  1.48s/it]"
      }
     },
     "19ef2d43bafa44a8b20dc5230aea5ae4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ca042ffa14e4dbebdc66435f7b1f07f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_19ef2d43bafa44a8b20dc5230aea5ae4",
       "placeholder": "​",
       "style": "IPY_MODEL_d8a7714cd80d479e859b6ae31ebce7e5",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "1d03719518b8423099b8b68a92e449d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64ef70cfa9c04764868fa52963323322",
       "placeholder": "​",
       "style": "IPY_MODEL_5e81b324ca1b46a2a96d02bb2acadc0a",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "1d89705c74d34016bbc1e0601ead825c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d409334237014614bf9ae742597d98ea",
       "placeholder": "​",
       "style": "IPY_MODEL_875758123e4f41f0b5c3fa0cd4fb47c6",
       "value": " 2/2 [01:18&lt;00:00, 34.68s/it]"
      }
     },
     "1ef6d64d40d8461d9e6adddd513089b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "268e3946106b4e41849bf11c5a375dac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "324c2396f44f45c89d9ec264007ef9ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5bb130c471af4927a6644f932ae47523": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5d243712a1a545e99fa858b0cf19831d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e81b324ca1b46a2a96d02bb2acadc0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "64ef70cfa9c04764868fa52963323322": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68ae4b02a13f4570ad729c437ebd28ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ca042ffa14e4dbebdc66435f7b1f07f",
        "IPY_MODEL_81b4a9a7cde64b17856b89dbd238c0ef",
        "IPY_MODEL_0f59addf0d2f40309e025976c382cad8"
       ],
       "layout": "IPY_MODEL_9422a87b93ab4473913e601da3a18689"
      }
     },
     "81b4a9a7cde64b17856b89dbd238c0ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1ef6d64d40d8461d9e6adddd513089b8",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_324c2396f44f45c89d9ec264007ef9ff",
       "value": 2
      }
     },
     "85d217d6b45847869cea506db59e8b42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5d243712a1a545e99fa858b0cf19831d",
       "max": 2,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_96385fd98f304649ab5c4ae81333fb63",
       "value": 2
      }
     },
     "875758123e4f41f0b5c3fa0cd4fb47c6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9422a87b93ab4473913e601da3a18689": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96385fd98f304649ab5c4ae81333fb63": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d409334237014614bf9ae742597d98ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d576a283e6424206ab4c25d809241c21": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d8a7714cd80d479e859b6ae31ebce7e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d98918fae8174629b4819a1114f21202": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1d03719518b8423099b8b68a92e449d7",
        "IPY_MODEL_85d217d6b45847869cea506db59e8b42",
        "IPY_MODEL_1d89705c74d34016bbc1e0601ead825c"
       ],
       "layout": "IPY_MODEL_d576a283e6424206ab4c25d809241c21"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
