{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df88fe9d",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYS - Chatbot Arenaコンペティションにおける人間の好みを予測するためのモデルを構築することを目的としています。特に、このノートブックは、2つの大規模言語モデル（モデルAとモデルB）の応答がユーザーに好まれる確率を分析し、予測するための手法を実装しています。\n",
    "\n",
    "### 主な内容と手法\n",
    "\n",
    "1. **ライブラリのインポート**: \n",
    "   - `pandas`: データ操作に使用。\n",
    "   - `scikit-learn`からの複数のモジュール: データセットの分割、TF-IDFによるテキストのベクトル化、ロジスティック回帰モデル、ログ損失の計算。\n",
    "\n",
    "2. **データセットの読み込み**: \n",
    "   - 訓練データ（`train.csv`）とテストデータ（`test.csv`）をPandasを使用して読み込みます。\n",
    "\n",
    "3. **ターゲット変数の作成**: \n",
    "   - モデルAが好まれた場合は1、それ以外は0として新しいカラム`target`を生成します。\n",
    "\n",
    "4. **テキストデータの準備**: \n",
    "   - プロンプトとそれに対応するモデルAおよびモデルBの応答を結合した新しいテキストデータカラムを作成します。\n",
    "\n",
    "5. **TF-IDFベクトル化**: \n",
    "   - テキストデータを最大5000の特徴量にベクトル化します。\n",
    "\n",
    "6. **データセットの分割**: \n",
    "   - 訓練データを訓練用と検証用に80:20の割合で分割します。\n",
    "\n",
    "7. **ロジスティック回帰モデルの実装**: \n",
    "   - 2つのロジスティック回帰モデル（モデルAとモデルB）を設定し、訓練データを用いて学習させます。\n",
    "\n",
    "8. **検証データの予測と評価**: \n",
    "   - 検証データに対する予測を行い、ログ損失を計算してモデルのパフォーマンスを評価します。\n",
    "\n",
    "9. **テストデータの予測と提出ファイルの作成**: \n",
    "   - テストデータに対して学習したモデルを用いて予測を行い、最終的な提出ファイル（`submission.csv`）を作成します。\n",
    "\n",
    "このノートブックでは、データ前処理からモデル訓練、評価、予測結果の出力までの一連の流れが示されており、機械学習を用いたテキストデータの解析における基本的な技術を適用しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db200f",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、初心者がつまずきそうな専門用語や概念について簡単な解説を提供します。特に、実務経験が少ないまたはこのノートブック特有のものに焦点を当てています。\n",
    "\n",
    "1. **TF-IDF (Term Frequency-Inverse Document Frequency)**:\n",
    "   - 文章内での単語の重要性を計算する手法。TFは特定の単語が文書内に出現する頻度、IDFはその単語がどれほど多くの文書に出現するかを反映し、一般的に文書全体におけるその単語の情報の重要性を示します。これにより、特定の単語が1つの文書においてどれほど特徴的かを評価します。\n",
    "\n",
    "2. **max_features**:\n",
    "   - `TfidfVectorizer`の引数で、辞書に含まれる最大の特徴量（単語）の数を指定します。この設定により、計算効率が向上し、モデルの過剰適合を防ぐ効果があります。特に大規模なデータセットでは、すべての単語を考慮することが難しいため、重要な単語のみに絞ることが有効です。\n",
    "\n",
    "3. **train_test_split**:\n",
    "   - データの訓練セットとテストセットをランダムに分割するための関数。モデルの評価における一般的な手法で、過学習を防ぐために使用されます。ここでは、訓練用データの80%と検証用データの20%に分割しています。\n",
    "\n",
    "4. **predict_proba**:\n",
    "   - モデルが各クラスに属する確率を返すメソッド。分類タスクにおいて、各クラスの予測を行うだけでなく、それぞれのクラスに対する信頼度を示します。この確率に基づいて、最終的にクラスを決定します。\n",
    "\n",
    "5. **log_loss**:\n",
    "   - モデルの予測と実際の結果との間の対数損失を計算する指標。特に確率的な出力を持つモデルにおいて、予測の正確性を測るのに利用されます。値が低いほど、モデルの予測が実際のターゲットに近いことを示します。\n",
    "\n",
    "6. **winner_model_a、winner_model_b、winner_tie**:\n",
    "   - 提出ファイルで使用されるカラム名。`winner_model_a`はモデルAが選ばれる確率、`winner_model_b`はモデルBが選ばれる確率、そして`winner_tie`は同点になる確率を表します。この提出形式は、競争におけるモデルのパフォーマンスを評価するためのものです。\n",
    "\n",
    "7. **submission.csv**:\n",
    "   - コンペティションでの結果を提出するためのファイル形式。指定したフォーマットに従って、予測結果を保存し、後で評価されるモデルの性能を確認するために使用されます。\n",
    "\n",
    "これらの用語や概念は、機械学習や深層学習の文脈でよく使用されるが、実務経験が少ないと理解が難しい場合があります。各用語についての説明を通じて、より深く理解しやすくなると思います。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c4ba60",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# ライブラリのインポート\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# データセットの読み込み\n",
    "train_file_path = '/kaggle/input/lmsysdataset/train.csv'\n",
    "test_file_path = '/kaggle/input/lmsysdataset/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)\n",
    "test_df = pd.read_csv(test_file_path)\n",
    "\n",
    "# ターゲット変数の作成\n",
    "train_df['target'] = train_df.apply(lambda row: 1 if row['winner_model_a'] == 1 else 0, axis=1)\n",
    "\n",
    "# テキストデータの結合\n",
    "train_df['text_a'] = train_df['prompt'] + ' ' + train_df['response_a']\n",
    "train_df['text_b'] = train_df['prompt'] + ' ' + train_df['response_b']\n",
    "test_df['text_a'] = test_df['prompt'] + ' ' + test_df['response_a']\n",
    "test_df['text_b'] = test_df['prompt'] + ' ' + test_df['response_b']\n",
    "\n",
    "# TF-IDFベクトライザの設定\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "# テキストデータのベクトル化\n",
    "X_a = vectorizer.fit_transform(train_df['text_a'])\n",
    "X_b = vectorizer.fit_transform(train_df['text_b'])\n",
    "X_test_a = vectorizer.transform(test_df['text_a'])\n",
    "X_test_b = vectorizer.transform(test_df['text_b'])\n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "X_train_a, X_valid_a, y_train, y_valid = train_test_split(X_a, train_df['target'], test_size=0.2, random_state=42)\n",
    "X_train_b, X_valid_b, _, _ = train_test_split(X_b, train_df['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# ロジスティック回帰モデルの設定\n",
    "model_a = LogisticRegression(max_iter=1000)\n",
    "model_b = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# モデルの訓練\n",
    "model_a.fit(X_train_a, y_train)\n",
    "model_b.fit(X_train_b, y_train)\n",
    "\n",
    "# 検証データの予測\n",
    "valid_preds_a = model_a.predict_proba(X_valid_a)[:, 1]\n",
    "valid_preds_b = model_b.predict_proba(X_valid_b)[:, 1]\n",
    "\n",
    "# ログ損失の計算\n",
    "loss_a = log_loss(y_valid, valid_preds_a)\n",
    "loss_b = log_loss(y_valid, valid_preds_b)\n",
    "\n",
    "print(f'Log Loss for model_a: {loss_a}')\n",
    "print(f'Log Loss for model_b: {loss_b}')\n",
    "\n",
    "# テストデータの予測\n",
    "test_preds_a = model_a.predict_proba(X_test_a)[:, 1]\n",
    "test_preds_b = model_b.predict_proba(X_test_b)[:, 1]\n",
    "\n",
    "# 提出ファイルの作成\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'winner_model_a': test_preds_a,\n",
    "    'winner_model_b': test_preds_b,\n",
    "    'winner_tie': 0.0  # 同点の場合は0とします（必要に応じて調整）\n",
    "})\n",
    "\n",
    "# 提出ファイルの保存\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Submission file created successfully!\")\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ライブラリのインポート\n",
    "import pandas as pd  # データ操作のためのPandasライブラリをインポートします\n",
    "from sklearn.model_selection import train_test_split  # データセットを分割するための関数をインポートします\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトル化のためのライブラリをインポートします\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰モデルをインポートします\n",
    "from sklearn.metrics import log_loss  # ログ損失の計算のための関数をインポートします\n",
    "\n",
    "# データセットの読み込み\n",
    "train_file_path = '/kaggle/input/lmsysdataset/train.csv'  # 訓練データのファイルパス\n",
    "test_file_path = '/kaggle/input/lmsysdataset/test.csv'  # テストデータのファイルパス\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)  # 訓練データを読み込みます\n",
    "test_df = pd.read_csv(test_file_path)  # テストデータを読み込みます\n",
    "\n",
    "# ターゲット変数の作成\n",
    "# 'winner_model_a'が1の行には1を、それ以外は0をターゲットとします\n",
    "train_df['target'] = train_df.apply(lambda row: 1 if row['winner_model_a'] == 1 else 0, axis=1)\n",
    "\n",
    "# テキストデータの結合\n",
    "# プロンプトとモデルA及びモデルBの応答を結合した新しいカラムを作成します\n",
    "train_df['text_a'] = train_df['prompt'] + ' ' + train_df['response_a']\n",
    "train_df['text_b'] = train_df['prompt'] + ' ' + train_df['response_b']\n",
    "test_df['text_a'] = test_df['prompt'] + ' ' + test_df['response_a']\n",
    "test_df['text_b'] = test_df['prompt'] + ' ' + test_df['response_b']\n",
    "\n",
    "# TF-IDFベクトライザの設定\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # 最大5000の特徴量を持つTF-IDFベクトライザを作成します\n",
    "\n",
    "# テキストデータのベクトル化\n",
    "# 訓練データのテキストをベクトル化します\n",
    "X_a = vectorizer.fit_transform(train_df['text_a'])  \n",
    "# 訓練データの別のテキストをベクトル化します\n",
    "X_b = vectorizer.fit_transform(train_df['text_b'])  \n",
    "# テストデータのテキストをベクトル化します\n",
    "X_test_a = vectorizer.transform(test_df['text_a'])  \n",
    "X_test_b = vectorizer.transform(test_df['text_b'])  \n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "# 訓練データを訓練用と検証用に分割します（8:2の割合）\n",
    "X_train_a, X_valid_a, y_train, y_valid = train_test_split(X_a, train_df['target'], test_size=0.2, random_state=42)  \n",
    "X_train_b, X_valid_b, _, _ = train_test_split(X_b, train_df['target'], test_size=0.2, random_state=42)  \n",
    "\n",
    "# ロジスティック回帰モデルの設定\n",
    "model_a = LogisticRegression(max_iter=1000)  # モデルAのロジスティック回帰を設定します\n",
    "model_b = LogisticRegression(max_iter=1000)  # モデルBのロジスティック回帰を設定します\n",
    "\n",
    "# モデルの訓練\n",
    "model_a.fit(X_train_a, y_train)  # モデルAを訓練データで学習させます\n",
    "model_b.fit(X_train_b, y_train)  # モデルBを訓練データで学習させます\n",
    "\n",
    "# 検証データの予測\n",
    "valid_preds_a = model_a.predict_proba(X_valid_a)[:, 1]  # モデルAによる検証データの予測確率を計算します\n",
    "valid_preds_b = model_b.predict_proba(X_valid_b)[:, 1]  # モデルBによる検証データの予測確率を計算します\n",
    "\n",
    "# ログ損失の計算\n",
    "loss_a = log_loss(y_valid, valid_preds_a)  # モデルAのログ損失を計算します\n",
    "loss_b = log_loss(y_valid, valid_preds_b)  # モデルBのログ損失を計算します\n",
    "\n",
    "print(f'Log Loss for model_a: {loss_a}')  # モデルAのログ損失を表示します\n",
    "print(f'Log Loss for model_b: {loss_b}')  # モデルBのログ損失を表示します\n",
    "\n",
    "# テストデータの予測\n",
    "test_preds_a = model_a.predict_proba(X_test_a)[:, 1]  # モデルAによるテストデータの予測確率を計算します\n",
    "test_preds_b = model_b.predict_proba(X_test_b)[:, 1]  # モデルBによるテストデータの予測確率を計算します\n",
    "\n",
    "# 提出ファイルの作成\n",
    "submission = pd.DataFrame({  # 提出用のDataFrameを作成します\n",
    "    'id': test_df['id'],  # テストデータのIDを追加します\n",
    "    'winner_model_a': test_preds_a,  # モデルAの予測確率を追加します\n",
    "    'winner_model_b': test_preds_b,  # モデルBの予測確率を追加します\n",
    "    'winner_tie': 0.0  # 同点の場合は0とします（必要に応じて調整）\n",
    "})\n",
    "\n",
    "# 提出ファイルの保存\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出ファイルをCSV形式で保存します\n",
    "print(\"Submission file created successfully!\")  # 提出ファイル作成の成功メッセージを表示します\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-12T06:57:15.400116Z",
     "iopub.status.busy": "2024-07-12T06:57:15.39943Z",
     "iopub.status.idle": "2024-07-12T06:57:56.329438Z",
     "shell.execute_reply": "2024-07-12T06:57:56.328352Z",
     "shell.execute_reply.started": "2024-07-12T06:57:15.400079Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import pandas as pd  # データ操作のためのPandasライブラリをインポートします\n",
    "from sklearn.model_selection import train_test_split  # データセットを分割するための関数をインポートします\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトル化のためのライブラリをインポートします\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰モデルをインポートします\n",
    "from sklearn.metrics import log_loss  # ログ損失の計算のための関数をインポートします\n",
    "\n",
    "# データセットの読み込み\n",
    "train_file_path = '/kaggle/input/lmsysdataset/train.csv'  # 訓練データのファイルパス\n",
    "test_file_path = '/kaggle/input/lmsysdataset/test.csv'  # テストデータのファイルパス\n",
    "\n",
    "train_df = pd.read_csv(train_file_path)  # 訓練データを読み込みます\n",
    "test_df = pd.read_csv(test_file_path)  # テストデータを読み込みます\n",
    "\n",
    "# ターゲット変数の作成\n",
    "# 'winner_model_a'が1の行には1を、それ以外は0をターゲットとします\n",
    "train_df['target'] = train_df.apply(lambda row: 1 if row['winner_model_a'] == 1 else 0, axis=1)\n",
    "\n",
    "# テキストデータの結合\n",
    "# プロンプトとモデルA及びモデルBの応答を結合した新しいカラムを作成します\n",
    "train_df['text_a'] = train_df['prompt'] + ' ' + train_df['response_a']\n",
    "train_df['text_b'] = train_df['prompt'] + ' ' + train_df['response_b']\n",
    "test_df['text_a'] = test_df['prompt'] + ' ' + test_df['response_a']\n",
    "test_df['text_b'] = test_df['prompt'] + ' ' + test_df['response_b']\n",
    "\n",
    "# TF-IDFベクトライザの設定\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # 最大5000の特徴量を持つTF-IDFベクトライザを作成します\n",
    "\n",
    "# テキストデータのベクトル化\n",
    "# 訓練データのテキストをベクトル化します\n",
    "X_a = vectorizer.fit_transform(train_df['text_a'])  \n",
    "# 訓練データの別のテキストをベクトル化します\n",
    "X_b = vectorizer.fit_transform(train_df['text_b'])  \n",
    "# テストデータのテキストをベクトル化します\n",
    "X_test_a = vectorizer.transform(test_df['text_a'])  \n",
    "X_test_b = vectorizer.transform(test_df['text_b'])  \n",
    "\n",
    "# 訓練データと検証データの分割\n",
    "# 訓練データを訓練用と検証用に分割します（8:2の割合）\n",
    "X_train_a, X_valid_a, y_train, y_valid = train_test_split(X_a, train_df['target'], test_size=0.2, random_state=42)  \n",
    "X_train_b, X_valid_b, _, _ = train_test_split(X_b, train_df['target'], test_size=0.2, random_state=42)  \n",
    "\n",
    "# ロジスティック回帰モデルの設定\n",
    "model_a = LogisticRegression(max_iter=1000)  # モデルAのロジスティック回帰を設定します\n",
    "model_b = LogisticRegression(max_iter=1000)  # モデルBのロジスティック回帰を設定します\n",
    "\n",
    "# モデルの訓練\n",
    "model_a.fit(X_train_a, y_train)  # モデルAを訓練データで学習させます\n",
    "model_b.fit(X_train_b, y_train)  # モデルBを訓練データで学習させます\n",
    "\n",
    "# 検証データの予測\n",
    "valid_preds_a = model_a.predict_proba(X_valid_a)[:, 1]  # モデルAによる検証データの予測確率を計算します\n",
    "valid_preds_b = model_b.predict_proba(X_valid_b)[:, 1]  # モデルBによる検証データの予測確率を計算します\n",
    "\n",
    "# ログ損失の計算\n",
    "loss_a = log_loss(y_valid, valid_preds_a)  # モデルAのログ損失を計算します\n",
    "loss_b = log_loss(y_valid, valid_preds_b)  # モデルBのログ損失を計算します\n",
    "\n",
    "print(f'Log Loss for model_a: {loss_a}')  # モデルAのログ損失を表示します\n",
    "print(f'Log Loss for model_b: {loss_b}')  # モデルBのログ損失を表示します\n",
    "\n",
    "# テストデータの予測\n",
    "test_preds_a = model_a.predict_proba(X_test_a)[:, 1]  # モデルAによるテストデータの予測確率を計算します\n",
    "test_preds_b = model_b.predict_proba(X_test_b)[:, 1]  # モデルBによるテストデータの予測確率を計算します\n",
    "\n",
    "# 提出ファイルの作成\n",
    "submission = pd.DataFrame({  # 提出用のDataFrameを作成します\n",
    "    'id': test_df['id'],  # テストデータのIDを追加します\n",
    "    'winner_model_a': test_preds_a,  # モデルAの予測確率を追加します\n",
    "    'winner_model_b': test_preds_b,  # モデルBの予測確率を追加します\n",
    "    'winner_tie': 0.0  # 同点の場合は0とします（必要に応じて調整）\n",
    "})\n",
    "\n",
    "# 提出ファイルの保存\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出ファイルをCSV形式で保存します\n",
    "print(\"Submission file created successfully!\")  # 提出ファイル作成の成功メッセージを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6696509",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# このセルは現在何もコードがありません。必要なコードを挿入してください。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このセルは現在何もコードがありません。必要なコードを挿入してください。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5375908,
     "sourceId": 8935672,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
