{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c400d780",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」に参加するためのモデル推論を行うためのものです。具体的には、大規模言語モデル（LLM）の応答を比較し、どちらの応答がユーザーに好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "### 取り組む問題\n",
    "ノートブックは、与えられたテストデータに対して、異なるLLMの応答（モデルAとモデルB）の勝者を予測する問題に焦点を当てています。この予測は、選択肢のうちどちらのモデルの応答が優れているか、または同等であるのかを示す確率を出力することで行われます。\n",
    "\n",
    "### 使用する手法とライブラリ\n",
    "- **ライブラリ**:\n",
    "  - `bitsandbytes`: メモリ効率の良いパラメータ管理を提供。\n",
    "  - `peft`: モデルのパラメータを効率的にファインチューニングするためのラッパー。\n",
    "  - `transformers`: 事前学習済みのトークナイザーやモデルを使用。\n",
    "  - `pandas` と `numpy`: データ操作や数値計算を行うための一般的なライブラリ。\n",
    "  - `torch`: モデルの構築や訓練を行うための主要な深層学習ライブラリ。\n",
    "  - `datasets`: データセットの処理に特化したライブラリ。\n",
    "\n",
    "- **手法**:\n",
    "  1. **データのインポートと前処理**: テストデータを読み込み、応答やプロンプトから不要な記号を削除し、モデルの入力形式に整形します。\n",
    "  2. **トークナイゼーション**: ユーザーのプロンプトとモデルの応答をトークン化し、モデルが処理できる形式に変換します。\n",
    "  3. **モデルの読み込み**: 事前学習済みのLLMを読み込み、2つのGPUデバイスを使って異なるモデルを並行して評価します。\n",
    "  4. **推論**: 推論関数を使用して、トークン化されたデータに対してモデルを評価し、モデルAとモデルBの応答の勝者確率を計算します。\n",
    "  5. **結果の整理**: 推論結果をデータフレームに格納し、不要な列を削除して、最終的な出力ファイル（`submission.csv`）を作成します。\n",
    "\n",
    "全体として、このノートブックは、効率的なデータ処理と推論を通じて、ユーザーの好みを予測する能力を強化することを目的としています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3120f3",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、提供されたJupyter Notebookにおける機械学習や深層学習に関連する専門用語の解説です。初心者がつまずきそうなマイナーな用語や、実務経験がないと馴染みのないものに焦点を当てています。\n",
    "\n",
    "1. **PEFT (Parameter-Efficient Fine-Tuning)**:\n",
    "   - モデルの全パラメータを更新せずに、そのサブセットを効率的に微調整する手法。これにより、トレーニング時間やリソースを削減しながら、特定のタスクにモデルを適応させることができます。\n",
    "\n",
    "2. **BitsAndBytesConfig**:\n",
    "   - モデルのメモリ効率を向上させるための設定オブジェクト。この設定を使って、モデルを8ビットの精度でロードしたり、計算時のデータ型を指定したりします。\n",
    "\n",
    "3. **Autocast**:\n",
    "   - PyTorchにおける自動混合精度の機能。これにより、計算を半精度（16ビット）で行い、必要に応じて全精度（32ビット）に切り替えることで、計算速度とメモリ使用量を最適化します。\n",
    "\n",
    "4. **トークナイザー (Tokenizer)**:\n",
    "   - テキストデータを、モデルが理解できる数値形式（トークン）に変換する役割を持つコンポーネント。プロンプトやレスポンスを処理する際に使用されます。\n",
    "\n",
    "5. **Attention Mask**:\n",
    "   - 入力シーケンスの各トークンに対して、モデルがどのトークンに注意を払うべきかを示すマスク。通常、パディングトークンを無視するために使用され、1（注視する）または0（無視する）の値を持ちます。\n",
    "\n",
    "6. **Logits**:\n",
    "   - モデルが出力する生のスコアまたは値。この値は、最終的に確率に変換される前の未正規化の値です。\n",
    "\n",
    "7. **Merge and Unload**:\n",
    "   - 複数のモデルやパラメータを統合し、メモリ上から不要なデータを削除するプロセス。これにより、メモリ使用量を効率的に管理します。\n",
    "\n",
    "8. **ガーベジコレクション (Garbage Collection)**:\n",
    "   - プログラム実行中に不要になったメモリを自動的に解放するプロセス。これにより、メモリリークを防ぎ、プログラムの効率を向上させます。\n",
    "\n",
    "9. **ストレージデータ並列処理 (Storage Data Parallel, SDP)**:\n",
    "   - 複数のGPUにデータを分散して処理する手法。大きなモデルを効率的にトレーニングするために、データの分散とストレージの共有を行います。\n",
    "\n",
    "10. **パディングトークン (Padding Token)**:\n",
    "    - テキスト長を揃えるために追加される特別なトークン。主にバッチ処理の際に、各シーケンスを同じ長さにするために使われます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a77509",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n",
    "!pip install -U /kaggle/input/peft-wheel/pytorch/version1/1/peft-0.10.0-py3-none-any.whl -qq\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインストールするためのコマンドです。\n",
    "# 'bitsandbytes'というライブラリを指定されたホイールファイルからインストールします。\n",
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n",
    "\n",
    "# 次に、'peft'というライブラリを同様に指定されたホイールファイルからインストールします。\n",
    "!pip install -U /kaggle/input/peft-wheel/pytorch/version1/1/peft-0.10.0-py3-none-any.whl -qq\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:45:46.411366Z",
     "iopub.status.busy": "2024-07-06T12:45:46.410517Z",
     "iopub.status.idle": "2024-07-06T12:46:56.122877Z",
     "shell.execute_reply": "2024-07-06T12:46:56.121632Z",
     "shell.execute_reply.started": "2024-07-06T12:45:46.41132Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインストールするためのコマンドです。\n",
    "# 'bitsandbytes'というライブラリを指定されたホイールファイルからインストールします。\n",
    "!pip install -U /kaggle/input/bitsandbytes-0-42-0-py3-none-any-whl/bitsandbytes-0.42.0-py3-none-any.whl -qq\n",
    "\n",
    "# 次に、'peft'というライブラリを同様に指定されたホイールファイルからインストールします。\n",
    "!pip install -U /kaggle/input/peft-wheel/pytorch/version1/1/peft-0.10.0-py3-none-any.whl -qq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5f2df8",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from datasets import Dataset\n",
    "import torch.nn.functional as F\n",
    "from threading import Thread\n",
    "import gc\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 必要なライブラリをインポートするためのコードです。\n",
    "\n",
    "# pandasはデータ処理に便利なライブラリです。\n",
    "import pandas as pd\n",
    "\n",
    "# numpyは数値計算や配列処理のためのライブラリです。\n",
    "import numpy as np\n",
    "\n",
    "# softmax 関数は、入力された値を確率分布に変換します。\n",
    "from scipy.special import softmax\n",
    "\n",
    "# transformersライブラリから、事前学習済みのトークナイザーとモデルをインポートします。\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "# peftライブラリからPeftModelとPeftConfigをインポートします。\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# PyTorchをインポートします。これにより、深層学習モデルを構築・訓練できます。\n",
    "import torch\n",
    "\n",
    "# 自動混合精度を使用するためのモジュールをインポートします。\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# datasetsライブラリからDatasetクラスをインポートします。これを使ってデータセットを扱います。\n",
    "from datasets import Dataset\n",
    "\n",
    "# PyTorchの機能を活用するための関数をインポートします。\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# スレッドを作成するためのモジュールです。\n",
    "from threading import Thread\n",
    "\n",
    "# メモリ管理のためにガーベジコレクションを行うためのモジュールです。\n",
    "import gc\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-06T12:46:56.125204Z",
     "iopub.status.busy": "2024-07-06T12:46:56.124907Z",
     "iopub.status.idle": "2024-07-06T12:47:04.022214Z",
     "shell.execute_reply": "2024-07-06T12:47:04.021448Z",
     "shell.execute_reply.started": "2024-07-06T12:46:56.125174Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートするためのコードです。\n",
    "\n",
    "# pandasはデータ処理に便利なライブラリです。\n",
    "import pandas as pd\n",
    "\n",
    "# numpyは数値計算や配列処理のためのライブラリです。\n",
    "import numpy as np\n",
    "\n",
    "# softmax 関数は、入力された値を確率分布に変換します。\n",
    "from scipy.special import softmax\n",
    "\n",
    "# transformersライブラリから、事前学習済みのトークナイザーとモデルをインポートします。\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, LlamaForSequenceClassification, BitsAndBytesConfig\n",
    "\n",
    "# peftライブラリからPeftModelとPeftConfigをインポートします。\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# PyTorchをインポートします。これにより、深層学習モデルを構築・訓練できます。\n",
    "import torch\n",
    "\n",
    "# 自動混合精度を使用するためのモジュールをインポートします。\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# datasetsライブラリからDatasetクラスをインポートします。これを使ってデータセットを扱います。\n",
    "from datasets import Dataset\n",
    "\n",
    "# PyTorchの機能を活用するための関数をインポートします。\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# スレッドを作成するためのモジュールです。\n",
    "from threading import Thread\n",
    "\n",
    "# メモリ管理のためにガーベジコレクションを行うためのモジュールです。\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e154587",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "MODEL_NAME = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n",
    "MAX_LENGTH = 1284\n",
    "BATCH_SIZE = 4\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# GPUのメモリ効率を改善するための設定です。\n",
    "# ストレージ記憶に適したデータ並列処理を有効にします。\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "\n",
    "# フラッシュSDP（ストレージデータ並列処理）を有効にします。\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "# モデルが保存されているディレクトリのパスを指定します。\n",
    "MODEL_NAME = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n",
    "\n",
    "# モデルの入力シーケンスの最大長を指定します。この長さを超えるテキストは切り捨てられます。\n",
    "MAX_LENGTH = 1284\n",
    "\n",
    "# バッチサイズを指定します。バッチサイズは、モデルに一度に渡すデータの量を決定します。\n",
    "BATCH_SIZE = 4\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.023805Z",
     "iopub.status.busy": "2024-07-06T12:47:04.023314Z",
     "iopub.status.idle": "2024-07-06T12:47:04.028508Z",
     "shell.execute_reply": "2024-07-06T12:47:04.027708Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.023778Z"
    }
   },
   "outputs": [],
   "source": [
    "# GPUのメモリ効率を改善するための設定です。\n",
    "# ストレージ記憶に適したデータ並列処理を有効にします。\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "\n",
    "# フラッシュSDP（ストレージデータ並列処理）を有効にします。\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "# モデルが保存されているディレクトリのパスを指定します。\n",
    "MODEL_NAME = \"/kaggle/input/llama-3/transformers/8b-hf/1\"\n",
    "\n",
    "# モデルの入力シーケンスの最大長を指定します。この長さを超えるテキストは切り捨てられます。\n",
    "MAX_LENGTH = 1284\n",
    "\n",
    "# バッチサイズを指定します。バッチサイズは、モデルに一度に渡すデータの量を決定します。\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8e628e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 指定されたCSVファイルを読み込みます。\n",
    "# test.csvファイルは、テストデータを含んでいます。\n",
    "df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "\n",
    "# 読み込んだデータフレームの最初の5行を表示します。\n",
    "# これにより、データの構造や内容を確認できます。\n",
    "df.head()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.030963Z",
     "iopub.status.busy": "2024-07-06T12:47:04.030677Z",
     "iopub.status.idle": "2024-07-06T12:47:04.067682Z",
     "shell.execute_reply": "2024-07-06T12:47:04.066813Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.03094Z"
    }
   },
   "outputs": [],
   "source": [
    "# 指定されたCSVファイルを読み込みます。\n",
    "# test.csvファイルは、テストデータを含んでいます。\n",
    "df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "\n",
    "# 読み込んだデータフレームの最初の5行を表示します。\n",
    "# これにより、データの構造や内容を確認できます。\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6f4e1d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def transform(row):\n",
    "    return row.strip('[]')\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 行データを変換するための関数を定義します。\n",
    "def transform(row):\n",
    "    # 文字列の前後から角括弧（[]）を削除して返します。\n",
    "    return row.strip('[]')  # 余分な括弧を取り除くことで、データをクリーンにします。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.068823Z",
     "iopub.status.busy": "2024-07-06T12:47:04.068588Z",
     "iopub.status.idle": "2024-07-06T12:47:04.073019Z",
     "shell.execute_reply": "2024-07-06T12:47:04.072044Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.068802Z"
    }
   },
   "outputs": [],
   "source": [
    "# 行データを変換するための関数を定義します。\n",
    "def transform(row):\n",
    "    # 文字列の前後から角括弧（[]）を削除して返します。\n",
    "    return row.strip('[]')  # 余分な括弧を取り除くことで、データをクリーンにします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15edcb44",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df['prompt'] = df['prompt'].apply(transform)\n",
    "df['response_a'] = df['response_a'].apply(transform)\n",
    "df['response_b'] = df['response_b'].apply(transform)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームの特定の列に対して、先ほど定義したtransform関数を適用します。\n",
    "# 'prompt'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['prompt'] = df['prompt'].apply(transform)\n",
    "\n",
    "# 'response_a'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['response_a'] = df['response_a'].apply(transform)\n",
    "\n",
    "# 'response_b'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['response_b'] = df['response_b'].apply(transform)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.074433Z",
     "iopub.status.busy": "2024-07-06T12:47:04.07411Z",
     "iopub.status.idle": "2024-07-06T12:47:04.085064Z",
     "shell.execute_reply": "2024-07-06T12:47:04.084026Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.074401Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームの特定の列に対して、先ほど定義したtransform関数を適用します。\n",
    "# 'prompt'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['prompt'] = df['prompt'].apply(transform)\n",
    "\n",
    "# 'response_a'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['response_a'] = df['response_a'].apply(transform)\n",
    "\n",
    "# 'response_b'列の各要素にtransform関数を適用して角括弧を取り除きます。\n",
    "df['response_b'] = df['response_b'].apply(transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a44c98",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df['text'] = 'User prompt: ' + df['prompt'] +  '\\n\\nModel A :\\n' + df['response_a'] +'\\n\\n----------\\n\\nModel B:\\n'  + df['response_b']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 新しい列'text'をデータフレームに作成します。\n",
    "# この列にはユーザープロンプトと2つのモデルの応答がフォーマットされた状態で格納されます。\n",
    "df['text'] = 'User prompt: ' + df['prompt'] +  '\\n\\nModel A :\\n' + df['response_a'] +'\\n\\n----------\\n\\nModel B:\\n'  + df['response_b'] \n",
    "\n",
    "# これにより、各行がユーザーの入力とそれに対するモデルAおよびモデルBの応答を持つ形式になります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.086628Z",
     "iopub.status.busy": "2024-07-06T12:47:04.086266Z",
     "iopub.status.idle": "2024-07-06T12:47:04.096075Z",
     "shell.execute_reply": "2024-07-06T12:47:04.095197Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.086597Z"
    }
   },
   "outputs": [],
   "source": [
    "# 新しい列'text'をデータフレームに作成します。\n",
    "# この列にはユーザープロンプトと2つのモデルの応答がフォーマットされた状態で格納されます。\n",
    "df['text'] = 'User prompt: ' + df['prompt'] +  '\\n\\nModel A :\\n' + df['response_a'] +'\\n\\n----------\\n\\nModel B:\\n'  + df['response_b'] \n",
    "\n",
    "# これにより、各行がユーザーの入力とそれに対するモデルAおよびモデルBの応答を持つ形式になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f934fdb",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "# peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# PEFTモデルのIDを指定し、PEFT設定を取得するためのコードです。\n",
    "# ただしこの行はコメントアウトされています。\n",
    "# peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "# peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# 事前学習済みのトークナイザーを指定したモデル名から読み込みます。\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# パディングトークンのIDとトークンを設定します。\n",
    "# パディングトークンは、シーケンスの長さを揃えるために使用されます。\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id  # EOS（文の終了）トークンをパディング用に指定\n",
    "tokenizer.pad_token = tokenizer.eos_token  # EOSトークンを使用してパディングトークンを設定\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.097488Z",
     "iopub.status.busy": "2024-07-06T12:47:04.097234Z",
     "iopub.status.idle": "2024-07-06T12:47:04.609309Z",
     "shell.execute_reply": "2024-07-06T12:47:04.608535Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.097466Z"
    }
   },
   "outputs": [],
   "source": [
    "# PEFTモデルのIDを指定し、PEFT設定を取得するためのコードです。\n",
    "# ただしこの行はコメントアウトされています。\n",
    "# peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "# peft_config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# 事前学習済みのトークナイザーを指定したモデル名から読み込みます。\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# パディングトークンのIDとトークンを設定します。\n",
    "# パディングトークンは、シーケンスの長さを揃えるために使用されます。\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id  # EOS（文の終了）トークンをパディング用に指定\n",
    "tokenizer.pad_token = tokenizer.eos_token  # EOSトークンを使用してパディングトークンを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fece919",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def tokenize_function(df):\n",
    "    result = tokenizer(df, padding=\"max_length\", truncation=True, max_length = MAX_LENGTH)\n",
    "    return result['input_ids'], result['attention_mask']\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームのテキストをトークナイズ（分割）するための関数を定義します。\n",
    "def tokenize_function(df):\n",
    "    # トークナイザーを使用して、テキストをトークン化します。\n",
    "    # paddingは最大長に合わせて行い、長さが超えた場合は切り詰めます。\n",
    "    result = tokenizer(df, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    # トークナイズした結果からinput_ids（トークンID）とattention_mask（注目マスク）を返します。\n",
    "    return result['input_ids'], result['attention_mask']  # input_ids: 入力トークンのID, attention_mask: パディング位置を示すマスク\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:47:04.610679Z",
     "iopub.status.busy": "2024-07-06T12:47:04.610405Z",
     "iopub.status.idle": "2024-07-06T12:47:04.616589Z",
     "shell.execute_reply": "2024-07-06T12:47:04.615856Z",
     "shell.execute_reply.started": "2024-07-06T12:47:04.610654Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームのテキストをトークナイズ（分割）するための関数を定義します。\n",
    "def tokenize_function(df):\n",
    "    # トークナイザーを使用して、テキストをトークン化します。\n",
    "    # paddingは最大長に合わせて行い、長さが超えた場合は切り詰めます。\n",
    "    result = tokenizer(df, padding=\"max_length\", truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "    # トークナイズした結果からinput_ids（トークンID）とattention_mask（注目マスク）を返します。\n",
    "    return result['input_ids'], result['attention_mask']  # input_ids: 入力トークンのID, attention_mask: パディング位置を示すマスク"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5452da4e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "temp = df['text'].apply(tokenize_function)\n",
    "df['input_ids'] = temp.apply(lambda x: x[0])\n",
    "df['attention_mask'] = temp.apply(lambda x: x[0])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームの'text'列に対してトークナイズ関数を適用します。\n",
    "temp = df['text'].apply(tokenize_function)\n",
    "\n",
    "# トークナイズの結果からinput_ids（トークンID）をデータフレームの新しい列'input_ids'に格納します。\n",
    "df['input_ids'] = temp.apply(lambda x: x[0])\n",
    "\n",
    "# トークナイズの結果からattention_mask（注目マスク）をデータフレームの新しい列'attention_mask'に格納します。\n",
    "# （注意: ここではinput_idsが二重に使用されているため、正しくはx[1]であるべきです。）\n",
    "df['attention_mask'] = temp.apply(lambda x: x[0])  # これはx[1]に変更する必要があります。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:00.067958Z",
     "iopub.status.busy": "2024-07-06T12:48:00.067048Z",
     "iopub.status.idle": "2024-07-06T12:48:00.081557Z",
     "shell.execute_reply": "2024-07-06T12:48:00.080565Z",
     "shell.execute_reply.started": "2024-07-06T12:48:00.067923Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームの'text'列に対してトークナイズ関数を適用します。\n",
    "temp = df['text'].apply(tokenize_function)\n",
    "\n",
    "# トークナイズの結果からinput_ids（トークンID）をデータフレームの新しい列'input_ids'に格納します。\n",
    "df['input_ids'] = temp.apply(lambda x: x[0])\n",
    "\n",
    "# トークナイズの結果からattention_mask（注目マスク）をデータフレームの新しい列'attention_mask'に格納します。\n",
    "# （注意: ここではinput_idsが二重に使用されているため、正しくはx[1]であるべきです。）\n",
    "df['attention_mask'] = temp.apply(lambda x: x[0])  # これはx[1]に変更する必要があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a580ba",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームの全体を表示します。\n",
    "# データの内容や新しく追加した列'example', 'input_ids', 'attention_mask'などを確認できます。\n",
    "df\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:07.377336Z",
     "iopub.status.busy": "2024-07-06T12:48:07.37698Z",
     "iopub.status.idle": "2024-07-06T12:48:07.39649Z",
     "shell.execute_reply": "2024-07-06T12:48:07.395322Z",
     "shell.execute_reply.started": "2024-07-06T12:48:07.377302Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームの全体を表示します。\n",
    "# データの内容や新しく追加した列'example', 'input_ids', 'attention_mask'などを確認できます。\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7329bdc",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# data = Dataset.from_pandas(df[['text']])\n",
    "# data = data.map(tokenize_function, batched=True)\n",
    "# data.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームから特定の列を使ってデータセットを作成するコードです。\n",
    "# ただし、現在この行はコメントアウトされています。\n",
    "# data = Dataset.from_pandas(df[['text']])\n",
    "\n",
    "# 作成したデータセットに対して、トークナイズ関数をバッチ処理で適用します。\n",
    "# data = data.map(tokenize_function, batched=True)\n",
    "\n",
    "# データセットの形式を設定します。PyTorch形式で、特定の列を指定します。\n",
    "# data.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.332502Z",
     "iopub.status.busy": "2024-07-06T12:48:20.331635Z",
     "iopub.status.idle": "2024-07-06T12:48:20.33626Z",
     "shell.execute_reply": "2024-07-06T12:48:20.335287Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.332467Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームから特定の列を使ってデータセットを作成するコードです。\n",
    "# ただし、現在この行はコメントアウトされています。\n",
    "# data = Dataset.from_pandas(df[['text']])\n",
    "\n",
    "# 作成したデータセットに対して、トークナイズ関数をバッチ処理で適用します。\n",
    "# data = data.map(tokenize_function, batched=True)\n",
    "\n",
    "# データセットの形式を設定します。PyTorch形式で、特定の列を指定します。\n",
    "# data.set_format(type='torch', columns=['input_ids', 'attention_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7195f37",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "# data\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データセットの内容を表示します。\n",
    "# 現在のデータセットの構造や含まれているデータの確認を行います。\n",
    "# ただし、現在この行はコメントアウトされています。\n",
    "# data\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.365693Z",
     "iopub.status.busy": "2024-07-06T12:48:20.365434Z",
     "iopub.status.idle": "2024-07-06T12:48:20.36919Z",
     "shell.execute_reply": "2024-07-06T12:48:20.368292Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.36567Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットの内容を表示します。\n",
    "# 現在のデータセットの構造や含まれているデータの確認を行います。\n",
    "# ただし、現在この行はコメントアウトされています。\n",
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd8dcf5",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "device0 = torch.device('cuda:0')\n",
    "device1 = torch.device('cuda:1')\n",
    "\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 使用するデバイスを指定します。ここでは、GPUデバイスを設定しています。\n",
    "device0 = torch.device('cuda:0')  # 最初のGPUデバイスを指定\n",
    "device1 = torch.device('cuda:1')  # 2つ目のGPUデバイスを指定\n",
    "\n",
    "# BitsAndBytesConfigを使用して、メモリ効率の良いモデルを構成します。\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでのモデル読み込みを有効にします。\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 計算に使用するデータ型を16ビット浮動小数点に設定します。\n",
    "    bnb_8bit_use_double_quant=False  # ダブル量子化を無効にします。\n",
    ")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.397825Z",
     "iopub.status.busy": "2024-07-06T12:48:20.397573Z",
     "iopub.status.idle": "2024-07-06T12:48:20.403307Z",
     "shell.execute_reply": "2024-07-06T12:48:20.402289Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.397804Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用するデバイスを指定します。ここでは、GPUデバイスを設定しています。\n",
    "device0 = torch.device('cuda:0')  # 最初のGPUデバイスを指定\n",
    "device1 = torch.device('cuda:1')  # 2つ目のGPUデバイスを指定\n",
    "\n",
    "# BitsAndBytesConfigを使用して、メモリ効率の良いモデルを構成します。\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,  # 8ビットでのモデル読み込みを有効にします。\n",
    "    bnb_8bit_compute_dtype=torch.float16,  # 計算に使用するデータ型を16ビット浮動小数点に設定します。\n",
    "    bnb_8bit_use_double_quant=False  # ダブル量子化を無効にします。\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96654d54",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# PEFTモデルのIDを指定します。\n",
    "# このパスは、指定されたディレクトリに格納されているPEFTモデルを参照します。\n",
    "peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\"\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.435991Z",
     "iopub.status.busy": "2024-07-06T12:48:20.435696Z",
     "iopub.status.idle": "2024-07-06T12:48:20.439876Z",
     "shell.execute_reply": "2024-07-06T12:48:20.438794Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.435966Z"
    }
   },
   "outputs": [],
   "source": [
    "# PEFTモデルのIDを指定します。\n",
    "# このパスは、指定されたディレクトリに格納されているPEFTモデルを参照します。\n",
    "peft_model_id = \"/kaggle/input/lmsys-llama-lora/pytorch/version1/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedabe18",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:0')\n",
    "model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model_0 = PeftModel.from_pretrained(model_0, peft_model_id).to(device0)\n",
    "model_0 = model_0.merge_and_unload()\n",
    "model_0.eval()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# Llamaモデルを事前学習済みの重みから読み込みます。\n",
    "# num_labelsは分類するラベルの数を指定します。\n",
    "model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類ラベルは3つであることを示します。\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型を16ビット浮動小数点に設定します。\n",
    "    quantization_config=bnb_config,  # 先ほど設定した量子化の設定を適用します。\n",
    "    device_map='cuda:0'  # 最初のGPUデバイスに割り当てます。\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンIDをモデルの設定に指定します。\n",
    "model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# PEFTモデルを事前学習済みのPEFT重みから読み込み、指定したデバイスに移行します。\n",
    "model_0 = PeftModel.from_pretrained(model_0, peft_model_id).to(device0)\n",
    "\n",
    "# モデルのマージとメモリからのアンロードを行います。\n",
    "model_0 = model_0.merge_and_unload()\n",
    "\n",
    "# モデルを評価モードに設定します。これにより、ドロップアウトなどのレイヤーが無効になります。\n",
    "model_0.eval()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:48:20.463942Z",
     "iopub.status.busy": "2024-07-06T12:48:20.463438Z",
     "iopub.status.idle": "2024-07-06T12:50:04.287314Z",
     "shell.execute_reply": "2024-07-06T12:50:04.286249Z",
     "shell.execute_reply.started": "2024-07-06T12:48:20.463918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Llamaモデルを事前学習済みの重みから読み込みます。\n",
    "# num_labelsは分類するラベルの数を指定します。\n",
    "model_0 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類ラベルは3つであることを示します。\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型を16ビット浮動小数点に設定します。\n",
    "    quantization_config=bnb_config,  # 先ほど設定した量子化の設定を適用します。\n",
    "    device_map='cuda:0'  # 最初のGPUデバイスに割り当てます。\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンIDをモデルの設定に指定します。\n",
    "model_0.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# PEFTモデルを事前学習済みのPEFT重みから読み込み、指定したデバイスに移行します。\n",
    "model_0 = PeftModel.from_pretrained(model_0, peft_model_id).to(device0)\n",
    "\n",
    "# モデルのマージとメモリからのアンロードを行います。\n",
    "model_0 = model_0.merge_and_unload()\n",
    "\n",
    "# モデルを評価モードに設定します。これにより、ドロップアウトなどのレイヤーが無効になります。\n",
    "model_0.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8e705d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map='cuda:1')\n",
    "model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "model_1 = PeftModel.from_pretrained(model_1, peft_model_id).to(device1)\n",
    "model_1 = model_1.merge_and_unload()\n",
    "model_1.eval()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 2つ目のLlamaモデルを事前学習済みの重みから読み込みます。\n",
    "# num_labelsは分類するラベルの数を指定します。\n",
    "model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類ラベルは3つであることを示します。\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型を16ビット浮動小数点に設定します。\n",
    "    quantization_config=bnb_config,  # 先ほど設定した量子化の設定を適用します。\n",
    "    device_map='cuda:1'  # 2つ目のGPUデバイスに割り当てます。\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンIDをモデルの設定に指定します。\n",
    "model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# PEFTモデルを事前学習済みのPEFT重みから読み込み、指定したデバイスに移行します。\n",
    "model_1 = PeftModel.from_pretrained(model_1, peft_model_id).to(device1)\n",
    "\n",
    "# モデルのマージとメモリからのアンロードを行います。\n",
    "model_1 = model_1.merge_and_unload()\n",
    "\n",
    "# モデルを評価モードに設定します。これにより、ドロップアウトなどのレイヤーが無効になります。\n",
    "model_1.eval()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:04.289854Z",
     "iopub.status.busy": "2024-07-06T12:50:04.289473Z",
     "iopub.status.idle": "2024-07-06T12:50:34.168108Z",
     "shell.execute_reply": "2024-07-06T12:50:34.16704Z",
     "shell.execute_reply.started": "2024-07-06T12:50:04.289805Z"
    }
   },
   "outputs": [],
   "source": [
    "# 2つ目のLlamaモデルを事前学習済みの重みから読み込みます。\n",
    "# num_labelsは分類するラベルの数を指定します。\n",
    "model_1 = LlamaForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 分類ラベルは3つであることを示します。\n",
    "    torch_dtype=torch.float16,  # モデルのデータ型を16ビット浮動小数点に設定します。\n",
    "    quantization_config=bnb_config,  # 先ほど設定した量子化の設定を適用します。\n",
    "    device_map='cuda:1'  # 2つ目のGPUデバイスに割り当てます。\n",
    ")\n",
    "\n",
    "# トークナイザーのパディングトークンIDをモデルの設定に指定します。\n",
    "model_1.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# PEFTモデルを事前学習済みのPEFT重みから読み込み、指定したデバイスに移行します。\n",
    "model_1 = PeftModel.from_pretrained(model_1, peft_model_id).to(device1)\n",
    "\n",
    "# モデルのマージとメモリからのアンロードを行います。\n",
    "model_1 = model_1.merge_and_unload()\n",
    "\n",
    "# モデルを評価モードに設定します。これにより、ドロップアウトなどのレイヤーが無効になります。\n",
    "model_1.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135bab4",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# ガーベジコレクションを実行します。\n",
    "# 不要なメモリを解放し、効率的なメモリ管理を促進するために使用します。\n",
    "gc.collect()\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.169604Z",
     "iopub.status.busy": "2024-07-06T12:50:34.169313Z",
     "iopub.status.idle": "2024-07-06T12:50:34.341422Z",
     "shell.execute_reply": "2024-07-06T12:50:34.340328Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.169579Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガーベジコレクションを実行します。\n",
    "# 不要なメモリを解放し、効率的なメモリ管理を促進するために使用します。\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0023476f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def inference(df,model,device,batch_size=BATCH_SIZE):\n",
    "    \n",
    "    all_probabilities = []\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        \n",
    "        batch_input_ids = torch.tensor(df['input_ids'][start_idx:end_idx].tolist()).to(device)\n",
    "        batch_attention_mask = torch.tensor(df['attention_mask'][start_idx:end_idx].tolist()).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits\n",
    "        probabilities = F.softmax(logits, dim=-1)\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    del batch_input_ids, batch_attention_mask, outputs\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()  \n",
    "\n",
    "    all_probabilities = np.array(all_probabilities)\n",
    "    \n",
    "    df['winner_model_a'] = all_probabilities[:, 0]\n",
    "    df['winner_model_b'] = all_probabilities[:, 1]\n",
    "    df['winner_tie'] = all_probabilities[:, 2]\n",
    "    return df\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# モデルを用いた推論を行うための関数を定義します。\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    # 出力結果を格納するリストを初期化します。\n",
    "    all_probabilities = []\n",
    "    \n",
    "    # データフレームをバッチサイズに基づいてループ処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終端インデックスを計算\n",
    "        \n",
    "        # バッチごとのinput_idsとattention_maskを取得し、指定したデバイスに転送します。\n",
    "        batch_input_ids = torch.tensor(df['input_ids'][start_idx:end_idx].tolist()).to(device)\n",
    "        batch_attention_mask = torch.tensor(df['attention_mask'][start_idx:end_idx].tolist()).to(device)\n",
    "        \n",
    "        # 勾配計算を無効にし、混合精度推論を使用します。\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits  # モデルの出力からlogitsを取得\n",
    "        probabilities = F.softmax(logits, dim=-1)  # logitsにソフトマックスを適用して確率を計算\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())  # 確率をリストに追加\n",
    "    \n",
    "    # バッチのテンソルを削除し、メモリを解放します。\n",
    "    del batch_input_ids, batch_attention_mask, outputs\n",
    "    gc.collect()  # ゴミ収集を実行\n",
    "    torch.cuda.empty_cache()  # CUDAメモリを空にします。\n",
    "\n",
    "    all_probabilities = np.array(all_probabilities)  # 確率をNumPy配列に変換\n",
    "    \n",
    "    # 各モデルの勝者確率をデータフレームに追加します。\n",
    "    df['winner_model_a'] = all_probabilities[:, 0]  # モデルAの勝者確率\n",
    "    df['winner_model_b'] = all_probabilities[:, 1]  # モデルBの勝者確率\n",
    "    df['winner_tie'] = all_probabilities[:, 2]  # 引き分けの確率\n",
    "    return df  # 更新されたデータフレームを返します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.34401Z",
     "iopub.status.busy": "2024-07-06T12:50:34.343704Z",
     "iopub.status.idle": "2024-07-06T12:50:34.352783Z",
     "shell.execute_reply": "2024-07-06T12:50:34.35189Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.343984Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルを用いた推論を行うための関数を定義します。\n",
    "def inference(df, model, device, batch_size=BATCH_SIZE):\n",
    "    \n",
    "    # 出力結果を格納するリストを初期化します。\n",
    "    all_probabilities = []\n",
    "    \n",
    "    # データフレームをバッチサイズに基づいてループ処理します。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # バッチの終端インデックスを計算\n",
    "        \n",
    "        # バッチごとのinput_idsとattention_maskを取得し、指定したデバイスに転送します。\n",
    "        batch_input_ids = torch.tensor(df['input_ids'][start_idx:end_idx].tolist()).to(device)\n",
    "        batch_attention_mask = torch.tensor(df['attention_mask'][start_idx:end_idx].tolist()).to(device)\n",
    "        \n",
    "        # 勾配計算を無効にし、混合精度推論を使用します。\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model(\n",
    "                    input_ids=batch_input_ids,\n",
    "                    attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits  # モデルの出力からlogitsを取得\n",
    "        probabilities = F.softmax(logits, dim=-1)  # logitsにソフトマックスを適用して確率を計算\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())  # 確率をリストに追加\n",
    "    \n",
    "    # バッチのテンソルを削除し、メモリを解放します。\n",
    "    del batch_input_ids, batch_attention_mask, outputs\n",
    "    gc.collect()  # ゴミ収集を実行\n",
    "    torch.cuda.empty_cache()  # CUDAメモリを空にします。\n",
    "\n",
    "    all_probabilities = np.array(all_probabilities)  # 確率をNumPy配列に変換\n",
    "    \n",
    "    # 各モデルの勝者確率をデータフレームに追加します。\n",
    "    df['winner_model_a'] = all_probabilities[:, 0]  # モデルAの勝者確率\n",
    "    df['winner_model_b'] = all_probabilities[:, 1]  # モデルBの勝者確率\n",
    "    df['winner_tie'] = all_probabilities[:, 2]  # 引き分けの確率\n",
    "    return df  # 更新されたデータフレームを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb8d72f",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "N_SAMPLES = len(df)\n",
    "\n",
    "half = round(N_SAMPLES / 2)\n",
    "sub1 = df.iloc[0:half].copy()\n",
    "sub2 = df.iloc[half:N_SAMPLES].copy()\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# データフレームのサンプル数を取得します。\n",
    "N_SAMPLES = len(df)\n",
    "\n",
    "# サンプルの数を半分に分割します。丸めて整数値にします。\n",
    "half = round(N_SAMPLES / 2)\n",
    "\n",
    "# データフレームを2つの部分に分割します。\n",
    "sub1 = df.iloc[0:half].copy()  # 最初の半分のデータをコピー\n",
    "sub2 = df.iloc[half:N_SAMPLES].copy()  # 残りの半分のデータをコピー\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.354286Z",
     "iopub.status.busy": "2024-07-06T12:50:34.353996Z",
     "iopub.status.idle": "2024-07-06T12:50:34.372055Z",
     "shell.execute_reply": "2024-07-06T12:50:34.371265Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.354262Z"
    }
   },
   "outputs": [],
   "source": [
    "# データフレームのサンプル数を取得します。\n",
    "N_SAMPLES = len(df)\n",
    "\n",
    "# サンプルの数を半分に分割します。丸めて整数値にします。\n",
    "half = round(N_SAMPLES / 2)\n",
    "\n",
    "# データフレームを2つの部分に分割します。\n",
    "sub1 = df.iloc[0:half].copy()  # 最初の半分のデータをコピー\n",
    "sub2 = df.iloc[half:N_SAMPLES].copy()  # 残りの半分のデータをコピー"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260aba9c",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 警告メッセージを無視する設定を行います。\n",
    "# これにより、警告メッセージが表示されなくなります。\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.373496Z",
     "iopub.status.busy": "2024-07-06T12:50:34.37319Z",
     "iopub.status.idle": "2024-07-06T12:50:34.377873Z",
     "shell.execute_reply": "2024-07-06T12:50:34.376906Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.373472Z"
    }
   },
   "outputs": [],
   "source": [
    "# 警告メッセージを無視する設定を行います。\n",
    "# これにより、警告メッセージが表示されなくなります。\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccd85d",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "def run_inference(df, model, device, results, index):\n",
    "    results[index] = inference(df, model, device)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 推論を実行するための関数を定義します。\n",
    "def run_inference(df, model, device, results, index):\n",
    "    # 指定されたインデックスに対して、推論結果を保存します。\n",
    "    results[index] = inference(df, model, device)  # inference関数を呼び出して結果を取得し、resultsリストに格納\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.379363Z",
     "iopub.status.busy": "2024-07-06T12:50:34.379101Z",
     "iopub.status.idle": "2024-07-06T12:50:34.388717Z",
     "shell.execute_reply": "2024-07-06T12:50:34.387884Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.379339Z"
    }
   },
   "outputs": [],
   "source": [
    "# 推論を実行するための関数を定義します。\n",
    "def run_inference(df, model, device, results, index):\n",
    "    # 指定されたインデックスに対して、推論結果を保存します。\n",
    "    results[index] = inference(df, model, device)  # inference関数を呼び出して結果を取得し、resultsリストに格納"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b493f0",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "results = {}\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0,results, 0))\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1,results, 1))\n",
    "\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# Wait for all threads to finish\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "data = pd.concat([results[0], results[1]], axis=0)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 結果を格納するための辞書を初期化します。\n",
    "results = {}\n",
    "\n",
    "# サブデータセットに対して異なるモデルで推論を行うためのスレッドを作成します。\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # モデル0用のスレッド\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # モデル1用のスレッド\n",
    "\n",
    "# スレッドを起動します。\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# すべてのスレッドが終了するのを待ちます。\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 2つの結果を結合して単一のデータフレームにします。\n",
    "data = pd.concat([results[0], results[1]], axis=0)  # 縦に結合します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:34.390058Z",
     "iopub.status.busy": "2024-07-06T12:50:34.389766Z",
     "iopub.status.idle": "2024-07-06T12:50:49.752074Z",
     "shell.execute_reply": "2024-07-06T12:50:49.751267Z",
     "shell.execute_reply.started": "2024-07-06T12:50:34.390026Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果を格納するための辞書を初期化します。\n",
    "results = {}\n",
    "\n",
    "# サブデータセットに対して異なるモデルで推論を行うためのスレッドを作成します。\n",
    "t0 = Thread(target=run_inference, args=(sub1, model_0, device0, results, 0))  # モデル0用のスレッド\n",
    "t1 = Thread(target=run_inference, args=(sub2, model_1, device1, results, 1))  # モデル1用のスレッド\n",
    "\n",
    "# スレッドを起動します。\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# すべてのスレッドが終了するのを待ちます。\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 2つの結果を結合して単一のデータフレームにします。\n",
    "data = pd.concat([results[0], results[1]], axis=0)  # 縦に結合します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae7399",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "data.drop(columns=['prompt','response_a','response_b','text','input_ids','attention_mask'],axis=1,inplace=True)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 不要な列をデータフレームから削除します。\n",
    "# 'prompt', 'response_a', 'response_b', 'text', 'input_ids', 'attention_mask'の各列を削除します。\n",
    "data.drop(columns=['prompt', 'response_a', 'response_b', 'text', 'input_ids', 'attention_mask'], axis=1, inplace=True)  # 'inplace=True' でデータフレームを直接更新します。\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:49.753862Z",
     "iopub.status.busy": "2024-07-06T12:50:49.753229Z",
     "iopub.status.idle": "2024-07-06T12:50:49.764639Z",
     "shell.execute_reply": "2024-07-06T12:50:49.763794Z",
     "shell.execute_reply.started": "2024-07-06T12:50:49.753807Z"
    }
   },
   "outputs": [],
   "source": [
    "# 不要な列をデータフレームから削除します。\n",
    "# 'prompt', 'response_a', 'response_b', 'text', 'input_ids', 'attention_mask'の各列を削除します。\n",
    "data.drop(columns=['prompt', 'response_a', 'response_b', 'text', 'input_ids', 'attention_mask'], axis=1, inplace=True)  # 'inplace=True' でデータフレームを直接更新します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c647c48",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "data\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終的なデータフレームの内容を表示します。\n",
    "# 不要な列を削除した後のデータフレームの構造や残っているデータを確認します。\n",
    "data\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:51:10.982061Z",
     "iopub.status.busy": "2024-07-06T12:51:10.981323Z",
     "iopub.status.idle": "2024-07-06T12:51:10.99276Z",
     "shell.execute_reply": "2024-07-06T12:51:10.991895Z",
     "shell.execute_reply.started": "2024-07-06T12:51:10.982017Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最終的なデータフレームの内容を表示します。\n",
    "# 不要な列を削除した後のデータフレームの構造や残っているデータを確認します。\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9040136e",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>pythonコードの比較（クリックすると展開されます）</summary>\n",
    "\n",
    "<style>\n",
    ".column-left{\n",
    "  float: left;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-right{\n",
    "  float: right;\n",
    "  width: 47.5%;\n",
    "  text-align: left;\n",
    "}\n",
    ".column-one{\n",
    "  float: left;\n",
    "  width: 100%;\n",
    "  text-align: left;\n",
    "}\n",
    "</style>\n",
    "\n",
    "\n",
    "<div class=\"column-left\">\n",
    "\n",
    "# original\n",
    "\n",
    "```python\n",
    "data.to_csv(\"submission.csv\",index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "<div class=\"column-right\">\n",
    "\n",
    "# 日本語訳\n",
    "\n",
    "```python\n",
    "# 最終的なデータフレームをCSVファイルとして保存します。\n",
    "# 'submission.csv'というファイル名で、インデックスは含めずに保存します。\n",
    "data.to_csv(\"submission.csv\", index=False)\n",
    "```\n",
    "\n",
    "</div>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T12:50:49.767486Z",
     "iopub.status.busy": "2024-07-06T12:50:49.767222Z",
     "iopub.status.idle": "2024-07-06T12:50:49.836704Z",
     "shell.execute_reply": "2024-07-06T12:50:49.835875Z",
     "shell.execute_reply.started": "2024-07-06T12:50:49.767463Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最終的なデータフレームをCSVファイルとして保存します。\n",
    "# 'submission.csv'というファイル名で、インデックスは含めずに保存します。\n",
    "data.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4281572,
     "sourceId": 7369493,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28071,
     "sourceId": 33534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 28079,
     "sourceId": 33547,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 62824,
     "sourceId": 74803,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
