# 要約 
このディスカッションは、Chatbot Arenaコンペティションのトレーニングデータが、単一の質問と回答ではなく、会話で構成されていることを明らかにしています。

**steubk**は、Chatbot Arenaのルールを説明し、会話の最後の質問が勝敗を決定し、それ以前の質問は引き分けとみなせることを示唆しています。

**Valentin Werner**は、最後の質問が最初の質問よりも重要であるため、トレーニングデータから最初の質問を削除する方が良いと主張しています。

**Shreshth Sharma**は、会話全体がモデルの評価に重要であり、最後の質問だけでなく、会話全体で生成された応答も考慮すべきだと主張しています。

**Valentin Werner**は、モデルが会話全体からユーザーにとって重要な質問と回答を学習できる可能性があると述べています。

このディスカッションは、Chatbot Arenaコンペティションのトレーニングデータの構造と、モデルの評価方法について重要な洞察を提供しています。参加者は、会話全体を考慮し、モデルが会話全体からユーザーの好みを学習できるようにする必要があります。


---


<style>
.column-left{
  float: left;
  width: 47.5%;
  text-align: left;
}
.column-right{
  float: right;
  width: 47.5%;
  text-align: left;
}
.column-one{
  float: left;
  width: 100%;
  text-align: left;
}
</style>


<div class="column-left">

# original

# Chatbot Arena's Rules

**steubk** *Thu May 09 2024 14:01:52 GMT+0900 (日本標準時)* (8 votes)

It has been noticed that the train set consists of conversations rather than single prompts and responses. ([https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633)](https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633)).

These are the rules of the chatbot arena ( [https://chat.lmsys.org/](https://chat.lmsys.org/) ) :

- Ask any question to two anonymous models (e.g., ChatGPT, Claude, Llama) and vote for the better one!

- You can chat for multiple turns until you identify a winner.

- Votes won't be counted if model identities are revealed during the conversation.

As a rough approximation, you might think that the last question has a winner while all the previous ones are ties.

Hope this helps!



---

 # Comments from other users

> ## Valentin Werner
> 
> This is highly important because this means that the last prompt and responses are more valuable than the first ones.
> 
> If you are truncating these information, you should truncate the start, not the end!
> 
> 
> 
> > ## Shreshth Sharma
> > 
> > Ideally, the model difference is generated by the prompt asked first and the response generated at the end. But don't you think that the responses generated in between also preserve important information since if a human makes the final selection, he/she will also consider the thinking process of LLM? Since reaching the right answer with unexplainable thinking itself will result in less credibility of the model.
> > 
> > 
> > 
> > > ## Valentin Werner
> > > 
> > > Models might be able to learn which prompt and response combination was the one that actually mattered to the user. I can only speak for myself, that I always voted once I was "that response is better", kind of disregarding everything else beforehand
> > > 
> > > 
> > > 


---



</div>
<div class="column-right">

# 日本語訳

# チャットボットアリーナのルール

**steubk** *2024年5月9日 木曜日 14:01:52 日本標準時* (8票)

トレーニングセットが単一のプロンプトと応答ではなく、会話で構成されていることに気づきました。([https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633](https://www.kaggle.com/competitions/lmsys-chatbot-arena/discussion/500633))。

チャットボットアリーナのルールは以下のとおりです（[https://chat.lmsys.org/](https://chat.lmsys.org/)）：

- 2つの匿名のモデル（例：ChatGPT、Claude、Llama）に質問をし、どちらが優れているか投票します！
- 勝者が見つかるまで、複数ターンにわたってチャットできます。
- 会話中にモデルのアイデンティティが明らかになった場合、投票はカウントされません。

大まかな近似として、最後の質問に勝者がいると考え、それ以前の質問はすべて引き分けと考えることができます。

お役に立てれば幸いです！

---

# 他のユーザーからのコメント

> ## Valentin Werner
> 
> これは非常に重要です。なぜなら、これは最後のプロンプトと応答が最初のものよりも価値があることを意味するからです。
> 
> この情報を切り捨てる場合は、終わりではなく、始めを切り捨てるべきです！
> 
> 
> 
> > ## Shreshth Sharma
> > 
> > 理想的には、モデルの違いは最初に尋ねられたプロンプトと最後に生成された応答によって生成されます。しかし、人間の最終的な選択は、LLMの思考プロセスも考慮するため、間に生成された応答も重要な情報を保持していると思いませんか？説明できない思考で正しい答えにたどり着くことは、モデルの信頼性を低下させる結果になります。
> > 
> > 
> > 
> > > ## Valentin Werner
> > > 
> > > モデルは、どのプロンプトと応答の組み合わせが実際にユーザーにとって重要だったかを学習できるかもしれません。私は自分のことしか言えませんが、私は常に「その応答の方が良い」と思ったときに投票し、それ以前のことはすべて無視していました。
> > > 
> > > 
> > > 
---



</div>