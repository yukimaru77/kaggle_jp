{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02e5c50",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、「LMSYS - Chatbot Arena人間による好み予測チャレンジ」に参加するための機械学習モデルの構築プロセスを示しています。主な目的は、2つの異なる言語モデル（LLM）が生成した応答の中から、どちらがユーザーに好まれるかを予測することです。\n",
    "\n",
    "### 問題の取り組み\n",
    "本Notebookでは、提供されたトレーニングデータを使用して、ユーザーが選択した応答の勝者を予測するモデルを構築しています。具体的には、ユーザーが選んだモデルの応答に基づいて、クラス分類問題を解決します。データの不均衡が存在するため、SMOTE（Synthetic Minority Over-sampling Technique）を用いて不均衡データのリサンプリングも行っています。\n",
    "\n",
    "### 使用する手法とライブラリ\n",
    "Notebookでは以下の手法とライブラリが使用されています：\n",
    "- **NumPyとPandas**: 配列操作やデータフレームの操作に使用され、データの前処理と可視化に役立ちます。\n",
    "- **Scikit-learn**: モデルの構築と評価に用いられ、特に以下が使用されています。\n",
    "  - `TfidfVectorizer`: テキストデータをベクトル化するために使用。\n",
    "  - `LogisticRegression`, `RandomForestClassifier`, `GradientBoostingClassifier`: 様々な分類モデルの構築に使用。\n",
    "  - `GridSearchCV`: ハイパーパラメータの最適化に利用。\n",
    "  - `SMOTE`: 不均衡データのオーバーサンプリングに使用。\n",
    "  - `classification_report`, `log_loss`, `confusion_matrix`, `roc_curve`: モデルの評価指標。\n",
    "  \n",
    "- **MatplotlibとSeaborn**: データの可視化によく使われ、クラス分布のプロットや混同行列、ROC曲線などが表示されます。\n",
    "\n",
    "### プロセスの概要\n",
    "1. **データ収集**: トレーニングデータとテストデータをCSVファイルから読み込み。\n",
    "2. **データ理解**: データの情報を確認し、特にクラスの分布などを可視化。\n",
    "3. **データ準備**: テキストデータのクリーニング（URLやHTMLタグの除去、ストップワードの削除）を行い、テキストデータをTF-IDFベクトルに変換。\n",
    "4. **特長エンジニアリング**: 応答の長さや自己強調に関する特徴量を追加。\n",
    "5. **モデルの選択と評価**: モデルをトレーニング、バリデーションセットで評価、最適なハイパーパラメータを探索。\n",
    "6. **予測**: 最良モデルを用いてテストデータに対する予測確率を生成し、最終的な提出ファイルを作成。\n",
    "\n",
    "最終的に、テストデータの予測結果を含むCSVファイルを作成し、提出準備を完了します。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cc0fe",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説をリストします。特に、初心者にとってマイナーなものや実務経験がないと馴染みが薄い用語、ノートブック特有のドメイン知識に焦点を当てました。\n",
    "\n",
    "1. **TF-IDF（Term Frequency-Inverse Document Frequency）**:\n",
    "   - 文書における単語の重要性を評価する手法。単語の出現頻度とその単語が他の文書に出現する頻度を考慮して、情報をベクトルで表現する。\n",
    "\n",
    "2. **SMOTE（Synthetic Minority Over-sampling Technique）**:\n",
    "   - 不均衡データ処理手法の一つ。少数派クラスのサンプルを合成することでサンプル数を増やし、クラスバランスを改善する。近傍のデータポイントを元に新しいサンプルを生成する。\n",
    "\n",
    "3. **クラス分布**:\n",
    "   - データの各クラス（ラベル）がどのように分布しているかを示す。例えば、2つのクラスがある場合、クラスAとクラスBのデータポイントの割合を示す。\n",
    "\n",
    "4. **バイアス（Bias）**:\n",
    "   - モデルやデータ処理において、特定の特徴や傾向に偏りが生じる現象。例えば、どちらかのモデルの応答が常に選ばれることがある場合、順序バイアスが存在する。\n",
    "\n",
    "5. **ポジションバイアス**:\n",
    "   - 対応する応答がリスト上でどの位置にあるかによる影響。例えば、最初に提示された応答が好まれる傾向がある。\n",
    "\n",
    "6. **セルフエンハンスメント**:\n",
    "   - 自己宣伝とも言われ、モデルが自身を過剰に良く見せるために用いる表現やキーワード。例えば、「私は最高の〇〇です」といった表現を含む。\n",
    "\n",
    "7. **ダミー変数（Dummy Variables）**:\n",
    "   - カテゴリデータを数値データに変換するために使用される変数。例えば、「モデルA」と「モデルB」というカテゴリをそれぞれ0と1の値に変換して扱う。\n",
    "\n",
    "8. **グリッドサーチ（Grid Search）**:\n",
    "   - ハイパーパラメータの最適化手法。指定された複数のハイパーパラメータの組み合わせを試し、その中から最適なモデルを選ぶ。\n",
    "\n",
    "9. **混同行列**:\n",
    "   - モデルの予測性能を示す行列。真陽性、偽陽性、真陰性、偽陰性の数を用いて、モデルの分類結果を視覚化する。\n",
    "\n",
    "10. **ROC曲線（Receiver Operating Characteristic Curve）**:\n",
    "   - 分類モデルの性能を評価するためのグラフ。偽陽性率と真陽性率をプロットしたもので、曲線の下の面積（AUC）が大きいほどモデルの性能が良いとされる。\n",
    "\n",
    "これらの用語は、初心者が理解するのが難しいが、特定のコンテキストや実務経験があれば意味を把握できるものです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-11T09:31:16.06664Z",
     "iopub.status.busy": "2024-07-11T09:31:16.066182Z",
     "iopub.status.idle": "2024-07-11T09:31:17.822835Z",
     "shell.execute_reply": "2024-07-11T09:31:17.820993Z",
     "shell.execute_reply.started": "2024-07-11T09:31:16.066602Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# たとえば、以下はいくつかの便利なパッケージのロード方法です\n",
    "\n",
    "import numpy as np # 線形代数のためのライブラリ\n",
    "import pandas as pd # データ処理とCSVファイルの入出力 (例: pd.read_csv)\n",
    "\n",
    "# 入力データファイルは、読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# たとえば、これを実行すると（クリックするかShift+Enterを押すことで）入力ディレクトリ下の全ファイルが一覧表示されます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'): # 指定したディレクトリ内を再帰的に探索します\n",
    "    for filename in filenames: # 見つかったファイルのリストをループします\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのフルパスを出力します\n",
    "\n",
    "# 現在のディレクトリ (/kaggle/working/) には最大で20GBのデータを書き込むことができ、\n",
    "# このデータは「保存してすべて実行」を使用してバージョンを作成するときに出力として保存されます\n",
    "# また、一時ファイルを/kaggle/temp/に書き込むこともできますが、これは現在のセッションの外で保存されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:34:46.155601Z",
     "iopub.status.busy": "2024-07-11T09:34:46.154388Z",
     "iopub.status.idle": "2024-07-11T09:34:46.163657Z",
     "shell.execute_reply": "2024-07-11T09:34:46.162306Z",
     "shell.execute_reply.started": "2024-07-11T09:34:46.155552Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします\n",
    "import numpy as np  # 数値計算用のライブラリ\n",
    "import pandas as pd  # データ処理用のライブラリ\n",
    "import re  # 正規表現操作用のライブラリ\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトル化用\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV  # データ分割およびグリッドサーチ用\n",
    "from sklearn.metrics import classification_report, log_loss, confusion_matrix, roc_curve, auc  # モデル評価用のメトリクス\n",
    "from imblearn.over_sampling import SMOTE  # 不均衡データを扱うためのオーバーサンプリング手法\n",
    "from sklearn.linear_model import LogisticRegression  # ロジスティック回帰モデル\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # ランダムフォレストおよび勾配ブースティングモデル\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のライブラリ\n",
    "import seaborn as sns  # データ可視化用のライブラリ\n",
    "\n",
    "print('全てのライブラリがインポートされました')  # インポートが完了したことを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:34:54.45723Z",
     "iopub.status.busy": "2024-07-11T09:34:54.455786Z",
     "iopub.status.idle": "2024-07-11T09:34:58.404044Z",
     "shell.execute_reply": "2024-07-11T09:34:58.402866Z",
     "shell.execute_reply.started": "2024-07-11T09:34:54.457178Z"
    }
   },
   "outputs": [],
   "source": [
    "# データ収集\n",
    "train_file = '/kaggle/input/lmsys-chatbot-arena/train.csv'  # トレーニングデータのファイルパス\n",
    "test_file = '/kaggle/input/lmsys-chatbot-arena/test.csv'  # テストデータのファイルパス\n",
    "train_data = pd.read_csv(train_file)  # トレーニングデータをCSVファイルから読み込みます\n",
    "test_data = pd.read_csv(test_file)  # テストデータをCSVファイルから読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:35:08.07966Z",
     "iopub.status.busy": "2024-07-11T09:35:08.079216Z",
     "iopub.status.idle": "2024-07-11T09:35:08.445124Z",
     "shell.execute_reply": "2024-07-11T09:35:08.443929Z",
     "shell.execute_reply.started": "2024-07-11T09:35:08.079625Z"
    }
   },
   "outputs": [],
   "source": [
    "# データ理解\n",
    "print(\"トレーニングデータセット情報:\")\n",
    "print(train_data.info())  # トレーニングデータセットの情報を表示します\n",
    "print(\"\\n最初の数行:\")\n",
    "print(train_data.head())  # トレーニングデータの最初の数行を表示します\n",
    "\n",
    "print(\"\\nテストデータセット情報:\")\n",
    "print(test_data.info())  # テストデータセットの情報を表示します\n",
    "print(\"\\n最初の数行:\")\n",
    "print(test_data.head())  # テストデータの最初の数行を表示します\n",
    "\n",
    "# リサンプリング前のクラス分布を可視化\n",
    "plt.figure(figsize=(12, 6))  # グラフのサイズを設定\n",
    "sns.countplot(x=train_data['winner_model_a'])  # 'winner_model_a'のクラス分布をカウントプロットします\n",
    "plt.title(\"リサンプリング前のクラス分布\")  # グラフのタイトルを設定\n",
    "plt.show()  # グラフを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:35:16.89655Z",
     "iopub.status.busy": "2024-07-11T09:35:16.895836Z",
     "iopub.status.idle": "2024-07-11T09:35:22.952786Z",
     "shell.execute_reply": "2024-07-11T09:35:22.951303Z",
     "shell.execute_reply.started": "2024-07-11T09:35:16.896495Z"
    }
   },
   "outputs": [],
   "source": [
    "# データ準備\n",
    "def clean_text(text, stop_words):  # テキストをクリーンアップする関数\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # 角括弧内のテキストを削除\n",
    "    text = re.sub(r'http\\S+|www.\\S+', '', text)  # URLを削除\n",
    "    text = re.sub(r'<.*?>+', '', text)  # HTMLタグを削除\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # アルファベットとスペース以外の文字を削除\n",
    "    text = text.lower()  # すべての文字を小文字に変換\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)  # ストップワードを削除\n",
    "    return text  # クリーンアップされたテキストを返す\n",
    "\n",
    "stop_words = set()  # ストップワードのセットを初期化\n",
    "\n",
    "# テキストデータをクリーンアップ\n",
    "train_data['prompt'] = train_data['prompt'].apply(lambda x: clean_text(x, stop_words))  # 'prompt'列のテキストをクリーンアップ\n",
    "train_data['response_a'] = train_data['response_a'].apply(lambda x: clean_text(x, stop_words))  # 'response_a'列のテキストをクリーンアップ\n",
    "train_data['response_b'] = train_data['response_b'].apply(lambda x: clean_text(x, stop_words))  # 'response_b'列のテキストをクリーンアップ\n",
    "\n",
    "test_data['prompt'] = test_data['prompt'].apply(lambda x: clean_text(x, stop_words))  # テストデータの'prompt'列をクリーンアップ\n",
    "test_data['response_a'] = test_data['response_a'].apply(lambda x: clean_text(x, stop_words))  # テストデータの'response_a'列をクリーンアップ\n",
    "test_data['response_b'] = test_data['response_b'].apply(lambda x: clean_text(x, stop_words))  # テストデータの'response_b'列をクリーンアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:35:31.208589Z",
     "iopub.status.busy": "2024-07-11T09:35:31.208024Z",
     "iopub.status.idle": "2024-07-11T09:35:34.26134Z",
     "shell.execute_reply": "2024-07-11T09:35:34.260045Z",
     "shell.execute_reply.started": "2024-07-11T09:35:31.208544Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストデータをベクトル化\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # 最大1000特徴を持つTF-IDFベクトルライザーを作成\n",
    "train_text = train_data['prompt'] + ' ' + train_data['response_a'] + ' ' + train_data['response_b']  # トレーニングテキストを結合\n",
    "test_text = test_data['prompt'] + ' ' + test_data['response_a'] + ' ' + test_data['response_b']  # テストテキストを結合\n",
    "\n",
    "X_train_text = vectorizer.fit_transform(train_text)  # トレーニングデータをTF-IDFベクトル化\n",
    "X_test_text = vectorizer.transform(test_text)  # テストデータをTF-IDFベクトル化\n",
    "\n",
    "# 表現のバイアス - 応答の長さと長さの差を追加\n",
    "train_data['response_a_length'] = train_data['response_a'].apply(len)  # 'response_a'の長さを計算\n",
    "train_data['response_b_length'] = train_data['response_b'].apply(len)  # 'response_b'の長さを計算\n",
    "test_data['response_a_length'] = test_data['response_a'].apply(len)  # テストデータの'response_a'の長さを計算\n",
    "test_data['response_b_length'] = test_data['response_b'].apply(len)  # テストデータの'response_b'の長さを計算\n",
    "train_data['length_diff'] = train_data['response_a_length'] - train_data['response_b_length']  # 応答長の差を計算\n",
    "test_data['length_diff'] = test_data['response_a_length'] - test_data['response_b_length']  # テストデータの応答長の差を計算\n",
    "\n",
    "# ポジションバイアス - ポジションバイアスの特徴を追加\n",
    "train_data['position_bias_a'] = 0  # 'response_a'が常に最初であると仮定\n",
    "train_data['position_bias_b'] = 1  # 'response_b'が常に2番目であると仮定\n",
    "test_data['position_bias_a'] = 0\n",
    "test_data['position_bias_b'] = 1\n",
    "\n",
    "# セルフエンハンスメントバイアス - セルフエンハンスメント検出の特徴を追加\n",
    "def detect_self_enhancement(text):  # セルフエンハンスメントを検出する関数\n",
    "    keywords = ['best', 'better', 'excellent', 'superior', 'number one']  # キーワードリスト\n",
    "    for keyword in keywords:  # キーワードの各要素について\n",
    "        if keyword in text:  # キーワードがテキストに含まれているかチェック\n",
    "            return 1  # 見つかった場合は1を返す\n",
    "    return 0  # 見つからなかった場合は0を返す\n",
    "\n",
    "train_data['self_enhancement_a'] = train_data['response_a'].apply(detect_self_enhancement)  # 'response_a'のセルフエンハンスメントを検出\n",
    "train_data['self_enhancement_b'] = train_data['response_b'].apply(detect_self_enhancement)  # 'response_b'のセルフエンハンスメントを検出\n",
    "test_data['self_enhancement_a'] = test_data['response_a'].apply(detect_self_enhancement)  # テストデータの'response_a'のセルフエンハンスメントを検出\n",
    "test_data['self_enhancement_b'] = test_data['response_b'].apply(detect_self_enhancement)  # テストデータの'response_b'のセルフエンハンスメントを検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:36:01.536381Z",
     "iopub.status.busy": "2024-07-11T09:36:01.535916Z",
     "iopub.status.idle": "2024-07-11T09:36:02.104743Z",
     "shell.execute_reply": "2024-07-11T09:36:02.103381Z",
     "shell.execute_reply.started": "2024-07-11T09:36:01.536331Z"
    }
   },
   "outputs": [],
   "source": [
    "# カテゴリカル特徴のエンコーディング\n",
    "categorical_columns = ['model_a', 'model_b']  # カテゴリカル列のリスト\n",
    "for column in categorical_columns:  # 各カテゴリカル列について\n",
    "    if column not in test_data.columns:  # テストデータに列が存在しない場合\n",
    "        test_data[column] = 'missing'  # 存在しない列には'missing'という値を設定\n",
    "train_data_encoded = pd.get_dummies(train_data, columns=categorical_columns)  # トレーニングデータをダミー変数にエンコード\n",
    "test_data_encoded = pd.get_dummies(test_data, columns=categorical_columns)  # テストデータをダミー変数にエンコード\n",
    "train_data_encoded, test_data_encoded = train_data_encoded.align(test_data_encoded, join='left', axis=1, fill_value=0)  # データセットの整合性を確保\n",
    "\n",
    "# 欠損列の処理\n",
    "test_data_encoded.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie'], errors='ignore', inplace=True)  # テストデータから無視可能な列を削除\n",
    "\n",
    "# 非数値列の削除\n",
    "non_numeric_columns = train_data_encoded.select_dtypes(exclude=[np.number]).columns  # 非数値列を選択\n",
    "train_data_encoded.drop(columns=non_numeric_columns, inplace=True)  # トレーニングデータから非数値列を削除\n",
    "test_data_encoded.drop(columns=non_numeric_columns, inplace=True)  # テストデータから非数値列を削除\n",
    "\n",
    "# すべての特徴をトレーニングおよびテストセットに結合\n",
    "X_train_combined = np.hstack((X_train_text.toarray(), train_data_encoded.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie']).values))  # トレーニングセットを結合\n",
    "X_test_combined = np.hstack((X_test_text.toarray(), test_data_encoded.values))  # テストセットを結合\n",
    "X = X_train_combined  # 特徴行列Xにトレーニングセットを設定\n",
    "y = train_data_encoded['winner_model_a']  # 目的変数yにトレーニングデータの'winner_model_a'を設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:36:16.126603Z",
     "iopub.status.busy": "2024-07-11T09:36:16.126148Z",
     "iopub.status.idle": "2024-07-11T09:36:32.788713Z",
     "shell.execute_reply": "2024-07-11T09:36:32.787375Z",
     "shell.execute_reply.started": "2024-07-11T09:36:16.126566Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデリング\n",
    "# データのリサンプリング\n",
    "smote = SMOTE(random_state=42)  # SMOTEインスタンスを作成（ランダムシードを42に設定）\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)  # データをリサンプリング\n",
    "\n",
    "# リサンプリング後のクラス分布を可視化\n",
    "plt.figure(figsize=(12, 6))  # グラフのサイズを設定\n",
    "sns.countplot(x=y_resampled)  # リサンプリング後のクラス分布をカウントプロット\n",
    "plt.title(\"リサンプリング後のクラス分布\")  # グラフのタイトルを設定\n",
    "plt.show()  # グラフを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:36:37.575501Z",
     "iopub.status.busy": "2024-07-11T09:36:37.574799Z",
     "iopub.status.idle": "2024-07-11T09:36:37.793416Z",
     "shell.execute_reply": "2024-07-11T09:36:37.792022Z",
     "shell.execute_reply.started": "2024-07-11T09:36:37.57546Z"
    }
   },
   "outputs": [],
   "source": [
    "# リサンプルされたデータをトレーニングセットとバリデーションセットに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # データを80%トレーニング、20%バリデーションに分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T09:36:46.735141Z",
     "iopub.status.busy": "2024-07-11T09:36:46.73429Z",
     "iopub.status.idle": "2024-07-11T11:09:25.315774Z",
     "shell.execute_reply": "2024-07-11T11:09:25.314176Z",
     "shell.execute_reply.started": "2024-07-11T09:36:46.735105Z"
    }
   },
   "outputs": [],
   "source": [
    "# ハイパーパラメータの調整とモデル選択\n",
    "models = {  # 使用するモデルの設定\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),  # ロジスティック回帰モデル\n",
    "        'params': {'C': [0.01, 0.1, 1, 10, 100]}  # ハイパーパラメータの候補\n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),  # ランダムフォレストモデル\n",
    "        'params': {'n_estimators': [50, 100, 200], 'max_depth': [10, 20, 30]}  # ハイパーパラメータの候補\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'model': GradientBoostingClassifier(random_state=42),  # 勾配ブースティングモデル\n",
    "        'params': {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200]}  # ハイパーパラメータの候補\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models = {}  # 最良モデルを格納する辞書\n",
    "\n",
    "for model_name, config in models.items():  # 各モデルについて\n",
    "    grid_search = GridSearchCV(estimator=config['model'], param_grid=config['params'], cv=5, scoring='neg_log_loss', verbose=2, n_jobs=-1)  # グリッドサーチを設定\n",
    "    grid_search.fit(X_train, y_train)  # トレーニングデータでモデルを学習\n",
    "    best_models[model_name] = grid_search.best_estimator_  # 最良モデルを保存\n",
    "    print(f\"最良の{model_name}モデル: {grid_search.best_params_}\")  # 最良ハイパーパラメータを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T11:10:04.345155Z",
     "iopub.status.busy": "2024-07-11T11:10:04.344728Z",
     "iopub.status.idle": "2024-07-11T11:10:08.986953Z",
     "shell.execute_reply": "2024-07-11T11:10:08.98556Z",
     "shell.execute_reply.started": "2024-07-11T11:10:04.345116Z"
    }
   },
   "outputs": [],
   "source": [
    "# 評価\n",
    "for model_name, model in best_models.items():  # 最良モデルの各名称とモデルについて\n",
    "    y_val_pred = model.predict(X_val)  # バリデーションセットに対する予測を行う\n",
    "    y_val_pred_proba = model.predict_proba(X_val)  # バリデーションセットに対する予測確率を計算\n",
    "    print(f\"バリデーションセットの分類レポート ({model_name}):\")\n",
    "    print(classification_report(y_val, y_val_pred, zero_division=1))  # 分類レポートを表示\n",
    "    print(f\"ログ損失 ({model_name}): {log_loss(y_val, y_val_pred_proba)}\")  # ログ損失を表示\n",
    "\n",
    "    # 混同行列\n",
    "    cm = confusion_matrix(y_val, y_val_pred)  # 混同行列を計算\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')  # 混同行列をヒートマップで表示\n",
    "    plt.title(f'混同行列 ({model_name})')  # タイトルを設定\n",
    "    plt.xlabel('予測値')  # x軸のラベルを設定\n",
    "    plt.ylabel('真の値')  # y軸のラベルを設定\n",
    "    plt.show()  # グラフを表示\n",
    "\n",
    "    # ROC曲線\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_val_pred_proba[:, 1])  # 偽陽性率と真陽性率を計算\n",
    "    roc_auc = auc(fpr, tpr)  # ROC曲線の下の面積を計算\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC曲線 (面積 = %0.2f)' % roc_auc)  # ROC曲線をプロット\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')  # 対角線をプロット\n",
    "    plt.xlim([0.0, 1.0])  # x軸の範囲を設定\n",
    "    plt.ylim([0.0, 1.05])  # y軸の範囲を設定\n",
    "    plt.xlabel('偽陽性率')  # x軸のラベルを設定\n",
    "    plt.ylabel('真陽性率')  # y軸のラベルを設定\n",
    "    plt.title(f'受信者動作特性 ({model_name})')  # タイトルを設定\n",
    "    plt.legend(loc=\"lower right\")  # 凡例を表示\n",
    "    plt.show()  # グラフを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-11T11:10:31.161289Z",
     "iopub.status.busy": "2024-07-11T11:10:31.160802Z",
     "iopub.status.idle": "2024-07-11T11:10:31.184943Z",
     "shell.execute_reply": "2024-07-11T11:10:31.18274Z",
     "shell.execute_reply.started": "2024-07-11T11:10:31.16125Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最良モデルを用いたデプロイメント (例: ロジスティック回帰)\n",
    "best_lr_model = best_models['Logistic Regression']  # 最良のロジスティック回帰モデルを取得\n",
    "test_predictions_proba = best_lr_model.predict_proba(X_test_combined)  # テストデータに対する予測確率を計算\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_data['id'],  # テストデータのIDを追加\n",
    "    'winner_model_a': test_predictions_proba[:, 0],  # モデルAの予測確率を追加\n",
    "    'winner_model_b': test_predictions_proba[:, 1],  # モデルBの予測確率を追加\n",
    "    'winner_tie': 0.0  # バイナリ分類であると仮定し、引き分けの列を0.0に設定\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)  # 提出用ファイルをCSVとして保存\n",
    "print(submission_df.head())  # 提出用ファイルの先頭行を表示\n",
    "print(\"提出ファイルが正常に保存されました。\")  # 保存完了のメッセージを表示"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
