{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "313884b6",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYS - Chatbot Arenaコンペティションにおけるトピックモデリングを目的としたもので、主要な問題はテキストデータから有意義なトピックを抽出し、それを視覚化することです。特に、ユーザーからのプロンプトとそれに対する応答を解析し、各プロンプトの潜在的なパターンを特定することで、チャットボットの応答を改善するための洞察を得ることを目指しています。\n",
    "\n",
    "### 使用されている手法およびライブラリ\n",
    "\n",
    "1. **テキスト処理とデータ前処理**:\n",
    "   - **Pandas**: データフレームを操作し、トレーニングとテストデータを読み込み、空の応答を除外するために使用。\n",
    "   - **literal_eval**: 文字列をPythonのリテラルに変換するために使用。\n",
    "\n",
    "2. **トピックモデリング**:\n",
    "   - **BERTopic**: トピックモデリングを行うためのライブラリで、以下の一連の処理を実施:\n",
    "     - **SentenceTransformer**: 文を埋め込みベクトルに変換。\n",
    "     - **UMAP**: 次元削減手法で、データの次元数を減少させるために使用。\n",
    "     - **HDBSCAN**: 様々な形状のクラスタを見つけるための密度ベースのクラスタリング手法。\n",
    "     - **CountVectorizer / TfidfVectorizer**: テキストデータを数値ベクトルに変換。\n",
    "     - **c-TF-IDF**: 重み付けされたトピック表現を生成するために使われる。\n",
    "\n",
    "3. **視覚化手法**:\n",
    "   - トピックの重要度や関係性を示すために、バーチャートやヒートマップを生成。具体的には `visualize_barchart` や `visualize_heatmap` を使用。\n",
    "\n",
    "4. **ガイド付きトピックモデリング**:\n",
    "   - 修正されたタスクキーワードを用いて、ガイド付きトピックモデリングを実施し、特定のNLPタスクに関連するテーマを強化。\n",
    "\n",
    "このノートブックでは、具体的なトピックモデリングの手続きや視覚化に重点を置いており、同時にデータの探索的分析（EDA）の結果も考慮しながら、ユーザーの好みに影響を与えうる要素（バイアスや冗長性など）を考察しています。最終的に、特定のトピックがどのように分布し、各トピックがどの文脈において重要であるのかを示すことで、ほしい応答を導く意思決定を支援することを目指しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b4949",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの専門用語について、初心者がつまずきそうなマイナーな用語や、このノートブック特有のドメイン知識に焦点を当てて解説します。\n",
    "\n",
    "1. **BERTopic**:\n",
    "   - トピックモデリングの手法の一つで、文書をトピックにクラスタリングし、トピックごとに代表的な単語や文書を抽出するためのライブラリ。BERTの埋め込みを利用し、単語と文書の分散表現を組み合わせてトピックを形成します。\n",
    "\n",
    "2. **HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise)**:\n",
    "   - 密度ベースのクラスタリングアルゴリズムで、データの密度を基にデータポイントをクラスタに分けます。一般的なK-meansクラスタリングのように事前にクラスタ数を定義する必要がなく、異なる密度を持つクラスタを検出できるため、実務での応用において優れています。\n",
    "\n",
    "3. **c-TF-IDF (class-based Term Frequency-Inverse Document Frequency)**:\n",
    "   - クラスごとの情報を考慮に入れたTF-IDFの変種。特定のトピックやクラスにおける単語の重要性を評価するための指標で、通常のTF-IDFよりもトピックに関連する情報をより良く反映します。\n",
    "\n",
    "4. **UMAP (Uniform Manifold Approximation and Projection)**:\n",
    "   - 高次元データを低次元空間にマッピングする次元削減の手法。データセットのトポロジーを保持しながらデータ点同士の関係性を維持するため、視覚化やクラスタリングの前処理によく使用されます。\n",
    "\n",
    "5. **Maximal Marginal Relevance (MMR)**:\n",
    "   - 情報検索の用語で、情報の多様性を最大化しつつ関連性を考慮する手法。ドキュメントの選択や要約に利用され、タスクに基づいて重要な情報を選び出す際に役立ちます。\n",
    "\n",
    "6. **Bag-of-Words (BoW)**:\n",
    "   - 文書を単語の集合として表現する方法で、単語の出現頻度をカウントします。文書の順序を無視するため、意味を捉えるのは難しいが、計算が簡単で効率的です。\n",
    "\n",
    "7. **エンベディング (Embedding)**:\n",
    "   - 単語や文書をベクトル形式で表現する技術。特に深層学習モデルでよく使用され、語彙の意味的な距離をベクトル空間で表現し、機械学習のモデルに入力可能な形に変換します。\n",
    "\n",
    "8. **スカイキット (Scikit-learn)**:\n",
    "   - 機械学習のためのPythonライブラリの一つで、多くの標準的なアルゴリズムやツールが実装されており、データ前処理やモデルの評価、選択などで使用されます。\n",
    "\n",
    "9. **ランダムシード (Random Seed)**:\n",
    "   - コンピュータープログラムで生成されるランダムな数値列の初期値。再現性を持たせるために用いることが多く、同じデータセットに対して同じ結果を得るために重要な要素です。\n",
    "\n",
    "10. **ストップワード (Stop Words)**:\n",
    "    - テキスト解析において無意味またはあまり意味を持たないとされる一般的な単語（例：あ、か、の、the, isなど）は、分析から除外されることが多いです。これにより、重要な情報が強調され、計算コストが軽減されます。\n",
    "\n",
    "11. **位置バイアス (Position Bias)**:\n",
    "    - レコメンデーションシステムや評価において、提示された選択肢の位置によってユーザーの選択が影響を受ける現象。このバイアスを理解することで、より公平な評価が可能になります。\n",
    "\n",
    "このリストは、初心者がつまずきそうなマイナーな用語や、このノートブック特有の用語に基づいて解説されており、専門的な内容に触れる際の助けとなるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eeded61",
   "metadata": {},
   "source": [
    "# インポート（ライブラリの読み込み）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython.displayモジュールからclear_output関数をインポートします。\n",
    "# この関数は、Jupyter Notebookの出力をクリアするために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:33:52.921668Z",
     "iopub.status.busy": "2024-07-17T12:33:52.921015Z",
     "iopub.status.idle": "2024-07-17T12:34:30.56459Z",
     "shell.execute_reply": "2024-07-17T12:34:30.562952Z",
     "shell.execute_reply.started": "2024-07-17T12:33:52.921604Z"
    }
   },
   "outputs": [],
   "source": [
    "# bertopicというライブラリをインストールします。\n",
    "# -qオプションは、インストール中の進行状況を表示しないようにするためのものです。\n",
    "# これにより、インストールのメッセージが少なくなり、ノートブックの出力がスッキリします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:52:01.743052Z",
     "iopub.status.busy": "2024-07-17T12:52:01.742554Z",
     "iopub.status.idle": "2024-07-17T12:52:18.661461Z",
     "shell.execute_reply": "2024-07-17T12:52:18.659919Z",
     "shell.execute_reply.started": "2024-07-17T12:52:01.743013Z"
    }
   },
   "outputs": [],
   "source": [
    "# numpyライブラリを、バージョン1.23.5にアップグレードしてインストールします。\n",
    "# -Uオプションは、指定したバージョンがインストールされていない場合や古いバージョンがインストールされている場合に更新することを指示します。\n",
    "# NumPyは、数値計算や配列操作に非常に便利なライブラリです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-17T12:50:26.327198Z",
     "iopub.status.busy": "2024-07-17T12:50:26.324366Z",
     "iopub.status.idle": "2024-07-17T12:50:26.343563Z",
     "shell.execute_reply": "2024-07-17T12:50:26.341069Z",
     "shell.execute_reply.started": "2024-07-17T12:50:26.327108Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandasライブラリをpdという略称でインポートします。\n",
    "# literal_eval関数をastモジュールからインポートします。これは、文字列をPythonのリテラルに評価するために使用します。\n",
    "# numpyライブラリをnpという略称でインポートします。数値計算用のライブラリです。\n",
    "# osモジュールをインポートします。これは、オペレーティングシステムとのインタラクションに使用します。\n",
    "# randomモジュールをインポートします。これは、ランダムな数値や選択を生成するために使用します。\n",
    "# reモジュールをインポートします。これは、正規表現操作を行うために使用します。\n",
    "\n",
    "# UMAPとHDBSCANは、データの次元削減およびクラスタリングに使用されるライブラリです。\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "\n",
    "# CountVectorizerとTfidfVectorizerは、テキストデータを数値ベクトルに変換するために使用される方法です。\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# SentenceTransformerは、文章をベクトルに変換するためのモデルを提供するライブラリです。\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BERTopicは、トピックモデリングを行うためのライブラリです。\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired, MaximalMarginalRelevance\n",
    "from bertopic.vectorizers import ClassTfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7893b78",
   "metadata": {},
   "source": [
    "**始める前に、以下はこのノートブックで行われた素晴らしい探索的データ分析（EDA）から得られた概要です：**https://www.kaggle.com/code/abaojiang/lmsys-detailed-eda\n",
    "\n",
    "**一般的な発見**\n",
    "\n",
    "- トレーニングセットには64種類の異なるモデルがあります。\n",
    "- 各プロンプトに対して3つの応答があり、それぞれ異なるモデルからのもので、人間の好みに基づいてランク付けされています。\n",
    "- トレーニングデータで最も一般的（頻出）なモデルは以下の通りです：\n",
    "\n",
    "    - gpt-4-1106-preview \n",
    "    - gpt-3.5-turbo-0613\n",
    "    - gpt-4-0613 \n",
    "    - claude-2.1 \n",
    "    - (gpt-4-0314, claude-instant-1)\n",
    "    \n",
    "    \n",
    "- ターン数：トレーニングデータのプロンプト/応答ペアの数。\n",
    "\n",
    "    - 約86.88％の会話はシングルターンです。\n",
    "    - 99.19％以上の会話は6ターン未満です。\n",
    "    - 最大ターン数は36です。\n",
    "    \n",
    "    \n",
    "\n",
    "**モデルの応答の好み**\n",
    "\n",
    "- gpt-3.5-turbo-0314、gpt-4-0125-preview、gpt-4-1106-previewを含む3つのLLMが勝率50％を超えています。\n",
    "- 低いタイ率は勝者をより決定的に判断できることを意味します。\n",
    "\n",
    "\n",
    "**応答/プロンプトにおけるバイアスと相関関係**\n",
    "\n",
    "- 人間の判断者には位置バイアスがありません。つまり、トレーニングデータにおける位置A、B、Cには、アノテータの好みに関する位置バイアスが存在しません。\n",
    " \n",
    "- 同じプロンプトに対するモデルの応答の長さの相関：同じプロンプトに対する応答の長さには強い相関があります。\n",
    " \n",
    "- プロンプトの長さと応答の長さの相関：プロンプトの長さと応答の長さの間には線形関係があるが、相関はかなり弱いようです。\n",
    "\n",
    "- 冗長性バイアス（応答の冗長さが人間の好みに与える影響）：\n",
    "    - データには明確な冗長性バイアスがあります。\n",
    "    - 「平均応答長」と「勝率」の相関 = 0.488\n",
    "    - gpt-4-0125-previewとgpt-4-1106-previewは、平均応答長が最も長いトップ2のモデルです。\n",
    "    \n",
    "\n",
    "**ヌル/空の応答またはプロンプト**\n",
    "\n",
    "- 空のプロンプトを持つサンプルが5つあります。\n",
    "- 空のプロンプトはすべて単一のスペース \" \" で、会話の最後のプロンプトに現れます。\n",
    "- モデルは空のプロンプトが送信されても応答を続けることができます。\n",
    "- 欠落した応答は空またはNoneである可能性があります。\n",
    "\n",
    "- 判断者への影響：\n",
    "    - タイ率は約0.15に低下し、これは非常に妥当です。\n",
    "    - もし1つのモデルの応答が欠落している場合、判断者は通常応答する別のモデルに投票したり、タイにする傾向があります。\n",
    "    \n",
    "\n",
    "**トレーニングデータとテストデータの確認**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.422896Z",
     "iopub.status.idle": "2024-07-17T12:35:41.423383Z",
     "shell.execute_reply": "2024-07-17T12:35:41.423167Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.423149Z"
    }
   },
   "outputs": [],
   "source": [
    "# 応答オブジェクトを解析するための関数を定義します。\n",
    "def parse_response(response_object:str)->[str,]:\n",
    "    # response_objectが文字列として与えられ、それをPythonリテラルに評価しようとします。\n",
    "    try:\n",
    "        resp = literal_eval(response_object)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # もし評価に失敗した場合、'null'をNoneに置き換えます。\n",
    "        try:\n",
    "            response_object = response_object.replace('null',None)\n",
    "            resp = literal_eval(response_object)\n",
    "        except Exception as e:\n",
    "            # 評価失敗時、デバッグ用に応答オブジェクトの型と内容を出力しますが、コメントアウトされています。\n",
    "            # print(type(response_object),response_object)\n",
    "            # 空のリストを返します。\n",
    "            resp = []\n",
    "\n",
    "    # 解析された応答を返します。\n",
    "    return resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.425537Z",
     "iopub.status.idle": "2024-07-17T12:35:41.42595Z",
     "shell.execute_reply": "2024-07-17T12:35:41.425775Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.42576Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータとテストデータを読み込みます。\n",
    "train = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "# 'prompt'列の各要素に対してliteral_evalを適用し、文字列をPythonのリテラルに変換します。\n",
    "train['prompt'] = train['prompt'].apply(literal_eval)\n",
    "# 'response_a'列と'response_b'列の各要素に対してparse_response関数を適用し、応答を解析します。\n",
    "train['response_a'] = train['response_a'].apply(parse_response)\n",
    "train['response_b'] = train['response_b'].apply(parse_response)\n",
    "\n",
    "# テストデータを読み込みます。\n",
    "test = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "\n",
    "# トレーニングデータとテストデータの形状（行数と列数）を出力します。\n",
    "_ = print(train.shape),print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.42975Z",
     "iopub.status.idle": "2024-07-17T12:35:41.430249Z",
     "shell.execute_reply": "2024-07-17T12:35:41.430054Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.430031Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの最初の5行を表示します。\n",
    "# これにより、データの構造や内容を確認することができます。\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.432483Z",
     "iopub.status.idle": "2024-07-17T12:35:41.432953Z",
     "shell.execute_reply": "2024-07-17T12:35:41.432746Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.432729Z"
    }
   },
   "outputs": [],
   "source": [
    "# 空の応答を持つ行を削除します。\n",
    "# response_aとresponse_bの両方が非空である行のみをフィルタリングします。\n",
    "train_ss = train[(train.response_a.apply(len)>0) & (train.response_b.apply(len)>0)]\n",
    "\n",
    "# フィルタリング後のデータの形状（行数と列数）を表示します。\n",
    "train_ss.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.435804Z",
     "iopub.status.idle": "2024-07-17T12:35:41.436558Z",
     "shell.execute_reply": "2024-07-17T12:35:41.436222Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.436195Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータの最初の5行を表示します。\n",
    "# これにより、テストデータの構造や内容を確認することができます。\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545b272b",
   "metadata": {},
   "source": [
    "# トピックモデリング\n",
    "\n",
    "**仕組み (出典: https://maartengr.github.io/BERTopic/algorithm/algorithm.html)**\n",
    "\n",
    "![image.png](attachment:60ac0df8-5866-4948-9240-7e6453976a10.png)\n",
    "\n",
    "1. ドキュメントの埋め込み：トランスフォーマーベースのモデル埋め込みを使用して、ドキュメントを数値表現に変換することから始めます。\n",
    "\n",
    "2. 次元削減：ドキュメントの数値表現を作成した後、これらの表現の次元を削減する必要があります。クラスターモデルは、高次元データを扱う際に「次元の呪い」のために困難を抱えることがよくあります。\n",
    "\n",
    "3. ドキュメントのクラスタリング：埋め込みを減少させた後、データのクラスタリングを始めることができます。そのために、密度ベースのクラスタリング手法であるHDBSCANを利用します。HDBSCANは、さまざまな形状のクラスターを見つけることができ、可能な場合には外れ値を特定する優れた機能を持っています。\n",
    "\n",
    "4. Bag-of-words：BERTopicのアルゴリズムでは、モジュラリティを許可しながらトピック表現を作成するためにHDBSCANをクラスタリングモデルとして使用します。これは、異なる密度と形状のクラスターを収容するからです。重心ベースの手法を使用するのではなく、クラスター内のすべてのドキュメントを単一のドキュメントに統合し、各単語の頻度をカウントしてbag-of-words表現を形成します。この表現は、クラスターサイズの違いに対して正規化され、特定のクラスター構造を仮定せずにクラスターレベルでの単語に焦点を当てます。\n",
    "\n",
    "5. トピック表現：生成されたbag-of-words表現から、1つのクラスターを他のクラスターと区別する要素を知りたいと思います。クラスター1に典型的な単語は何で、他のすべてのクラスターにはあまり典型的でないのはどれでしょうか？これを解決するために、ドキュメントではなくトピック（すなわちクラスター）を考慮するようにTF-IDFを修正する必要があります。\n",
    "\n",
    "6. トピック表現の微調整：生成されたc-TF-IDFトピックを候補トピックとして考えることができます。それぞれに一連のキーワードと、トピック表現をさらに微調整するために使用できる代表的なドキュメントが含まれます。各トピックに対して代表的なドキュメントのセットを持つことは、大きな利点です。これにより、限られた数のドキュメントの微調整が可能になります。これにより、大規模モデルの計算コストが削減され、各トピックごとにその小さな代表的なドキュメントのセットでのみ操作を行う必要があります。\n",
    "\n",
    "次に、教師なしトピックモデリングアプローチを使用して、プロンプト内の潜在的なパターンを見つけてみましょう。これにより、プロンプトに含まれるトピックの大まかな理解が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.438765Z",
     "iopub.status.idle": "2024-07-17T12:35:41.439466Z",
     "shell.execute_reply": "2024-07-17T12:35:41.439139Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.439114Z"
    }
   },
   "outputs": [],
   "source": [
    "# モジュールのセットアップ\n",
    "\n",
    "# ステップ1 - 埋め込みを抽出する\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ステップ2 - 次元を削減する\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=20,  # 各点の近傍の数\n",
    "    n_components=5,  # 出力する次元数\n",
    "    min_dist=0.0,    # 最小距離の制約\n",
    "    metric=\"cosine\", # コサイン距離を使用\n",
    "    random_state=7,  # 再現性のためのランダムシード\n",
    ")\n",
    "\n",
    "# ステップ3 - 減少した埋め込みをクラスタリングする\n",
    "hdbscan_model = HDBSCAN(\n",
    "    min_cluster_size=32,  # 最小クラスタサイズ\n",
    "    min_samples=1,        # 最小サンプル数\n",
    "    metric=\"euclidean\",   # ユークリッド距離を使用\n",
    "    cluster_selection_method=\"eom\", # クラスタ選択メソッド\n",
    "    prediction_data=True   # クラスタリング結果を予測するためのデータを保持\n",
    ")\n",
    "\n",
    "# ステップ4 - トピックをトークナイズする\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\") # 英語のストップワードを取り除く\n",
    "\n",
    "# ステップ5 - トピック表現を作成する\n",
    "ctfidf_model = ClassTfidfTransformer(reduce_frequent_words=True,) # 頻出単語を減少させるオプション\n",
    "\n",
    "# `bertopic.representation`モデルを使用してトピック表現を微調整\n",
    "representation_model = MaximalMarginalRelevance(diversity=0.4,   # 多様性の調整\n",
    "                                                top_n_words=15    # トピック表現に含める単語の数\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.440938Z",
     "iopub.status.idle": "2024-07-17T12:35:41.441681Z",
     "shell.execute_reply": "2024-07-17T12:35:41.441311Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.441285Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピックモデリングのパイプラインを構築します。\n",
    "topic_model = BERTopic(\n",
    "    embedding_model=embedding_model,  # 埋め込みモデルを指定\n",
    "    umap_model=umap_model,            # 次元削減モデルを指定\n",
    "    hdbscan_model=hdbscan_model,      # クラスタリングモデルを指定\n",
    "    vectorizer_model=vectorizer_model, # トークナイザーを指定\n",
    "    ctfidf_model=ctfidf_model,        # c-TF-IDFモデルを指定\n",
    "    representation_model=representation_model, # 表現モデルを指定\n",
    "    n_gram_range=(1,5),               # n-gramの範囲を設定（1から5）\n",
    "    language=\"english\"                # 言語を英語に設定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.443865Z",
     "iopub.status.idle": "2024-07-17T12:35:41.444604Z",
     "shell.execute_reply": "2024-07-17T12:35:41.444286Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.44426Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングプロンプトを結合します。\n",
    "# 各プロンプトの要素を2つの改行で結合し、リストに変換します。\n",
    "train_prompt_concatenated = train.prompt.apply(lambda x: \"\\n\\n\".join(x)).to_list()\n",
    "\n",
    "# 結合されたプロンプトの数を表示します。\n",
    "len(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.447172Z",
     "iopub.status.idle": "2024-07-17T12:35:41.447834Z",
     "shell.execute_reply": "2024-07-17T12:35:41.447546Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.447523Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピックモデリングの適合を行います。\n",
    "# train_prompt_concatenatedに基づいてトピックをフィットさせ、トピックとその確率を得ます。\n",
    "# %%timeマジックコマンドは、このセルの実行時間を計測します。\n",
    "%%time\n",
    "topics, topic_proba = topic_model.fit_transform(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トピックモデルを保存します。\n",
    "# 保存時に\"safetensors\"形式を使用します。\n",
    "topic_model.save(\"topic_model_unguided\", serialization=\"safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.449705Z",
     "iopub.status.idle": "2024-07-17T12:35:41.450401Z",
     "shell.execute_reply": "2024-07-17T12:35:41.450079Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.450053Z"
    }
   },
   "outputs": [],
   "source": [
    "# ユニークなトピックの数を表示します。\n",
    "# np.uniqueを使用して、トピックの配列からユニークな値の数を取得します。\n",
    "print(f\"ユニークなトピックの数: {len(np.unique(topics))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.452791Z",
     "iopub.status.idle": "2024-07-17T12:35:41.453477Z",
     "shell.execute_reply": "2024-07-17T12:35:41.453171Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.453147Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピック情報を取得します。\n",
    "# トピックに関する詳細情報を含むデータフレームを取得します。\n",
    "topic_info = topic_model.get_topic_info()\n",
    "\n",
    "# 最初の10行を表示します。\n",
    "topic_info.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定のトピックの表現を取得します。\n",
    "# トピック0に関する情報を得ます。\n",
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.455888Z",
     "iopub.status.idle": "2024-07-17T12:35:41.456404Z",
     "shell.execute_reply": "2024-07-17T12:35:41.456197Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.456181Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピック表現を視覚化します。\n",
    "# 上位30のトピックについて、各トピックの上位10単語を表示する棒グラフを作成します。\n",
    "topic_model.visualize_barchart(top_n_topics=30, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.457709Z",
     "iopub.status.idle": "2024-07-17T12:35:41.458136Z",
     "shell.execute_reply": "2024-07-17T12:35:41.45795Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.457933Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピックの用語ランクを視覚化します。\n",
    "# トピックにおける単語の重要度のランクを示すプロットを作成します。\n",
    "topic_model.visualize_term_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.460194Z",
     "iopub.status.idle": "2024-07-17T12:35:41.460659Z",
     "shell.execute_reply": "2024-07-17T12:35:41.460456Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.460439Z"
    }
   },
   "outputs": [],
   "source": [
    "# トピックのヒートマップを視覚化します。\n",
    "# 上位20トピックの関係性を示すヒートマップを作成します。\n",
    "topic_model.visualize_heatmap(top_n_topics=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58e195a",
   "metadata": {},
   "source": [
    "# ガイド付きトピックモデリング\n",
    "\n",
    "以下の図は、ガイド付きトピックモデリングの基本的な考え方を示しています（出典: https://maartengr.github.io/BERTopic/getting_started/guided）。\n",
    "\n",
    "![image.png](attachment:e350c127-4025-4b0a-9942-3768abb34873.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.463165Z",
     "iopub.status.idle": "2024-07-17T12:35:41.464666Z",
     "shell.execute_reply": "2024-07-17T12:35:41.464416Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.464386Z"
    }
   },
   "outputs": [],
   "source": [
    "# タスクトピックを定義します。\n",
    "# さまざまな自然言語処理タスクに関連するテーマをカンマで区切ってリスト化します。\n",
    "task_topics = \"Code to text,,text to code,Named entity recognition,Sentiment Analysis,Translation,Question Answering,Program Execution, Miscallenous tasks,Text Categorization,Language Identification, Information Extraction,Text Quality,Summarization,text completion,essay writing,poem writing,creative writing,fact verification,reasoning,mathematical,grammer task,rephrasing,style transfer,paraphrasing,natural language inference,question generation,text matching,dialogue generation,harmfullness detection,toxic language detection,fact verification,keyword tagging\".split(\",\")\n",
    "\n",
    "# 定義したタスクトピックを表示します。\n",
    "print(task_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d160833",
   "metadata": {},
   "source": [
    "**CHATGPTを使用して修正されたタスクキーワード**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.466159Z",
     "iopub.status.idle": "2024-07-17T12:35:41.466607Z",
     "shell.execute_reply": "2024-07-17T12:35:41.46641Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.466392Z"
    }
   },
   "outputs": [],
   "source": [
    "# シードトピックを定義します。\n",
    "# 修正されたタスクに関連するキーワードのリストを作成します。\n",
    "task_topics_modified = [\n",
    "    ['Code to text', 'source code', 'comments', 'explanation', 'description', 'documentation'],\n",
    "    ['Text to code', 'programming', 'syntax', 'function', 'script', 'automation'],\n",
    "    ['Named entity recognition', 'NER', 'entities', 'classification', 'annotation', 'identification'],\n",
    "    ['Sentiment Analysis', 'emotion', 'opinion', 'polarity', 'attitude', 'mood'],\n",
    "    ['Translation', 'bilingual', 'language pair', 'conversion', 'interpretation', 'localization'],\n",
    "    ['Question Answering', 'QA', 'response', 'inquiry', 'knowledge', 'retrieval'],\n",
    "    ['Program Execution', 'run', 'execute', 'compile', 'script', 'process'],\n",
    "    ['Miscellaneous tasks', 'varied', 'general', 'diverse', 'assorted', 'multiple'],\n",
    "    ['Text Categorization', 'classification', 'labeling', 'sorting', 'grouping', 'organization'],\n",
    "    ['Language Identification', 'detection', 'recognition', 'classification', 'language', 'dialect'],\n",
    "    ['Information Extraction', 'data mining', 'retrieval', 'extraction', 'parsing', 'harvesting'],\n",
    "    ['Text Quality', 'clarity', 'readability', 'coherence', 'accuracy', 'precision'],\n",
    "    ['Summarization', 'abstract', 'condense', 'overview', 'digest', 'outline'],\n",
    "    ['Text completion', 'autocomplete', 'fill-in', 'predictive', 'continuation', 'suggestion'],\n",
    "    ['Essay writing', 'composition', 'argument', 'thesis', 'structure', 'drafting'],\n",
    "    ['Poem writing', 'verse', 'rhyme', 'stanza', 'meter', 'lyric'],\n",
    "    ['Creative writing', 'story', 'imagination', 'narrative', 'fiction', 'expression'],\n",
    "    ['Fact verification', 'truth', 'validation', 'accuracy', 'confirmation', 'authenticity'],\n",
    "    ['Reasoning', 'logic', 'deduction', 'inference', 'rationale', 'analysis'],\n",
    "    ['Mathematical', 'calculation', 'formula', 'equation', 'computation', 'arithmetic'],\n",
    "    ['Grammar task', 'syntax', 'rules', 'correction', 'structure', 'editing'],\n",
    "    ['Rephrasing', 'paraphrase', 'reword', 'rewrite', 'restatement', 'alteration'],\n",
    "    ['Style transfer', 'transformation', 'conversion', 'adaptation', 'modification', 'recasting'],\n",
    "    ['Paraphrasing', 'rewording', 'restating', 'rephrasing', 'altering', 'modifying'],\n",
    "    ['Natural language inference', 'NLI', 'hypothesis', 'entailment', 'contradiction', 'inference'],\n",
    "    ['Question generation', 'inquiry', 'query', 'interrogative', 'ask', 'question'],\n",
    "    ['Text matching', 'similarity', 'comparison', 'alignment', 'correlation', 'matching'],\n",
    "    ['Dialogue generation', 'conversation', 'interaction', 'exchange', 'communication', 'chatbot'],\n",
    "    ['Harmfulness detection', 'toxicity', 'abuse', 'malice', 'danger', 'risk'],\n",
    "    ['Toxic language detection', 'abusive', 'offensive', 'harmful', 'inappropriate', 'insulting'],\n",
    "    ['Fact verification', 'validation', 'authenticity', 'accuracy', 'truth', 'confirmation'],\n",
    "    ['Keyword tagging', 'labeling', 'annotation', 'classification', 'indexing', 'tagging'],\n",
    "    ['Topic modeling', 'themes', 'topics', 'clustering', 'segmentation', 'grouping'],\n",
    "    ['Contextual embedding', 'context', 'representation', 'vectors', 'embeddings', 'contextualization'],\n",
    "    ['Coreference resolution', 'pronouns', 'anaphora', 'antecedents', 'referents', 'binding'],\n",
    "    ['Semantic similarity', 'meaning', 'relation', 'comparison', 'equivalence', 'likeness'],\n",
    "    ['Document summarization', 'overview', 'digest', 'abstract', 'compendium', 'condensation'],\n",
    "    ['Speech recognition', 'transcription', 'audio', 'voice', 'ASR', 'spoken'],\n",
    "    ['Optical character recognition', 'OCR', 'text', 'image', 'scanning', 'extraction'],\n",
    "    ['Text generation', 'creation', 'synthesis', 'generation', 'writing', 'production'],\n",
    "    ['Dialogue summarization', 'conversation', 'overview', 'recap', 'condensation', 'summary'],\n",
    "    ['Data anonymization', 'privacy', 'masking', 'obfuscation', 'anonymity', 'de-identification']\n",
    "]\n",
    "\n",
    "# 修正されたタスクキーワードの数を表示します。\n",
    "len(task_topics_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.469022Z",
     "iopub.status.idle": "2024-07-17T12:35:41.469718Z",
     "shell.execute_reply": "2024-07-17T12:35:41.469424Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.469395Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガイド付きトピックモデリングのパイプラインを構築します。\n",
    "# 修正されたタスクキーワードを使ってガイド付きトピックモデルを定義します。\n",
    "topic_model_guided = BERTopic(\n",
    "    embedding_model=embedding_model,       # 埋め込みモデルを指定\n",
    "    umap_model=umap_model,                 # 次元削減モデルを指定\n",
    "    hdbscan_model=hdbscan_model,           # クラスタリングモデルを指定\n",
    "    vectorizer_model=vectorizer_model,     # トークナイザーを指定\n",
    "    ctfidf_model=ctfidf_model,             # c-TF-IDFモデルを指定\n",
    "    representation_model=representation_model, # 表現モデルを指定\n",
    "    n_gram_range=(1,5),                    # n-gramの範囲を設定（1から5）\n",
    "    language=\"english\",                    # 言語を英語に設定\n",
    "    seed_topic_list=task_topics_modified    # ガイド付きのシードトピックを指定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.472249Z",
     "iopub.status.idle": "2024-07-17T12:35:41.472912Z",
     "shell.execute_reply": "2024-07-17T12:35:41.47262Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.472596Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガイド付きトピックモデリングの適合を行います。\n",
    "# train_prompt_concatenatedに基づいてトピックをフィットさせ、トピックとその確率を得ます。\n",
    "# %%timeマジックコマンドは、このセルの実行時間を計測します。\n",
    "%%time\n",
    "topics, topic_proba = topic_model_guided.fit_transform(train_prompt_concatenated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-07-17T12:35:41.474916Z",
     "iopub.status.idle": "2024-07-17T12:35:41.475573Z",
     "shell.execute_reply": "2024-07-17T12:35:41.475266Z",
     "shell.execute_reply.started": "2024-07-17T12:35:41.475241Z"
    }
   },
   "outputs": [],
   "source": [
    "# ガイド付きトピックモデリングのトピック表現を視覚化します。\n",
    "# 上位30のトピックについて、各トピックの上位10単語を表示する棒グラフを作成します。\n",
    "topic_model_guided.visualize_barchart(top_n_topics=30, n_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ガイド付きトピックモデルを保存します。\n",
    "# 保存時に\"safetensors\"形式を使用します。\n",
    "topic_model_guided.save(\"topic_model_guided\", serialization=\"safetensors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae99a6d0",
   "metadata": {},
   "source": [
    "# リソース\n",
    "\n",
    "* https://research.google/pubs/large-language-models-are-effective-text-rankers-with-pairwise-ranking-prompting/\n",
    "* https://magazine.sebastianraschka.com/p/tips-for-llm-pretraining-and-evaluating-rms\n",
    "* https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\n",
    "* https://www.kaggle.com/code/abaojiang/lmsys-detailed-eda\n",
    "* https://www.kaggle.com/code/robikscube/lmsys-chatbot-arena-data-anaylsis#Response-Length-Baseline\n",
    "* https://medium.com/data-reply-it-datatech/bertopic-topic-modeling-as-you-have-never-seen-it-before-abb48bbab2b2"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
