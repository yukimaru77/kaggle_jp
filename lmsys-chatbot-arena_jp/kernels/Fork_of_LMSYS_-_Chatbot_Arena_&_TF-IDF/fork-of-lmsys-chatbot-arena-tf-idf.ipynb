{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "924b53f9",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、ユーザーに対する大規模言語モデル（LLM）の応答の好みを予測するための機械学習モデルを構築することを目的としています。主に、LightGBMとTF-IDF（Term Frequency-Inverse Document Frequency）を用いるアプローチが採用されています。\n",
    "\n",
    "### 問題に取り組む内容\n",
    "ノートブックでは、ユーザーからのプロンプトに対する二つのLLMの応答の中で、どちらが好まれるかを予測するためのタスクが中心です。具体的には、次のステップが含まれています。\n",
    "\n",
    "1. **データの読み込みと探索的データ分析（EDA）**: データを読み込んで、基本的な統計情報や分布を確認します。\n",
    "2. **TF-IDFベクトル化**: テキストデータを数値フォーマットに変換するためにTF-IDFを用います。この手法は、重要な単語を特定し、文書の類似性を測定するために使われます。\n",
    "3. **データの前処理**: 各応答の情報を含む特徴量を追加し、類似性や距離を計算します。\n",
    "4. **モデルの訓練**: LightGBMを用いてデータを訓練し、交差検証を行いながら性能を評価します。\n",
    "5. **モデルの推論**: テストデータに対して予測を行い、結果を元に混同行列を作成し評価します。\n",
    "6. **提出用ファイルの生成**: 予測結果を適切なフォーマットでCSVファイルとして保存します。\n",
    "\n",
    "### 使用している主な手法とライブラリ\n",
    "- **LightGBM**: 勾配ブースティングフレームワークを使用してモデルを訓練します。これは大容量のデータセットに対して効率的かつ効果的に学習を行えるライブラリです。\n",
    "- **TF-IDF**: テキストデータを数値ベクトルに変換するために使用されています。具体的には、単語の重要性を測定するための手法です。\n",
    "- **Label Encoding**: 複数のラベルを単一のラベルに統合するためのカスタム関数が定義されています。\n",
    "- **混同行列**: モデルのパフォーマンスを評価するために使用されています。\n",
    "\n",
    "全体として、このノートブックはチャットボットの応答の好みを予測するために高度な機械学習を実装しており、ユーザーのニーズに対してより優れた応答を生成するための強力なフレームワークを提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88864ad",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、機械学習・深層学習の初心者がつまずきそうな専門用語の簡単な解説を挙げます。特に、このノートブック特有のドメイン知識や、実務を経験していないと馴染みのないものに焦点を当てています。\n",
    "\n",
    "1. **LightGBM**:\n",
    "   - 概要: Microsoftによって開発された勾配ブースティングアルゴリズムの一種で、大規模なデータセットで高速に動作し、メモリ効率が良いのが特徴です。\n",
    "   - 特徴: 決定木の葉の分割による学習を行い、トレーニング時間を大幅に短縮することができます。\n",
    "\n",
    "2. **TF-IDF (Term Frequency-Inverse Document Frequency)**:\n",
    "   - 概要: テキストデータを数値化する手法の一つで、特定の単語が文書内でどれくらい重要であるかを評価します。\n",
    "   - ドメイン特有のポイント: TFは単語の出現頻度を示し、IDFは単語の一般的な重要性を示すため、両者を掛け算することで、文書の内容に応じた重要な単語を特定できます。\n",
    "\n",
    "3. **n-grams**:\n",
    "   - 概要: テキストにおける連続したn個の単語（またはトークン）の組み合わせを指します。1つの単語からなる1-gram（unigram）、2つの単語からなる2-gram（bigram）などがあります。\n",
    "   - ドメイン特有のポイント: 文脈を捉える力が向上し、単語単位だけでは捉えきれない意味を抽出するのに役立つ。\n",
    "\n",
    "4. **StratifiedKFold**:\n",
    "   - 概要: K分割交差検証の一種で、各フォールドにおいてクラスの分布を維持します。\n",
    "   - ドメイン特有のポイント: クラス不均衡があるデータセットにおいて、モデルの評価をより正確に行うために使用されます。\n",
    "\n",
    "5. **トランケイテッド SVD (Truncated Singular Value Decomposition)**:\n",
    "   - 概要: 行列の次元削減技術で、大きなデータを小さくし、重要な情報を保持しつつ余計な情報を取り除きます。\n",
    "   - ドメイン特有のポイント: TF-IDFで得られた高次元の特徴空間をより小さな空間に圧縮する際に用いられます。\n",
    "\n",
    "6. **混同行列 (Confusion Matrix)**:\n",
    "   - 概要: 分類モデルの性能を評価するための表で、実際のラベルと予測されたラベルを比較するものです。\n",
    "   - ドメイン特有のポイント: 正しい予測と誤った予測の数を示し、各クラスの精度や再現率を計算する際に使用されます。\n",
    "\n",
    "7. **コサイン類似度 (Cosine Similarity)**:\n",
    "   - 概要: 2つのベクトル間の角度を使って、その類似性を測定する尺度です。1に近いほど、類似していることを示します。\n",
    "   - ドメイン特有のポイント: テキストの類似性を測定する際によく使用され、TF-IDFベクトルの比較に利用されます。\n",
    "\n",
    "8. **ユークリッド距離 (Euclidean Distance)**:\n",
    "   - 概要: 二点間の直線距離を計測する方法で、平面上の点同士の最短距離を示します。\n",
    "   - ドメイン特有のポイント: 特徴空間内でのデータポイント間の距離を測定し、分類やクラスタリングに役立ちます。\n",
    "\n",
    "9. **ラプラシアン カーネル (Laplacian Kernel)**:\n",
    "   - 概要: データポイント間の隣接関係をモデル化し、特にグラフデータに基づいた距離を評価するためのカーネル関数です。\n",
    "   - ドメイン特有のポイント: 特徴間の非線形関係を捉えたり、データの局所的な構造を考慮した距離計算に役立ちます。\n",
    "\n",
    "これらの用語の理解が進むことで、ノートブックの内容や機械学習の実務により自信を持って取り組めるようになるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cee246",
   "metadata": {},
   "source": [
    "# イントロダクション 📜\n",
    "\n",
    "✔️ このノートブックの目的は何ですか？\n",
    "\n",
    "目標は、LightGBMとTF-IDFベクトル化を使用して、ユーザーのLLM応答への好みを予測するための堅牢で効率的なソリューションを作成することです。\n",
    "\n",
    "---\n",
    "\n",
    "✔️ このノートブックでは何が扱われていますか？\n",
    "\n",
    "- `データの読み込みと探索的データ分析（EDA）`\n",
    "\n",
    "- `TF-IDFの理論`\n",
    "\n",
    "- `データの前処理`\n",
    "\n",
    "- `モデルの訓練`\n",
    "\n",
    "- `モデルの推論`\n",
    "     \n",
    "# インポート 📦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:31:51.269648Z",
     "iopub.status.busy": "2024-06-17T17:31:51.269196Z",
     "iopub.status.idle": "2024-06-17T17:31:51.319543Z",
     "shell.execute_reply": "2024-06-17T17:31:51.318188Z",
     "shell.execute_reply.started": "2024-06-17T17:31:51.269611Z"
    }
   },
   "outputs": [],
   "source": [
    "# 警告メッセージを処理する\n",
    "import warnings\n",
    "# 警告を無視する設定を行います\n",
    "warnings.filterwarnings('ignore')  # これにより、実行時に表示される警告が表示されなくなります"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:32:20.758585Z",
     "iopub.status.busy": "2024-06-17T17:32:20.757965Z",
     "iopub.status.idle": "2024-06-17T17:32:20.766174Z",
     "shell.execute_reply": "2024-06-17T17:32:20.764803Z",
     "shell.execute_reply.started": "2024-06-17T17:32:20.758551Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの前処理\n",
    "import numpy as np  # NumPyライブラリをインポート。数値計算や配列操作に使います。\n",
    "import pandas as pd  # pandasライブラリをインポート。データフレーム作成や操作に使用します。\n",
    "from pathlib import Path  # パス操作用のPathライブラリをインポート\n",
    "\n",
    "# データの視覚化\n",
    "import plotly.graph_objects as go  # Plotlyライブラリをインポート。インタラクティブなグラフ作成に使用します。\n",
    "from sklearn.metrics import confusion_matrix  # 混同行列の計算用のメトリクスをインポート\n",
    "\n",
    "# モデルの開発\n",
    "import lightgbm as lgb  # LightGBMライブラリをインポート。勾配ブースティングを用いたモデル作成に使用します。\n",
    "from sklearn.model_selection import StratifiedKFold  # 層化Kフォールド交差検証用のクラスをインポート\n",
    "\n",
    "# TF-IDFベクトル化\n",
    "from sklearn.decomposition import TruncatedSVD  # 次元削減用のトランケイテッドSVDをインポート\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDFベクトル化のためのクラスをインポート\n",
    "\n",
    "# TF-IDFベクトルの類似性/距離特徴\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, laplacian_kernel  # コサイン類似度、ユークリッド距離、ラプラシアンカーネルの計算用メトリクスをインポート"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966dc609",
   "metadata": {},
   "source": [
    "# 設定 ⚙️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:33:16.95883Z",
     "iopub.status.busy": "2024-06-17T17:33:16.958249Z",
     "iopub.status.idle": "2024-06-17T17:33:16.970032Z",
     "shell.execute_reply": "2024-06-17T17:33:16.968747Z",
     "shell.execute_reply.started": "2024-06-17T17:33:16.95869Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # コンペティションデータへのパス\n",
    "    train_data = Path(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")  # トレーニングデータのパス\n",
    "    test_data = Path(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")    # テストデータのパス\n",
    "    subm_data = Path(\"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\")  # 提出ファイルのサンプルパス\n",
    "    \n",
    "    # 混同行列のカラースケール\n",
    "    colorscale = \"peach\"  # 混同行列を表示する際のカラースケール設定\n",
    "    \n",
    "    # TF-IDFベクトル化のパラメータ\n",
    "    components = 32  # 次元削減で保持する成分の数\n",
    "    ngrams = (1, 7)  # 使用するn-gramの範囲\n",
    "    max_freq = 0.95  # 95%以上の文書に出現する単語は除外\n",
    "    min_freq = 10    # 10文書未満に出現する単語は除外\n",
    "    \n",
    "    # トレーニングの引数\n",
    "    num_classes = 3   # 分類するクラスの数\n",
    "    early_stop = 50   # 早期終了のためのイテレーション数\n",
    "    log_steps = 100   # ログを記録するステップ数\n",
    "    \n",
    "    # LightGBMのパラメータ\n",
    "    params = {\n",
    "        \"objective\": \"multiclass\",  # マルチクラス分類を指定\n",
    "        \"colsample_bytree\": 0.8,     # 木のサンプリング比率\n",
    "        \"colsample_bynode\": 0.8,      # ノードでのサンプリング比率\n",
    "        \"metric\": \"multiclass\",      # 評価指標をマルチクラスに設定\n",
    "        \"learning_rate\": 0.02,        # 学習率\n",
    "        \"extra_trees\": True,          # 追加の木を使用するかどうか\n",
    "        \"num_rounds\": 3000,           # 学習のラウンド数\n",
    "        \"reg_lambda\": 1.3,            # L2正則化\n",
    "        \"num_classes\": 3,             # 分類するクラス数\n",
    "        \"num_leaves\": 64,             # 葉の数\n",
    "        \"reg_alpha\": 0.1,             # L1正則化\n",
    "        \"device\": \"cpu\",              # デバイスはCPUを指定\n",
    "        \"max_depth\": 6,               # 木の最大深さ\n",
    "        \"max_bin\": 128,               # 最大ビンの数\n",
    "        \"verbose\": -1,                # 出力の詳細度設定\n",
    "        \"seed\": 42                    # 再現性のためのシード値\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d92604",
   "metadata": {},
   "source": [
    "# 探索的データ分析（EDA） 🗃️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:20.288524Z",
     "iopub.status.busy": "2024-06-17T17:38:20.288118Z",
     "iopub.status.idle": "2024-06-17T17:38:20.308922Z",
     "shell.execute_reply": "2024-06-17T17:38:20.307347Z",
     "shell.execute_reply.started": "2024-06-17T17:38:20.288494Z"
    }
   },
   "outputs": [],
   "source": [
    "class EDA:\n",
    "    def read_data(self, path):\n",
    "        # 指定したパスからデータフレームを読み込み\n",
    "        df = pd.read_csv(path)\n",
    "        \n",
    "        # データフレームの形状と最初の3行を表示\n",
    "        print(f\"データフレームの形状は: {df.shape}です\")\n",
    "        display(df.head(3))  # データの最初の3行を表示\n",
    "        \n",
    "        return df  # 読み込んだデータフレームを返す\n",
    "    \n",
    "    def pie_chart(self, data):\n",
    "        # 各勝者の列のカウントを計算\n",
    "        counts = {\n",
    "            'winner_model_a': data['winner_model_a'].sum(),  # モデルAの勝ち数\n",
    "            'winner_model_b': data['winner_model_b'].sum(),  # モデルBの勝ち数\n",
    "            'winner_tie': data['winner_tie'].sum()           # 引き分けの数\n",
    "        }\n",
    "\n",
    "        # カラーを定義\n",
    "        colors = ['#a89192', '#8083a8', '#a8c28c']  # クリーム、ライトブルー、ミント\n",
    "        identifiers = ['Creme', 'Light Blue', 'Mint']  # 各色の識別子\n",
    "        \n",
    "        # 円グラフを作成\n",
    "        fig = go.Figure(data=[go.Pie(labels=identifiers, \n",
    "                                     values=list(counts.values()), \n",
    "                                     textinfo='percent', \n",
    "                                     hole=0.1,\n",
    "                                     marker=dict(colors=colors, line=dict(color='#FFFFFF')))])\n",
    "        \n",
    "        # 背景を透明にし、円グラフを左寄せにするためにレイアウトを更新\n",
    "        fig.update_layout(plot_bgcolor='rgba(0,0,0,0)', \n",
    "                          paper_bgcolor='rgba(0,0,0,0)', \n",
    "                          margin=dict(l=0, r=0, t=0, b=0))\n",
    "        \n",
    "        # 凡例を非表示にする\n",
    "        fig.update_layout(showlegend=False)\n",
    "        \n",
    "        # プロットを表示\n",
    "        fig.show()\n",
    "\n",
    "        # カウントをテーブルとして表示\n",
    "        counts_df = pd.DataFrame(list(counts.items()), columns=['クラス', 'カウント'])\n",
    "        counts_df['識別子'] = identifiers\n",
    "        display(counts_df)  # カウントテーブルを表示\n",
    "        \n",
    "    def response_length(self, data):\n",
    "        # 元のデータを変更しないためにデータフレームのコピーを作成\n",
    "        data_copy = data.copy()\n",
    "        \n",
    "        # 各応答の単語数を計算\n",
    "        data_copy['word_count_a'] = data_copy['response_a'].apply(lambda x: len(str(x).split()))  # モデルAの単語数\n",
    "        data_copy['word_count_b'] = data_copy['response_b'].apply(lambda x: len(str(x).split()))  # モデルBの単語数\n",
    "        \n",
    "        # 各勝者クラスの平均単語数を計算\n",
    "        word_counts = {\n",
    "            'winner_model_a': int(\n",
    "                data_copy[data_copy['winner_model_a'] == 1][\n",
    "                    ['word_count_a', \n",
    "                     'word_count_b']\n",
    "                ].mean().mean()  # モデルAの平均単語数\n",
    "            ),\n",
    "            \n",
    "            'winner_model_b': int(\n",
    "                data_copy[data_copy['winner_model_b'] == 1][\n",
    "                    ['word_count_a', \n",
    "                     'word_count_b']\n",
    "                ].mean().mean()  # モデルBの平均単語数\n",
    "            ),\n",
    "            \n",
    "            'winner_tie': int(\n",
    "                data_copy[data_copy['winner_tie'] == 1][\n",
    "                    ['word_count_a', \n",
    "                     'word_count_b']\n",
    "                ].mean().mean()  # 引き分けの平均単語数\n",
    "            )\n",
    "        }\n",
    "        \n",
    "        # カスタムホバーテキストを作成\n",
    "        hover_texts = [f\"単語数: {value}<br>{key}\" for key, value in word_counts.items()]\n",
    "        \n",
    "        # 棒グラフを作成\n",
    "        fig = go.Figure(data=[go.Bar(\n",
    "            x=list(word_counts.keys()),  # 勝者クラスラベルをx軸に\n",
    "            y=list(word_counts.values()),  # 単語数をy軸に\n",
    "            marker=dict(color=['#a89192', '#8083a8', '#a8c28c']),\n",
    "            hovertext=hover_texts,  # ホバー時のテキスト\n",
    "            hoverinfo='text',\n",
    "            orientation='v'  # 棒を縦にする\n",
    "        )])\n",
    "        \n",
    "        # レイアウトを更新\n",
    "        fig.update_layout(\n",
    "            title='勝者クラスによる平均応答単語数',\n",
    "            xaxis_title='',\n",
    "            yaxis_title='平均応答単語数',\n",
    "            plot_bgcolor='rgba(0,0,0,0)',\n",
    "            paper_bgcolor='rgba(0,0,0,0)',\n",
    "            xaxis=dict(showticklabels=False)  # x軸のラベルを非表示\n",
    "        )\n",
    "        \n",
    "        # プロットを表示\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:21.695756Z",
     "iopub.status.busy": "2024-06-17T17:38:21.695297Z",
     "iopub.status.idle": "2024-06-17T17:38:21.702409Z",
     "shell.execute_reply": "2024-06-17T17:38:21.701089Z",
     "shell.execute_reply.started": "2024-06-17T17:38:21.695695Z"
    }
   },
   "outputs": [],
   "source": [
    "eda = EDA()  # EDAクラスのインスタンスを作成し、探索的データ分析を実行できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:25.551342Z",
     "iopub.status.busy": "2024-06-17T17:38:25.550913Z",
     "iopub.status.idle": "2024-06-17T17:38:30.501504Z",
     "shell.execute_reply": "2024-06-17T17:38:30.500243Z",
     "shell.execute_reply.started": "2024-06-17T17:38:25.551312Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = eda.read_data(CFG.train_data)  # 設定されたパスからトレーニングデータを読み込み、データフレームを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:36.653436Z",
     "iopub.status.busy": "2024-06-17T17:38:36.652917Z",
     "iopub.status.idle": "2024-06-17T17:38:36.672035Z",
     "shell.execute_reply": "2024-06-17T17:38:36.670511Z",
     "shell.execute_reply.started": "2024-06-17T17:38:36.653398Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = eda.read_data(CFG.test_data)  # 設定されたパスからテストデータを読み込み、データフレームを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:43.898851Z",
     "iopub.status.busy": "2024-06-17T17:38:43.898369Z",
     "iopub.status.idle": "2024-06-17T17:38:43.922869Z",
     "shell.execute_reply": "2024-06-17T17:38:43.921453Z",
     "shell.execute_reply.started": "2024-06-17T17:38:43.898813Z"
    }
   },
   "outputs": [],
   "source": [
    "subm_data = eda.read_data(CFG.subm_data)  # 設定されたパスから提出データのサンプルを読み込み、データフレームを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:48.962237Z",
     "iopub.status.busy": "2024-06-17T17:38:48.961789Z",
     "iopub.status.idle": "2024-06-17T17:38:49.482496Z",
     "shell.execute_reply": "2024-06-17T17:38:49.481275Z",
     "shell.execute_reply.started": "2024-06-17T17:38:48.962204Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"クラスの分布（勝者）:\")  # 勝者のクラス分布を表示するメッセージ\n",
    "eda.pie_chart(train_data)  # トレーニングデータを使ってクラス分布の円グラフを作成し表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T17:38:59.135398Z",
     "iopub.status.busy": "2024-06-17T17:38:59.134924Z",
     "iopub.status.idle": "2024-06-17T17:39:01.210285Z",
     "shell.execute_reply": "2024-06-17T17:39:01.208513Z",
     "shell.execute_reply.started": "2024-06-17T17:38:59.13536Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者モデルごとの平均応答単語数をプロットする\n",
    "eda.response_length(train_data)  # トレーニングデータを使用して、各勝者モデルの応答の平均単語数をプロットします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9337728",
   "metadata": {},
   "source": [
    "# 理論 📒\n",
    "\n",
    "✔️ **単語頻度 - 逆文書頻度**、または **TF-IDF**ベクトル化は、テキストマイニングや情報検索で使用され、文書内の単語の重要性をコーパスに対して評価します。この技術は、テキストデータを機械学習アルゴリズムに適した数値フォーマットに変換します。\n",
    "\n",
    "---\n",
    "\n",
    "✔️ **TF-IDFの構成要素**\n",
    "\n",
    "1. 単語頻度 (TF):\n",
    "\n",
    "   - *定義:* 文書内の特定単語の出現頻度を測定します。\n",
    "   \n",
    "   - *式:* $ \\text{TF}(t,d) = \\frac{f_{t,d}}{\\sum\\limits_{t' \\in d} f_{t',d}} $ , ここで $ f_{t,d} $ は文書 $ d $ 内の単語 $ t $ の出現頻度です。\n",
    "\n",
    "2. 逆文書頻度 (IDF):\n",
    "\n",
    "   - *定義:* コーパス全体における特定単語の重要性を測定します。\n",
    "   \n",
    "   - *式:* $ \\text{IDF}(t) = \\log \\left( \\frac{N}{1 + n_t} \\right) $ , ここで $ N $ は文書の総数、$ n_t $ は単語 $ t $ を含む文書の数です。\n",
    "\n",
    "3. TF-IDFスコア:\n",
    "\n",
    "   - *定義:* TFとIDFスコアの積です。\n",
    "   \n",
    "   - *式:* $ \\text{TF-IDF}(t,d) = \\text{TF}(t,d) \\times \\text{IDF}(t) $\n",
    "   \n",
    "---\n",
    "\n",
    "✔️ ***N-grams* の説明**\n",
    "\n",
    "*N-grams* は、テキスト文書から抽出される連続した $ n $ 項目（トークン）のシーケンスです。これにより、個々の単語に比べて言語構造と文脈のより包括的な表現が得られます。\n",
    "\n",
    "*式:* $ N\\text{-grams} = [t_1, t_2, ..., t_n] $\n",
    "\n",
    "*例:* `ngrams = (1, 3)` の場合、テキスト文書内の長さ3のスライディングウィンドウで可能な全てのトークンの組み合わせを考慮します。各3トークンの組み合わせはトライグラムを表します。\n",
    "\n",
    "例えば、「I love coding.」という文を考えます。\n",
    "\n",
    "`ngrams = (1, 3)`の場合、この文から抽出されるn-gramsには以下が含まれます：\n",
    "\n",
    "   * ユニグラム (1-grams): [\"I\"], [\"love\"], [\"coding\"]\n",
    "    \n",
    "   * バイグラム (2-grams): [\"I love\"], [\"love coding\"]\n",
    "    \n",
    "   * トリグラム (3-grams): [\"I love coding\"]\n",
    "\n",
    "このように、$ N-grams $ は個々の単語だけでなく、フレーズや文中のコンテキスト情報も捉えます。\n",
    "\n",
    "---\n",
    "   \n",
    "✔️ **TF-IDFのステップ**\n",
    "\n",
    "1. トークン化:\n",
    "\n",
    "   - *定義:* テキストをトークンに分けます。\n",
    "   \n",
    "   - *例:* \"I love coding\" -> [\"I\", \"love\", \"coding\"]\n",
    "\n",
    "2. 文書頻度の計算:\n",
    "\n",
    "   - *定義:* 各単語を含む文書の数をカウントします。\n",
    "   \n",
    "   - *例:* \"love\" は1つの文書に出現します。\n",
    "\n",
    "3. TF-IDFの計算:\n",
    "\n",
    "   - *定義:* 各文書内の各単語のTF-IDFスコアを計算します。\n",
    "   \n",
    "   - *例:* ngrams = (1, 3) の場合、\"love\"は文書1に出現し、そのTFとIDFに基づいてTF-IDFスコアが計算されます。\n",
    "\n",
    "4. ベクトル化:\n",
    "\n",
    "   - *定義:* 各文書をTF-IDFスコアのベクトルとして表現します。\n",
    "   \n",
    "   - *例:* 各文書は、高次元ベクトルになり、各次元はユニークな単語またはn-gramに対応します。\n",
    "\n",
    "# データ前処理 🛠️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T18:16:09.085037Z",
     "iopub.status.busy": "2024-06-17T18:16:09.084595Z",
     "iopub.status.idle": "2024-06-17T18:16:09.127941Z",
     "shell.execute_reply": "2024-06-17T18:16:09.126578Z",
     "shell.execute_reply.started": "2024-06-17T18:16:09.085004Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataPreprocessing:\n",
    "    # 入力リスト内にNoneが存在するかチェック\n",
    "    @staticmethod\n",
    "    def retrieve_none(vals):\n",
    "        return int(any(val is None for val in vals))  # 1つでもNoneがあれば1を返す\n",
    "\n",
    "    # 入力リスト内の文字列の合計長を計算\n",
    "    @staticmethod\n",
    "    def retrieve_length(vals):\n",
    "        length = 0\n",
    "        for val in vals:\n",
    "            if isinstance(val, str):  # valが文字列であれば\n",
    "                length += len(val)  # その長さを加算\n",
    "        return length\n",
    "    \n",
    "    # 入力リスト内のユニークな単語のカウントを計算\n",
    "    @staticmethod\n",
    "    def retrieve_nuniques(vals):\n",
    "        if isinstance(vals, str):  # valsが文字列の場合\n",
    "            return len(set(vals.split()))  # ユニークな単語の数をカウントして返す\n",
    "        return 0\n",
    "    \n",
    "    # リスト内の'None'を'STR'に置き換え、要素をスペースで結合\n",
    "    @staticmethod\n",
    "    def clean_response(text):\n",
    "        if isinstance(text, list):  # textがリストの場合\n",
    "            cleaned_text = ' '.join([str(item) if item is not None else 'NONE' for item in text])  # Noneを'STR'に置き換え\n",
    "            return cleaned_text\n",
    "\n",
    "        return text  # それ以外は元のtextを返す\n",
    "\n",
    "    def add_features(self, data):\n",
    "        # 応答列の長さやNoneの有無に関連する特徴を追加\n",
    "        data[f\"response_a_len\"] = data[f\"response_a\"].apply(self.retrieve_length)  # 応答Aの長さ\n",
    "        data[f\"response_b_len\"] = data[f\"response_b\"].apply(self.retrieve_length)  # 応答Bの長さ\n",
    "\n",
    "        # 応答のユニークな単語数を計算\n",
    "        data[f\"response_a_unique\"] = data[f\"response_a\"].apply(self.retrieve_nuniques)  # 応答Aのユニーク単語数\n",
    "        data[f\"response_b_unique\"] = data[f\"response_b\"].apply(self.retrieve_nuniques)  # 応答Bのユニーク単語数\n",
    "\n",
    "        # 長さの差、平均長さ、長さ差比を計算\n",
    "        data[\"response_len_diff\"] = data[\"response_a_len\"] - data[\"response_b_len\"]  # 長さの差\n",
    "        data[\"response_len_mean\"] = (data[\"response_a_len\"] + data[\"response_b_len\"]) / 2  # 平均長さ\n",
    "        data[\"response_diff_ratio\"] = data[\"response_len_diff\"] / data[\"response_len_mean\"]  # 長さ差比\n",
    "\n",
    "        # ユニーク単語数の差、平均、および比を計算\n",
    "        data[\"response_unique_diff\"] = data[\"response_a_unique\"] - data[\"response_b_unique\"]  # ユニーク単語数の差\n",
    "        data[\"response_unique_mean\"] = (data[\"response_a_unique\"] + \n",
    "                                        data[\"response_b_unique\"]) / 2  # ユニーク単語数の平均\n",
    "        data[\"response_unique_ratio\"] = (data[\"response_unique_diff\"] / \n",
    "                                         data[\"response_unique_mean\"])  # ユニーク単語数差比\n",
    "\n",
    "        # 応答列内にNoneが含まれているかをチェック\n",
    "        data[\"a_has_none\"] = data[\"response_a\"].apply(self.retrieve_none)  # 応答AにNoneがあるか\n",
    "        data[\"b_has_none\"] = data[\"response_b\"].apply(self.retrieve_none)  # 応答BにNoneがあるか\n",
    "        data[\"has_none_diff\"] = data[\"a_has_none\"] - data[\"b_has_none\"]  # Noneの差\n",
    "\n",
    "        return data  # 加工したデータを返す\n",
    "    \n",
    "    # プロンプトと応答間のコサイン類似度を計算\n",
    "    @staticmethod\n",
    "    def calculate_cosine_similarity(tfidf_matrix, \n",
    "                                    prompt_idx, \n",
    "                                    response_a_idx, \n",
    "                                    response_b_idx):\n",
    "        \n",
    "        # プロンプト（p）と応答A（a）のコサイン類似度\n",
    "        similarity_pa = cosine_similarity(\n",
    "                tfidf_matrix[prompt_idx].reshape(1, -1), \n",
    "                tfidf_matrix[response_a_idx].reshape(1, -1)\n",
    "        )[0][0]\n",
    "\n",
    "        # プロンプト（p）と応答B（b）のコサイン類似度\n",
    "        similarity_pb = cosine_similarity(\n",
    "                tfidf_matrix[prompt_idx].reshape(1, -1), \n",
    "                tfidf_matrix[response_b_idx].reshape(1, -1)\n",
    "        )[0][0]\n",
    "\n",
    "        return similarity_pa, similarity_pb  # 類似度を返す\n",
    "\n",
    "    # プロンプトと応答間の距離（ユークリッド/ラプラシアン）を計算\n",
    "    @staticmethod\n",
    "    def calculate_distances(tfidf_matrix, \n",
    "                            prompt_idx, \n",
    "                            response_a_idx, \n",
    "                            response_b_idx, \n",
    "                            distance_metric):\n",
    "        \n",
    "        # プロンプト（p）と応答A（a）の距離\n",
    "        distance_pa = distance_metric(\n",
    "                tfidf_matrix[prompt_idx].reshape(1, -1), \n",
    "                tfidf_matrix[response_a_idx].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        \n",
    "        # プロンプト（p）と応答B（b）の距離\n",
    "        distance_pb = distance_metric(\n",
    "                tfidf_matrix[prompt_idx].reshape(1, -1),\n",
    "                tfidf_matrix[response_b_idx].reshape(1, -1)\n",
    "        )[0][0]\n",
    "        \n",
    "        return distance_pa, distance_pb  # 距離を返す\n",
    "\n",
    "    def create_tfidf_features(self, train, test, ngrams, min_freq, max_freq, components):\n",
    "        # TF-IDFベクトルライザを初期化\n",
    "        tfidf_vectorizer = TfidfVectorizer(analyzer='char', \n",
    "                                           ngram_range=ngrams, \n",
    "                                           min_df=min_freq, \n",
    "                                           max_df=max_freq,\n",
    "                                           lowercase=False,\n",
    "                                           sublinear_tf=True)\n",
    "\n",
    "        # トレーニングデータとテストデータを単一のデータフレームに結合\n",
    "        full_data = pd.concat([train, test], ignore_index=True)\n",
    "\n",
    "        # テキスト列をクリーンアップして準備\n",
    "        for col in ['prompt', 'response_a', 'response_b']:\n",
    "            full_data[col] = full_data[col].apply(self.clean_response)\n",
    "\n",
    "        # TF-IDFベクトル化のためにすべてのテキスト列を結合\n",
    "        full_corpus = pd.concat([full_data['prompt'], \n",
    "                                 full_data['response_a'], \n",
    "                                 full_data['response_b']], \n",
    "                                 ignore_index=True)\n",
    "\n",
    "        # TF-IDFマトリックスを計算\n",
    "        tfidf_matrix = tfidf_vectorizer.fit_transform(full_corpus)\n",
    "\n",
    "        # 次元削減をトランケイテッドSVDで実施\n",
    "        svd = TruncatedSVD(n_components=components, random_state=42)\n",
    "        reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
    "\n",
    "        # コーパスの異なる部分を分割するためのインデックスを計算\n",
    "        len_full = len(full_data)\n",
    "        split_index_01 = len_full\n",
    "        split_index_02 = len_full * 2\n",
    "\n",
    "        # 短縮マトリックスをプロンプト、応答A、および応答B部分に分割\n",
    "        full_tfidf_prompts = reduced_matrix[:split_index_01]\n",
    "        full_tfidf_response_a = reduced_matrix[split_index_01:split_index_02]\n",
    "        full_tfidf_response_b = reduced_matrix[split_index_02:]\n",
    "\n",
    "        # 短縮マトリックスをトレーニングセットとテストセットに分割\n",
    "        len_train = len(train)\n",
    "        train_tfidf_prompts = full_tfidf_prompts[:len_train]\n",
    "        train_tfidf_response_a = full_tfidf_response_a[:len_train]\n",
    "        train_tfidf_response_b = full_tfidf_response_b[:len_train]\n",
    "        test_tfidf_prompts = full_tfidf_prompts[len_train:]\n",
    "        test_tfidf_response_a = full_tfidf_response_a[len_train:]\n",
    "        test_tfidf_response_b = full_tfidf_response_b[len_train:]\n",
    "\n",
    "        # トレーニングおよびテストセットのSVD特徴を保持するためのデータフレームを作成\n",
    "        feature_names = [f'svd_feature_{i}' for i in range(components)]\n",
    "        train_features = pd.DataFrame(index=train.index)\n",
    "        test_features = pd.DataFrame(index=test.index)\n",
    "\n",
    "        # SVD特徴を特徴データフレームの対応する列に割り当て\n",
    "        for i in range(components):\n",
    "            train_features[f'svd_prompts_{i}'] = train_tfidf_prompts[:, i]\n",
    "            train_features[f'svd_response_a_{i}'] = train_tfidf_response_a[:, i]\n",
    "            train_features[f'svd_response_b_{i}'] = train_tfidf_response_b[:, i]\n",
    "            test_features[f'svd_prompts_{i}'] = test_tfidf_prompts[:, i]\n",
    "            test_features[f'svd_response_a_{i}'] = test_tfidf_response_a[:, i]\n",
    "            test_features[f'svd_response_b_{i}'] = test_tfidf_response_b[:, i]\n",
    "\n",
    "        # 新しい特徴を元のトレーニングおよびテストデータフレームと連結\n",
    "        train = pd.concat([train, train_features], axis=1)\n",
    "        test = pd.concat([test, test_features], axis=1)\n",
    "\n",
    "        # 類似度と距離の特徴を計算\n",
    "        for df, len_df in zip([train, test], [len(train), len(test)]):\n",
    "            prompt_indices = df.index\n",
    "\n",
    "            # コサイン類似度の特徴を計算\n",
    "            df['similarity_pa'], df['similarity_pb'] = zip(*[\n",
    "                self.calculate_cosine_similarity(reduced_matrix, i, i + len_df, i + 2 * len_df)\n",
    "                for i in prompt_indices\n",
    "            ])\n",
    "\n",
    "            # ユークリッド距離の特徴を計算\n",
    "            df['euclidean_pa'], df['euclidean_pb'] = zip(*[\n",
    "                self.calculate_distances(reduced_matrix, i, i + len_df, i + 2 * len_df, \n",
    "                                         euclidean_distances)\n",
    "                for i in prompt_indices\n",
    "            ])\n",
    "\n",
    "            # ラプラシアンカーネル距離の特徴を計算\n",
    "            df['laplacian_pa'], df['laplacian_pb']= zip(*[\n",
    "                self.calculate_distances(reduced_matrix, i, i + len_df, i + 2 * len_df, \n",
    "                                         laplacian_kernel)\n",
    "                for i in prompt_indices\n",
    "            ])\n",
    "\n",
    "        return train, test  # 加工したトレーニングデータとテストデータを返す\n",
    "    \n",
    "    # 複数のラベルを単一のラベルにマージ\n",
    "    def merge_label(self, row):\n",
    "        if row[\"winner_model_a\"] == 1:\n",
    "            return 0  # モデルAが勝者の場合\n",
    "        if row[\"winner_model_b\"] == 1:\n",
    "            return 1  # モデルBが勝者の場合\n",
    "        if row[\"winner_tie\"] == 1:\n",
    "            return 2  # 引き分けの場合\n",
    "        raise ValueError(\"値が無効です。\")  # 無効な値の場合エラーを発生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T18:16:11.276607Z",
     "iopub.status.busy": "2024-06-17T18:16:11.276207Z",
     "iopub.status.idle": "2024-06-17T18:16:11.282244Z",
     "shell.execute_reply": "2024-06-17T18:16:11.280811Z",
     "shell.execute_reply.started": "2024-06-17T18:16:11.276577Z"
    }
   },
   "outputs": [],
   "source": [
    "dp = DataPreprocessing()  # データ前処理クラスのインスタンスを作成し、データの前処理を実行できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T18:16:12.76684Z",
     "iopub.status.busy": "2024-06-17T18:16:12.766348Z",
     "iopub.status.idle": "2024-06-17T18:17:12.04567Z",
     "shell.execute_reply": "2024-06-17T18:17:12.044262Z",
     "shell.execute_reply.started": "2024-06-17T18:16:12.766804Z"
    }
   },
   "outputs": [],
   "source": [
    "# 長さ、類似度、および距離の特徴を追加する\n",
    "train_data = dp.add_features(train_data)  # トレーニングデータに特徴を追加\n",
    "test_data = dp.add_features(test_data)    # テストデータに特徴を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-17T18:17:12.048154Z",
     "iopub.status.busy": "2024-06-17T18:17:12.047755Z"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF特徴を抽出し、次元削減を実施する\n",
    "train_data, test_data = dp.create_tfidf_features(train_data,  # トレーニングデータを使用\n",
    "                                                 test_data,   # テストデータを使用\n",
    "                                                 CFG.ngrams,  # n-gramの設定\n",
    "                                                 CFG.min_freq,  # 最小頻度の設定\n",
    "                                                 CFG.max_freq,  # 最大頻度の設定\n",
    "                                                 CFG.components)  # コンポーネントの数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複数のラベルを単一のラベルにマージする\n",
    "train_data[\"target\"] = train_data[  # ターゲット列を作成\n",
    "    [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "].apply(lambda x: dp.merge_label(x), axis=1)  # 各行にmerge_label関数を適用してターゲットを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dac940c",
   "metadata": {},
   "source": [
    "# モデル開発 🧠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelDevelopment:\n",
    "    def train_lgb(self, train_data, test_data, feature_cols, params, early_stop, log_steps):\n",
    "        # トレーニングデータとテストデータから特徴量とターゲットラベルを抽出\n",
    "        X_train = train_data[feature_cols].values  # 特徴量の行列\n",
    "        X_test = test_data[feature_cols].values    # テスト用特徴量\n",
    "        Y_train = train_data[\"target\"]              # ターゲットラベル\n",
    "\n",
    "        # 予測を保存するリスト\n",
    "        train_preds_list = []\n",
    "        test_preds_list = []\n",
    "\n",
    "        # StratifiedKFoldを初期化\n",
    "        cv = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train, Y_train)):\n",
    "            # 現在のフォールドのためにトレーニングデータをトレーニングセットとバリデーションセットに分割\n",
    "            x_train, x_valid = X_train[train_index], X_train[valid_index]\n",
    "            y_train, y_valid = Y_train[train_index], Y_train[valid_index]\n",
    "\n",
    "            # トレーニングとバリデーションのためのLightGBMデータセットオブジェクトを作成\n",
    "            train = lgb.Dataset(x_train, y_train)\n",
    "            valid = lgb.Dataset(x_valid, y_valid, reference=train)\n",
    "\n",
    "            # 現在のフォールドでモデルを訓練\n",
    "            model = lgb.train(\n",
    "                params,\n",
    "                train,\n",
    "                valid_sets=[train, valid],\n",
    "                feature_name=feature_cols,\n",
    "                callbacks=[lgb.early_stopping(early_stop),\n",
    "                           lgb.log_evaluation(log_steps)])\n",
    "\n",
    "            # トレーニングセットとテストセットに対して予測を行う\n",
    "            train_preds = model.predict(X_train)  # トレーニングデータの予測\n",
    "            test_preds = model.predict(X_test)    # テストデータの予測\n",
    "\n",
    "            train_preds_list.append(train_preds)  # トレーニング予測をリストに追加\n",
    "            test_preds_list.append(test_preds)    # テスト予測をリストに追加\n",
    "\n",
    "        # 予測の平均を計算\n",
    "        train_preds = np.mean(train_preds_list, axis=0)  # トレーニング予測の平均\n",
    "        test_preds = np.mean(test_preds_list, axis=0)    # テスト予測の平均\n",
    "\n",
    "        return train_preds, test_preds  # 予測を返す\n",
    "    \n",
    "    # トレーニングデータ予測用の混同行列をプロット\n",
    "    def plot_cm(self, y_true, y_pred, labels, colorscale):\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)  # 混同行列を計算\n",
    "\n",
    "        # カスタムホバーテキストフォーマッタを作成\n",
    "        def format_hover_text(value):\n",
    "            if value >= 10000:\n",
    "                return str(int(value))  # 整数値に変換してカンマなしで返す\n",
    "            else:\n",
    "                return str(value)\n",
    "\n",
    "        # ヒートマップを作成\n",
    "        fig = go.Figure(data=go.Heatmap(\n",
    "            z=cm,\n",
    "            x=labels,\n",
    "            y=labels,\n",
    "            colorscale=colorscale,\n",
    "            zmin=0,\n",
    "            zmax=20000,\n",
    "            text=cm,\n",
    "            texttemplate=\"%{text:.0f}\",\n",
    "            hovertemplate=\"真実: %{y}<br>予測: %{x}<br>カウント: %{z:,.0f}<extra></extra>\",\n",
    "            customdata=[format_hover_text(value) for value in cm.flatten()]\n",
    "        ))\n",
    "\n",
    "        # 背景を透明にし、正方形のアスペクト比に設定するためにレイアウトを更新\n",
    "        fig.update_layout(\n",
    "            plot_bgcolor='rgba(0,0,0,0)',\n",
    "            paper_bgcolor='rgba(0,0,0,0)',\n",
    "            xaxis_title=\"予測ラベル\",\n",
    "            yaxis_title=\"真実のラベル\",\n",
    "            xaxis=dict(constrain='domain'),\n",
    "            yaxis=dict(constrain='domain', scaleanchor='x'),\n",
    "            width=650,  \n",
    "            height=650,  \n",
    "            margin=dict(t=65, b=65, l=65, r=65) \n",
    "        )\n",
    "\n",
    "        # プロットを表示\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ModelDevelopment()  # モデル開発クラスのインスタンスを作成し、モデルの訓練や評価を実行できるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ラベル列を定義\n",
    "label_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "\n",
    "# トレーニングデータから除外する特徴量のリストを定義\n",
    "excluded_features = ['id', \n",
    "                     'model_a', \n",
    "                     'model_b', \n",
    "                     'prompt', \n",
    "                     'response_a', \n",
    "                     'response_b',\n",
    "                     'winner_model_a', \n",
    "                     'winner_model_b', \n",
    "                     'winner_tie', \n",
    "                     'target', \n",
    "                     'fold_id']\n",
    "\n",
    "# 除外リストに含まれない列を特徴量としてリスト化\n",
    "features = [col for col in train_data.columns if col not in excluded_features]  # 使用する特徴量のリストを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMを訓練する\n",
    "train_preds, test_preds = md.train_lgb(  # トレーニングデータとテストデータを用いてLightGBMを訓練\n",
    "    train_data, \n",
    "    test_data, \n",
    "    features,  # 使用する特徴量\n",
    "    CFG.params,  # モデルパラメータ\n",
    "    CFG.early_stop,  # 早期終了のための基準\n",
    "    CFG.log_steps  # ログステップの設定\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータに対する（平均）予測の混同行列\n",
    "md.plot_cm(train_data['target'], np.argmax(train_preds, axis=1), [0, 1, 2], CFG.colorscale)  # ターゲットと予測ラベルを用いて混同行列をプロット"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e484c33",
   "metadata": {},
   "source": [
    "# 予測を提出する 💡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用データフレームに予測したテストラベルを割り当て\n",
    "subm_data[label_cols] = test_preds  # テストデータの予測結果を提出データフレームに追加\n",
    "\n",
    "# 提出データフレームを保存し、最初の3行を表示\n",
    "subm_data.to_csv(\"submission.csv\", index=False)  # 提出ファイルをCSV形式で保存\n",
    "display(subm_data.head(3))  # 提出データフレームの最初の3行を表示"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 4959805,
     "sourceId": 8377405,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30715,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2593.627859,
   "end_time": "2024-06-06T20:41:57.399746",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-06T19:58:43.771887",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
