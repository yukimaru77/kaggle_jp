{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373571eb",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このノートブックは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、チャットボットの応答に対する人間の好みを予測するための機械学習モデルを構築することに取り組んでいます。具体的には、提供されたデータセット内のPythonとTensorFlow、およびKerasを使用して、自然言語処理を行い、複数の異なるモデルの出力を評価し、勝者を予測するシステムを作成します。\n",
    "\n",
    "### 使用ライブラリと手法\n",
    "1. **ライブラリのインポート**: `Keras`, `TensorFlow`, `NumPy`, `Pandas`など、モデル構築やデータ処理のために多くのライブラリをインポートします。また、`keras_nlp`を利用して自然言語処理を実行します。\n",
    "  \n",
    "2. **ハードウェアの設定**: 利用可能なGPUやTPUを確認し、最適な学習戦略を選択します。これにより、分散学習を利用してトレーニングの効率を向上させます。\n",
    "\n",
    "3. **データの前処理**: トレーニングデータとテストデータを読み込み、重複を削除するなどして基本的な整形を行います。また、応答をプロンプトに基づいて文脈化してペアを作成し、各応答をテキストクリーニングします。\n",
    "\n",
    "4. **特徴量の生成**: `DataFrameStatsProcessor`クラスを使用し、データフレームから特徴量を計算し、欠損値の統計や応答の長さに関する情報を整理します。\n",
    "\n",
    "5. **モデル構築**: `DebertaV3Backbone`を用いたニューラルネットワークモデルを構築し、層を追加して最後はSoftmax関数を用いてクラス確率を予測します。ここでは、L2正則化やドロップアウトレイヤーを使用して過学習を防ぎます。\n",
    "\n",
    "6. **トレーニング**: 学習率のスケジュールを設定し、モデルをトレーニングします。学習が進むにつれてモデルの性能を評価しつつ、最良のモデルを保存します。\n",
    "\n",
    "7. **評価と予測**: トレーニングを経たモデルを使用して、テストデータセットに対して予測を実行します。また、FGM（Fast Gradient Method）を利用してモデルの堅牢性を評価します。\n",
    "\n",
    "8. **出力ファイルの作成**: 最後に、予測結果をCSVファイルとして保存し、コンペティションに提出します。\n",
    "\n",
    "このノートブックは、全体を通して深層学習を活用した自然言語処理モデルの構築と評価に焦点を当てており、特にモデルの再現性を高めるための工夫が随所に見られます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7cc478",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に関連する専門用語の解説です。初心者がつまずきそうな要点に焦点を当てています。\n",
    "\n",
    "1. **Kerasバックエンド (Keras backend)**:\n",
    "   - Kerasは高レベルのニューラルネットワークAPIであり、TensorFlowやTheanoといった他の深層学習ライブラリの上で動作します。`KERAS_BACKEND`を設定することで、Kerasがどのライブラリを使用するかを指定します。\n",
    "\n",
    "2. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが開発した、特に機械学習のために設計されたハードウェア加速器です。TPUは演算を効率化し、大規模なモデルをより速く訓練または推論するために特化しています。\n",
    "\n",
    "3. **混合精度 (Mixed Precision)**:\n",
    "   - 深層学習トレーニング中に、異なる精度（通常はfloat32とfloat16）を使用してメモリ使用量を減少させる手法です。これにより、トレーニングプロセスが速くなり、大きなバッチサイズを使用できるようになります。\n",
    "\n",
    "4. **データローダー (DataLoader)**:\n",
    "   - モデルにデータを供給するための仕組みを指します。効率的なデータ読み込みや前処理のために使用され、ハードウェアのキャパシティを最大限に活用するのに役立ちます。\n",
    "\n",
    "5. **FGM (Fast Gradient Method)**:\n",
    "   - モデルの堅牢性を向上させる手法の一つで、特徴量に摺動（微小なランダムな変更）を加えることによって、モデルが攻撃に強くなることを目的としています。\n",
    "\n",
    "6. **AWP (Adversarial Weight Perturbation)**:\n",
    "   - モデルの重みを動的に微調整することにより、強化学習されたモデルの堅牢性を高める手法です。この手法では、各バッチの開始時に重みに摺動を加えます。\n",
    "\n",
    "7. **Zスコア正規化 (Z-score Normalization)**:\n",
    "   - データを標準化する手法で、データの平均を0、標準偏差を1に調整します。これにより、異なるスケールの特徴量を比較可能にします。\n",
    "\n",
    "8. **前処理器 (Preprocessor)**:\n",
    "   - データをモデルが扱いやすい形式に変換するための仕組み。トークン化、パディング、エンコーディングなどの操作を行います。\n",
    "\n",
    "9. **温度スケーリング (Temperature Scaling)**:\n",
    "   - モデルの予測確率を調整するための手法です。ロジット（ニューラルネットワークの出力）を温度パラメータで割ることによって、確率分布を平滑化し、過剰適合を防ぎます。\n",
    "\n",
    "10. **ラベルスムージング (Label Smoothing)**:\n",
    "    - 正解ラベルに対して、ほんの少しノイズを加えて柔軟性を持たせる手法です。これにより、過剰適合を防ぎ、一般化性能を向上させる効果があります。\n",
    "\n",
    "これらの用語は、実務経験が乏しい初心者にとっては馴染みが薄いものでありながら、深層学習モデルの実装においては非常に重要な要素です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac4669",
   "metadata": {},
   "source": [
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:24.696323Z",
     "iopub.status.busy": "2024-07-06T08:18:24.695656Z",
     "iopub.status.idle": "2024-07-06T08:18:38.603387Z",
     "shell.execute_reply": "2024-07-06T08:18:38.602609Z",
     "shell.execute_reply.started": "2024-07-06T08:18:24.696269Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # または \"jax\" または \"torch\"\n",
    "# Kerasのバックエンドとして使用するフレームワークを環境変数に設定します\n",
    "\n",
    "import re  # 正規表現を操作するためのライブラリをインポートします\n",
    "\n",
    "import keras_nlp  # Kerasの自然言語処理用ライブラリをインポートします\n",
    "import keras  # Kerasライブラリをインポートします\n",
    "import tensorflow as tf  # TensorFlowライブラリをインポートします\n",
    "\n",
    "import numpy as np  # NumPyライブラリをインポートします（数値計算用）\n",
    "import pandas as pd  # Pandasライブラリをインポートします（データ操作用）\n",
    "from tqdm import tqdm  # プログレスバー表示のためのライブラリをインポートします\n",
    "import json  # JSONデータを扱うためのライブラリをインポートします"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b5bdad",
   "metadata": {},
   "source": [
    "# 利用可能なGPUの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:38.605512Z",
     "iopub.status.busy": "2024-07-06T08:18:38.604965Z",
     "iopub.status.idle": "2024-07-06T08:18:39.274199Z",
     "shell.execute_reply": "2024-07-06T08:18:39.272847Z",
     "shell.execute_reply.started": "2024-07-06T08:18:38.605485Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "# 利用可能なGPUの数を出力します\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "# モデルの分散学習のために、MirroredStrategyを使用します\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "# 同期中のデバイス（GPU）の数を出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432d3312",
   "metadata": {},
   "source": [
    "# TPU（Tensor Processing Unit）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.275981Z",
     "iopub.status.busy": "2024-07-06T08:18:39.275537Z",
     "iopub.status.idle": "2024-07-06T08:18:39.296311Z",
     "shell.execute_reply": "2024-07-06T08:18:39.295509Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.275939Z"
    }
   },
   "outputs": [],
   "source": [
    "# ハードウェアを検出し、適切な分散戦略を返します\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPUの検出。TPU_NAME環境変数が設定されていればパラメータは不要です。Kaggleでは常にこの設定が行われています。\n",
    "    print('Running on TPU ', tpu.master())\n",
    "    # TPUが見つかった場合、そのマスターの情報を出力します\n",
    "except ValueError:\n",
    "    tpu = None  # TPUが見つからない場合、tpuをNoneに設定します\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    # TPUクラスタへの接続を確立します\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    # TPUシステムを初期化します\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    # TPU用の分散戦略を設定します\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()  # TensorFlowのデフォルトの分散戦略を取得します。CPUおよび単一GPUで動作します。\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "# 同期中の複製数を出力します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa5920",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.299068Z",
     "iopub.status.busy": "2024-07-06T08:18:39.298649Z",
     "iopub.status.idle": "2024-07-06T08:18:39.307362Z",
     "shell.execute_reply": "2024-07-06T08:18:39.306565Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.299039Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    seed = 42  # ランダムシードの設定\n",
    "    preset = \"deberta_v3_extra_small_en\"  # 使用するモデルのプリセット\n",
    "    sequence_length = 512  # 入力シーケンスの最大長\n",
    "    epochs = 6  # 学習するエポック数\n",
    "    batch_size = 16  # バッチサイズ\n",
    "#     batch_size = 16 * strategy.num_replicas_in_sync  # (コメントアウトされたコード) 複製に応じたバッチサイズの計算\n",
    "    scheduler = 'cosine'  # 学習率スケジューラーの設定\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}  # ラベルと名前のマッピング\n",
    "    name2label = {v:k for k, v in label2name.items()}  # 名前からラベルへの逆マッピング\n",
    "    class_labels = list(label2name.keys())  # 使用するクラスラベルのリスト\n",
    "    class_names = list(label2name.values())  # 使用するクラス名のリスト"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64909c3b",
   "metadata": {},
   "source": [
    "# 再現性\n",
    "ランダムシードの値を設定することで、毎回の実行で類似の結果を得ることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.308477Z",
     "iopub.status.busy": "2024-07-06T08:18:39.308223Z",
     "iopub.status.idle": "2024-07-06T08:18:39.317829Z",
     "shell.execute_reply": "2024-07-06T08:18:39.316936Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.308456Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(CFG.seed)  # Kerasのランダムシードを設定します。これにより、モデルの再現性が確保されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75a189",
   "metadata": {},
   "source": [
    "# 混合精度\n",
    "\n",
    "本ノートブックでは、GPUのメモリ使用量を減少させるために、float32精度の代わりに混合精度を使用してトレーニングと推論を行います。これにより、より大きなバッチサイズを使用できるようになり、トレーニングと推論の時間を短縮できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.319115Z",
     "iopub.status.busy": "2024-07-06T08:18:39.318845Z",
     "iopub.status.idle": "2024-07-06T08:18:39.328914Z",
     "shell.execute_reply": "2024-07-06T08:18:39.328119Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.319092Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "# \"mixed_float16\"ポリシーを設定します。この設定により、モデルの一部は自動的にfloat16で計算され、他の部分（例えば損失関数の計算）は安定性を保つために引き続きfloat32を使用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0e1f29",
   "metadata": {},
   "source": [
    "# データセットのパス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.330581Z",
     "iopub.status.busy": "2024-07-06T08:18:39.329996Z",
     "iopub.status.idle": "2024-07-06T08:18:39.339076Z",
     "shell.execute_reply": "2024-07-06T08:18:39.338163Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.330549Z"
    }
   },
   "outputs": [],
   "source": [
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'  # データセットのベースパスを設定します。このパスはKaggleの入力データを指します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fd39b4",
   "metadata": {},
   "source": [
    "# メタデータ\n",
    "## ファイル\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: 各行のユニーク識別子。\n",
    "- `model_[a/b]`: モデルの識別子。train.csvには存在するが、test.csvには存在しません。\n",
    "- `prompt`: 両モデルに与えられた入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。\n",
    "- `winner_model_[a/b/tie]`: 審査員の選択を示すバイナリ列（正解ターゲット）。\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: 各行のユニーク識別子。\n",
    "- `prompt`: 両モデルに与えられた入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:39.340799Z",
     "iopub.status.busy": "2024-07-06T08:18:39.340245Z",
     "iopub.status.idle": "2024-07-06T08:18:46.525334Z",
     "shell.execute_reply": "2024-07-06T08:18:46.524439Z",
     "shell.execute_reply.started": "2024-07-06T08:18:39.340768Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータを読み込む\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv')  # train.csvファイルを読み込みます\n",
    "ultrachat_df = pd.read_csv('/kaggle/input/ultrachat-train/ultrachat_s42_a0.5.csv')  # ultrachatデータを読み込みます\n",
    "df = pd.concat([df, ultrachat_df], axis=0)  # データフレームを縦に結合します\n",
    "lmsys_33k_deduplicated = pd.read_csv('/kaggle/input/lmsys-33k-deduplicated/lmsys-33k-deduplicated.csv')  # 重複のないlmsysデータを読み込みます\n",
    "df = pd.concat([df, lmsys_33k_deduplicated], axis=0)  # 再びデータフレームを結合します\n",
    "# ultrafeedback_lmsysformat = pd.read_parquet('/kaggle/input/ultrafeedback-lmsysformat/ultrafeedback_lmsysformat.parquet', engine='pyarrow')\n",
    "# ultrafeedback_lmsysformat['prompt'] = ultrafeedback_lmsysformat['prompt'].apply(lambda x: f'[\"{x}\"]')\n",
    "# df = pd.concat([df, ultrafeedback_lmsysformat], axis=0)  # コメントアウトされたコード。別のデータフレームの読み込みと結合。\n",
    "\n",
    "# テストデータを読み込む\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')  # test.csvファイルを読み込みます\n",
    "\n",
    "# display(ultrafeedback_lmsysformat.head())  # コメントアウトされたコード。ultrafeedbackデータの先頭を表示。\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:46.526829Z",
     "iopub.status.busy": "2024-07-06T08:18:46.526529Z",
     "iopub.status.idle": "2024-07-06T08:18:55.668662Z",
     "shell.execute_reply": "2024-07-06T08:18:55.667798Z",
     "shell.execute_reply.started": "2024-07-06T08:18:46.526804Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"id\", axis=1)  # 'id'列を削除します\n",
    "df = df.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、インデックスを再設定します\n",
    "\n",
    "for col in [\"prompt\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x))  # 'prompt'列の各要素を評価してリストに変換します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x))  # テストデータの'prompt'列も同様に処理します\n",
    "for col in [\"response_a\", \"response_b\"]:\n",
    "    df[col] = df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # 'null'を'None'に置き換え、評価します\n",
    "    test_df[col] = test_df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))  # テストデータも同様に処理します\n",
    "    \n",
    "# サンプリングデータ（コメントアウト）\n",
    "# df = df.sample(frac=0.01)  # データの1%をサンプリングします\n",
    "\n",
    "# ラベル変換\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)  # 各行で最大値のインデックスを取得し、クラス名を設定\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)  # クラス名をラベルに変換します\n",
    "\n",
    "# サンプルを表示\n",
    "display(df.head())  # トレーニングデータフレームの先頭5行を表示します\n",
    "# サンプルを表示\n",
    "display(test_df.head())  # テストデータフレームの先頭5行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a208bef",
   "metadata": {},
   "source": [
    "## プロンプトで応答を文脈化する\n",
    "\n",
    "私たちのアプローチでは、すべての応答に対して単一のプロンプトを使用するのではなく、各応答をプロンプトに基づいて文脈化します。これは、各応答ごとに、モデルに同じプロンプトのセットとその各応答（例えば、「(P + R_A)」、「(P + R_B)」など）を提供することを意味します。\n",
    "\n",
    "> 一部のプロンプトおよび応答は `utf-8` エンコーディングが使用されていない場合があり、その結果データローダーの作成時にエラーが発生する可能性があります。この場合、これらを空の文字列に置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:55.67367Z",
     "iopub.status.busy": "2024-07-06T08:18:55.673373Z",
     "iopub.status.idle": "2024-07-06T08:18:55.683287Z",
     "shell.execute_reply": "2024-07-06T08:18:55.682351Z",
     "shell.execute_reply.started": "2024-07-06T08:18:55.673644Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_pairs(row):\n",
    "    row['options'] = []  # optionsリストを初期化します\n",
    "    row[\"encode_fail\"] = False  # エンコード失敗フラグを初期化します\n",
    "\n",
    "    try:\n",
    "        # 必要なキーがすべてrow辞書に存在することを確認します\n",
    "        prompts = row['prompt']  # プロンプトを取得します\n",
    "        responses_a = row['response_a']  # 応答Aを取得します\n",
    "        responses_b = row['response_b']  # 応答Bを取得します\n",
    "        \n",
    "        # リストの長さが一致することを確認します\n",
    "        if not (len(prompts) == len(responses_a) == len(responses_b)):\n",
    "            raise ValueError(\"The lists 'prompt', 'response_a', and 'response_b' must be of the same length.\")\n",
    "            # プロンプト、応答A、および応答Bのリストが同じ長さである必要があります\n",
    "            \n",
    "        response_a_str = ''\n",
    "        response_b_str = ''\n",
    "        \n",
    "        for idx in range(len(prompts)):\n",
    "            response_a_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_a[idx]}\"\n",
    "            response_b_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_b[idx]}\"\n",
    "        \n",
    "        # テキストのクリーニング、たとえば、認識できないUnicode文字を除去または置き換えます\n",
    "        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_a_str))  # ASCII文字のみを残します\n",
    "        clean_response_b_str = \"\".join(filter(lambda x: ord(x) < 128, response_b_str))  # ASCII文字のみを残します\n",
    "        \n",
    "        row['options'].append(clean_response_a_str)  # クリーンされた応答Aをoptionsリストに追加\n",
    "        row['options'].append(clean_response_b_str)  # クリーンされた応答Bをoptionsリストに追加\n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in row: {e}\")  # 指定されたキーが見つからない場合のエラーメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except ValueError as e:\n",
    "        print(e)  # 値エラーの場合のメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "    except Exception as e:\n",
    "        # その他すべての例外をキャッチ\n",
    "        print(f\"An unexpected error occurred: {e}\")  # 予期しないエラーのメッセージ\n",
    "        row[\"encode_fail\"] = True  # エンコード失敗フラグを立てる\n",
    "\n",
    "    return row  # 処理された行を返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-06T08:18:55.68493Z",
     "iopub.status.busy": "2024-07-06T08:18:55.684564Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.apply(make_pairs, axis=1)  # 各行に対してmake_pairs関数を適用します\n",
    "display(df.head(2))  # トレーニングデータフレームの最初の2行を表示します\n",
    "\n",
    "test_df = test_df.apply(make_pairs, axis=1)  # テストデータフレームの各行にも同様にmake_pairs関数を適用します\n",
    "display(test_df.head(2))  # テストデータフレームの最初の2行を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075d9084",
   "metadata": {},
   "source": [
    "## エンコーディング失敗の統計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.encode_fail.value_counts(normalize=False)  # エンコーディング失敗フラグのカウントを表示します（正規化せず）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea074f8",
   "metadata": {},
   "source": [
    "# EDA（探索的データ分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameStatsProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df  # 初期化時にデータフレームを設定します\n",
    "\n",
    "    def _is_empty(self, string: str) -> bool:\n",
    "        return bool(re.match(\"^\\s*$\", string))  # 文字列が空かどうかを判断します\n",
    "\n",
    "    def _len(self, string: str) -> int:\n",
    "        if string is None:\n",
    "            return 0  # Noneの場合は長さ0を返します\n",
    "        return len(string)  # 文字列の長さを返します\n",
    "\n",
    "    def _add_len_stats(self, col: str) -> pd.DataFrame:\n",
    "        if col == \"prompt\":\n",
    "            col_prefix = \"p_len\"  # プロンプトの列接頭辞\n",
    "        elif col == \"response_a\":\n",
    "            col_prefix = \"res_a_len\"  # 応答Aの列接頭辞\n",
    "        elif col == \"response_b\":\n",
    "            col_prefix = \"res_b_len\"  # 応答Bの列接頭辞\n",
    "        \n",
    "        # 各長さの統計を計算\n",
    "        self.df[f\"{col_prefix}_sum\"] = self.df[col].apply(lambda x: sum(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_mean\"] =  self.df[col].apply(lambda x: np.mean(list(self._len(s) for s in x)))\n",
    "        self.df[f\"{col_prefix}_max\"] = self.df[col].apply(lambda x: max(self._len(s) for s in x))\n",
    "        self.df[f\"{col_prefix}_sum_log\"] = np.log1p(self.df[f\"{col_prefix}_sum\"])\n",
    "        self.df[f\"{col_prefix}_mean_log\"] =  np.log1p(self.df[f\"{col_prefix}_mean\"])\n",
    "        self.df[f\"{col_prefix}_max_log\"] = np.log1p(self.df[f\"{col_prefix}_max\"])\n",
    "        \n",
    "        return self.df  # 更新されたデータフレームを返します\n",
    "    \n",
    "    def z_score_normalize(self, columns):\n",
    "        \"\"\"\n",
    "        指定した列にZスコア正規化を適用します。\n",
    "        パラメータ:\n",
    "            columns (list): Zスコア正規化を実施する列名のリスト。\n",
    "        \"\"\"\n",
    "        for col in columns:\n",
    "            self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()  # Zスコア正規化を実施します\n",
    "    \n",
    "    def process_dataframe(self):\n",
    "        # データフレームの処理を実施します\n",
    "        self.df[\"n_prompts\"] = self.df[\"prompt\"].apply(lambda x: len(x))  # プロンプトの数を数えます\n",
    "        self.df[\"n_res_a\"] = self.df[\"response_a\"].apply(lambda x: len(x))  # 応答Aの数を数えます\n",
    "        self.df[\"n_res_b\"] = self.df[\"response_b\"].apply(lambda x: len(x))  # 応答Bの数を数えます\n",
    "        assert ((self.df[\"n_prompts\"] == self.df[\"n_res_a\"]) & (self.df[\"n_prompts\"] == self.df[\"n_res_b\"])).all()  # 数が一致することを確認します\n",
    "\n",
    "        # プロンプトと応答の欠損値や空の値をカウントします\n",
    "        self.df[\"n_na_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "        self.df[\"n_na_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n",
    "        self.df[\"n_empty_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n",
    "\n",
    "        # 欠損値の合計を計算します\n",
    "        self.df[\"n_miss_res_a\"] = self.df[\"n_na_res_a\"] + self.df[\"n_empty_res_a\"]\n",
    "        self.df[\"n_miss_res_b\"] = self.df[\"n_na_res_b\"] + self.df[\"n_empty_res_b\"]\n",
    "\n",
    "        # 有効な応答数を計算します\n",
    "        self.df[\"n_eff_res_a\"] = self.df[\"n_res_a\"] - self.df[\"n_miss_res_a\"]\n",
    "        self.df[\"n_eff_res_b\"] = self.df[\"n_res_b\"] - self.df[\"n_miss_res_b\"]\n",
    "\n",
    "        # 長さの統計を追加します\n",
    "        self._add_len_stats(\"prompt\")\n",
    "        self._add_len_stats(\"response_a\")\n",
    "        self._add_len_stats(\"response_b\")\n",
    "\n",
    "        self.df[\"res_len_mean_diff\"] = self.df[\"res_a_len_mean\"] - self.df[\"res_b_len_mean\"]  # 応答AとBの長さの平均の差を計算\n",
    "        self.df[\"res_len_mean_diff_clip\"] = self.df[\"res_len_mean_diff\"].clip(-6000, 6000)  # 差の範囲をクリップします\n",
    "\n",
    "        # プロンプトの欠損値をカウントします\n",
    "        self.df[\"n_miss_prompts\"] = self.df[\"n_na_prompts\"] + self.df[\"n_empty_prompts\"]\n",
    "        self.df[\"n_eff_prompts\"] = self.df[\"n_prompts\"] - self.df[\"n_miss_prompts\"]\n",
    "\n",
    "        # 比率を計算します\n",
    "        self.df[\"na_prompt_ratio\"] = self.df[\"n_na_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"empty_prompt_ratio\"] = self.df[\"n_empty_prompts\"] / self.df[\"n_prompts\"]\n",
    "        self.df[\"miss_prompt_ratio\"] = self.df[\"n_miss_prompts\"] / self.df[\"n_prompts\"]\n",
    "        \n",
    "        self.df[\"na_res_a_ratio\"] = self.df[\"n_na_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"empty_res_a_ratio\"] = self.df[\"n_empty_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"miss_res_a_ratio\"] = self.df[\"n_miss_res_a\"] / self.df[\"n_res_a\"]\n",
    "        self.df[\"na_res_b_ratio\"] = self.df[\"n_na_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"empty_res_b_ratio\"] = self.df[\"n_empty_res_b\"] / self.df[\"n_res_b\"]\n",
    "        self.df[\"miss_res_b_ratio\"] = self.df[\"n_miss_res_b\"] / self.df[\"n_res_b\"]\n",
    "\n",
    "        # 各種長さの統計を追加します\n",
    "        for col, col_prefix in zip([\"prompt\", \"response_a\", \"response_b\"], [\"p_len\", \"res_a_len\", \"res_b_len\"]):\n",
    "            self.df[f\"{col_prefix}_med\"] = self.df[col].apply(lambda x: np.median(list(self._len(s) for s in x)))  # 中央値を計算します\n",
    "            self.df[f\"{col_prefix}_std\"] = self.df[col].apply(lambda x: np.std(list(self._len(s) for s in x)))  # 標準偏差を計算します\n",
    "\n",
    "        # 有効な長さの平均を計算します\n",
    "        self.df[\"p_len_eff_mean\"] = self.df[\"p_len_sum\"] / self.df[\"n_eff_prompts\"]\n",
    "        self.df[\"res_a_len_eff_mean\"] = self.df[\"res_a_len_sum\"] / self.df[\"n_eff_res_a\"]\n",
    "        self.df[\"res_b_len_eff_mean\"] = self.df[\"res_b_len_sum\"] / self.df[\"n_eff_res_b\"]\n",
    "\n",
    "        # 長さの差を計算します\n",
    "        for stats in [\"sum\", \"mean\", \"max\", \"med\", \"eff_mean\"]:\n",
    "            self.df[f\"p_a_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_a_len_{stats}\"]\n",
    "            self.df[f\"p_b_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            self.df[f\"a_b_{stats}_diff\"] = self.df[f\"res_a_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n",
    "            \n",
    "        # 特徴量列を定義します\n",
    "        len_feature_a_col = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                     \"p_a_eff_mean_diff\"]\n",
    "        \n",
    "        len_feature_b_col = [\"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                             \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                             \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        numerical_feature_columns = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n",
    "                                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n",
    "                                     \"p_a_eff_mean_diff\", \"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n",
    "                                     \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n",
    "                                     \"p_b_eff_mean_diff\"]\n",
    "        \n",
    "        # ゼロで割らないように正規化します\n",
    "        for col in numerical_feature_columns:\n",
    "            if self.df[col].std() == 0:\n",
    "                print(f\"Warning: Standard deviation is zero for column {col}. Skipping normalization.\")\n",
    "            else:\n",
    "                self.z_score_normalize([col])  # Zスコア正規化を適用します\n",
    "                \n",
    "        self.df = self.df.fillna(0)  # NaNを0で埋めます\n",
    "        \n",
    "        # 特徴量をリストに変換します\n",
    "        len_features_a = self.df[len_feature_a_col].values.tolist()\n",
    "        len_features_b = self.df[len_feature_b_col].values.tolist()\n",
    "\n",
    "        return len_features_a, len_features_b  # 長さ特徴量を返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e001db",
   "metadata": {},
   "source": [
    "# データ分割\n",
    "\n",
    "以下のコードスニペットでは、class_label列の層化を使用して、既存のデータをトレーニングデータと検証データに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # パッケージをインポートします\n",
    "\n",
    "# データフレームをトレーニングデータ（80%）と検証データ（20%）に分割します\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])  # class_label列をもとに層化分割を行います"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ed54a2",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset,  # 設定されたプリセットを使用して前処理器を作成します\n",
    "    sequence_length=CFG.sequence_length,  # 設定されたシーケンス長を指定します\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None, features_a=None, features_b=None):\n",
    "    text = preprocessor(text)  # テキストを前処理します\n",
    "    if features_a is not None:\n",
    "        text['features_a'] = features_a  # features_aが指定されている場合、テキストに追加します\n",
    "    if features_b is not None:\n",
    "         text['features_b'] = features_b  # features_bが指定されている場合、テキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd68c79",
   "metadata": {},
   "source": [
    "# FGM（Fast Gradient Method）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGMの摂動関数を追加します\n",
    "def fgm_perturb(features, epsilon=1.0):\n",
    "    # 摂動量を計算します。epsilonは摂動の割合です。\n",
    "    perturbation = np.random.uniform(-1, 1, features.shape) * epsilon  # 特徴量の形状に基づいてランダムな摂動を生成します\n",
    "    # 摂動を適用します\n",
    "    return features + perturbation  # 特徴量に摂動を加えたものを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ前処理関数を修正してFGM摂動を含めます\n",
    "def preprocess_fn(text, label=None, features_a=None, features_b=None, is_fgm=False, epsilon=1.0):\n",
    "    # テキストを前処理します\n",
    "    text = preprocessor(text)\n",
    "    if features_a is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_a = fgm_perturb(features_a, epsilon)  # 特徴量AにFGM摂動を加えます\n",
    "        text['features_a'] = features_a  # 特徴量Aをテキストに追加します\n",
    "    if features_b is not None:\n",
    "        if is_fgm:\n",
    "            # FGMの場合、摺動を適用します\n",
    "            features_b = fgm_perturb(features_b, epsilon)  # 特徴量BにFGM摂動を加えます\n",
    "        text['features_b'] = features_b  # 特徴量Bをテキストに追加します\n",
    "    return (text, label) if label is not None else text  # ラベルがあれば、処理されたテキストとラベルを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9a7dbc",
   "metadata": {},
   "source": [
    "# AWP（Adversarial Weight Perturbation）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWP摺動関数を定義します\n",
    "def awp_perturb(model, epsilon=1e-4):\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel'):\n",
    "            # 重みを取得します\n",
    "            weights = layer.kernel\n",
    "            # 摺動を計算します\n",
    "            perturbation = tf.random.normal(weights.shape, stddev=epsilon)  # 標準偏差epsilonの正規分布から摺動を生成します\n",
    "            # 摺動を適用します\n",
    "            layer.kernel.assign_add(perturbation)  # 重みに摺動を加えます\n",
    "\n",
    "# AWPコールバック関数を作成します\n",
    "class AWPCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, epsilon):\n",
    "        super(AWPCallback, self).__init__()  # 親クラスの初期化\n",
    "        self.epsilon = epsilon  # 摺動の値を保存します\n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # 各バッチの開始時にAWP摺動を適用します\n",
    "        awp_perturb(self.model, self.epsilon)  # モデルにAWP摺動を加えます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b03ad44",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "以下のコードは、tf.data.Datasetを使用してデータ処理のための堅牢なデータフロー・パイプラインを設定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def build_dataset_with_features(texts, labels=None, features_a=None, features_b=None, batch_size=32, is_fgm=False,  epsilon=1.0,\n",
    "                                cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # 自動調整を有効にします\n",
    "    if (features_a is not None) and (features_b is not None):\n",
    "        # ラベルがない場合はテキストと特徴量のみ、ある場合はラベルも追加します\n",
    "        slices = (texts, None, features_a, features_b) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3), features_a, features_b)  # スライスを作成します\n",
    "    else:\n",
    "        slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # スライスを作成します\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # テンソルのスライスからデータセットを生成します\n",
    "    ds = ds.cache() if cache else ds  # キャッシュを使用するかどうかを設定します\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # 前処理関数を各要素に適用します\n",
    "#     ds = ds.map(lambda x: preprocess_fn(x, features_a=features_a, features_b=features_b, is_fgm=is_fgm, epsilon=epsilon),\n",
    "#                 num_parallel_calls=tf.data.AUTOTUNE)  # (コメントアウトされたコード)摺動を考慮した前処理\n",
    "    opt = tf.data.Options()\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # シャッフルを有効にします\n",
    "        opt.experimental_deterministic = False  # 結果の非決定性を許可します\n",
    "    ds = ds.with_options(opt)  # オプションを適用します\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # バッチに分けます\n",
    "    ds = ds.prefetch(AUTO)  # プリフェッチを使用してデータを事前に読み込む\n",
    "\n",
    "    return ds  # データセットを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa4066b",
   "metadata": {},
   "source": [
    "## トレーニング/検証データローダーの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_processor = DataFrameStatsProcessor(train_df.copy())  # トレーニングデータフレームのコピーを使用して特徴量処理器を作成します\n",
    "train_features_a, train_features_b = train_features_processor.process_dataframe()  # トレーニングデータの特徴量を処理します\n",
    "valid_features_processor = DataFrameStatsProcessor(valid_df.copy())  # 検証データフレームのコピーを使用して特徴量処理器を作成します\n",
    "valid_features_a, valid_features_b = valid_features_processor.process_dataframe()  # 検証データの特徴量を処理します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "# トレーニングデータの準備\n",
    "train_texts = train_df.options.tolist()  # トレーニングデータのテキストをリストに変換します\n",
    "train_labels = train_df.class_label.tolist()  # トレーニングデータのラベルをリストに変換します\n",
    "train_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=True)  # シャッフルを有効にします\n",
    "\n",
    "# 検証データの準備\n",
    "valid_texts = valid_df.options.tolist()  # 検証データのテキストをリストに変換します\n",
    "valid_labels = valid_df.class_label.tolist()  # 検証データのラベルをリストに変換します\n",
    "valid_ds = build_dataset_with_features(valid_texts, valid_labels, valid_features_a, valid_features_b, \n",
    "                         batch_size=CFG.batch_size,  # 設定されたバッチサイズを使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(train_ds)  # トレーニングデータセットの情報を表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893b7e0",
   "metadata": {},
   "source": [
    "# 学習率スケジュール\n",
    "\n",
    "学習率スケジューラの実装は、転移学習において重要です。\n",
    "\n",
    "学習率は、lr_startから始まり、さまざまな手法を使用してlr_minまで徐々に減少します。これには以下が含まれます：\n",
    "\n",
    "- step：階段状に学習率を段階的に減少させます。\n",
    "- cos：コサイン曲線を利用して学習率を徐々に減少させます。\n",
    "- exp：指数関数的に学習率を減少させます。\n",
    "\n",
    "**重要性**：適切に構造化された学習率スケジュールは、モデルの効果的なトレーニングに不可欠であり、最適な収束を保証し、オーバーシュートや停滞などの問題を回避します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # 学習率の開始値、最大値、最小値を設定します\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # 学習率のランプアップエポック、持続エポック、減衰率を設定します\n",
    "\n",
    "    def lrfn(epoch):  # 学習率更新関数\n",
    "        # エポックに応じて学習率を計算します\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ランプアップ段階\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # 最大学習率を維持します\n",
    "        elif mode == 'exp:': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # 指数的減衰\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ステップ減衰\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # コサインの位相を計算します\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min  # コサイン曲線による減衰\n",
    "        return lr  # 計算された学習率を返します\n",
    "    \n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # 学習率コールバックを作成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cb = get_lr_callback(CFG.batch_size, epochs=CFG.epochs)  # 設定されたバッチサイズとエポック数で学習率コールバックを取得します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80186ba6",
   "metadata": {},
   "source": [
    "# モデルチェックポイント\n",
    "\n",
    "以下のコードは、トレーニング中にモデルの最良のチェックポイントを保存するコールバックを作成します。これは、提出時の推論に使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # 検証ロスを監視します\n",
    "                                          save_best_only=True,  # 最良のモデルのみを保存します\n",
    "                                          save_weights_only=True,  # 重みのみを保存します\n",
    "                                          mode='min')  # 最小化モードで監視します（ロスが最小のときに保存）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef402a",
   "metadata": {},
   "source": [
    "# メトリック\n",
    "\n",
    "今回のコンペティションの評価指標は対数損失です。この尺度は数学的に次のように表されます：\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\", label_smoothing=0.1, from_logits=False)  # 対数損失を計算するためのメトリックを定義します。ラベルスムージングを適用します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf286f2",
   "metadata": {},
   "source": [
    "# モデリング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # すべての入力層を辞書にまとめます\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),  # トークンIDの入力\n",
    "        \"padding_mask\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),  # パディングマスクの入力\n",
    "        \"features_a\": keras.layers.Input(shape=(14,), name=\"features_a\", dtype=tf.float32),  # 特徴量Aの入力\n",
    "        \"features_b\": keras.layers.Input(shape=(14,), name=\"features_b\", dtype=tf.float32),  # 特徴量Bの入力\n",
    "    }\n",
    "\n",
    "    # DebertaV3Classifierバックボーンを作成します\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "        CFG.preset,\n",
    "    )\n",
    "\n",
    "    # response_aとresponse_bの作成方法を修正し、padding_maskを含めます\n",
    "    response_a = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 0, :],  # 最初のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 0, :]  # 最初のパディングマスクを取得\n",
    "    }\n",
    "    embed_a = backbone(response_a)  # バックボーンを通して埋め込みを取得します\n",
    "\n",
    "    response_b = {\n",
    "        \"token_ids\": inputs[\"token_ids\"][:, 1, :],  # 2番目のトークンIDを取得\n",
    "        \"padding_mask\": inputs[\"padding_mask\"][:, 1, :]  # 2番目のパディングマスクを取得\n",
    "    }\n",
    "    embed_b = backbone(response_b)  # バックボーンを通して埋め込みを取得します\n",
    "    \n",
    "    # 数値特徴を埋め込みます\n",
    "    len_features_a_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_a\"])  # 特徴量Aの数値埋め込み\n",
    "    len_features_b_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_b\"])  # 特徴量Bの数値埋め込み\n",
    "    \n",
    "    # Flatten層を使用して数値特徴埋め込みを2次元テンソルに展開します\n",
    "    flattened_len_features_a = keras.layers.Flatten()(len_features_a_embedding)  # Flattenによる変換\n",
    "    flattened_len_features_b = keras.layers.Flatten()(len_features_b_embedding)  # Flattenによる変換\n",
    "    \n",
    "    embed_a = keras.layers.GlobalAveragePooling1D()(embed_a)  # グローバル平均プーリング\n",
    "    embed_b = keras.layers.GlobalAveragePooling1D()(embed_b)  # グローバル平均プーリング\n",
    "    embeds_text_features_a = keras.layers.Concatenate(axis=-1)([embed_a, flattened_len_features_a])  # テキスト埋め込みと数値特徴を結合\n",
    "    embeds_text_features_b = keras.layers.Concatenate(axis=-1)([embed_b, flattened_len_features_b])  # テキスト埋め込みと数値特徴を結合\n",
    "    \n",
    "    # テキスト埋め込みと数値特徴埋め込みを結合します\n",
    "    combined_embeds = keras.layers.Concatenate(axis=-1)([embeds_text_features_a, embeds_text_features_b])  # テキストと特徴を結合\n",
    "    \n",
    "    # モデルにL2正則化とDropoutを追加します\n",
    "    combined_embeds = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(combined_embeds)  # L2正則化\n",
    "    combined_embeds = Dropout(0.05)(combined_embeds)  # Dropoutレイヤー、5%のニューロンをドロップ\n",
    "    \n",
    "    # 温度スケール関数を定義します\n",
    "    def temperature_scale(logits, T=1.0):\n",
    "        return logits / T  # ロジットを温度で割ります\n",
    "    \n",
    "    # 温度パラメータTを定義します\n",
    "    T = 0.85\n",
    "    # 温度スケーリングを適用します\n",
    "    scaled_logits = temperature_scale(combined_embeds, T)  # 温度スケールを適用したロジット\n",
    "    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(scaled_logits)  # 出力層を定義します\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)  # モデルを作成します\n",
    "    \n",
    "    # オプティマイザ、損失、メトリックでモデルをコンパイルします\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-6, clipnorm=1.0),  # Adamオプティマイザを使用\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1, from_logits=False),  # カテゴリカルクロスエントロピー損失\n",
    "        metrics=[\n",
    "            log_loss,  # 定義した対数損失\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),  # 精度メトリック\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    # AWPコールバックをモデルのトレーニングに追加します\n",
    "    awp_cb = AWPCallback(epsilon=1e-4)  # epsilon値は必要に応じて調整できます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6658a4fe",
   "metadata": {},
   "source": [
    "### モデルの概要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "model.summary()  # モデルのサマリーを表示します。各層の出力形状やパラメータ数を確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b56cd3",
   "metadata": {},
   "source": [
    "# トレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# tryブロック内でエラー処理を実装します\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,  # トレーニングデータセット\n",
    "        epochs=CFG.epochs,  # 設定されたエポック数で学習\n",
    "        validation_data=valid_ds,  # 検証データセット\n",
    "        callbacks=[lr_cb, ckpt_cb, awp_cb]  # 学習率コールバック、チェックポイントコールバック、AWPコールバックを追加\n",
    "    )\n",
    "except tf.errors.InvalidArgumentError as e:\n",
    "    print(f\"無効な引数エラーが発生しました：{e}\")  # エラーが発生した場合、そのメッセージを表示します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb8606",
   "metadata": {},
   "source": [
    "## 最良モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('/kaggle/working/best_model.weights.h5')  # 最良モデルの重みを読み込みます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070811c7",
   "metadata": {},
   "source": [
    "# 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGM摺動を使用したデータセットでモデルを評価します\n",
    "fgm_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b,\n",
    "                                     is_fgm=True, epsilon=1.0)  # FGMを使用してデータセットを構築します\n",
    "evaluation_results = model.evaluate(fgm_ds)  # 評価を実行します\n",
    "\n",
    "print(f\"FGM摺動データセットの評価結果: {evaluation_results}\")  # FGM摺動データセットでの評価結果を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_features_processor = DataFrameStatsProcessor(test_df)  # テストデータフレームの特徴量処理器を作成します\n",
    "test_df_features_a, test_df_features_b = test_df_features_processor.process_dataframe()  # テストデータの特徴量を処理します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = test_df.options.tolist()  # テストデータのテキストをリストに変換します\n",
    "test_ds = build_dataset_with_features(test_texts, features_a=test_df_features_a, features_b=test_df_features_b,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),  # テストデータの長さと設定されたバッチサイズの最小値を使用します\n",
    "                         shuffle=False)  # シャッフルを無効にします\n",
    "print(test_ds)  # テストデータセットの情報を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_ds, verbose=1)  # テストデータセットに対してモデルの予測を実行します。進捗を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e9062",
   "metadata": {},
   "source": [
    "# 提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_df[[\"id\"]].copy()  # テストデータから'id'列をコピーします\n",
    "sub_df[CFG.class_names] = test_preds.tolist()  # 予測結果をコピーして新しいデータフレームに追加します\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # 提出用ファイルをCSV形式で保存します\n",
    "sub_df.head()  # 提出データフレームの先頭を表示します"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5306138,
     "sourceId": 8820093,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5310688,
     "sourceId": 8826860,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5310716,
     "sourceId": 8826894,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
