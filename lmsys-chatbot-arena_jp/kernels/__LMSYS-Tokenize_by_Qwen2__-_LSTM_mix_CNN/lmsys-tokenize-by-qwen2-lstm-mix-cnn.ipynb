{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b499a9f7",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、大規模言語モデル（LLM）を利用して、ユーザーからのプロンプトに対する2つの異なる応答モデルのどちらが好まれるかを予測する問題に取り組んでいます。競技はKaggleの「LMSYS - Chatbot Arena」コンペティションの一環であり、具体的にはユーザーの好みに基づく会話システムを改善するための機械学習モデルの開発が目指されています。\n",
    "\n",
    "### 使用する手法とライブラリ\n",
    "ノートブックでは、次のような手法とライブラリが使用されています：\n",
    "\n",
    "1. **ライブラリのインポート**:\n",
    "   - 主に`numpy`, `pandas`, `torch`, `transformers`, `sklearn`, `keras`などのライブラリを使用して、データの処理、モデルの構築、トレーニングを行っています。\n",
    "\n",
    "2. **トークナイザー**:\n",
    "   - `transformers` ライブラリの `AutoTokenizer` を用い、テキストデータをトークン化します。特に、Qwen2のトークナイザーを使用し、入力シーケンスの最大長やパディングトークンの設定を行います。\n",
    "\n",
    "3. **データ処理**:\n",
    "   - トレーニングデータの前処理として、プロンプトと応答のクリーンアップを行い、さらにテキストを結合してモデルの入力用データを準備します。\n",
    "\n",
    "4. **モデルの構築**:\n",
    "   - CNN（畳み込みニューラルネットワーク）とLSTM（長短期記憶ネットワーク）のハイブリッドモデルを作成します。このモデルは、テキストの埋め込みを用いて、アテンションマスクを考慮した上での分類を行います。\n",
    "\n",
    "5. **トレーニングと評価**:\n",
    "   - モデルを訓練する際に、早期停止やモデルチェックポイントを使用して最適なパフォーマンスを保証します。訓練データを用いてモデルをトレーニングし、バリデーションデータで評価します。\n",
    "\n",
    "6. **予測**:\n",
    "   - テストデータに対してモデルを適用し、それぞれの応答モデルの勝者を予測します。最終的には、結果をCSVファイルとして出力します。\n",
    "\n",
    "ノートブックの結論部分では、さらなるデータの追加や異なるハイパーパラメータの調整によってモデルの最適化の余地があることが示唆されています。全体として、ユーザーの好みを反映した会話生成モデルの構築に向けた包括的なアプローチが取られています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b8cc43",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebook内で使用されている専門用語の解説です。マイナーなものや実務経験のないと馴染みのない用語に焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **トークナイザー (Tokenizer)**\n",
    "   - テキストをモデルが理解できる形式に変換するためのプロセス。具体的には、文字列を単語やサブワードの単位（トークン）に分割し、それぞれに整数IDを割り当てる役割を持つ。\n",
    "\n",
    "2. **EOSトークン (End of Sequence Token)**\n",
    "   - シーケンス（テキスト）の終わりを示す特別なトークン。モデルが、入力が終了したことを認識できるようにするために使用される。\n",
    "\n",
    "3. **アテンションマスク (Attention Mask)**\n",
    "   - モデルが特定の入力部分に注意を集中できるようにするためのマスク。この値は、入力の中でパディングされている部分を無視するために使用される。通常は1（注意を向ける）または0（無視する）の値を持つ。\n",
    "\n",
    "4. **トークンの長さ (Token Length)**\n",
    "   - テキスト内のトークンの数。トークンの長さはモデルの入力制限に影響を与え、長すぎる場合は切り捨てられることがある。\n",
    "\n",
    "5. **フィルター数 (Number of Filters)**\n",
    "   - 畳み込み層において、フィルター（カーネル）の数。各フィルターは入力データから異なる特徴を抽出する役割を持つ。フィルター数が多いほど、モデルの表現力が増すが、計算負荷も増加する。\n",
    "\n",
    "6. **カーネルサイズ (Kernel Size)**\n",
    "   - 畳み込みに使用されるフィルターのサイズ。特に1次元畳み込み層（Convolution1D）において、入力シーケンスのいくつの連続した要素を同時に見るかを示す。\n",
    "\n",
    "7. **GlobalMaxPooling1D**\n",
    "   - 1次元での最大プーリング層。特定の特徴マップ内の最大値を抽出し、次の層に縮小された特徴を供給する。長さの異なるシーケンスを統一する際に用いられる。\n",
    "\n",
    "8. **ドロップアウト (Dropout)**\n",
    "   - 過学習を防ぐための正則化手法。トレーニング中にランダムにニューロン（隠れ層のユニット）を無効化することで、モデルの汎用性を向上させる。\n",
    "\n",
    "9. **アーリーストッピング (Early Stopping)**\n",
    "   - バリデーションデータの損失が一定期間改善されない場合にトレーニングを早期に終了させる技術。過学習を防ぐためによく用いられる。\n",
    "\n",
    "10. **アダデルタ (Adadelta)**\n",
    "    - 学習率を適応的に調整する最適化アルゴリズムの一つ。過去の勾配に基づいて学習率を調整することにより、より安定したトレーニングを実現する。\n",
    "\n",
    "11. **アダマックス (Adamax)**\n",
    "    - Adamアルゴリズムの変種で、L1正則化が存在する場合に有効。特に大きな勾配を含むデータセットに対して安定した性能を発揮することができる。\n",
    "\n",
    "12. **LSTM (Long Short-Term Memory)**\n",
    "    - 隠れ層内にメモリセルを持つ特殊なリカレントニューラルネットワーク（RNN）の形式。長期依存関係を持つシーケンスデータの学習に特化している。\n",
    "\n",
    "13. **マルチチャネルモデル (Multi-channel Model)**\n",
    "    - 異なるタイプのデータやフィルターを同時に処理するために設計されたモデル。例えば、異なるサイズの畳み込みフィルターを使用して異なる特徴を捉えることができる。\n",
    "\n",
    "これらの用語は、Notebookの操作や理解に役立つ背景知識として、特に実務経験の少ない初心者にとって重要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb946d67",
   "metadata": {},
   "source": [
    "# ライブラリのインポート\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:16.158729Z",
     "iopub.status.busy": "2024-07-21T15:14:16.15847Z",
     "iopub.status.idle": "2024-07-21T15:14:24.595436Z",
     "shell.execute_reply": "2024-07-21T15:14:24.594472Z",
     "shell.execute_reply.started": "2024-07-21T15:14:16.158705Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "from time import time\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification, AutoModel\n",
    "import torch.nn.functional as F\n",
    "np.random.seed(1337)  # 乱数のシードを1337に設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fe358",
   "metadata": {},
   "source": [
    "# トークナイザー\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:24.598181Z",
     "iopub.status.busy": "2024-07-21T15:14:24.597373Z",
     "iopub.status.idle": "2024-07-21T15:14:31.080351Z",
     "shell.execute_reply": "2024-07-21T15:14:31.079306Z",
     "shell.execute_reply.started": "2024-07-21T15:14:24.598145Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen2-7B-Instruct\")\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンをEOSトークンに設定\n",
    "tokenizer.padding_side = 'right'  # パディングを右側に設定\n",
    "tokenizer.add_eos_token = True  # EOSトークンを追加\n",
    "\n",
    "# 推論時にオフラインでトークナイザーを読み込むために保存\n",
    "tokenizer.save_pretrained('tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:31.082086Z",
     "iopub.status.busy": "2024-07-21T15:14:31.081766Z",
     "iopub.status.idle": "2024-07-21T15:14:31.087211Z",
     "shell.execute_reply": "2024-07-21T15:14:31.086151Z",
     "shell.execute_reply.started": "2024-07-21T15:14:31.082061Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークンの長さを取得するユーティリティ関数\n",
    "def get_token_lengths(texts):\n",
    "    # テキストごとにトークン化し、input_idsを取得\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # 各テキストのinput_idsの長さを返す\n",
    "    return [len(t) for t in input_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835efcc6",
   "metadata": {},
   "source": [
    "# トレーニングデータの準備\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:31.090449Z",
     "iopub.status.busy": "2024-07-21T15:14:31.08983Z",
     "iopub.status.idle": "2024-07-21T15:14:34.574896Z",
     "shell.execute_reply": "2024-07-21T15:14:34.57383Z",
     "shell.execute_reply.started": "2024-07-21T15:14:31.090424Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込む\n",
    "\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 文字列からブラケットを削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文を分割してクオートを削除\n",
    "    return  ' '.join(sentences)  # 文をスペースで結合して返す\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # プロンプトを処理\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # モデルAの応答を処理\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # モデルBの応答を処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.576524Z",
     "iopub.status.busy": "2024-07-21T15:14:34.576147Z",
     "iopub.status.idle": "2024-07-21T15:14:34.594077Z",
     "shell.execute_reply": "2024-07-21T15:14:34.593208Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.576491Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(5)  # データフレームの先頭5行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.595496Z",
     "iopub.status.busy": "2024-07-21T15:14:34.595223Z",
     "iopub.status.idle": "2024-07-21T15:14:34.863738Z",
     "shell.execute_reply": "2024-07-21T15:14:34.862784Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.595473Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = 'User prompt: ' + train['prompt'] +  '\\n\\nModel A :\\n' + train['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(train['text'][4])  # 4番目のテキストを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:14:34.865029Z",
     "iopub.status.busy": "2024-07-21T15:14:34.864747Z",
     "iopub.status.idle": "2024-07-21T15:15:42.052187Z",
     "shell.execute_reply": "2024-07-21T15:15:42.051287Z",
     "shell.execute_reply.started": "2024-07-21T15:14:34.865005Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータセットの50％のみを使用\n",
    "train = train[:int(len(train) * 1)]\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # 各テキストのトークン数を取得\n",
    "\n",
    "# モデル用のラベルを準備\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a','winner_model_b','winner_tie']].values, axis=1)\n",
    "\n",
    "# データを表示\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.053765Z",
     "iopub.status.busy": "2024-07-21T15:15:42.05349Z",
     "iopub.status.idle": "2024-07-21T15:15:42.066714Z",
     "shell.execute_reply": "2024-07-21T15:15:42.065847Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.05374Z"
    }
   },
   "outputs": [],
   "source": [
    "train.label.value_counts()  # 各ラベルのカウントを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.068273Z",
     "iopub.status.busy": "2024-07-21T15:15:42.067931Z",
     "iopub.status.idle": "2024-07-21T15:15:42.090686Z",
     "shell.execute_reply": "2024-07-21T15:15:42.089936Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.06825Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークンのカウントの要約表示\n",
    "display(train['token_count'].describe().to_frame().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.091911Z",
     "iopub.status.busy": "2024-07-21T15:15:42.091646Z",
     "iopub.status.idle": "2024-07-21T15:15:42.098523Z",
     "shell.execute_reply": "2024-07-21T15:15:42.097554Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.091869Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの90%をカバーするトークンの長さを取得。ここでは1024の長さを使用します！\n",
    "np.percentile(train['token_count'], 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc441ed9",
   "metadata": {},
   "source": [
    "# トークン化\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:15:42.102475Z",
     "iopub.status.busy": "2024-07-21T15:15:42.102219Z",
     "iopub.status.idle": "2024-07-21T15:16:44.236123Z",
     "shell.execute_reply": "2024-07-21T15:16:44.235128Z",
     "shell.execute_reply.started": "2024-07-21T15:15:42.102454Z"
    }
   },
   "outputs": [],
   "source": [
    "# データをトークン化\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')  # numpy配列として返す\n",
    "\n",
    "# INPUT_IDSはトークンIDです\n",
    "INPUT_IDS = tokens['input_ids']\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS = tokens['attention_mask']\n",
    "# テキストのラベル\n",
    "LABELS = train[['winner_model_a','winner_model_b','winner_tie']].values\n",
    "\n",
    "print(f'INPUT_IDSの形状: {INPUT_IDS.shape}, ATTENTION_MASKSの形状: {ATTENTION_MASKS.shape}')  # 形状を表示\n",
    "print(f'LABELSの形状: {LABELS.shape}')  # ラベルの形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:44.237864Z",
     "iopub.status.busy": "2024-07-21T15:16:44.237471Z",
     "iopub.status.idle": "2024-07-21T15:16:44.243414Z",
     "shell.execute_reply": "2024-07-21T15:16:44.242354Z",
     "shell.execute_reply.started": "2024-07-21T15:16:44.237829Z"
    }
   },
   "outputs": [],
   "source": [
    "max_features = 14300  # 最大特徴量数\n",
    "maxlen = 1024  # 最大トークン数\n",
    "batch_size = 16  # バッチサイズ\n",
    "embedding_dims = 100  # 埋め込み次元数\n",
    "nb_filter = 150  # フィルター数\n",
    "filter_length = 3  # フィルターの長さ\n",
    "hidden_dims = 100  # 隠れ層の次元数\n",
    "nb_epoch = 100  # エポック数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:44.244999Z",
     "iopub.status.busy": "2024-07-21T15:16:44.244645Z",
     "iopub.status.idle": "2024-07-21T15:16:54.727089Z",
     "shell.execute_reply": "2024-07-21T15:16:54.726245Z",
     "shell.execute_reply.started": "2024-07-21T15:16:44.244975Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Convolution1D, LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adadelta,Adamax\n",
    "from keras.preprocessing import sequence as sq\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda,Input,TimeDistributed,Flatten\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from tensorflow.python.keras.backend import set_session as K\n",
    "num_samples = INPUT_IDS.shape[0]  # サンプル数を取得\n",
    "\n",
    "# X_validのサンプル数（X_trainの20%）\n",
    "num_valid_samples = int(num_samples * 0.2)\n",
    "\n",
    "# X_trainのインデックスをシャッフル\n",
    "indices = np.random.permutation(num_samples)\n",
    "\n",
    "# 最初の20%のインデックスをX_validのインデックスとして選択\n",
    "valid_indices = indices[:num_valid_samples]\n",
    "\n",
    "# 残りのインデックスをX_trainのインデックスとして選択\n",
    "train_indices = indices[num_valid_samples:]\n",
    "\n",
    "# 選ばれたインデックスから新しいX_validとX_trainを作成\n",
    "X_train = sq.pad_sequences(INPUT_IDS[train_indices], maxlen=maxlen)  # パディングを適用\n",
    "X_train_attention = sq.pad_sequences(ATTENTION_MASKS[train_indices], maxlen=maxlen)  # アテンションマスクにもパディングを適用\n",
    "y_train = LABELS[train_indices]  # トレーニングラベル\n",
    "\n",
    "X_valid = sq.pad_sequences(INPUT_IDS[valid_indices], maxlen=maxlen)  # バリデーションデータのパディング\n",
    "X_valid_attention = sq.pad_sequences(ATTENTION_MASKS[valid_indices], maxlen=maxlen)  # バリデーションアテンションマスクのパディング\n",
    "y_valid = LABELS[valid_indices]  # バリデーションラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:54.728506Z",
     "iopub.status.busy": "2024-07-21T15:16:54.728212Z",
     "iopub.status.idle": "2024-07-21T15:16:54.820841Z",
     "shell.execute_reply": "2024-07-21T15:16:54.820075Z",
     "shell.execute_reply.started": "2024-07-21T15:16:54.728481Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)  # X_trainをnumpy配列に変換\n",
    "y_train = np.array(y_train)  # y_trainをnumpy配列に変換\n",
    "X_valid = np.array(X_valid)  # X_validをnumpy配列に変換\n",
    "y_valid = np.array(y_valid)  # y_validをnumpy配列に変換"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8062651a",
   "metadata": {},
   "source": [
    "# モデルの定義\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:54.822449Z",
     "iopub.status.busy": "2024-07-21T15:16:54.822147Z",
     "iopub.status.idle": "2024-07-21T15:16:56.077159Z",
     "shell.execute_reply": "2024-07-21T15:16:56.076243Z",
     "shell.execute_reply.started": "2024-07-21T15:16:54.822425Z"
    }
   },
   "outputs": [],
   "source": [
    "'''この例は、テキスト分類におけるConvolution1Dの使用を示しています。\n",
    "2エポック後にテスト精度は0.88に達します。\n",
    "Intel i5 2.4GHz CPUで90秒/エポック。\n",
    "Tesla K40 GPUで10秒/エポック。\n",
    "'''\n",
    "from tensorflow.keras.layers import Layer\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import  GlobalMaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "#config = K.tf.ConfigProto(intra_op_parallelism_threads=16, inter_op_parallelism_threads=16, \\\n",
    "#                        allow_soft_placement=True, device_count = {'CPU': 1})\n",
    "\n",
    "# tf_config = K.tf.ConfigProto()\n",
    "# tf_config.gpu_options.allow_growth = True\n",
    "# session = K.tf.Session(config=tf_config)\n",
    "# K.set_session(session)\n",
    "\n",
    "# config = K.tf.ConfigProto(intra_op_parallelism_threads=4, inter_op_parallelism_threads=4, \\\n",
    "#                         allow_soft_placement=True, device_count = {'CPU': 4})\n",
    "# session = K.tf.Session(config=config)\n",
    "# K.set_session(session)\n",
    "\n",
    "class ApplyAttentionMask(Layer):\n",
    "    def call(self, inputs):\n",
    "        embeddings, attention_mask = inputs  # 入力から埋め込みとアテンションマスクを取得\n",
    "        return embeddings * tf.expand_dims(attention_mask, -1)  # アテンションマスクを使用して埋め込みを適用\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "input_layer = Input(shape=(maxlen,),dtype='int32', name='main_input')  # 入力層を定義\n",
    "attention_masks = Input(shape=(maxlen,), dtype='float32', name=\"attention_masks\")  # アテンションマスクの入力層\n",
    "\n",
    "emb_layer = Embedding(max_features,\n",
    "                      embedding_dims,\n",
    "                      input_length=maxlen\n",
    "                      )(input_layer)  # 埋め込み層\n",
    "\n",
    "masked_embeddings = ApplyAttentionMask(name='apply_attention_mask')([emb_layer, attention_masks])  # アテンションマスクを適用\n",
    "\n",
    "def max_1d(X):\n",
    "    return K.max(X, axis=1)  # 1Dの最大値を取得する関数\n",
    "\n",
    "# 3のサイズのフィルターを持つConvolution1Dを追加\n",
    "con3_layer = Convolution1D(filters=nb_filter,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    kernel_size =3,\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con3_layer = GlobalMaxPooling1D()(con3_layer)  # 最大プーリング\n",
    "\n",
    "# 4のサイズのフィルターを持つConvolution1Dを追加\n",
    "con4_layer = Convolution1D(filters=nb_filter,\n",
    "                    kernel_size=5,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con4_layer = GlobalMaxPooling1D()(con4_layer)  # 最大プーリング\n",
    "\n",
    "# 5のサイズのフィルターを持つConvolution1Dを追加\n",
    "con5_layer = Convolution1D(filters=nb_filter,\n",
    "                    kernel_size=7,\n",
    "                    padding='valid',\n",
    "                    activation='relu',\n",
    "                    strides=1)(masked_embeddings)\n",
    "\n",
    "pool_con5_layer = GlobalMaxPooling1D()(con5_layer)  # 最大プーリング\n",
    "\n",
    "cnn_layer = Concatenate()([pool_con3_layer, pool_con5_layer, pool_con4_layer])  # CNNの出力を結合\n",
    "\n",
    "# LSTM層を追加\n",
    "x = masked_embeddings\n",
    "lstm_layer = LSTM(128)(x)\n",
    "\n",
    "cnn_lstm_layer = Concatenate()([lstm_layer, cnn_layer])  # LSTMとCNNの出力を結合\n",
    "\n",
    "dense_layer = Dense(hidden_dims*2, activation='sigmoid')(cnn_lstm_layer)  # 隠れ層を追加\n",
    "output_layer= Dropout(0.2)(dense_layer)  # ドロップアウトを追加\n",
    "output_layer = Dense(3, trainable=True, activation='softmax')(output_layer)  # 出力層を定義\n",
    "\n",
    "model = Model(inputs=[input_layer, attention_masks], outputs=[output_layer])  # モデルを定義\n",
    "adadelta = Adadelta(learning_rate=1.0, rho=0.75, epsilon=1e-06)  # 最適化アルゴリズムを定義\n",
    "adamax = Adamax(learning_rate=0.001)  # 別の最適化アルゴリズムを定義\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])  # モデルをコンパイル\n",
    "model.summary()  # モデルの概要を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f7aeec",
   "metadata": {},
   "source": [
    "# モデルのトレーニング\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T15:16:56.078492Z",
     "iopub.status.busy": "2024-07-21T15:16:56.078221Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "checkpoint = ModelCheckpoint('CNN-LSTM-weights/weights.keras',\n",
    "                                 monitor='val_acc', verbose=0, save_best_only=True,\n",
    "                                 mode='max')  # 最良のモデルを保存するためのチェックポイント\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)  # アーリーストッピングの設定\n",
    "\n",
    "model.fit([X_train,X_train_attention], y_train,\n",
    "          batch_size=16,\n",
    "          epochs=nb_epoch,\n",
    "          callbacks=[checkpoint, early_stopping],\n",
    "          validation_data=([X_valid,X_valid_attention], y_valid))  # モデルのトレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])  # モデルを再コンパイル\n",
    "model.save('model_LSTM_mix_CNN.keras')  # モデルの保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59412f6",
   "metadata": {},
   "source": [
    "# モデルのテスト\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込む\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # プロンプトを処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # モデルAの応答を処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # モデルBの応答を処理\n",
    "\n",
    "# トレーニング用に'Null'を削除\n",
    "indexes = test[(test.response_a == 'null') & (test.response_b == 'null')].index\n",
    "test.drop(indexes, inplace=True)  # 'Null'行を削除\n",
    "test.reset_index(inplace=True, drop=True)  # インデックスをリセット\n",
    "\n",
    "print(f\"合計 {len(indexes)} 行のNull応答が削除されました\")\n",
    "print('合計トレーニングサンプル数: ', len(test))  # トレーニングサンプル数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()  # テストデータの先頭5行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = 'User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n--------\\n\\nModel B:\\n'  + train['response_b']\n",
    "print(test['text'])  # テキストを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データをトークン化\n",
    "tokens_test = tokenizer(\n",
    "    test['text'].tolist(), \n",
    "    max_length=1024, \n",
    "    truncation=True, \n",
    "    return_tensors='np')  # numpy配列として返す\n",
    "\n",
    "# INPUT_IDSはトークンIDです\n",
    "INPUT_test = tokens_test['input_ids']\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS2 = tokens_test['attention_mask']\n",
    "\n",
    "print(f'INPUT_IDSの形状: {INPUT_test.shape}, ATTENTION_MASKSの形状: {ATTENTION_MASKS2.shape}')  # 形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = sq.pad_sequences(INPUT_test, maxlen=maxlen)  # テストデータにパディングを適用\n",
    "X_test_attention = sq.pad_sequences(ATTENTION_MASKS2, maxlen=maxlen)  # テストアテンションマスクにもパディングを適用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test  # テストデータを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict([X_test,X_test_attention])  # テストデータで予測を実行\n",
    "y_predict  # 予測結果を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df = pd.DataFrame(y_predict, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])  # 予測結果をデータフレームに変換\n",
    "result_df = pd.concat([test['id'], winner_df], axis=1)  # 結果データフレームを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('submission.csv', index=False)  # 結果をCSVファイルに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df  # 予測結果データフレームを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4146046",
   "metadata": {},
   "source": [
    "# 結論\n",
    "\n",
    "トレーニングの速度を上げて最適化する余地はまだまだあります！ もっと多くのデータ、異なるバッチサイズ、学習率を試してみてください。ご健闘を祈ります！\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e82516",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント\n",
    "\n",
    "> ## carvingfate\n",
    "> \n",
    "> Qwen2はGemma2よりも優れているのでしょうか？\n",
    "> \n",
    "> > ## Nguyễn Anh Tú（トピック作成者）\n",
    "> > \n",
    "> > Gemmaにアクセスできなかったため、Qwen 2を使用しています :(( ですので、レビューをお届けすることはできません。異なるトークナイザーを試して、モデルのハイパーパラメータを同じに保つことでジャッジしてください。私のモデルの構造を構築する際に参照した論文です：[https://www.researchgate.net/publication/321259272_Multi-channel_LSTM-CNN_model_for_Vietnamese_sentiment_analysis](https://www.researchgate.net/publication/321259272_Multi-channel_LSTM-CNN_model_for_Vietnamese_sentiment_analysis)\n",
    "> > \n",
    "> > \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 3863727,
     "sourceId": 6703755,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 71342,
     "modelInstanceId": 51944,
     "sourceId": 62188,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
