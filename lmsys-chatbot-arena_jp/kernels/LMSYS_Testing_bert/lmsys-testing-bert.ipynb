{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "788c6a54",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleのコンペティション「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」において、チャットボットの応答の好ましさを予測する問題に取り組んでいます。この課題は、大規模な言語モデル（LLM）からの応答の中で、どちらが人間に好まれるかを選ぶためのモデルを構築することです。\n",
    "\n",
    "Notebookでは、以下のような手法やライブラリが使用されています：\n",
    "\n",
    "1. **ライブラリのインポート**:\n",
    "   - `pandas`: データ操作のために使用。\n",
    "   - `torch`: PyTorchライブラリは深層学習の実行に必要。\n",
    "   - `transformers`: 自然言語処理モデルのトークナイザーとモデルを利用するために使用。\n",
    "   - `scikit-learn`: 機械学習アルゴリズムや評価指標のために利用。\n",
    "\n",
    "2. **データの読み込みと前処理**:\n",
    "   - 訓練データセット（`train.csv`）を読み込み、その構造を確認。\n",
    "   - 自然言語処理モデルの一つであるBERT（`bert-base-uncased`）を使用してテキストをトークン化し、さらに埋め込みを生成。この埋め込みは、後の機械学習モデルの特徴量として使用されます。\n",
    "\n",
    "3. **特徴量とターゲットの形成**:\n",
    "   - トークン化されたテキストから埋め込みを取得し、それらを結合して特徴量データフレームを形成。\n",
    "   - 勝者モデルを識別するためのターゲット変数 `y` を生成。\n",
    "\n",
    "4. **モデルの訓練と評価**:\n",
    "   - ランダムフォレスト分類器を使用してモデルを訓練し、検証データに対する精度を評価。\n",
    "\n",
    "5. **テストデータの処理と予測**:\n",
    "   - テストデータセット（`test.csv`）を読み込み、同様のトークン化と埋め込み処理を実施。\n",
    "   - 訓練したモデルを用いてテストデータに対する予測を行い、予測確率を取得。\n",
    "\n",
    "6. **提出ファイルの生成**:\n",
    "   - 予測結果をCSVファイル形式で保存し、コンペティションに提出する準備を整えています。\n",
    "\n",
    "全体として、NotebookはBERTを用いた自然言語処理とランダムフォレストを組み合わせ、チャットボットの応答を基に人間の好みを予測する問題に取り組んでいます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1eebd0",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、指定されたJupyter Notebook内での専門用語の簡単な解説です。初心者にとって馴染みの薄い言葉やこのノートブック特有の知識に焦点を当てています。\n",
    "\n",
    "1. **トークナイザー (Tokenizer)**:\n",
    "   トークナイザーは、文章などのテキストデータを単語やサブワード、あるいは文字といったトークンのリストに変換するツールです。NLPモデルがテキストを処理するためには、まずトークン化が必要です。\n",
    "\n",
    "2. **埋め込み (Embeddings)**:\n",
    "   埋め込みは、単語や文などのテキストを数値的なベクトル表現に変換したものです。これにより、モデルはテキストの意味的な情報を数値として扱えるようになります。一般に、埋め込みは高次元空間での意味の類似性を保ちながら低次元にマッピングされます。\n",
    "\n",
    "3. **最後の隠れ状態 (Last Hidden State)**:\n",
    "   ニューラルネットワークの中間層で生成された出力の一つで、通常はモデルの全層からの出力をまとめたものです。この状態は、入力テキストに対するニューロンの反応を示しており、取得した埋め込みや予測に使用されます。\n",
    "\n",
    "4. **勾配計算 (Gradient Calculation)**:\n",
    "   モデルが学習するために必要なプロセスで、誤差逆伝播法を利用して重みを更新するために誤差の勾配を計算します。ここでは、勾配計算を無効にすることにより、テスト時に計算量を減らし、メモリの使用量を抑えつつ、モデルの出力だけを取得します。\n",
    "\n",
    "5. **デバイス (Device)**:\n",
    "   モデルやデータが格納されるコンピュータのリソースを指します。特に、CPU (中央処理装置) またはGPU (グラフィックス処理装置)が使われることが多く、GPUは深層学習の計算を高速化するために設計されています。\n",
    "\n",
    "6. **ランダムフォレスト (Random Forest)**:\n",
    "   複数の決定木からなる機械学習のアンサンブル手法です。個々の決定木の予測を結合して、より頑健な予測を行います。ノイズの多いデータや欠損値に対しても強い特性を持っています。\n",
    "\n",
    "7. **argmax (アルグマックス)**:\n",
    "   指定された配列またはデータセット内で最大の値を持つ要素のインデックスを返す操作です。この操作は、どのクラスラベルが予測されるべきかを決定するために使用されることが多いです。\n",
    "\n",
    "8. **パディング (Padding)**:\n",
    "   入力の長さを統一するために、短いシーケンスに対して追加される特別なトークンです。これにより、異なる長さのデータを同じサイズでモデルに入力できるようになります。\n",
    "\n",
    "9. **切り捨て (Truncation)**:\n",
    "   長すぎる入力シーケンスを指定した最大長さに制限する操作です。これにより、モデルが処理できる標準的な長さ内に収まるようにデータを調整します。\n",
    "\n",
    "10. **test_size**:\n",
    "    `train_test_split`関数におけるパラメータで、データセットの何パーセントをテストデータとして使うかを指定します。0.2の場合、全体の20%がテストデータとして分割されます。\n",
    "\n",
    "これらの解説は、特に初心者にとっての理解を助けるために選ばれたものであり、ノートブック内で使用されている構文や概念に基づいたものです。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-29T15:45:22.005006Z",
     "iopub.status.busy": "2024-07-29T15:45:22.004242Z",
     "iopub.status.idle": "2024-07-29T15:45:26.607756Z",
     "shell.execute_reply": "2024-07-29T15:45:26.606692Z",
     "shell.execute_reply.started": "2024-07-29T15:45:22.004972Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandasをpdとしてインポートします\n",
    "import pandas as pd\n",
    "# PyTorchライブラリをインポートします\n",
    "import torch\n",
    "# TransformersライブラリからAutoTokenizerとAutoModelをインポートします\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# scikit-learnからtrain_test_splitをインポートします\n",
    "from sklearn.model_selection import train_test_split\n",
    "# scikit-learnからRandomForestClassifierをインポートします\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# scikit-learnからaccuracy_scoreをインポートします\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# これは、データの前処理やモデルの訓練に必要なライブラリをインポートしている部分です。\n",
    "# pandasはデータフレームの操作に、torchは深層学習に必要なライブラリです。\n",
    "# transformersはNLP（自然言語処理）モデルの使用に使います。\n",
    "# scikit-learnは機械学習の様々なアルゴリズムや評価指標を提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:45:44.55312Z",
     "iopub.status.busy": "2024-07-29T15:45:44.55235Z",
     "iopub.status.idle": "2024-07-29T15:45:47.971006Z",
     "shell.execute_reply": "2024-07-29T15:45:47.970154Z",
     "shell.execute_reply.started": "2024-07-29T15:45:44.553078Z"
    }
   },
   "outputs": [],
   "source": [
    "# 入力ディレクトリのパスを定義します\n",
    "INPUT_DIR = \"/kaggle/input/lmsys-chatbot-arena/\"\n",
    "# train.csvファイルを読み込み、train_dfというデータフレームに格納します\n",
    "train_df = pd.read_csv(f\"{INPUT_DIR}/train.csv\")\n",
    "\n",
    "# ここでは、訓練データセット（train.csv）を指定したディレクトリから読み込み、\n",
    "# pandasのデータフレーム形式で変数train_dfに保存しています。\n",
    "# このデータフレームには、モデルの訓練に使用するデータが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:45:49.326197Z",
     "iopub.status.busy": "2024-07-29T15:45:49.325826Z",
     "iopub.status.idle": "2024-07-29T15:45:49.343125Z",
     "shell.execute_reply": "2024-07-29T15:45:49.342049Z",
     "shell.execute_reply.started": "2024-07-29T15:45:49.326165Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dfデータフレームの内容を表示します\n",
    "train_df\n",
    "\n",
    "# このセルでは、先ほど読み込んだ訓練データセット（train_df）の中身を確認しています。\n",
    "# データフレームがどのようなデータを含んでいるか、行数や列数、各列のデータ型などを\n",
    "# 確認することができます。これはデータ解析や前処理を行う前に必要なステップです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:45:51.776787Z",
     "iopub.status.busy": "2024-07-29T15:45:51.776136Z",
     "iopub.status.idle": "2024-07-29T15:45:51.836264Z",
     "shell.execute_reply": "2024-07-29T15:45:51.835316Z",
     "shell.execute_reply.started": "2024-07-29T15:45:51.776755Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dfデータフレームの構造と情報を表示します\n",
    "train_df.info()\n",
    "\n",
    "# このセルでは、train_dfのデータフレームの詳細情報を表示しています。\n",
    "# info()メソッドは、データフレームの各列のデータ型、欠損値の数、データ数などを\n",
    "# 確認するために使用されます。これにより、データの準備や前処理に必要な問題を特定する助けとなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:45:54.21277Z",
     "iopub.status.busy": "2024-07-29T15:45:54.212386Z",
     "iopub.status.idle": "2024-07-29T15:45:59.487518Z",
     "shell.execute_reply": "2024-07-29T15:45:59.48643Z",
     "shell.execute_reply.started": "2024-07-29T15:45:54.212739Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用するモデルのIDを定義します（ここではBERTを使用）\n",
    "MODEL_ID = \"bert-base-uncased\"\n",
    "# 指定したモデルIDからトークナイザーを読み込んでtokenizer変数に保存します\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "# 指定したモデルIDから事前学習済みのモデルを読み込んでmodel変数に保存します\n",
    "model = AutoModel.from_pretrained(MODEL_ID)\n",
    "\n",
    "# このセルでは、自然言語処理のためのBERTモデルを設定しています。\n",
    "# MODEL_IDで指定された事前学習済みのBERTモデルを使用し、トークナイザー（tokenizer）と\n",
    "# モデル（model）をそれぞれ初期化しています。これにより、テキストをトークン化し、モデルを通じて\n",
    "# 処理する準備が整います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:46:01.80508Z",
     "iopub.status.busy": "2024-07-29T15:46:01.804428Z",
     "iopub.status.idle": "2024-07-29T15:46:01.864994Z",
     "shell.execute_reply": "2024-07-29T15:46:01.863926Z",
     "shell.execute_reply.started": "2024-07-29T15:46:01.805045Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用可能なデバイス（GPUまたはCPU）を判別します\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 判別したデバイスの情報を表示します\n",
    "print(device)\n",
    "\n",
    "# このセルでは、PyTorchを使用して、計算に使用するデバイスを設定しています。\n",
    "# GPUが利用可能な場合は'cuda'（GPU）を、そうでない場合は'cpu'（CPU）を使用します。\n",
    "# 最後に、選択されたデバイスを表示することで、後続の計算がどのデバイスで行われるかを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:46:04.76693Z",
     "iopub.status.busy": "2024-07-29T15:46:04.766122Z",
     "iopub.status.idle": "2024-07-29T15:46:05.094372Z",
     "shell.execute_reply": "2024-07-29T15:46:05.093467Z",
     "shell.execute_reply.started": "2024-07-29T15:46:04.7669Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルを選択したデバイス（GPUまたはCPU）に移動します\n",
    "model.to(device)\n",
    "\n",
    "# このセルでは、事前に設定したデバイス（device）にモデルを移動させています。\n",
    "# これにより、計算リソースを有効活用し、訓練や推論のプロセスを高速化することができます。\n",
    "# GPUを使用することで、特に大規模なモデルやデータセットに対してパフォーマンスが向上します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:46:30.889365Z",
     "iopub.status.busy": "2024-07-29T15:46:30.888689Z",
     "iopub.status.idle": "2024-07-29T15:46:30.894205Z",
     "shell.execute_reply": "2024-07-29T15:46:30.892929Z",
     "shell.execute_reply.started": "2024-07-29T15:46:30.889325Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーにパディングトークンが設定されていない場合\n",
    "if tokenizer.pad_token is None:\n",
    "    # 特殊トークンとしてパディングトークンを追加します\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    # パディングトークンを設定します\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "\n",
    "# このセルでは、トークナイザーにパディングトークンが存在しない場合に、新たにパディングトークンを追加しています。\n",
    "# パディングトークンは、バッチ内のシーケンスの長さを揃えるために使用されます。\n",
    "# これにより、異なる長さの入力データを同じ次元に揃えることができ、モデルにとって処理しやすくなります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:52:26.63758Z",
     "iopub.status.busy": "2024-07-29T15:52:26.637204Z",
     "iopub.status.idle": "2024-07-29T15:52:26.642611Z",
     "shell.execute_reply": "2024-07-29T15:52:26.64146Z",
     "shell.execute_reply.started": "2024-07-29T15:52:26.637547Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストをトークン化する関数を定義します\n",
    "def tokenize_text(text):\n",
    "    # トークン化を行い、パディングと切り捨てを適用し、テンソル形式で返します\n",
    "    return tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "\n",
    "# このセルでは、与えられたテキストをトークン化するための関数tokenize_textを定義しています。\n",
    "# この関数は、テキストをトークナイザーに渡し、パディング（長さを調整）と切り捨て（長さを制限）を行い、\n",
    "# PyTorchのテンソル形式に変換して選択されたデバイスに移動させます。\n",
    "# これにより、後続のモデルへの入力が適切な形式で提供されることになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:52:27.835878Z",
     "iopub.status.busy": "2024-07-29T15:52:27.834996Z",
     "iopub.status.idle": "2024-07-29T15:56:18.703387Z",
     "shell.execute_reply": "2024-07-29T15:56:18.702495Z",
     "shell.execute_reply.started": "2024-07-29T15:52:27.835847Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'prompt'列をトークン化して新しい列'prompt_tokens'を作成します\n",
    "train_df['prompt_tokens'] = train_df['prompt'].apply(tokenize_text)\n",
    "# 'response_a'列をトークン化して新しい列'response_a_tokens'を作成します\n",
    "train_df['response_a_tokens'] = train_df['response_a'].apply(tokenize_text)\n",
    "# 'response_b'列をトークン化して新しい列'response_b_tokens'を作成します\n",
    "train_df['response_b_tokens'] = train_df['response_b'].apply(tokenize_text)\n",
    "\n",
    "# このセルでは、訓練データフレーム（train_df）の各列に対し、\n",
    "# それぞれのテキストデータをトークン化し、新しい列を作成しています。\n",
    "# 'prompt'、'response_a'、'response_b'の各列からトークン化された結果を\n",
    "# 'prompt_tokens'、'response_a_tokens'、'response_b_tokens'という新しい列に格納します。\n",
    "# これにより、モデルへの入力形式が整えられます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:56:18.705783Z",
     "iopub.status.busy": "2024-07-29T15:56:18.705464Z",
     "iopub.status.idle": "2024-07-29T15:56:18.739322Z",
     "shell.execute_reply": "2024-07-29T15:56:18.73824Z",
     "shell.execute_reply.started": "2024-07-29T15:56:18.705756Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dfデータフレームの内容を表示します\n",
    "train_df\n",
    "\n",
    "# このセルでは、トークン化された結果を含む訓練データフレーム（train_df）の中身を確認しています。\n",
    "# 新たに追加された'tokens'列が含まれており、各テキストがどのようにトークン化されたかを\n",
    "# 確認することができます。データフレームの変化を把握することで、次の処理を行う準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:56:18.750386Z",
     "iopub.status.busy": "2024-07-29T15:56:18.750052Z",
     "iopub.status.idle": "2024-07-29T15:56:18.766567Z",
     "shell.execute_reply": "2024-07-29T15:56:18.765645Z",
     "shell.execute_reply.started": "2024-07-29T15:56:18.75035Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン化されたテキストから埋め込みを取得する関数を定義します\n",
    "def get_embeddings(text_tokens):\n",
    "    # 勾配計算を無効にしてモデルの出力を取得します\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**text_tokens)\n",
    "    # 最後の隠れ状態の平均を計算し、1次元削減してNumPy配列に変換して返します\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "# このセルでは、トークン化されたテキストからモデルを使用して埋め込み（特徴ベクトル）を取得するための\n",
    "# 関数get_embeddingsを定義しています。\n",
    "# モデルの出力は勾配計算を行わずに取得し、最終的な隠れ状態の平均を計算することで\n",
    "# 各入力テキストに対する埋め込みを生成します。得られた埋め込みはNumPy配列として返され、\n",
    "# 機械学習モデルへの入力として使用されることが想定されています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T15:56:18.768034Z",
     "iopub.status.busy": "2024-07-29T15:56:18.767732Z",
     "iopub.status.idle": "2024-07-29T16:42:56.714703Z",
     "shell.execute_reply": "2024-07-29T16:42:56.71372Z",
     "shell.execute_reply.started": "2024-07-29T15:56:18.768006Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'prompt_tokens'列のトークン化結果から埋め込みを取得し、新しい列'prompt_embeddings'を作成します\n",
    "train_df['prompt_embeddings'] = train_df['prompt_tokens'].apply(lambda x: get_embeddings(x))\n",
    "# 'response_a_tokens'列のトークン化結果から埋め込みを取得し、新しい列'response_a_embeddings'を作成します\n",
    "train_df['response_a_embeddings'] = train_df['response_a_tokens'].apply(lambda x: get_embeddings(x))\n",
    "# 'response_b_tokens'列のトークン化結果から埋め込みを取得し、新しい列'response_b_embeddings'を作成します\n",
    "train_df['response_b_embeddings'] = train_df['response_b_tokens'].apply(lambda x: get_embeddings(x))\n",
    "\n",
    "# このセルでは、トークン化されたテキストから埋め込みを取得し、それぞれの埋め込みを新しい列に格納しています。\n",
    "# 'prompt'、'response_a'、'response_b'のトークン化結果に対してget_embeddings関数を適用し、\n",
    "# それぞれの埋め込み結果（'prompt_embeddings'、'response_a_embeddings'、'response_b_embeddings'）をデータフレームに追加します。\n",
    "# これにより、モデルの出力がデータフレーム内で利用可能となり、今後の機械学習処理や分析に活用される予定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:43:21.913194Z",
     "iopub.status.busy": "2024-07-29T16:43:21.912515Z",
     "iopub.status.idle": "2024-07-29T16:44:55.73248Z",
     "shell.execute_reply": "2024-07-29T16:44:55.731639Z",
     "shell.execute_reply.started": "2024-07-29T16:43:21.913146Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各埋め込みをデータフレーム形式に変換し、Xという特徴量データフレームを作成します\n",
    "X = pd.concat([pd.DataFrame(train_df['prompt_embeddings'].tolist()), \n",
    "               pd.DataFrame(train_df['response_a_embeddings'].tolist()), \n",
    "               pd.DataFrame(train_df['response_b_embeddings'].tolist())], axis=1)\n",
    "# ターゲット変数yを定義し、各行で最も大きな値を持つ列のインデックスを取得します\n",
    "y = train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values.argmax(axis=1)\n",
    "\n",
    "# このセルでは、'prompt_embeddings'、'response_a_embeddings'、'response_b_embeddings'の埋め込みを\n",
    "# 一つの特徴量データフレームXに結合しています。\n",
    "# さらに、3つの勝者モデルの情報から最も大きな値を持つインデックスを取得し、yというターゲット変数を作成します。\n",
    "# yは、各行の勝者モデルを示すため、後のモデル訓練で使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:44:55.734497Z",
     "iopub.status.busy": "2024-07-29T16:44:55.734173Z",
     "iopub.status.idle": "2024-07-29T16:44:55.771555Z",
     "shell.execute_reply": "2024-07-29T16:44:55.770647Z",
     "shell.execute_reply.started": "2024-07-29T16:44:55.734469Z"
    }
   },
   "outputs": [],
   "source": [
    "# 特徴量データフレームXの内容を表示します\n",
    "X\n",
    "\n",
    "# このセルでは、訓練データの特徴量データフレーム（X）の中身を確認しています。\n",
    "# Xには、prompt、response_a、response_bの埋め込みが結合されており、\n",
    "# 今後の機械学習モデルで使用するための入力データが整えられています。\n",
    "# モデルの訓練や予測を行う前に、データの変化や形状を確認するためのステップです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:44:55.773464Z",
     "iopub.status.busy": "2024-07-29T16:44:55.773036Z",
     "iopub.status.idle": "2024-07-29T16:44:55.780271Z",
     "shell.execute_reply": "2024-07-29T16:44:55.779339Z",
     "shell.execute_reply.started": "2024-07-29T16:44:55.773428Z"
    }
   },
   "outputs": [],
   "source": [
    "# ターゲット変数yの内容を表示します\n",
    "y\n",
    "\n",
    "# このセルでは、ターゲット変数yの中身を確認しています。\n",
    "# yは、特徴量データに対するモデルの勝者を示すインデックスを持ちます。\n",
    "# 各エントリは、対応する特徴量データのどのモデルが選ばれたかを表しており、\n",
    "# モデルの訓練や評価に使用される重要な情報です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:54:21.859786Z",
     "iopub.status.busy": "2024-07-29T16:54:21.858799Z",
     "iopub.status.idle": "2024-07-29T16:54:22.301019Z",
     "shell.execute_reply": "2024-07-29T16:54:22.300217Z",
     "shell.execute_reply.started": "2024-07-29T16:54:21.859747Z"
    }
   },
   "outputs": [],
   "source": [
    "# データを訓練セットと検証セットに分割します\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# このセルでは、特徴量データXとターゲット変数yを訓練データと検証データに分割しています。\n",
    "# train_test_split関数を使用しており、全データの20%を検証データとして確保します。\n",
    "# random_stateを指定することで、再現性を持たせた分割が行われます。\n",
    "# これによりモデルの訓練と評価を行う準備が整います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:54:29.430379Z",
     "iopub.status.busy": "2024-07-29T16:54:29.429673Z",
     "iopub.status.idle": "2024-07-29T16:59:45.516713Z",
     "shell.execute_reply": "2024-07-29T16:59:45.515639Z",
     "shell.execute_reply.started": "2024-07-29T16:54:29.430344Z"
    }
   },
   "outputs": [],
   "source": [
    "# ランダムフォレスト分類器を初期化します（決定木の数として100を指定）\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# 訓練データを使用してモデルを訓練します\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# このセルでは、ランダムフォレスト分類器を作成し、訓練データ（X_train）とターゲット変数（y_train）を使ってモデルを訓練しています。\n",
    "# n_estimatorsで指定した数の決定木を持つランダムフォレストモデルが構築され、\n",
    "# random_stateを利用することで訓練の再現性を確保しています。これにより、将来の予測や評価を行うためのモデルが準備されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:59:45.519645Z",
     "iopub.status.busy": "2024-07-29T16:59:45.519226Z",
     "iopub.status.idle": "2024-07-29T16:59:46.296424Z",
     "shell.execute_reply": "2024-07-29T16:59:46.295434Z",
     "shell.execute_reply.started": "2024-07-29T16:59:45.519609Z"
    }
   },
   "outputs": [],
   "source": [
    "# 検証データを使用して予測を行います\n",
    "y_pred = clf.predict(X_val)\n",
    "# 検証データに対する精度を計算します\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "# 精度を表示します\n",
    "print(f'Validation Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# このセルでは、訓練したモデルを用いて検証データ（X_val）に対する予測を行い、\n",
    "# その結果を基に精度を計算しています。\n",
    "# accuracy_score関数を使用して、実際の値（y_val）と予測値（y_pred）を比較し\n",
    "# 精度を求め、結果を小数点以下4桁で表示します。\n",
    "# モデルの性能を評価する重要なステップです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T16:59:46.298139Z",
     "iopub.status.busy": "2024-07-29T16:59:46.297753Z",
     "iopub.status.idle": "2024-07-29T16:59:46.308541Z",
     "shell.execute_reply": "2024-07-29T16:59:46.307775Z",
     "shell.execute_reply.started": "2024-07-29T16:59:46.298103Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータセットを読み込み、test_dfというデータフレームに格納します\n",
    "test_df = pd.read_csv(f\"{INPUT_DIR}/test.csv\")\n",
    "\n",
    "# このセルでは、指定したディレクトリからテストデータ（test.csv）を読み込み、\n",
    "# pandasのデータフレーム形式で変数test_dfに保存しています。\n",
    "# このデータフレームは、モデルの性能を評価するためのテストに利用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T17:00:05.171126Z",
     "iopub.status.busy": "2024-07-29T17:00:05.170163Z",
     "iopub.status.idle": "2024-07-29T17:00:05.428797Z",
     "shell.execute_reply": "2024-07-29T17:00:05.427774Z",
     "shell.execute_reply.started": "2024-07-29T17:00:05.171072Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータを処理します\n",
    "test_df['prompt_tokens'] = test_df['prompt'].apply(tokenize_text)\n",
    "test_df['response_a_tokens'] = test_df['response_a'].apply(tokenize_text)\n",
    "test_df['response_b_tokens'] = test_df['response_b'].apply(tokenize_text)\n",
    "\n",
    "# 埋め込みを取得します\n",
    "test_df['prompt_embeddings'] = test_df['prompt_tokens'].apply(get_embeddings)\n",
    "test_df['response_a_embeddings'] = test_df['response_a_tokens'].apply(get_embeddings)\n",
    "test_df['response_b_embeddings'] = test_df['response_b_tokens'].apply(get_embeddings)\n",
    "\n",
    "# テスト特徴量を準備します\n",
    "X_test = pd.concat([pd.DataFrame(test_df['prompt_embeddings'].tolist()), \n",
    "                    pd.DataFrame(test_df['response_a_embeddings'].tolist()), \n",
    "                    pd.DataFrame(test_df['response_b_embeddings'].tolist())], axis=1)\n",
    "\n",
    "# このセルでは、テストデータフレーム（test_df）の各列をトークン化し、\n",
    "# それからトークン化されたデータを基に埋め込みを取得する過程を経ています。\n",
    "# 'prompt'、'response_a'、'response_b'それぞれの埋め込みを作成し、\n",
    "# 最後にこれらを結合してテスト特徴量データフレーム（X_test）を作成しています。\n",
    "# モデルによる予測を行う準備が整います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T17:00:27.734646Z",
     "iopub.status.busy": "2024-07-29T17:00:27.733816Z",
     "iopub.status.idle": "2024-07-29T17:00:27.766853Z",
     "shell.execute_reply": "2024-07-29T17:00:27.765647Z",
     "shell.execute_reply.started": "2024-07-29T17:00:27.734589Z"
    }
   },
   "outputs": [],
   "source": [
    "# テスト特徴量データフレームX_testの内容を表示します\n",
    "X_test\n",
    "\n",
    "# このセルでは、処理されたテスト特徴量データフレーム（X_test）の中身を確認しています。\n",
    "# X_testには、'prompt'、'response_a'、'response_b'の埋め込みが結合されており、\n",
    "# モデルによる予測に利用するための入力データが整えられています。\n",
    "# データの変化や形状を確認することで、次のステップに進む準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T17:00:35.389917Z",
     "iopub.status.busy": "2024-07-29T17:00:35.389517Z",
     "iopub.status.idle": "2024-07-29T17:00:35.45484Z",
     "shell.execute_reply": "2024-07-29T17:00:35.45391Z",
     "shell.execute_reply.started": "2024-07-29T17:00:35.389889Z"
    }
   },
   "outputs": [],
   "source": [
    "# テスト特徴量に基づいて各クラスの予測確率を取得します\n",
    "y_test_pred_prob = clf.predict_proba(X_test)\n",
    "\n",
    "# 予測確率を持つデータフレームを作成し、カラム名を指定します\n",
    "submission_df = pd.DataFrame(y_test_pred_prob, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
    "# テストデータフレームの'id'列を最初のカラムとして挿入します\n",
    "submission_df.insert(0, 'id', test_df['id'])\n",
    "\n",
    "# このセルでは、訓練したモデルを使ってテストデータ（X_test）に対する各クラスの予測確率を取得しています。\n",
    "# 予測結果を新しいデータフレーム（submission_df）に格納し、カラム名を指定しています。\n",
    "# さらに、元のテストデータに含まれる'id'を最初のカラムに追加して、提出用のフォーマットを整えています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T17:00:37.167742Z",
     "iopub.status.busy": "2024-07-29T17:00:37.167028Z",
     "iopub.status.idle": "2024-07-29T17:00:37.181737Z",
     "shell.execute_reply": "2024-07-29T17:00:37.180781Z",
     "shell.execute_reply.started": "2024-07-29T17:00:37.167711Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用データフレームsubmission_dfの内容を表示します\n",
    "submission_df\n",
    "\n",
    "# このセルでは、作成した提出用データフレーム（submission_df）の中身を確認しています。\n",
    "# submission_dfには、テストデータの各エントリに対するモデルの予測確率（winner_model_a、winner_model_b、winner_tie）が含まれており、\n",
    "# 提出ファイルとして適切な形式になっています。これを後で提出することで、コンペティションの結果を評価してもらうことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T17:00:39.547636Z",
     "iopub.status.busy": "2024-07-29T17:00:39.546988Z",
     "iopub.status.idle": "2024-07-29T17:00:39.557479Z",
     "shell.execute_reply": "2024-07-29T17:00:39.556534Z",
     "shell.execute_reply.started": "2024-07-29T17:00:39.547606Z"
    }
   },
   "outputs": [],
   "source": [
    "# 作成した提出用データフレームをCSVファイルとして保存します\n",
    "submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "# 提出ファイルが作成されたことを表示します\n",
    "print(\"Submission file created.\")\n",
    "\n",
    "# このセルでは、生成した提出用データフレーム（submission_df）をCSV形式で保存し、\n",
    "# 提出ファイル（submission.csv）を作成しています。index=Falseを設定することで、行番号をファイルに含めません。\n",
    "# 最後のメッセージにより、提出ファイルが正常に作成されたことを確認できます。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
