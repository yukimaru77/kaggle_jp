{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfbcc0e4",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このノートブックは、LMSYS - Chatbot Arenaコンペティションにおいて、ユーザーの好みを予測するための機械学習モデルのトレーニングおよび推論に取り組んでいます。特に、KerasとTensorFlowを使用して、Gemma Causal Language Modelを基にしたモデルを構築しています。\n",
    "\n",
    "### 主な問題\n",
    "ノートブックの目的は、ユーザーからの応答データに基づいて、どのチャットボットの応答が好まれるかを予測するモデルを訓練することです。このモデルは、モデルのトークン化やデータ前処理を行い、各種ハイパーパラメータによる最適化を実施します。\n",
    "\n",
    "### 使用している手法とライブラリ\n",
    "1. **KerasとTensorFlow**:\n",
    "   - Kerasの分散APIを利用して、TPUにモデルをデプロイし、メモリ断片化を防ぐために設定を行います。\n",
    "   - JAXをバックエンドに使用し、TPU上でのトレーニングと推論を高速化します。\n",
    "\n",
    "2. **モデル構築**:\n",
    "   - Gemma Causal Language Modelをロードし、そのバックボーンを利用して、ユーザーの入力とレスポンスを処理するモデルを構築します。\n",
    "   - 出力層にはソフトマックス関数を適用し、多クラス分類を行います。\n",
    "\n",
    "3. **データ処理**:\n",
    "   - CSVファイルからデータを読み込み、必要な列を抽出してサロゲートペアを除去する関数を定義します。\n",
    "   - TensorFlowのデータセットAPIを使用して、バッチ化と前処理を効率的に行います。\n",
    "\n",
    "4. **ハイパーパラメータの設定**:\n",
    "   - AdamWオプティマイザーを使用し、学習率や重み減衰を調整することでモデルのトレーニング性能を向上させます。\n",
    "\n",
    "5. **モデルのトレーニングと推論**:\n",
    "   - 訓練データに対してモデルをコンパイルし、予測を行います。最終的な予測結果はCSV形式で保存され、提出用にフォーマットされます。\n",
    "\n",
    "### コメントと次のステップ\n",
    "ノートブックでは、タイムアウト問題や推論速度の向上についても言及されており、今後の改善が期待されています。また、他の参加者からのフィードバックや提案も含まれており、相互学習や情報共有の場が形成されています。\n",
    "\n",
    "全体として、このノートブックは、自然言語処理タスクにおける現代的なアプローチを採用しており、効率的なモデルの構築とデータ処理の手法を示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9f1108",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookに登場する専門用語の簡単な解説を列挙します。これは、機械学習や深層学習に一定の知識があるが、実務経験が少ない初心者向けです。\n",
    "\n",
    "1. **float16**: 浮動小数点数を表すデータ型の一つで、16ビットで表現される。計算精度は低いが、メモリ使用量が少なく、ディープラーニングのトレーニングや推論では高速化が期待される。\n",
    "\n",
    "2. **TPU (Tensor Processing Unit)**: Googleが開発した、ディープラーニング専用のハードウェア加速装置。通常のCPUやGPUに比べて、特にテンソル演算に最適化されているため、モデルのトレーニングや推論を高速化できる。\n",
    "\n",
    "3. **メモリ断片化 (Memory Fragmentation)**: プログラムがメモリを使用したり解放したりする過程で、メモリ空間が小さな断片に分かれ、十分な連続したメモリを確保できなくなる現象。TPUではメモリの効率的な使用が重要。\n",
    "\n",
    "4. **デバイスメッシュ (Device Mesh)**: 複数のデバイス（GPUやTPUなど）をグリッド状に配置し、計算を並行して行うための概念。これにより、計算負荷を分散しスピードアップが可能になる。\n",
    "\n",
    "5. **レイアウトマップ (LayoutMap)**: モデルのレイヤーやパラメータを、デバイスメッシュ上にどのように分散させるかを指定するためのマッピング。\n",
    "\n",
    "6. **LoRA (Low-Rank Adaptation)**: モデルを少ないパラメータで適応させる手法。特定のタスクに対して重みを効率的に調整できるため、トレーニングコストを削減しつつ性能を向上させることができる。\n",
    "\n",
    "7. **サロゲートペア (Surrogate Pairs)**: Unicodeにおける特定の文字の範囲（U+D800からU+DFFF）であり、通常の文字コード上では表現できない文字を扱うために使われる。これらのペアを含むテキストを処理する際には特別な対策が必要。\n",
    "\n",
    "8. **トークナイザー (Tokenizer)**: テキストデータをトークン（単語やサブワードなどの単位）に分割するためのツール。トークンは機械学習モデルが理解できる形式で表現される。\n",
    "\n",
    "9. **バックボーン (Backbone)**: 特定のタスクに使用されるモデルの基礎部分。通常は特定のアーキテクチャに基づいており、タスクに特化した追加の層がその上に構築される。\n",
    "\n",
    "10. **トレーニング不可 (Non-trainable)**: 各レイヤーやパラメータがトレーニング中に更新されない設定。この設定は、あらかじめトレーニングされたモデルを再利用する場合に使用される。\n",
    "\n",
    "理解を助けるために、これらの用語は具体的な文脈において重要であり、それぞれの機能や影響を把握することで、ノートブックのコードの理解が深まります。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee130f5",
   "metadata": {},
   "source": [
    "float16での推論には???時間かかるはずです。\n",
    "\n",
    "トレーニングノートブック:\n",
    "\n",
    "https://www.kaggle.com/code/pranshubahadur/tf-gemma-2-9b-lmsys-training-tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:02:18.076291Z",
     "iopub.status.busy": "2024-08-02T10:02:18.075797Z",
     "iopub.status.idle": "2024-08-02T10:02:22.879101Z",
     "shell.execute_reply": "2024-08-02T10:02:22.878325Z",
     "shell.execute_reply.started": "2024-08-02T10:02:18.076247Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Keras 3の分散APIは、現時点ではJAXバックエンドのみに実装されています\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# TPUのメモリ断片化と割り当てのオーバーヘッドを最小限に抑えるために、すべてのTPUメモリを事前に割り当てます。\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "# (1, 2)の形状を持つデバイスメッシュを作成し、すべての8つのTPUに重みを分散させます。\n",
    "device_mesh = keras.distribution.DeviceMesh(\n",
    "    (1, 2),  # バッチとモデルのための次元\n",
    "    [\"batch\", \"model\"],\n",
    "    devices=['gpu:0', 'gpu:1'],  # 使用するGPUデバイスのリスト\n",
    ")\n",
    "\n",
    "model_dim = \"model\"  # モデルの次元を指定\n",
    "\n",
    "layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "\n",
    "# 'token_embedding/embeddings'に一致する重みが8つのTPUに分散されます\n",
    "layout_map[\"token_embedding/embeddings\"] = (model_dim, None)  # トークン埋め込みのマッピング\n",
    "layout_map[\"position_embedding/embeddings\"] = (model_dim, None)  # 位置埋め込みのマッピング\n",
    "\n",
    "# 注意層のクエリ、キー、値行列に対してマッチする正規表現\n",
    "layout_map[\"decoder_block.*attention.*(query|key|value)/kernel\"] = (model_dim, None, None)\n",
    "layout_map[\"decoder_block.*attention_output/kernel\"] = (model_dim, None, None)\n",
    "layout_map[\"decoder_block.*ffw_gating.*/kernel\"] = (None, model_dim)\n",
    "layout_map[\"decoder_block.*ffw_linear/kernel\"] = (model_dim, None)\n",
    "\n",
    "layout_map[\"decoder_block.*layer_norm/scale\"] = (model_dim,)  # スケールのマッピング\n",
    "layout_map[\"decoder_block.*layer_norm/bias\"] = (model_dim,)  # バイアスのマッピング\n",
    "\n",
    "# モデルの分散設定を行います\n",
    "model_parallel = keras.distribution.ModelParallel(\n",
    "    layout_map=layout_map,\n",
    "    batch_dim_name=\"batch\",  # バッチの次元名を指定\n",
    ")\n",
    "\n",
    "# モデルの分散をセットします\n",
    "keras.distribution.set_distribution(model_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:02:22.884177Z",
     "iopub.status.busy": "2024-08-02T10:02:22.883842Z",
     "iopub.status.idle": "2024-08-02T10:02:22.892038Z",
     "shell.execute_reply": "2024-08-02T10:02:22.891248Z",
     "shell.execute_reply.started": "2024-08-02T10:02:22.884146Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# JAXのデフォルトデバイスをCPUに設定します\n",
    "jax.default_device = jax.devices('cpu')[0]\n",
    "\n",
    "# 現在のデバイス情報を表示します\n",
    "jax.devices()  # これにより、使用可能なデバイスのリストが返されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:02:22.893459Z",
     "iopub.status.busy": "2024-08-02T10:02:22.893165Z",
     "iopub.status.idle": "2024-08-02T10:02:22.901665Z",
     "shell.execute_reply": "2024-08-02T10:02:22.90061Z",
     "shell.execute_reply.started": "2024-08-02T10:02:22.893436Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasのデータ型ポリシーをfloat16に設定します\n",
    "keras.config.set_dtype_policy(\"float16\")  # これにより、モデルのトレーニングや推論で使用されるデータの型がfloat16になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このセルにはコードが含まれていません。必要な処理やデータをここに追加してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:02:22.905598Z",
     "iopub.status.busy": "2024-08-02T10:02:22.904695Z",
     "iopub.status.idle": "2024-08-02T10:05:49.51796Z",
     "shell.execute_reply": "2024-08-02T10:05:49.517034Z",
     "shell.execute_reply.started": "2024-08-02T10:02:22.905569Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gemma Causal Language Model を事前設定からロードします\n",
    "# trainable=False でモデルを読み込むと、重みが更新されない設定になります。\n",
    "# dtype='int8' でデータ型を int8 に設定します。\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma2/keras/gemma2_instruct_9b_en/1\", trainable=False, dtype='int8')\n",
    "\n",
    "# モデルの概要を表示します\n",
    "gemma_lm.summary()  # これにより、モデルの構造やパラメータの数が表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:05:49.519475Z",
     "iopub.status.busy": "2024-08-02T10:05:49.519119Z",
     "iopub.status.idle": "2024-08-02T10:05:49.527042Z",
     "shell.execute_reply": "2024-08-02T10:05:49.526071Z",
     "shell.execute_reply.started": "2024-08-02T10:05:49.519448Z"
    }
   },
   "outputs": [],
   "source": [
    "# サロゲートペア（代理対）を削除する関数を定義します\n",
    "def remove_surrogates(text):\n",
    "    # サロゲートペアの範囲 (0xD800 から 0xDFFF) に含まれない文字をフィルタリングして結合します\n",
    "    return ''.join(char for char in text if not (0xD800 <= ord(char) <= 0xDFFF))  # テキストからサロゲートペアを取り除いた結果を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:57.792761Z",
     "iopub.status.busy": "2024-08-02T10:07:57.792373Z",
     "iopub.status.idle": "2024-08-02T10:07:57.829743Z",
     "shell.execute_reply": "2024-08-02T10:07:57.828966Z",
     "shell.execute_reply.started": "2024-08-02T10:07:57.792728Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "# 使用する入力列の名前を指定\n",
    "input_columns = ['prompt', 'response_a', 'response_b']\n",
    "# ラベル列の名前を指定\n",
    "label_columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# CSVファイルから生のテストデータセットを読み込みます\n",
    "raw_test_dataset = read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# 以下はコメントアウトされているコードです\n",
    "# raw_test_dataset[input_columns] = raw_test_dataset[input_columns].map(lambda x: eval(x)[0])  # 各列の中身を評価して最初の要素を取得する\n",
    "# raw_test_dataset = raw_test_dataset.dropna().reset_index(drop=True)  # NaNを含む行を削除し、インデックスをリセットします\n",
    "\n",
    "# トレーニングデータセットを作成します\n",
    "train_dataset = DataFrame({\n",
    "    # 入力列を結合し、サロゲートペアを削除して新しいカラム 'text' を作成します\n",
    "    'text' : raw_test_dataset[input_columns].agg('\\n\\nRESPONSE:\\n\\n'.join, axis=1)  # 各行の入力を2つのレスポンスで結合\n",
    "                .apply(lambda x: '\\n\\nPROMPT\\n\\n' + x)  # 各行の先頭に極末文を追加\n",
    "                .apply(lambda x: remove_surrogates(x)),  # サロゲートペアを削除\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:57.839291Z",
     "iopub.status.busy": "2024-08-02T10:07:57.838987Z",
     "iopub.status.idle": "2024-08-02T10:07:57.843437Z",
     "shell.execute_reply": "2024-08-02T10:07:57.842378Z",
     "shell.execute_reply.started": "2024-08-02T10:07:57.839267Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gemmaモデルからトークナイザーとバックボーンを取得します\n",
    "tokenizer = gemma_lm._preprocessor  # モデルの事前処理（トークナイザー）を取得\n",
    "backbone = gemma_lm.backbone  # モデルのバックボーン（基盤部分）を取得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:57.844775Z",
     "iopub.status.busy": "2024-08-02T10:07:57.844506Z",
     "iopub.status.idle": "2024-08-02T10:07:57.853109Z",
     "shell.execute_reply": "2024-08-02T10:07:57.852359Z",
     "shell.execute_reply.started": "2024-08-02T10:07:57.844754Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストとオプションのラベルを前処理する関数を定義します\n",
    "def preprocess_fn(text, label=None):\n",
    "    # テキストをトークナイザーを使って処理し、トークンIDとパディングマスクを取得します\n",
    "    preprocessed = tokenizer(text, sequence_length=512)[0]  # シーケンスの長さは512に制限します\n",
    "    print(preprocessed)  # 前処理された結果を表示します\n",
    "\n",
    "    # 前処理関数が必要な入力のみを返すことを確認します\n",
    "    return {'token_ids': preprocessed['token_ids'], 'padding_mask': preprocessed['padding_mask']}  # トークンIDとパディングマスクを含む辞書を返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:57.855468Z",
     "iopub.status.busy": "2024-08-02T10:07:57.855124Z",
     "iopub.status.idle": "2024-08-02T10:07:58.04386Z",
     "shell.execute_reply": "2024-08-02T10:07:58.042853Z",
     "shell.execute_reply.started": "2024-08-02T10:07:57.855446Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling1D\n",
    "from keras import Model\n",
    "\n",
    "# モデルの入力を定義します\n",
    "inputs = {\n",
    "        \"token_ids\": keras.Input(shape=(512,), dtype=tf.int32, name=\"token_ids\"),  # トークンIDの入力\n",
    "        \"padding_mask\": keras.Input(shape=(512,), dtype=tf.int32, name=\"padding_mask\"),  # パディングマスクの入力\n",
    "    }\n",
    "\n",
    "# バックボーンモデルを通じて入力を処理します\n",
    "x = backbone(inputs)  # バックボーンに入力を渡します\n",
    "print(x.shape)  # 出力の形状を表示します\n",
    "\n",
    "# グローバル平均プーリングを適用します\n",
    "x = GlobalAveragePooling1D()(x)  # 1次元のデータに対してグローバル平均プーリングを行います\n",
    "print(x.shape)  # プーリング後の出力の形状を表示します\n",
    "\n",
    "# 出力層を追加します\n",
    "outputs = Dense(3, 'softmax')(x)  # 3つのクラスに対してソフトマックス関数を使用する出力層を追加します\n",
    "\n",
    "# モデルを定義します\n",
    "model = Model(inputs, outputs)  # 入力と出力からモデルを構築します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:58.045185Z",
     "iopub.status.busy": "2024-08-02T10:07:58.044922Z",
     "iopub.status.idle": "2024-08-02T10:07:58.050843Z",
     "shell.execute_reply": "2024-08-02T10:07:58.049971Z",
     "shell.execute_reply.started": "2024-08-02T10:07:58.045161Z"
    }
   },
   "outputs": [],
   "source": [
    "# AdamWオプティマイザーを定義します\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "                    learning_rate=5e-5,  # 学習率を5e-5に設定します\n",
    "                    weight_decay=0.01,  # 重み減衰を0.01に設定します\n",
    "                )\n",
    "\n",
    "# バイアスとスケールの変数を重み減衰の対象から除外します\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])  # これにより、指定された変数は重み減衰が適用されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:58.052169Z",
     "iopub.status.busy": "2024-08-02T10:07:58.051902Z",
     "iopub.status.idle": "2024-08-02T10:07:58.062355Z",
     "shell.execute_reply": "2024-08-02T10:07:58.061532Z",
     "shell.execute_reply.started": "2024-08-02T10:07:58.052146Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルをコンパイルします\n",
    "model.compile(optimizer,  # 先ほど定義したオプティマイザーを使用\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),  # 多クラスのクロスエントロピー損失を使用\n",
    "             )  # これにより、指定したオプティマイザーと損失関数でモデルが準備されます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:07:58.063876Z",
     "iopub.status.busy": "2024-08-02T10:07:58.063542Z",
     "iopub.status.idle": "2024-08-02T10:08:07.990848Z",
     "shell.execute_reply": "2024-08-02T10:08:07.990018Z",
     "shell.execute_reply.started": "2024-08-02T10:07:58.063846Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの3番目のレイヤーにLoRAの重みをロードします\n",
    "model.layers[2].load_lora_weights(\"/kaggle/input/tf-gemma-2-9b-lmsys-training-tpu/model.lora.h5\")  # 指定されたファイルからLoRAの重みを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:07.992384Z",
     "iopub.status.busy": "2024-08-02T10:08:07.992041Z",
     "iopub.status.idle": "2024-08-02T10:08:07.99962Z",
     "shell.execute_reply": "2024-08-02T10:08:07.998747Z",
     "shell.execute_reply.started": "2024-08-02T10:08:07.992357Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 保存された重みとバイアスを読み込みます\n",
    "dense_1_weights = np.load('/kaggle/input/tf-gemma-2-9b-lmsys-training-tpu/dense_1_kernel.npy')  # 重みを読み込み\n",
    "dense_1_biases = np.load('/kaggle/input/tf-gemma-2-9b-lmsys-training-tpu/dense_1_bias.npy')  # バイアスを読み込み\n",
    "\n",
    "# 読み込んだ重みとバイアスを組み合わせてリストを作成します\n",
    "dense_1_combined = [dense_1_weights, dense_1_biases]\n",
    "\n",
    "# モデルの最終レイヤーに重みを設定します\n",
    "model.layers[-1].set_weights(dense_1_combined)  # 最後のレイヤーに対して重みを設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:08.00107Z",
     "iopub.status.busy": "2024-08-02T10:08:08.000775Z",
     "iopub.status.idle": "2024-08-02T10:08:08.016858Z",
     "shell.execute_reply": "2024-08-02T10:08:08.016062Z",
     "shell.execute_reply.started": "2024-08-02T10:08:08.001047Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデル内のすべてのレイヤーをトレーニング不可に設定します\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False  # 各レイヤーのトレーニング可能フラグをFalseに設定し、重みが更新されないようにします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:08.019836Z",
     "iopub.status.busy": "2024-08-02T10:08:08.019564Z",
     "iopub.status.idle": "2024-08-02T10:08:08.056106Z",
     "shell.execute_reply": "2024-08-02T10:08:08.055248Z",
     "shell.execute_reply.started": "2024-08-02T10:08:08.019813Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの概要を表示します\n",
    "model.summary()  # モデルのアーキテクチャ、レイヤーの数、パラメータ数などの情報を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:08.057475Z",
     "iopub.status.busy": "2024-08-02T10:08:08.057106Z",
     "iopub.status.idle": "2024-08-02T10:08:08.314362Z",
     "shell.execute_reply": "2024-08-02T10:08:08.313418Z",
     "shell.execute_reply.started": "2024-08-02T10:08:08.057442Z"
    }
   },
   "outputs": [],
   "source": [
    "# テンソルスライスからデータセットを作成し、前処理関数を適用してバッチ化します\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_dataset.text.values))  # トレーニングデータのテキストをスライスしてデータセットを作成\n",
    "ds = ds.map(preprocess_fn)  # 前処理関数を適用します\n",
    "ds = ds.batch(16)  # バッチサイズを16に設定してデータをバッチ化します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:08.316884Z",
     "iopub.status.busy": "2024-08-02T10:08:08.316494Z",
     "iopub.status.idle": "2024-08-02T10:08:18.142255Z",
     "shell.execute_reply": "2024-08-02T10:08:18.141277Z",
     "shell.execute_reply.started": "2024-08-02T10:08:08.316845Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 予測結果を保存するリストを初期化します\n",
    "preds = []\n",
    "\n",
    "# データセットに対して予測を行います\n",
    "for inputs in tqdm(ds):  # 進行状況を表示しながらデータセットをイテレート\n",
    "    keras.backend.clear_session(free_memory=True)  # セッションをクリアしてメモリを解放します\n",
    "    preds.append(model(inputs))  # モデルを使用して入力データから予測を行い、結果をリストに追加します\n",
    "    keras.backend.clear_session()  # 再びセッションをクリアしてメモリを解放します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:18.143999Z",
     "iopub.status.busy": "2024-08-02T10:08:18.143736Z",
     "iopub.status.idle": "2024-08-02T10:08:18.213278Z",
     "shell.execute_reply": "2024-08-02T10:08:18.212267Z",
     "shell.execute_reply.started": "2024-08-02T10:08:18.143977Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 予測結果を連結します\n",
    "results = np.concatenate(preds)  # リストに格納された予測結果を一つの配列にまとめます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:18.21479Z",
     "iopub.status.busy": "2024-08-02T10:08:18.214493Z",
     "iopub.status.idle": "2024-08-02T10:08:18.219869Z",
     "shell.execute_reply": "2024-08-02T10:08:18.218877Z",
     "shell.execute_reply.started": "2024-08-02T10:08:18.214767Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "# 予測結果をDataFrameに変換します\n",
    "submission = pandas.DataFrame(data=results, index=raw_test_dataset.id, columns=label_columns)  # 結果をDataFrameに格納し、インデックスをテストデータセットのIDに設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:18.221322Z",
     "iopub.status.busy": "2024-08-02T10:08:18.221006Z",
     "iopub.status.idle": "2024-08-02T10:08:18.232322Z",
     "shell.execute_reply": "2024-08-02T10:08:18.231557Z",
     "shell.execute_reply.started": "2024-08-02T10:08:18.221298Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用ファイルをCSV形式で保存します\n",
    "submission.to_csv('submission.csv', index=False)  # インデックスを含めずに'submission.csv'として保存します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-02T10:08:18.234335Z",
     "iopub.status.busy": "2024-08-02T10:08:18.233568Z",
     "iopub.status.idle": "2024-08-02T10:08:18.24813Z",
     "shell.execute_reply": "2024-08-02T10:08:18.247248Z",
     "shell.execute_reply.started": "2024-08-02T10:08:18.234303Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用DataFrameの最初の5行を表示します\n",
    "submission.head()  # DataFrameの冒頭の内容を確認して、予測結果が正しく保存されているか確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# このセルにはコードが含まれていません。必要な処理やデータをここに追加してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1b1a5b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# コメント\n",
    "\n",
    "> ## ano\n",
    "> \n",
    "> ノートブックのバージョン18を2回提出しました。どちらもタイムアウトによるエラー提出となりました。コードを改善してスピードを上げる必要があります。とにかく、素晴らしいスタートですね！\n",
    "> \n",
    "> \n",
    "> \n",
    "> > ## Pranshu Bahadur（トピック著者）\n",
    "> > \n",
    "> > そうですね…バージョン19がタイムアウトしないことを願っています。スピードアップのために何か提案はありますか？\n",
    "> > \n",
    "> > \n",
    "> > \n",
    "> > > ## ano\n",
    "> > > \n",
    "> > > 一番最初に思い浮かんだのは、[このノートブック](https://www.kaggle.com/code/emiz6413/inference-gemma-2-9b-4-bit-qlora?scriptVersionId=187740026)のような並列計算です。cuda 0のモデルとcuda 1のモデルを使い、スレッドプールを使って同時に推論します。しかし、100%確実とは言えません。コードを書くことはできますが、正直言って私はLLMやkeras_nlpなどに新しいです…\n",
    "> > > \n",
    "> > > \n",
    "> > > \n",
    "> > > ## Pranshu Bahadur（トピック著者）\n",
    "> > > \n",
    "> > > スレッドプールに関して調べてみます。何らかの形で機能するかもしれません。正直、私もLLMについてはとても新しいですが、実装を通じて学んでいます！\n",
    "> > > \n",
    "> > > \n",
    "\n",
    "---\n",
    "\n",
    "> ## carvingfate\n",
    "> \n",
    "> 素晴らしい仕事です！Gemma-2は最近のバージョンのトランスフォーマーが必要で、これが原因で古いクラウドGPUプラットフォームでのトレーニング中に多くの問題が発生しました。コードを共有してくれてありがとう。\n",
    "> \n",
    "> \n",
    "\n",
    "---\n",
    "\n",
    "> ## Lorry Zou\n",
    "> \n",
    "> 今日は土曜日です。提出の成功はありましたか？\n",
    "> \n",
    "> \n",
    "> \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "sourceId": 190099209,
     "sourceType": "kernelVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 57466,
     "sourceId": 69834,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
