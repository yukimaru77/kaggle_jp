{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05b4562a",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、KerasおよびKerasNLPを使用して、LMSYS - Chatbot Arenaコンペティションにおける人間による好み予測のためのモデルを構築するスターターノートブックです。具体的には、LLM（大規模言語モデル）によって生成されたチャットボットの応答に対して、どの応答がユーザーに好まれるかを予測する問題に取り組んでいます。\n",
    "\n",
    "## 問題\n",
    "コンペティションの目的は、ユーザーが提示するプロンプトに対して複数の応答から選んだ場合に、その選ばれる可能性の高い応答を予測することです。これは、多数のLLMからの応答に基づいて行われます。\n",
    "\n",
    "## 使用している手法\n",
    "このノートブックでは、**DebertaV3**というモデルをファインチューニングし、選択肢問題の形式で応答を処理しています。具体的には、各プロンプトと応答をペアで使用し、LLMがどの応答を好ましく評価するかを学習します。モデルにはKerasNLPを使用し、混合精度トレーニングを利用することでトレーニング時間を短縮し、GPUのメモリ使用量を減らしています。\n",
    "\n",
    "## 使用しているライブラリ\n",
    "- **Keras**: モデルの構築とトレーニングに使用され、ユーザーが指定したバックエンド（TensorFlow、PyTorch、JAX）を選択して使用できます。\n",
    "- **KerasNLP**: NLPのために設計されたKerasのサブライブラリで、特にDebertaV3のような様々な事前学習モデルの実装を提供しています。\n",
    "- **TensorFlow**: モデルのトレーニングと評価を行うためのエコシステム。\n",
    "- **NumPy/Pandas**: データ操作および分析に使用。\n",
    "- **Matplotlib/Plotly**: データの可視化に使用。\n",
    "\n",
    "## その他\n",
    "ノートブックは、データの読み込みから前処理、モデル構築、訓練、予測、提出ファイルの作成までのプロセスが詳細に示されており、各ステップでのコードが含まれています。多段階のアプローチを取り入れており、最良のモデル評価を行うためのチェックポイントも設定されています。また、今後の改善ポイントとして、大規模モデルへの拡大、クロスバリデーション、応答の順序シャッフル、エポック数の増加などが提案されています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb6da78",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookに関連する専門用語の簡単な解説です。特に、初心者がつまずきやすい詳細や実務経験がないと馴染みが薄いものに焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **ファインチューニング (Fine-tuning)**:\n",
    "   事前に学習したモデルに新たなデータを用いて追加の学習を行うこと。特に転移学習の文脈で、新しいタスクに特化させるために用いられる。\n",
    "\n",
    "2. **混合精度 (Mixed Precision)**:\n",
    "   トレーニング時に異なる精度のデータ型を混ぜて使用する技術。通常、計算処理の効率を高め、GPUメモリの使用量を削減するために使用される。たとえば、`float16`（半精度）と`float32`（単精度）を組み合わせることが一般的。\n",
    "\n",
    "3. **前処理器 (Preprocessor)**:\n",
    "   生データを機械学習モデルの入力として使用できる形式に変換するためのツール。具体的には、トークン化、正規化、パディング等が含まれる。\n",
    "\n",
    "4. **トークン化 (Tokenization)**:\n",
    "   生のテキストデータを意味のある単位（トークン）に分割するプロセス。これにより、テキストをモデルが理解しやすい形式に変換できる。\n",
    "\n",
    "5. **パディング (Padding)**:\n",
    "   シーケンスの長さを一定にするために、短いシーケンスに追加のトークン（通常はゼロ）を付与すること。これにより、ミニバッチ処理を効率的に行うことが可能になる。\n",
    "\n",
    "6. **エンコーディング (Encoding)**:\n",
    "   文字列データを数値データに変換するプロセス。特に、モデルがテキストを処理できる形式に変換するために重要で、UTF-8などの標準的な文字エンコーディングが使われる。\n",
    "\n",
    "7. **層別化 (Stratification)**:\n",
    "   データを分割する際に、特定の属性に基づいてその分布を保つようにすること。特に、異なるクラスのデータサンプルが均等に分割されるようにするために使用される。\n",
    "\n",
    "8. **ロス (Loss)**:\n",
    "   モデルの予測が正解とどれだけ乖離しているかを示す指標。学習中はこの値を最小化することを目的とする。`ログロス`は特に、クラス確率の予測精度を測るために用いられる。\n",
    "\n",
    "9. **ウェイトシェアリング (Weight Sharing)**:\n",
    "   複数の部分で同一の重みを共有すること。特に、同じ入力形式の異なる部分（例えば、異なる応答の処理）に同じモデルのパラメータを使用する手法。\n",
    "\n",
    "10. **メトリック (Metric)**:\n",
    "    モデルのパフォーマンスを評価するために使用される指標。精度やロスなど、モデルの性能を測るために選択される。\n",
    "\n",
    "11. **入力層 (Input Layer)**:\n",
    "    モデルにデータを供給するための層で、データの特徴を定義します。形状やデータ型が指定されることが一般的です。\n",
    "\n",
    "12. **グローバル平均プーリング (Global Average Pooling)**:\n",
    "    特徴マップ全体の平均を計算して出力する層。これにより、シーケンスや画像の情報を圧縮し、過剰適合を防ぐ手助けがされる。\n",
    "\n",
    "これらの用語は、特に実務経験がない初学者にとっては馴染みが薄いものが多いですが、理解が深まると同時に機械学習や深層学習の実践的なスキル向上に役立ちます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec678ab2",
   "metadata": {},
   "source": [
    "<center><img src=\"https://keras.io/img/logo-small.png\" alt=\"Kerasのロゴ\" width=\"100\"><br/>\n",
    "このスターターノートブックはKerasチームによって提供されています。</center>\n",
    "\n",
    "# LMSYS - Chatbot Arena 人間による好み予測 [KerasNLP](https://github.com/keras-team/keras-nlp) と [Keras](https://github.com/keras-team/keras) を使用\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.ibb.co/wJMF5HL/lmsys.png\">\n",
    "</div>\n",
    "\n",
    "このコンペティションでは、我々の目的は、LLM（大規模言語モデル）によって動かされるチャットボット同士の対戦において、どのLLMの応答がユーザーに好まれるかを予測することです。言い換えれば、このコンペティションの目標は、審査員の好みを予測し、特定のプロンプト/応答ペアが勝者として選ばれる可能性を決定することです。このノートブックでは、KerasNLPを使用して、このコンペティションのために**DebertaV3**モデルをファインチューニングするプロセスを案内します。この戦略は、選択肢問題（MCQ）モデルがトレーニングされる方法に似ています。さらに、トレーニングと推論を迅速化するために混合精度を使用します。\n",
    "\n",
    "**ご存知でしたか**: このノートブックはバックエンドに依存しないため、TensorFlow、PyTorch、JAXのいずれのバックエンドにも対応しています。ただし、最良のパフォーマンスを達成するには `JAX` を使用することをお勧めします。KerasNLPとKerasは、好みのバックエンドを選択することを可能にしています。さらなる詳細は[Keras](https://keras.io/keras_3/)で確認してください。\n",
    "\n",
    "**注意**: KerasNLPについてのより深い理解を得るためには、[KerasNLPガイド](https://keras.io/keras_nlp/)を参照してください。\n",
    "\n",
    "# 📚 | ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:09.411574Z",
     "iopub.status.busy": "2024-07-03T03:01:09.410774Z",
     "iopub.status.idle": "2024-07-03T03:01:09.417451Z",
     "shell.execute_reply": "2024-07-03T03:01:09.416382Z",
     "shell.execute_reply.started": "2024-07-03T03:01:09.411539Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Kerasのバックエンドを\"jax\"に設定します。\n",
    "# \"tensorflow\" または \"torch\" を使用することもできます。\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # または \"tensorflow\" または \"torch\"\n",
    "\n",
    "# KerasNLPライブラリをインポートします。\n",
    "import keras_nlp\n",
    "# Kerasライブラリをインポートします。\n",
    "import keras\n",
    "# TensorFlowライブラリをインポートします。\n",
    "import tensorflow as tf\n",
    "\n",
    "# 数値計算のためのNumPyライブラリをインポートします。\n",
    "import numpy as np \n",
    "# データ操作のためのPandasライブラリをインポートします。\n",
    "import pandas as pd\n",
    "# プログレスバーの表示のためのtqdmライブラリをインポートします。\n",
    "from tqdm import tqdm\n",
    "# JSON操作のためのjsonライブラリをインポートします。\n",
    "import json\n",
    "\n",
    "# グラフ描画のためのMatplotlibライブラリをインポートします。\n",
    "import matplotlib.pyplot as plt\n",
    "# Matplotlibの設定を行うためのmplモジュールをインポートします。\n",
    "import matplotlib as mpl\n",
    "# Plotlyでインタラクティブなグラフを作成するためのexpressモジュールをインポートします。\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8c5640",
   "metadata": {},
   "source": [
    "## ライブラリのバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:20.664741Z",
     "iopub.status.busy": "2024-07-03T03:01:20.663852Z",
     "iopub.status.idle": "2024-07-03T03:01:20.670008Z",
     "shell.execute_reply": "2024-07-03T03:01:20.668776Z",
     "shell.execute_reply.started": "2024-07-03T03:01:20.664707Z"
    }
   },
   "outputs": [],
   "source": [
    "# 現在のTensorFlowのバージョンを出力します。\n",
    "print(\"TensorFlow:\", tf.__version__)\n",
    "# 現在のKerasのバージョンを出力します。\n",
    "print(\"Keras:\", keras.__version__)\n",
    "# 現在のKerasNLPのバージョンを出力します。\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6324e097",
   "metadata": {},
   "source": [
    "# ⚙️ | 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:22.100663Z",
     "iopub.status.busy": "2024-07-03T03:01:22.100299Z",
     "iopub.status.idle": "2024-07-03T03:01:22.106816Z",
     "shell.execute_reply": "2024-07-03T03:01:22.105711Z",
     "shell.execute_reply.started": "2024-07-03T03:01:22.100634Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    # ランダムシードを設定します。\n",
    "    seed = 42  # ランダムシード\n",
    "    # 使用する事前トレーニングモデルの名前を指定します。\n",
    "    preset = \"deberta_v3_extra_small_en\" # 事前トレーニングモデルの名前\n",
    "    # 入力シーケンスの長さを設定します。\n",
    "    sequence_length = 512  # 入力シーケンスの長さ\n",
    "    # トレーニングエポックの数を設定します。\n",
    "    epochs = 3 # トレーニングエポック数\n",
    "    # バッチサイズを指定します。\n",
    "    batch_size = 16  # バッチサイズ\n",
    "    # 学習率スケジューラのタイプを設定します。\n",
    "    scheduler = 'cosine'  # 学習率スケジューラ\n",
    "    # ラベルとその名前の対応を定義します。\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n",
    "    # 名前からラベルを取得する辞書を作成します。\n",
    "    name2label = {v:k for k, v in label2name.items()}\n",
    "    # クラスラベルのリストを作成します。\n",
    "    class_labels = list(label2name.keys())\n",
    "    # クラス名のリストを作成します。\n",
    "    class_names = list(label2name.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59d3363",
   "metadata": {},
   "source": [
    "# ♻️ | 再現性\n",
    "ランダムシードの値を設定して、各実行で類似した結果を得られるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:23.340681Z",
     "iopub.status.busy": "2024-07-03T03:01:23.340338Z",
     "iopub.status.idle": "2024-07-03T03:01:23.34536Z",
     "shell.execute_reply": "2024-07-03T03:01:23.344456Z",
     "shell.execute_reply.started": "2024-07-03T03:01:23.340653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasで使用するランダムシードを設定します。\n",
    "keras.utils.set_random_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798dc62",
   "metadata": {},
   "source": [
    "# 🧮 | 混合精度\n",
    "\n",
    "このノートブックでは、トレーニングと推論の際にfloat32精度の代わりに混合精度を使用して、GPUメモリの使用量を削減します。これにより、より大きなバッチサイズを使用できるようになり、トレーニングと推論の時間を短縮することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:34.266272Z",
     "iopub.status.busy": "2024-07-03T03:01:34.265925Z",
     "iopub.status.idle": "2024-07-03T03:01:34.270737Z",
     "shell.execute_reply": "2024-07-03T03:01:34.269676Z",
     "shell.execute_reply.started": "2024-07-03T03:01:34.266246Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasの全体的なポリシーを混合精度（mixed_float16）に設定します。\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd6b11",
   "metadata": {},
   "source": [
    "# 📁 | データセットのパス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:39.653268Z",
     "iopub.status.busy": "2024-07-03T03:01:39.652928Z",
     "iopub.status.idle": "2024-07-03T03:01:39.657264Z",
     "shell.execute_reply": "2024-07-03T03:01:39.656349Z",
     "shell.execute_reply.started": "2024-07-03T03:01:39.653242Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットのベースパスを設定します。\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6b4c8",
   "metadata": {},
   "source": [
    "# 📖 | メタデータ\n",
    "\n",
    "コンペティションのデータセットは、ChatBot Arenaからのユーザーのインタラクションで構成されています。各インタラクションでは、審査員が2つの異なる大規模言語モデルに対して1つ以上のプロンプトを提示し、どのモデルがより満足のいく応答を提供したかを示します。トレーニングデータには`55,000`行が含まれており、テストセットには約`25,000`行が期待されています。\n",
    "\n",
    "## ファイル\n",
    "\n",
    "### `train.csv`\n",
    "- `id`: 各行の一意の識別子。\n",
    "- `model_[a/b]`: モデルの識別子。train.csvには存在しますが、test.csvには存在しません。\n",
    "- `prompt`: 両方のモデルに与えられる入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。\n",
    "- `winner_model_[a/b/tie]`: 審査員の選択（正解ターゲット）を示すバイナリ列。\n",
    "\n",
    "### `test.csv`\n",
    "- `id`: 各行の一意の識別子。\n",
    "- `prompt`: 両方のモデルに与えられる入力プロンプト。\n",
    "- `response_[a/b]`: モデル_[a/b]のプロンプトに対する応答。\n",
    "\n",
    "> 注意: 各インタラクションには複数のプロンプトと応答がある場合がありますが、このノートブックでは**各インタラクションにつき1つのプロンプト**のみを使用します。すべてのプロンプトと応答を使用することもできます。また、データフレーム内のプロンプトと応答は文字列形式のリストとして提供されているため、`eval()`を使用してリテラルリストに変換する必要があります。\n",
    "\n",
    "## トレーニングデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:01:41.865573Z",
     "iopub.status.busy": "2024-07-03T03:01:41.865244Z",
     "iopub.status.idle": "2024-07-03T03:01:49.241992Z",
     "shell.execute_reply": "2024-07-03T03:01:49.24084Z",
     "shell.execute_reply.started": "2024-07-03T03:01:41.865549Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータを読み込みます。\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv') \n",
    "\n",
    "# サンプルデータ\n",
    "# df = df.sample(frac=0.10)\n",
    "\n",
    "# 最初のプロンプトとその関連する応答を取得します。\n",
    "df[\"prompt\"] = df.prompt.map(lambda x: eval(x)[0])\n",
    "df[\"response_a\"] = df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "df[\"response_b\"] = df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# ラベルの変換を行います。\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)\n",
    "\n",
    "# サンプルを表示します。\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99f3e37",
   "metadata": {},
   "source": [
    "## テストデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:00.748821Z",
     "iopub.status.busy": "2024-07-03T03:02:00.748482Z",
     "iopub.status.idle": "2024-07-03T03:02:00.766516Z",
     "shell.execute_reply": "2024-07-03T03:02:00.765701Z",
     "shell.execute_reply.started": "2024-07-03T03:02:00.748794Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータを読み込みます。\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n",
    "\n",
    "# 最初のプロンプトと応答を取得します。\n",
    "test_df[\"prompt\"] = test_df.prompt.map(lambda x: eval(x)[0])\n",
    "test_df[\"response_a\"] = test_df.response_a.map(lambda x: eval(x.replace(\"null\",\"''\"))[0])\n",
    "test_df[\"response_b\"] = test_df.response_b.map(lambda x: eval(x.replace(\"null\", \"''\"))[0])\n",
    "\n",
    "# サンプルを表示します。\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40b9b3",
   "metadata": {},
   "source": [
    "## プロンプトによる応答の文脈化\n",
    "\n",
    "我々のアプローチでは、すべての応答に対して単一のプロンプトを使用するのではなく、各応答をプロンプトで文脈化します。つまり、各応答に対して、モデルにそれぞれの応答と組み合わせた同じセットのプロンプトを提供することになります（例: `(P + R_A)`、`(P + R_B)`など）。このアプローチは、NLPにおける選択肢問題のタスクに類似しています。\n",
    "\n",
    "> 注意: 一部のプロンプトや応答が`utf-8`でエンコードされていない場合、データローダーを作成する際にエラーが発生することがあります。その場合、空の文字列に置き換えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:03.654162Z",
     "iopub.status.busy": "2024-07-03T03:02:03.653385Z",
     "iopub.status.idle": "2024-07-03T03:02:03.660622Z",
     "shell.execute_reply": "2024-07-03T03:02:03.659762Z",
     "shell.execute_reply.started": "2024-07-03T03:02:03.654128Z"
    }
   },
   "outputs": [],
   "source": [
    "# プロンプトと選択肢に基づいてオプションを作成する関数を定義します。\n",
    "def make_pairs(row):\n",
    "    row[\"encode_fail\"] = False\n",
    "    try:\n",
    "        # プロンプトをUTF-8でエンコードし、デコードします。\n",
    "        prompt = row.prompt.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # エンコードに失敗した場合は空の文字列にします。\n",
    "        prompt = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # モデルAの応答をUTF-8でエンコードし、デコードします。\n",
    "        response_a = row.response_a.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # エンコードに失敗した場合は空の文字列にします。\n",
    "        response_a = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "\n",
    "    try:\n",
    "        # モデルBの応答をUTF-8でエンコードし、デコードします。\n",
    "        response_b = row.response_b.encode(\"utf-8\").decode(\"utf-8\")\n",
    "    except:\n",
    "        # エンコードに失敗した場合は空の文字列にします。\n",
    "        response_b = \"\"\n",
    "        row[\"encode_fail\"] = True\n",
    "        \n",
    "    # プロンプトと応答を組み合わせたオプションを作成します。\n",
    "    row['options'] = [f\"Prompt: {prompt}\\n\\nResponse: {response_a}\",  # モデルAからの応答\n",
    "                      f\"Prompt: {prompt}\\n\\nResponse: {response_b}\"  # モデルBからの応答\n",
    "                     ]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:02:04.251033Z",
     "iopub.status.busy": "2024-07-03T03:02:04.250673Z",
     "iopub.status.idle": "2024-07-03T03:03:06.883282Z",
     "shell.execute_reply": "2024-07-03T03:03:06.882333Z",
     "shell.execute_reply.started": "2024-07-03T03:02:04.251004Z"
    }
   },
   "outputs": [],
   "source": [
    "# make_pairs関数をdfの各行に適用します。\n",
    "df = df.apply(make_pairs, axis=1)  \n",
    "# dfの最初の2行を表示します。\n",
    "display(df.head(2))  \n",
    "\n",
    "# make_pairs関数をtest_dfの各行に適用します。\n",
    "test_df = test_df.apply(make_pairs, axis=1)  \n",
    "# test_dfの最初の2行を表示します。\n",
    "display(test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e34ac",
   "metadata": {},
   "source": [
    "## エンコーディング失敗統計\n",
    "\n",
    "エンコーディングの問題があるサンプル数を確認してみましょう。以下のコードから、エンコーディングに失敗したサンプルはわずか$1\\%$であり、$99\\%$のサンプルには問題がないことがわかります。テストデータでも同様の傾向が期待できます。このため、データのごく一部を空の文字列として扱っても、トレーニングや推論に大きな影響はないでしょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:25.535096Z",
     "iopub.status.busy": "2024-07-03T03:03:25.534482Z",
     "iopub.status.idle": "2024-07-03T03:03:25.5487Z",
     "shell.execute_reply": "2024-07-03T03:03:25.547732Z",
     "shell.execute_reply.started": "2024-07-03T03:03:25.535061Z"
    }
   },
   "outputs": [],
   "source": [
    "# エンコーディング失敗の統計をカウントします。\n",
    "df.encode_fail.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b624d29",
   "metadata": {},
   "source": [
    "# 🎨 | 探索的データ分析 (EDA)\n",
    "\n",
    "## LLMの分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:28.92519Z",
     "iopub.status.busy": "2024-07-03T03:03:28.924349Z",
     "iopub.status.idle": "2024-07-03T03:03:30.427658Z",
     "shell.execute_reply": "2024-07-03T03:03:30.426828Z",
     "shell.execute_reply.started": "2024-07-03T03:03:28.925156Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルAとモデルBのデータを結合します。\n",
    "model_df = pd.concat([df.model_a, df.model_b])\n",
    "# 各モデルのカウントを取得します。\n",
    "counts = model_df.value_counts().reset_index()\n",
    "counts.columns = ['LLM', 'Count']\n",
    "\n",
    "# Plotlyを使用してカスタムスタイリングの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='LLMの分布',\n",
    "             color='Count', color_continuous_scale='viridis')\n",
    "\n",
    "# x軸ラベルを回転させて、読みやすくします。\n",
    "fig.update_layout(xaxis_tickangle=-45)  \n",
    "\n",
    "# グラフを表示します。\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2bfa71",
   "metadata": {},
   "source": [
    "## 勝利の分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:32.598799Z",
     "iopub.status.busy": "2024-07-03T03:03:32.598445Z",
     "iopub.status.idle": "2024-07-03T03:03:32.699131Z",
     "shell.execute_reply": "2024-07-03T03:03:32.698246Z",
     "shell.execute_reply.started": "2024-07-03T03:03:32.59877Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者のカウントを取得します。\n",
    "counts = df['class_name'].value_counts().reset_index()\n",
    "counts.columns = ['Winner', 'Win Count']\n",
    "\n",
    "# トレーニングデータの勝者分布を示す棒グラフを作成します。\n",
    "fig = px.bar(counts, x='Winner', y='Win Count',\n",
    "             title='トレーニングデータの勝者分布',\n",
    "             labels={'Winner': '勝者', 'Win Count': '勝利の数'},\n",
    "             color='Winner', color_continuous_scale='viridis')\n",
    "\n",
    "# x軸とy軸のタイトルを設定します。\n",
    "fig.update_layout(xaxis_title=\"勝者\", yaxis_title=\"勝利の数\")\n",
    "\n",
    "# グラフを表示します。\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138afa67",
   "metadata": {},
   "source": [
    "# 🔪 | データ分割\n",
    "\n",
    "以下のコードスニペットでは、`class_label`列の層別化を使用して、既存のデータをトレーニングデータと検証データに分割します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:34.279102Z",
     "iopub.status.busy": "2024-07-03T03:03:34.278745Z",
     "iopub.status.idle": "2024-07-03T03:03:35.091617Z",
     "shell.execute_reply": "2024-07-03T03:03:35.090834Z",
     "shell.execute_reply.started": "2024-07-03T03:03:34.279073Z"
    }
   },
   "outputs": [],
   "source": [
    "# パッケージをインポートします。\n",
    "from sklearn.model_selection import train_test_split  # パッケージをインポート\n",
    "\n",
    "# データをトレーニングデータと検証データに分割します。\n",
    "train_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c032524",
   "metadata": {},
   "source": [
    "# 🍽️ | 前処理\n",
    "\n",
    "**何をするのか:** 前処理器は入力文字列を受け取り、それを前処理されたテンソルを含む辞書（`token_ids`, `padding_mask`）に変換します。このプロセスはトークン化から始まり、入力文字列がトークンIDのシーケンスに変換されます。\n",
    "\n",
    "**なぜ重要なのか:** 生のテキストデータは、その高次元性のためにモデル化が難しく、複雑です。テキストをトークンのコンパクトなセットに変換することで、例えば `\"The quick brown fox\"` を `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]` に変換することで、データを単純化します。多くのモデルは、特別なトークンや追加のテンソルを使用して入力を理解します。これらのトークンは、入力を分割し、パディングを特定するなどのタスクに役立ちます。すべてのシーケンスをパディングを使って同じ長さにすることで、計算効率が向上し、その後のステップがスムーズになります。\n",
    "\n",
    "**KerasNLP**で利用可能な前処理およびトークナイザー層にアクセスするには、以下のページを確認してください:\n",
    "- [前処理](https://keras.io/api/keras_nlp/preprocessing_layers/)\n",
    "- [トークナイザー](https://keras.io/api/keras_nlp/tokenizers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:38.194065Z",
     "iopub.status.busy": "2024-07-03T03:03:38.193696Z",
     "iopub.status.idle": "2024-07-03T03:03:42.601299Z",
     "shell.execute_reply": "2024-07-03T03:03:42.600413Z",
     "shell.execute_reply.started": "2024-07-03T03:03:38.194034Z"
    }
   },
   "outputs": [],
   "source": [
    "# DebertaV3モデルの前処理器を設定します。\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    preset=CFG.preset, # モデルの名前\n",
    "    sequence_length=CFG.sequence_length, # 最大シーケンス長、短い場合はパディングされる\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00083ff6",
   "metadata": {},
   "source": [
    "次に、前処理層の出力形状がどのようになるかを確認しましょう。層の出力形状は $(num\\_responses, sequence\\_length)$ として表されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:44.404213Z",
     "iopub.status.busy": "2024-07-03T03:03:44.403854Z",
     "iopub.status.idle": "2024-07-03T03:03:45.484601Z",
     "shell.execute_reply": "2024-07-03T03:03:45.483734Z",
     "shell.execute_reply.started": "2024-07-03T03:03:44.404184Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最初の行のオプションを処理します。\n",
    "outs = preprocessor(df.options.iloc[0])  \n",
    "\n",
    "# 各処理された出力の形状を表示します。\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa1dcc",
   "metadata": {},
   "source": [
    "`preprocessing_fn`関数を使用して、`dataset.map(preprocessing_fn)`メソッドを介して各テキストオプションを変換します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:51.848513Z",
     "iopub.status.busy": "2024-07-03T03:03:51.848175Z",
     "iopub.status.idle": "2024-07-03T03:03:51.853591Z",
     "shell.execute_reply": "2024-07-03T03:03:51.852609Z",
     "shell.execute_reply.started": "2024-07-03T03:03:51.848488Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストを前処理するための関数を定義します。\n",
    "def preprocess_fn(text, label=None):\n",
    "    # テキストを前処理します。\n",
    "    text = preprocessor(text)  \n",
    "    # ラベルが利用可能であれば、処理されたテキストとラベルを返します。\n",
    "    return (text, label) if label is not None else text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a2c061",
   "metadata": {},
   "source": [
    "# 🍚 | データローダー\n",
    "\n",
    "以下のコードは、データ処理のために`tf.data.Dataset`を使用して堅牢なデータフローパイプラインを構築します。`tf.data`の主な特徴は、パイプラインの構築を簡素化し、コンポーネントをシーケンスで表現できる点です。\n",
    "\n",
    "`tf.data`に関する詳細は、この[ドキュメント](https://www.tensorflow.org/guide/data)を参照してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:03:55.445788Z",
     "iopub.status.busy": "2024-07-03T03:03:55.445396Z",
     "iopub.status.idle": "2024-07-03T03:03:55.454007Z",
     "shell.execute_reply": "2024-07-03T03:03:55.452986Z",
     "shell.execute_reply.started": "2024-07-03T03:03:55.445757Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストとラベルを使用してデータセットを構築する関数を定義します。\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNEオプション\n",
    "    # ラベルが指定されていない場合、slicesをテキストのタプルに設定します。\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # スライスを作成\n",
    "    # スライスからデータセットを作成します。\n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  \n",
    "    # キャッシュが有効な場合、データセットをキャッシュします。\n",
    "    ds = ds.cache() if cache else ds  \n",
    "    # 前処理関数をマッピングします。\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  \n",
    "    opt = tf.data.Options()  # データセットオプションを作成\n",
    "    if shuffle: \n",
    "        # シャッフルが有効な場合、データセットをシャッフルします。\n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  \n",
    "        opt.experimental_deterministic = False\n",
    "    # データセットオプションを設定します。\n",
    "    ds = ds.with_options(opt)  \n",
    "    # データセットをバッチ化します。\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  \n",
    "    # 次のバッチをプリフェッチします。\n",
    "    ds = ds.prefetch(AUTO)  \n",
    "    return ds  # 構築されたデータセットを返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17d028",
   "metadata": {},
   "source": [
    "## トレーニング/検証データローダーの構築"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:07.792009Z",
     "iopub.status.busy": "2024-07-03T03:06:07.791295Z",
     "iopub.status.idle": "2024-07-03T03:06:13.267405Z",
     "shell.execute_reply": "2024-07-03T03:06:13.266631Z",
     "shell.execute_reply.started": "2024-07-03T03:06:07.791974Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータのテキストとラベルを抽出します。\n",
    "train_texts = train_df.options.tolist()  # トレーニングテキストを抽出\n",
    "train_labels = train_df.class_label.tolist()  # トレーニングラベルを抽出\n",
    "# トレーニングデータローダーを構築します。\n",
    "train_ds = build_dataset(train_texts, train_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# 検証データのテキストとラベルを抽出します。\n",
    "valid_texts = valid_df.options.tolist()  # 検証テキストを抽出\n",
    "valid_labels = valid_df.class_label.tolist()  # 検証ラベルを抽出\n",
    "# 検証データローダーを構築します。\n",
    "valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                         batch_size=CFG.batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec52d95",
   "metadata": {},
   "source": [
    "# ⚓ | 学習率スケジュール\n",
    "\n",
    "学習率スケジューラーの実装は、転移学習において非常に重要です。学習率は`lr_start`から始まり、さまざまな手法を用いて徐々に`lr_min`まで減少します。手法には以下が含まれます:\n",
    "- `step`: ステップ状に学習率を下げる方法で、階段のように見えます。\n",
    "- `cos`: コサインカーブを利用して、学習率を徐々に減少させる方法です。\n",
    "- `exp`: 学習率を指数的に減少させる方法です。\n",
    "\n",
    "**重要性:** 適切に構築された学習率スケジュールは、効率的なモデルのトレーニングに不可欠であり、最適な収束を保証し、オーバーシュートや停滞といった問題を避けるのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:18.470471Z",
     "iopub.status.busy": "2024-07-03T03:06:18.470112Z",
     "iopub.status.idle": "2024-07-03T03:06:18.481152Z",
     "shell.execute_reply": "2024-07-03T03:06:18.48017Z",
     "shell.execute_reply.started": "2024-07-03T03:06:18.470441Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# 学習率コールバックを取得する関数を定義します。\n",
    "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
    "    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6  # 学習率の開始、最大、最小値を設定\n",
    "    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8  # 学習率ランプのエポック数、持続エポック数、減衰率を設定\n",
    "\n",
    "    def lrfn(epoch):  # 学習率更新関数\n",
    "        if epoch < lr_ramp_ep: \n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start  # ランプアップ\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: \n",
    "            lr = lr_max  # 最大値で維持\n",
    "        elif mode == 'exp': \n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min  # 指数減衰\n",
    "        elif mode == 'step': \n",
    "            lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)  # ステップ減衰\n",
    "        elif mode == 'cos':\n",
    "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
    "            phase = math.pi * decay_epoch_index / decay_total_epochs  # コサイン減衰\n",
    "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
    "        return lr\n",
    "\n",
    "    if plot:  # plotがTrueの場合、学習率曲線をプロットします。\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
    "        plt.xlabel('epoch'); plt.ylabel('lr')\n",
    "        plt.title('学習率スケジューラ')\n",
    "        plt.show()\n",
    "\n",
    "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # 学習率コールバックを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:21.533106Z",
     "iopub.status.busy": "2024-07-03T03:06:21.532624Z",
     "iopub.status.idle": "2024-07-03T03:06:21.825406Z",
     "shell.execute_reply": "2024-07-03T03:06:21.824443Z",
     "shell.execute_reply.started": "2024-07-03T03:06:21.533073Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習率コールバックを取得します。プロットを表示します。\n",
    "lr_cb = get_lr_callback(CFG.batch_size, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8e8766",
   "metadata": {},
   "source": [
    "# 💾 | モデルチェックポイント\n",
    "\n",
    "以下のコードは、トレーニング中にモデルの最良のチェックポイントを保存するコールバックを作成します。このチェックポイントは、提出時の推論に使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:24.427293Z",
     "iopub.status.busy": "2024-07-03T03:06:24.426939Z",
     "iopub.status.idle": "2024-07-03T03:06:24.432176Z",
     "shell.execute_reply": "2024-07-03T03:06:24.431208Z",
     "shell.execute_reply.started": "2024-07-03T03:06:24.427265Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルチェックポイントコールバックを取得します。\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n",
    "                                          monitor='val_log_loss',  # 検証ロスを監視\n",
    "                                          save_best_only=True,  # 最良のみを保存\n",
    "                                          save_weights_only=True,  # 重みのみを保存\n",
    "                                          mode='min')  # 最小値で監視"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcdf555",
   "metadata": {},
   "source": [
    "# 📏 | メトリック\n",
    "\n",
    "このコンペティションのメトリックは**ログロス**です。このメトリックは数学的に次のように表されます。\n",
    "\n",
    "$$\n",
    "\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n",
    "$$\n",
    "\n",
    "ここで、$ N $はサンプルの数、$ y_i $は真のラベル、$ p_i $はサンプルが正のクラスに属する予測確率です。\n",
    "\n",
    "このメトリックは、分類タスクで広く使用されるカテゴリカルクロスエントロピーに似ています。したがって、ロスをゼロから実装する必要はありません。Kerasライブラリにはこのメトリックの実装が既にあるため、単にこのメトリックを使用してモデルの性能を監視します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:26.316344Z",
     "iopub.status.busy": "2024-07-03T03:06:26.315994Z",
     "iopub.status.idle": "2024-07-03T03:06:26.340548Z",
     "shell.execute_reply": "2024-07-03T03:06:26.339407Z",
     "shell.execute_reply.started": "2024-07-03T03:06:26.316317Z"
    }
   },
   "outputs": [],
   "source": [
    "# ログロスメトリックをKerasのCategoricalCrossentropyとして定義します。\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5daf74",
   "metadata": {},
   "source": [
    "# 🤖 | モデリング\n",
    "\n",
    "`KerasNLP`ライブラリは、`Bert`、`Roberta`、`DebertaV3`などのさまざまなNLPモデルアーキテクチャを提供します。このノートブックでは`DebertaV3`に焦点を当てていますが、他のモデルは[KerasNLPのドキュメント](https://keras.io/api/keras_nlp/models/)で探索できます。より深い理解のためには、[入門ガイド](https://keras.io/guides/keras_nlp/getting_started/)を参照してください。\n",
    "\n",
    "我々のアプローチでは、`keras_nlp.models.DebertaV3Classifier`を利用して各プロンプトと応答のペアを処理し、出力埋め込みを生成します。その後、これらの埋め込みを連結し、プーリング層と分類器を通してログitsを取得し、最終的な出力のために`softmax`関数を適用します。\n",
    "\n",
    "複数の応答を扱う際には、ウェイトシェアリング戦略を使用します。つまり、モデルにはプロンプトとともに1つの応答をずつ提供し、`(P + R_A)`, `(P + R_B)`などの形で全ての応答に対して同じモデルの重みを使用します。全ての応答の埋め込みを取得した後、それらを連結し、平均プーリングを適用します。次に、`Linear/Dense`層と`Softmax`関数を分類器として最終結果を取得します。一度に全ての応答を提供すると、テキストの長さが増加し、モデルの扱いが複雑になります。分類器では`winner_model_a`、`winner_model_b`、および`draw`ケースの3つのクラスを使用することに注意してください。\n",
    "\n",
    "下の図はこのアプローチを示しています：\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"https://i.postimg.cc/g0gcvy3f/Kaggle-drawio.png\">\n",
    "</div>\n",
    "\n",
    "コーディングの観点からは、図に示されているように別々のモデルではなく、共有重みを持つ同一のモデルをすべての応答に使用することに注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:28.027331Z",
     "iopub.status.busy": "2024-07-03T03:06:28.026985Z",
     "iopub.status.idle": "2024-07-03T03:06:36.425525Z",
     "shell.execute_reply": "2024-07-03T03:06:36.424584Z",
     "shell.execute_reply.started": "2024-07-03T03:06:28.027304Z"
    }
   },
   "outputs": [],
   "source": [
    "# 入力層を定義します。\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "# DebertaV3Classifierバックボーンを作成します。\n",
    "backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "    CFG.preset,\n",
    ")\n",
    "\n",
    "# 最初の応答: (P + R_A) の埋め込みをバックボーンを使用して計算します。\n",
    "response_a = {k: v[:, 0, :] for k, v in inputs.items()}\n",
    "embed_a = backbone(response_a)\n",
    "\n",
    "# 2番目の応答: (P + R_B) の埋め込みを、同じバックボーンを使用して計算します。\n",
    "response_b = {k: v[:, 1, :] for k, v in inputs.items()}\n",
    "embed_b = backbone(response_b)\n",
    "\n",
    "# 最終的な出力を計算します。\n",
    "embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])\n",
    "embeds = keras.layers.GlobalAveragePooling1D()(embeds)\n",
    "outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# オプティマイザー、損失、メトリックとともにモデルをコンパイルします。\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(5e-6),\n",
    "    loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),\n",
    "    metrics=[\n",
    "        log_loss,\n",
    "        keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814a24a",
   "metadata": {},
   "source": [
    "### モデルサマリー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:39.067045Z",
     "iopub.status.busy": "2024-07-03T03:06:39.066199Z",
     "iopub.status.idle": "2024-07-03T03:06:39.100211Z",
     "shell.execute_reply": "2024-07-03T03:06:39.099373Z",
     "shell.execute_reply.started": "2024-07-03T03:06:39.067011Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの概要を表示します。\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387c8f5e",
   "metadata": {},
   "source": [
    "### モデルのプロット\n",
    "\n",
    "以下のモデルグラフでは、**4つ**の入力があるように見えるかもしれませんが、実際には前述の通り**2つ**の入力があります。我々の入力は2つの部分から構成されており、それぞれの応答に対するものです。しかし、各入力には`token_ids`と`padding_mask`があるため、4つの入力があるように見えますが、実際には2つの入力となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:42.873525Z",
     "iopub.status.busy": "2024-07-03T03:06:42.872898Z",
     "iopub.status.idle": "2024-07-03T03:06:42.87754Z",
     "shell.execute_reply": "2024-07-03T03:06:42.87662Z",
     "shell.execute_reply.started": "2024-07-03T03:06:42.873486Z"
    }
   },
   "outputs": [],
   "source": [
    "# 現在エラーが発生しています!! [おそらくライブラリや環境の問題ですので、近いうちに修正されることを願っています]\n",
    "\n",
    "# モデルのプロットを試みますが、エラーが発生する可能性があります。\n",
    "# keras.utils.plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a3002c",
   "metadata": {},
   "source": [
    "# 🚂 | トレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-07-03T03:06:44.56032Z",
     "iopub.status.busy": "2024-07-03T03:06:44.559968Z",
     "iopub.status.idle": "2024-07-03T05:21:44.517705Z",
     "shell.execute_reply": "2024-07-03T05:21:44.516664Z",
     "shell.execute_reply.started": "2024-07-03T03:06:44.560292Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのトレーニングを開始します。\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=CFG.epochs,\n",
    "    validation_data=valid_ds,\n",
    "    callbacks=[lr_cb, ckpt_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5f95c5",
   "metadata": {},
   "source": [
    "## 最良モデルの読み込み\n",
    "\n",
    "トレーニングが完了した後、最良の結果を得るために重みを読み込み、最良のパフォーマンスを得ましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:21:46.299458Z",
     "iopub.status.busy": "2024-07-03T05:21:46.299204Z",
     "iopub.status.idle": "2024-07-03T05:21:47.893914Z",
     "shell.execute_reply": "2024-07-03T05:21:47.893141Z",
     "shell.execute_reply.started": "2024-07-03T05:21:46.299433Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最良の重みを読み込みます。\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d756bd03",
   "metadata": {},
   "source": [
    "# 🧪 | 予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:25:55.97338Z",
     "iopub.status.busy": "2024-07-03T05:25:55.973023Z",
     "iopub.status.idle": "2024-07-03T05:25:56.361133Z",
     "shell.execute_reply": "2024-07-03T05:25:56.360269Z",
     "shell.execute_reply.started": "2024-07-03T05:25:55.973356Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータセットを構築します。\n",
    "test_texts = test_df.options.tolist()\n",
    "test_ds = build_dataset(test_texts,\n",
    "                         batch_size=min(len(test_df), CFG.batch_size),\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:26:01.567019Z",
     "iopub.status.busy": "2024-07-03T05:26:01.566397Z",
     "iopub.status.idle": "2024-07-03T05:26:06.882117Z",
     "shell.execute_reply": "2024-07-03T05:26:06.881359Z",
     "shell.execute_reply.started": "2024-07-03T05:26:01.566983Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングされたモデルを使用してテストデータに対して予測を行います。\n",
    "test_preds = model.predict(test_ds, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00664232",
   "metadata": {},
   "source": [
    "# 📬 | 提出\n",
    "\n",
    "以下のコードは、提出ファイルの準備をします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-03T05:26:18.174315Z",
     "iopub.status.busy": "2024-07-03T05:26:18.173702Z",
     "iopub.status.idle": "2024-07-03T05:26:18.19321Z",
     "shell.execute_reply": "2024-07-03T05:26:18.192347Z",
     "shell.execute_reply.started": "2024-07-03T05:26:18.174283Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用のデータフレームを作成します。\n",
    "sub_df = test_df[[\"id\"]].copy()\n",
    "# 予測結果を追加します。\n",
    "sub_df[CFG.class_names] = test_preds.tolist()\n",
    "# 提出ファイルをCSV形式で保存します。\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "# 最初の数行を表示します。\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d5679c",
   "metadata": {},
   "source": [
    "# 🔭 | 今後の方向性\n",
    "\n",
    "このノートブックでは、小さなモデルと控えめなトークン長で良いスコアを達成しましたが、改善の余地はまだたくさんあります。以下の方法でさらなる向上を図ることができます：\n",
    "\n",
    "1. `Deberta-Base`や`Deberta-Small`のような大きなモデル、あるいは`Gemma`のようなLLMを試してみる。\n",
    "2. 最大トークン長を増やしてデータの損失を減らす。\n",
    "3. 5フォールドクロスバリデーションとアンサンブルを使用してモデルを堅牢にし、より良いスコアを得る。\n",
    "4. 応答の順序をシャッフルするなどの拡張を追加して、より堅牢なパフォーマンスを得る。\n",
    "5. より多くのエポックでトレーニングする。\n",
    "6. 学習率スケジューラーを調整する。\n",
    "\n",
    "# 📌 | 参考文献\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLP Starter](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
