{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4140e579",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「Chatbot Arena Competition」に参加するために設計されており、AIチャットボットの評価を行い、ユーザーの好みを予測することを目的としています。\n",
    "\n",
    "### 問題の概要\n",
    "本コンペティションでは、ユーザーのプロンプトに対して2つの異なるAIモデルが生成した応答のどちらが好まれるかを予測することが主な課題です。Notebookは、与えられたデータセットを基にし、どちらの応答がユーザーの好みに合致するかを予測するためのモデルを構築します。\n",
    "\n",
    "### 手法とライブラリ\n",
    "1. **環境の設定**: TensorFlow、Pandas、NumPy、Scikit-learnなどのライブラリを使用し、必要なパッケージをインストールします。\n",
    "2. **データのロード**: 訓練データとテストデータをCSVファイルから読み込みます。\n",
    "3. **テキストデータの前処理**: プロンプトとモデルの応答を連結してトークン化し、シーケンス化します。この際、パディングを行い、モデルの入力形式に整えます。\n",
    "4. **モデルの構築**: Kerasを使用して、LSTMネットワークを含むニューラルネットワークを構築します。プロンプトと応答を入力として受け取り、各応答の勝者を予測するための3つの出力を持つモデルを設計します。\n",
    "5. **モデルのトレーニング**: モデルを訓練データでトレーニングし、バリデーションデータを用いてその性能を確認します。\n",
    "6. **モデルの評価**: トレーニング後、検証データを用いてモデルの精度や損失を評価します。\n",
    "7. **予測を行う**: テストデータに対して予測を行い、その結果を取得します。\n",
    "8. **提出ファイルの準備**: 予測結果を整理し、Kaggleに提出するためのCSVファイルを作成します。\n",
    "\n",
    "### まとめ\n",
    "このNotebookは、ユーザーの好みを予測するための機械学習モデルを効果的に構築し、評価するフレームワークを提供しています。使用されている手法やライブラリは、データ前処理からモデルの設計、トレーニング、評価まで、機械学習プロセス全体を網羅しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a7e19",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookに含まれる専門用語の簡単な解説です。特に初心者がつまずきやすいが、基礎的な知識としてはあまり知られていないか、実務経験がないとなじみの薄いものに焦点を当てました。\n",
    "\n",
    "### 解説リスト\n",
    "\n",
    "1. **トークン化 (Tokenization)**:\n",
    "   テキストデータを単語や文などの小さな単位（トークン）に分割するプロセス。自然言語処理においては、モデルがテキストを理解しやすくするための前処理ステップとして重要。\n",
    "\n",
    "2. **パディング (Padding)**:\n",
    "   シーケンスデータの長さを一致させるため、短いシーケンスにゼロまたは特定の値を追加する処理。モデル入力のサイズを統一するために必要な手法。\n",
    "\n",
    "3. **埋め込み層 (Embedding Layer)**:\n",
    "   単語を連続的なベクトル空間にマッピングする層。言葉の意味を距離で表現し、類似した意味の単語が近くに位置するように学習される。\n",
    "\n",
    "4. **LSTM (Long Short-Term Memory)**:\n",
    "   長期記憶を持つリカレントニューラルネットワークの一種。時間的な依存関係を持つデータ（時系列データやテキストなど）を扱う場合に用いる。忘却ゲートや入力ゲートなど、情報を管理するための特別な構造を持つ。\n",
    "\n",
    "5. **連結 (Concatenate)**:\n",
    "   複数の配列やテンソルを指定した次元に沿って結合する操作。モデル内で異なる特徴を組み合わせる際に使用される。\n",
    "\n",
    "6. **全結合層 (Dense Layer)**:\n",
    "   前の層の出力がすべてのユニットに接続される層。全結合層のユニット数は任意で、ここでは主に分類タスクのために用いられる。\n",
    "\n",
    "7. **出力層 (Output Layer)**:\n",
    "   モデルが予測を行う最終層。タスクに応じたアクティベーション関数（例えば、分類には`sigmoid`や`softmax`など）が使用され、出力がラベルとなる。\n",
    "\n",
    "8. **カテゴリカルクロスエントロピー (Categorical Crossentropy)**:\n",
    "   多クラスの分類問題で使われる損失関数。モデルが予測した確率分布と実際のクラスの分布間の差異を測定する。\n",
    "\n",
    "9. **バッチサイズ (Batch Size)**:\n",
    "   一度にモデルに供給するデータのサンプル数。大きなバッチサイズでは計算が効率的になる一方、小さなバッチサイズではモデルがより良い一般化を学習できる。\n",
    "\n",
    "10. **エポック (Epoch)**:\n",
    "    訓練データ全体がニューラルネットワークによって一回処理されるサイクルのこと。一般的に複数回繰り返して学習する。\n",
    "\n",
    "このリストを通して、使用されている専門用語に関する理解が深まれば、Jupyter Notebookの内容がより明確になると思います。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145f11a",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Arial', sans-serif; \n",
    "    padding: 30px; \n",
    "    border-radius: 15px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 6px 12px rgba(0, 0, 0, 0.4);\n",
    "    margin-bottom: 30px;\n",
    "\">\n",
    "    <h1 style=\"font-size: 2.5em;\">🧠 LMSYS - AIチャット評価者: 人間とAIの相互強化</h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 20px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
    "    margin-bottom: 20px;\n",
    "\">\n",
    "    <h1>私のノートブックへようこそ！🙏</h1>\n",
    "    <p>このノートブックは<strong>Chatbot Arena Competition</strong>に捧げられています。ここでは、会話AIの領域で探求し、革新を行います。</p>\n",
    "    <p><strong>コンペティションの概要:</strong>目標は、自然で関連性のある会話を通じてユーザーを理解し、関与させるチャットボットを開発することです。ここでは、最高のチャットボットを作成するためのデータ、テクニック、洞察が見つかります。</p>\n",
    "    <p>この旅に参加していただきありがとうございます。ぜひ深く掘り下げて探検し、チャットボットで魔法を作りましょう！</p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    " 1. 環境の設定\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-22T09:09:58.963626Z",
     "iopub.status.busy": "2024-07-22T09:09:58.963177Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ce939",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "2. ライブラリのインポート\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # データ操作のためのライブラリ\n",
    "import numpy as np  # 数値計算のためのライブラリ\n",
    "from sklearn.model_selection import train_test_split  # データ分割のための関数\n",
    "from sklearn.preprocessing import LabelEncoder  # ラベルエンコーディングのためのクラス\n",
    "from sklearn.metrics import classification_report  # 分類結果のレポートを生成するための関数\n",
    "import tensorflow as tf  # TensorFlowライブラリ\n",
    "from tensorflow.keras.models import Model  # Kerasのモデルを構築するためのクラス\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Concatenate  # ニューラルネットワークの層\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # テキストを前処理するためのクラス\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # シーケンスのパディングを行う関数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42474e3f",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "3. データのロード\n",
    "</h1>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # 訓練データをCSV形式で読み込む\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSV形式で読み込む"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b5880",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "4. テキストデータの前処理\n",
    "</h1>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 応答とプロンプトを連結してトークン化する\n",
    "texts = train_df['prompt'] + ' ' + train_df['response_a'] + ' ' + train_df['response_b']  # プロンプトと応答を結合\n",
    "tokenizer = Tokenizer()  # トークナイザーのインスタンスを作成\n",
    "tokenizer.fit_on_texts(texts)  # テキストに基づいてトークナイザーをフィットさせる\n",
    "\n",
    "# テキストをシーケンスに変換する関数\n",
    "def text_to_sequences(texts):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)  # テキストをシーケンスに変換\n",
    "    return pad_sequences(sequences, maxlen=500)  # maxlenに基づいてパディング処理を行う\n",
    "\n",
    "# 訓練データの処理\n",
    "X_prompt_a = text_to_sequences(train_df['prompt'])  # プロンプトをシーケンスに変換\n",
    "X_response_a = text_to_sequences(train_df['response_a'])  # 応答Aをシーケンスに変換\n",
    "X_response_b = text_to_sequences(train_df['response_b'])  # 応答Bをシーケンスに変換\n",
    "\n",
    "# ラベルの取得\n",
    "y_a = train_df['winner_model_a']  # モデルAの勝者ラベル\n",
    "y_b = train_df['winner_model_b']  # モデルBの勝者ラベル\n",
    "y_tie = train_df['winner_tie']  # 引き分けラベル\n",
    "\n",
    "# 訓練データの分割\n",
    "X_train_a, X_val_a, y_train_a, y_val_a = train_test_split(X_prompt_a, y_a, test_size=0.2, random_state=42)  # 訓練データと評価データに分割\n",
    "X_train_b, X_val_b, y_train_b, y_val_b = train_test_split(X_prompt_a, y_b, test_size=0.2, random_state=42)  # 訓練データと評価データに分割\n",
    "X_train_tie, X_val_tie, y_train_tie, y_val_tie = train_test_split(X_prompt_a, y_tie, test_size=0.2, random_state=42)  # 訓練データと評価データに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628e92e3",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "5. モデルの構築\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのパラメータを定義する\n",
    "vocab_size = len(tokenizer.word_index) + 1  # ボキャブラリーのサイズを取得\n",
    "embedding_dim = 100  # 埋め込み次元\n",
    "max_len = 500  # 最大シーケンス長\n",
    "\n",
    "# 入力の定義\n",
    "input_prompt = Input(shape=(max_len,))  # プロンプト入力\n",
    "input_response_a = Input(shape=(max_len,))  # 応答A入力\n",
    "input_response_b = Input(shape=(max_len,))  # 応答B入力\n",
    "\n",
    "# 埋め込み層の定義\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim, input_length=max_len)\n",
    "\n",
    "# 入力を埋め込みベクトルに変換\n",
    "embedded_prompt = embedding_layer(input_prompt)  # プロンプトの埋め込み\n",
    "embedded_response_a = embedding_layer(input_response_a)  # 応答Aの埋め込み\n",
    "embedded_response_b = embedding_layer(input_response_b)  # 応答Bの埋め込み\n",
    "\n",
    "# LSTM層の定義\n",
    "lstm_layer = LSTM(64)  # LSTMユニット数は64\n",
    "\n",
    "# 入力をLSTM層に通す\n",
    "encoded_prompt = lstm_layer(embedded_prompt)  # プロンプトのエンコード\n",
    "encoded_response_a = lstm_layer(embedded_response_a)  # 応答Aのエンコード\n",
    "encoded_response_b = lstm_layer(embedded_response_b)  # 応答Bのエンコード\n",
    "\n",
    "# プロンプトとエンコードされた応答を連結する\n",
    "concat_a = Concatenate()([encoded_prompt, encoded_response_a])  # 応答Aとの連結\n",
    "concat_b = Concatenate()([encoded_prompt, encoded_response_b])  # 応答Bとの連結\n",
    "\n",
    "# 分類用の全結合層\n",
    "dense_layer = Dense(64, activation='relu')  # 全結合層（ReLU活性化関数）\n",
    "\n",
    "# 出力層の定義\n",
    "output_a = Dense(1, activation='sigmoid')(dense_layer(concat_a))  # 応答Aの勝者を予測\n",
    "output_b = Dense(1, activation='sigmoid')(dense_layer(concat_b))  # 応答Bの勝者を予測\n",
    "output_tie = Dense(1, activation='sigmoid')(dense_layer(concat_a))  # 引き分けの勝者を予測\n",
    "\n",
    "# モデルの定義\n",
    "model = Model(inputs=[input_prompt, input_response_a, input_response_b], \n",
    "              outputs=[output_a, output_b, output_tie])  # モデルの入力と出力を設定\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # モデルをコンパイル\n",
    "\n",
    "# モデルの要約（構造）を表示\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5617cc87",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "6. モデルのトレーニング\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',  # 最適化手法にAdamを使用\n",
    "    loss=['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy'],  # 損失関数にカテゴリカルクロスエントロピーを使用\n",
    "    metrics=[['accuracy'], ['accuracy'], ['accuracy']]  # 各出力の精度を評価指標で指定\n",
    ")\n",
    "\n",
    "# モデルのトレーニング\n",
    "history = model.fit(\n",
    "    [X_train_a, X_train_b, X_train_b],  # 訓練データ\n",
    "    [y_train_a, y_train_b, y_train_tie],  # 訓練ラベル\n",
    "    validation_data=([X_val_a, X_val_b, X_val_b], [y_val_a, y_val_b, y_val_tie]),  # 検証データ\n",
    "    epochs=5,  # エポック数は必要に応じて調整\n",
    "    batch_size=32  # バッチサイズ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba528102",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "7. モデルの評価\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを評価する\n",
    "eval_results = model.evaluate([X_val_a, X_val_b, X_val_b], [y_val_a, y_val_b, y_val_tie])  # 検証データに対する評価を行う\n",
    "\n",
    "# 結果を展開する\n",
    "val_loss = eval_results[0]  # 検証損失\n",
    "loss_a = eval_results[1]  # モデルAの損失\n",
    "loss_b = eval_results[2]  # モデルBの損失\n",
    "loss_tie = eval_results[3]  # 引き分けの損失\n",
    "acc_a = eval_results[4]  # モデルAの精度\n",
    "acc_b = eval_results[5]  # モデルBの精度\n",
    "acc_tie = eval_results[6]  # 引き分けの精度\n",
    "\n",
    "print(f'検証損失: {val_loss}')  # 検証損失を出力\n",
    "print(f'モデルAの予測損失: {loss_a}')  # モデルAの損失を出力\n",
    "print(f'モデルBの予測損失: {loss_b}')  # モデルBの損失を出力\n",
    "print(f'引き分け予測の損失: {loss_tie}')  # 引き分けの損失を出力\n",
    "print(f'モデルAの予測精度: {acc_a}')  # モデルAの精度を出力\n",
    "print(f'モデルBの予測精度: {acc_b}')  # モデルBの精度を出力\n",
    "print(f'引き分け予測の精度: {acc_tie}')  # 引き分けの精度を出力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61f8caa",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "8. 予測を行う\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの前処理\n",
    "X_test_prompt = text_to_sequences(test_df['prompt'])  # テストデータのプロンプトをシーケンスに変換\n",
    "X_test_response_a = text_to_sequences(test_df['response_a'])  # テストデータの応答Aをシーケンスに変換\n",
    "X_test_response_b = text_to_sequences(test_df['response_b'])  # テストデータの応答Bをシーケンスに変換\n",
    "\n",
    "# 予測\n",
    "predictions = model.predict([X_test_prompt, X_test_response_a, X_test_response_b])  # テストデータに対する予測を実施\n",
    "\n",
    "# 予測結果を展開する\n",
    "predicted_a = predictions[0].flatten()  # モデルAの予測結果を平坦化\n",
    "predicted_b = predictions[1].flatten()  # モデルBの予測結果を平坦化\n",
    "predicted_tie = predictions[2].flatten()  # 引き分けの予測結果を平坦化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5ce35",
   "metadata": {},
   "source": [
    "# \n",
    "<h1 style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Comic Sans MS', cursive, sans-serif; \n",
    "    padding: 15px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);\n",
    "    border: 2px solid #3776ab;\n",
    "\">\n",
    "9. 提出ファイルの準備\n",
    "</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出用に予測をフォーマットする\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],  # テストデータのIDを取得\n",
    "    'winner_model_a': predicted_a,  # モデルAの予測結果\n",
    "    'winner_model_b': predicted_b,  # モデルBの予測結果\n",
    "    'winner_tie': predicted_tie  # 引き分けの予測結果\n",
    "})\n",
    "\n",
    "# CSV形式で保存する\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出ファイルをCSV形式で保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.head()  # 提出ファイルの先頭5行を表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6433d6",
   "metadata": {},
   "source": [
    "<div style=\"\n",
    "    background: #f0f8ff; \n",
    "    color: #3777ac; \n",
    "    font-family: 'Arial', sans-serif; \n",
    "    padding: 20px; \n",
    "    border-radius: 10px; \n",
    "    text-align: center; \n",
    "    box-shadow: 0 4px 8px rgba(0, 0, 0, 0.3);\n",
    "    margin-top: 30px;\n",
    "\">\n",
    "    <h2><strong>私のノートブックを探究していただきありがとうございます！ 🙏<strong></h2>\n",
    "    <p>この<strong>LMSYS - AIチャット評価者</strong>プロジェクトを通じて、内容や洞察が価値あるものであったことを願っています。</p>\n",
    "    <p>あなたのフィードバックとサポートは私にとって非常に大切です。このノートブックが楽しく、役立ったと感じた場合は、<span style=\"background-color: #dde9f4; color: #3777ac; padding: 5px 10px; border-radius: 5px;\"> <strong>アップボートを検討してください ⬆️</strong></span>。あなたの励ましは、私が今後も改善し、有用なコンテンツを共有し続けるための助けになります。</p>\n",
    "    <p><span style=\"background-color: #dde9f4; color: #3777ac; padding: 5px 10px; border-radius: 5px;\"><strong> 改めて、あなたの時間とサポートに感謝します！</strong></span></p>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
