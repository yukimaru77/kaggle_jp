{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bafad64c",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」における人間の好み予測タスクに取り組んでいます。主な目的は、ユーザーが異なるチャットボットからの応答の中でどちらを選ぶかを予測するためのモデルを開発することです。ノートブックではトレーニングデータのサイズが大きいため、そのわずか0.5%のみを使用して、データのクリーニングと特徴量エンジニアリングを行います。\n",
    "\n",
    "### 使用される手法やライブラリ\n",
    "1. **データ処理と分析**:\n",
    "   - `pandas`, `numpy`: データフレームの操作や数値計算。\n",
    "   - `textstat`: テキストの読みやすさや統計分析。\n",
    "   - `SweetViz`: データ分析と視覚化。\n",
    "\n",
    "2. **自然言語処理**:\n",
    "   - `nltk`: ストップワードの取得やテキストの分析。\n",
    "   - `transformers`: BERTモデルを用いたトークン化と埋め込み生成。\n",
    "\n",
    "3. **機械学習**:\n",
    "   - `scikit-learn`: データの分割、モデル評価、さまざまな分類器（ランダムフォレスト、勾配ブースティング、サポートベクターマシンなど）の実装。\n",
    "   - `tensorflow`: ニューラルネットワークモデルの構築とトレーニング。\n",
    "\n",
    "### 主な工程\n",
    "- **データの読み込みと前処理**: トレーニングデータとテストデータをCSVから読み込み、クリーニングを実施（特殊文字の削除、正規化など）。\n",
    "- **特徴量エンジニアリング**: テキストの単語数、文字数、感情分析、およびBERTを用いた埋め込み生成を含む多様な特徴量を抽出。\n",
    "- **モデルの構築と評価**: 複数の機械学習モデルをトレーニングし、その性能を精度やログ損失を用いて評価。最良のモデルを選択します。\n",
    "- **テストデータに対する予測**: 最良モデルを用いてテストデータに対する予測を実施し、提出用フォーマットでCSVファイルを生成。\n",
    "\n",
    "このノートブックは、機械学習や自然言語処理を用いて実際の問題にアプローチし、チャットボットの応答のユーザー選好を予測するための包括的なフレームワークを提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fcca75",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookにおいて初心者がつまずきそうな専門用語の簡単な解説です。特にこのノートブック特有のドメイン知識や、実務未経験者にはなじみが薄い用語に焦点を当てています。\n",
    "\n",
    "1. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが設計した特化型ハードウェアで、特に機械学習のために最適化されているプロセッサです。通常のGPUよりも大規模なモデルを高速にトレーニングできます。\n",
    "\n",
    "2. **埋め込み (Embedding)**:\n",
    "   - 単語や文などの高次元のデータを低次元のベクトルに変換する手法です。意味情報を保持しつつ、計算効率を向上させるために使います。BERTのような言語モデルでは、言語の意味を理解するために重要です。\n",
    "\n",
    "3. **VADER (Valence Aware Dictionary and sEntiment Reasoner)**:\n",
    "   - 主にソーシャルメディアでの感情分析に対応した辞書およびルールベースの手法です。ポジティブやネガティブな感情をスコアとして評価し、特に短いテキストや感情的な表現に効果的です。\n",
    "\n",
    "4. **Flesch Reading Easeスコア**:\n",
    "   - テキストの読みやすさを数値化した指標で、高いスコアほど読みやすいことを示します。文の長さや音節数を考慮して計算されます。\n",
    "\n",
    "5. **コサイン類似度 (Cosine Similarity)**:\n",
    "   - 二つのベクトルのコサインの角度を基準にした類似度指標です。1に近いほど似ていることを示し、主に情報検索や自然言語処理で使用されます。\n",
    "\n",
    "6. **ドロップアウト (Dropout)**:\n",
    "   - ニューラルネットワークの訓練中に、過学習を防ぐためにランダムに一定の割合のニューロンを「ドロップ」する手法です。これにより、モデルの一般化能力が向上します。\n",
    "\n",
    "7. **ログ損失 (Log Loss)**:\n",
    "   - 分類問題におけるモデルの性能を評価するための指標で、確率的な予測に対する損失を計算します。モデルが予測した確率と実際のラベルとの違いを反映します。\n",
    "\n",
    "8. **シーケンス (Sequence)**:\n",
    "   - 一連のデータポイントの配列で、通常は時系列データやテキストのように順序が重要なデータに使用されます。\n",
    "\n",
    "9. **トークン化 (Tokenization)**:\n",
    "   - テキストを単語やフレーズといった「トークン」に分割する過程です。機械学習モデルがテキストを理解するために不可欠な第一歩です。\n",
    "\n",
    "10. **特徴量エンジニアリング (Feature Engineering)**:\n",
    "    - 生データから機械学習モデルが有用な情報を引き出すための特徴量を生成、選択、変換するプロセスです。モデル性能に大きく影響します。\n",
    "\n",
    "この解説リストが、ノートブックを理解するのに役立つことを願っています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e86d813",
   "metadata": {},
   "source": [
    "# LMSYS - Chatbot Arenaでの人間の好み予測\n",
    "\n",
    "\n",
    "\n",
    "**トレーニングデータのサイズが大きいため、私はトレーニングデータのわずか0.5%のみを使用しています！**\n",
    "\n",
    "作業中：TPUを使用して別のノートブックで埋め込みを計算し、フルトレーニングデータを使用した後、ここに埋め込みをロードします！\n",
    "\n",
    "## ライブラリのインストールと読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:33:41.416352Z",
     "iopub.status.busy": "2024-07-15T10:33:41.415887Z",
     "iopub.status.idle": "2024-07-15T10:33:59.382928Z",
     "shell.execute_reply": "2024-07-15T10:33:59.381338Z",
     "shell.execute_reply.started": "2024-07-15T10:33:41.416315Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install textstat SweetViz  # textstatとSweetVizをインストールします。\n",
    "\n",
    "# textstatはテキストの統計情報を分析するためのライブラリで、例えば読みやすさのスコアを計算することができます。\n",
    "# SweetVizはデータの可視化を提供するライブラリで、データセットの探索に役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T10:33:59.385882Z",
     "iopub.status.busy": "2024-07-15T10:33:59.385457Z",
     "iopub.status.idle": "2024-07-15T10:34:26.626598Z",
     "shell.execute_reply": "2024-07-15T10:34:26.625291Z",
     "shell.execute_reply.started": "2024-07-15T10:33:59.385844Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings  # 警告を表示しないように設定します。\n",
    "warnings.filterwarnings('ignore')  # すべての警告を無視します。\n",
    "\n",
    "import pandas as pd  # データ操作のためのライブラリ\n",
    "import numpy as np  # 数値計算のためのライブラリ\n",
    "\n",
    "import seaborn as sns  # データの可視化に役立つライブラリ\n",
    "import matplotlib.pyplot as plt  # グラフを描画するためのライブラリ\n",
    "import plotly.express as px  # インタラクティブなグラフを描画するためのライブラリ\n",
    "import sweetviz as sv  # データセットの探索に役立つ可視化ライブラリ\n",
    "\n",
    "import re  # 正規表現を扱うためのライブラリ\n",
    "import string  # 文字列操作のためのライブラリ\n",
    "import nltk  # 自然言語処理のためのライブラリ\n",
    "from nltk.corpus import stopwords  # ストップワード（意味を持たない単語）のリストを取得するためのモジュール\n",
    "\n",
    "import tensorflow as tf  # 機械学習と深層学習のフレームワーク\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # テキストのトークン化を行うためのクラス\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # シーケンスを一定の長さにパディングするための関数\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer  # 感情分析を行うためのモジュール\n",
    "\n",
    "import textstat  # テキストの統計情報を計算するためのライブラリ\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # テキストデータを数値に変換するためのクラス\n",
    "\n",
    "from sklearn.model_selection import train_test_split  # データセットをトレーニングとテストに分割するための関数\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity  # コサイン類似度を計算するための関数\n",
    "from transformers import BertTokenizer, TFBertModel  # BERTトークン化とBERTモデルを使用するためのライブラリ\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # ランダムフォレストと勾配ブースティングのクラス\n",
    "from sklearn.svm import SVC  # サポートベクターマシンのクラス\n",
    "\n",
    "from tensorflow.keras.models import Sequential  # Kerasのシーケンシャルモデル\n",
    "from tensorflow.keras.layers import Dense, Dropout  # 全結合層とドロップアウト層\n",
    "from tensorflow.keras.optimizers import Adam  # Adamオプティマイザ\n",
    "\n",
    "from sklearn.metrics import accuracy_score, \\  # 精度を評価するための関数\n",
    "                            log_loss, \\  # ログ損失を評価するための関数\n",
    "                            confusion_matrix, \\  # 混同行列を計算するための関数\n",
    "                            classification_report  # 分類結果のレポートを生成するための関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:26.629331Z",
     "iopub.status.busy": "2024-07-15T10:34:26.628304Z",
     "iopub.status.idle": "2024-07-15T10:34:26.705902Z",
     "shell.execute_reply": "2024-07-15T10:34:26.704543Z",
     "shell.execute_reply.started": "2024-07-15T10:34:26.629283Z"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('stopwords')  # NLTKライブラリからストップワードのリストをダウンロードします。\n",
    "stop_words = set(stopwords.words('english'))  # 英語のストップワードを取得し、セットとして格納します。\n",
    "\n",
    "# ストップワードとは、テキストデータの中で特に意味を持たない単語のことであり、\n",
    "# これを除外することで、テキスト分析の精度を向上させることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c1e9ed",
   "metadata": {},
   "source": [
    "## データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:26.709185Z",
     "iopub.status.busy": "2024-07-15T10:34:26.708734Z",
     "iopub.status.idle": "2024-07-15T10:34:30.485346Z",
     "shell.execute_reply": "2024-07-15T10:34:30.483633Z",
     "shell.execute_reply.started": "2024-07-15T10:34:26.709137Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータをCSVファイルから読み込みます。\n",
    "test_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "\n",
    "# pd.read_csv関数は、指定されたファイルパスからCSV形式のデータを読み込むための関数です。\n",
    "# 読み込まれたデータはpandasのDataFrame形式で格納され、データの操作や分析に利用できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bca9bd",
   "metadata": {},
   "source": [
    "## 探索的データ分析（EDA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:30.487034Z",
     "iopub.status.busy": "2024-07-15T10:34:30.486668Z",
     "iopub.status.idle": "2024-07-15T10:34:39.325863Z",
     "shell.execute_reply": "2024-07-15T10:34:39.32424Z",
     "shell.execute_reply.started": "2024-07-15T10:34:30.487001Z"
    }
   },
   "outputs": [],
   "source": [
    "train_analysis = sv.analyze(train_data)  # トレーニングデータに対してSweetVizを用いて分析を行います。\n",
    "\n",
    "# sv.analyze関数は、指定されたデータセットに関する詳細なレポートを生成し、\n",
    "# データの特性や分布を視覚的に示すための情報を提供します。 \n",
    "# このレポートは、データの概要を把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.328624Z",
     "iopub.status.busy": "2024-07-15T10:34:39.327819Z",
     "iopub.status.idle": "2024-07-15T10:34:39.67726Z",
     "shell.execute_reply": "2024-07-15T10:34:39.675712Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.328578Z"
    }
   },
   "outputs": [],
   "source": [
    "train_analysis.show_html('train_analysis.html')  # SweetVizによるトレーニングデータの分析結果をHTMLファイルとして保存します。\n",
    "\n",
    "# show_html関数は、分析結果をHTML形式で出力し、指定されたファイル名で保存します。\n",
    "# このHTMLファイルは、データの可視化や分析結果をブラウザで確認するのに便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.679353Z",
     "iopub.status.busy": "2024-07-15T10:34:39.678987Z",
     "iopub.status.idle": "2024-07-15T10:34:39.700291Z",
     "shell.execute_reply": "2024-07-15T10:34:39.699087Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.679322Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()  # トレーニングデータの最初の5行を表示します。\n",
    "\n",
    "# head()関数は、DataFrameの最初の数行を表示するための関数で、\n",
    "# データの構造や内容をすばやく確認するのに役立ちます。\n",
    "# 引数を指定することで、表示する行数を変更することも可能です。デフォルトでは5行表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.702126Z",
     "iopub.status.busy": "2024-07-15T10:34:39.701764Z",
     "iopub.status.idle": "2024-07-15T10:34:39.708363Z",
     "shell.execute_reply": "2024-07-15T10:34:39.707161Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.702092Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Training Data -\", train_data.shape)  # トレーニングデータの形状（行数と列数）を表示します。\n",
    "print(\"Test Data -\", test_data.shape)  # テストデータの形状（行数と列数）を表示します。\n",
    "\n",
    "# shape属性は、データフレームの行数と列数をタプル形式で返します。\n",
    "# これにより、データセットのサイズを簡単に把握することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.710466Z",
     "iopub.status.busy": "2024-07-15T10:34:39.709973Z",
     "iopub.status.idle": "2024-07-15T10:34:39.979519Z",
     "shell.execute_reply": "2024-07-15T10:34:39.977988Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.710412Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.describe(include=['O'])  # トレーニングデータのオブジェクト型（文字列）の列に関する要約統計量を表示します。\n",
    "\n",
    "# describe()関数は、データフレームの基本的な統計情報を提供します。\n",
    "# include=['O']を指定することで、オブジェクト型の列（通常は文字列データ）のみを対象にした要約が取得できます。\n",
    "# 出力には、ユニークな値の数や最頻値などが含まれ、データの特徴を把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:39.985526Z",
     "iopub.status.busy": "2024-07-15T10:34:39.985109Z",
     "iopub.status.idle": "2024-07-15T10:34:40.039905Z",
     "shell.execute_reply": "2024-07-15T10:34:40.038678Z",
     "shell.execute_reply.started": "2024-07-15T10:34:39.985495Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_data.info())  # トレーニングデータの情報を表示します。\n",
    "\n",
    "# info()関数は、データフレームの構造に関する詳細情報を提供します。\n",
    "# 出力には、各列のデータ型、非NULL値のカウント、メモリの使用量などが含まれます。\n",
    "# これにより、データセットの各列の状態を簡単に確認することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:40.041517Z",
     "iopub.status.busy": "2024-07-15T10:34:40.041135Z",
     "iopub.status.idle": "2024-07-15T10:34:40.551835Z",
     "shell.execute_reply": "2024-07-15T10:34:40.550554Z",
     "shell.execute_reply.started": "2024-07-15T10:34:40.041484Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(\"id\", axis=1).duplicated().sum()  # \"id\"列を除いたトレーニングデータの重複行の数をカウントします。\n",
    "\n",
    "# drop(\"id\", axis=1)は、\"id\"という列をデータフレームから削除します。\n",
    "# duplicated()メソッドは、重複している行を検出し、重複行に対してTrueを返します。\n",
    "# sum()は、Trueの合計を計算し、重複行の総数を返します。 \n",
    "# これにより、データセット内の重複するデータの有無を確認できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8abad8c",
   "metadata": {},
   "source": [
    "14行の重複が存在し、7つのグループを形成しています。私は各グループごとに1行のみを保持します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:40.55393Z",
     "iopub.status.busy": "2024-07-15T10:34:40.553437Z",
     "iopub.status.idle": "2024-07-15T10:34:41.059542Z",
     "shell.execute_reply": "2024-07-15T10:34:41.058435Z",
     "shell.execute_reply.started": "2024-07-15T10:34:40.553889Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop_duplicates(keep=\"first\", ignore_index=True)  # 重複行を削除し、先頭の行を保持します。\n",
    "\n",
    "# drop_duplicates()メソッドは、データフレーム内の重複行を削除します。\n",
    "# 引数keep=\"first\"は、最初の出現を保持し、他の重複行を削除することを指定します。\n",
    "# ignore_index=Trueを指定することで、インデックスをリセットし、新たな連続したインデックスを付与します。\n",
    "# これにより、重複行が削除された後でも、インデックスが整然とした状態になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2608d7a",
   "metadata": {},
   "source": [
    "`id`列に関してトレーニングデータの品質を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.061181Z",
     "iopub.status.busy": "2024-07-15T10:34:41.060808Z",
     "iopub.status.idle": "2024-07-15T10:34:41.60334Z",
     "shell.execute_reply": "2024-07-15T10:34:41.602224Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.061135Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.nunique()  # トレーニングデータの各列におけるユニークな値の数を表示します。\n",
    "\n",
    "# nunique()メソッドは、データフレーム内の各列においてユニークな値の個数を計算します。\n",
    "# この情報は、各列のデータにどれだけのバリエーションがあるかを把握するのに役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.605597Z",
     "iopub.status.busy": "2024-07-15T10:34:41.605228Z",
     "iopub.status.idle": "2024-07-15T10:34:41.613706Z",
     "shell.execute_reply": "2024-07-15T10:34:41.61272Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.605566Z"
    }
   },
   "outputs": [],
   "source": [
    "assert train_data[\"id\"].nunique() == len(train_data)  # `id`列のユニークな値の数がトレーニングデータの行数と等しいことを確認します。\n",
    "\n",
    "# assert文は、指定された条件がTrueであることをチェックします。\n",
    "# もし条件が満たされない場合、エラーが発生し、プログラムの実行が停止します。\n",
    "# この条件により、`id`列に重複がないこと（すなわち、全ての`id`がユニークであること）を確認しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.615433Z",
     "iopub.status.busy": "2024-07-15T10:34:41.615071Z",
     "iopub.status.idle": "2024-07-15T10:34:41.666185Z",
     "shell.execute_reply": "2024-07-15T10:34:41.664758Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.615402Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.isna().sum()  # トレーニングデータの各列における欠損値（NaN）の合計を表示します。\n",
    "\n",
    "# isna()メソッドは、データフレームの各セルが欠損値であるかどうかを確認し、ブーリアン値（TrueまたはFalse）を返します。\n",
    "# sum()関数を使用することで、各列に含まれる欠損値の合計を計算し、結果を表示します。\n",
    "# この情報は、データのクリーニングや前処理において欠損値の処理を行う前に確認するのに役立ちます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab10f6",
   "metadata": {},
   "source": [
    "### 分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:41.668356Z",
     "iopub.status.busy": "2024-07-15T10:34:41.667864Z",
     "iopub.status.idle": "2024-07-15T10:34:43.90637Z",
     "shell.execute_reply": "2024-07-15T10:34:43.905165Z",
     "shell.execute_reply.started": "2024-07-15T10:34:41.668315Z"
    }
   },
   "outputs": [],
   "source": [
    "model_df = pd.concat([train_data.model_a, train_data.model_b])  # model_aとmodel_bの列を結合します。\n",
    "counts = model_df.value_counts().reset_index()  # 各モデルの出現回数をカウントし、データフレームにリセットします。\n",
    "counts.columns = ['LLM', 'Count']  # カラム名を設定します。\n",
    "\n",
    "# Plotlyを使用してカスタムスタイルの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='LLM', y='Count',\n",
    "             title='モデルの分布',\n",
    "             color='Count')  # モデルに応じた色を設定します。\n",
    "\n",
    "fig.update_layout(xaxis_tickangle=-45)  # x軸のラベルを45度回転させて見やすくします。\n",
    "\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:43.908277Z",
     "iopub.status.busy": "2024-07-15T10:34:43.907864Z",
     "iopub.status.idle": "2024-07-15T10:34:44.035778Z",
     "shell.execute_reply": "2024-07-15T10:34:44.034645Z",
     "shell.execute_reply.started": "2024-07-15T10:34:43.908231Z"
    }
   },
   "outputs": [],
   "source": [
    "counts_a = train_data['winner_model_a'].value_counts().reset_index()  # モデルAの勝利数をカウントします。\n",
    "counts_b = train_data['winner_model_b'].value_counts().reset_index()  # モデルBの勝利数をカウントします。\n",
    "counts_tie = train_data['winner_tie'].value_counts().reset_index()  # 引き分けの数をカウントします。\n",
    "\n",
    "# 分かりやすくするためにカラム名を変更します。\n",
    "counts_a.columns = ['Winner', 'Count']\n",
    "counts_b.columns = ['Winner', 'Count']\n",
    "counts_tie.columns = ['Winner', 'Count']\n",
    "\n",
    "# モデルを識別するためのカラムを追加します。\n",
    "counts_a['Model'] = 'Model A'\n",
    "counts_b['Model'] = 'Model B'\n",
    "counts_tie['Model'] = 'Tie'\n",
    "\n",
    "# すべてのカウントを結合します。\n",
    "counts = pd.concat([counts_a, counts_b, counts_tie])\n",
    "\n",
    "# カスタムスタイルの棒グラフを作成します。\n",
    "fig = px.bar(counts, x='Model', y='Count', \n",
    "             color='Model',\n",
    "             title='トレーニングデータの勝者分布',\n",
    "             labels={'Model': 'モデル', 'Count': '勝利数', 'Winner': '勝者'})\n",
    "\n",
    "fig.update_layout(xaxis_title=\"モデル\", yaxis_title=\"勝利数\")  # x軸とy軸のタイトルを設定します。\n",
    "\n",
    "fig.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5bebf",
   "metadata": {},
   "source": [
    "結論:\n",
    "\n",
    "* トレーニングデータは57,477行、テストデータは3行です。\n",
    "    * 注: スコアリングフェーズ中にテストデータは完全なテストセット（約25,000行、70%はプライベートLB用）に置き換えられます。\n",
    "* `id`列には重複値がありません。\n",
    "* モデルの識別子はテストセットでは明らかにされていません。\n",
    "* `prompt`、`response_a`、`response_b`の各列の文字列はリストにラップされています。\n",
    "    * これは、各チャットが複数のプロンプト/レスポンスのペアを含む可能性があるためです。\n",
    "* `id`列を削除した後、14行の重複が存在し、7つのグループを形成しています。各グループごとに1行だけを保持した結果、トレーニングデータフレームの形状は(57,470, 8)になります。\n",
    "\n",
    "## データ準備と特徴量エンジニアリング\n",
    "\n",
    "* データのクリーニング: 特殊文字を削除し、小文字に正規化し、ストップワードを削除し、トークン化するなどのテキストをクリーンアップします。\n",
    "* 入力のトークン化: トレーニングデータに基づいてTensorFlow/Kerasのトークナイザーを使用し、トレーニングデータとテストデータの両方にフィットさせます。\n",
    "* シーケンスを`max_len`にパディングします。\n",
    "* BERT埋め込みを作成します。\n",
    "* 各モデルのプロンプトとレスポンス間でBERTを使用した類似度特徴量を計算します。\n",
    "* 各レスポンスについて、単語数、文字数、語彙の多様性を計算します。\n",
    "* BERTモデル用にテキスト入力をトークン化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:44.037769Z",
     "iopub.status.busy": "2024-07-15T10:34:44.037333Z",
     "iopub.status.idle": "2024-07-15T10:34:46.277777Z",
     "shell.execute_reply": "2024-07-15T10:34:46.276634Z",
     "shell.execute_reply.started": "2024-07-15T10:34:44.037729Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv').sample(frac=0.001)  # トレーニングデータをCSVファイルから読み込み、全体の0.1%をサンプリングします。\n",
    "\n",
    "# read_csv()関数は、指定されたファイルパスからCSV形式のデータを読み込みます。\n",
    "# sample(frac=0.001)は、データフレームから全体の0.1%（0.001）のランダムなサンプルを抽出します。\n",
    "# これにより、大規模なデータセットの一部を使用して迅速に実験や分析を行うことができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6c6572",
   "metadata": {},
   "source": [
    "### データのクリーニング\n",
    "\n",
    "特殊文字を削除し、小文字に正規化し、ストップワードを削除するなどのクリーンなテキストを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.280599Z",
     "iopub.status.busy": "2024-07-15T10:34:46.280195Z",
     "iopub.status.idle": "2024-07-15T10:34:46.28861Z",
     "shell.execute_reply": "2024-07-15T10:34:46.287229Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.280566Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):  # テキストをクリーンアップするための関数を定義します。\n",
    "    text = text.lower()  # テキストを小文字に変換します。\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # 括弧内の内容を削除します。\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # URLを削除します。\n",
    "    text = re.sub(r'<.*?>+', '', text)  # HTMLタグを削除します。\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # 句読点を削除します。\n",
    "    text = re.sub(r'\\n', '', text)  # 改行を削除します。\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # 数字を含む単語を削除します。\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)  # ストップワードを削除し、単語を再結合します。\n",
    "    return text  # クリーンアップされたテキストを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.290769Z",
     "iopub.status.busy": "2024-07-15T10:34:46.290311Z",
     "iopub.status.idle": "2024-07-15T10:34:46.316756Z",
     "shell.execute_reply": "2024-07-15T10:34:46.315617Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.290725Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストのクリーニングを行います。\n",
    "train_data['prompt_clean'] = train_data['prompt'].apply(clean_text)  # 'prompt'列にclean_text関数を適用し、クリーニングした結果を'prompt_clean'列に格納します。\n",
    "train_data['response_a_clean'] = train_data['response_a'].apply(clean_text)  # 'response_a'列にclean_text関数を適用し、クリーニングした結果を'response_a_clean'列に格納します。\n",
    "train_data['response_b_clean'] = train_data['response_b'].apply(clean_text)  # 'response_b'列にclean_text関数を適用し、クリーニングした結果を'response_b_clean'列に格納します。\n",
    "\n",
    "# apply()メソッドは、指定した関数をデータフレームの各要素に適用し、新しいシリーズを返します。\n",
    "# これにより、元のテキストデータがクリーニングされ、分析やモデルの入力に適した形式へと変換されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafdd47b",
   "metadata": {},
   "source": [
    "### 入力のトークン化\n",
    "\n",
    "TensorFlow/Kerasのトークナイザーを使用して、トレーニングデータとテストデータの両方に対してトークン化を行います。シーケンスを`max_len`にパディングします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.319341Z",
     "iopub.status.busy": "2024-07-15T10:34:46.318825Z",
     "iopub.status.idle": "2024-07-15T10:34:46.326669Z",
     "shell.execute_reply": "2024-07-15T10:34:46.325432Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.319296Z"
    }
   },
   "outputs": [],
   "source": [
    "max_len = 512  # シーケンスの最大長を512に設定します。\n",
    "\n",
    "# max_lenは、BERTなどのトランスフォーマーモデルで処理できる入力シーケンスの最大の長さを指定します。\n",
    "# これにより、すべての入力が均一な長さになるようにパディングやカットが適用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.328517Z",
     "iopub.status.busy": "2024-07-15T10:34:46.328108Z",
     "iopub.status.idle": "2024-07-15T10:34:46.336728Z",
     "shell.execute_reply": "2024-07-15T10:34:46.335637Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.328475Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=20000)  # 語彙サイズを20,000語に制限したトークナイザーを初期化します。\n",
    "\n",
    "# Tokenizerクラスは、テキストを数値のトークンに変換するためのもので、num_words引数は使用する語彙の最大数を指定します。\n",
    "# これにより、頻出の単語を保持し、あまり使われない単語は除外されるため、モデルの効率が向上します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.338587Z",
     "iopub.status.busy": "2024-07-15T10:34:46.338196Z",
     "iopub.status.idle": "2024-07-15T10:34:46.355879Z",
     "shell.execute_reply": "2024-07-15T10:34:46.354609Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.338554Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(pd.concat([train_data['prompt_clean'], train_data['response_a_clean'], train_data['response_b_clean']]))  # トークナイザーをトレーニングデータのクリーニングされたプロンプトとレスポンスでフィットさせます。\n",
    "\n",
    "# fit_on_texts()メソッドは、指定されたテキストデータから単語の頻度に基づいて語彙を構築します。\n",
    "# pd.concat()を使用して、プロンプトとレスポンスを結合し、一緒にトークン化することで、すべてのテキストに基づいた語彙を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.357828Z",
     "iopub.status.busy": "2024-07-15T10:34:46.357412Z",
     "iopub.status.idle": "2024-07-15T10:34:46.36959Z",
     "shell.execute_reply": "2024-07-15T10:34:46.36843Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.357793Z"
    }
   },
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_data['prompt_clean'])  # クリーニングされたプロンプトを数値のシーケンスに変換します。\n",
    "response_a_sequences = tokenizer.texts_to_sequences(train_data['response_a_clean'])  # クリーニングされたレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_sequences = tokenizer.texts_to_sequences(train_data['response_b_clean'])  # クリーニングされたレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドは、テキストを数値のシーケンスに変換し、各単語を対応するインデックスに置き換えます。\n",
    "# これにより、モデルに入力できる形式のデータが得られ、後の処理や学習のために準備されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.371665Z",
     "iopub.status.busy": "2024-07-15T10:34:46.37117Z",
     "iopub.status.idle": "2024-07-15T10:34:46.382058Z",
     "shell.execute_reply": "2024-07-15T10:34:46.380991Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.371623Z"
    }
   },
   "outputs": [],
   "source": [
    "# パディングを行います。\n",
    "train_sequences = pad_sequences(train_sequences, maxlen=max_len, padding='post')  # プロンプトのシーケンスを最大長にパディングします。シーケンスの末尾にパディングを追加します。\n",
    "response_a_sequences = pad_sequences(response_a_sequences, maxlen=max_len, padding='post')  # レスポンスAのシーケンスを最大長にパディングします。\n",
    "response_b_sequences = pad_sequences(response_b_sequences, maxlen=max_len, padding='post')  # レスポンスBのシーケンスを最大長にパディングします。\n",
    "\n",
    "# pad_sequences()は、すべてのシーケンスを指定した最大長に整形し、短いシーケンスにはゼロや指定したパディング値を追加します。\n",
    "# padding='post'を指定することで、シーケンスの後ろにパディングを追加し、長さを統一します。これにより、モデルの入力データが整った形式になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2606a9b",
   "metadata": {},
   "source": [
    "### 感情分析\n",
    "\n",
    "`vaderSentiment`を使用した感情分析。VADER（Valence Aware Dictionary and sEntiment Reasoner）は、特にソーシャルメディアで表現される感情に調整された、辞書およびルールベースの感情分析ツールです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.38392Z",
     "iopub.status.busy": "2024-07-15T10:34:46.383538Z",
     "iopub.status.idle": "2024-07-15T10:34:46.410086Z",
     "shell.execute_reply": "2024-07-15T10:34:46.40907Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.383888Z"
    }
   },
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()  # 感情分析のためのSentimentIntensityAnalyzerを初期化します。\n",
    "\n",
    "# SentimentIntensityAnalyzerは、テキストの感情を評価するための便利なツールで、\n",
    "# 各テキストに対してポジティブ、ネガティブ、ニュートラルなスコアを生成し、\n",
    "# 全体的な感情の強度を示すコンパウンドスコアも計算します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.411742Z",
     "iopub.status.busy": "2024-07-15T10:34:46.411397Z",
     "iopub.status.idle": "2024-07-15T10:34:46.41693Z",
     "shell.execute_reply": "2024-07-15T10:34:46.41562Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.411701Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):  # 感情分析を行う関数を定義します。\n",
    "    return analyzer.polarity_scores(text)['compound']  # テキストの感情スコアを計算し、コンパウンドスコアを返します。\n",
    "\n",
    "# polarity_scores()メソッドは、入力テキストに対して感情のポジティブ、ネガティブ、ニュートラル、およびコンパウンドスコアを計算します。\n",
    "# コンパウンドスコアは、全体的な感情の強度を示し、-1（非常にネガティブ）から1（非常にポジティブ）の範囲で評価されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.428431Z",
     "iopub.status.busy": "2024-07-15T10:34:46.427898Z",
     "iopub.status.idle": "2024-07-15T10:34:46.46698Z",
     "shell.execute_reply": "2024-07-15T10:34:46.46566Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.428396Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['sentiment_prompt'] = train_data['prompt_clean'].apply(sentiment_analysis)  # クリーニングされたプロンプトに対して感情分析を行い、結果を'sentiment_prompt'列に格納します。\n",
    "train_data['sentiment_response_a'] = train_data['response_a_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスAに対して感情分析を行い、結果を'sentiment_response_a'列に格納します。\n",
    "train_data['sentiment_response_b'] = train_data['response_b_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスBに対して感情分析を行い、結果を'sentiment_response_b'列に格納します。\n",
    "\n",
    "# apply()メソッドを使用して、各クリーニングされたテキストにsentiment_analysis関数を適用することで、\n",
    "# 各テキストの感情スコアを計算し、新しい列としてデータフレームに追加します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5279bc",
   "metadata": {},
   "source": [
    "### テキスト特徴量\n",
    "\n",
    "単語数、文字数、語彙の多様性、音節数、文の数、各レスポンスの読みやすさを定量的に測定するFlesch Reading Easeスコアなどのテキスト特徴量を計算します。\n",
    "\n",
    "テキスト統計を分析するために`textstat`ライブラリを使用しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.469188Z",
     "iopub.status.busy": "2024-07-15T10:34:46.468702Z",
     "iopub.status.idle": "2024-07-15T10:34:46.479754Z",
     "shell.execute_reply": "2024-07-15T10:34:46.478069Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.46913Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_count(text):  # 単語数を計算する関数を定義します。\n",
    "    return len(text.split())  # テキストをスペースで分割し、単語数を返します。\n",
    "\n",
    "def char_count(text):  # 文字数を計算する関数を定義します。\n",
    "    return len(text)  # テキストの全体の長さ（文字数）を返します。\n",
    "\n",
    "def lexical_diversity(text):  # 語彙の多様性を計算する関数を定義します。\n",
    "    words = text.split()  # テキストを単語に分割します。\n",
    "    return len(set(words)) / len(words) if words else 0  # ユニークな単語の数を全単語数で割り、語彙の多様性を計算します。\n",
    "\n",
    "def syllable_count(text):  # 音節数を計算する関数を定義します。\n",
    "    return textstat.syllable_count(text)  # textstatライブラリを使用して音節数を返します。\n",
    "\n",
    "def sentence_count(text):  # 文の数を計算する関数を定義します。\n",
    "    return textstat.sentence_count(text)  # textstatライブラリを使用して文の数を返します。\n",
    "\n",
    "def flesch_reading_ease(text):  # Flesch Reading Easeスコアを計算する関数を定義します。\n",
    "    return textstat.flesch_reading_ease(text)  # textstatライブラリを使用してFlesch Reading Easeスコアを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.481803Z",
     "iopub.status.busy": "2024-07-15T10:34:46.481399Z",
     "iopub.status.idle": "2024-07-15T10:34:46.555079Z",
     "shell.execute_reply": "2024-07-15T10:34:46.553915Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.481769Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['word_count_prompt'] = train_data['prompt_clean'].apply(word_count)  # クリーニングされたプロンプトに対して単語数を計算し、'word_count_prompt'列に格納します。\n",
    "train_data['word_count_response_a'] = train_data['response_a_clean'].apply(word_count)  # クリーニングされたレスポンスAに対して単語数を計算し、'word_count_response_a'列に格納します。\n",
    "train_data['word_count_response_b'] = train_data['response_b_clean'].apply(word_count)  # クリーニングされたレスポンスBに対して単語数を計算し、'word_count_response_b'列に格納します。\n",
    "train_data['char_count_prompt'] = train_data['prompt_clean'].apply(char_count)  # クリーニングされたプロンプトに対して文字数を計算し、'char_count_prompt'列に格納します。\n",
    "train_data['char_count_response_a'] = train_data['response_a_clean'].apply(char_count)  # クリーニングされたレスポンスAに対して文字数を計算し、'char_count_response_a'列に格納します。\n",
    "train_data['char_count_response_b'] = train_data['response_b_clean'].apply(char_count)  # クリーニングされたレスポンスBに対して文字数を計算し、'char_count_response_b'列に格納します。\n",
    "train_data['lexical_diversity_prompt'] = train_data['prompt_clean'].apply(lexical_diversity)  # クリーニングされたプロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "train_data['lexical_diversity_response_a'] = train_data['response_a_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "train_data['lexical_diversity_response_b'] = train_data['response_b_clean'].apply(lexical_diversity)  # クリーニングされたレスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "train_data['syllable_count_prompt'] = train_data['prompt_clean'].apply(syllable_count)  # クリーニングされたプロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "train_data['syllable_count_response_a'] = train_data['response_a_clean'].apply(syllable_count)  # クリーニングされたレスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "train_data['syllable_count_response_b'] = train_data['response_b_clean'].apply(syllable_count)  # クリーニングされたレスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "train_data['sentence_count_prompt'] = train_data['prompt_clean'].apply(sentence_count)  # クリーニングされたプロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "train_data['sentence_count_response_a'] = train_data['response_a_clean'].apply(sentence_count)  # クリーニングされたレスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "train_data['sentence_count_response_b'] = train_data['response_b_clean'].apply(sentence_count)  # クリーニングされたレスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "train_data['flesch_reading_ease_prompt'] = train_data['prompt_clean'].apply(flesch_reading_ease)  # クリーニングされたプロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "train_data['flesch_reading_ease_response_a'] = train_data['response_a_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "train_data['flesch_reading_ease_response_b'] = train_data['response_b_clean'].apply(flesch_reading_ease)  # クリーニングされたレスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4bab08",
   "metadata": {},
   "source": [
    "### BERT埋め込みの作成\n",
    "\n",
    "トレーニングデータおよびテストデータのプロンプトとレスポンスに対してBERT埋め込みを計算します。また、各モデルのプロンプトとレスポンス間でBERTを使用したコサイン類似度特徴量も計算します。\n",
    "\n",
    "効率的なパイプラインを作成するために`tf.data.Dataset`を使用し、GPUを利用してバッチで特徴量を処理します。また、`joblib`ライブラリを使用して中間埋め込みを保存する予定です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:46.557088Z",
     "iopub.status.busy": "2024-07-15T10:34:46.556727Z",
     "iopub.status.idle": "2024-07-15T10:34:52.940246Z",
     "shell.execute_reply": "2024-07-15T10:34:52.939065Z",
     "shell.execute_reply.started": "2024-07-15T10:34:46.557055Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERTモデルをロードします。\n",
    "bert_model_name = 'bert-base-uncased'  # 使用するBERTモデルの名前を指定します。\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)  # BERTトークナイザーを事前学習済みモデルから初期化します。\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)  # BERTモデルを事前学習済みモデルから初期化します。\n",
    "\n",
    "# BertTokenizerはテキストをBERTモデル用にトークン化するためのもので、\n",
    "# TFBertModelはTensorFlowで動作するBERTモデル本体を提供します。\n",
    "# これにより、自然言語処理タスクにおいてBERTを利用できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.942183Z",
     "iopub.status.busy": "2024-07-15T10:34:52.941823Z",
     "iopub.status.idle": "2024-07-15T10:34:52.949586Z",
     "shell.execute_reply": "2024-07-15T10:34:52.948307Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.942133Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function  # TensorFlowの関数として最適化されることを示します。\n",
    "def get_bert_embeddings(texts):  # テキストに対してBERT埋め込みを取得する関数を定義します。\n",
    "    inputs = bert_tokenizer(texts,  # テキストをトークナイズします。\n",
    "                       return_tensors='tf',  # TensorFlowテンソルとして返します。\n",
    "                       padding=True,  # パディングを有効にします。\n",
    "                       truncation=True,  # テキストがmax_lengthを超える場合は切り捨てます。\n",
    "                       max_length=512)  # 最大入力長を512に設定します。\n",
    "    outputs = bert_model(inputs)  # BERTモデルを使用して埋め込みを生成します。\n",
    "    return outputs.last_hidden_state[:, 0, :]  # 最後の隠れ層の出力の最初のトークン（[CLS]トークン）の埋め込みを返します。\n",
    "\n",
    "# この関数は、与えられたテキストからBERT埋め込みを効率的に計算し、\n",
    "# 特に分類タスクなどで重要な役割を果たす[CLS]トークンの埋め込みを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.951293Z",
     "iopub.status.busy": "2024-07-15T10:34:52.950899Z",
     "iopub.status.idle": "2024-07-15T10:34:52.972941Z",
     "shell.execute_reply": "2024-07-15T10:34:52.971525Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.95126Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_column(column_data):  # 指定された列のデータを処理する関数を定義します。\n",
    "    column_data = column_data.dropna().tolist()  # 欠損値を削除し、リストに変換します。\n",
    "    column_data = [str(text) for text in column_data]  # 各テキストを文字列に変換します。  \n",
    "    dataset = tf.data.Dataset.from_tensor_slices(column_data)  # リストからTensorFlowデータセットを作成します。\n",
    "    dataset = dataset.batch(8)  # バッチサイズを8に設定します。\n",
    "\n",
    "    embeddings = []  # 埋め込みを格納するリストを初期化します。\n",
    "    for batch in dataset:  # データセットの各バッチに対してループします。\n",
    "        batch_list = [str(text) for text in batch.numpy().tolist()]  # バッチ内のテキストをリストに変換します。\n",
    "        batch_embeddings = get_bert_embeddings(batch_list)  # BERT埋め込みを取得します。\n",
    "        embeddings.append(batch_embeddings)  # 埋め込みをリストに追加します。\n",
    "    \n",
    "    return np.concatenate(embeddings, axis=0)  # 埋め込みを結合し、1つのNumPy配列として返します。\n",
    "\n",
    "# この関数は、与えられた列のテキストデータを処理し、BERTを使用して埋め込みを生成します。\n",
    "# バッチ処理を使用することで、メモリ使用量を最適化し、GPUを効率的に活用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.975178Z",
     "iopub.status.busy": "2024-07-15T10:34:52.974743Z",
     "iopub.status.idle": "2024-07-15T10:34:52.983785Z",
     "shell.execute_reply": "2024-07-15T10:34:52.982354Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.975124Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_embeddings_to_dataframe(df, column_names):  # データフレームに埋め込みを追加する関数を定義します。\n",
    "    for column in column_names:  # 各指定された列に対してループします。\n",
    "        print(f\"Processing column: {column}\")  # 現在処理中の列を表示します。\n",
    "        embeddings = process_column(df[column])  # 指定された列に対して埋め込みを生成します。\n",
    "        df[f'{column}_embedding'] = list(embeddings)  # 生成された埋め込みを新しい列としてデータフレームに追加します。\n",
    "    return df  # 更新されたデータフレームを返します。\n",
    "\n",
    "# この関数は、指定された列の埋め込みを計算し、それらを元のデータフレームに追加します。\n",
    "# これにより、元のデータとその埋め込み表現を一緒に保持することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.985878Z",
     "iopub.status.busy": "2024-07-15T10:34:52.985495Z",
     "iopub.status.idle": "2024-07-15T10:34:52.99625Z",
     "shell.execute_reply": "2024-07-15T10:34:52.994963Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.985846Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_embed = ['prompt_clean', 'response_a_clean', 'response_b_clean']  # 埋め込みを計算する列のリストを定義します。\n",
    "\n",
    "# このリストには、クリーンなプロンプトおよびレスポンスのテキストデータが含まれており、\n",
    "# 後でこれらの列に対してBERT埋め込みを生成するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:34:52.998794Z",
     "iopub.status.busy": "2024-07-15T10:34:52.997849Z",
     "iopub.status.idle": "2024-07-15T10:39:58.701392Z",
     "shell.execute_reply": "2024-07-15T10:39:58.700299Z",
     "shell.execute_reply.started": "2024-07-15T10:34:52.998754Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = add_embeddings_to_dataframe(train_data, columns_to_embed)  # 指定された列に対して埋め込みを追加し、更新されたデータフレームを保存します。\n",
    "\n",
    "# add_embeddings_to_dataframe関数を呼び出すことで、トレーニングデータに埋め込みを計算し、\n",
    "# 新たに生成された埋め込みがデータフレームに追加されます。これにより、元のテキストデータとその埋め込みが一緒に使用できる状態になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.7034Z",
     "iopub.status.busy": "2024-07-15T10:39:58.702927Z",
     "iopub.status.idle": "2024-07-15T10:39:58.780638Z",
     "shell.execute_reply": "2024-07-15T10:39:58.779496Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.703357Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['similarity_prompt_response_a'] = train_data.apply(  # プロンプトとレスポンスAのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "train_data['similarity_prompt_response_b'] = train_data.apply(  # プロンプトとレスポンスBのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2afbe9",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.782321Z",
     "iopub.status.busy": "2024-07-15T10:39:58.78195Z",
     "iopub.status.idle": "2024-07-15T10:39:58.791644Z",
     "shell.execute_reply": "2024-07-15T10:39:58.790528Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.782289Z"
    }
   },
   "outputs": [],
   "source": [
    "X = train_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、モデルの入力に使用する特徴量（X）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# 学習に用いるデータとして後で利用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.793424Z",
     "iopub.status.busy": "2024-07-15T10:39:58.793015Z",
     "iopub.status.idle": "2024-07-15T10:39:58.809536Z",
     "shell.execute_reply": "2024-07-15T10:39:58.807975Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.793392Z"
    }
   },
   "outputs": [],
   "source": [
    "# 目標列を定義します。\n",
    "train_data['winner'] = train_data.apply(lambda x: 0 if x['winner_model_a'] == 1 else (1 if x['winner_model_b'] == 1 else 2), axis=1)  # モデルAの勝利を0、モデルBの勝利を1、引き分けを2として設定します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対して条件に基づいて勝者のラベルを決定します。\n",
    "# これにより、モデルの出力として使用される目標変数（winner）が作成されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.811502Z",
     "iopub.status.busy": "2024-07-15T10:39:58.811071Z",
     "iopub.status.idle": "2024-07-15T10:39:58.820646Z",
     "shell.execute_reply": "2024-07-15T10:39:58.819425Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.811468Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train_data['winner']  # 目標変数（勝者）をyとして定義します。\n",
    "\n",
    "# このコードにより、トレーニングデータにおける各サンプルの勝者ラベルを含むシリーズが作成され、学習用モデルのターゲットとして使用されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127a53b",
   "metadata": {},
   "source": [
    "### トレーニングデータとバリデーションデータの分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.82304Z",
     "iopub.status.busy": "2024-07-15T10:39:58.822473Z",
     "iopub.status.idle": "2024-07-15T10:39:58.835465Z",
     "shell.execute_reply": "2024-07-15T10:39:58.834233Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.822995Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,  # データをトレーニングセットとバリデーションセットに分割します。\n",
    "                                                  random_state=42)  # テストサイズを20%に設定し、乱数シードを42にします。\n",
    "\n",
    "# train_test_split()関数は、指定されたデータ（特徴量Xとターゲットy）をトレーニングデータとバリデーションデータに分割します。\n",
    "# random_stateを設定することで、分割結果を再現可能にします。これにより、毎回同じデータが分割されることが保証されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dbe2aa",
   "metadata": {},
   "source": [
    "## モデルの定義\n",
    "\n",
    "* ランダムフォレスト\n",
    "* ロジスティック回帰\n",
    "* サポートベクターマシン\n",
    "* 勾配ブースティング\n",
    "* ニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.837525Z",
     "iopub.status.busy": "2024-07-15T10:39:58.837088Z",
     "iopub.status.idle": "2024-07-15T10:39:58.8461Z",
     "shell.execute_reply": "2024-07-15T10:39:58.844944Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.83749Z"
    }
   },
   "outputs": [],
   "source": [
    "models = {  # モデルの辞書を定義します。\n",
    "    'Random Forest': RandomForestClassifier(),  # ランダムフォレスト分類器を追加します。\n",
    "    'SVM': SVC(probability=True),  # サポートベクターマシンを追加し、確率予測を有効にします。\n",
    "    'Gradient Boosting': GradientBoostingClassifier()  # 勾配ブースティング分類器を追加します。\n",
    "}\n",
    "\n",
    "# この辞書は、後で使用するための異なるモデルを格納し、\n",
    "# モデルのトレーニングや評価を簡単に行えるようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.848381Z",
     "iopub.status.busy": "2024-07-15T10:39:58.847872Z",
     "iopub.status.idle": "2024-07-15T10:39:58.857714Z",
     "shell.execute_reply": "2024-07-15T10:39:58.856626Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.848339Z"
    }
   },
   "outputs": [],
   "source": [
    "# ニューラルネットワークを作成します。\n",
    "def create_nn_model(input_shape):  # 入力形状を受け取る関数を定義します。\n",
    "    model = Sequential()  # シーケンシャルモデルを初期化します。\n",
    "    model.add(Dense(128, input_shape=(input_shape,), activation='relu'))  # 入力層と128のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # ドロップアウト層を追加し、過学習を防ぎます。\n",
    "    model.add(Dense(64, activation='relu'))  # 64のユニットを持つ全結合層を追加します。\n",
    "    model.add(Dropout(0.2))  # 再度ドロップアウト層を追加します。\n",
    "    model.add(Dense(3, activation='softmax'))  # 出力層を追加し、3つのクラスの確率を出力します。\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # モデルをコンパイルします。\n",
    "    return model  # 定義したモデルを返します。\n",
    "\n",
    "# この関数は、指定された入力形状を持つニューラルネットワークモデルを構築し、\n",
    "# トレーニングに使用するための準備を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.860205Z",
     "iopub.status.busy": "2024-07-15T10:39:58.859381Z",
     "iopub.status.idle": "2024-07-15T10:39:58.949196Z",
     "shell.execute_reply": "2024-07-15T10:39:58.947845Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.860164Z"
    }
   },
   "outputs": [],
   "source": [
    "nn_model = create_nn_model(X_train.shape[1])  # トレーニングデータの特徴量の数に基づいてニューラルネットワークモデルを作成します。\n",
    "models['Neural Network'] = nn_model  # 作成したニューラルネットワークモデルをモデルの辞書に追加します。\n",
    "\n",
    "# これにより、ニューラルネットワークモデルが定義されたモデルのリストに追加され、\n",
    "# 他のモデルと同様にトレーニングや評価が可能になります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a4e41",
   "metadata": {},
   "source": [
    "モデルのトレーニングと評価:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:39:58.951637Z",
     "iopub.status.busy": "2024-07-15T10:39:58.951172Z",
     "iopub.status.idle": "2024-07-15T10:40:02.02086Z",
     "shell.execute_reply": "2024-07-15T10:40:02.019202Z",
     "shell.execute_reply.started": "2024-07-15T10:39:58.951595Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}  # モデルの評価結果を格納する辞書を初期化します。\n",
    "\n",
    "for name, model in models.items():  # 定義されたすべてのモデルに対してループします。\n",
    "    print(f\"トレーニングと評価を行っています: {name}...\")\n",
    "    \n",
    "    if name == 'Neural Network':  # ニューラルネットワークの場合\n",
    "        model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val), verbose=2)  # モデルをフィットし、検証データを使用します。\n",
    "        y_pred = np.argmax(model.predict(X_val), axis=1)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict(X_val)  # 予測確率を取得します。\n",
    "    else:  # その他のモデルの場合\n",
    "        model.fit(X_train, y_train)  # モデルをフィットします。\n",
    "        y_pred = model.predict(X_val)  # バリデーションデータに対する予測結果を取得します。\n",
    "        y_pred_proba = model.predict_proba(X_val)  # 予測確率を取得します。\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)  # 精度を計算します。\n",
    "    logloss = log_loss(y_val, y_pred_proba)  # ログ損失を計算します。\n",
    "\n",
    "    results[name] = {  # 結果を辞書に格納します。\n",
    "        '精度': accuracy,\n",
    "        'ログ損失': logloss,\n",
    "        '分類レポート': classification_report(y_val, y_pred),\n",
    "        '混同行列': confusion_matrix(y_val, y_pred)\n",
    "    }\n",
    "\n",
    "    print(f\"{name}の精度: {accuracy}\")  # モデルの精度を表示します。\n",
    "    print(f\"{name}のログ損失: {logloss}\")  # モデルのログ損失を表示します。\n",
    "    print(f\"{name}の分類レポート:\\n{classification_report(y_val, y_pred)}\")  # 分類レポートを表示します。\n",
    "    print(f\"{name}の混同行列:\\n{confusion_matrix(y_val, y_pred)}\\n\")  # 混同行列を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e06943",
   "metadata": {},
   "source": [
    "ログ損失に基づいて最良のモデルを選択しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.023456Z",
     "iopub.status.busy": "2024-07-15T10:40:02.022929Z",
     "iopub.status.idle": "2024-07-15T10:40:02.030486Z",
     "shell.execute_reply": "2024-07-15T10:40:02.029099Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.023412Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model_name = max(results, key=lambda name: results[name]['Log Loss'])  # 最小のログ損失を持つモデル名を取得します。\n",
    "best_model = models[best_model_name]  # 最良のモデルを辞書から取得します。\n",
    "\n",
    "# これにより、ログ損失が最も小さいモデルを選択し、\n",
    "# そのモデルを後で使用するための変数best_modelに格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f61bd0",
   "metadata": {},
   "source": [
    "## 予測と提出\n",
    "\n",
    "テストデータの準備、テストデータに対する予測、および提出用データの作成を行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.032815Z",
     "iopub.status.busy": "2024-07-15T10:40:02.032348Z",
     "iopub.status.idle": "2024-07-15T10:40:02.046864Z",
     "shell.execute_reply": "2024-07-15T10:40:02.045704Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.032778Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのテキストをクリーンアップします。\n",
    "test_data['prompt_clean'] = test_data['prompt'].apply(clean_text)  # 'prompt'列にclean_text関数を適用し、クリーンアップした結果を'prompt_clean'列に格納します。\n",
    "test_data['response_a_clean'] = test_data['response_a'].apply(clean_text)  # 'response_a'列にclean_text関数を適用し、クリーンアップした結果を'response_a_clean'列に格納します。\n",
    "test_data['response_b_clean'] = test_data['response_b'].apply(clean_text)  # 'response_b'列にclean_text関数を適用し、クリーンアップした結果を'response_b_clean'列に格納します。\n",
    "\n",
    "# このコードにより、テストデータのテキストが前処理され、モデルへの入力に適した形式になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.04956Z",
     "iopub.status.busy": "2024-07-15T10:40:02.048561Z",
     "iopub.status.idle": "2024-07-15T10:40:02.060016Z",
     "shell.execute_reply": "2024-07-15T10:40:02.058788Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.049512Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのテキストをトークン化します。\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['prompt_clean'])  # クリーンなプロンプトを数値のシーケンスに変換します。\n",
    "response_a_test_sequences = tokenizer.texts_to_sequences(test_data['response_a_clean'])  # クリーンなレスポンスAを数値のシーケンスに変換します。\n",
    "response_b_test_sequences = tokenizer.texts_to_sequences(test_data['response_b_clean'])  # クリーンなレスポンスBを数値のシーケンスに変換します。\n",
    "\n",
    "# texts_to_sequences()メソッドを使用することで、テキストをトークンに変換し、\n",
    "# モデルの入力として使用できる形式に準備します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.062371Z",
     "iopub.status.busy": "2024-07-15T10:40:02.061838Z",
     "iopub.status.idle": "2024-07-15T10:40:02.071771Z",
     "shell.execute_reply": "2024-07-15T10:40:02.070235Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.06233Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのシーケンスにパディングを行います。\n",
    "test_sequences = pad_sequences(test_sequences, maxlen=max_len, padding='post')  # プロンプトのシーケンスを最大長にパディングします。\n",
    "response_a_test_sequences = pad_sequences(response_a_test_sequences, maxlen=max_len, padding='post')  # レスポンスAのシーケンスを最大長にパディングします。\n",
    "response_b_test_sequences = pad_sequences(response_b_test_sequences, maxlen=max_len, padding='post')  # レスポンスBのシーケンスを最大長にパディングします。\n",
    "\n",
    "# pad_sequences()を使用することで、すべてのシーケンスを指定した最大長に整形し、\n",
    "# 短いシーケンスにはゼロパディングを追加して、モデルに入力できる形式にします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.073651Z",
     "iopub.status.busy": "2024-07-15T10:40:02.073274Z",
     "iopub.status.idle": "2024-07-15T10:40:02.087868Z",
     "shell.execute_reply": "2024-07-15T10:40:02.086574Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.073619Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに対して感情分析を行います。\n",
    "test_data['sentiment_prompt'] = test_data['prompt_clean'].apply(sentiment_analysis)  # クリーニングされたプロンプトに感情分析を適用し、結果を'sentiment_prompt'列に格納します。\n",
    "test_data['sentiment_response_a'] = test_data['response_a_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスAに感情分析を適用し、結果を'sentiment_response_a'列に格納します。\n",
    "test_data['sentiment_response_b'] = test_data['response_b_clean'].apply(sentiment_analysis)  # クリーニングされたレスポンスBに感情分析を適用し、結果を'sentiment_response_b'列に格納します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストの感情スコアが計算され、\n",
    "# 後のモデルに対する入力として使用できるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.089988Z",
     "iopub.status.busy": "2024-07-15T10:40:02.089469Z",
     "iopub.status.idle": "2024-07-15T10:40:02.117195Z",
     "shell.execute_reply": "2024-07-15T10:40:02.115839Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.089945Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータからテキスト構造の特徴量を作成します。\n",
    "test_data['word_count_prompt'] = test_data['prompt_clean'].apply(word_count)  # プロンプトの単語数を計算し、'word_count_prompt'列に格納します。\n",
    "test_data['word_count_response_a'] = test_data['response_a_clean'].apply(word_count)  # レスポンスAの単語数を計算し、'word_count_response_a'列に格納します。\n",
    "test_data['word_count_response_b'] = test_data['response_b_clean'].apply(word_count)  # レスポンスBの単語数を計算し、'word_count_response_b'列に格納します。\n",
    "test_data['char_count_prompt'] = test_data['prompt_clean'].apply(char_count)  # プロンプトの文字数を計算し、'char_count_prompt'列に格納します。\n",
    "test_data['char_count_response_a'] = test_data['response_a_clean'].apply(char_count)  # レスポンスAの文字数を計算し、'char_count_response_a'列に格納します。\n",
    "test_data['char_count_response_b'] = test_data['response_b_clean'].apply(char_count)  # レスポンスBの文字数を計算し、'char_count_response_b'列に格納します。\n",
    "test_data['lexical_diversity_prompt'] = test_data['prompt_clean'].apply(lexical_diversity)  # プロンプトの語彙の多様性を計算し、'lexical_diversity_prompt'列に格納します。\n",
    "test_data['lexical_diversity_response_a'] = test_data['response_a_clean'].apply(lexical_diversity)  # レスポンスAの語彙の多様性を計算し、'lexical_diversity_response_a'列に格納します。\n",
    "test_data['lexical_diversity_response_b'] = test_data['response_b_clean'].apply(lexical_diversity)  # レスポンスBの語彙の多様性を計算し、'lexical_diversity_response_b'列に格納します。\n",
    "test_data['syllable_count_prompt'] = test_data['prompt_clean'].apply(syllable_count)  # プロンプトの音節数を計算し、'syllable_count_prompt'列に格納します。\n",
    "test_data['syllable_count_response_a'] = test_data['response_a_clean'].apply(syllable_count)  # レスポンスAの音節数を計算し、'syllable_count_response_a'列に格納します。\n",
    "test_data['syllable_count_response_b'] = test_data['response_b_clean'].apply(syllable_count)  # レスポンスBの音節数を計算し、'syllable_count_response_b'列に格納します。\n",
    "test_data['sentence_count_prompt'] = test_data['prompt_clean'].apply(sentence_count)  # プロンプトの文の数を計算し、'sentence_count_prompt'列に格納します。\n",
    "test_data['sentence_count_response_a'] = test_data['response_a_clean'].apply(sentence_count)  # レスポンスAの文の数を計算し、'sentence_count_response_a'列に格納します。\n",
    "test_data['sentence_count_response_b'] = test_data['response_b_clean'].apply(sentence_count)  # レスポンスBの文の数を計算し、'sentence_count_response_b'列に格納します。\n",
    "test_data['flesch_reading_ease_prompt'] = test_data['prompt_clean'].apply(flesch_reading_ease)  # プロンプトのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_prompt'列に格納します。\n",
    "test_data['flesch_reading_ease_response_a'] = test_data['response_a_clean'].apply(flesch_reading_ease)  # レスポンスAのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_a'列に格納します。\n",
    "test_data['flesch_reading_ease_response_b'] = test_data['response_b_clean'].apply(flesch_reading_ease)  # レスポンスBのFlesch Reading Easeスコアを計算し、'flesch_reading_ease_response_b'列に格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:02.119023Z",
     "iopub.status.busy": "2024-07-15T10:40:02.118583Z",
     "iopub.status.idle": "2024-07-15T10:40:12.682698Z",
     "shell.execute_reply": "2024-07-15T10:40:12.681274Z",
     "shell.execute_reply.started": "2024-07-15T10:40:02.11899Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータに埋め込みを追加します。\n",
    "test_data = add_embeddings_to_dataframe(test_data, columns_to_embed)  # 定義した列に対して埋め込みを生成し、テストデータフレームに追加します。\n",
    "\n",
    "# このコードにより、テストデータの各テキストに対してBERT埋め込みが計算され、\n",
    "# 他の特徴量と一緒に保持されるようになります。これによって、モデルに対する入力が整います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.684691Z",
     "iopub.status.busy": "2024-07-15T10:40:12.684291Z",
     "iopub.status.idle": "2024-07-15T10:40:12.702179Z",
     "shell.execute_reply": "2024-07-15T10:40:12.700706Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.684656Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータのコサイン類似度を計算します。\n",
    "test_data['similarity_prompt_response_a'] = test_data.apply(  # プロンプト埋め込みとレスポンスA埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_a_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスA埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "test_data['similarity_prompt_response_b'] = test_data.apply(  # プロンプト埋め込みとレスポンスB埋め込みのコサイン類似度を計算して新しい列を作成します。\n",
    "    lambda x: cosine_similarity(np.array(x['prompt_clean_embedding']).reshape(1, -1),  # プロンプト埋め込みを1次元の配列に変形します。\n",
    "                                np.array(x['response_b_clean_embedding']).reshape(1, -1))[0][0], axis=1)  # レスポンスB埋め込みを1次元の配列に変形し、コサイン類似度を計算します。\n",
    "\n",
    "# apply()メソッドを使用して、各行に対してプロンプト埋め込みとレスポンス埋め込みのコサイン類似度を計算し、\n",
    "# 結果を新しい列に格納します。コサイン類似度は、二つのベクトルの角度を基にした類似度の指標であり、\n",
    "# 値が1に近いほど二つのベクトルが類似していることを意味します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.703966Z",
     "iopub.status.busy": "2024-07-15T10:40:12.703587Z",
     "iopub.status.idle": "2024-07-15T10:40:12.72027Z",
     "shell.execute_reply": "2024-07-15T10:40:12.718688Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.703935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = test_data[['word_count_prompt', 'word_count_response_a', 'word_count_response_b',  # プロンプトおよびレスポンスAとBの単語数\n",
    "                    'char_count_prompt', 'char_count_response_a', 'char_count_response_b',  # プロンプトおよびレスポンスの文字数\n",
    "                    'lexical_diversity_prompt', 'lexical_diversity_response_a', 'lexical_diversity_response_b',  # 語彙の多様性\n",
    "                    'syllable_count_prompt', 'syllable_count_response_a', 'syllable_count_response_b',  # 音節数\n",
    "                    'sentence_count_prompt', 'sentence_count_response_a', 'sentence_count_response_b',  # 文の数\n",
    "                    'flesch_reading_ease_prompt', 'flesch_reading_ease_response_a', 'flesch_reading_ease_response_b',  # Flesch Reading Easeスコア\n",
    "                    'similarity_prompt_response_a', 'similarity_prompt_response_b',  # コサイン類似度\n",
    "                    'sentiment_prompt', 'sentiment_response_a', 'sentiment_response_b']]  # 感情スコア\n",
    "\n",
    "# このコードは、テストデータの特徴量（X_test）のデータフレームを作成しています。\n",
    "# 各列はテキスト特徴量、感情スコア、コサイン類似度を表しており、\n",
    "# モデルによる予測のために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.722607Z",
     "iopub.status.busy": "2024-07-15T10:40:12.722101Z",
     "iopub.status.idle": "2024-07-15T10:40:12.855745Z",
     "shell.execute_reply": "2024-07-15T10:40:12.854613Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.722567Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred_proba = best_model.predict(X_test)  # 最良のモデルを使用してテストデータに対する予測確率を計算します。\n",
    "\n",
    "# このコードにより、テストデータに対して最良のモデルが予測を行い、\n",
    "# 各クラスに対する確率が'test_pred_proba'に格納されます。これにより、後でクラスラベルを決定するために使用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.857957Z",
     "iopub.status.busy": "2024-07-15T10:40:12.85759Z",
     "iopub.status.idle": "2024-07-15T10:40:12.870832Z",
     "shell.execute_reply": "2024-07-15T10:40:12.8695Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.857926Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(test_data['id'])  # テストデータの'id'列を含む新しいデータフレームを作成します。\n",
    "submission['winner_model_a'] = test_pred_proba[:, 0]  # モデルAの勝率を追加します。\n",
    "submission['winner_model_b'] = test_pred_proba[:, 1]  # モデルBの勝率を追加します。\n",
    "submission['winner_tie'] = test_pred_proba[:, 2]  # 引き分けの勝率を追加します。\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)  # 提出用データフレームをCSVファイルに保存します。\n",
    "\n",
    "# このコードにより、予測結果を含む提出ファイルが作成され、コンペティションへの提出に利用できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T10:40:12.872888Z",
     "iopub.status.busy": "2024-07-15T10:40:12.872415Z",
     "iopub.status.idle": "2024-07-15T10:40:12.887076Z",
     "shell.execute_reply": "2024-07-15T10:40:12.88578Z",
     "shell.execute_reply.started": "2024-07-15T10:40:12.87285Z"
    }
   },
   "outputs": [],
   "source": [
    "submission  # 作成した提出用データフレームを表示します。\n",
    "\n",
    "# これにより、提出ファイルに含まれる内容を確認できます。各行にはテストデータのIDと、その勝者モデルに対する予測確率が含まれています。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
