{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009b2351",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYSのChatbot Arenaコンペティションにおけるチャットボットの応答の好みを予測するための機械学習モデルの開発に取り組んでいます。具体的には、RoBERTaという事前学習済みモデルを用いて、与えられたテキストに対してラベルを予測するタスクを実行しています。\n",
    "\n",
    "## 問題の概要\n",
    "Notebookは、チャットボットからの応答を基にしたユーザーの好みを予測するためのモデルを構築することを目的としています。具体的には、トレーニングデータには、各モデルの応答が含まれており、どちらのモデルが好まれるかを予測するためのラベルが与えられています。\n",
    "\n",
    "## 使用している手法およびライブラリ\n",
    "1. **ライブラリ**:\n",
    "   - NumPy: 数値計算\n",
    "   - pandas: データ操作\n",
    "   - scikit-learn: モデルの評価（平均二乗誤差など）やデータの分割\n",
    "   - PyTorch: ニューラルネットワークの構築\n",
    "   - transformers: 事前学習済みのRoBERTaモデルの使用\n",
    "   - matplotlib: データの可視化\n",
    "   - tqdm: プログレスバーの表示\n",
    "\n",
    "2. **手法**:\n",
    "   - **データの準備**: 訓練データとテストデータの読み込みと前処理を行い、層化K分割交差検証を使用してデータを分割。\n",
    "   - **トークナイゼーション**: RoBERTaトークナイザーを用いてテキストデータをトークン化し、モデルに入力できる形式に変換。\n",
    "   - **モデルの構築**: PyTorchを使用してRoBERTaモデルベースの分類器を構築し、訓練データに基づいて学習。\n",
    "   - **訓練と評価**: モデルを訓練し（自動混合精度を使用）、検証データで評価するルーチンを実装。\n",
    "   - **予測**: テストデータに対して予測を実行し、最終的な結果を提出用の形式に整形。\n",
    "\n",
    "このNotebookは、RoBERTaを利用した深層学習を通じて、ユーザーの好みを予測するモデルを開発するための一連のプロセスを詳しく示しています。最終的に得られた予測結果を元に提出ファイルを生成する準備を行っています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafb4255",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容を基に、機械学習・深層学習の初心者がつまずきそうな専門用語についての簡単な解説を列挙します。\n",
    "\n",
    "1. **torch.cuda.amp.GradScaler**\n",
    "   - PyTorchの自動混合精度トレーニングで使用するスケーラー。このスケーラーは、計算の精度を自動的に調整し、メモリ消費を減らしつつ、モデルのトレーニングを高速化します。\n",
    "\n",
    "2. **cuDNN**\n",
    "   - NVIDIAのGPU向けの深層学習を最適化するためのライブラリ。特に、畳込み層の計算を高速化するために利用され、GPUを使用している場合に速さを向上させる役割を持ちます。\n",
    "\n",
    "3. **StratifiedKFold**\n",
    "   - 層化K分割交差検証。データセットをK個のフォールドに分割する際、各フォールドが元のデータセットのクラス分布を維持するように注意して分割します。これにより、クラスの不均衡がある場合でも効果的に評価できます。\n",
    "\n",
    "4. **tokenizer**  \n",
    "   - 文章をトークンに分割し、機械が扱いやすい形式に変換するツール。トークニゼーションは自然言語処理において基本的なステップであり、入力文をモデルが理解できる形式にするのに重要です。\n",
    "\n",
    "5. **attention_mask**\n",
    "   - トークン化された入力シーケンスにおいて、どのトークンがモデルによって注意を払うべきかを示すマスク。通常、パディングされた部分は0（無視する）とし、実際のトークンには1（処理する）を設定します。\n",
    "\n",
    "6. **AdamW**\n",
    "   - Adamオプティマイザの改良版で、重みの減衰（weight decay）を直接オプティマイザに組み込んでいます。これはオーバーフィッティングを防ぐための技術で、特に深層学習において成果を上げています。\n",
    "\n",
    "7. **get_linear_schedule_with_warmup**\n",
    "   - 学習率スケジューラで、訓練の最初に学習率を徐々に上げ（ウォームアップ）、その後線形に減少させる方法。これにより、初期の研磨が行われ、学習がより安定します。\n",
    "\n",
    "8. **RMSE (Root Mean Squared Error)**\n",
    "   - 平均二乗誤差の平方根を取った指標。予測と実際の値との誤差の大きさを示すもので、モデルの性能評価に使用されます。値が低いほど良いモデルとされます。\n",
    "\n",
    "9. **DataLoader**\n",
    "   - PyTorchにおけるデータの入出力管理のためのユーティリティ。バッチ処理やデータのシャッフル、マルチスレッドによるデータの前処理が容易に行えます。\n",
    "\n",
    "10. **encode_plus**\n",
    "    - Transformersライブラリで入力テキストをトークン化し、モデルに渡す準備をするためのメソッド。入力トークンID、注意マスク、そしてオプションで追加情報を生成します。\n",
    "\n",
    "11. **class Dataset**\n",
    "    - PyTorchにおいてカスタムデータセットを定義するためのクラス。通常、データセットが持つデータやラベルを管理し、データローダーが使いやすい形式で返すメソッド（`__getitem__` や `__len__`）を持っています。\n",
    "\n",
    "12. **torch.no_grad()**\n",
    "    - 勾配計算を無効にするためのコンテキストマネージャ。モデルの評価や推論時に使用し、無駄な計算を省くために活用します。\n",
    "\n",
    "これらの用語は、初心者にとっては親しみのないものもあるため、特に注意が必要です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3714513d",
   "metadata": {},
   "source": [
    "# LMSYS キーワード torch RoBERTa\n",
    "インターネット上の条件の下で\n",
    "\n",
    "https://www.kaggle.com/code/stpeteishii/lmsys-prompt-response-words-keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:22:50.432157Z",
     "iopub.status.busy": "2024-07-23T09:22:50.431872Z",
     "iopub.status.idle": "2024-07-23T09:23:02.326852Z",
     "shell.execute_reply": "2024-07-23T09:23:02.325671Z",
     "shell.execute_reply.started": "2024-07-23T09:22:50.432132Z"
    },
    "papermill": {
     "duration": 13.253789,
     "end_time": "2023-06-28T07:17:40.715086",
     "exception": false,
     "start_time": "2023-06-28T07:17:27.461297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install chardet  # chardetライブラリをインストールします。 これは、文字エンコーディングを自動的に検出するために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:23:02.328852Z",
     "iopub.status.busy": "2024-07-23T09:23:02.328537Z",
     "iopub.status.idle": "2024-07-23T09:23:02.33341Z",
     "shell.execute_reply": "2024-07-23T09:23:02.332436Z",
     "shell.execute_reply.started": "2024-07-23T09:23:02.328825Z"
    },
    "papermill": {
     "duration": 0.020191,
     "end_time": "2023-06-28T07:17:40.747178",
     "exception": false,
     "start_time": "2023-06-28T07:17:40.726987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# debug = False  # デバッグモードを無効にします。デバッグ情報は表示されません。\n",
    "# debug2 = False  # さらなるデバッグモードを無効にします。追加のデバッグ情報は表示されません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:23:02.336693Z",
     "iopub.status.busy": "2024-07-23T09:23:02.334581Z",
     "iopub.status.idle": "2024-07-23T09:23:02.349212Z",
     "shell.execute_reply": "2024-07-23T09:23:02.348327Z",
     "shell.execute_reply.started": "2024-07-23T09:23:02.336668Z"
    },
    "papermill": {
     "duration": 6.118647,
     "end_time": "2023-06-28T07:17:46.877542",
     "exception": false,
     "start_time": "2023-06-28T07:17:40.758895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np  # NumPyライブラリをインポートします。数値計算に使います。\n",
    "import pandas as pd  # pandasライブラリをインポートします。データ操作に使います。\n",
    "import os  # osモジュールをインポートします。ファイルやディレクトリ操作に使います。\n",
    "from sklearn.metrics import mean_squared_error  # 平均二乗誤差を計算するための関数をインポートします。\n",
    "from sklearn.model_selection import StratifiedKFold  # 層化K分割交差検証を行うためのクラスをインポートします。\n",
    "import torch  # PyTorchライブラリをインポートします。深層学習に使います。\n",
    "import torch.nn as nn  # PyTorchのニューラルネットワークモジュールをインポートします。\n",
    "from torch.utils.data import DataLoader, Dataset  # データローダーとデータセットのクラスをインポートします。\n",
    "from tqdm import tqdm  # 進捗バーを表示するためのtqdmをインポートします。\n",
    "import matplotlib.pyplot as plt  # グラフ描画のためのmatplotlibをインポートします。\n",
    "import transformers  # transformersライブラリをインポートします。事前学習済みモデルにアクセスするために使用します。\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification  # トークナイザーと分類用モデルをインポートします。\n",
    "import random  # ランダム数生成のためのrandomモジュールをインポートします。\n",
    "import chardet  # 文字エンコーディングを自動的に検出するためのchardetをインポートします。\n",
    "import warnings  # 警告メッセージの制御のためにwarningsモジュールをインポートします。\n",
    "warnings.simplefilter('ignore')  # 警告を無視するフィルターを設定します。\n",
    "scaler = torch.cuda.amp.GradScaler()  # 自動混合精度トレーニングに使うスケーラーを初期化します。\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 使用可能なデバイスを確認し、CUDA対応GPUがあればそれを使います。\n",
    "device  # 現在使用しているデバイスを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:23:02.350557Z",
     "iopub.status.busy": "2024-07-23T09:23:02.350258Z",
     "iopub.status.idle": "2024-07-23T09:23:02.360647Z",
     "shell.execute_reply": "2024-07-23T09:23:02.359898Z",
     "shell.execute_reply.started": "2024-07-23T09:23:02.350535Z"
    },
    "papermill": {
     "duration": 0.026662,
     "end_time": "2023-06-28T07:17:46.916292",
     "exception": false,
     "start_time": "2023-06-28T07:17:46.88963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_seed(SEED):  # ランダムシードを設定する関数を定義します。\n",
    "    \n",
    "    random.seed(SEED)  # randomモジュールのシードを設定します。\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)  # 環境変数にシードを設定します。ハッシュ値の決定に影響します。\n",
    "    np.random.seed(SEED)  # NumPyの乱数生成器のシードを設定します。\n",
    "    torch.manual_seed(SEED)  # PyTorch CPUのシードを設定します。\n",
    "    torch.cuda.manual_seed(SEED)  # PyTorchのCUDA GPUのシードを設定します。\n",
    "    torch.cuda.manual_seed_all(SEED)  # 全てのCUDAデバイスにシードを設定します。\n",
    "    torch.backends.cudnn.deterministic = True  # cuDNNの決定論的動作を有効にします。これにより再現性が向上します。\n",
    "    \n",
    "SEED = 508  # 使用するシード値を設定します。\n",
    "random_seed(SEED)  # 定義した関数を呼び出してシードを設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085a0f7e",
   "metadata": {},
   "source": [
    "# ラベルはランキングです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:23:02.361849Z",
     "iopub.status.busy": "2024-07-23T09:23:02.361623Z",
     "iopub.status.idle": "2024-07-23T09:23:02.443216Z",
     "shell.execute_reply": "2024-07-23T09:23:02.442407Z",
     "shell.execute_reply.started": "2024-07-23T09:23:02.36183Z"
    }
   },
   "outputs": [],
   "source": [
    "train0 = pd.read_csv('/kaggle/input/lmsys-prompt-response-words-keybert/train_key.csv')  # 訓練データをCSVファイルから読み込みます。\n",
    "train0 = train0[0:20000]  # 訓練データの最初の20,000行を取得します。\n",
    "display(train0)  # 訓練データを表示します。\n",
    "print(train0.columns.tolist())  # 訓練データのカラム名をリスト形式で表示します。\n",
    "\n",
    "test0 = pd.read_csv('/kaggle/input/lmsys-prompt-response-words-keybert/test_key.csv')  # テストデータをCSVファイルから読み込みます。\n",
    "display(test0)  # テストデータを表示します。\n",
    "print(test0.columns.tolist())  # テストデータのカラム名をリスト形式で表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-23T09:31:37.966978Z",
     "iopub.status.busy": "2024-07-23T09:31:37.966597Z",
     "iopub.status.idle": "2024-07-23T09:31:37.993858Z",
     "shell.execute_reply": "2024-07-23T09:31:37.992982Z",
     "shell.execute_reply.started": "2024-07-23T09:31:37.966951Z"
    }
   },
   "outputs": [],
   "source": [
    "trainA = train0[['res_a_kw', 'winner_model_a']]  # 訓練データからモデルAに関するカラムを選択します。\n",
    "trainA.columns = ['text', 'label']  # カラム名を 'text' と 'label' に変更します。\n",
    "trainB = train0[['res_b_kw', 'winner_model_b']]  # 訓練データからモデルBに関するカラムを選択します。\n",
    "trainB.columns = ['text', 'label']  # カラム名を 'text' と 'label' に変更します。\n",
    "data = pd.concat([trainA, trainB], axis=0)  # モデルAとモデルBのデータを縦に結合します。\n",
    "\n",
    "testA = test0[['res_a_kw']]  # テストデータからモデルAに関するカラムを選択します。\n",
    "testA['label'] = 0  # モデルAのラベルを0に設定します。\n",
    "testA.columns = ['text', 'label']  # カラム名を 'text' と 'label' に変更します。\n",
    "testB = test0[['res_b_kw']]  # テストデータからモデルBに関するカラムを選択します。\n",
    "testB['label'] = 0  # モデルBのラベルを0に設定します。\n",
    "testB.columns = ['text', 'label']  # カラム名を 'text' と 'label' に変更します。\n",
    "TEST = pd.concat([testA, testB], axis=0)  # モデルAとモデルBのテストデータを縦に結合します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:00.618653Z",
     "iopub.status.busy": "2024-04-21T15:27:00.618357Z",
     "iopub.status.idle": "2024-04-21T15:27:00.668866Z",
     "shell.execute_reply": "2024-04-21T15:27:00.667944Z",
     "shell.execute_reply.started": "2024-04-21T15:27:00.618628Z"
    },
    "papermill": {
     "duration": 0.026581,
     "end_time": "2023-06-28T07:18:29.183917",
     "exception": false,
     "start_time": "2023-06-28T07:18:29.157336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # データを訓練セットとテストセットに分割するための関数をインポートします。\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)  # データを80%の訓練セットと20%のテストセットに分割します。random_stateを設定することで再現性を持たせます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:00.670721Z",
     "iopub.status.busy": "2024-04-21T15:27:00.67012Z",
     "iopub.status.idle": "2024-04-21T15:27:04.921664Z",
     "shell.execute_reply": "2024-04-21T15:27:04.92069Z",
     "shell.execute_reply.started": "2024-04-21T15:27:00.670688Z"
    },
    "papermill": {
     "duration": 2.112898,
     "end_time": "2023-06-28T07:18:31.309109",
     "exception": false,
     "start_time": "2023-06-28T07:18:29.196211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")  # BERTのトークナイザーを事前学習済みモデルから読み込みます。パスは指定された場所に応じて設定します。\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"roberta-base\")  # RoBERTaのトークナイザーを事前学習済みモデルから読み込みます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:04.923347Z",
     "iopub.status.busy": "2024-04-21T15:27:04.923052Z",
     "iopub.status.idle": "2024-04-21T15:27:11.313477Z",
     "shell.execute_reply": "2024-04-21T15:27:11.312494Z",
     "shell.execute_reply.started": "2024-04-21T15:27:04.923321Z"
    },
    "papermill": {
     "duration": 5.697647,
     "end_time": "2023-06-28T07:18:37.019837",
     "exception": false,
     "start_time": "2023-06-28T07:18:31.32219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_s = train['text'].iloc[0]  # 訓練データから最初のテキストを取得します。\n",
    "result1 = tokenizer.encode_plus(test_s)  # テキストをトークン化し、入力IDと注意マスクなどを生成します。\n",
    "tokenizer.decode(result1[\"input_ids\"])  # トークン化された入力IDをデコードして元のテキストに戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.31493Z",
     "iopub.status.busy": "2024-04-21T15:27:11.314643Z",
     "iopub.status.idle": "2024-04-21T15:27:11.32222Z",
     "shell.execute_reply": "2024-04-21T15:27:11.321279Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.314899Z"
    },
    "papermill": {
     "duration": 0.022816,
     "end_time": "2023-06-28T07:18:37.055794",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.032978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(test_s.split(\" \"))  # テキストをスペースで分割し、単語の数をカウントします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.326432Z",
     "iopub.status.busy": "2024-04-21T15:27:11.326177Z",
     "iopub.status.idle": "2024-04-21T15:27:11.336362Z",
     "shell.execute_reply": "2024-04-21T15:27:11.335725Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.326409Z"
    },
    "papermill": {
     "duration": 0.020965,
     "end_time": "2023-06-28T07:18:37.089429",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.068464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = tokenizer.encode_plus(  # テキストをトークン化してエンコードします。\n",
    "    test_s,  # エンコードするテキスト\n",
    "    add_special_tokens=True,  # 特殊トークン（[CLS]や[SEP]）を追加します。\n",
    "    max_length=20,  # 最大トークン数を20に設定します。\n",
    "    pad_to_max_length=True,  # 最大トークン数に満たない場合はパディングを追加します。\n",
    "    truncation=True  # 最大長を超える場合はトークンを切り捨てます。\n",
    ")  # エンコードされた結果をresult2に格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.338107Z",
     "iopub.status.busy": "2024-04-21T15:27:11.337843Z",
     "iopub.status.idle": "2024-04-21T15:27:11.349792Z",
     "shell.execute_reply": "2024-04-21T15:27:11.348942Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.338081Z"
    },
    "papermill": {
     "duration": 0.02102,
     "end_time": "2023-06-28T07:18:37.123143",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.102123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.decode(result2[\"input_ids\"])  # エンコードされた入力IDをデコードして、人間が読める形式のテキストに戻します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.351248Z",
     "iopub.status.busy": "2024-04-21T15:27:11.350926Z",
     "iopub.status.idle": "2024-04-21T15:27:11.361283Z",
     "shell.execute_reply": "2024-04-21T15:27:11.360591Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.351214Z"
    },
    "papermill": {
     "duration": 0.030376,
     "end_time": "2023-06-28T07:18:37.166117",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.135741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sens = 20  # 最大文の長さを20に設定します。\n",
    "\n",
    "train = train.sort_values(\"label\").reset_index(drop=True)  # ラベルに基づいて訓練データをソートし、インデックスをリセットします。\n",
    "\n",
    "train[\"kfold\"] = train.index % 5  # K-Foldクロスバリデーションのために0から4のインデックスを生成します。\n",
    "\n",
    "p_train = train[train[\"kfold\"] != 0].reset_index(drop=True)  # K-Foldのインデックスが0でない訓練データを取得します。\n",
    "p_valid = train[train[\"kfold\"] == 0].reset_index(drop=True)  # K-Foldのインデックスが0の訓練データを取得し、検証データとします。\n",
    "\n",
    "p_test = TEST.reset_index(drop=True)  # テストデータのインデックスをリセットします。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa42fb7a",
   "metadata": {},
   "source": [
    "'>>token_type_ids' はRoBERTa/DeBERTaでは必要ありません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.362469Z",
     "iopub.status.busy": "2024-04-21T15:27:11.362223Z",
     "iopub.status.idle": "2024-04-21T15:27:11.371986Z",
     "shell.execute_reply": "2024-04-21T15:27:11.37122Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.362448Z"
    },
    "papermill": {
     "duration": 0.023548,
     "end_time": "2023-06-28T07:18:37.228036",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.204488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataSet(Dataset):  # BERT用のデータセットクラスを定義します。\n",
    "    \n",
    "    def __init__(self, sentences, targets):  # コンストラクタで文とターゲットを受け取ります。        \n",
    "        self.sentences = sentences  # 文をインスタンス変数に格納します。\n",
    "        self.targets = targets  # ターゲットをインスタンス変数に格納します。\n",
    "        \n",
    "    def __len__(self):  # データセットの長さを返すメソッドを定義します。        \n",
    "        return len(self.sentences)  # 文の数を返します。\n",
    "    \n",
    "    def __getitem__(self, idx):  # インデックス指定でデータを取得するメソッドを定義します。        \n",
    "        sentence = self.sentences[idx]  # 指定されたインデックスの文を取得します。    \n",
    "        bert_sens = tokenizer.encode_plus(  # 文をトークン化し、BERT用の形式に変換します。\n",
    "                                sentence,\n",
    "                                add_special_tokens=True,  # 特殊トークンを追加します。\n",
    "                                max_length=max_sens,  # 最大長を設定します。\n",
    "                                pad_to_max_length=True,  # 最大長にパディングします。\n",
    "                                return_attention_mask=True)  # 注意マスクも返します。\n",
    "\n",
    "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)  # 入力IDをテンソルに変換します。\n",
    "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)  # 注意マスクをテンソルに変換します。\n",
    "\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float)  # ターゲットをテンソルに変換します。\n",
    "        \n",
    "        return {  # 辞書形式でデータを返します。\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': target\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.373525Z",
     "iopub.status.busy": "2024-04-21T15:27:11.373088Z",
     "iopub.status.idle": "2024-04-21T15:27:11.382953Z",
     "shell.execute_reply": "2024-04-21T15:27:11.382072Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.373494Z"
    },
    "papermill": {
     "duration": 0.023996,
     "end_time": "2023-06-28T07:18:37.264616",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.24062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = BERTDataSet(p_train[\"text\"], p_train[\"label\"])  # 訓練データセットをBERTDataSetクラスを使って作成します。\n",
    "valid_dataset = BERTDataSet(p_valid[\"text\"], p_valid[\"label\"])  # 検証データセットを作成します。\n",
    "test_dataset = BERTDataSet(p_test[\"text\"], p_test[\"label\"])  # テストデータセットを作成します。\n",
    "\n",
    "train_batch = 16  # 訓練時のバッチサイズを16に設定します。\n",
    "valid_batch = 32  # 検証時のバッチサイズを32に設定します。\n",
    "test_batch = 32   # テスト時のバッチサイズを32に設定します。\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, num_workers=8, pin_memory=True)  # 訓練データローダーを作成します。\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=valid_batch, shuffle=False, num_workers=8, pin_memory=True)  # 検証データローダーを作成します。\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch, shuffle=False, num_workers=8, pin_memory=True)  # テストデータローダーを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:11.384979Z",
     "iopub.status.busy": "2024-04-21T15:27:11.384056Z",
     "iopub.status.idle": "2024-04-21T15:27:22.908743Z",
     "shell.execute_reply": "2024-04-21T15:27:22.907975Z",
     "shell.execute_reply.started": "2024-04-21T15:27:11.384943Z"
    },
    "papermill": {
     "duration": 5.239221,
     "end_time": "2023-06-28T07:18:42.516586",
     "exception": false,
     "start_time": "2023-06-28T07:18:37.277365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)  # RoBERTaの事前学習済みモデルを読み込み、シーケンス分類用に設定します。ラベル数は1です。\n",
    "# model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\", num_labels=1)  # BERTの事前学習済みモデルを読み込むためのコメントアウトされたコードです。こちらもラベル数は1です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:22.910275Z",
     "iopub.status.busy": "2024-04-21T15:27:22.909926Z",
     "iopub.status.idle": "2024-04-21T15:27:23.209704Z",
     "shell.execute_reply": "2024-04-21T15:27:23.208753Z",
     "shell.execute_reply.started": "2024-04-21T15:27:22.910245Z"
    },
    "papermill": {
     "duration": 5.090094,
     "end_time": "2023-06-28T07:18:47.620511",
     "exception": false,
     "start_time": "2023-06-28T07:18:42.530417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)  # モデルを指定したデバイス（GPUまたはCPU）に移動させます。\n",
    "model.train()  # モデルを訓練モードに設定します。これにより、ドロップアウトなどの訓練専用の機能が有効になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:23.211394Z",
     "iopub.status.busy": "2024-04-21T15:27:23.211096Z",
     "iopub.status.idle": "2024-04-21T15:27:24.093806Z",
     "shell.execute_reply": "2024-04-21T15:27:24.092767Z",
     "shell.execute_reply.started": "2024-04-21T15:27:23.211369Z"
    },
    "papermill": {
     "duration": 2.557418,
     "end_time": "2023-06-28T07:18:50.195121",
     "exception": false,
     "start_time": "2023-06-28T07:18:47.637703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for a in train_dataloader:  # 訓練データローダーからデータを取得するループを開始します。\n",
    "    ids = a[\"ids\"].to(device)  # バッチ内の入力IDをデバイスに移動させます。\n",
    "    mask = a[\"mask\"].to(device)  # バッチ内の注意マスクをデバイスに移動させます。\n",
    "    output = model(ids, mask)  # モデルにIDとマスクを入力し、出力を取得します。\n",
    "    break  # 一度のループで処理を止めます。 (デバッグ目的についての一時停止)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.095438Z",
     "iopub.status.busy": "2024-04-21T15:27:24.095141Z",
     "iopub.status.idle": "2024-04-21T15:27:24.102328Z",
     "shell.execute_reply": "2024-04-21T15:27:24.101496Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.095408Z"
    },
    "papermill": {
     "duration": 0.027307,
     "end_time": "2023-06-28T07:18:50.236812",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.209505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = output[\"logits\"].squeeze(-1).shape  # モデルの出力からlogitsを抽出し、次元を1つ削減して、出力の形状を取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.103928Z",
     "iopub.status.busy": "2024-04-21T15:27:24.103688Z",
     "iopub.status.idle": "2024-04-21T15:27:24.123001Z",
     "shell.execute_reply": "2024-04-21T15:27:24.122352Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.103907Z"
    },
    "papermill": {
     "duration": 0.033736,
     "end_time": "2023-06-28T07:18:50.284707",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.250971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW  # AdamWオプティマイザをインポートします。\n",
    "LR = 2e-5  # 学習率を2e-5に設定します。\n",
    "optimizer = AdamW(model.parameters(), LR, betas=(0.9, 0.999), weight_decay=1e-2)  # モデルのパラメータに対してAdamWオプティマイザを初期化します。ベータ値と重み減衰率も設定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6891c6",
   "metadata": {},
   "source": [
    "# エポック数を設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.124184Z",
     "iopub.status.busy": "2024-04-21T15:27:24.123934Z",
     "iopub.status.idle": "2024-04-21T15:27:24.130037Z",
     "shell.execute_reply": "2024-04-21T15:27:24.129018Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.124162Z"
    },
    "papermill": {
     "duration": 0.026503,
     "end_time": "2023-06-28T07:18:50.325816",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.299313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup  # ウォームアップ付きの線形スケジューラをインポートします。\n",
    "epochs = 30  # エポック数を30に設定します。\n",
    "# if debug:\n",
    "#     epochs = 1  # デバッグモードの場合、エポック数を1に設定します（コメントアウトされています）。\n",
    "train_steps = int(len(p_train) / train_batch * epochs)  # 訓練ステップ数を計算します。\n",
    "print(train_steps)  # 計算された訓練ステップ数を表示します。\n",
    "num_steps = int(train_steps * 0.1)  # ウォームアップ期間中のステップ数を全体の10%として計算します。\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)  # オプティマイザ用にウォームアップ付きの線形スケジューラを初期化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.13148Z",
     "iopub.status.busy": "2024-04-21T15:27:24.131178Z",
     "iopub.status.idle": "2024-04-21T15:27:24.138481Z",
     "shell.execute_reply": "2024-04-21T15:27:24.137556Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.131451Z"
    },
    "papermill": {
     "duration": 0.024242,
     "end_time": "2023-06-28T07:18:50.365039",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.340797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(output, target):  # 出力とターゲットに基づいて損失を計算する関数を定義します。\n",
    "    return torch.sqrt(nn.MSELoss()(output, target))  # 平均二乗誤差（MSE）を計算し、それに平方根を取ってロスを返します。これはRMSE（Root Mean Squared Error）を求めるためです。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fb635c",
   "metadata": {},
   "source": [
    "# トレーニング（訓練）関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.139863Z",
     "iopub.status.busy": "2024-04-21T15:27:24.139598Z",
     "iopub.status.idle": "2024-04-21T15:27:24.149616Z",
     "shell.execute_reply": "2024-04-21T15:27:24.148819Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.13984Z"
    },
    "papermill": {
     "duration": 0.029401,
     "end_time": "2023-06-28T07:18:50.439727",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.410326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(  # 訓練を行う関数を定義します。\n",
    "    train_dataloader,  # 訓練データローダー\n",
    "    model,  # モデル\n",
    "    optimizer,  # オプティマイザ\n",
    "    scheduler  # スケジューラ\n",
    "):\n",
    "    \n",
    "    model.train()  # モデルを訓練モードに設定します。\n",
    "    torch.backends.cudnn.benchmark = True  # cuDNNのベンチマークを有効にします。動的な最適化のために使用されます。\n",
    "    allpreds = []  # すべての予測を格納するリスト\n",
    "    alltargets = []  # すべてのターゲットを格納するリスト\n",
    "\n",
    "    for a in train_dataloader:  # 訓練データローダーからデータを取得します。\n",
    "\n",
    "        losses = []  # 各バッチの損失を格納するリスト\n",
    "        optimizer.zero_grad()  # 勾配を初期化します。\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # 自動混合精度を使用して計算します。\n",
    "            \n",
    "            ids = a[\"ids\"].to(device, non_blocking=True)  # バッチ内の入力IDをデバイスに移動させます。\n",
    "            mask = a[\"mask\"].to(device, non_blocking=True)  # バッチ内の注意マスクをデバイスに移動させます。\n",
    "\n",
    "            output = model(ids, mask)  # モデルにIDとマスクを入力し、出力を取得します。\n",
    "            output = output[\"logits\"].squeeze(-1)  # 出力からlogitsを抽出し、次元を1つ削減します。\n",
    "            target = a[\"targets\"].to(device, non_blocking=True)  # バッチ内のターゲットをデバイスに移動させます。\n",
    "            loss = loss_fn(output, target)  # 出力とターゲットを用いて損失を計算します。\n",
    "\n",
    "            losses.append(loss.item())  # 損失を記録します。\n",
    "            allpreds.append(output.detach().cpu().numpy())  # 予測をCPUに移動させるとともにリストに追加します。\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())  # ターゲットをCPUに移動させ、リストに追加します。\n",
    "\n",
    "        scaler.scale(loss).backward()  # 損失をスケールし、逆伝播を行います。\n",
    "        scaler.step(optimizer)  # オプティマイザでステップ実行します。\n",
    "        scaler.update()  # スケーラーを更新します。\n",
    "        \n",
    "        del loss  # 使用した損失のメモリを解放します。\n",
    "\n",
    "        scheduler.step()  # スケジューラを1ステップ進めます。\n",
    "\n",
    "    allpreds = np.concatenate(allpreds)  # すべての予測を結合します。\n",
    "    alltargets = np.concatenate(alltargets)  # すべてのターゲットを結合します。\n",
    "    losses = np.mean(losses)  # すべての損失の平均を計算します。\n",
    "    train_rme_loss = np.sqrt(mean_squared_error(alltargets, allpreds))  # RMSEを計算します。\n",
    "\n",
    "    return losses, train_rme_loss  # 損失とRMSEを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81773945",
   "metadata": {},
   "source": [
    "# 検証（バリデーション）関数の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:24.151088Z",
     "iopub.status.busy": "2024-04-21T15:27:24.150802Z",
     "iopub.status.idle": "2024-04-21T15:27:24.163516Z",
     "shell.execute_reply": "2024-04-21T15:27:24.162696Z",
     "shell.execute_reply.started": "2024-04-21T15:27:24.151058Z"
    },
    "papermill": {
     "duration": 0.02798,
     "end_time": "2023-06-28T07:18:50.511175",
     "exception": false,
     "start_time": "2023-06-28T07:18:50.483195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validating(valid_dataloader, model):  # 検証を行う関数を定義します。\n",
    "    \n",
    "    model.eval()  # モデルを評価モードに設定します。\n",
    "    allpreds = []  # すべての予測を格納するリスト\n",
    "    alltargets = []  # すべてのターゲットを格納するリスト\n",
    "\n",
    "    for a in valid_dataloader:  # 検証データローダーからデータを取得します。\n",
    "        losses = []  # 各バッチの損失を格納するリスト\n",
    "        with torch.no_grad():  # 勾配計算を行わないようにします。\n",
    "\n",
    "            ids = a[\"ids\"].to(device)  # バッチ内の入力IDをデバイスに移動させます。\n",
    "            mask = a[\"mask\"].to(device)  # バッチ内の注意マスクをデバイスに移動させます。\n",
    "\n",
    "            output = model(ids, mask)  # モデルにIDとマスクを入力し、出力を取得します。\n",
    "            output = output[\"logits\"].squeeze(-1)  # 出力からlogitsを抽出し、次元を1つ削減します。\n",
    "            target = a[\"targets\"].to(device)  # バッチ内のターゲットをデバイスに移動させます。\n",
    "            loss = loss_fn(output, target)  # 出力とターゲットを用いて損失を計算します。\n",
    "            losses.append(loss.item())  # 損失を記録します。\n",
    "            allpreds.append(output.detach().cpu().numpy())  # 予測をCPUに移動させるとともにリストに追加します。\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())  # ターゲットをCPUに移動させ、リストに追加します。\n",
    "            \n",
    "            del loss  # 使用した損失のメモリを解放します。\n",
    "\n",
    "    allpreds = np.concatenate(allpreds)  # すべての予測を結合します。\n",
    "    alltargets = np.concatenate(alltargets)  # すべてのターゲットを結合します。\n",
    "    losses = np.mean(losses)  # すべての損失の平均を計算します。\n",
    "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets, allpreds))  # RMSEを計算します。\n",
    "\n",
    "    return allpreds, losses, valid_rme_loss  # 予測、損失、RMSEを返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e103c6b1",
   "metadata": {},
   "source": [
    "    if debug2 == False:  # debug2がFalseの場合の処理\n",
    "        for a in range(epochs):  # エポック数分のループを開始します。\n",
    "            for b in train_dataloader:  # 訓練データローダーからデータを取得します。\n",
    "                break  # 一度のループで処理を止めます。 (デバッグ目的についての一時停止)\n",
    "\n",
    "        losses, train_rme_loss = training(train_dataloader, model, optimizer, scheduler)  # 訓練を行い、損失とRMSEを取得します。\n",
    "\n",
    "        for a in valid_dataloader:  # 検証データローダーからデータを取得します。\n",
    "            break  # 一度のループで処理を止めます。 (デバッグ目的についての一時停止)\n",
    "\n",
    "# 訓練と検証を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:27:29.174135Z",
     "iopub.status.busy": "2024-04-21T15:27:29.173749Z",
     "iopub.status.idle": "2024-04-21T15:28:03.846473Z",
     "shell.execute_reply": "2024-04-21T15:28:03.845402Z",
     "shell.execute_reply.started": "2024-04-21T15:27:29.174095Z"
    },
    "papermill": {
     "duration": 237.459602,
     "end_time": "2023-06-28T07:24:40.146621",
     "exception": false,
     "start_time": "2023-06-28T07:20:42.687019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainlosses = []  # 訓練時の損失を格納するリスト\n",
    "vallosses = []  # 検証時の損失を格納するリスト\n",
    "bestscore = None  # 最良スコアを初期化します。\n",
    "trainscores = []  # 訓練スコアを格納するリスト\n",
    "validscores = []  # 検証スコアを格納するリスト\n",
    "\n",
    "for epoch in tqdm(range(epochs)):  # エポック数分のループを進行状況とともに実行します。\n",
    "    \n",
    "    print(\"---------------\" + str(epoch) + \" start -------------\")  # 現在のエポックを表示します。\n",
    "    \n",
    "    trainloss, trainscore = training(train_dataloader, model, optimizer, scheduler)  # 訓練を行い、損失とスコアを取得します。\n",
    "    trainlosses.append(trainloss)  # 訓練損失をリストに追加します。\n",
    "    trainscores.append(trainscore)  # 訓練スコアをリストに追加します。\n",
    "    \n",
    "    print(\"trainscore is \" + str(trainscore))  # 訓練スコアを表示します。\n",
    "    \n",
    "    preds, validloss, valscore = validating(valid_dataloader, model)  # 検証を行い、予測、損失とスコアを取得します。\n",
    "    vallosses.append(validloss)  # 検証損失をリストに追加します。\n",
    "    validscores.append(valscore)  # 検証スコアをリストに追加します。\n",
    "    \n",
    "    print(\"valscore is \" + str(valscore))  # 検証スコアを表示します。\n",
    "    \n",
    "    if bestscore is None:  # 最良スコアが未設定の場合\n",
    "        bestscore = valscore  # 最良スコアを更新します。\n",
    "        \n",
    "        print(\"Save first model\")  # 最初のモデルを保存します。\n",
    "        \n",
    "        state = {  # モデルの状態を辞書に格納します。\n",
    "                        'state_dict': model.state_dict(),  # モデルの状態辞書\n",
    "                        'optimizer_dict': optimizer.state_dict(),  # オプティマイザの状態辞書\n",
    "                        \"bestscore\": bestscore  # 最良スコア\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")  # モデルをファイルに保存します。\n",
    "        \n",
    "    elif bestscore > valscore:  # 新しいスコアが最良スコアよりも良い場合\n",
    "        bestscore = valscore  # 最良スコアを更新します。        \n",
    "        print(\"found better point\")  # より良いポイントが見つかったことを表示します。        \n",
    "        state = {  # モデルの状態を辞書に格納します。\n",
    "                        'state_dict': model.state_dict(),  # モデルの状態辞書\n",
    "                        'optimizer_dict': optimizer.state_dict(),  # オプティマイザの状態辞書\n",
    "                        \"bestscore\": bestscore  # 最良スコア\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")  # モデルをファイルに保存します。\n",
    "        \n",
    "    else:  # それ以外の場合\n",
    "        pass  # 何もしません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:28:03.848381Z",
     "iopub.status.busy": "2024-04-21T15:28:03.847986Z",
     "iopub.status.idle": "2024-04-21T15:28:04.73517Z",
     "shell.execute_reply": "2024-04-21T15:28:04.734256Z",
     "shell.execute_reply.started": "2024-04-21T15:28:03.848349Z"
    },
    "papermill": {
     "duration": 0.775119,
     "end_time": "2023-06-28T07:24:40.942226",
     "exception": false,
     "start_time": "2023-06-28T07:24:40.167107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.scatter(p_valid['label'], preds, alpha=0.2)  # 検証データの実際のラベルと予測値を散布図で表示します。\n",
    "plt.title('Validation Prediction Result')  # グラフのタイトルを設定します。\n",
    "plt.xlabel('Actual')  # x軸のラベルを設定します。\n",
    "plt.ylabel('Prediction')  # y軸のラベルを設定します。\n",
    "plt.show()  # グラフを表示します。\n",
    "\n",
    "x = np.arange(epochs)  # エポック数の範囲を生成します。\n",
    "plt.title('Validation Losses')  # グラフのタイトルを設定します。\n",
    "plt.xlabel('Epoch')  # x軸のラベルを設定します。\n",
    "plt.ylabel('Loss')  # y軸のラベルを設定します。\n",
    "plt.plot(x, trainlosses)  # 訓練損失をプロットします。\n",
    "plt.plot(x, vallosses)  # 検証損失をプロットします。\n",
    "plt.show()  # グラフを表示します。\n",
    "\n",
    "x = np.arange(epochs)  # エポック数の範囲を生成します。\n",
    "plt.title('Validation Scores')  # グラフのタイトルを設定します。\n",
    "plt.xlabel('Epoch')  # x軸のラベルを設定します。\n",
    "plt.ylabel('Score')  # y軸のラベルを設定します。\n",
    "plt.plot(x, trainscores)  # 訓練スコアをプロットします。\n",
    "plt.plot(x, validscores)  # 検証スコアをプロットします。\n",
    "plt.show()  # グラフを表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27837509",
   "metadata": {},
   "source": [
    "# モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-04-21T15:28:04.737019Z",
     "iopub.status.busy": "2024-04-21T15:28:04.736646Z",
     "iopub.status.idle": "2024-04-21T15:29:18.000052Z",
     "shell.execute_reply": "2024-04-21T15:29:17.998771Z",
     "shell.execute_reply.started": "2024-04-21T15:28:04.736983Z"
    },
    "papermill": {
     "duration": 969.305172,
     "end_time": "2023-06-28T07:40:50.393338",
     "exception": false,
     "start_time": "2023-06-28T07:24:41.088166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestscores = []  # 最良スコアを格納するリストを初期化します。\n",
    "bestscores.append(bestscore)  # 最初の最良スコアをリストに追加します。\n",
    "\n",
    "for fold in range(1, 5):  # 1から4までのフォールドについてループします。\n",
    "    \n",
    "    # データを初期化します。\n",
    "    p_train = train[train[\"kfold\"] != fold].reset_index(drop=True)  # 現在のフォールド以外のデータを訓練データに設定します。\n",
    "    p_valid = train[train[\"kfold\"] == fold].reset_index(drop=True)  # 現在のフォールドのデータを検証データに設定します。\n",
    "\n",
    "    train_dataset = BERTDataSet(p_train[\"text\"], p_train[\"label\"])  # 訓練データセットの作成。\n",
    "    valid_dataset = BERTDataSet(p_valid[\"text\"], p_valid[\"label\"])  # 検証データセットの作成。\n",
    "    \n",
    "    model = transformers.AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)  # RoBERTaの事前学習済みモデルを読み込みます。\n",
    "    \n",
    "    model.to(device)  # モデルを指定したデバイスに移動させます。\n",
    "    LR = 2e-5  # 学習率を設定します。\n",
    "    optimizer = AdamW(model.parameters(), LR, betas=(0.9, 0.999), weight_decay=1e-2)  # AdamWオプティマイザを初期化します。\n",
    "    train_steps = int(len(p_train) / train_batch * epochs)  # 訓練ステップ数を計算します。\n",
    "    num_steps = int(train_steps * 0.1)  # ウォームアップ期間中のステップ数を全体の10%として計算します。\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)  # スケジューラを初期化します。\n",
    "\n",
    "    trainlosses = []  # 訓練損失を格納するリスト\n",
    "    vallosses = []  # 検証損失を格納するリスト\n",
    "    bestscore = None  # 最良スコアを初期化します。\n",
    "    trainscores = []  # 訓練スコアを格納するリスト\n",
    "    validscores = []  # 検証スコアを格納するリスト\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):  # エポック数分のループを進行状況とともに実行します。\n",
    "\n",
    "        print(\"---------------\" + str(epoch) + \" start -------------\")  # 現在のエポックを表示します。\n",
    "\n",
    "        trainloss, trainscore = training(train_dataloader, model, optimizer, scheduler)  # 訓練を行い、損失とスコアを取得します。\n",
    "        trainlosses.append(trainloss)  # 訓練損失をリストに追加します。\n",
    "        trainscores.append(trainscore)  # 訓練スコアをリストに追加します。\n",
    "\n",
    "        print(\"trainscore is \" + str(trainscore))  # 訓練スコアを表示します。\n",
    "\n",
    "        preds, validloss, valscore = validating(valid_dataloader, model)  # 検証を行い、予測、損失とスコアを取得します。\n",
    "        vallosses.append(validloss)  # 検証損失をリストに追加します。\n",
    "        validscores.append(valscore)  # 検証スコアをリストに追加します。\n",
    "\n",
    "        print(\"valscore is \" + str(valscore))  # 検証スコアを表示します。\n",
    "\n",
    "        if bestscore is None:  # 最良スコアが未設定の場合\n",
    "            bestscore = valscore  # 最良スコアを更新します。\n",
    "\n",
    "            print(\"Save first model\")  # 最初のモデルを保存します。\n",
    "\n",
    "            state = {  # モデルの状態を辞書に格納します。\n",
    "                            'state_dict': model.state_dict(),  # モデルの状態辞書\n",
    "                            'optimizer_dict': optimizer.state_dict(),  # オプティマイザの状態辞書\n",
    "                            \"bestscore\": bestscore  # 最良スコア\n",
    "                        }\n",
    "\n",
    "            torch.save(state, \"model\" + str(fold) + \".pth\")  # モデルをファイルに保存します。 \n",
    "\n",
    "        elif bestscore > valscore:  # 新しいスコアが最良スコアよりも良い場合\n",
    "            bestscore = valscore  # 最良スコアを更新します。\n",
    "            print(\"found better point\")  # より良いポイントが見つかったことを表示します。\n",
    "\n",
    "            state = {  # モデルの状態を辞書に格納します。\n",
    "                            'state_dict': model.state_dict(),  # モデルの状態辞書\n",
    "                            'optimizer_dict': optimizer.state_dict(),  # オプティマイザの状態辞書\n",
    "                            \"bestscore\": bestscore  # 最良スコア\n",
    "                        }\n",
    "            torch.save(state, \"model\" + str(fold) + \".pth\")  # モデルをファイルに保存します。\n",
    "\n",
    "        else:  # それ以外の場合\n",
    "            pass  # 何もしません。\n",
    "\n",
    "    bestscores.append(bestscore)  # 最良スコアをリストに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:18.002462Z",
     "iopub.status.busy": "2024-04-21T15:29:18.002063Z",
     "iopub.status.idle": "2024-04-21T15:29:18.010475Z",
     "shell.execute_reply": "2024-04-21T15:29:18.009599Z",
     "shell.execute_reply.started": "2024-04-21T15:29:18.002418Z"
    },
    "papermill": {
     "duration": 0.04631,
     "end_time": "2023-06-28T07:40:50.474497",
     "exception": false,
     "start_time": "2023-06-28T07:40:50.428187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestscores  # 各フォールドの最良スコアを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:18.01202Z",
     "iopub.status.busy": "2024-04-21T15:29:18.011748Z",
     "iopub.status.idle": "2024-04-21T15:29:20.822635Z",
     "shell.execute_reply": "2024-04-21T15:29:20.821515Z",
     "shell.execute_reply.started": "2024-04-21T15:29:18.011997Z"
    },
    "papermill": {
     "duration": 0.043282,
     "end_time": "2023-06-28T07:40:50.552707",
     "exception": false,
     "start_time": "2023-06-28T07:40:50.509425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.mean(bestscores)  # 各フォールドの最良スコアの平均を計算します。\n",
    "print(\"My CV is \" + str(np.mean(bestscores)) + \".\")  # クロスバリデーションの結果を表示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3cdb4",
   "metadata": {},
   "source": [
    "# 予測関数の定義\n",
    "保存されたモデルは使用しません。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:20.824508Z",
     "iopub.status.busy": "2024-04-21T15:29:20.824121Z",
     "iopub.status.idle": "2024-04-21T15:29:20.833769Z",
     "shell.execute_reply": "2024-04-21T15:29:20.832868Z",
     "shell.execute_reply.started": "2024-04-21T15:29:20.824463Z"
    },
    "papermill": {
     "duration": 0.043725,
     "end_time": "2023-06-28T07:40:50.691507",
     "exception": false,
     "start_time": "2023-06-28T07:40:50.647782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicting(test_dataloader, model):  # 予測を行う関数を定義します。\n",
    "    \n",
    "    model.to(device)  # モデルを指定したデバイスに移動させます。\n",
    "    model.eval()  # モデルを評価モードに設定します。   \n",
    "    allpreds = []  # すべての予測を格納するリスト\n",
    "    preds = []  # 個々の予測を格納するリスト\n",
    "    allvalloss = 0  # 検証損失の合計を初期化します。\n",
    "\n",
    "    with torch.no_grad():  # 勾配計算を行わないようにします。\n",
    "        for a in test_dataloader:  # テストデータローダーからデータを取得します。\n",
    "\n",
    "            ids = a[\"ids\"].to(device)  # バッチ内の入力IDをデバイスに移動させます。\n",
    "            mask = a[\"mask\"].to(device)  # バッチ内の注意マスクをデバイスに移動させます。\n",
    "\n",
    "            output = model(ids, mask)  # モデルにIDとマスクを入力し、出力を取得します。\n",
    "            output = output[\"logits\"].squeeze(-1)  # 出力からlogitsを抽出し、次元を1つ削減します。\n",
    "            preds.append(output.cpu().numpy())  # 予測をCPUに移動させ、リストに追加します。\n",
    "\n",
    "        preds = np.concatenate(preds)  # すべての予測を結合します。\n",
    "        allpreds.append(preds)  # 予測を全体のリストに追加します。\n",
    "\n",
    "    return allpreds  # すべての予測を返します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d106552f",
   "metadata": {},
   "source": [
    "# 予測を行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:22.260435Z",
     "iopub.status.busy": "2024-04-21T15:29:22.260177Z",
     "iopub.status.idle": "2024-04-21T15:29:30.45845Z",
     "shell.execute_reply": "2024-04-21T15:29:30.457356Z",
     "shell.execute_reply.started": "2024-04-21T15:29:22.260412Z"
    },
    "papermill": {
     "duration": 71.891932,
     "end_time": "2023-06-28T07:42:05.088325",
     "exception": false,
     "start_time": "2023-06-28T07:40:53.196393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tpreds = predicting(test_dataloader, model)  # テストデータローダーを使用して予測を実行し、結果をtpredsに格納します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f59d4",
   "metadata": {},
   "source": [
    "# 予測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:30.460891Z",
     "iopub.status.busy": "2024-04-21T15:29:30.46046Z",
     "iopub.status.idle": "2024-04-21T15:29:30.465747Z",
     "shell.execute_reply": "2024-04-21T15:29:30.4647Z",
     "shell.execute_reply.started": "2024-04-21T15:29:30.460858Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pred = []  # 予測結果を格納するリストを初期化します。\n",
    "for p in tpreds[0]:  # tpredsの最初の要素（予測結果）をループします。\n",
    "    test_pred += [p]  # 各予測値をリストに追加します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-21T15:29:30.467268Z",
     "iopub.status.busy": "2024-04-21T15:29:30.46695Z",
     "iopub.status.idle": "2024-04-21T15:29:30.733329Z",
     "shell.execute_reply": "2024-04-21T15:29:30.732391Z",
     "shell.execute_reply.started": "2024-04-21T15:29:30.467237Z"
    }
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # 提出用のサンプルCSVファイルを読み込みます。\n",
    "pa = test_pred[0:len(test0)]  # 予測結果の最初の部分をモデルAの結果として設定します。\n",
    "pb = test_pred[len(test0):]  # 予測結果の残りの部分をモデルBの結果として設定します。\n",
    "pc = []  # モデルの引き分け結果を格納するリストを初期化します。\n",
    "for i in range(len(test0)):  # テストデータの長さ分ループします。\n",
    "    pc += [np.clip(1 - (pa[i] + pb[i]), 0, 1)]  # モデルAとモデルBの結果から引き分けのスコアを計算し、0〜1の範囲にクリップします。\n",
    "submit['winner_model_a'] = pa  # 提出データフレームにモデルAの結果を追加します。\n",
    "submit['winner_model_b'] = pb  # 提出データフレームにモデルBの結果を追加します。\n",
    "submit['winner_tie'] = pc  # 提出データフレームに引き分けの結果を追加します。\n",
    "display(submit)  # 提出データフレームを表示します。\n",
    "submit.to_csv('submission.csv', index=False)  # 提出データフレームをCSVファイルとして保存します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b6660",
   "metadata": {},
   "source": [
    "[Caution] 'submission.csv'は提出用ではありません。このノートブックはインターネット接続の条件で実行されているためです。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "sourceId": 190123501,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
