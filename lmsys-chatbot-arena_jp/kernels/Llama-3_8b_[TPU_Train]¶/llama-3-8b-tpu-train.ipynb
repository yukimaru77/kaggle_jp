{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc2b6ee2",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、「Llama-3 8b」を使用してTPU上で大規模言語モデル（LLM）のトレーニングを実行することを目的としています。コンペティションの文脈では、異なるLLMの応答の好みを予測するために必要なデータ処理やモデルのトレーニング手法に焦点を当てています。\n",
    "\n",
    "### 主な内容と手法:\n",
    "1. **ライブラリのインポート**: \n",
    "   - トレーニングには、`transformers`, `torch`, `peft`, `torch_xla`などのライブラリが使用されます。これらは、MLモデルの構築、データ処理、およびTPUでの効率的なトレーニングに役立ちます。\n",
    "  \n",
    "2. **TPU環境の設定**:\n",
    "   - TPU上での作業を行うため、TPU関連のモジュールがインポートされ、デバイスを初期化しています。\n",
    "\n",
    "3. **データの前処理**:\n",
    "   - KaggleのデータセットをCSVから読み込み、プロンプトと応答を整形します。無効なデータ（両方の応答が`null`の場合）は削除され、トークン長が計算されてデータフレームに追加されます。\n",
    "\n",
    "4. **トークナイゼーション**:\n",
    "   - トークン化に`AutoTokenizer`を利用し、テキストの長さを設定、パディングを施し、ラベルを取得します。\n",
    "\n",
    "5. **モデルの構築**:\n",
    "   - `LlamaForSequenceClassification`を使用して、3つのターゲットラベルに基づく分類モデルを構築します。また、LoRA（Low-Rank Adaptation）の手法を用いてモデルのパラメータ最適化を図ります。\n",
    "\n",
    "6. **トレーニング実行**:\n",
    "   - モデルを指定されたエポックでトレーニングし、損失関数として交差エントロピーを使用。学習率の調整やメトリクスの記録を行いながら、各エポックの進捗を追うことができます。\n",
    "\n",
    "7. **モデルの保存**:\n",
    "   - トレーニング後、モデルとオプティマイザの状態を保存し、後の利用や再トレーニングに備えます。\n",
    "\n",
    "8. **ビジュアライゼーション**:\n",
    "   - トレーニング過程での損失をプロットし、モデルの学習の進捗を評価する手段を提供しています。\n",
    "\n",
    "### 結論:\n",
    "このノートブックは、TPUを使用したLLMトレーニングに特化しており、効率的なデータ処理、モデル構築、トレーニング手法を整備しています。トレーニングのスピードや最適化の余地があることを指摘し、さらなる改善のための方向性を示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009f22b0",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関連する、機械学習・深層学習の初心者がつまずきそうな専門用語の解説を示します。\n",
    "\n",
    "1. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが開発した専用のハードウェアで、深層学習モデルのトレーニングを加速するために設計されています。GPUよりも高速で大規模なデータ処理に適しているため、大規模なモデルのトレーニングに広く使用されます。\n",
    "\n",
    "2. **LoRA (Low-Rank Adaptation)**:\n",
    "   - モデル微調整の手法で、特定のタスクにおいて大規模言語モデルの一部のパラメータを効率的に適応させるためのアプローチです。従来の微調整と比べてメモリ消費を抑え、より少ないデータで効果的に学習を行えます。\n",
    "\n",
    "3. **シャーディング (Sharding)**:\n",
    "   - データやモデルの大規模な分散処理の手法で、計算資源を効率的に使用するために、データを複数の部分に分けて同時に処理する方法です。TPU環境では、モデルやデータを複数のTPUデバイスに分散させることで、トレーニング速度を向上させます。\n",
    "\n",
    "4. **アテンションマスク (Attention Mask)**:\n",
    "   - モデルが入力を処理する際に、どの部分に注意を向けるべきかを示すための配列です。特に、パディングされた部分を無視するために使用され、計算の効率を高めます。\n",
    "\n",
    "5. **ウォームアップ (Warmup)**:\n",
    "   - 学習率スケジュールの一部で、トレーニングの初期段階で学習率を徐々に増加させる手法です。これにより、モデルが安定した状態で学習を開始でき、オーバーシュートを防ぐ効果があります。\n",
    "\n",
    "6. **ガーベジコレクション (Garbage Collection)**:\n",
    "   - プログラミングにおいて、自動でメモリを管理し、使用されていないメモリを解放するプロセスです。特に、大規模なデータを扱う機械学習において、メモリ使用量を適切に管理することは重要です。\n",
    "\n",
    "7. **ロジット (Logits)**:\n",
    "   - モデルの出力として得られる未正規化の値で、最終的なクラス予測を行う前に、Softmax関数を通じて確率に変換される値です。\n",
    "\n",
    "8. **SPMD (Single Program Multiple Data)**:\n",
    "   - 同じプログラムを複数のデータに対して同時に実行するパラダイムです。TPUやGPUでの並列アルゴリズムにおいて、効率的な計算を行うために重要です。\n",
    "\n",
    "9. **NumPyとPandas**:\n",
    "   - NumPyは数値計算用のライブラリで、行列演算に特化しており、Pandasはデータ操作のためのライブラリです。特にデータフレームを扱うことで、データの前処理や分析を効率的に行います。\n",
    "\n",
    "10. **スケジューラ (Scheduler)**:\n",
    "    - 学習率などのハイパーパラメータをトレーニングの進行に応じて調整するための仕組みです。これにより、トレーニングの各段階で最適な値を使用して、学習の効率を改善します。\n",
    "\n",
    "この用語集は、該当のノートブックの内容に特有の概念や技術に焦点を当てており、初心者が理解を深めることに役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485bbc2",
   "metadata": {},
   "source": [
    "# Llama-3 8b [TPUトレーニング]\n",
    "\n",
    "TPU上での大規模言語モデル（LLM）のトレーニングを学びます。これがあなたにも役に立つことを願っています！\n",
    "\n",
    "このノートブックは以下のリソースに触発されました：\n",
    "\n",
    "* [LLM detect AI competition Mistral-7B](https://www.kaggle.com/code/hotchpotch/train-llm-detect-ai-comp-mistral-7b/notebook)\n",
    "* [DAIGT Mistral-7B TPU BFloat16 [トレーニング]](https://www.kaggle.com/code/markwijkhuizen/daigt-mistral-7b-tpu-bfloat16-train)\n",
    "* [LLAMA 2 13B on TPU (トレーニング)](https://www.kaggle.com/code/defdet/llama-2-13b-on-tpu-training)\n",
    "\n",
    "前提条件：Llama-3を使用するためのアクセス\n",
    "\n",
    "注意：これはトレーニング用のノートブックであり、推論用のノートブックは[こちら](https://www.kaggle.com/code/kishanvavdara/inference-llama-3-8b)で見つけることができます。\n",
    "\n",
    "学びがあったり、役立つと感じた場合は、ぜひ投票してください！\n",
    "\n",
    "# ライブラリのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:36.902952Z",
     "iopub.status.busy": "2024-07-18T06:45:36.902248Z",
     "iopub.status.idle": "2024-07-18T06:45:58.797746Z",
     "shell.execute_reply": "2024-07-18T06:45:58.796513Z",
     "shell.execute_reply.started": "2024-07-18T06:45:36.902917Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインストール\n",
    "!pip install -qq peft==0.6.0  # peftライブラリのインストール\n",
    "!pip install -qq bitsandbytes==0.41.1  # bitsandbytesライブラリのインストール\n",
    "!pip install -qq accelerate==0.24.1  # accelerateライブラリのインストール\n",
    "!pip install -qq transformers==4.35.0  # transformersライブラリのインストール\n",
    "!pip install -qq torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q  # CPU版のPyTorchのインストール\n",
    "!pip install -qq torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q  # TPU用のtorch_xlaのインストール\n",
    "!pip uninstall -qq tensorflow -y  # TensorFlowがTPUを占有して権限エラーを引き起こすため、アンインストールします\n",
    "!cp /kaggle/input/utils-xla/spmd_util.py .  # このリポジトリからのファイルコピー：https://github.com/HeegyuKim/torch-xla-SPMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:06.395601Z",
     "iopub.status.busy": "2024-07-18T06:18:06.395209Z",
     "iopub.status.idle": "2024-07-18T06:18:06.563828Z",
     "shell.execute_reply": "2024-07-18T06:18:06.563166Z",
     "shell.execute_reply.started": "2024-07-18T06:18:06.395564Z"
    }
   },
   "outputs": [],
   "source": [
    "import os  # osモジュールのインポート\n",
    "import gc  # ガーベジコレクション用モジュールのインポート\n",
    "import re  # 正規表現操作用モジュールのインポート\n",
    "from time import time  # 時間関連の関数用にtimeをインポート\n",
    "import random  # 乱数生成用モジュールのインポート\n",
    "import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "import torch  # PyTorchのインポート\n",
    "import transformers  # transformersライブラリのインポート\n",
    "from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:39:35.941175Z",
     "iopub.status.busy": "2024-07-18T06:39:35.94052Z",
     "iopub.status.idle": "2024-07-18T06:39:35.957638Z",
     "shell.execute_reply": "2024-07-18T06:39:35.95664Z",
     "shell.execute_reply.started": "2024-07-18T06:39:35.941134Z"
    }
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "# import os  # osモジュールのインポート\n",
    "# import gc  # ガーベジコレクション用モジュールのインポート\n",
    "# import re  # 正規表現操作用モジュールのインポート\n",
    "# from time import time  # 時間関連の関数用にtimeをインポート\n",
    "# import random  # 乱数生成用モジュールのインポート\n",
    "# import warnings  # 警告メッセージの管理用モジュールのインポート\n",
    "# import numpy as np  # 数値計算用のライブラリNumPyのインポート\n",
    "# import pandas as pd  # データ操作用のライブラリPandasのインポート\n",
    "# import matplotlib.pyplot as plt  # グラフ描画用のmatplotlibのインポート\n",
    "# from tqdm.auto import tqdm  # プログレスバー表示用のtqdmをインポート\n",
    "\n",
    "# import torch  # PyTorchのインポート\n",
    "# import transformers  # transformersライブラリのインポート\n",
    "# from sklearn.metrics import accuracy_score  # 精度スコア評価のための関数インポート\n",
    "# from transformers import AutoTokenizer, LlamaModel, LlamaForSequenceClassification  # トークナイザーとモデルのインポート\n",
    "# from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType  # Peft関連のモジュールをインポート\n",
    "# import torch.nn.functional as F  # PyTorchの関数型APIをインポート\n",
    "\n",
    "# import torch_xla.debug.profiler as xp  # XLAのデバッグ用プロファイラーインポート\n",
    "# import torch_xla.core.xla_model as xm  # XLAモデル用モジュールをインポート\n",
    "# import torch_xla.experimental.xla_sharding as xs  # XLAシャーディング用モジュールのインポート\n",
    "# import torch_xla.runtime as xr  # XLA実行時間用モジュールのインポート\n",
    "\n",
    "# xr.use_spmd()  # SPMD（Single Program Multiple Data）を使用するように設定\n",
    "\n",
    "# from torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor  # XLAシャーディングされたテンソル用のインポート\n",
    "# from torch_xla.experimental.xla_sharding import Mesh  # XLAシャーディングのためのメッシュをインポート\n",
    "# from spmd_util import partition_module  # モジュールのパーティション分割用ユーティリティのインポート\n",
    "\n",
    "# tqdm.pandas()  # Pandas DataFrameとの互換性を持たせるための設定\n",
    "\n",
    "# print(f'Torch Version: {torch.__version__}')  # 現在のTorchのバージョンを表示します\n",
    "# /usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
    "#   warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
    "# /usr/local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
    "# Torch Version: 2.1.2+cpu\n",
    "\n",
    "# 設定\n",
    "# class CFG:\n",
    "#     NUM_EPOCHS = 1  # エポック数\n",
    "#     BATCH_SIZE = 1  # バッチサイズ（以前は16）\n",
    "#     DROPOUT = 0.05  # ドロップアウト率\n",
    "#     MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのパス\n",
    "#     SEED = 2024  # 乱数シード\n",
    "#     MAX_LENGTH = 1024  # 最大シーケンス長\n",
    "#     NUM_WARMUP_STEPS = 128  # ウォームアップステップ数\n",
    "#     LR_MAX = 5e-5  # 最大学習率\n",
    "#     NUM_LABELS = 3  # ラベル数\n",
    "#     LORA_RANK = 4  # LoRAのランク\n",
    "#     LORA_ALPHA = 8  # LoRAのアルファ値\n",
    "#     LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモジュール\n",
    "    \n",
    "# DEVICE = xm.xla_device()  # TPUデバイスの初期化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cca9c70",
   "metadata": {},
   "source": [
    "# 設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:29.087051Z",
     "iopub.status.busy": "2024-07-18T06:45:29.086452Z",
     "iopub.status.idle": "2024-07-18T06:45:29.133175Z",
     "shell.execute_reply": "2024-07-18T06:45:29.132226Z",
     "shell.execute_reply.started": "2024-07-18T06:45:29.087017Z"
    }
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    NUM_EPOCHS = 1  # エポック数\n",
    "    BATCH_SIZE = 1  # バッチサイズ（以前は16だった）\n",
    "    DROPOUT = 0.05  # ドロップアウト率\n",
    "    MODEL_NAME = '/kaggle/input/llama-3/transformers/8b-chat-hf/1'  # モデルのパス\n",
    "    SEED = 2024  # 乱数シード\n",
    "    MAX_LENGTH = 1024  # 最大シーケンス長\n",
    "    NUM_WARMUP_STEPS = 128  # ウォームアップステップ数\n",
    "    LR_MAX = 5e-5  # 最大学習率\n",
    "    NUM_LABELS = 3  # ラベルの数\n",
    "    LORA_RANK = 4  # LoRAのランク\n",
    "    LORA_ALPHA = 8  # LoRAのアルファ値\n",
    "    LORA_MODULES = ['o_proj', 'v_proj']  # LoRAを適用するモジュールのリスト\n",
    "    \n",
    "DEVICE = xm.xla_device()  # TPUデバイスの初期化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:24.361144Z",
     "iopub.status.busy": "2024-07-18T06:18:24.36047Z",
     "iopub.status.idle": "2024-07-18T06:18:24.36895Z",
     "shell.execute_reply": "2024-07-18T06:18:24.368251Z",
     "shell.execute_reply.started": "2024-07-18T06:18:24.361105Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    \"\"\"再現性のためのシードを設定します\"\"\"\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Pythonのハッシュシードを設定\n",
    "    random.seed(seed)  # randomモジュールのシードを設定\n",
    "    np.random.seed(seed)  # NumPyのシードを設定\n",
    "    torch.manual_seed(seed)  # PyTorchのシードを設定\n",
    "    if torch.cuda.is_available():  # GPUが利用可能な場合\n",
    "        torch.cuda.manual_seed(seed)  # CUDA用のシードを設定\n",
    "        torch.cuda.manual_seed_all(seed)  # 全てのCUDAデバイスにシードを設定\n",
    "        \n",
    "    # 全TPUコアのためにシードを設定\n",
    "    xm.set_rng_state(seed, device=xm.xla_device())  \n",
    "\n",
    "set_seeds(seed=CFG.SEED)  # 設定したシードを使ってシードを設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba86a36",
   "metadata": {},
   "source": [
    "# トークナイザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:27.768896Z",
     "iopub.status.busy": "2024-07-18T06:18:27.768498Z",
     "iopub.status.idle": "2024-07-18T06:18:28.392621Z",
     "shell.execute_reply": "2024-07-18T06:18:28.391957Z",
     "shell.execute_reply.started": "2024-07-18T06:18:27.76886Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(CFG.MODEL_NAME)  # 指定したモデル名からトークナイザーをロード\n",
    "tokenizer.pad_token = tokenizer.eos_token  # パディングトークンを終了トークンに設定\n",
    "tokenizer.padding_side = 'right'  # パディングを右側に設定\n",
    "tokenizer.add_eos_token = True  # 終了トークンを追加する設定\n",
    "\n",
    "# 推論時にオフラインでロードできるようにトークナイザーを保存\n",
    "tokenizer.save_pretrained('tokenizer')  # トークナイザーを指定したディレクトリに保存します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:32.691262Z",
     "iopub.status.busy": "2024-07-18T06:18:32.690884Z",
     "iopub.status.idle": "2024-07-18T06:18:32.696118Z",
     "shell.execute_reply": "2024-07-18T06:18:32.695375Z",
     "shell.execute_reply.started": "2024-07-18T06:18:32.69123Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン長を取得するユーティリティ関数\n",
    "def get_token_lengths(texts):\n",
    "    # テキストをトークナイズし、各テキストのinput_idsを取得\n",
    "    input_ids = tokenizer(texts.tolist(), return_tensors='np')['input_ids']\n",
    "    # 各テキストのinput_idsの長さを返す\n",
    "    return [len(t) for t in input_ids]  # 各トークンの長さをリストとして返します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15760842",
   "metadata": {},
   "source": [
    "# トレーニングデータの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:36.452066Z",
     "iopub.status.busy": "2024-07-18T06:18:36.451226Z",
     "iopub.status.idle": "2024-07-18T06:18:40.062409Z",
     "shell.execute_reply": "2024-07-18T06:18:40.061689Z",
     "shell.execute_reply.started": "2024-07-18T06:18:36.452026Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータのCSVファイルを読み込む\n",
    "def process(input_str):\n",
    "    stripped_str = input_str.strip('[]')  # 角括弧を取り除く\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文章を分割し、各文章の余分な引用符を取り除く\n",
    "    return ' '.join(sentences)  # 文章をスペースで結合して返す\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # プロンプト列を処理\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # 応答A列を処理\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # 応答B列を処理\n",
    "\n",
    "# トレーニングに向けて 'Null' を削除\n",
    "indexes = train[(train.response_a == 'null') & (train.response_b == 'null')].index  # 応答Aと応答Bが両方 'null' の行を見つける\n",
    "train.drop(indexes, inplace=True)  # 該当する行を削除\n",
    "train.reset_index(inplace=True, drop=True)  # インデックスをリセット\n",
    "\n",
    "print(f\"総計 {len(indexes)} 行のNull応答が削除されました\")\n",
    "print('トレーニングサンプルの合計: ', len(train))  # 残ったトレーニングサンプルの数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:40.06401Z",
     "iopub.status.busy": "2024-07-18T06:18:40.063715Z",
     "iopub.status.idle": "2024-07-18T06:18:40.079067Z",
     "shell.execute_reply": "2024-07-18T06:18:40.078222Z",
     "shell.execute_reply.started": "2024-07-18T06:18:40.06398Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(5)  # トレーニングデータの最初の5行を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:18:43.496382Z",
     "iopub.status.busy": "2024-07-18T06:18:43.496034Z",
     "iopub.status.idle": "2024-07-18T06:18:43.808097Z",
     "shell.execute_reply": "2024-07-18T06:18:43.807411Z",
     "shell.execute_reply.started": "2024-07-18T06:18:43.496349Z"
    }
   },
   "outputs": [],
   "source": [
    "train['text'] = 'User prompt: ' + train['prompt'] + '\\n\\nModel A:\\n' + train['response_a'] + '\\n\\n--------\\n\\nModel B:\\n' + train['response_b']  # 各行にユーザープロンプトとモデルの応答を結合\n",
    "print(train['text'][4])  # 4番目のテキストを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:20.62856Z",
     "iopub.status.busy": "2024-07-18T06:45:20.628221Z",
     "iopub.status.idle": "2024-07-18T06:45:20.650268Z",
     "shell.execute_reply": "2024-07-18T06:45:20.649282Z",
     "shell.execute_reply.started": "2024-07-18T06:45:20.62853Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータセットの50%のみを使用してトレーニング\n",
    "# train = train[:int(len(train) * 0.5)]  # 最初の50%を使用する場合（コメントアウト）\n",
    "train = train[int(len(train) * 0.5):]  # データセットの後半を使用\n",
    "\n",
    "# データを2つの半分に分割\n",
    "first_half = train[:int(len(train) * 0.5)]  # 最初の半分を取得\n",
    "\n",
    "first_half.loc[:, 'token_count'] = get_token_lengths(first_half['text'])  # 最初の半分のテキストのトークン数をカウント\n",
    "first_half.loc[:, 'label'] = np.argmax(first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "train.loc[:, 'token_count'] = get_token_lengths(train['text'])  # トレーニングデータ全体のトークン数をカウント\n",
    "\n",
    "# モデルのラベルを準備し、最大インデックスを取得\n",
    "train.loc[:, 'label'] = np.argmax(train[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # 勝者モデルのインデックスを取得\n",
    "\n",
    "# データを表示\n",
    "display(train.head())  # トレーニングデータの最初の数行を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:43.073681Z",
     "iopub.status.busy": "2024-07-18T06:19:43.073305Z",
     "iopub.status.idle": "2024-07-18T06:19:43.080943Z",
     "shell.execute_reply": "2024-07-18T06:19:43.080199Z",
     "shell.execute_reply.started": "2024-07-18T06:19:43.073646Z"
    }
   },
   "outputs": [],
   "source": [
    "train.label.value_counts()  # ラベルの値カウントを表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:43.919899Z",
     "iopub.status.busy": "2024-07-18T06:19:43.919256Z",
     "iopub.status.idle": "2024-07-18T06:19:43.930622Z",
     "shell.execute_reply": "2024-07-18T06:19:43.929879Z",
     "shell.execute_reply.started": "2024-07-18T06:19:43.919861Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークン数の統計を表示\n",
    "display(train['token_count'].describe().to_frame().astype(int))  # トークン数の統計情報を整数型のデータフレームとして表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:19:47.811834Z",
     "iopub.status.busy": "2024-07-18T06:19:47.811444Z",
     "iopub.status.idle": "2024-07-18T06:19:47.818289Z",
     "shell.execute_reply": "2024-07-18T06:19:47.817447Z",
     "shell.execute_reply.started": "2024-07-18T06:19:47.811798Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの90%をカバーするトークンの長さを取得しますが、1024の長さを維持します！\n",
    "np.percentile(train['token_count'], 90)  # トークン数の90パーセンタイルを取得します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abfe7f4",
   "metadata": {},
   "source": [
    "# トークナイズ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:53:02.164609Z",
     "iopub.status.busy": "2024-07-18T00:53:02.164336Z",
     "iopub.status.idle": "2024-07-18T00:53:18.442152Z",
     "shell.execute_reply": "2024-07-18T00:53:18.440966Z",
     "shell.execute_reply.started": "2024-07-18T00:53:02.164583Z"
    }
   },
   "outputs": [],
   "source": [
    "# データをトークナイズします\n",
    "tokens = tokenizer(\n",
    "    train['text'].tolist(),  # テキストをリストとしてトークナイズ\n",
    "    padding='max_length',  # 最大長でパディング\n",
    "    max_length=CFG.MAX_LENGTH,  # 最大長を設定\n",
    "    truncation=True,  # 長すぎるテキストは切り詰める\n",
    "    return_tensors='np')  # NumPyテンソルとして返す\n",
    "\n",
    "# 入力IDはトークンIDです\n",
    "INPUT_IDS = tokens['input_ids']  # トークンIDを取得\n",
    "# パディングトークンを無視するためのアテンションマスク\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得\n",
    "# テキストのラベル\n",
    "LABELS = train[['winner_model_a', 'winner_model_b', 'winner_tie']].values  # ラベルを取得\n",
    "\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:20:44.78341Z",
     "iopub.status.busy": "2024-07-18T06:20:44.782805Z",
     "iopub.status.idle": "2024-07-18T06:20:48.556603Z",
     "shell.execute_reply": "2024-07-18T06:20:48.555869Z",
     "shell.execute_reply.started": "2024-07-18T06:20:44.783355Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(\n",
    "    first_half['text'].tolist(),  # 最初の半分のテキストをリストとしてトークナイズ\n",
    "    padding='max_length',  # 最大長でパディングを行う\n",
    "    max_length=CFG.MAX_LENGTH,  # 最大長を設定\n",
    "    truncation=True,  # 長すぎるテキストは切り捨てる\n",
    "    return_tensors='np'  # NumPyテンソルとして返す\n",
    ")\n",
    "\n",
    "INPUT_IDS = tokens['input_ids']  # トークンIDを取得\n",
    "ATTENTION_MASKS = tokens['attention_mask']  # アテンションマスクを取得\n",
    "LABELS = first_half[['winner_model_a', 'winner_model_b', 'winner_tie']].values  # ラベルを取得\n",
    "print(f'INPUT_IDS shape: {INPUT_IDS.shape}, ATTENTION_MASKS shape: {ATTENTION_MASKS.shape}')  # 入力IDとアテンションマスクの形状を表示\n",
    "print(f'LABELS shape: {LABELS.shape}')  # ラベルの形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:13.638946Z",
     "iopub.status.busy": "2024-07-18T06:45:13.638158Z",
     "iopub.status.idle": "2024-07-18T06:45:13.662002Z",
     "shell.execute_reply": "2024-07-18T06:45:13.661088Z",
     "shell.execute_reply.started": "2024-07-18T06:45:13.638914Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_dataset(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        # インデックスをシャッフル\n",
    "        np.random.shuffle(IDXS)\n",
    "        # 全インデックスを一度だけイテレート\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る（マルチラベル出力）\n",
    "            \n",
    "            # TPUノードにシャーディングを行う（適用可能であれば、メッシュを適切に定義する必要があります）\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            \n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset(CFG.BATCH_SIZE)  # トレーニングデータセットを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:42:27.644213Z",
     "iopub.status.busy": "2024-07-18T06:42:27.643351Z",
     "iopub.status.idle": "2024-07-18T06:42:27.650446Z",
     "shell.execute_reply": "2024-07-18T06:42:27.649653Z",
     "shell.execute_reply.started": "2024-07-18T06:42:27.644165Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最初の半分のデータセット生成器を定義します\n",
    "def train_dataset_first_half(batch_size):\n",
    "    N_SAMPLES = LABELS.shape[0]  # サンプル数を取得\n",
    "    IDXS = np.arange(N_SAMPLES - (N_SAMPLES % batch_size))  # バッチサイズに基づいてインデックスを作成\n",
    "    while True:\n",
    "        np.random.shuffle(IDXS)  # インデックスをシャッフル\n",
    "        for idxs in IDXS.reshape(-1, batch_size):  # バッチサイズに分割\n",
    "            input_ids = torch.tensor(INPUT_IDS[idxs]).to(DEVICE)  # 入力IDをデバイスに送る\n",
    "            attention_mask = torch.tensor(ATTENTION_MASKS[idxs]).to(DEVICE)  # アテンションマスクをデバイスに送る\n",
    "            labels = torch.tensor(LABELS[idxs]).to(DEVICE)  # ラベルをデバイスに送る\n",
    "            xs.mark_sharding(input_ids, mesh, (0, 1))  # 入力IDのシャーディングマーク\n",
    "            xs.mark_sharding(attention_mask, mesh, (0, 1))  # アテンションマスクのシャーディングマーク\n",
    "            xs.mark_sharding(labels, mesh, (0, 1))  # ラベルのシャーディングマーク\n",
    "            yield input_ids, attention_mask, labels  # バッチを生成\n",
    "\n",
    "TRAIN_DATASET = train_dataset_first_half(CFG.BATCH_SIZE)  # 最初の半分のトレーニングデータセットを作成\n",
    "\n",
    "# 最初の半分のためのエポックごとのステップ数を計算\n",
    "STEPS_PER_EPOCH = len(first_half) // CFG.BATCH_SIZE  # エポックごとのステップ数を計算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae51fc",
   "metadata": {},
   "source": [
    "# モデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:07.266502Z",
     "iopub.status.busy": "2024-07-18T06:45:07.266175Z",
     "iopub.status.idle": "2024-07-18T06:45:07.284182Z",
     "shell.execute_reply": "2024-07-18T06:45:07.283207Z",
     "shell.execute_reply.started": "2024-07-18T06:45:07.266473Z"
    }
   },
   "outputs": [],
   "source": [
    "# 3つのターゲットラベルを用いた分類用のモデルを読み込みます\n",
    "base_model = LlamaForSequenceClassification.from_pretrained(\n",
    "    CFG.MODEL_NAME,  # 指定したモデル名から読み込む\n",
    "    num_labels=CFG.NUM_LABELS,  # ラベルの数を指定\n",
    "    torch_dtype=torch.bfloat16)  # PyTorchのデータ型を指定\n",
    "\n",
    "base_model.config.pretraining_tp = 1  # 事前トレーニングのTPを1に設定\n",
    "\n",
    "# パディングトークンを設定\n",
    "base_model.config.pad_token_id = tokenizer.pad_token_id  # パディングトークンIDを設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ebb861e",
   "metadata": {},
   "source": [
    "# ローレンジ適応（LORA）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:45:03.421955Z",
     "iopub.status.busy": "2024-07-18T06:45:03.421575Z",
     "iopub.status.idle": "2024-07-18T06:45:03.44123Z",
     "shell.execute_reply": "2024-07-18T06:45:03.440229Z",
     "shell.execute_reply.started": "2024-07-18T06:45:03.421921Z"
    }
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=CFG.LORA_RANK,  # ローランク行列の次元\n",
    "    lora_alpha=CFG.LORA_ALPHA,  # LoRAのアクティベーションと事前トレーニングされた重みアクティベーションのスケーリング係数\n",
    "    lora_dropout=CFG.DROPOUT,  # ドロップアウト率\n",
    "    bias='none',  # バイアスの設定\n",
    "    inference_mode=False,  # 推論モードの設定\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプをシーケンス分類に設定\n",
    "    target_modules=CFG.LORA_MODULES  # 出力と値のプロジェクションのみを使用\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:44:56.918569Z",
     "iopub.status.busy": "2024-07-18T06:44:56.91778Z",
     "iopub.status.idle": "2024-07-18T06:44:56.934615Z",
     "shell.execute_reply": "2024-07-18T06:44:56.93381Z",
     "shell.execute_reply.started": "2024-07-18T06:44:56.918535Z"
    }
   },
   "outputs": [],
   "source": [
    "# LoRAモデルを作成\n",
    "model = get_peft_model(base_model, lora_config)  # 基本モデルとLoRA設定からLoRAモデルを生成\n",
    "# 学習可能なパラメータを表示\n",
    "model.print_trainable_parameters()  # 学習可能なパラメータの情報を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPUノードの数を取得\n",
    "num_devices = xr.global_runtime_device_count()  # グローバルなランタイムデバイスの数を取得\n",
    "mesh_shape = (1, num_devices, 1)  # メッシュの形状を定義\n",
    "device_ids = np.array(range(num_devices))  # デバイスIDの配列を作成\n",
    "mesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))  # メッシュを作成\n",
    "\n",
    "# モデルを分割\n",
    "partition_module(model, mesh)  # モデルをメッシュに分配\n",
    "\n",
    "print(f'num_devices: {num_devices}')  # 使用するデバイスの数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T06:44:31.246215Z",
     "iopub.status.busy": "2024-07-18T06:44:31.2459Z",
     "iopub.status.idle": "2024-07-18T06:44:31.476841Z",
     "shell.execute_reply": "2024-07-18T06:44:31.476084Z",
     "shell.execute_reply.started": "2024-07-18T06:44:31.246187Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習可能な層を確認します\n",
    "MODEL_LAYERS_ROWS = []  # モデル層情報を格納するリスト\n",
    "TRAINABLE_PARAMS = []  # 学習可能なパラメータを格納するリスト\n",
    "N_TRAINABLE_PARAMS = 0  # 学習可能なパラメータの総数\n",
    "\n",
    "# モデルの各パラメータをループ\n",
    "for name, param in model.named_parameters():\n",
    "    # レイヤーのパラメータ数を計算\n",
    "    n_parameters = int(torch.prod(torch.tensor(param.shape)))\n",
    "    # 学習可能な層のみ\n",
    "    if param.requires_grad:\n",
    "        # 層の情報を追加\n",
    "        MODEL_LAYERS_ROWS.append({\n",
    "            'param': n_parameters,  # パラメータ数\n",
    "            'name': name,  # レイヤー名\n",
    "            'dtype': param.data.dtype,  # データ型\n",
    "        })\n",
    "        # 学習可能なパラメータを追加\n",
    "        TRAINABLE_PARAMS.append({'params': param})\n",
    "        # 学習可能なパラメータの数を加算\n",
    "        N_TRAINABLE_PARAMS += n_parameters\n",
    "        \n",
    "display(pd.DataFrame(MODEL_LAYERS_ROWS))  # モデル層情報のデータフレームを表示\n",
    "\n",
    "print(f\"\"\"\n",
    "===============================\n",
    "N_TRAINABLE_PARAMS: {N_TRAINABLE_PARAMS:,}  # 学習可能なパラメータの総数を表示\n",
    "N_TRAINABLE_LAYERS: {len(TRAINABLE_PARAMS)}  # 学習可能な層の数を表示\n",
    "===============================\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a088b",
   "metadata": {},
   "source": [
    "# トレーニング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:00:10.070423Z",
     "iopub.status.busy": "2024-07-18T01:00:10.070122Z",
     "iopub.status.idle": "2024-07-18T01:00:12.011654Z",
     "shell.execute_reply": "2024-07-18T01:00:12.010562Z",
     "shell.execute_reply.started": "2024-07-18T01:00:10.070395Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習率とオプティマイザーの設定\n",
    "N_SAMPLES = len(train)  # トレーニングサンプルの数を取得\n",
    "STEPS_PER_EPOCH = N_SAMPLES // CFG.BATCH_SIZE  # エポックごとのステップ数を計算\n",
    "\n",
    "OPTIMIZER = torch.optim.AdamW(model.parameters(), lr=CFG.LR_MAX)  # AdamWオプティマイザーを設定\n",
    "\n",
    "# ウォームアップ付きコサイン学習率スケジューラ\n",
    "lr_scheduler = transformers.get_cosine_schedule_with_warmup(\n",
    "    optimizer=OPTIMIZER,  # オプティマイザーを指定\n",
    "    num_warmup_steps=CFG.NUM_WARMUP_STEPS,  # ウォームアップステップ数を指定\n",
    "    num_training_steps=STEPS_PER_EPOCH * CFG.NUM_EPOCHS  # 総トレーニングステップ数を計算\n",
    ")\n",
    "\n",
    "print(f'BATCH_SIZE: {CFG.BATCH_SIZE}, N_SAMPLES: {N_SAMPLES}, STEPS_PER_EPOCH: {STEPS_PER_EPOCH}')  # バッチサイズ、サンプル数、エポックごとのステップ数を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T01:00:12.013144Z",
     "iopub.status.busy": "2024-07-18T01:00:12.012839Z",
     "iopub.status.idle": "2024-07-18T01:00:15.084005Z",
     "shell.execute_reply": "2024-07-18T01:00:15.082811Z",
     "shell.execute_reply.started": "2024-07-18T01:00:12.013118Z"
    }
   },
   "outputs": [],
   "source": [
    "# オプティマイザーの状態（例えば、モーメンタムバッファ）のデータ型を設定\n",
    "for state in OPTIMIZER.state.values():  # オプティマイザーの状態をループ\n",
    "    for k, v in state.items():  # 各状態のキーと値をループ\n",
    "        if isinstance(v, torch.Tensor) and state[k].dtype is not torch.float32:  # 値がテンソルで、データ型がfloat32でない場合\n",
    "            state[v] = v.to(dtype=torch.float32)  # データ型をfloat32に変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:36.095228Z",
     "iopub.status.busy": "2024-07-18T00:33:36.095004Z",
     "iopub.status.idle": "2024-07-18T00:33:36.108934Z",
     "shell.execute_reply": "2024-07-18T00:33:36.108232Z",
     "shell.execute_reply.started": "2024-07-18T00:33:36.095206Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids, attention_mask, labels = next(TRAIN_DATASET)  # トレーニングデータセットから次のバッチを取得\n",
    "\n",
    "print(f'input_ids shape: {input_ids.shape}, dtype: {input_ids.dtype}')  # 入力IDの形状とデータ型を表示\n",
    "print(f'attention_mask shape: {attention_mask.shape}, dtype: {attention_mask.dtype}')  # アテンションマスクの形状とデータ型を表示\n",
    "print(f'labels shape: {labels.shape}, dtype: {labels.dtype}')  # ラベルの形状とデータ型を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:36.110039Z",
     "iopub.status.busy": "2024-07-18T00:33:36.109801Z",
     "iopub.status.idle": "2024-07-18T00:33:58.48704Z",
     "shell.execute_reply": "2024-07-18T00:33:58.486299Z",
     "shell.execute_reply.started": "2024-07-18T00:33:36.110017Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# ダミー予測\n",
    "with torch.no_grad():  # 勾配計算を行わない設定\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)  # モデルに入力IDとアテンションマスクを与えて出力を取得\n",
    "    \n",
    "print(f'logits: {outputs.logits}, dtype: {outputs.logits.dtype}')  # ロジットとそのデータ型を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:58.489137Z",
     "iopub.status.busy": "2024-07-18T00:33:58.488884Z",
     "iopub.status.idle": "2024-07-18T00:33:58.496974Z",
     "shell.execute_reply": "2024-07-18T00:33:58.496317Z",
     "shell.execute_reply.started": "2024-07-18T00:33:58.489112Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルをトレーニングモードに設定\n",
    "model.train()\n",
    "\n",
    "# 損失関数、交差エントロピー\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss().to(dtype=torch.float32)  # 交差エントロピー損失関数をfloat32型に設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:33:58.4981Z",
     "iopub.status.busy": "2024-07-18T00:33:58.497867Z"
    }
   },
   "outputs": [],
   "source": [
    "st = time()  # 開始時間を記録\n",
    "warnings.filterwarnings(\"error\")  # 警告をエラーとして表示\n",
    "METRICS = {\n",
    "    'loss': [],  # 損失を格納するリスト\n",
    "    'accuracy': {'y_true': [], 'y_pred': []}  # 正解ラベルと予測ラベルを格納する辞書\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(CFG.NUM_EPOCHS)):  # エポックをループ\n",
    "    ste = time()  # 各エポックの開始時間を記録\n",
    "    for step in range(STEPS_PER_EPOCH):  # 各エポックのステップをループ\n",
    "        # 勾配をゼロに設定\n",
    "        OPTIMIZER.zero_grad()\n",
    "        \n",
    "        # バッチを取得\n",
    "        input_ids, attention_mask, labels = next(TRAIN_DATASET)\n",
    "        \n",
    "        # フォワードパス\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "       \n",
    "        # ロジットをfloat32に設定\n",
    "        logits = outputs.logits.to(dtype=torch.float32)\n",
    "        \n",
    "        # バックワードパス\n",
    "        loss = LOSS_FN(logits, labels.to(dtype=torch.float32))  # 損失を計算\n",
    "        loss.backward()  # 勾配を計算\n",
    "        \n",
    "        # オプティマイザステップ\n",
    "        OPTIMIZER.step()  # パラメータを更新\n",
    "        xm.mark_step()  # TPUステップをマーク\n",
    "        \n",
    "        # 学習率スケジューラを更新\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        # メトリクスとプログレスバーを更新\n",
    "        METRICS['loss'].append(float(loss))  # 損失を追加\n",
    "        METRICS['accuracy']['y_true'] += labels.squeeze().tolist()  # 正解ラベルを追加\n",
    "        METRICS['accuracy']['y_pred'] += torch.argmax(F.softmax(logits, dim=-1), dim=1).cpu().tolist()  # 予測ラベルを追加\n",
    "        \n",
    "        if (step + 1) % 200 == 0:  # 200ステップごとにメトリクスを表示\n",
    "            metrics = 'µ_loss: {:.3f}'.format(np.mean(METRICS['loss']))\n",
    "            metrics += ', step_loss: {:.3f}'.format(METRICS['loss'][-1])  # 最新の損失を追加\n",
    "            metrics += ', µ_auc: {:.3f}'.format(accuracy_score(torch.argmax(torch.tensor(METRICS['accuracy']['y_true']), axis=-1), \\\n",
    "                                                               METRICS['accuracy']['y_pred']))  # 精度を計算\n",
    "            lr = OPTIMIZER.param_groups[0]['lr']  # 学習率を取得\n",
    "            print(f'{epoch+1:02}/{CFG.NUM_EPOCHS:02} | {step+1:04}/{STEPS_PER_EPOCH} lr: {lr:.2E}, {metrics}', end='')\n",
    "            print(f'\\nSteps per epoch: {step+1} complete | Time elapsed: {time()- st}')  # 経過時間を表示\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1} Completed | Total time for epoch: {time() - ste} ' )  # エポックの完了時間を表示\n",
    "\n",
    "    # 停止した場合、TPUで将来的にトレーニングを続けるためにモデルとオプティマイザを保存\n",
    "    xm.save({k: v.cpu() for k, v in model.named_parameters() if v.requires_grad}, f'model_llama_3_cp_{epoch+1}_v1.pth')  # モデルを保存\n",
    "    xm.save(OPTIMIZER.state_dict(), f'optimizer_llama_3_cp_{epoch+1}_v1.pth')  # オプティマイザを保存\n",
    "    \n",
    "    print(f'Model saved at epoch {epoch+1}| Elapsed time: {time() - st} ')  # モデル保存のメッセージを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-18T00:39:32.034628Z",
     "iopub.status.busy": "2024-07-18T00:39:32.034322Z",
     "iopub.status.idle": "2024-07-18T00:39:32.2572Z",
     "shell.execute_reply": "2024-07-18T00:39:32.25633Z",
     "shell.execute_reply.started": "2024-07-18T00:39:32.034602Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))  # グラフのサイズを設定\n",
    "plt.plot(METRICS['loss'])  # 損失のプロット\n",
    "plt.xlabel('Step per epoch')  # x軸のラベル\n",
    "plt.ylabel('Loss')  # y軸のラベル\n",
    "plt.title('Loss Plot step per epoch')  # グラフのタイトル\n",
    "plt.show()  # グラフを表示"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f369c",
   "metadata": {},
   "source": [
    "# モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-14T14:52:40.497887Z",
     "iopub.status.busy": "2024-06-14T14:52:40.497608Z",
     "iopub.status.idle": "2024-06-14T14:54:33.373114Z",
     "shell.execute_reply": "2024-06-14T14:54:33.371833Z",
     "shell.execute_reply.started": "2024-06-14T14:52:40.49786Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.cpu()  # モデルをCPUに移動\n",
    "torch.save(dict([(k, v) for k, v in model.named_parameters() if v.requires_grad]), 'llama_3_finetuned_model.pth')  # 学習可能なパラメータを保存"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99e56c1",
   "metadata": {},
   "source": [
    "# 結論\n",
    "\n",
    "トレーニングの速度を上げて最適化する余地はまだたくさんあります！ より多くのデータや異なるバッチサイズ、学習率を試してみてください... すべての成功を祈ります！"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 3863727,
     "sourceId": 6703755,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30748,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
