{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61eb9d20",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleコンペティション「LMSYS - Chatbot Arena」において、大規模言語モデル（LLM）によって生成されたチャット応答の優劣を予測するための機械学習モデルを構築することを目的としています。具体的には、モデルが異なる応答の中でどちらがユーザーに好まれるかを予測し、データセットの特徴量作成やモデルのトレーニング・評価を行っています。\n",
    "\n",
    "### 問題の概要\n",
    "コンペティションでは、2つの異なるチャットボット（モデルAおよびモデルB）が生成した応答が与えられ、その中でどちらが好まれるかを予測することが求められています。データセットには、これらの応答や、それに対するユーザーの好み（勝者）が含まれています。\n",
    "\n",
    "### 使用される手法とライブラリ\n",
    "1. **データの読み込みと前処理**\n",
    "   - `pandas`を用いてデータセットを読み込み、基本的な情報を確認する。\n",
    "   - 各応答の特徴量を生成するために、句読点の数、言葉の多様性（ユニークな単語数）、ストップワードの比率、応答の長さ、先頭文字の大文字チェックなどの計算を行う。\n",
    "\n",
    "2. **特徴量エンコード**\n",
    "   - `OneHotEncoder`や`LabelEncoder`を使った勝者やモデル名のエンコード。\n",
    "   - 機械学習モデルに適した形にデータを加工。\n",
    "\n",
    "3. **機械学習モデルの構築**\n",
    "   - `train_test_split`でデータを訓練セットとテストセットに分割し、`StandardScaler`を使用してデータの標準化を行う。\n",
    "   - `RandomForestClassifier`を利用してモデルをトレーニングし、テストセットに対して予測を行い、混同行列や分類レポートで評価。\n",
    "\n",
    "4. **感情分析**\n",
    "   - `TextBlob`ライブラリを使用して、応答の感情分析を行い、感情スコアやエラーカウントを新しい特徴量として追加。\n",
    "\n",
    "5. **結果の保存**\n",
    "   - 最終的な応答や勝者モデルを含むデータをCSVファイルとしてエクスポートし、勝者モデルに基づく集計を行う。\n",
    "\n",
    "このNotebookでは、様々な特徴量エンジニアリングや機械学習手法をインタラクティブに駆使することで、モデルの性能を向上させ、チャットボットの応答に対するユーザーの好みを予測するタスクに取り組んでいます。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eabe831",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookで使用されている用語や手法の中から、初心者がつまずきそうな専門用語について簡単に解説します。一般的な知識はあると仮定していますが、具体的なドメイン知識や実務経験が少ない参加者向けの解説にしています。\n",
    "\n",
    "1. **TfidfVectorizer**:\n",
    "   - テキストデータの数値化手法の一つで、単語の出現頻度と逆文書頻度を組み合わせて特徴量を生成します。文書中での重要語の重み付けがなされるため、情報検索や文書分類において効果的です。\n",
    "\n",
    "2. **ColumnTransformer**:\n",
    "   - データ前処理のためのツールで、異なる種類の特徴量に対して異なる変換を適用することができます。例えば、数値データには標準化を行い、テキストデータにはそのまま通過させるといった処理が可能です。\n",
    "\n",
    "3. **Pipeline**:\n",
    "   - 機械学習フロー全体（データ前処理からモデルの訓練まで）を一つのオブジェクトにまとめる手法です。これにより、モデルの再利用が容易になり、コードがスッキリします。\n",
    "\n",
    "4. **StandardScaler**:\n",
    "   - 数値データの前処理に使われ、データの平均を0、標準偏差を1に変換します。この正規化により、異なるスケールの特徴量が同等に扱われるようになります。\n",
    "\n",
    "5. **混同行列 (Confusion Matrix)**:\n",
    "   - 分類モデルの予測結果を整理した表で、各クラスの予測と実際のラベルの対比を示します。モデルの性能評価に役立ち、正確さ、適合率、再現率などの指標を計算するための基礎となります。\n",
    "\n",
    "6. **LabelEncoder**:\n",
    "   - カテゴリカルデータを整数に変換する工具で、モデルが理解できるようにするために用いられます。ただし、順序情報を持たないカテゴリに同じスペースを与えてしまうため、注意が必要です。\n",
    "\n",
    "7. **OneHotEncoder**:\n",
    "   - カテゴリデータをバイナリ特徴量に変換する手法で、各カテゴリを独立したビットとして表現します。これにより、モデルは各カテゴリを同等に扱うことができます。\n",
    "\n",
    "8. **感情分析 (Sentiment Analysis)**:\n",
    "   - テキストデータの感情的なトーンを解析する手法で、ポジティブ、ネガティブ、ニュートラルなどの感情を特定します。特に顧客のフィードバックやレビュー分析に利用されます。\n",
    "\n",
    "9. **Polars**:\n",
    "   - 高速なデータフレームライブラリで、特に大規模データセットの処理に優れています。Pandasに似たAPIを持ちますが、処理速度が向上しているため、大規模なデータ分析に向いています。\n",
    "\n",
    "10. **訓練セット (Training Set) とテストセット (Test Set)**:\n",
    "    - 機械学習モデルの評価において、モデルの訓練に用いるデータセットを訓練セットと呼び、モデルの性能を評価するために使うデータセットをテストセットと呼びます。通常、全データセットは9:1や8:2の割合で分割されます。\n",
    "\n",
    "11. **応答の多様性 (Response Diversity)**:\n",
    "    - チャットボットの応答がどれだけ多様でユニークなものかを示す指標で、ユーザーの興味を引くためには高い多様性が求められます。\n",
    "\n",
    "12. **過度な冗長性 (Redundancy)**:\n",
    "    - モデルの応答が無駄に重複している状態を指し、ユーザーの関心を失わせる可能性があります。機械学習モデルにおいては、応答が単なる繰り返しにならないように努めることが重要です。\n",
    "\n",
    "これらの用語は、特定の技術や手法における理解を深め、実際のデータ処理やモデル訓練時に役立つ基礎的な概念を提供します。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T00:00:06.863637Z",
     "iopub.status.busy": "2024-07-10T00:00:06.863306Z",
     "iopub.status.idle": "2024-07-10T00:00:07.921585Z",
     "shell.execute_reply": "2024-07-10T00:00:07.920485Z",
     "shell.execute_reply.started": "2024-07-10T00:00:06.863608Z"
    }
   },
   "outputs": [],
   "source": [
    "# この Python 3 環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これは kaggle/python Docker イメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# たとえば、以下のいくつかの便利なパッケージをロードします\n",
    "\n",
    "import numpy as np # 線形代数\n",
    "import pandas as pd # データ処理、CSVファイルの入出力 (例: pd.read_csv)\n",
    "\n",
    "# 入力データファイルは読み取り専用の \"../input/\" ディレクトリにあります\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするか、Shift + Enterを押すことで）、入力ディレクトリ内のすべてのファイルがリストされます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 現在のディレクトリ (/kaggle/working/) に最大20GBのデータを書き込むことができ、\n",
    "# 「すべてを保存して実行」オプションでバージョンを作成すると、その結果が保存されます\n",
    "# 一時ファイルを /kaggle/temp/ に書き込むこともできますが、\n",
    "# 現在のセッション外では保存されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:06:52.937831Z",
     "iopub.status.busy": "2024-07-10T00:06:52.937119Z",
     "iopub.status.idle": "2024-07-10T00:06:54.84631Z",
     "shell.execute_reply": "2024-07-10T00:06:54.845253Z",
     "shell.execute_reply.started": "2024-07-10T00:06:52.937799Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# データセットを読み込む\n",
    "df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "\n",
    "# データセットの最初の数行を確認する\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:05:44.78886Z",
     "iopub.status.busy": "2024-07-10T00:05:44.788173Z",
     "iopub.status.idle": "2024-07-10T00:05:44.793382Z",
     "shell.execute_reply": "2024-07-10T00:05:44.79232Z",
     "shell.execute_reply.started": "2024-07-10T00:05:44.788826Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:23:09.357811Z",
     "iopub.status.busy": "2024-07-10T00:23:09.356985Z",
     "iopub.status.idle": "2024-07-10T00:23:36.393468Z",
     "shell.execute_reply": "2024-07-10T00:23:36.392433Z",
     "shell.execute_reply.started": "2024-07-10T00:23:09.35777Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# 各モデルの応答に含まれる句読点の数を特徴量として追加する\n",
    "df['response_a_punctuation_count'] = df['response_a'].apply(lambda x: sum([1 for char in x if char in string.punctuation]))\n",
    "df['response_b_punctuation_count'] = df['response_b'].apply(lambda x: sum([1 for char in x if char in string.punctuation]))\n",
    "\n",
    "# 言葉の多様性を示す特徴量を追加する\n",
    "df['response_a_unique_words'] = df['response_a'].apply(lambda x: len(set(x.split())))\n",
    "df['response_b_unique_words'] = df['response_b'].apply(lambda x: len(set(x.split())))\n",
    "\n",
    "# ストップワードの比率を示す特徴量を追加する（例としてストップワードリストを使用）\n",
    "stop_words = set(['the', 'and', 'is', 'in', 'at', 'of', 'it', 'to'])\n",
    "df['response_a_stop_words_ratio'] = df['response_a'].apply(lambda x: len([word for word in x.lower().split() if word in stop_words]) / len(x.split()))\n",
    "df['response_b_stop_words_ratio'] = df['response_b'].apply(lambda x: len([word for word in x.lower().split() if word in stop_words]) / len(x.split()))\n",
    "\n",
    "# 文の最初の文字が大文字であるかを示す特徴量を追加する\n",
    "df['response_a_startswith_upper'] = df['response_a'].apply(lambda x: 1 if x[0].isupper() else 0)\n",
    "df['response_b_startswith_upper'] = df['response_b'].apply(lambda x: 1 if x[0].isupper() else 0)\n",
    "\n",
    "# 応答の長さとその差を示す特徴量を追加する\n",
    "df['response_a_length'] = df['response_a'].apply(len)\n",
    "df['response_b_length'] = df['response_b'].apply(len)\n",
    "df['response_length_difference'] = df['response_a_length'] - df['response_b_length']\n",
    "\n",
    "# 勝者モデルの列を追加する\n",
    "df['winner'] = df.apply(lambda row: 'model_a' if row['winner_model_a'] == 1 else 'model_b' if row['winner_model_b'] == 1 else 'tie', axis=1)\n",
    "\n",
    "# モデル名の列を追加する\n",
    "df['model_name'] = df.apply(lambda row: row['model_a'] if row['winner'] == 'model_a' else row['model_b'] if row['winner'] == 'model_b' else '', axis=1)\n",
    "\n",
    "# One-hotエンコーディングを実施する\n",
    "encoder = OneHotEncoder()\n",
    "winner_encoded = encoder.fit_transform(df[['winner']])\n",
    "\n",
    "# エンコードされた列をデータフレームに追加する\n",
    "df_encoded = pd.concat([df, pd.DataFrame(winner_encoded.toarray(), columns=encoder.categories_[0])], axis=1)\n",
    "\n",
    "# 結果を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:31:21.247967Z",
     "iopub.status.busy": "2024-07-10T00:31:21.247555Z",
     "iopub.status.idle": "2024-07-10T00:31:28.451202Z",
     "shell.execute_reply": "2024-07-10T00:31:28.450323Z",
     "shell.execute_reply.started": "2024-07-10T00:31:21.247937Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# データセットを準備するための関数\n",
    "def prepare_data_for_ml(df):\n",
    "    # 句読点のカウントを行う関数\n",
    "    def count_punctuation(text):\n",
    "        return sum(1 for char in str(text) if char in '.,;:?')\n",
    "\n",
    "    # 新しい列を追加する\n",
    "    df['response_a_punctuation_count'] = df['response_a'].apply(count_punctuation)\n",
    "    df['response_b_punctuation_count'] = df['response_b'].apply(count_punctuation)\n",
    "    df['response_b_startswith_upper'] = df['response_b'].apply(lambda x: int(str(x)[0].isupper()))\n",
    "    df['response_a_length'] = df['response_a'].str.len() # 応答の長さを計算\n",
    "    df['response_b_length'] = df['response_b'].str.len() # 応答の長さを計算\n",
    "    df['response_length_difference'] = abs(df['response_a_length'] - df['response_b_length']) # 応答の長さの絶対差を計算\n",
    "\n",
    "    # 勝者のエンコードされた列を作成\n",
    "    le = LabelEncoder()\n",
    "    df['winner_encoded'] = le.fit_transform(df['winner']) # 勝者情報を数値でエンコードする\n",
    "\n",
    "    # モデル名の列を作成\n",
    "    df['model_name'] = np.where(df['winner_model_a'] == 1, df['model_a'], df['model_b']) # 勝ったモデルを表示\n",
    "\n",
    "    # カテゴリ変数をエンコードする\n",
    "    categorical_columns = ['model_a', 'model_b', 'model_name']\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[f'{col}_encoded'] = le.fit_transform(df[col]) # カテゴリ変数を数値にエンコードする\n",
    "\n",
    "    # ブール値を0と1に変換\n",
    "    df['model_a_win'] = df['winner'] == 'model_a'\n",
    "    df['model_b_win'] = df['winner'] == 'model_b'\n",
    "    df['winner_tie'] = df['winner'] == 'tie'\n",
    "    df['tie'] = df['winner'] == 'tie'\n",
    "\n",
    "    boolean_columns = ['response_b_startswith_upper', 'model_a_win', 'model_b_win', 'winner_tie', 'tie']\n",
    "    for col in boolean_columns:\n",
    "        df[col] = df[col].astype(int) # ブール値を整数に変換\n",
    "\n",
    "    return df\n",
    "\n",
    "# データセットを準備する\n",
    "prepared_df = prepare_data_for_ml(df)\n",
    "\n",
    "# 必要な列を選択し、欠損列を確認する\n",
    "columns_to_keep = [\n",
    "    'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b',\n",
    "    'winner', 'model_a_win', 'model_b_win', 'winner_tie',\n",
    "    'response_a_punctuation_count', 'response_b_punctuation_count',\n",
    "    'response_b_startswith_upper', 'response_a_length', 'response_b_length',\n",
    "    'response_length_difference', 'winner_encoded',\n",
    "    'model_name', 'tie', 'model_a_encoded', 'model_b_encoded', 'model_name_encoded'\n",
    "]\n",
    "\n",
    "prepared_df = prepared_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:29:15.031576Z",
     "iopub.status.busy": "2024-07-10T00:29:15.030931Z",
     "iopub.status.idle": "2024-07-10T00:29:15.056618Z",
     "shell.execute_reply": "2024-07-10T00:29:15.055546Z",
     "shell.execute_reply.started": "2024-07-10T00:29:15.031543Z"
    }
   },
   "outputs": [],
   "source": [
    "prepared_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:31:33.016684Z",
     "iopub.status.busy": "2024-07-10T00:31:33.016273Z",
     "iopub.status.idle": "2024-07-10T00:31:33.102926Z",
     "shell.execute_reply": "2024-07-10T00:31:33.101479Z",
     "shell.execute_reply.started": "2024-07-10T00:31:33.016652Z"
    }
   },
   "outputs": [],
   "source": [
    "# データを準備する\n",
    "X = prepared_df[['response_a_punctuation_count', 'response_b_punctuation_count',\n",
    "        'response_a_startswith_upper', 'response_b_startswith_upper',\n",
    "        'response_a_length', 'response_b_length', 'response_length_difference']]\n",
    "y = prepared_df['winner_encoded']  # LabelEncodedを使用してエンコードされたターゲット変数\n",
    "\n",
    "# データをトレーニングセットとテストセットに分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# データを標準化する\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # トレーニングデータを標準化\n",
    "X_test_scaled = scaler.transform(X_test) # テストデータを標準化\n",
    "\n",
    "# モデルをトレーニングする\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train) # モデルをトレーニングデータでフィット\n",
    "\n",
    "# モデルを使用して予測を行う\n",
    "y_pred = model.predict(X_test_scaled) # テストデータで予測を行う\n",
    "\n",
    "# 結果を評価する\n",
    "print(\"混同行列:\\n\", confusion_matrix(y_test, y_pred)) # 混合の行列を显示\n",
    "print(\"\\n分類レポート:\\n\", classification_report(y_test, y_pred, target_names=['model_a', 'model_b', 'tie'])) # 各モデルのパフォーマンスを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:32:10.5434Z",
     "iopub.status.busy": "2024-07-10T00:32:10.542465Z",
     "iopub.status.idle": "2024-07-10T00:32:26.843601Z",
     "shell.execute_reply": "2024-07-10T00:32:26.842673Z",
     "shell.execute_reply.started": "2024-07-10T00:32:10.543366Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# データセットを準備するための関数\n",
    "def prepare_data_for_ml(df):\n",
    "    # 句読点のカウントを行う関数\n",
    "    def count_punctuation(text):\n",
    "        return sum(1 for char in str(text) if char in '.,;!?') # 句読点の種類を数えます\n",
    "\n",
    "    # 新しい列を追加する\n",
    "    df['response_a_punctuation_count'] = df['response_a'].apply(count_punctuation) # モデルAの応答の句読点数\n",
    "    df['response_b_punctuation_count'] = df['response_b'].apply(count_punctuation) # モデルBの応答の句読点数\n",
    "    df['response_b_startswith_upper'] = df['response_b'].apply(lambda x: int(str(x)[0].isupper())) # モデルBの応答が大文字で始まるか\n",
    "    df['response_a_startswith_upper'] = df['response_a'].apply(lambda x: int(str(x)[0].isupper())) # モデルAの応答が大文字で始まるか\n",
    "    df['response_a_length'] = df['response_a'].str.len() # モデルAの応答の長さ\n",
    "    df['response_b_length'] = df['response_b'].str.len() # モデルBの応答の長さ\n",
    "    df['response_length_difference'] = abs(df['response_a_length'] - df['response_b_length']) # 長さの絶対値の差を計算\n",
    "\n",
    "    # 勝者のエンコードされた列を作成\n",
    "    le = LabelEncoder()\n",
    "    df['winner_encoded'] = le.fit_transform(df['winner']) # 勝者をエンコードする\n",
    "\n",
    "    # モデル名の列を作成\n",
    "    df['model_name'] = np.where(df['winner_model_a'] == 1, df['model_a'], df['model_b']) # 勝者モデルの名前をつける\n",
    "\n",
    "    # カテゴリ変数をエンコードする\n",
    "    categorical_columns = ['model_a', 'model_b', 'model_name']\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[f'{col}_encoded'] = le.fit_transform(df[col]) # カテゴリ変数を数値にエンコード\n",
    "\n",
    "    # ブール値を0と1に変換\n",
    "    df['model_a_win'] = df['winner'] == 'model_a' # モデルAが勝つ場合\n",
    "    df['model_b_win'] = df['winner'] == 'model_b' # モデルBが勝つ場合\n",
    "    df['winner_tie'] = df['winner'] == 'tie' # 引き分けかどうか\n",
    "    df['tie'] = df['winner'] == 'tie' # 引き分けかどうかを示す\n",
    "\n",
    "    boolean_columns = ['response_b_startswith_upper', 'response_a_startswith_upper', 'model_a_win', 'model_b_win', 'winner_tie', 'tie']\n",
    "    for col in boolean_columns:\n",
    "        df[col] = df[col].astype(int) # ブール値を整数型に変換\n",
    "\n",
    "    return df\n",
    "\n",
    "# データセットを準備する\n",
    "prepared_df = prepare_data_for_ml(df)\n",
    "\n",
    "# 必要な列を選択し、欠損列を確認する\n",
    "columns_to_keep = [\n",
    "    'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b',\n",
    "    'winner', 'model_a_win', 'model_b_win', 'winner_tie',\n",
    "    'response_a_punctuation_count', 'response_b_punctuation_count',\n",
    "    'response_b_startswith_upper', 'response_a_startswith_upper',  # response_a_startswith_upper を追加\n",
    "    'response_a_length', 'response_b_length',\n",
    "    'response_length_difference', 'winner_encoded',\n",
    "    'model_name', 'tie', 'model_a_encoded', 'model_b_encoded', 'model_name_encoded'\n",
    "]\n",
    "\n",
    "prepared_df = prepared_df[columns_to_keep]\n",
    "\n",
    "# データを準備する\n",
    "X = prepared_df[['response_a_punctuation_count', 'response_b_punctuation_count',\n",
    "        'response_a_startswith_upper', 'response_b_startswith_upper',\n",
    "        'response_a_length', 'response_b_length', 'response_length_difference']]\n",
    "y = prepared_df['winner_encoded']  # LabelEncodedを使用してエンコードされたターゲット変数\n",
    "\n",
    "# データをトレーニングセットとテストセットに分割する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# データを標準化する\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train) # トレーニングデータを標準化\n",
    "X_test_scaled = scaler.transform(X_test) # テストデータを標準化\n",
    "\n",
    "# モデルをトレーニングする\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_scaled, y_train) # モデルをトレーニングデータで適合\n",
    "\n",
    "# モデルを使用して予測を行う\n",
    "y_pred = model.predict(X_test_scaled) # テストデータで予測を行う\n",
    "\n",
    "# 結果を評価する\n",
    "print(\"混同行列:\\n\", confusion_matrix(y_test, y_pred)) # 混合行列を表示\n",
    "print(\"\\n分類レポート:\\n\", classification_report(y_test, y_pred, target_names=['model_a', 'model_b', 'tie'])) # モデルのパフォーマンスを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:20:07.180153Z",
     "iopub.status.busy": "2024-07-10T00:20:07.179807Z",
     "iopub.status.idle": "2024-07-10T00:20:07.188696Z",
     "shell.execute_reply": "2024-07-10T00:20:07.187436Z",
     "shell.execute_reply.started": "2024-07-10T00:20:07.180125Z"
    }
   },
   "outputs": [],
   "source": [
    "df['winner']  # 勝者の列を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:14:59.564948Z",
     "iopub.status.busy": "2024-07-10T00:14:59.564206Z",
     "iopub.status.idle": "2024-07-10T00:14:59.571034Z",
     "shell.execute_reply": "2024-07-10T00:14:59.569796Z",
     "shell.execute_reply.started": "2024-07-10T00:14:59.564919Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:14:34.575966Z",
     "iopub.status.busy": "2024-07-10T00:14:34.575552Z",
     "iopub.status.idle": "2024-07-10T00:14:35.259676Z",
     "shell.execute_reply": "2024-07-10T00:14:35.258058Z",
     "shell.execute_reply.started": "2024-07-10T00:14:34.575936Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者モデルをエンコードする\n",
    "label_encoder = LabelEncoder()\n",
    "df['winner_encoded'] = label_encoder.fit_transform(df['winner']) # 勝者のラベルを数値にエンコードする\n",
    "\n",
    "# 数値特徴量とテキスト特徴量の列を分ける\n",
    "numeric_features = [\n",
    "    'response_a_punctuation_count', 'response_b_punctuation_count',\n",
    "    'response_a_unique_words', 'response_b_unique_words',\n",
    "    'response_a_stop_words_ratio', 'response_b_stop_words_ratio',\n",
    "    'response_a_length', 'response_b_length', 'response_length_difference'\n",
    "]\n",
    "\n",
    "text_features = ['prompt', 'response_a', 'response_b']\n",
    "\n",
    "# ColumnTransformerを作成する\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features), # 数値特徴量を標準化する\n",
    "        ('text', 'passthrough', text_features)  # テキスト特徴量はそのまま通過させる\n",
    "    ])\n",
    "\n",
    "# データをX（特徴量）とy（ターゲット変数）に分ける\n",
    "X = df[numeric_features + text_features]\n",
    "y = df['winner_encoded']\n",
    "\n",
    "# トレーニングセットとテストセットを作成する\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# パイプラインを作成する\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42)) # ランダムフォレストモデルを使用する\n",
    "])\n",
    "\n",
    "# モデルを訓練する\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# テストセットでモデルを評価する\n",
    "accuracy = pipeline.score(X_test, y_test)\n",
    "print(f\"モデルの精度: {accuracy}\") # モデルの精度を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T00:00:07.924371Z",
     "iopub.status.busy": "2024-07-10T00:00:07.923837Z",
     "iopub.status.idle": "2024-07-10T00:00:11.7266Z",
     "shell.execute_reply": "2024-07-10T00:00:11.725421Z",
     "shell.execute_reply.started": "2024-07-10T00:00:07.924332Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSVファイルを読み込む\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# データを結合する\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# 結果を確認する\n",
    "df.head() # 結合したデータの最初の数行を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.547258Z",
     "iopub.status.busy": "2024-07-09T23:32:11.546942Z",
     "iopub.status.idle": "2024-07-09T23:32:11.553441Z",
     "shell.execute_reply": "2024-07-09T23:32:11.552405Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.547202Z"
    }
   },
   "outputs": [],
   "source": [
    "df.shape # データフレームの形状を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.555586Z",
     "iopub.status.busy": "2024-07-09T23:32:11.55469Z",
     "iopub.status.idle": "2024-07-09T23:32:11.563398Z",
     "shell.execute_reply": "2024-07-09T23:32:11.562392Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.555555Z"
    }
   },
   "outputs": [],
   "source": [
    "len(df.id) # データフレームのIDの数を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.565893Z",
     "iopub.status.busy": "2024-07-09T23:32:11.56559Z",
     "iopub.status.idle": "2024-07-09T23:32:11.608162Z",
     "shell.execute_reply": "2024-07-09T23:32:11.607378Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.565859Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info() # データフレームの情報を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.609338Z",
     "iopub.status.busy": "2024-07-09T23:32:11.60907Z",
     "iopub.status.idle": "2024-07-09T23:32:11.619521Z",
     "shell.execute_reply": "2024-07-09T23:32:11.618544Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.609315Z"
    }
   },
   "outputs": [],
   "source": [
    "winner_counts = {\n",
    "    'model_a': df['winner_model_a'].value_counts(), # model_aの勝者数をカウントする\n",
    "    'model_b': df['winner_model_b'].value_counts(), # model_bの勝者数をカウントする\n",
    "    'tie': df['winner_tie'].sum() # 引き分けの合計をカウントする\n",
    "}\n",
    "\n",
    "print(winner_counts) # 勝者のカウントを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.621194Z",
     "iopub.status.busy": "2024-07-09T23:32:11.620881Z",
     "iopub.status.idle": "2024-07-09T23:32:11.62802Z",
     "shell.execute_reply": "2024-07-09T23:32:11.627003Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.621163Z"
    }
   },
   "outputs": [],
   "source": [
    "# winner_model_aとwinner_model_bがともに0である行をフィルタリングする\n",
    "zero_winner_df = df[(df['winner_model_a'] == 1.0) & (df['winner_model_b'] == 1.0)].astype(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.62959Z",
     "iopub.status.busy": "2024-07-09T23:32:11.62928Z",
     "iopub.status.idle": "2024-07-09T23:32:11.653628Z",
     "shell.execute_reply": "2024-07-09T23:32:11.652722Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.629559Z"
    }
   },
   "outputs": [],
   "source": [
    "# winner_model_aが1である行をフィルタリングする\n",
    "model_a_winner_df = df[df['winner_model_a'] == 1.0]\n",
    "\n",
    "# winner_model_bが1である行をフィルタリングする\n",
    "model_b_winner_df = df[df['winner_model_b'] == 1.0]\n",
    "\n",
    "# 1である行におけるmodel_aとmodel_bの最も多く出現する値を取得する\n",
    "model_a_counts = model_a_winner_df['model_a'].value_counts() # model_aの出現回数をカウント\n",
    "model_b_counts = model_b_winner_df['model_b'].value_counts() # model_bの出現回数をカウント\n",
    "\n",
    "print(\"model_aの最も多く出現する値 (combined):\")\n",
    "print(model_a_counts.head()) # model_aで最も多く出現する値の上位を表示\n",
    "\n",
    "print(\"\\nmodel_bの最も多く出現する値 (combined):\")\n",
    "print(model_b_counts.head()) # model_bで最も多く出現する値の上位を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.654896Z",
     "iopub.status.busy": "2024-07-09T23:32:11.654639Z",
     "iopub.status.idle": "2024-07-09T23:32:11.683132Z",
     "shell.execute_reply": "2024-07-09T23:32:11.68247Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.654874Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_a列での最も多く出現する応答を取得する\n",
    "response_a_counts = model_a_winner_df['response_a'].value_counts() # model_aの応答の出現回数をカウント\n",
    "response_b_counts = model_b_winner_df['response_b'].value_counts() # model_bの応答の出現回数をカウント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.684437Z",
     "iopub.status.busy": "2024-07-09T23:32:11.684157Z",
     "iopub.status.idle": "2024-07-09T23:32:11.788274Z",
     "shell.execute_reply": "2024-07-09T23:32:11.787409Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.684415Z"
    }
   },
   "outputs": [],
   "source": [
    "# response_a列での最も多く出現する応答を取得し、勝者モデルに基づいてグループ分けする\n",
    "response_a_counts_df = model_a_winner_df.groupby(['model_a', 'prompt']).size().reset_index(name='count') # model_aの応答をグループ化\n",
    "# response_b列での最も多く出現する応答を取得し、勝者モデルに基づいてグループ分けする\n",
    "response_b_counts_df = model_b_winner_df.groupby(['model_b', 'prompt']).size().reset_index(name='count') # model_bの応答をグループ化\n",
    "\n",
    "print(\"response_aの最も多く出現する値 (combined):\")\n",
    "print(response_a_counts_df.head()) # model_aの最も多く出現する応答の上位を表示\n",
    "\n",
    "print(\"\\nresponse_bの最も多く出現する値 (combined):\")\n",
    "print(response_b_counts_df.head()) # model_bの最も多く出現する応答の上位を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.792514Z",
     "iopub.status.busy": "2024-07-09T23:32:11.792197Z",
     "iopub.status.idle": "2024-07-09T23:32:11.802455Z",
     "shell.execute_reply": "2024-07-09T23:32:11.801379Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.79249Z"
    }
   },
   "outputs": [],
   "source": [
    "response_a_counts_df # model_aの応答の出現回数データフレームを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.804291Z",
     "iopub.status.busy": "2024-07-09T23:32:11.803741Z",
     "iopub.status.idle": "2024-07-09T23:32:11.809703Z",
     "shell.execute_reply": "2024-07-09T23:32:11.808573Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.80426Z"
    }
   },
   "outputs": [],
   "source": [
    "top_models = ['gpt-4-1106-preview', 'gpt-4-0613', 'gpt-3.5-turbo-0613', 'gpt-4-0314'] # 最も高性能なモデルのリスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.811073Z",
     "iopub.status.busy": "2024-07-09T23:32:11.810729Z",
     "iopub.status.idle": "2024-07-09T23:32:11.865559Z",
     "shell.execute_reply": "2024-07-09T23:32:11.864715Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.811041Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各モデルの最も多く出現する10の応答を取得する\n",
    "for model in top_models:\n",
    "    print(f\"\\nモデル: {model} - 最も多く出現する10の応答 (response_a):\")\n",
    "    top_responses_a = response_a_counts_df[response_a_counts_df['model_a'] == model].sort_values(by='count', ascending=False).head(10) # 出現回数でソートして上位10を取得\n",
    "    print(top_responses_a)\n",
    "\n",
    "    print(f\"\\nモデル: {model} - 最も多く出現する10の応答 (response_b):\")\n",
    "    top_responses_b = response_b_counts_df[response_b_counts_df['model_b'] == model].sort_values(by='count', ascending=False).head(10) # 出現回数でソートして上位10を取得\n",
    "    print(top_responses_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:11.867529Z",
     "iopub.status.busy": "2024-07-09T23:32:11.866751Z",
     "iopub.status.idle": "2024-07-09T23:32:15.597461Z",
     "shell.execute_reply": "2024-07-09T23:32:15.596527Z",
     "shell.execute_reply.started": "2024-07-09T23:32:11.867498Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者モデルの名前を決定し、新しい列を作成する関数\n",
    "def determine_winner(row):\n",
    "    if row['winner_model_a'] == 1.0:\n",
    "        return row['model_a'] # model_aが勝者の場合\n",
    "    elif row['winner_model_b'] == 1.0:\n",
    "        return row['model_b'] # model_bが勝者の場合\n",
    "    else:\n",
    "        return 'tie' # 引き分けの場合\n",
    "\n",
    "# 勝者列を作成する\n",
    "df['winner'] = df.apply(determine_winner, axis=1)\n",
    "\n",
    "# promptとwinner列のみを取得し、グループ化する\n",
    "grouped_df = df[['prompt', 'winner']].groupby('prompt')['winner'].apply(list).reset_index() # 各promptに対する勝者をリスト化する\n",
    "\n",
    "# CSVとして出力する\n",
    "grouped_df.to_csv('prompt_winners.csv', index=False) # 結果をCSVファイルとして保存する\n",
    "\n",
    "print(\"CSVファイルが正常に作成されました: 'prompt_winners.csv'\") # メッセージ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:15.599136Z",
     "iopub.status.busy": "2024-07-09T23:32:15.598774Z",
     "iopub.status.idle": "2024-07-09T23:32:15.81651Z",
     "shell.execute_reply": "2024-07-09T23:32:15.815597Z",
     "shell.execute_reply.started": "2024-07-09T23:32:15.599101Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = pd.read_csv(\"/kaggle/working/prompt_winners.csv\") # 作成したCSVファイルを読み込む\n",
    "prompt.groupby(\"winner\").count().reset_index().head(20) # 勝者ごとのカウントを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:15.817928Z",
     "iopub.status.busy": "2024-07-09T23:32:15.817662Z",
     "iopub.status.idle": "2024-07-09T23:32:15.857518Z",
     "shell.execute_reply": "2024-07-09T23:32:15.856685Z",
     "shell.execute_reply.started": "2024-07-09T23:32:15.817904Z"
    }
   },
   "outputs": [],
   "source": [
    "# 勝者モデルに基づいてpromptをグループ化し、最も多く出現するものを見つける\n",
    "winner_counts = prompt.explode('winner').groupby('winner').size().reset_index(name='count') # 各勝者の出現回数を集計する\n",
    "winner_counts = winner_counts.sort_values(by='count', ascending=False) # 出現回数でソートする\n",
    "\n",
    "# CSVとして出力する\n",
    "winner_counts.to_csv('prompt_top_winners.csv', index=False) # 出現回数をCSVファイルとして保存する\n",
    "\n",
    "print(\"CSVファイルが正常に作成されました: 'prompt_top_winners.csv'\") # メッセージ表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:15.858765Z",
     "iopub.status.busy": "2024-07-09T23:32:15.85852Z",
     "iopub.status.idle": "2024-07-09T23:32:15.868386Z",
     "shell.execute_reply": "2024-07-09T23:32:15.867429Z",
     "shell.execute_reply.started": "2024-07-09T23:32:15.858744Z"
    }
   },
   "outputs": [],
   "source": [
    "winner_counts.head(20) # 出現回数の上位20を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:15.869833Z",
     "iopub.status.busy": "2024-07-09T23:32:15.86958Z",
     "iopub.status.idle": "2024-07-09T23:32:16.092112Z",
     "shell.execute_reply": "2024-07-09T23:32:16.091283Z",
     "shell.execute_reply.started": "2024-07-09T23:32:15.869811Z"
    }
   },
   "outputs": [],
   "source": [
    "# promptと勝者モデルの情報で出力を作成する\n",
    "prompt_winners = df.groupby(['winner', 'prompt']).sum().reset_index() # 勝者とpromptでグループ化\n",
    "\n",
    "prompt_winners # 結果を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:16.093797Z",
     "iopub.status.busy": "2024-07-09T23:32:16.09343Z",
     "iopub.status.idle": "2024-07-09T23:32:16.106242Z",
     "shell.execute_reply": "2024-07-09T23:32:16.105404Z",
     "shell.execute_reply.started": "2024-07-09T23:32:16.093763Z"
    }
   },
   "outputs": [],
   "source": [
    "top_prompt = pd.read_csv(\"/kaggle/working/prompt_top_winners.csv\") # 先程作成したCSVファイルを読み込む\n",
    "top_prompt.head(20) # 最も多く出現する勝者の情報を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:16.108162Z",
     "iopub.status.busy": "2024-07-09T23:32:16.107454Z",
     "iopub.status.idle": "2024-07-09T23:32:16.298557Z",
     "shell.execute_reply": "2024-07-09T23:32:16.297585Z",
     "shell.execute_reply.started": "2024-07-09T23:32:16.108131Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'tie'の場合のresponse_aとresponse_bの値をグループ化して出力する\n",
    "tie_responses = df[df['winner'] == 'tie'].groupby(['response_a', 'response_b']).sum().reset_index()[['response_a', 'response_b',\"prompt\"]] # 引き分けの応答をグループ化\n",
    "\n",
    "tie_responses # 引き分けの応答を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:32:16.300093Z",
     "iopub.status.busy": "2024-07-09T23:32:16.299816Z",
     "iopub.status.idle": "2024-07-09T23:32:30.889905Z",
     "shell.execute_reply": "2024-07-09T23:32:30.888921Z",
     "shell.execute_reply.started": "2024-07-09T23:32:16.300069Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_winner_and_loser(row):\n",
    "    if row['winner_model_a'] == 1.0:\n",
    "        winner = row['model_a'] # 勝者はmodel_a\n",
    "        loser = row['model_b'] # 敗者はmodel_b\n",
    "        winner_response = row['response_a'] # 勝者の応答はresponse_a\n",
    "        loser_response = row['response_b'] # 敗者の応答はresponse_b\n",
    "    elif row['winner_model_b'] == 1.0:\n",
    "        winner = row['model_b'] # 勝者はmodel_b\n",
    "        loser = row['model_a'] # 敗者はmodel_a\n",
    "        winner_response = row['response_b'] # 勝者の応答はresponse_b\n",
    "        loser_response = row['response_a'] # 敗者の応答はresponse_a\n",
    "    else:\n",
    "        winner = 'tie' # 引き分けの場合\n",
    "        loser = 'tie' # 敗者も引き分け\n",
    "        winner_response = '' # 勝者の応答は空\n",
    "        loser_response = '' # 敗者の応答も空\n",
    "    \n",
    "    return pd.Series([winner, loser, len(winner_response), len(loser_response)], index=['winner', 'loser', 'winner_response_length', 'loser_response_length'])\n",
    "\n",
    "# 勝者と敗者の列を作成する\n",
    "winner_loser_lengths = df.apply(determine_winner_and_loser, axis=1) # 勝者と敗者の情報を取得\n",
    "\n",
    "# 以前のデータフレームに追加して新しいデータフレームを作成する\n",
    "prompt_df = pd.concat([df[['prompt']], winner_loser_lengths], axis=1) # promptと勝者・敗者情報を結合する\n",
    "\n",
    "prompt_df.head(20) # 結果を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:39:04.528755Z",
     "iopub.status.busy": "2024-07-09T23:39:04.527875Z",
     "iopub.status.idle": "2024-07-09T23:39:06.294763Z",
     "shell.execute_reply": "2024-07-09T23:39:06.293902Z",
     "shell.execute_reply.started": "2024-07-09T23:39:04.528721Z"
    }
   },
   "outputs": [],
   "source": [
    "# CSVファイルを読み込む\n",
    "train_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# データを結合する\n",
    "df = pd.concat([train_df, test_df], ignore_index=True) # トレーニングデータとテストデータを結合する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:39:45.422758Z",
     "iopub.status.busy": "2024-07-09T23:39:45.422089Z",
     "iopub.status.idle": "2024-07-09T23:39:45.437105Z",
     "shell.execute_reply": "2024-07-09T23:39:45.436116Z",
     "shell.execute_reply.started": "2024-07-09T23:39:45.422725Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df # トレーニングデータフレームを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:39:08.332626Z",
     "iopub.status.busy": "2024-07-09T23:39:08.332247Z",
     "iopub.status.idle": "2024-07-09T23:39:08.35138Z",
     "shell.execute_reply": "2024-07-09T23:39:08.350518Z",
     "shell.execute_reply.started": "2024-07-09T23:39:08.332598Z"
    }
   },
   "outputs": [],
   "source": [
    "df # 結合されたデータフレームを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:47:57.874638Z",
     "iopub.status.busy": "2024-07-09T23:47:57.874307Z",
     "iopub.status.idle": "2024-07-09T23:47:57.879044Z",
     "shell.execute_reply": "2024-07-09T23:47:57.878127Z",
     "shell.execute_reply.started": "2024-07-09T23:47:57.874615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Polars DataFrameを作成する\n",
    "import polars as pl\n",
    "from textblob import TextBlob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-09T23:49:28.363129Z",
     "iopub.status.busy": "2024-07-09T23:49:28.36233Z",
     "iopub.status.idle": "2024-07-09T23:49:28.801753Z",
     "shell.execute_reply": "2024-07-09T23:49:28.80086Z",
     "shell.execute_reply.started": "2024-07-09T23:49:28.3631Z"
    }
   },
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Polars DataFrameを作成する\n",
    "df = pl.DataFrame(df)\n",
    "\n",
    "# 感情分析とエラー数カウントの関数を定義\n",
    "def batch_analyze_sentiment(texts):\n",
    "    return np.array([TextBlob(text).sentiment.polarity for text in texts]) # 各テキストの感情極性を取得\n",
    "\n",
    "def batch_count_errors(texts):\n",
    "    return np.array([text.lower().count('error') for text in texts]) # 各テキストでの\"error\"の数をカウント\n",
    "    \n",
    "# 新しい列を作成する\n",
    "df = df.with_columns([\n",
    "    pl.col('response_a').str.lengths().alias('response_a_length'), # response_aの長さを計算\n",
    "    pl.col('response_b').str.lengths().alias('response_b_length'), # response_bの長さを計算\n",
    "    (pl.col('response_a').str.lengths() - pl.col('response_b').str.lengths()).abs().alias('response_length_difference'), # 長さの差を正の絶対値にする\n",
    "])\n",
    "\n",
    "# 感情分析とエラー数計数のために最初の100行を処理\n",
    "if len(df) > 0:\n",
    "    n_rows = min(100, len(df)) # 処理する行数を決定\n",
    "    \n",
    "    sentiment_a = batch_analyze_sentiment(df['response_a'].head(n_rows).to_numpy()) # response_aの感情分析\n",
    "    sentiment_b = batch_analyze_sentiment(df['response_b'].head(n_rows).to_numpy()) # response_bの感情分析\n",
    "    errors_a = batch_count_errors(df['response_a'].head(n_rows).to_numpy()) # response_aのエラー数をカウント\n",
    "    errors_b = batch_count_errors(df['response_b'].head(n_rows).to_numpy()) # response_bのエラー数をカウント\n",
    "\n",
    "    # 新しい列を追加\n",
    "    df = df.with_columns([\n",
    "        pl.Series('sentiment_a', sentiment_a).extend(pl.Series([None] * (len(df) - n_rows))), # sentiment_aの列を追加\n",
    "        pl.Series('sentiment_b', sentiment_b).extend(pl.Series([None] * (len(df) - n_rows))), # sentiment_bの列を追加\n",
    "        pl.Series('errors_a', errors_a).extend(pl.Series([None] * (len(df) - n_rows))), # errors_aの列を追加\n",
    "        pl.Series('errors_b', errors_b).extend(pl.Series([None] * (len(df) - n_rows))), # errors_bの列を追加\n",
    "    ])\n",
    "\n",
    "# 勝者と敗者の列を作成する（古いバージョンとの互換性）\n",
    "df = df.with_columns([\n",
    "    pl.when(pl.col('sentiment_a') > pl.col('sentiment_b')) # sentiment_aが大きければ\n",
    "      .then(pl.col('response_a')) # winner_sentimentはresponse_a\n",
    "      .when(pl.col('sentiment_a') <= pl.col('sentiment_b')) # sentiment_aが小さければ\n",
    "      .then(pl.col('response_b')) # winner_sentimentはresponse_b\n",
    "      .alias('winner_sentiment'), # 列名を設定\n",
    "    pl.when(pl.col('sentiment_a') < pl.col('sentiment_b')) # sentiment_aが小さければ\n",
    "      .then(pl.col('response_a')) # loser_sentimentはresponse_a\n",
    "      .when(pl.col('sentiment_a') >= pl.col('sentiment_b')) # sentiment_aが大きければ\n",
    "      .then(pl.col('response_b')) # loser_sentimentはresponse_b\n",
    "      .alias('loser_sentiment') # 列名を設定\n",
    "])\n",
    "\n",
    "df # 結果を表示する"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
