{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28288df",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、「LMSYS Keras Gemma 2B」というタイトルで、LMSYS - Chatbot Arenaのコンペティションにおけるチャットボット応答の評価問題に取り組んでいます。具体的には、与えられたユーザーのプロンプトに対して複数の応答モデルから勝者を予測するためのモデルを構築およびトレーニングしています。\n",
    "\n",
    "### 実装手法:\n",
    "1. **ライブラリと環境の設定:**\n",
    "   - `keras-nlp`および`tensorflow-text`を使用して自然言語処理のためのKeras機能を強化し、`tensorflow-cpu`をインストールしてTPUに悪影響を与えないよう設定しています。\n",
    "   - JAXライブラリを利用し、高速な数値計算が可能な環境を整えています。\n",
    "\n",
    "2. **デバイスの管理:**\n",
    "   - KerasのディストリビューションAPIを使用して、TPUリソースを効率的に利用するためのデバイスメッシュを設定し、モデルの重みを8つのTPUに分散させています。\n",
    "\n",
    "3. **データの前処理:**\n",
    "   - 入力プロンプトとレスポンスのペアをCSVファイルから読み込み、適切に整形して新しいデータフレームを作成しています。このデータには、応答の勝利モデル情報も含まれています。\n",
    "   - テキスト内の非表示文字（サロゲートペア）を取り除く関数を定義し、データクレンジングを行っています。\n",
    "\n",
    "4. **モデルの構築:**\n",
    "   - Kerasの`GemmaCausalLM`モデルを利用して、因果モデルをベースとした構造を設計しています。そして、独自の全結合層を追加して、最終的な出力を3クラスのsoftmax出力にセットしています。\n",
    "   - LoRA（Low-Rank Adaptation）を使用してモデルの知識を効率的に適応させ、計算資源の無駄を減らしています。\n",
    "\n",
    "5. **モデルのコンパイルとトレーニング:**\n",
    "   - AdamWオプティマイザを利用し、学習率と重みの減衰を設定してモデルをコンパイルしています。\n",
    "   - TensorFlowのデータセットAPIを利用してトレーニングデータを準備し、モデルを1エポック訓練しています。\n",
    "\n",
    "6. **重みの保存:**\n",
    "   - トレーニング後、LoRAで適応したモデルの重みを保存して、後で再利用できるようにしています。\n",
    "\n",
    "このノートブックは、KerasとTensorFlowを利用して、複数の応答モデル間の優劣を予測するための効率的な機械学習モデルを構築するための枠組みを提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5cf0d",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容に関連する機械学習・深層学習の専門用語の簡易解説を列挙します。特に初心者がつまずきそうなマイナーなものやドメイン特有のものに焦点を当てています。\n",
    "\n",
    "1. **TPU (Tensor Processing Unit)**:\n",
    "   - Googleが開発した専用のハードウェアで、大規模な機械学習のモデルを効率的にトレーニングするために設計されています。TPUは特に行列演算を高速化するための最適化がされており、深層学習モデルのトレーニングに利用されます。\n",
    "\n",
    "2. **JAX**:\n",
    "   - Googleが開発した数値計算ライブラリで、NumPyに似たインターフェースを持ちながら、自動微分、GPU/TPUのサポート、高速な数値計算が可能です。研究者やデータサイエンティストが特に利用します。\n",
    "\n",
    "3. **XLA (Accelerated Linear Algebra)**:\n",
    "   - TensorFlowの背後にある最適化される線形代数コンパイラで、数値計算の効率を向上させることを目的としています。特に計算グラフを最適化し、さまざまなハードウェアで実行速度を向上させます。\n",
    "\n",
    "4. **デバイスメッシュ (Device Mesh)**:\n",
    "   - 分散処理のために、複数のデバイス（CPUまたはTPU）を論理的に構築した構成です。これにより、大規模モデルのトレーニングや推論が効率的に行えます。\n",
    "\n",
    "5. **レイアウトマップ (Layout Map)**:\n",
    "   - モデルの重みや計算を特定のデバイスに分散させるために使用される構造です。特にTPUのような特定のハードウェアでの効率的な計算を実現するために重要です。\n",
    "\n",
    "6. **サロゲートペア (Surrogate Pairs)**:\n",
    "   - Unicodeでの文字エンコーディングにおいて、2つの16ビットのコード単位（サロゲートペア）を使って1つの文字を表現する方法です。通常の文字としては表現できない範囲の文字に使用され、テキスト処理で問題を引き起こすことがあるため、除去が必要になる場合があります。\n",
    "\n",
    "7. **LoRA (Low-Rank Adaptation)**:\n",
    "   - 大規模な事前学習済みモデルの特定のタスク向けの微調整を行うための手法で、モデルのパラメータ数を増やさずに adaptationを行います。このテクニックは計算リソースを効率的に使用し、モデルの性能を向上させることができます。\n",
    "\n",
    "8. **グローバル平均プール (Global Average Pooling)**:\n",
    "   - 多次元のテンソル（通常は空間的な特徴マップ）のすべての要素の平均を取る操作です。画像分類や自然言語処理のタスクで、各特徴チャネルから1つの数値を抽出し、全体の特徴を要約するのに使われます。\n",
    "\n",
    "9. **tf.data.Dataset**:\n",
    "   - TensorFlowでデータを効率的に管理し、モデルに供給するためのAPIです。これを使うことで、データの前処理、シャッフル、バッチ処理などを簡便に行うことができます。\n",
    "\n",
    "10. **ハイパーパラメータ (Hyperparameter)**:\n",
    "    - モデルのトレーニングプロセスや構造を設定するためのパラメータであり、学習率やバッチサイズなどが含まれます。これらは学習前に設定され、モデルの性能に大きく影響します。\n",
    "\n",
    "これらの解説が、ノートブックの内容を理解する助けになることを願っています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa0fdc",
   "metadata": {},
   "source": [
    "# LMSYS Keras Gemma 2B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:56:05.498051Z",
     "iopub.status.busy": "2024-07-29T06:56:05.497652Z",
     "iopub.status.idle": "2024-07-29T06:57:43.429684Z",
     "shell.execute_reply": "2024-07-29T06:57:43.428802Z",
     "shell.execute_reply.started": "2024-07-29T06:56:05.49802Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-nlp tensorflow-text\n",
    "# keras-nlp と tensorflow-text をアップグレードしてインストールします。\n",
    "# これにより、NLP用のKerasライブラリとテキスト処理用のTensorFlowライブラリが使用可能になります。\n",
    "\n",
    "!pip install -q -U tensorflow-cpu\n",
    "# tensorflow-cpu をインストールします。\n",
    "# これにより、TensorFlow がTPUにアクセスしようとしないようにします。\n",
    "# TPU は特別なハードウェアで、通常のCPUの代わりに使われることがあるため、ここではCPU版を指定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:57:43.43165Z",
     "iopub.status.busy": "2024-07-29T06:57:43.431382Z",
     "iopub.status.idle": "2024-07-29T06:57:52.444325Z",
     "shell.execute_reply": "2024-07-29T06:57:52.443449Z",
     "shell.execute_reply.started": "2024-07-29T06:57:43.431622Z"
    }
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "# JAXライブラリをインポートします。\n",
    "# JAXは、高速な数値計算や自動微分を提供するライブラリです。\n",
    "\n",
    "jax.devices()\n",
    "# 使用可能なデバイスを表示します。\n",
    "# この関数は、JAXが使用できるCPUやGPU、TPUなどのデバイスをリストします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:57:52.445765Z",
     "iopub.status.busy": "2024-07-29T06:57:52.445389Z",
     "iopub.status.idle": "2024-07-29T06:57:52.449746Z",
     "shell.execute_reply": "2024-07-29T06:57:52.449044Z",
     "shell.execute_reply.started": "2024-07-29T06:57:52.445733Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Keras 3のディストリビューションAPIは、現時点ではJAXバックエンドでのみ実装されています。\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# TPUのメモリを事前に確保して、メモリの断片化と割り当てのオーバーヘッドを最小化します。\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "# XLA（Accelerated Linear Algebra）Pythonクライアントのメモリ使用率を1.0に設定し、\n",
    "# すべてのTPUメモリを確保します。これにより、メモリの効率的な使用が促進されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:57:52.451882Z",
     "iopub.status.busy": "2024-07-29T06:57:52.451493Z",
     "iopub.status.idle": "2024-07-29T06:58:01.309233Z",
     "shell.execute_reply": "2024-07-29T06:58:01.308395Z",
     "shell.execute_reply.started": "2024-07-29T06:57:52.451825Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_nlp\n",
    "\n",
    "# Kerasライブラリをインポートします。\n",
    "# Kerasは、深層学習モデルを簡単に構築・トレーニングできる高水準なAPIです。\n",
    "\n",
    "import keras_nlp\n",
    "# keras_nlpライブラリをインポートします。\n",
    "# keras_nlpは、自然言語処理（NLP）タスクに特化したKerasの拡張機能であり、\n",
    "# モデルの構築やデータ処理を支援するための豊富なツールやモジュールを提供します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:01.310493Z",
     "iopub.status.busy": "2024-07-29T06:58:01.310095Z",
     "iopub.status.idle": "2024-07-29T06:58:01.31465Z",
     "shell.execute_reply": "2024-07-29T06:58:01.31388Z",
     "shell.execute_reply.started": "2024-07-29T06:58:01.310466Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1, 8) の形状のデバイスメッシュを作成し、すべての8つのTPUに重みを分散させます。\n",
    "device_mesh = keras.distribution.DeviceMesh(\n",
    "    (8, 1),  # デバイスメッシュの形状を指定します。ここでは8つのTPUを使います。\n",
    "    [\"batch\", \"model\"],  # バッチ次元とモデル次元を指定します。\n",
    "    devices=keras.distribution.list_devices(),  # 使用可能なデバイスのリストを取得します。\n",
    ") \n",
    "# このデバイスメッシュは、TPUのリソースを効果的に利用するために、\n",
    "# モデルの重みを複数のTPUにまたがって分散させるために使用されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:01.315786Z",
     "iopub.status.busy": "2024-07-29T06:58:01.315522Z",
     "iopub.status.idle": "2024-07-29T06:58:01.334109Z",
     "shell.execute_reply": "2024-07-29T06:58:01.333367Z",
     "shell.execute_reply.started": "2024-07-29T06:58:01.31575Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dim = \"model\"\n",
    "\n",
    "layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "\n",
    "# 'token_embedding/embeddings'に一致する重みは、8つのTPUに分割されます。\n",
    "layout_map[\"token_embedding/embeddings\"] = (model_dim, None)\n",
    "\n",
    "# Attentionレイヤー内のクエリ、キー、値の行列に対して一致する正規表現\n",
    "layout_map[\"decoder_block.*attention.*(query|key|value)/kernel\"] = (model_dim, None, None)\n",
    "\n",
    "# Attention出力のカーネルに対するレイアウトマップの設定\n",
    "layout_map[\"decoder_block.*attention_output/kernel\"] = (model_dim, None, None)\n",
    "\n",
    "# フィードフォワードゲーティングのカーネルに対するレイアウトマップの設定\n",
    "layout_map[\"decoder_block.*ffw_gating.*/kernel\"] = (None, model_dim)\n",
    "\n",
    "# フィードフォワード線形変換のカーネルに対するレイアウトマップの設定\n",
    "layout_map[\"decoder_block.*ffw_linear/kernel\"] = (model_dim, None)\n",
    "\n",
    "# このレイアウトマップは、モデルの重みがTPU間で適切に分散されるように配置を設定します。\n",
    "# 各重みに対して適切なデバイスを指定することで、計算効率を向上させます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:01.3352Z",
     "iopub.status.busy": "2024-07-29T06:58:01.334945Z",
     "iopub.status.idle": "2024-07-29T06:58:01.343022Z",
     "shell.execute_reply": "2024-07-29T06:58:01.342334Z",
     "shell.execute_reply.started": "2024-07-29T06:58:01.335175Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_surrogates(text):\n",
    "    # テキスト内のサロゲートペア（Unicodeの範囲0xD800から0xDFFF）を削除する関数です。\n",
    "    return ''.join(char for char in text if not (0xD800 <= ord(char) <= 0xDFFF))\n",
    "    # 上記の条件に基づいて、サロゲートペアではない文字のみを結合して新しい文字列を作成し、\n",
    "    # サロゲートペアを排除したテキストを返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:01.344112Z",
     "iopub.status.busy": "2024-07-29T06:58:01.343867Z",
     "iopub.status.idle": "2024-07-29T06:58:26.479656Z",
     "shell.execute_reply": "2024-07-29T06:58:26.478889Z",
     "shell.execute_reply.started": "2024-07-29T06:58:01.344088Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, DataFrame\n",
    "\n",
    "input_columns = ['prompt', 'response_a', 'response_b']\n",
    "label_columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# CSVファイルから生のトレーニングデータセットを読み込みます。\n",
    "raw_train_dataset = read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "\n",
    "# nullでない場合にevalを使って最初の要素を取得し、入力カラムに適用します。\n",
    "raw_train_dataset[input_columns] = raw_train_dataset[input_columns].map(lambda x: eval(x)[0] if 'null' not in x else None)\n",
    "\n",
    "# 欠損値を持つ行を削除し、不要なカラム（'model_a', 'model_b'）を削除してインデックスをリセットします。\n",
    "raw_train_dataset = raw_train_dataset.dropna().drop(['model_a', 'model_b'], axis=1).reset_index(drop=True)\n",
    "\n",
    "# 新しいデータフレームを作成し、テキストとラベルを設定します。\n",
    "train_dataset = DataFrame({\n",
    "    'text' : raw_train_dataset[input_columns].apply(lambda x: '<start_of_turn>user\\nFind which one is the best answer for the question:\\n'+x['prompt']+'\\n\\nA:\\n'+x['response_a']+'\\n\\nB\\n:'+x['response_b']+'\\n\\nC:\\n both right (or) both wrong<end_of_turn>\\n<start_of_turn>model\\n', axis=1).apply(lambda x: remove_surrogates(x)),\n",
    "    # テキスト列には、ユーザーからのプロンプトとモデルの応答が含まれます。\n",
    "    'label' : raw_train_dataset[label_columns].apply(lambda x: x.values.tolist(), axis=1)\n",
    "    # ラベル列には、各応答の勝者をリストとして格納します。\n",
    "    # 'label' : raw_train_dataset[label_columns].apply(lambda x: 'A' if x.values.tolist()[0] == 1 else 'B' if x.values.tolist()[1] == 1 else 'C', axis=1)\n",
    "})\n",
    "\n",
    "# データセットを最初の4000行に制限します。\n",
    "train_dataset = train_dataset[:4000]\n",
    "raw_train_dataset = raw_train_dataset[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:26.480954Z",
     "iopub.status.busy": "2024-07-29T06:58:26.48068Z",
     "iopub.status.idle": "2024-07-29T06:58:26.485472Z",
     "shell.execute_reply": "2024-07-29T06:58:26.484799Z",
     "shell.execute_reply.started": "2024-07-29T06:58:26.480928Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_dataset)\n",
    "# train_datasetのデータフレームの行数を取得します。\n",
    "# この行数はトレーニングデータセットに含まれるサンプルの数を示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:26.488253Z",
     "iopub.status.busy": "2024-07-29T06:58:26.488019Z",
     "iopub.status.idle": "2024-07-29T06:58:26.500549Z",
     "shell.execute_reply": "2024-07-29T06:58:26.499878Z",
     "shell.execute_reply.started": "2024-07-29T06:58:26.48823Z"
    }
   },
   "outputs": [],
   "source": [
    "model_parallel = keras.distribution.ModelParallel(\n",
    "    layout_map=layout_map,  # 先に定義したレイアウトマップを使用します。\n",
    "    batch_dim_name=\"batch\",  # バッチ次元の名前を指定します。\n",
    ")\n",
    "\n",
    "# モデルの並列処理の設定を行います。\n",
    "keras.distribution.set_distribution(model_parallel)\n",
    "# これにより、モデルがTPUでのトレーニングのために適切に分散されるようになります。\n",
    "# 同時に複数のTPUを利用してトレーニングが行えるようになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:58:26.501593Z",
     "iopub.status.busy": "2024-07-29T06:58:26.501345Z",
     "iopub.status.idle": "2024-07-29T06:59:23.098852Z",
     "shell.execute_reply": "2024-07-29T06:59:23.09785Z",
     "shell.execute_reply.started": "2024-07-29T06:58:26.50157Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.config.set_floatx(\"float16\")\n",
    "# Kerasの浮動小数点数の精度をfloat16に設定します。\n",
    "# これにより、メモリ使用量が削減され、高速な計算が可能になります。\n",
    "\n",
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma/keras/gemma_instruct_2b_en/2\")\n",
    "# GemmaCausalLMモデルを指定されたプレセットから読み込みます。\n",
    "# このモデルは因果言語モデルであり、自然言語の生成タスクに使用されます。\n",
    "\n",
    "gemma_lm.summary()\n",
    "# モデルの概要を表示します。\n",
    "# これにより、モデルの構造、パラメータの数、レイヤーの情報などが確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.100115Z",
     "iopub.status.busy": "2024-07-29T06:59:23.099862Z",
     "iopub.status.idle": "2024-07-29T06:59:23.809402Z",
     "shell.execute_reply": "2024-07-29T06:59:23.808235Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.10009Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.backbone.enable_lora(rank=8)\n",
    "# GemmaモデルのバックボーンにLoRA（Low-Rank Adaptation）を有効にします。\n",
    "# rank=8は、LoRAのランクを8に設定することを意味します。\n",
    "# LoRAは、モデルのパラメータ数を増やさずに、特定のタスクに対するモデルの適応能力を向上させるための手法です。\n",
    "# これにより、少ない計算リソースで効果的にモデルを微調整できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.810799Z",
     "iopub.status.busy": "2024-07-29T06:59:23.810479Z",
     "iopub.status.idle": "2024-07-29T06:59:23.814453Z",
     "shell.execute_reply": "2024-07-29T06:59:23.81367Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.810769Z"
    }
   },
   "outputs": [],
   "source": [
    "# gemma_lm.backbone.layers[:16]の各レイヤーについて、学習可能な状態を無効化します。\n",
    "# for layer in gemma_lm.backbone.layers[:16]:\n",
    "#     layer.trainable = False\n",
    "# 最初の16層の重みを固定し、トレーニング中にこれらのパラメータが更新されないようにします。\n",
    "# これにより、モデル全体のトレーニング時間を短縮し、過学習を防ぐことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.815544Z",
     "iopub.status.busy": "2024-07-29T06:59:23.81532Z",
     "iopub.status.idle": "2024-07-29T06:59:23.844591Z",
     "shell.execute_reply": "2024-07-29T06:59:23.843877Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.815521Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.summary()\n",
    "# モデルの概要を再表示します。\n",
    "# これにより、モデルの構造、レイヤーの情報、トレーニング可能なパラメータの数などが確認でき、\n",
    "# 変更後のモデルの状態を確認できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.84574Z",
     "iopub.status.busy": "2024-07-29T06:59:23.845516Z",
     "iopub.status.idle": "2024-07-29T06:59:23.849963Z",
     "shell.execute_reply": "2024-07-29T06:59:23.849244Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.845717Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    # テキストとラベルを前処理する関数です。\n",
    "    preprocessed = gemma_lm._preprocessor(text, sequence_length=3072)[0]\n",
    "    # Gemmaモデルのプリプロセッサを使用してテキストを3072のシーケンス長に前処理します。\n",
    "    \n",
    "    # 前処理関数が必要な入力のみを返すようにします。\n",
    "    return (\n",
    "        {'token_ids': preprocessed['token_ids'], 'padding_mask': preprocessed['padding_mask']}, \n",
    "        label if label is not None else {'token_ids': preprocessed['token_ids'], 'padding_mask': preprocessed['padding_mask']}\n",
    "    )\n",
    "    # token_idsとpadding_maskからなる辞書を返します。\n",
    "    # ラベルがNoneでない場合は、ラベルも一緒に返します。そうでなければ、token_idsとpadding_maskの辞書を返します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.85123Z",
     "iopub.status.busy": "2024-07-29T06:59:23.850969Z",
     "iopub.status.idle": "2024-07-29T06:59:23.861982Z",
     "shell.execute_reply": "2024-07-29T06:59:23.861171Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.851203Z"
    }
   },
   "outputs": [],
   "source": [
    "gemma_lm.layers[-1]\n",
    "# Gemmaモデルの最後のレイヤーを取得します。\n",
    "# これにより、モデルの出力層や最後の層の詳細を確認できます。\n",
    "# モデルのアーキテクチャを理解するために役立ちます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:23.863087Z",
     "iopub.status.busy": "2024-07-29T06:59:23.862876Z",
     "iopub.status.idle": "2024-07-29T06:59:24.115594Z",
     "shell.execute_reply": "2024-07-29T06:59:24.114674Z",
     "shell.execute_reply.started": "2024-07-29T06:59:23.863065Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "# Gemmaモデルの最後のレイヤーを削除します。\n",
    "del gemma_lm.layers[-1]\n",
    "\n",
    "# ガーベジコレクションを実行して、不要なメモリを解放します。\n",
    "gc.collect()\n",
    "# これにより、削除されたレイヤーに関連するメモリが解放され、\n",
    "# メモリ使用量を最適化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:24.117133Z",
     "iopub.status.busy": "2024-07-29T06:59:24.116753Z",
     "iopub.status.idle": "2024-07-29T06:59:24.627224Z",
     "shell.execute_reply": "2024-07-29T06:59:24.626229Z",
     "shell.execute_reply.started": "2024-07-29T06:59:24.117104Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling1D\n",
    "from keras import Model\n",
    "\n",
    "# モデルの入力を定義します。\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(3072,), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(3072,), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "\n",
    "# Gemmaモデルのバックボーンを通して入力を処理します。\n",
    "x = gemma_lm.backbone(inputs)\n",
    "print(x.shape)  # Gemmaモデルの出力の形状を表示します。\n",
    "\n",
    "# 出力をグローバル平均プールします。\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "print(x.shape)  # プーリング後の形状を表示します。\n",
    "\n",
    "# 最後に、3クラスのsoftmax出力を持つ全結合層を定義します。\n",
    "outputs = Dense(3, 'softmax')(x)\n",
    "# 入力と出力を使ってモデルを構築します。\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:24.628659Z",
     "iopub.status.busy": "2024-07-29T06:59:24.628409Z",
     "iopub.status.idle": "2024-07-29T06:59:24.635005Z",
     "shell.execute_reply": "2024-07-29T06:59:24.634212Z",
     "shell.execute_reply.started": "2024-07-29T06:59:24.628633Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.AdamW(\n",
    "                learning_rate=5e-5,  # 学習率を5e-5に設定します。\n",
    "                weight_decay=0.01,   # 重みの減衰を0.01に設定します。\n",
    ")\n",
    "\n",
    "# 重み減衰を適用しない変数の名前を指定します。\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "# これにより、バイアスとスケールに関連するパラメータには重み減衰が適用されません。\n",
    "# これは、過学習を防ぎつつモデルの学習パフォーマンスを向上させるために行われます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:24.636332Z",
     "iopub.status.busy": "2024-07-29T06:59:24.636074Z",
     "iopub.status.idle": "2024-07-29T06:59:24.647394Z",
     "shell.execute_reply": "2024-07-29T06:59:24.64663Z",
     "shell.execute_reply.started": "2024-07-29T06:59:24.6363Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),)\n",
    "# モデルをコンパイルします。\n",
    "# 指定したオプティマイザ（optimizer）を使用し、損失関数としてカテゴリカルクロスエントロピーを設定します。\n",
    "# カテゴリカルクロスエントロピーは、多クラス分類の問題でよく使用される損失関数であり、\n",
    "# モデルの出力と教師データのクラスラベルとの間の不一致を測定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:24.648628Z",
     "iopub.status.busy": "2024-07-29T06:59:24.648388Z",
     "iopub.status.idle": "2024-07-29T06:59:24.988915Z",
     "shell.execute_reply": "2024-07-29T06:59:24.987991Z",
     "shell.execute_reply.started": "2024-07-29T06:59:24.648604Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# トレーニングデータセットからテキストとラベルを含むデータセットを作成します。\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_dataset.text.values, raw_train_dataset[label_columns].values))\\\n",
    "    .batch(8)  # バッチサイズを8に設定します。\n",
    "    \n",
    "# 前処理関数をデータセットに適用します。\n",
    "ds = ds.map(preprocess_fn)\n",
    "\n",
    "# データセットをシャッフルします。\n",
    "ds = ds.shuffle(ds.cardinality())\n",
    "# cardinality()はデータセットのサンプル数を返します。\n",
    "# シャッフルにより、トレーニングデータの順序がランダム化され、モデルの学習が改善されることが期待されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T06:59:24.990156Z",
     "iopub.status.busy": "2024-07-29T06:59:24.989917Z",
     "iopub.status.idle": "2024-07-29T07:10:31.283727Z",
     "shell.execute_reply": "2024-07-29T07:10:31.282559Z",
     "shell.execute_reply.started": "2024-07-29T06:59:24.990133Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split = ds.take(int(len(ds) * 0.9))\n",
    "# データセットの90%を訓練用分割として取得します。\n",
    "\n",
    "val_split = ds.skip(int(len(ds) * 0.9)).take(int(len(ds) * 0.1))\n",
    "# データセットの残りの10%を検証用分割として取得します。\n",
    "# skip()で90%をスキップし、take()で次の10%を取得します。\n",
    "\n",
    "# モデルを訓練します。\n",
    "histories = model.fit(train_split, validation_data=[val_split], epochs=1, batch_size=8)\n",
    "# 訓練を1エポック行い、バッチサイズを8に設定します。\n",
    "# validation_data引数を用いて、検証用データを設定し、モデルの性能を評価します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-29T07:10:31.285648Z",
     "iopub.status.busy": "2024-07-29T07:10:31.285373Z",
     "iopub.status.idle": "2024-07-29T07:10:31.356179Z",
     "shell.execute_reply": "2024-07-29T07:10:31.355291Z",
     "shell.execute_reply.started": "2024-07-29T07:10:31.28562Z"
    }
   },
   "outputs": [],
   "source": [
    "model.get_layer(\"gemma_backbone\").save_lora_weights('/kaggle/working/lora19.lora.h5')\n",
    "# Gemmaモデルのバックボーンレイヤーに対してLoRA（Low-Rank Adaptation）重みを保存します。\n",
    "# 指定されたパス（'/kaggle/working/lora19.lora.h5'）に重みをHDF5形式で保存します。\n",
    "# これにより、後でこの重みを再利用したり、試験したりすることができます。"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5388,
     "sourceId": 11372,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
