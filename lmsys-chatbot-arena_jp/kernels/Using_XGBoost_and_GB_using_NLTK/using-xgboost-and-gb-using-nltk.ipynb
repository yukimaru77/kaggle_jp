{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f3aadd5",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyterノートブックは、Kaggleの「LMSYS - Chatbot Arena」コンペティションにおいて、ユーザーの好みを予測するためのモデルを構築する過程を示しています。特に、異なるチャットボットモデルの応答の評価を基に、どちらがより好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "### 問題とデータセット\n",
    "- コンペティションは、ユーザーが異なる応答を選択する際の選好を予測することを目指しています。このノートブックでは、与えられたデータセットを用いて、どちらのモデルが勝者かを予測するための特徴量を生成し、分類モデルを訓練します。\n",
    "\n",
    "### 手法とライブラリ\n",
    "1. **データ前処理**:\n",
    "   - `textstat`, `nltk`, `pandas`を使用して、テキストデータを読み込み、処理を行っています。具体的には、テキストから得られる単語数、文字数、文数、平均単語長、平均文長などの特徴量を計算しています。\n",
    "\n",
    "2. **特徴量生成**:\n",
    "   - 各応答の読みやすさスコアや頻度情報も計算され、最終的に訓練データセットに特徴量として追加されます。\n",
    "\n",
    "3. **モデル構築**:\n",
    "   - モデルとして、**Gradient Boosting**および**XGBoost**が使用されており、Scikit-learnの`RandomizedSearchCV`を用いてハイパーパラメータのチューニングが行われています。\n",
    "   - 層化K分割交差検証を用いてモデルのパフォーマンスを評価し、ログ損失（log loss）をスコアとして用いて最良のモデルを選択します。\n",
    "\n",
    "4. **予測と提出準備**:\n",
    "   - 最終的に選ばれたモデルを用いてテストデータに対し予測を行い、結果を指定された提出形式（`submission.csv`）で出力します。\n",
    "\n",
    "このノートブック全体を通じて、データの準備から特徴量の生成、モデルの訓練、予測および提出ファイルの生成まで一連の流れが分かりやすく実装されており、効果的な機械学習パイプラインが示されています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2a443",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebookの内容をもとに、機械学習・深層学習において初心者がつまずく可能性のある専門用語の解説を行います。\n",
    "\n",
    "1. **Pyphen**:\n",
    "   - テキストのハイフネーション（単語の分割においてハイフンを使用する方法）を行うライブラリです。自然言語処理の際に、単語を適切に行分けするために使用されることがあります。\n",
    "\n",
    "2. **textstat**:\n",
    "   - テキストの統計情報を計算するためのライブラリで、文章の読みやすさや単語数、文の数などを評価する機能を提供します。言語の特性を評価するのに役立ちます。\n",
    "\n",
    "3. **Gradient Boosting**:\n",
    "   - 決定木を基本のアルゴリズムとし、予測性能を高めるために弱い学習器を徐々に組み合わせて強い学習器を作成するアンサンブル学習の手法です。特に、モデルの過去の予測の誤差を学ぶことで改善を図ります。\n",
    "\n",
    "4. **XGBoost**:\n",
    "   - Gradient Boostingの一種で、効率性と予測精度に特化した実装です。大規模なデータセットでも扱いやすく、競技プログラミングや実務でも広く利用されています。\n",
    "\n",
    "5. **log_loss**:\n",
    "   - ログ損失関数は、確率的予測の精度を測るための指標で、モデルが予測した確率と実際のクラスのラベルとの間の違いを評価します。数値が小さいほどモデルの性能が良いことを示します。\n",
    "\n",
    "6. **StratifiedKFold**:\n",
    "   - データセットを分割する際に、各クラスの比率が保たれるように層化して分割する方法です。特に不均衡なデータにおいて、モデル評価のバイアスを減らすのに役立ちます。\n",
    "\n",
    "7. **RandomizedSearchCV**:\n",
    "   - ハイパーパラメータのチューニングのための手法で、指定されたパラメータ空間からのランダムサンプリングを行い、最適なパラメータの組み合わせを見つけるために使われます。計算コストを抑えつつ、高速に探索を行うことができます。\n",
    "\n",
    "8. **Counter**:\n",
    "   - Pythonの標準ライブラリcollectionsにあるクラスで、要素のカウント機能を提供します。例えば、テキスト中の単語の頻度を簡単に計算するのに使用します。\n",
    "\n",
    "9. **バイグラム (Bigram)**:\n",
    "   - 連続する2つの単語の組み合わせのことを指します。言語モデルやテキスト解析で文脈を理解するための重要な特徴として用いられます。\n",
    "\n",
    "10. **Flesch-Kincaid Score**:\n",
    "    - 文章の難易度を評価するための指標で、主に米国の教育現場で利用されます。高いスコアは読みやすい文章を示し、低いスコアは難解な文章を示します。\n",
    "\n",
    "11. **smog index**:\n",
    "    - テキストの読みやすさを評価する指標で、特に教育や健康関連の文書において推奨される学年レベルを示します。単語の数と難しい単語の数から算出されます。\n",
    "\n",
    "12. **型トークン比 (TTR)**:\n",
    "    - テキスト内のユニークな単語の数を、総単語数で割った値です。言語の多様性を示す指標で、テキストがどれだけ異なる単語を使用しているかを評価します。\n",
    "\n",
    "これらの用語を理解することで、ノートブックの内容がより深く把握でき、機械学習と自然言語処理の実践に役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T03:45:33.930479Z",
     "iopub.status.busy": "2024-07-08T03:45:33.92994Z",
     "iopub.status.idle": "2024-07-08T03:46:48.731426Z",
     "shell.execute_reply": "2024-07-08T03:46:48.72923Z",
     "shell.execute_reply.started": "2024-07-08T03:45:33.930436Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install ../input/textstat/Pyphen-0.10.0-py3-none-any.whl  # Pyphenライブラリをインストール\n",
    "!pip install ../input/textstat/textstat-0.7.0-py3-none-any.whl  # textstatライブラリをインストール\n",
    "import textstat  # textstatをインポートして、テキスト統計に関する機能を使用できるようにする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T02:57:54.415241Z",
     "iopub.status.busy": "2024-07-08T02:57:54.414809Z",
     "iopub.status.idle": "2024-07-08T02:57:54.426416Z",
     "shell.execute_reply": "2024-07-08T02:57:54.424526Z",
     "shell.execute_reply.started": "2024-07-08T02:57:54.41521Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn  # sklearnをインポート\n",
    "import numpy as np  # numpyをインポート（数値計算のためのライブラリ）\n",
    "import pandas as pd  # pandasをインポート（データ操作のためのライブラリ）\n",
    "import matplotlib.pyplot as plt  # matplotlibをインポート（グラフ描画のためのライブラリ）\n",
    "import time  # timeをインポート（時間計測のために使用）\n",
    "from xgboost import XGBClassifier  # XGBoostの分類器をインポート\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 勾配ブースティングの分類器をインポート\n",
    "from sklearn.metrics import log_loss  # ログ損失を評価指標としてインポート\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV  # データ分割と交差検証を行うための関数をインポート\n",
    "import nltk  # nltkをインポート（自然言語処理ライブラリ）\n",
    "import textstat  # textstatを再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from textblob import TextBlob  # テキスト処理のためのTextBlobをインポート\n",
    "from collections import Counter  # 要素のカウントを行うためのCounterをインポート\n",
    "\n",
    "import warnings  # 警告を管理するためのライブラリをインポート\n",
    "warnings.filterwarnings(\"ignore\")  # 警告を無視する設定\n",
    "warnings.filterwarnings('ignore')  # 再度同じ設定（冗長）\n",
    "pd.options.display.float_format = '{:.2f}'.format  # pandasの浮動小数点数の表示形式を設定\n",
    "pd.set_option('display.max_rows', None)  # 行数を制限せずに表示設定\n",
    "pd.set_option('display.max_columns', None)  # 列数を制限せずに表示設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:32:35.517063Z",
     "iopub.status.busy": "2024-07-07T05:32:35.516642Z",
     "iopub.status.idle": "2024-07-07T05:32:39.187137Z",
     "shell.execute_reply": "2024-07-07T05:32:39.185863Z",
     "shell.execute_reply.started": "2024-07-07T05:32:35.517031Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # サンプル提出ファイルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:32:42.051025Z",
     "iopub.status.busy": "2024-07-07T05:32:42.050567Z",
     "iopub.status.idle": "2024-07-07T05:32:42.082817Z",
     "shell.execute_reply": "2024-07-07T05:32:42.08115Z",
     "shell.execute_reply.started": "2024-07-07T05:32:42.050989Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()  # トレーニングデータの最初の5行を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:32:47.403048Z",
     "iopub.status.busy": "2024-07-07T05:32:47.402627Z",
     "iopub.status.idle": "2024-07-07T05:32:47.416005Z",
     "shell.execute_reply": "2024-07-07T05:32:47.414552Z",
     "shell.execute_reply.started": "2024-07-07T05:32:47.403014Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()  # テストデータの最初の5行を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:32:52.892621Z",
     "iopub.status.busy": "2024-07-07T05:32:52.892097Z",
     "iopub.status.idle": "2024-07-07T05:32:52.898579Z",
     "shell.execute_reply": "2024-07-07T05:32:52.897322Z",
     "shell.execute_reply.started": "2024-07-07T05:32:52.892578Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"The size of the train data: {train.shape} is and the test data is: {test.shape}\")  # トレーニングデータとテストデータのサイズを表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:34:12.864865Z",
     "iopub.status.busy": "2024-07-07T05:34:12.864408Z",
     "iopub.status.idle": "2024-07-07T05:34:12.886202Z",
     "shell.execute_reply": "2024-07-07T05:34:12.884996Z",
     "shell.execute_reply.started": "2024-07-07T05:34:12.864831Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train['winner_model_a'].value_counts())  # winner_model_aの値のカウントを表示\n",
    "print(train['winner_model_b'].value_counts())  # winner_model_bの値のカウントを表示\n",
    "print(train['winner_tie'].value_counts())  # winner_tieの値のカウントを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:34:19.213053Z",
     "iopub.status.busy": "2024-07-07T05:34:19.21252Z",
     "iopub.status.idle": "2024-07-07T05:34:20.118606Z",
     "shell.execute_reply": "2024-07-07T05:34:20.117368Z",
     "shell.execute_reply.started": "2024-07-07T05:34:19.21301Z"
    }
   },
   "outputs": [],
   "source": [
    "# 図と軸を作成する\n",
    "fig, axes = plt.subplots(3, 1, figsize=(7, 6))\n",
    "\n",
    "# プロットする列を指定\n",
    "columns = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# 0と1の色を定義\n",
    "colors = {0: 'steelblue', 1: 'salmon'}\n",
    "\n",
    "# 各列をそれぞれのサブプロットにプロット\n",
    "for i, column in enumerate(columns):\n",
    "    ax = axes[i]\n",
    "    value_counts = train[column].value_counts().sort_index()\n",
    "    \n",
    "    # 指定した色とラベルでバーをプロット\n",
    "    bars = ax.bar(value_counts.index.astype(str), value_counts, color=[colors[idx] for idx in value_counts.index],\n",
    "                  label=value_counts.index.map({0: 'Lose (0)', 1: 'Win (1)'}))\n",
    "    \n",
    "    # バーにカウントを注釈する\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3ポイントの垂直オフセット\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    ax.set_xlabel('Winner')  # x軸のラベル\n",
    "    ax.set_ylabel('Count')  # y軸のラベル\n",
    "    ax.set_title(f'Model {column.split(\"_\")[-1].capitalize()} Counts')  # タイトル設定\n",
    "    ax.legend(title='Outcome', loc='upper right')  # 凡例を設定\n",
    "\n",
    "# 全体のタイトルを追加し、レイアウトを調整\n",
    "fig.suptitle('Distribution of Winners Across Models', fontsize=16)  # 図全体のタイトル\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # レイアウトを調整\n",
    "\n",
    "# プロットを表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:34:55.667447Z",
     "iopub.status.busy": "2024-07-07T05:34:55.666991Z",
     "iopub.status.idle": "2024-07-07T05:34:56.066463Z",
     "shell.execute_reply": "2024-07-07T05:34:56.06515Z",
     "shell.execute_reply.started": "2024-07-07T05:34:55.667412Z"
    }
   },
   "outputs": [],
   "source": [
    "def process(input_str):  # 入力された文字列を処理する関数\n",
    "    stripped_str = input_str.strip('[]')  # 先頭と末尾の[]を削除\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]  # 文を分割して不要な\"\"を削除\n",
    "    return  ' '.join(sentences)  # 文を結合して返す\n",
    "\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)  # テストデータのprompt列を処理\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)  # テストデータのresponse_a列を処理\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)  # テストデータのresponse_b列を処理\n",
    "\n",
    "train.loc[:, 'prompt'] = train['prompt'].apply(process)  # トレーニングデータのprompt列を処理\n",
    "train.loc[:, 'response_a'] = train['response_a'].apply(process)  # トレーニングデータのresponse_a列を処理\n",
    "train.loc[:, 'response_b'] = train['response_b'].apply(process)  # トレーニングデータのresponse_b列を処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:34:57.853126Z",
     "iopub.status.busy": "2024-07-07T05:34:57.852697Z",
     "iopub.status.idle": "2024-07-07T05:34:57.868674Z",
     "shell.execute_reply": "2024-07-07T05:34:57.867465Z",
     "shell.execute_reply.started": "2024-07-07T05:34:57.853093Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head(3)  # トレーニングデータの最初の3行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:34:59.482959Z",
     "iopub.status.busy": "2024-07-07T05:34:59.482496Z",
     "iopub.status.idle": "2024-07-07T05:34:59.497273Z",
     "shell.execute_reply": "2024-07-07T05:34:59.496004Z",
     "shell.execute_reply.started": "2024-07-07T05:34:59.482899Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head(3)  # テストデータの最初の3行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T05:35:40.647479Z",
     "iopub.status.busy": "2024-07-07T05:35:40.647056Z",
     "iopub.status.idle": "2024-07-07T06:04:05.299653Z",
     "shell.execute_reply": "2024-07-07T06:04:05.298472Z",
     "shell.execute_reply.started": "2024-07-07T05:35:40.647444Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time  # 次の処理にかかる時間を計測するマジックコマンド\n",
    "\n",
    "# 単語数を計算する関数\n",
    "def word_count(text):\n",
    "    return len(nltk.word_tokenize(text))  # テキストをトークンに分割し、単語数を返す\n",
    "\n",
    "# 文字数を計算する関数\n",
    "def char_count(text):\n",
    "    return len(text)  # テキストの文字数を返す\n",
    "\n",
    "# 文の数を計算する関数\n",
    "def sentence_count(text):\n",
    "    return len(nltk.sent_tokenize(text))  # テキストを文に分割し、文の数を返す\n",
    "\n",
    "# 平均単語長を計算する関数\n",
    "def avg_word_length(text):\n",
    "    words = nltk.word_tokenize(text)  # テキストをトークンに分割\n",
    "    if len(words) == 0:  # 単語がない場合\n",
    "        return 0  # 0を返す\n",
    "    return sum(len(word) for word in words) / len(words)  # 単語の長さの合計を単語数で割る\n",
    "\n",
    "# 平均文長を計算する関数\n",
    "def avg_sentence_length(text):\n",
    "    words = nltk.word_tokenize(text)  # テキストをトークンに分割\n",
    "    sentences = nltk.sent_tokenize(text)  # テキストを文に分割\n",
    "    if len(sentences) == 0:  # 文がない場合\n",
    "        return 0  # 0を返す\n",
    "    return len(words) / len(sentences)  # 単語数を文の数で割る\n",
    "\n",
    "# 型トークン比を計算する関数\n",
    "def ttr(text):\n",
    "    words = nltk.word_tokenize(text)  # テキストをトークンに分割\n",
    "    if len(words) == 0:  # 単語がない場合\n",
    "        return 0  # 0を返す\n",
    "    unique_words = set(words)  # ユニークな単語を取得\n",
    "    return len(unique_words) / len(words)  # ユニーク単語数を全単語数で割る\n",
    "\n",
    "# 単語頻度を計算する関数\n",
    "def word_freq(text):\n",
    "    words = nltk.word_tokenize(text)  # テキストをトークンに分割\n",
    "    return Counter(words)  # 単語のカウントを返す\n",
    "\n",
    "# バイグラム頻度を計算する関数\n",
    "def bigram_freq(text):\n",
    "    words = nltk.word_tokenize(text)  # テキストをトークンに分割\n",
    "    bigrams = list(nltk.bigrams(words))  # バイグラムを取得\n",
    "    return Counter(bigrams)  # バイグラムのカウントを返す\n",
    "\n",
    "# 読みやすさスコアを計算する関数\n",
    "def readability_scores(text):\n",
    "    scores = {  # 各種読みやすさスコアを計算\n",
    "        \"flesch_kincaid_score\": textstat.flesch_kincaid_grade(text),\n",
    "        \"gunning_fog_index\": textstat.gunning_fog(text),\n",
    "        \"smog_index\": textstat.smog_index(text),\n",
    "        \"ari\": textstat.automated_readability_index(text)\n",
    "    }\n",
    "    return scores  # スコア辞書を返す\n",
    "\n",
    "# 追加のメトリックを計算し、データフレームに追加\n",
    "for column in [\"prompt\", \"response_a\", \"response_b\"]:\n",
    "    train[f\"{column}_word_count\"] = train[column].apply(word_count)  # 各列に単語数を追加\n",
    "    train[f\"{column}_char_count\"] = train[column].apply(char_count)  # 各列に文字数を追加\n",
    "    train[f\"{column}_sentence_count\"] = train[column].apply(sentence_count)  # 各列に文の数を追加\n",
    "    train[f\"{column}_avg_word_length\"] = train[column].apply(avg_word_length)  # 各列に平均単語長を追加\n",
    "    train[f\"{column}_avg_sentence_length\"] = train[column].apply(avg_sentence_length)  # 各列に平均文長を追加\n",
    "#     train[f\"{column}_ttr\"] = train[column].apply(ttr)  # 型トークン比を計算して追加（コメントアウト）\n",
    "#     readability = train[column].apply(readability_scores)  # 読みやすさスコアを計算\n",
    "#     train[f\"{column}_flesch_kincaid_score\"] = readability.apply(lambda x: x[\"flesch_kincaid_score\"])  # Flesch-Kincaidスコアを追加\n",
    "#     train[f\"{column}_gunning_fog_index\"] = readability.apply(lambda x: x[\"gunning_fog_index\"])  # Gunning-Fogインデックスを追加\n",
    "#     train[f\"{column}_smog_index\"] = readability.apply(lambda x: x[\"smog_index\"])  # SMOGインデックスを追加\n",
    "#     train[f\"{column}_ari\"] = readability.apply(lambda x: x[\"ari\"])  # ARIスコアを追加\n",
    "\n",
    "train.head()  # トレーニングデータの最初の5行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T09:46:55.217811Z",
     "iopub.status.busy": "2024-07-07T09:46:55.217348Z",
     "iopub.status.idle": "2024-07-07T10:38:17.625572Z",
     "shell.execute_reply": "2024-07-07T10:38:17.623941Z",
     "shell.execute_reply.started": "2024-07-07T09:46:55.217775Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time  # 次の処理にかかる時間を計測するマジックコマンド\n",
    "\n",
    "import time  # timeを再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from sklearn.ensemble import GradientBoostingClassifier  # 勾配ブースティングの分類器を再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from xgboost import XGBClassifier  # XGBoostの分類器を再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV  # データ分割と交差検証を行うための関数を再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from sklearn.metrics import log_loss  # ログ損失を評価指標として再インポート（重複していますが、他の機能を使う可能性があるため）\n",
    "from scipy.stats import uniform, randint  # scipyから乱数生成のためのライブラリをインポート\n",
    "\n",
    "# ターゲットをカテゴリカルラベルの単一列に変換\n",
    "train['winner'] = (train['winner_model_a'] * 1 + train['winner_model_b'] * 2 + train['winner_tie'] * 3).astype(int)\n",
    "\n",
    "# 特徴量とターゲットを定義\n",
    "columns_to_remove = {'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', \n",
    "                     'winner_model_a', 'winner_model_b', 'winner_tie', 'winner'}\n",
    "\n",
    "features = [col for col in train.columns if col not in columns_to_remove]  # 特徴量のリストを作成\n",
    "\n",
    "X = train[features]  # 特徴量データをXに設定\n",
    "y = train['winner'] - 1  # ターゲットデータをyに設定\n",
    "\n",
    "# データをトレーニングセットとバリデーションセットに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# モデルを定義\n",
    "models = {\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),  # 勾配ブースティング分類器\n",
    "    'XGBClassifier': XGBClassifier()  # XGBoost分類器\n",
    "}\n",
    "\n",
    "# ランダムサーチのためのパラメータの分布を定義\n",
    "param_distributions = {\n",
    "    'GradientBoostingClassifier': {\n",
    "        'n_estimators': [100,200,350,300],  # 使用する決定木の数\n",
    "        'max_depth': [2,3,4,5,7,9]  # 決定木の最大深さ\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': [100,200,350,300],  # 使用する決定木の数\n",
    "        'max_depth': [2,3,4,5,7,9]  # 決定木の最大深さ\n",
    "    }\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=1234)  # 層化K分割交差検証を設定\n",
    "\n",
    "best_models = {}  # 最良モデルを保存する辞書\n",
    "\n",
    "# 各モデルに対して繰り返し\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Model training for {model_name}\")  # 現在のモデル名を表示\n",
    "    \n",
    "    # ランダムサーチの実行\n",
    "    random_search = RandomizedSearchCV(model, param_distributions[model_name], n_iter=10, scoring='neg_log_loss', \n",
    "                                       n_jobs=-1, cv=skf, random_state=42)\n",
    "    random_search.fit(X_train, y_train)  # トレーニングデータでモデルをフィッティング\n",
    "    \n",
    "    best_model = random_search.best_estimator_  # ベストモデルを取得\n",
    "    best_models[model_name] = best_model  # 現在のモデルタイプのベストモデルを保存\n",
    "    \n",
    "    logloss_scores = []  # ログ損失スコアを保存するリスト\n",
    "    start_time = time.time()  # 計測開始時間\n",
    "    \n",
    "    count = 0  # カウント初期化\n",
    "    for train_index, test_index in skf.split(X, y):  # K分割交差検証のための分割\n",
    "        X_train_fold, X_test_fold = X.iloc[train_index], X.iloc[test_index]  # トレーニングフォールドとテストフォールド\n",
    "        y_train_fold, y_test_fold = y.iloc[train_index], y.iloc[test_index]  # ターゲットのフォールド\n",
    "\n",
    "        best_model.fit(X_train_fold, y_train_fold)  # 最良モデルでトレーニングフォールドをフィッティング\n",
    "        y_test_pred_proba = best_model.predict_proba(X_test_fold)  # テストフォールドに対する確率を予測\n",
    "\n",
    "        logloss = log_loss(y_test_fold, y_test_pred_proba)  # ログ損失を計算\n",
    "        logloss_scores.append(logloss)  # スコアをリストに追加\n",
    "        print(f\"The log loss score for fold {count}: {logloss}\")  # 現在のフォールドのログ損失を表示\n",
    "        count += 1  # カウントをインクリメント\n",
    "\n",
    "    average_logloss = sum(logloss_scores) / len(logloss_scores)  # 平均ログ損失を計算\n",
    "    print(f\"The average log loss score for {model_name} across all folds: {average_logloss}\")  # すべてのフォールドの平均ログ損失を表示\n",
    "    \n",
    "    elapsed_time = time.time() - start_time  # 経過時間を計測\n",
    "    print(f\"Time taken for {model_name}: {elapsed_time:.2f} seconds\")  # モデルのトレーニングにかかった時間を表示\n",
    "    \n",
    "    # バリデーションセットに対する確率を予測\n",
    "    y_val_prob = best_model.predict_proba(X_val)\n",
    "    # バリデーションセットでのログ損失を計算\n",
    "    val_loss = log_loss(y_val, y_val_prob)\n",
    "    print(f'Log Loss using {model_name} on validation set: {val_loss}')  # バリデーションセットでのログ損失を表示\n",
    "\n",
    "# バリデーションセットのパフォーマンスに基づいてベストモデルを特定\n",
    "best_model_name = min(best_models, key=lambda k: log_loss(y_val, best_models[k].predict_proba(X_val)))  # 最良モデル名を取得\n",
    "best_average_logloss = log_loss(y_val, best_models[best_model_name].predict_proba(X_val))  # 最良モデルの平均ログ損失を計算\n",
    "\n",
    "print(f\"The best model is {best_model_name} with an average log loss score of {best_average_logloss}\")  # 最良モデルとその平均ログ損失を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:43.661176Z",
     "iopub.status.busy": "2024-07-07T10:42:43.660688Z",
     "iopub.status.idle": "2024-07-07T10:42:43.671235Z",
     "shell.execute_reply": "2024-07-07T10:42:43.669902Z",
     "shell.execute_reply.started": "2024-07-07T10:42:43.66114Z"
    }
   },
   "outputs": [],
   "source": [
    "model_to_use = best_models[best_model_name]  # 使用するモデルを最良モデルに設定\n",
    "model_to_use  # モデル情報を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:47.716873Z",
     "iopub.status.busy": "2024-07-07T10:42:47.716419Z",
     "iopub.status.idle": "2024-07-07T10:42:47.838442Z",
     "shell.execute_reply": "2024-07-07T10:42:47.837278Z",
     "shell.execute_reply.started": "2024-07-07T10:42:47.716839Z"
    }
   },
   "outputs": [],
   "source": [
    "# 追加のメトリックを計算し、データフレームに追加\n",
    "for column in [\"prompt\", \"response_a\", \"response_b\"]:\n",
    "    test[f\"{column}_word_count\"] = test[column].apply(word_count)  # 各列に単語数を追加\n",
    "    test[f\"{column}_char_count\"] = test[column].apply(char_count)  # 各列に文字数を追加\n",
    "    test[f\"{column}_sentence_count\"] = test[column].apply(sentence_count)  # 各列に文の数を追加\n",
    "    test[f\"{column}_avg_word_length\"] = test[column].apply(avg_word_length)  # 各列に平均単語長を追加\n",
    "    test[f\"{column}_avg_sentence_length\"] = test[column].apply(avg_sentence_length)  # 各列に平均文長を追加\n",
    "    \n",
    "test.head()  # テストデータの最初の5行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:50.207123Z",
     "iopub.status.busy": "2024-07-07T10:42:50.20663Z",
     "iopub.status.idle": "2024-07-07T10:42:50.220057Z",
     "shell.execute_reply": "2024-07-07T10:42:50.218288Z",
     "shell.execute_reply.started": "2024-07-07T10:42:50.207087Z"
    }
   },
   "outputs": [],
   "source": [
    "test_features = test[features]  # テストデータの特徴量を取得\n",
    "test_predictions = model_to_use.predict_proba(test_features)  # テストデータに対する予測確率を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:52.48017Z",
     "iopub.status.busy": "2024-07-07T10:42:52.479148Z",
     "iopub.status.idle": "2024-07-07T10:42:52.488907Z",
     "shell.execute_reply": "2024-07-07T10:42:52.487241Z",
     "shell.execute_reply.started": "2024-07-07T10:42:52.480126Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions  # テストデータに対する予測確率を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:53.791742Z",
     "iopub.status.busy": "2024-07-07T10:42:53.791246Z",
     "iopub.status.idle": "2024-07-07T10:42:53.800145Z",
     "shell.execute_reply": "2024-07-07T10:42:53.798649Z",
     "shell.execute_reply.started": "2024-07-07T10:42:53.791699Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出ファイルを準備する\n",
    "submission = pd.DataFrame({  # データフレームを生成\n",
    "    'id': test['id'],  # テストデータのIDを含める\n",
    "    'winner_model_a': test_predictions[:, 0],  # モデルAの勝者確率\n",
    "    'winner_model_b': test_predictions[:, 1],  # モデルBの勝者確率\n",
    "    'winner_tie': test_predictions[:, 2]  # 引き分けの確率\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:55.43495Z",
     "iopub.status.busy": "2024-07-07T10:42:55.434499Z",
     "iopub.status.idle": "2024-07-07T10:42:55.44877Z",
     "shell.execute_reply": "2024-07-07T10:42:55.447018Z",
     "shell.execute_reply.started": "2024-07-07T10:42:55.434893Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.head()  # 提出ファイルの最初の5行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-07T10:42:57.389724Z",
     "iopub.status.busy": "2024-07-07T10:42:57.389244Z",
     "iopub.status.idle": "2024-07-07T10:42:57.397559Z",
     "shell.execute_reply": "2024-07-07T10:42:57.396252Z",
     "shell.execute_reply.started": "2024-07-07T10:42:57.389692Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出ファイルをCSV形式で保存"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 1325242,
     "sourceId": 2206666,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
