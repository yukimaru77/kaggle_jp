{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d95424",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena」競技において、ユーザーの好みを予測するために設計されています。具体的には、与えられた2つの応答（モデルAとモデルB）から、ユーザーがどちらの応答を好むかを予測するための機械学習モデルを構築します。この競技の目標は、応答の好みを正確に予測するための「報酬モデル」を作成することです。\n",
    "\n",
    "### 問題の概要\n",
    "Notebookでは、チャットボットからの異なる応答（レスポンスAとレスポンスB）が与えられ、それらがユーザーによってどのように評価されるかを予測するためのモデルを構築しています。データは、プロンプトとそれに対する2つの応答、およびそれに関連するラベルから構成されています。\n",
    "\n",
    "### 使用されている手法とライブラリ\n",
    "このノートブックでは、以下の手法とライブラリが使用されています：\n",
    "\n",
    "- **ライブラリ**:\n",
    "  - `Keras`とその関連ライブラリ`keras_nlp`: 深層学習モデルの構築に使用。\n",
    "  - `TensorFlow`: モデルのトレーニングと推論に使用。\n",
    "  - `pandas`: データの読み込みと処理に使用。\n",
    "  - `scikit-learn`: データの分割に使用。\n",
    "  - `tqdm`: プロセス中の進捗バー表示に使用。\n",
    "  - `transformers`: 事前訓練された言語モデルを利用するために使用（このコードでは特にDeBERTa V3が利用されています）。\n",
    "\n",
    "- **手法**:\n",
    "  - **データ処理**: JSONデータを読み込んでプロンプトと応答を結合し、クラスラベルにマッピングします。\n",
    "  - **データセットの構築**: TensorFlowのデータセットを使用して効率的にバッチ処理を行います。\n",
    "  - **モデルのアーキテクチャ**: DeBERTa V3をバックボーンとして使用し、応答AとBの埋め込みを結合して最終的な予測を行います。\n",
    "  - **モデルのトレーニング**: 渡されたデータセットを使用し、ロスが最小のモデルを選択するよう設定されています。\n",
    "\n",
    "### 結果の出力\n",
    "トレーニングが完了したら、最良のモデルの重みが読み込まれ、テストデータに対する予測が行われます。予測結果はCSVファイルとして保存され、最終的にKaggleへ提出する形式に整理されています。\n",
    "\n",
    "このNotebookは、効果的なデータ処理とモデルの構築を通じて、ユーザーの応答選好を予測するための実践的なアプローチを示しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fe575",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、提供されたJupyter Notebookに見られる専門用語の解説リストです。初心者がつまずきやすいマイナーな用語や、特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "1. **Keras**: Pythonの高水準なニューラルネットワークAPIで、TensorFlowの上に構築されています。簡潔かつ使いやすく、深層学習モデルを迅速に構築、トレーニング、評価するために使用されます。\n",
    "\n",
    "2. **KerasNLP**: Keras用の自然言語処理ライブラリで、最新のNLPモデルやトークナイザー、データセットの処理を簡略化します。特にTransformerアーキテクチャに特化した機能が含まれています。\n",
    "\n",
    "3. **bfloat16**: 「brain floating point format」と呼ばれる数値データ型で、主に深層学習で使用されます。精度を犠牲にすることなく、計算のメモリ使用量を削減する利点があります。\n",
    "\n",
    "4. **層化サンプリング (Stratified Sampling)**: データセットを分割するときに、各クラスの比率を維持する方法です。クラスの不均衡を防ぎ、モデルの性能を向上させるために重要です。\n",
    "\n",
    "5. **LoRA (Low-Rank Adaptation)**: 既存のモデルのパラメータを低次元のサブスペースで最適化する手法で、特にメモリ効率を高めつつファインチューニングを行う際に用いられます。\n",
    "\n",
    "6. **パディング (Padding)**: データのシーケンス長を揃えるために、短いシーケンスの末尾にゼロまたは特定の値を加える操作です。自然言語処理モデルでは、バッチ内の全てのシーケンスを同じ長さに保つためによく使用されます。\n",
    "\n",
    "7. **オプティマイザー (Optimizer)**: モデルが学習する際、損失関数を最小化するために使用するアルゴリズムのこと。AdamやSGDなどのさまざまなオプティマイザーが存在します。\n",
    "\n",
    "8. **トークン化 (Tokenization)**: テキストを処理可能な単位（トークン）に分割する工程です。これは、自然言語モデルがテキストを理解しやすくするために必要です。\n",
    "\n",
    "9. **カテゴリカルクロスエントロピー (Categorical Crossentropy)**: 多クラス分類問題において、モデルの予測した確率と実際のクラスラベルとの間の損失を計算する指標です。\n",
    "\n",
    "10. **グローバル平均プーリング (Global Average Pooling)**: 特徴マップの各チャネルの平均値を計算する操作で、モデルの出力を低次元のベクトルに変換します。この方法は、過学習を防ぐのに役立ちます。\n",
    "\n",
    "これらの用語は、特に初学者が機械学習や深層学習を学ぶ過程で出会う状況が多いので、理解しておくと良いでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:28.616074Z",
     "iopub.status.busy": "2024-07-15T04:33:28.615382Z",
     "iopub.status.idle": "2024-07-15T04:33:29.847844Z",
     "shell.execute_reply": "2024-07-15T04:33:29.846816Z",
     "shell.execute_reply.started": "2024-07-15T04:33:28.616035Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これはkaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、以下はいくつかの便利なパッケージの読み込み例です\n",
    "\n",
    "import numpy as np # 線形代数用のライブラリ\n",
    "import pandas as pd # データ処理用のライブラリ、CSVファイルの入出力（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは、読み取り専用の\"../input/\"ディレクトリで利用可能です\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするか、Shift+Enterを押すことで）入力ディレクトリ内のすべてのファイルをリストします\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    # 指定されたディレクトリ（dirname）内のファイルをすべて走査します\n",
    "    for filename in filenames:\n",
    "        # 各ファイルのフルパスを出力します\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 現在のディレクトリ（/kaggle/working/）には最大20GBを書き込むことができ、\n",
    "# 「すべてを保存して実行」したときに出力として保持されます\n",
    "# また、/kaggle/temp/に一時ファイルを書き込むこともできますが、現在のセッション外では保存されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:29.850453Z",
     "iopub.status.busy": "2024-07-15T04:33:29.849913Z",
     "iopub.status.idle": "2024-07-15T04:33:50.941943Z",
     "shell.execute_reply": "2024-07-15T04:33:50.941098Z",
     "shell.execute_reply.started": "2024-07-15T04:33:29.850415Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Kerasのバックエンドを設定します。\"tensorflow\"または\"torch\"のいずれかを指定できます\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # ここではtensorflowを選択\n",
    "\n",
    "import keras_nlp  # Kerasの自然言語処理用ライブラリをインポート\n",
    "import keras  # Kerasライブラリをインポート\n",
    "import tensorflow as tf  # TensorFlowライブラリをインポート\n",
    "\n",
    "import numpy as np  # 数値計算用のライブラリをインポート\n",
    "import pandas as pd  # データ処理用のライブラリをインポート\n",
    "from tqdm import tqdm  # 進捗バーを表示するライブラリをインポート\n",
    "import json  # JSONデータを扱うためのライブラリをインポート\n",
    "\n",
    "import matplotlib.pyplot as plt  # グラフ描画用ライブラリをインポート\n",
    "import matplotlib as mpl  # Matplotlibの設定を行うためのライブラリをインポート\n",
    "import transformers  # Transformersライブラリをインポート（自然言語処理モデル用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:50.944321Z",
     "iopub.status.busy": "2024-07-15T04:33:50.943011Z",
     "iopub.status.idle": "2024-07-15T04:33:50.950353Z",
     "shell.execute_reply": "2024-07-15T04:33:50.949374Z",
     "shell.execute_reply.started": "2024-07-15T04:33:50.944263Z"
    }
   },
   "outputs": [],
   "source": [
    "# TensorFlow、Keras、KerasNLPのバージョンを表示します\n",
    "print(\"TensorFlow:\", tf.__version__)  # TensorFlowのバージョンを出力\n",
    "print(\"Keras:\", keras.__version__)  # Kerasのバージョンを出力\n",
    "print(\"KerasNLP:\", keras_nlp.__version__)  # KerasNLPのバージョンを出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:50.952805Z",
     "iopub.status.busy": "2024-07-15T04:33:50.952485Z",
     "iopub.status.idle": "2024-07-15T04:33:50.961227Z",
     "shell.execute_reply": "2024-07-15T04:33:50.96044Z",
     "shell.execute_reply.started": "2024-07-15T04:33:50.95278Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルの設定を保持するためのクラスを定義します\n",
    "class CFG:\n",
    "    seed = 50  # 乱数シードを指定します（再現性を保つため）\n",
    "    sequence_length = 1024  # 入力シーケンスの長さを指定します\n",
    "    epochs = 2  # 学習のエポック数を指定します\n",
    "    batch_size = 2  # バッチサイズを指定します\n",
    "    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}  \n",
    "    # ラベルをモデル名にマッピングする辞書を定義します\n",
    "    name2label = {v:k for k, v in label2name.items()}  \n",
    "    # モデル名をラベルにマッピングする辞書を生成します\n",
    "    class_labels = list(label2name.keys())  # クラスラベルのリストを生成します\n",
    "    class_names = list(label2name.values())  # クラス名のリストを生成します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:50.962452Z",
     "iopub.status.busy": "2024-07-15T04:33:50.962139Z",
     "iopub.status.idle": "2024-07-15T04:33:50.97211Z",
     "shell.execute_reply": "2024-07-15T04:33:50.971242Z",
     "shell.execute_reply.started": "2024-07-15T04:33:50.962427Z"
    }
   },
   "outputs": [],
   "source": [
    "# 乱数シードを設定して、再現性のある結果を得るための準備をします\n",
    "keras.utils.set_random_seed(CFG.seed)  # Kerasの乱数シードを設定します\n",
    "\n",
    "# 計算精度のポリシーを設定します。ここではbfloat16を使用します\n",
    "keras.mixed_precision.set_global_policy(\"bfloat16\")\n",
    "\n",
    "# データセットのベースパスを定義します\n",
    "BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'  # データセットが格納されているパスを設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:50.973722Z",
     "iopub.status.busy": "2024-07-15T04:33:50.973365Z",
     "iopub.status.idle": "2024-07-15T04:33:50.981477Z",
     "shell.execute_reply": "2024-07-15T04:33:50.980579Z",
     "shell.execute_reply.started": "2024-07-15T04:33:50.97369Z"
    }
   },
   "outputs": [],
   "source": [
    "# JSON形式のデータを読み込み、リストからNoneではない要素を結合して返す関数を定義します\n",
    "def load_data(row):\n",
    "    # 行データをJSONとして読み込みます\n",
    "    row_list = json.loads(row)\n",
    "    # Noneでない要素をスペースで結合して返します\n",
    "    return \" \".join(row for row in row_list if row != None)  # Noneでない要素を結合して1つの文字列にします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:50.982942Z",
     "iopub.status.busy": "2024-07-15T04:33:50.982589Z",
     "iopub.status.idle": "2024-07-15T04:33:54.316765Z",
     "shell.execute_reply": "2024-07-15T04:33:54.315722Z",
     "shell.execute_reply.started": "2024-07-15T04:33:50.982907Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データを読み込みます\n",
    "df = pd.read_csv(f'{BASE_PATH}/train.csv')  # CSVファイルを読み込み、データフレームを作成します\n",
    "# df = df.iloc[:100] # デモ用にデータのサブセットを使用する場合はこちらを有効にします\n",
    "\n",
    "# 最初のプロンプトとそれに関連するレスポンスを取得します\n",
    "df[\"prompt\"] = df[\"prompt\"].apply(load_data)  # プロンプト列にload_data関数を適用\n",
    "df[\"response_a\"] = df[\"response_a\"].apply(load_data)  # レスポンスA列にload_data関数を適用\n",
    "df[\"response_b\"] = df[\"response_b\"].apply(load_data)  # レスポンスB列にload_data関数を適用\n",
    "\n",
    "# ラベルの変換を行います\n",
    "df[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)  \n",
    "# 各行の勝者モデルを判定し、対応するクラス名を取得\n",
    "df[\"class_label\"] = df.class_name.map(CFG.name2label)  # クラス名をクラスラベルにマッピング\n",
    "\n",
    "# サンプルを表示します\n",
    "df.head()  # データフレームの最初の数行を表示して確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:54.31834Z",
     "iopub.status.busy": "2024-07-15T04:33:54.31803Z",
     "iopub.status.idle": "2024-07-15T04:33:54.33623Z",
     "shell.execute_reply": "2024-07-15T04:33:54.335358Z",
     "shell.execute_reply.started": "2024-07-15T04:33:54.318288Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータを読み込みます\n",
    "test_df = pd.read_csv(f'{BASE_PATH}/test.csv')  # テスト用のCSVファイルを読み込み、データフレームを作成します\n",
    "\n",
    "# 最初のプロンプトとレスポンスを取得します\n",
    "test_df[\"prompt\"] = test_df[\"prompt\"].apply(load_data)  # プロンプト列にload_data関数を適用\n",
    "test_df[\"response_a\"] = test_df[\"response_a\"].apply(load_data)  # レスポンスA列にload_data関数を適用\n",
    "test_df[\"response_b\"] = test_df[\"response_b\"].apply(load_data)  # レスポンスB列にload_data関数を適用\n",
    "\n",
    "# サンプルを表示します\n",
    "test_df.head()  # テストデータフレームの最初の数行を表示して確認します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:54.337633Z",
     "iopub.status.busy": "2024-07-15T04:33:54.337364Z",
     "iopub.status.idle": "2024-07-15T04:33:54.365852Z",
     "shell.execute_reply": "2024-07-15T04:33:54.364967Z",
     "shell.execute_reply.started": "2024-07-15T04:33:54.33761Z"
    }
   },
   "outputs": [],
   "source": [
    "# オプション列を作成します。レスポンスAとレスポンスBをリストに格納します\n",
    "df['options'] = df.apply(lambda row: [row.response_a, row.response_b], axis=1)\n",
    "display(df.head(2))  # データフレームdfの最初の2行を表示します\n",
    "\n",
    "# テストデータにも同様にオプション列を作成します\n",
    "test_df['options'] = test_df.apply(lambda row: [row.response_a, row.response_b], axis=1)\n",
    "display(test_df.head(2))  # テストデータフレームtest_dfの最初の2行を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:54.369785Z",
     "iopub.status.busy": "2024-07-15T04:33:54.3695Z",
     "iopub.status.idle": "2024-07-15T04:33:55.292749Z",
     "shell.execute_reply": "2024-07-15T04:33:55.291852Z",
     "shell.execute_reply.started": "2024-07-15T04:33:54.36976Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  # パッケージをインポートします（データ分割用）\n",
    "\n",
    "# データを訓練セットと検証セットに分割します\n",
    "train_df, valid_df = train_test_split(df, test_size=0.1, stratify=df[\"class_label\"])  \n",
    "# 10%を検証セットとして分割し、クラスラベルに基づいて層化サンプリングを行います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:33:55.294372Z",
     "iopub.status.busy": "2024-07-15T04:33:55.294018Z",
     "iopub.status.idle": "2024-07-15T04:34:00.287267Z",
     "shell.execute_reply": "2024-07-15T04:34:00.286389Z",
     "shell.execute_reply.started": "2024-07-15T04:33:55.294341Z"
    }
   },
   "outputs": [],
   "source": [
    "# DeBERTa V3の前処理器を設定します\n",
    "preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n",
    "    \"deberta_v3_small_en\",  # 使用するモデルのプリセット名を指定します\n",
    "    sequence_length=CFG.sequence_length,  # 最大シーケンス長を設定します。短い場合はパディングされます\n",
    "    dtype=\"bfloat16\",  # データ型をbfloat16に設定します\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:34:00.288775Z",
     "iopub.status.busy": "2024-07-15T04:34:00.288486Z",
     "iopub.status.idle": "2024-07-15T04:34:00.391456Z",
     "shell.execute_reply": "2024-07-15T04:34:00.390552Z",
     "shell.execute_reply.started": "2024-07-15T04:34:00.288749Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最初の行のオプションを前処理します\n",
    "outs = preprocessor(df.options.iloc[0])  # 最初の行のレスポンスオプションを処理\n",
    "\n",
    "# 各処理された出力の形状を表示します\n",
    "for k, v in outs.items():\n",
    "    print(k, \":\", v.shape)  # キーと対応する出力の形状を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:34:00.39283Z",
     "iopub.status.busy": "2024-07-15T04:34:00.39256Z",
     "iopub.status.idle": "2024-07-15T04:34:00.397604Z",
     "shell.execute_reply": "2024-07-15T04:34:00.396598Z",
     "shell.execute_reply.started": "2024-07-15T04:34:00.392806Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストとラベルを前処理する関数を定義します\n",
    "def preprocess_fn(text, label=None):\n",
    "    text = preprocessor(text)  # テキストを前処理します\n",
    "    # ラベルが存在する場合は、処理されたテキストとラベルを返します\n",
    "    return (text, label) if label is not None else text  # ラベルがなければ処理されたテキストのみを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:34:00.398974Z",
     "iopub.status.busy": "2024-07-15T04:34:00.398706Z",
     "iopub.status.idle": "2024-07-15T04:34:00.407893Z",
     "shell.execute_reply": "2024-07-15T04:34:00.406919Z",
     "shell.execute_reply.started": "2024-07-15T04:34:00.398945Z"
    }
   },
   "outputs": [],
   "source": [
    "# テキストとラベルからデータセットを構築する関数を定義します\n",
    "def build_dataset(texts, labels=None, batch_size=32,\n",
    "                  cache=True, shuffle=1024):\n",
    "    AUTO = tf.data.AUTOTUNE  # AUTOTUNEオプションを設定\n",
    "    # ラベルがない場合はテキストのみのスライスを作成し、ある場合はラベルをワンホットエンコーディングします\n",
    "    slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  \n",
    "    ds = tf.data.Dataset.from_tensor_slices(slices)  # スライスからデータセットを作成します\n",
    "    ds = ds.cache() if cache else ds  # キャッシュを有効にする場合はデータセットをキャッシュ\n",
    "    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)  # 前処理関数をマッピングします\n",
    "    opt = tf.data.Options()  # データセットオプションを作成します\n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(shuffle, seed=CFG.seed)  # シャッフルが有効な場合、データセットをシャッフルします\n",
    "        opt.experimental_deterministic = False  # 確定的でないオプションを設定\n",
    "    ds = ds.with_options(opt)  # データセットオプションを設定します\n",
    "    ds = ds.batch(batch_size, drop_remainder=False)  # バッチサイズでデータセットをバッチ化します\n",
    "    ds = ds.prefetch(AUTO)  # 次のバッチを事前取得します\n",
    "    return ds  # 構築したデータセットを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:34:00.409384Z",
     "iopub.status.busy": "2024-07-15T04:34:00.409076Z",
     "iopub.status.idle": "2024-07-15T04:34:00.420913Z",
     "shell.execute_reply": "2024-07-15T04:34:00.42001Z",
     "shell.execute_reply.started": "2024-07-15T04:34:00.409359Z"
    }
   },
   "outputs": [],
   "source": [
    "# JAXライブラリをインポートします（コメントアウトされています）\n",
    "# import jax\n",
    "# GPUデバイスを取得します\n",
    "# devices = jax.devices(\"gpu\")\n",
    "# デバイスを表示します\n",
    "# print(\"devices\", devices)\n",
    "\n",
    "# Kerasのデータ並列処理を設定するためのオブジェクトを作成します（コメントアウトされています）\n",
    "# data_parallel = keras.distribution.DataParallel(devices=devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:35:59.007385Z",
     "iopub.status.busy": "2024-07-15T04:35:59.006555Z",
     "iopub.status.idle": "2024-07-15T04:35:59.015568Z",
     "shell.execute_reply": "2024-07-15T04:35:59.014284Z",
     "shell.execute_reply.started": "2024-07-15T04:35:59.007332Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットを取得する関数を定義します\n",
    "def get_data():\n",
    "    train_texts = train_df.options.tolist()  # 訓練用のテキストを抽出します\n",
    "    train_labels = train_df.class_label.tolist()  # 訓練用のラベルを抽出します\n",
    "    train_ds = build_dataset(train_texts, train_labels,\n",
    "                             batch_size=CFG.batch_size,  # バッチサイズを設定\n",
    "                             shuffle=True)  # 訓練データはシャッフルします\n",
    "\n",
    "    # 検証データ\n",
    "    valid_texts = valid_df.options.tolist()  # 検証用のテキストを抽出します\n",
    "    valid_labels = valid_df.class_label.tolist()  # 検証用のラベルを抽出します\n",
    "    valid_ds = build_dataset(valid_texts, valid_labels,\n",
    "                             batch_size=CFG.batch_size,  # バッチサイズを設定\n",
    "                             shuffle=False)  # 検証データはシャッフルしません\n",
    "\n",
    "    # テストデータセットを構築します\n",
    "    test_texts = test_df.options.tolist()  # テスト用のテキストを抽出します\n",
    "    test_ds = build_dataset(test_texts,\n",
    "                             batch_size=min(len(test_df), CFG.batch_size),  # テストデータのサイズに応じてバッチサイズを設定\n",
    "                             shuffle=False)  # テストデータはシャッフルしません\n",
    "    return train_ds, valid_ds, test_ds  # 訓練、検証、テストデータセットを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:34:03.714026Z",
     "iopub.status.busy": "2024-07-15T04:34:03.713741Z",
     "iopub.status.idle": "2024-07-15T04:34:03.718524Z",
     "shell.execute_reply": "2024-07-15T04:34:03.717469Z",
     "shell.execute_reply.started": "2024-07-15T04:34:03.714001Z"
    }
   },
   "outputs": [],
   "source": [
    "# Kerasのデータ並列処理を設定します（コメントアウトされています）\n",
    "# keras.distribution.set_distribution(data_parallel)  # モデルを両方のGPUで複製します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:40:33.113841Z",
     "iopub.status.busy": "2024-07-15T04:40:33.112801Z",
     "iopub.status.idle": "2024-07-15T04:40:33.118808Z",
     "shell.execute_reply": "2024-07-15T04:40:33.11785Z",
     "shell.execute_reply.started": "2024-07-15T04:40:33.113802Z"
    }
   },
   "outputs": [],
   "source": [
    "# バックボーンモデルを取得する関数を定義します\n",
    "def get_backbone():\n",
    "    # DeBERTa V3のバックボーンモデルをプリセットから取得します\n",
    "    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n",
    "        \"deberta_v3_small_en\",  # 使用するモデルのプリセット名を指定します\n",
    "        dtype=\"bfloat16\",  # データ型をbfloat16に設定します\n",
    "    )\n",
    "    backbone.enable_lora(8)  # LoRA（Low-Rank Adaptation）の有効化と設定を行います\n",
    "    \n",
    "    return backbone  # バックボーンモデルを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:40:33.655294Z",
     "iopub.status.busy": "2024-07-15T04:40:33.654404Z",
     "iopub.status.idle": "2024-07-15T04:40:33.661017Z",
     "shell.execute_reply": "2024-07-15T04:40:33.659828Z",
     "shell.execute_reply.started": "2024-07-15T04:40:33.655259Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのチェックポイントを設定するコールバックを定義します\n",
    "ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',  # モデルの重みを保存するファイル名\n",
    "                                  monitor='val_log_loss',  # 検証ロスを監視\n",
    "                                  save_best_only=True,  # 最良のモデルのみを保存\n",
    "                                  save_weights_only=True,  # 重みのみを保存\n",
    "                                  mode='min')  # 最小化を目指す設定（ロスが最小の時に保存）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:40:33.885671Z",
     "iopub.status.busy": "2024-07-15T04:40:33.885037Z",
     "iopub.status.idle": "2024-07-15T04:40:33.892667Z",
     "shell.execute_reply": "2024-07-15T04:40:33.891764Z",
     "shell.execute_reply.started": "2024-07-15T04:40:33.885641Z"
    }
   },
   "outputs": [],
   "source": [
    "# カテゴリカルクロスエントロピーのメトリクスを定義します\n",
    "log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\")  # ロスの名前を\"log_loss\"と設定します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:40:34.556628Z",
     "iopub.status.busy": "2024-07-15T04:40:34.556196Z",
     "iopub.status.idle": "2024-07-15T04:40:34.56666Z",
     "shell.execute_reply": "2024-07-15T04:40:34.565633Z",
     "shell.execute_reply.started": "2024-07-15T04:40:34.556597Z"
    }
   },
   "outputs": [],
   "source": [
    "# バックボーンを使用してモデルを構築する関数を定義します\n",
    "def get_model(backbone):\n",
    "    # 入力層を定義します\n",
    "    inputs = {\n",
    "        \"token_ids\": keras.Input(shape=(2, None), dtype=tf.int16, name=\"token_ids\"),  # トークンID入力\n",
    "        \"padding_mask\": keras.Input(shape=(2, None), dtype=tf.int16, name=\"padding_mask\"),  # パディングマスクリスト\n",
    "    }\n",
    "\n",
    "    # 最初のレスポンス（Response A）に対する埋め込みを計算します: (P + R_A)\n",
    "    response_a = {k: v[:, 0, :] for k, v in inputs.items()}  # 入力からAのレスポンスを抽出\n",
    "    embed_a = backbone(response_a)  # バックボーンを通して埋め込みを計算\n",
    "\n",
    "    # 2番目のレスポンス（Response B）に対する埋め込みを計算します: (P + R_B)\n",
    "    response_b = {k: v[:, 1, :] for k, v in inputs.items()}  # 入力からBのレスポンスを抽出\n",
    "    embed_b = backbone(response_b)  # 同じバックボーンを使用して埋め込みを計算\n",
    "\n",
    "    # 最終出力を計算します\n",
    "    embeds = keras.layers.Concatenate(axis=-1)([embed_a, embed_b])  # AとBの埋め込みを結合\n",
    "    embeds = keras.layers.GlobalAveragePooling1D()(embeds)  # グローバル平均プーリングを適用\n",
    "    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(embeds)  # 出力層を定義（3クラス分類）\n",
    "\n",
    "    # モデルを定義\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    # 最適化アルゴリズム、損失、メトリクスを指定してモデルをコンパイル\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(5e-6),  # Adamオプティマイザを使用\n",
    "        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.02),  # カテゴリカルクロスエントロピーを損失関数とする\n",
    "        metrics=[\n",
    "            log_loss,  # ロスメトリクス\n",
    "            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),  # カテゴリカル精度メトリクス\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    return model  # 構築したモデルを返します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:40:39.204136Z",
     "iopub.status.busy": "2024-07-15T04:40:39.203206Z",
     "iopub.status.idle": "2024-07-15T04:43:54.598272Z",
     "shell.execute_reply": "2024-07-15T04:43:54.597491Z",
     "shell.execute_reply.started": "2024-07-15T04:40:39.204101Z"
    }
   },
   "outputs": [],
   "source": [
    "# 分散処理のための戦略を設定します\n",
    "strategy = tf.distribute.MirroredStrategy()  # 複数のGPUでの計算を有効にします\n",
    "\n",
    "# 戦略スコープをオープンします\n",
    "with strategy.scope():\n",
    "    \n",
    "    train_ds, valid_ds, test_ds = get_data()  # データセットを取得します\n",
    "    \n",
    "    backbone = get_backbone()  # バックボーンモデルを取得します\n",
    "    \n",
    "    model = get_model(backbone)  # モデルを構築します\n",
    "    \n",
    "    # モデルを訓練します\n",
    "    history = model.fit(\n",
    "        train_ds,  # 訓練データ\n",
    "        epochs=CFG.epochs,  # 訓練のエポック数\n",
    "        validation_data=valid_ds,  # 検証データ\n",
    "        callbacks=[ckpt_cb]  # モデルチェックポイントコールバック\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:44:19.74979Z",
     "iopub.status.busy": "2024-07-15T04:44:19.749398Z",
     "iopub.status.idle": "2024-07-15T04:44:20.931734Z",
     "shell.execute_reply": "2024-07-15T04:44:20.930648Z",
     "shell.execute_reply.started": "2024-07-15T04:44:19.749759Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最良のモデルの重みを読み込みます\n",
    "model.load_weights('/kaggle/working/best_model.weights.h5')  # 保存したモデルの重みを指定したパスから読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:44:20.93432Z",
     "iopub.status.busy": "2024-07-15T04:44:20.933966Z",
     "iopub.status.idle": "2024-07-15T04:44:21.983389Z",
     "shell.execute_reply": "2024-07-15T04:44:21.982491Z",
     "shell.execute_reply.started": "2024-07-15T04:44:20.934267Z"
    }
   },
   "outputs": [],
   "source": [
    "# 訓練済みモデルを使用してテストデータに対する予測を行います\n",
    "test_preds = model.predict(test_ds, verbose=1)  # テストデータに対する予測を実行し、進捗を表示します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-15T04:44:21.989642Z",
     "iopub.status.busy": "2024-07-15T04:44:21.989047Z",
     "iopub.status.idle": "2024-07-15T04:44:22.006697Z",
     "shell.execute_reply": "2024-07-15T04:44:22.005627Z",
     "shell.execute_reply.started": "2024-07-15T04:44:21.989614Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用のデータフレームを作成します\n",
    "sub_df = test_df[[\"id\"]].copy()  # テストデータからID列をコピーします\n",
    "sub_df[CFG.class_names] = test_preds.tolist()  # 予測結果をデータフレームに追加します\n",
    "sub_df.to_csv(\"submission.csv\", index=False)  # 提出用のCSVファイルとして保存します\n",
    "sub_df.head()  # 作成したデータフレームの最初の数行を表示して確認します"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078a0f00",
   "metadata": {},
   "source": [
    "# 📌 | 参考文献\n",
    "\n",
    "* [LLM Science Exam: KerasCore + KerasNLP [TPU]](https://www.kaggle.com/code/awsaf49/llm-science-exam-kerascore-kerasnlp-tpu)\n",
    "* [AES 2.0: KerasNLPスターター](https://www.kaggle.com/code/awsaf49/aes-2-0-kerasnlp-starter)\n",
    "* [LMSYS: KerasNLPスターター](https://www.kaggle.com/code/awsaf49/lmsys-kerasnlp-starter)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4684,
     "sourceId": 6063,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4685,
     "sourceId": 6064,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4686,
     "sourceId": 6065,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 2820,
     "modelInstanceId": 4687,
     "sourceId": 6066,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3533,
     "modelInstanceId": 5171,
     "sourceId": 11371,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3301,
     "modelInstanceId": 6216,
     "sourceId": 11384,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 3301,
     "modelInstanceId": 6206,
     "sourceId": 11413,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
