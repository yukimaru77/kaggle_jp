{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46aca399",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Chatbot Arenaコンペティションにおいて、チャットボットの応答の好みを予測するモデルを構築するためのものです。具体的には、与えられたプロンプトに対して2つの異なる応答のうちどちらが好まれるかを予測するタスクに取り組んでいます。\n",
    "\n",
    "### 問題の概要\n",
    "コンペティションのゴールは、ユーザーが好むチャットボットの応答を予測することであり、そのためにさまざまな大規模言語モデル（LLM）を使用して、選好のスコアを生成することが必要です。\n",
    "\n",
    "### 使用した手法とライブラリ\n",
    "1. **ライブラリのインストールとインポート**:\n",
    "   - `pandas`: データ操作に使用。\n",
    "   - `catboost`: 最終的なモデルの学習にはCatBoostClassifierを利用。\n",
    "   - `transformers`: Hugging Faceライブラリからのモデルとトークナイザをインポート。\n",
    "   - `nltk`: 自然言語処理に必要なストップワードの処理。\n",
    "   - `tqdm`: プログレスバーの表示。\n",
    "   - `torch`: Pytorchを使用してモデルを扱います。\n",
    "\n",
    "2. **データ処理**:\n",
    "   - 入力データの読み込みと前処理を行い、プロンプトや応答をJSON形式から辞書型に変換。\n",
    "   - ストップワードリストを読み込み、不要な単語の削除を行うための準備。\n",
    "\n",
    "3. **モデルの構築**:\n",
    "   - Hugging FaceのPre-trainedモデル（RoBERTa, DeBERTa, DistilBERTなど）を用いて質問応答のパイプラインを構築。\n",
    "   - それぞれのモデルに対して、データセットに基づいたスコアを計算。\n",
    "\n",
    "4. **モデルの学習**:\n",
    "   - 生成された特徴量とターゲット（勝者モデル）を使用して、CatBoostClassifierでモデルを訓練。\n",
    "\n",
    "5. **予測と提出ファイルの作成**:\n",
    "   - テストデータに対し、モデルからの予測確率を算出し、サンプル提出ファイルに追加。\n",
    "   - 最終的にCSVファイルとして提出用のファイルを保存。\n",
    "\n",
    "### 結果の出力\n",
    "最終的には、予測結果を含むCSVファイルが生成されます。このノートブックはデータ処理、モデルの選定、訓練、評価、結果のフォーマットまでの一連の流れを示しており、コンペティションにおける優れたモデル構築のための実践的な手法を提供しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a4e34",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、機械学習・深層学習の初心者がつまずきそうな専門用語を解説します。ノートブックの内容に特有のものや、実務経験がないと馴染みのない用語に焦点を当てました。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **ロジスティック回帰 (Logistic Regression)**:\n",
    "   - 二項分類問題を解決するための確率モデルで、出力は0と1の間の値を取るシグモイド関数を使います。カテゴリカルデータやバイナリデータの予測に広く使用されます。\n",
    "\n",
    "2. **CatBoostClassifier**:\n",
    "   - カテゴリカルデータに特化した勾配ブースティングライブラリの一つです。他のブースティングアルゴリズムに比べて、前処理なしで直接カテゴリカルデータを扱えるのが特徴です。\n",
    "\n",
    "3. **StratifiedKFold**:\n",
    "   - クロスバリデーションの手法で、各フォールドにおけるクラスラベルの比率を元のデータと同じに保つことにより、データのバランスを取ります。クラス分布を均等に保ってモデルの評価を行うことができます。\n",
    "\n",
    "4. **log_loss**:\n",
    "   - モデルの予測確率と実際のラベルとの不一致を測るための指標で、対数損失関数とも呼ばれます。この値が小さいほど、モデルの予測が実際のラベルに近いことを示します。\n",
    "\n",
    "5. **トークナイザー (Tokenizer)**:\n",
    "   - テキストを単語やサブワードに分割するためのツールです。モデルが理解できる形式に変換するために必要で、特にNLPでは不可欠な処理です。\n",
    "\n",
    "6. **パイプライン (Pipeline)**:\n",
    "   - 一連のデータ処理やモデルのステップをまとめた手順で、トークン化、エンコーディング、予測の各段階を効率的に実行できるようにします。\n",
    "\n",
    "7. **doc_stride**:\n",
    "   - 質問応答タスクにおいて、コンテキストが長すぎる場合に、スライドさせて分割する幅を指します。これにより、モデルはより長いテキストを処理できるようになります。\n",
    "\n",
    "8. **json.loads()**:\n",
    "   - JSON（JavaScript Object Notation）形式の文字列をPythonの辞書型に変換する関数です。データの入出力やAPIとのやり取りでよく使用されます。\n",
    "\n",
    "9. **エンコード (Encoding)**:\n",
    "   - テキストデータを特定のフォーマットに変換する処理のこと。特に、文字コードの問題を解消するための修正が行われることがあります。\n",
    "\n",
    "10. **データセット (Dataset)**:\n",
    "    - 機械学習モデルに供給される訓練データや評価データのコレクションです。通常は特徴量とターゲットの情報を含みます。\n",
    "\n",
    "11. **optuna**:\n",
    "    - ハイパーパラメータの最適化を行うための自動化ライブラリです。機械学習モデルのパフォーマンスを向上させるための最適な設定を探索するために使用されます。\n",
    "\n",
    "12. **データフレーム (DataFrame)**:\n",
    "    - Pandasライブラリで提供される、構造化データを表形式で扱うためのデータ構造です。行と列に分かれており、データ操作や分析に便利です。\n",
    "\n",
    "これらの用語を理解することで、ノートブックのコードや処理の流れがより明確になるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af52c6c0",
   "metadata": {},
   "source": [
    "# ライブラリ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:32.041364Z",
     "iopub.status.busy": "2024-07-21T14:04:32.040604Z",
     "iopub.status.idle": "2024-07-21T14:04:44.568689Z",
     "shell.execute_reply": "2024-07-21T14:04:44.567523Z",
     "shell.execute_reply.started": "2024-07-21T14:04:32.041328Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/ftfy-dependeces/ftfy-6.2.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:44.571646Z",
     "iopub.status.busy": "2024-07-21T14:04:44.571219Z",
     "iopub.status.idle": "2024-07-21T14:04:52.397912Z",
     "shell.execute_reply": "2024-07-21T14:04:52.397059Z",
     "shell.execute_reply.started": "2024-07-21T14:04:44.571605Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ロジスティック回帰モデルをインポートするためのコードがコメントアウトされています\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline\n",
    "from ftfy import fix_encoding\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# NLTKのストップワードをダウンロードするためのコードがコメントアウトされています\n",
    "# nltk.download('stopwords')\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import json\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()  # プログレスバーの表示を可能にします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:52.399511Z",
     "iopub.status.busy": "2024-07-21T14:04:52.398977Z",
     "iopub.status.idle": "2024-07-21T14:04:52.409386Z",
     "shell.execute_reply": "2024-07-21T14:04:52.408376Z",
     "shell.execute_reply.started": "2024-07-21T14:04:52.399485Z"
    }
   },
   "outputs": [],
   "source": [
    "# ストップワードリストを読み込み、リスト形式で保存します\n",
    "stop_words = pd.read_csv(\"/kaggle/input/nltk-english-stopwords/nltk_eng_stopwords.csv\")[\"list_of_stopwords\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7402a2ba",
   "metadata": {},
   "source": [
    "# データの読み込み\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:52.411825Z",
     "iopub.status.busy": "2024-07-21T14:04:52.411529Z",
     "iopub.status.idle": "2024-07-21T14:04:54.210559Z",
     "shell.execute_reply": "2024-07-21T14:04:54.209787Z",
     "shell.execute_reply.started": "2024-07-21T14:04:52.411799Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データ、テストデータ、サンプル提出ファイルを読み込みます\n",
    "train_df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/test.csv\")\n",
    "sample_df = pd.read_csv(\"/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:54.212053Z",
     "iopub.status.busy": "2024-07-21T14:04:54.211708Z",
     "iopub.status.idle": "2024-07-21T14:04:54.216387Z",
     "shell.execute_reply": "2024-07-21T14:04:54.215251Z",
     "shell.execute_reply.started": "2024-07-21T14:04:54.212021Z"
    }
   },
   "outputs": [],
   "source": [
    "# テストデータの行数が10未満の場合、学習データを100行に制限するコードがコメントアウトされています\n",
    "# if test_df.shape[0] < 10:\n",
    "#     train_df = train_df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:54.2178Z",
     "iopub.status.busy": "2024-07-21T14:04:54.217506Z",
     "iopub.status.idle": "2024-07-21T14:04:54.226704Z",
     "shell.execute_reply": "2024-07-21T14:04:54.225843Z",
     "shell.execute_reply.started": "2024-07-21T14:04:54.217776Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_exploded(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    tmp = df.copy()\n",
    "    # prmopt列、response_a列、response_b列の各値をJSON形式から辞書型に変換し、進捗バーを表示します\n",
    "    tmp[\"prompt\"] = tmp[\"prompt\"].progress_apply(lambda x: json.loads(fix_encoding(x)))\n",
    "    tmp[\"response_a\"] = tmp[\"response_a\"].progress_apply(lambda x: json.loads(fix_encoding(x)))\n",
    "    tmp[\"response_b\"] = tmp[\"response_b\"].progress_apply(lambda x: json.loads(fix_encoding(x)))\n",
    "\n",
    "    # 各列でexplodeを適用してデータを展開します\n",
    "    tmp = tmp.explode(['prompt', 'response_a', 'response_b'])\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:54.228027Z",
     "iopub.status.busy": "2024-07-21T14:04:54.22773Z",
     "iopub.status.idle": "2024-07-21T14:04:58.793421Z",
     "shell.execute_reply": "2024-07-21T14:04:58.79272Z",
     "shell.execute_reply.started": "2024-07-21T14:04:54.228004Z"
    }
   },
   "outputs": [],
   "source": [
    "# 学習データとテストデータを展開します\n",
    "tmp_train = get_exploded(train_df)\n",
    "tmp_test = get_exploded(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:04:58.795458Z",
     "iopub.status.busy": "2024-07-21T14:04:58.795197Z",
     "iopub.status.idle": "2024-07-21T14:05:04.579552Z",
     "shell.execute_reply": "2024-07-21T14:05:04.578552Z",
     "shell.execute_reply.started": "2024-07-21T14:04:58.795434Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df, col):\n",
    "        self.col = col\n",
    "        self.df = df.copy()\n",
    "        \n",
    "        # prompt列と指定した列の値をエンコード修正します\n",
    "        self.df[\"prompt\"] = self.df[\"prompt\"].progress_apply(self.fix_encode)\n",
    "        self.df[col] = self.df[col].progress_apply(self.fix_encode)\n",
    "        \n",
    "        # 各列でexplodeを適用してデータを展開します\n",
    "        self.df = self.df.explode(['prompt', col])\n",
    "    \n",
    "    def fix_encode(self, x):\n",
    "        return json.loads(fix_encoding(x))  # エンコードを修正します\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)  # データフレームの長さを返します\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        QA_input = {}\n",
    "        QA_input['question'] = str(self.df.iloc[i][\"prompt\"])  # 質問を取得します\n",
    "        QA_input['context'] = str(self.df.iloc[i][self.col])  # コンテキストを取得します\n",
    "        \n",
    "        # 質問またはコンテキストが空の場合、ダミーテキストを設定します\n",
    "        if not QA_input['question']:\n",
    "            QA_input['question'] = 'empty_text' * 10\n",
    "        if not QA_input['context']:\n",
    "            QA_input['context'] = 'empty_text' * 10\n",
    "        \n",
    "        # 質問とコンテキストの長さを510文字に制限します\n",
    "        QA_input['question'] = QA_input['question'][:510]\n",
    "        QA_input['context'] = QA_input['context'][:510]\n",
    "\n",
    "        return QA_input  # 質問とコンテキストの辞書を返します\n",
    "\n",
    "\n",
    "# データセットのインスタンスを作成します\n",
    "dataset_a = MyDataset(train_df, col='response_a')\n",
    "dataset_b = MyDataset(train_df, col='response_b')\n",
    "\n",
    "dataset_a_test = MyDataset(test_df, col='response_a')\n",
    "dataset_b_test = MyDataset(test_df, col='response_b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:04.581181Z",
     "iopub.status.busy": "2024-07-21T14:05:04.580871Z",
     "iopub.status.idle": "2024-07-21T14:05:04.587378Z",
     "shell.execute_reply": "2024-07-21T14:05:04.586473Z",
     "shell.execute_reply.started": "2024-07-21T14:05:04.581156Z"
    }
   },
   "outputs": [],
   "source": [
    "# データセットの長さを確認します\n",
    "len(dataset_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:04.590398Z",
     "iopub.status.busy": "2024-07-21T14:05:04.590078Z",
     "iopub.status.idle": "2024-07-21T14:05:04.603032Z",
     "shell.execute_reply": "2024-07-21T14:05:04.602179Z",
     "shell.execute_reply.started": "2024-07-21T14:05:04.590373Z"
    }
   },
   "outputs": [],
   "source": [
    "# 出力結果を保存するための辞書を初期化します\n",
    "outs_dict = {'dataset_a': [], 'dataset_b': []}\n",
    "outs_dict_test = {'dataset_a': [], 'dataset_b': []}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d435ed",
   "metadata": {},
   "source": [
    "# モデル\n",
    "\n",
    "## スコアの生成\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:04.6043Z",
     "iopub.status.busy": "2024-07-21T14:05:04.604061Z",
     "iopub.status.idle": "2024-07-21T14:05:04.615026Z",
     "shell.execute_reply": "2024-07-21T14:05:04.614118Z",
     "shell.execute_reply.started": "2024-07-21T14:05:04.604279Z"
    }
   },
   "outputs": [],
   "source": [
    "# 使用するモデルのリストを定義します\n",
    "model_list = [\n",
    "    \"deepset/roberta-base-squad2\",\n",
    "    \"deepset/deberta-v3-base-squad2\",\n",
    "    \"distilbert/distilbert-base-cased-distilled-squad\"\n",
    "#     \"Palak/microsoft_deberta-large_squad\"\n",
    "#     'distilbert/distilbert-base-cased-distilled-squad',\n",
    "#     'deepset/bert-large-uncased-whole-word-masking-squad2'\n",
    "]\n",
    "\n",
    "# Kaggleのパスを加えたモデルリストのコピーを作成します\n",
    "model_list_kaggle = model_list.copy()\n",
    "for i, model_name in enumerate(model_list_kaggle):\n",
    "    model_list_kaggle[i] = '/kaggle/input/deberta-v3-base/' + model_name\n",
    "model_list_kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:04.616484Z",
     "iopub.status.busy": "2024-07-21T14:05:04.616204Z",
     "iopub.status.idle": "2024-07-21T14:05:09.461446Z",
     "shell.execute_reply": "2024-07-21T14:05:09.460435Z",
     "shell.execute_reply.started": "2024-07-21T14:05:04.61646Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp_list = []\n",
    "\n",
    "# それぞれのモデルに対して、モデルとトークナイザーを読み込み、パイプラインを作成します\n",
    "for model_name in model_list_kaggle:\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, padding=True, truncation=True)\n",
    "    \n",
    "    nlp = pipeline('question-answering', model=model, tokenizer=tokenizer, device='cuda', torch_dtype=torch.float16)\n",
    "    \n",
    "    nlp_list.append(nlp)  # パイプラインをリストに追加します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:09.463387Z",
     "iopub.status.busy": "2024-07-21T14:05:09.462757Z",
     "iopub.status.idle": "2024-07-21T14:05:12.762358Z",
     "shell.execute_reply": "2024-07-21T14:05:12.761387Z",
     "shell.execute_reply.started": "2024-07-21T14:05:09.46335Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのパイプラインを保存します\n",
    "for model_name, pipeline in tqdm(zip(model_list, nlp_list), total=len(nlp_list)):\n",
    "    pipeline.save_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:32.063044Z",
     "iopub.status.busy": "2024-07-21T14:05:32.062232Z",
     "iopub.status.idle": "2024-07-21T14:05:32.067584Z",
     "shell.execute_reply": "2024-07-21T14:05:32.066565Z",
     "shell.execute_reply.started": "2024-07-21T14:05:32.063014Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_outs(model_list):\n",
    "    outs_dict = {}\n",
    "    # 各モデルに対して出力辞書を初期化します\n",
    "    for model_name in model_list:\n",
    "        outs_dict[f'{model_name}-a'] = []\n",
    "        outs_dict[f'{model_name}-b'] = []\n",
    "    return outs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:32.238931Z",
     "iopub.status.busy": "2024-07-21T14:05:32.238551Z",
     "iopub.status.idle": "2024-07-21T14:05:32.245541Z",
     "shell.execute_reply": "2024-07-21T14:05:32.244702Z",
     "shell.execute_reply.started": "2024-07-21T14:05:32.238903Z"
    }
   },
   "outputs": [],
   "source": [
    "# 出力用の辞書を作成します\n",
    "outs_train = get_outs(model_list)\n",
    "outs_test = get_outs(model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:33.44427Z",
     "iopub.status.busy": "2024-07-21T14:05:33.443578Z",
     "iopub.status.idle": "2024-07-21T14:05:33.448355Z",
     "shell.execute_reply": "2024-07-21T14:05:33.447388Z",
     "shell.execute_reply.started": "2024-07-21T14:05:33.444237Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーの設定がコメントアウトされています\n",
    "# tokenizer_kwargs = {\"truncation\": True, 'max_length': 512, 'padding': True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:33.626432Z",
     "iopub.status.busy": "2024-07-21T14:05:33.62601Z",
     "iopub.status.idle": "2024-07-21T14:05:33.633675Z",
     "shell.execute_reply": "2024-07-21T14:05:33.632731Z",
     "shell.execute_reply.started": "2024-07-21T14:05:33.626399Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_score(nlp, dataset) -> list:\n",
    "    scores = []\n",
    "    # データセットの各サンプルに対してスコアを計算します\n",
    "    for sample in tqdm(dataset, total=len(dataset)):\n",
    "        try:\n",
    "            out = nlp(sample, doc_stride=47)  # NLPパイプラインを使用してスコアを計算します\n",
    "        except:\n",
    "            print('omom')  # エラーが発生した場合の処理\n",
    "            out = {}\n",
    "            out['score'] = 0  # スコアを0に設定します\n",
    "        scores.append(out['score'])  # スコアをリストに追加します\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-21T14:05:34.012511Z",
     "iopub.status.busy": "2024-07-21T14:05:34.011871Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各モデルに対してトレーニングとテストのスコアを取得します\n",
    "for model_name, nlp in tqdm(zip(model_list, nlp_list), total=len(model_list)):\n",
    "    outs_train[f'{model_name}-a'] = get_score(nlp, dataset_a)\n",
    "    outs_train[f'{model_name}-b'] = get_score(nlp, dataset_b)\n",
    "    \n",
    "    outs_test[f'{model_name}-a'] = get_score(nlp, dataset_a_test)\n",
    "    outs_test[f'{model_name}-b'] = get_score(nlp, dataset_b_test)\n",
    "    \n",
    "    del nlp  # 使用が終わったモデルのパイプラインを削除します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力辞書をデータフレームに変換します\n",
    "outs_train = pd.DataFrame(outs_train)\n",
    "outs_test = pd.DataFrame(outs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果を表示します\n",
    "outs_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習結果とID、勝者モデルの情報を結合します\n",
    "df_bert = pd.concat([outs_train, tmp_train[['id', 'winner_model_a', 'winner_model_b', 'winner_tie']].reset_index()], axis=1).drop('index', axis=1)\n",
    "df_bert_test = pd.concat([outs_test, tmp_test['id'].reset_index()], axis=1).drop('index', axis=1)\n",
    "df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのデータセットを取得します\n",
    "model_dataset = outs_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データをIDでグループ化し、平均を計算します\n",
    "df_bert_train = df_bert.groupby('id').mean()\n",
    "\n",
    "df_bert_test = df_bert_test.groupby('id').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データとテストデータをCSVファイルに保存します\n",
    "df_bert_train.to_csv('df_bert_train.csv', index=False)\n",
    "df_bert_test.to_csv('df_bert_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの最初の数行を表示します\n",
    "df_bert_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0195e5",
   "metadata": {},
   "source": [
    "## 一つの列に集約\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 勝者を示す列を追加します\n",
    "df_bert_train['winner'] = df_bert_train[['winner_model_a', 'winner_model_b', 'winner_tie']].apply(np.argmax, axis=1)\n",
    "df_bert_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要な列を削除します\n",
    "df_bert_train.drop(columns=['winner_model_a', 'winner_model_b', 'winner_tie'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 変換後のデータを表示します\n",
    "df_bert_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なデータをCSVファイルに保存します\n",
    "df_bert_train.to_csv('deberts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aa244",
   "metadata": {},
   "source": [
    "## モデルのトレーニング\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoostClassifierのモデルを定義します\n",
    "model = CatBoostClassifier(verbose=False, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'winner'  # 予測するターゲット列を定義します"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習データの最初の数行を表示します\n",
    "df_bert_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量とターゲットを分割します\n",
    "X_train = df_bert_train.drop(columns=target)  # 特徴量\n",
    "y_train = df_bert_train[target]  # ターゲット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させます\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対して予測を行います\n",
    "y_pred = model.predict_proba(df_bert_test)  # 予測確率を取得します\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46dd406",
   "metadata": {},
   "source": [
    "# 提出用ファイルの作成\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプル提出ファイルに予測結果を追加します\n",
    "sample_df[['winner_model_a', 'winner_model_b', 'winner_tie']] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイルの内容を表示します\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提出ファイルをCSV形式で保存します\n",
    "sample_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 9164256,
     "datasetId": 5392932,
     "sourceId": 8998220,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 9109222,
     "datasetId": 5383460,
     "sourceId": 8946182,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 2993549,
     "datasetId": 1806231,
     "sourceId": 2946034,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
