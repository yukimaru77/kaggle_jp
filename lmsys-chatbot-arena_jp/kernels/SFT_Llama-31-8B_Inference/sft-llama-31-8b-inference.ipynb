{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ab257dc",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYS - Chatbot Arenaのコンペティションにおいて、どちらのチャットボット応答がユーザーに好まれるかを予測するためのモデルをトレーニングするプロセスを示しています。具体的には、2つの大規模言語モデル（LLM）から生成された応答を比較し、選好を予測するための一連の手法を適用しています。\n",
    "\n",
    "主な取り組み内容としては、以下の手順が含まれています：\n",
    "\n",
    "1. **ライブラリのインポート**: `transformers`, `torch`, `peft`, `datasets`などのライブラリを用いて、モデルのトレーニング、推論、およびデータ処理を行います。\n",
    "\n",
    "2. **データの準備**: CSVファイルからトレーニングデータとテストデータを読み込み、JSON形式のテキストデータを処理してプロンプトと応答を結合する関数を作成します。この段階で、欠損値も処理されています。\n",
    "\n",
    "3. **トークナイザーの準備**: 指定したトークナイザーを用いてテキストをトークナイズし、入力IDとアテンションマスクを生成します。\n",
    "\n",
    "4. **モデル設定とロード**: GPUを2つ使ってモデルを設定し、LoRA（Low-Rank Adaptation）技術を利用してメモリ効率を最大化しながら8ビットの計算でモデルをロードします。その後、トレーニング済みの重みを読み込みます。\n",
    "\n",
    "5. **推論の実行**: スレッドプールを使用し、バッチごとにデータを処理しながらモデルの推論を行います。結果として、Aモデルが勝つ確率、Bモデルが勝つ確率、引き分けの確率を計算します。\n",
    "\n",
    "6. **提出ファイルの生成**: 最終的な予測結果を新しいデータフレームにまとめ、\"submission.csv\"という名前でCSVファイルとして保存します。\n",
    "\n",
    "このNotebookでは、特に`transformers`ライブラリの`AutoModelForSequenceClassification`やLoRA設定、また`PeftModel`を活用してモデルのメモリ効率とトレーニングの性能を向上させる努力がなされています。ユーザーの好みを効果的に予測するために、複数のモデルの出力を比較するアプローチが取られています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221c76c",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、提供されたJupyter Notebook内で機械学習や深層学習の初心者がつまずきそうな専門用語の解説です。基本的な知識を持つ方を対象にしているため、より詳細で特有の知識に焦点を当てています。\n",
    "\n",
    "1. **PEFT (Parameter-Efficient Fine-Tuning)**:\n",
    "   - モデルのパラメータを全て再訓練するのではなく、一部のパラメータのみを調整してファインチューニングを行う手法です。計算資源を削減しつつ、特定のタスクに適応させるのが目的です。このNotebookでは、LoRA設定を用いてPEFTを活用しています。\n",
    "\n",
    "2. **LoRA (Low-Rank Adaptation)**:\n",
    "   - モデルのパラメータ行列を低次元に近似することによって、効率的にパラメータ数を削減しつつ、モデルを特定のタスクに適応させる方法です。具体的には、更新対象の層を少数のランクで表現し、計算の負荷を下げることができます。\n",
    "\n",
    "3. **Causal Language Model (CLM)**:\n",
    "   - 言語モデルの一種で、テキストを生成する際に、過去の単語情報のみを考慮に入れて次の単語を予測します。計算された出力は、前の文脈に基づくもので、時系列データや文章生成において主に使用されます。\n",
    "\n",
    "4. **Attention Mask**:\n",
    "   - テキストを処理する際に、どのトークンが重要か、または無視されるべきかを示すためのマスクです。特にパディングされたトークンが計算に影響を及ぼさないようにするために使用され、機械学習モデルがトレーニングされる際のコンテキスト情報を保持する役割を果たします。\n",
    "\n",
    "5. **Softmax Function**:\n",
    "   - モデルの出力に対して確率分布を生成するための関数です。出力の値を正規化し、各クラスの予測確率を計算するために使用されます。このNotebookでは、モデルの結果に対してソフトマックス関数を適用することで、勝者確率を得ています。\n",
    "\n",
    "6. **Automatic Mixed Precision (AMP)**:\n",
    "   - 学習中に使用するデータ型を16ビットと32ビットの浮動小数点で自動的に切り替える技術です。これにより、計算速度を向上させ、GPUメモリの使用効率を高めることができます。特に大規模なモデルの場合、重要な最適化手法となります。\n",
    "\n",
    "7. **Batch Size**:\n",
    "   - モデルのパラメータを更新する際に、同時に処理するデータサンプルの数です。バッチサイズを調整することで、トレーニングの安定性や効率を管理することができます。\n",
    "\n",
    "8. **ThreadPoolExecutor**:\n",
    "   - Pythonのconcurrent.futuresライブラリに含まれるクラスで、スレッドによる並列処理を簡単に実現するためのものです。大規模なデータ処理や推論を効率よく行うために使用され、リソースを最大限に活用します。\n",
    "\n",
    "9. **BitsAndBytes**:\n",
    "   - モデルを8ビット量子化するための設定を行うライブラリです。これにより、モデルのメモリ使用量を削減し、計算の効率を向上させます。特に大規模なモデルを扱う際に重要です。\n",
    "\n",
    "10. **Data Collator**:\n",
    "    - データのバッチを形成するためのロジックを持つクラスまたは関数です。特に異なる長さの入力データを指定された形式でまとめるために使用され、パディングなどの処理を行います。特定のデータ形式に対応したデータコラレーターの使用がNotebook内で示されています。\n",
    "\n",
    "これらの用語は、初心者の方には馴染みがない場合が多いので、特に留意して解説しました。Notebookの内容を理解する際に役立つ情報となるでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27837676",
   "metadata": {},
   "source": [
    "# 注記\n",
    "- [トレーニングスクリプト](https://www.kaggle.com/code/shelterw/training-llama3-8b-4-bit-qlora-sft)\n",
    "\n",
    "# インポート\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:11:03.975521Z",
     "iopub.status.busy": "2024-07-27T09:11:03.974924Z",
     "iopub.status.idle": "2024-07-27T09:11:29.871874Z",
     "shell.execute_reply": "2024-07-27T09:11:29.870806Z",
     "shell.execute_reply.started": "2024-07-27T09:11:03.975489Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers -U --no-index --find-links /kaggle/input/lmsys-transformers/lmsys_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:11:29.874099Z",
     "iopub.status.busy": "2024-07-27T09:11:29.873762Z",
     "iopub.status.idle": "2024-07-27T09:11:46.466628Z",
     "shell.execute_reply": "2024-07-27T09:11:46.46572Z",
     "shell.execute_reply.started": "2024-07-27T09:11:29.874066Z"
    },
    "papermill": {
     "duration": 53.686843,
     "end_time": "2024-07-01T02:57:31.530755",
     "exception": false,
     "start_time": "2024-07-01T02:56:37.843912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install peft accelerate bitsandbytes -U --no-index --find-links /kaggle/input/lmsys-wheel-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:11:46.468327Z",
     "iopub.status.busy": "2024-07-27T09:11:46.468016Z",
     "iopub.status.idle": "2024-07-27T09:12:07.371377Z",
     "shell.execute_reply": "2024-07-27T09:12:07.370544Z",
     "shell.execute_reply.started": "2024-07-27T09:11:46.46829Z"
    },
    "papermill": {
     "duration": 21.138547,
     "end_time": "2024-07-01T02:57:52.676238",
     "exception": false,
     "start_time": "2024-07-01T02:57:31.537691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import autocast\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from threading import Thread\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorForSeq2Seq\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding, AutoModelForSequenceClassification\n",
    "from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType \n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "from transformers.modeling_outputs import CausalLMOutputWithPast\n",
    "from transformers import BitsAndBytesConfig, LlamaForCausalLM, LlamaModel, LlamaPreTrainedModel\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from transformers import set_seed\n",
    "\n",
    "# 高度なメモリ効率を利用するための設定\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(True)\n",
    "torch.backends.cuda.enable_flash_sdp(True)\n",
    "# 利用可能なGPUが2つあることを確認します\n",
    "assert torch.cuda.device_count() == 2, \"申し訳ありませんが、マルチGPUが必要です！\"\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:07.373424Z",
     "iopub.status.busy": "2024-07-27T09:12:07.372621Z",
     "iopub.status.idle": "2024-07-27T09:12:07.378892Z",
     "shell.execute_reply": "2024-07-27T09:12:07.377769Z",
     "shell.execute_reply.started": "2024-07-27T09:12:07.373387Z"
    },
    "papermill": {
     "duration": 0.014817,
     "end_time": "2024-07-01T02:57:52.720706",
     "exception": false,
     "start_time": "2024-07-01T02:57:52.705889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# モデルの設定\n",
    "MODEL_NAME = '/kaggle/input/meta-llama-3-8b/LLM-Research/Meta-Llama-3-8B'  # モデル名を指定\n",
    "WEIGHTS_PATH = '/kaggle/input/llama31-sample5500-cls/llama31-sample5500-cls/checkpoint-550'  # 重みのパス\n",
    "TOKENIZER_PATH = '/kaggle/input/llama31-sample5500-cls/llama31-sample5500-cls/tokenizer'  # トークナイザーのパス\n",
    "MAX_LENGTH = 2400  # 最大シーケンス長\n",
    "BATCH_SIZE = 4  # バッチサイズ設定\n",
    "DEVICE = torch.device(\"cuda\")  # CUDAデバイスを指定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9a90bf",
   "metadata": {},
   "source": [
    "# データの準備 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:07.382118Z",
     "iopub.status.busy": "2024-07-27T09:12:07.38182Z",
     "iopub.status.idle": "2024-07-27T09:12:07.38948Z",
     "shell.execute_reply": "2024-07-27T09:12:07.388581Z",
     "shell.execute_reply.started": "2024-07-27T09:12:07.382094Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_text(text: str) -> list:\n",
    "    # JSON形式のテキストを解析し、欠損値を'none'で置き換えます\n",
    "    x = json.loads(text)\n",
    "    x = ['none' if pd.isna(i) else i for i in x]\n",
    "    return x\n",
    "\n",
    "def merge_text(x):\n",
    "    # プロンプトとレスポンスを結合します\n",
    "    prompt = x['prompt']\n",
    "    response_a = x['response_a']\n",
    "    response_b = x['response_b']\n",
    "    res = ''\n",
    "    for i in range(len(prompt)):\n",
    "        if i == len(prompt) - 1:\n",
    "            res += f'<prompt>: {prompt[i]}' + f'\\n\\n<response_a>: {response_a[i]}' + f'\\n\\n<response_b>: {response_b[i]}'\n",
    "        else:\n",
    "            res += f'<prompt>: {prompt[i]}' + f'\\n\\n<response_a>: {response_a[i]}' + f'\\n\\n<response_b>: {response_b[i]}' + '\\n\\n'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:07.390654Z",
     "iopub.status.busy": "2024-07-27T09:12:07.390408Z",
     "iopub.status.idle": "2024-07-27T09:12:11.440512Z",
     "shell.execute_reply": "2024-07-27T09:12:11.439588Z",
     "shell.execute_reply.started": "2024-07-27T09:12:07.390631Z"
    }
   },
   "outputs": [],
   "source": [
    "# トレーニングデータとテストデータを読み込みます\n",
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# テストデータの行数が3のときは、トレーニングデータの最初の100行を使用します\n",
    "if test.shape[0] == 3:\n",
    "    test = train.head(100)\n",
    "\n",
    "# 各列を処理します\n",
    "test['prompt'] = test['prompt'].map(lambda x: process_text(x))\n",
    "test['response_a'] = test['response_a'].map(lambda x: process_text(x))\n",
    "test['response_b'] = test['response_b'].map(lambda x: process_text(x))\n",
    "\n",
    "# プロンプトとレスポンスを結合して新しいテキスト列を作ります\n",
    "test['text'] = test.apply(lambda x: merge_text(x), axis=1)\n",
    "# テストデータの最初の行を表示します\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05534547",
   "metadata": {},
   "source": [
    "# トークナイズ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:11.442369Z",
     "iopub.status.busy": "2024-07-27T09:12:11.441726Z",
     "iopub.status.idle": "2024-07-27T09:12:11.447577Z",
     "shell.execute_reply": "2024-07-27T09:12:11.446508Z",
     "shell.execute_reply.started": "2024-07-27T09:12:11.442334Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(tokenizer, x):\n",
    "    # テキストをトークナイズして、入力IDとアテンションマスクを生成します\n",
    "    tokenized = tokenizer(x, max_length=MAX_LENGTH, truncation=True)\n",
    "    return tokenized['input_ids'], tokenized['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:11.449222Z",
     "iopub.status.busy": "2024-07-27T09:12:11.448896Z",
     "iopub.status.idle": "2024-07-27T09:12:12.063094Z",
     "shell.execute_reply": "2024-07-27T09:12:12.062269Z",
     "shell.execute_reply.started": "2024-07-27T09:12:11.449188Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーをロードします\n",
    "llama31_tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "\n",
    "# 空のデータフレームを作成\n",
    "llama31_data = pd.DataFrame()\n",
    "llama31_data[\"id\"] = test[\"id\"]\n",
    "# トークナイズした結果をデータフレームに保存します\n",
    "llama31_data[\"input_ids\"], llama31_data[\"attention_mask\"] = tokenize(llama31_tokenizer, list(test['text']))\n",
    "# 入力IDの長さを計算します\n",
    "llama31_data[\"length\"] = llama31_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15926083",
   "metadata": {},
   "source": [
    "# モデルをロード \n",
    "それぞれのGPUに1つのモデルをロードします。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:12:12.064787Z",
     "iopub.status.busy": "2024-07-27T09:12:12.064404Z",
     "iopub.status.idle": "2024-07-27T09:14:05.403312Z",
     "shell.execute_reply": "2024-07-27T09:14:05.402389Z",
     "shell.execute_reply.started": "2024-07-27T09:12:12.064739Z"
    }
   },
   "outputs": [],
   "source": [
    "# 8ビットの計算に関する設定を定義します\n",
    "bnb_config =  BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    bnb_8bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "device_0 = torch.device('cuda:0')  # 最初のGPUを指定\n",
    "llama31_model_0 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,  # 出力ラベルの数\n",
    "    torch_dtype=torch.float16,  # 16ビット浮動小数点でモデルをロード\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=False,  # キャッシュを無効に\n",
    "    device_map=device_0  # デバイスの設定\n",
    ")\n",
    "# パディングトークンIDを設定します\n",
    "llama31_model_0.config.pad_token_id = llama31_tokenizer.pad_token_id\n",
    "\n",
    "device_1 = torch.device('cuda:1')  # 2つ目のGPUを指定\n",
    "llama31_model_1 = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=3,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    use_cache=False,\n",
    "    device_map=device_1\n",
    ")\n",
    "# パディングトークンIDを設定します\n",
    "llama31_model_1.config.pad_token_id = llama31_tokenizer.pad_token_id\n",
    "\n",
    "# LoRA設定の作成\n",
    "lora_config = LoraConfig(\n",
    "    r=4,\n",
    "    lora_alpha=8,\n",
    "    # 自己注意のターゲットモジュールのみ\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    lora_dropout=0,  # ドロップアウト率を0に設定\n",
    "    bias='none',  # バイアスを無効に\n",
    "    task_type=TaskType.SEQ_CLS,  # タスクタイプをシーケンス分類に設定\n",
    ")\n",
    "\n",
    "# モデルのトレーニング準備についてのコードはコメントアウトされています\n",
    "# llama31_model_0 = prepare_model_for_kbit_training(llama31_model_0)\n",
    "# llama31_model_0 = get_peft_model(llama31_model_0, lora_config)\n",
    "# llama31_model_0.print_trainable_parameters()\n",
    "\n",
    "# llama31_model_1 = prepare_model_for_kbit_training(llama31_model_1)\n",
    "# llama31_model_1 = get_peft_model(llama31_model_1, lora_config)\n",
    "# llama31_model_1.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9d35d",
   "metadata": {},
   "source": [
    "# 重みのロード \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:14:05.40471Z",
     "iopub.status.busy": "2024-07-27T09:14:05.404448Z",
     "iopub.status.idle": "2024-07-27T09:14:06.389814Z",
     "shell.execute_reply": "2024-07-27T09:14:06.388838Z",
     "shell.execute_reply.started": "2024-07-27T09:14:05.404687Z"
    },
    "papermill": {
     "duration": 13.701042,
     "end_time": "2024-07-01T02:59:52.320278",
     "exception": false,
     "start_time": "2024-07-01T02:59:38.619236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PEFTを取得します\n",
    "llama31_model_0 = PeftModel.from_pretrained(llama31_model_0, model_id=WEIGHTS_PATH).to(device_0)\n",
    "llama31_model_0.eval()  # 評価モードに設定\n",
    "\n",
    "llama31_model_1 = PeftModel.from_pretrained(llama31_model_1, model_id=WEIGHTS_PATH).to(device_1)\n",
    "llama31_model_1.eval();  # 評価モードに設定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4bd241",
   "metadata": {},
   "source": [
    "# 推論\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:14:06.391493Z",
     "iopub.status.busy": "2024-07-27T09:14:06.391124Z",
     "iopub.status.idle": "2024-07-27T09:14:06.401297Z",
     "shell.execute_reply": "2024-07-27T09:14:06.400349Z",
     "shell.execute_reply.started": "2024-07-27T09:14:06.391459Z"
    },
    "papermill": {
     "duration": 0.021078,
     "end_time": "2024-07-01T02:59:52.402973",
     "exception": false,
     "start_time": "2024-07-01T02:59:52.381895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()  # 勾配を計算しないようにします\n",
    "@torch.cuda.amp.autocast()  # 自動混合精度を使用します\n",
    "def inference(df, model, tokenizer, device, batch_size=BATCH_SIZE, max_length=MAX_LENGTH):\n",
    "    a_win, b_win, tie = [], [], []  # 各モデルの勝者を格納するリスト\n",
    "    \n",
    "    # バッチごとにデータを処理\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]  # 現在のバッチを取得\n",
    "        input_ids = tmp[\"input_ids\"].to_list()  # 入力IDをリストに変換\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()  # アテンションマスクをリストに変換\n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",  # 最も長いシーケンスに合わせてパディング\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",  # PyTorchテンソルとして返す\n",
    "        )\n",
    "        outputs = model(**inputs.to(device))  # モデルへの入力\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # ソフトマックス関数を適用して確率を計算\n",
    "        \n",
    "        # 各モデルの勝者の確率を収集\n",
    "        a_win.extend(proba[:, 0].tolist())\n",
    "        b_win.extend(proba[:, 1].tolist())\n",
    "        tie.extend(proba[:, 2].tolist())\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win  # 勝者モデルAの確率をデータフレームに追加\n",
    "    df[\"winner_model_b\"] = b_win  # 勝者モデルBの確率をデータフレームに追加\n",
    "    df[\"winner_tie\"] = tie  # 引き分けの確率をデータフレームに追加\n",
    "    \n",
    "    return df  # データフレームを返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:14:06.403013Z",
     "iopub.status.busy": "2024-07-27T09:14:06.402728Z",
     "iopub.status.idle": "2024-07-27T09:14:42.157842Z",
     "shell.execute_reply": "2024-07-27T09:14:42.156855Z",
     "shell.execute_reply.started": "2024-07-27T09:14:06.40299Z"
    },
    "papermill": {
     "duration": 3.316613,
     "end_time": "2024-07-01T02:59:55.727834",
     "exception": false,
     "start_time": "2024-07-01T02:59:52.411221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "st = time.time()  # 処理開始の時間を記録\n",
    "\n",
    "# テストデータを長さでソート\n",
    "llama31_data = llama31_data.sort_values(\"length\", ascending=False).reset_index(drop=True)\n",
    "sub_1 = llama31_data.iloc[0::2].copy()  # 偶数の行を取得\n",
    "sub_2 = llama31_data.iloc[1::2].copy()  # 奇数の行を取得\n",
    "\n",
    "# スレッドプールを使用して推論を並列処理\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (llama31_model_0, llama31_model_1), (llama31_tokenizer, llama31_tokenizer), (device_0, device_1))\n",
    "\n",
    "# 結果を結合\n",
    "result_df = pd.concat(list(results), axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]].values  # 各モデルの勝者確率を取得\n",
    "\n",
    "print(f\"経過時間: {time.time() - st}\")  # 処理にかかった時間を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-27T09:14:42.159219Z",
     "iopub.status.busy": "2024-07-27T09:14:42.158937Z",
     "iopub.status.idle": "2024-07-27T09:14:42.179202Z",
     "shell.execute_reply": "2024-07-27T09:14:42.178357Z",
     "shell.execute_reply.started": "2024-07-27T09:14:42.159193Z"
    },
    "papermill": {
     "duration": 1.755381,
     "end_time": "2024-07-01T02:59:57.492377",
     "exception": false,
     "start_time": "2024-07-01T02:59:55.736996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # モデルAの勝者確率を設定\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # モデルBの勝者確率を設定\n",
    "result_df.loc[:, \"winner_tie\"] = proba[:, 2]  # 引き分け確率を設定\n",
    "# 提出用データフレームを作成\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b', 'winner_tie']]\n",
    "# CSVファイルとして保存\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "# 提出データフレームを表示\n",
    "display(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5425581,
     "sourceId": 9006038,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5426043,
     "sourceId": 9006773,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5427273,
     "sourceId": 9008474,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5447195,
     "sourceId": 9036587,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5448856,
     "sourceId": 9038716,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5452078,
     "sourceId": 9043403,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5452122,
     "sourceId": 9043467,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5452946,
     "sourceId": 9044686,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 81881,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 206.513308,
   "end_time": "2024-07-01T03:00:01.146998",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-01T02:56:34.63369",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03b341b06afc40599e50c9c1ce88be20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "07273d2112d649ffbea2991a6a79df98": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "142be9e5949c44fabd0370c6df1203d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "15d31276fcd44350a50d1c561c13e3a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3974a6c7f61d4f4582a8e4fdf4c9976c",
       "placeholder": "​",
       "style": "IPY_MODEL_3daebd55184a4a9982813dc1ac948f2e",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "1df41ee456cd4fa78a23f7ea2fded110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "28cb0aaaf9d24d3d857d224850f62f5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_846776c5dc1f44bc9cf2e3d394e8ba48",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e7361623d5e1491c888080ee4fb8bfdd",
       "value": 4
      }
     },
     "3974a6c7f61d4f4582a8e4fdf4c9976c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3daebd55184a4a9982813dc1ac948f2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "411187a29c544ebbb425a06b0dfae7a4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "475dd481f05a46c1908b9f781ae1afa8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f43e003b1f2e4367800ba2bad74c7075",
        "IPY_MODEL_28cb0aaaf9d24d3d857d224850f62f5b",
        "IPY_MODEL_74d46aef6d8949c584024a6e7bb4f06c"
       ],
       "layout": "IPY_MODEL_1df41ee456cd4fa78a23f7ea2fded110"
      }
     },
     "74d46aef6d8949c584024a6e7bb4f06c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9c5128ae1d114334b30f2e1013062b26",
       "placeholder": "​",
       "style": "IPY_MODEL_03b341b06afc40599e50c9c1ce88be20",
       "value": " 4/4 [01:30&lt;00:00, 18.30s/it]"
      }
     },
     "846776c5dc1f44bc9cf2e3d394e8ba48": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e8e3620620b445eb1d0286befa13278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_15d31276fcd44350a50d1c561c13e3a4",
        "IPY_MODEL_cb2874dbe9904c07a254eb33d6f0ecfe",
        "IPY_MODEL_c23e125e5c3e4cee844bd057453c7aca"
       ],
       "layout": "IPY_MODEL_142be9e5949c44fabd0370c6df1203d6"
      }
     },
     "9c5128ae1d114334b30f2e1013062b26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7c6588ad13549ae958237ca8e3af9db": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c23e125e5c3e4cee844bd057453c7aca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dd4aa3639e4a46e7a3861fa3dbd5a31b",
       "placeholder": "​",
       "style": "IPY_MODEL_07273d2112d649ffbea2991a6a79df98",
       "value": " 4/4 [00:13&lt;00:00,  2.76s/it]"
      }
     },
     "cb2874dbe9904c07a254eb33d6f0ecfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_411187a29c544ebbb425a06b0dfae7a4",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d0043cb27ac54061b85f9b3886954314",
       "value": 4
      }
     },
     "d0043cb27ac54061b85f9b3886954314": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "dd4aa3639e4a46e7a3861fa3dbd5a31b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e7361623d5e1491c888080ee4fb8bfdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f0cc9ad10c3d4a63bd03716995531022": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f43e003b1f2e4367800ba2bad74c7075": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b7c6588ad13549ae958237ca8e3af9db",
       "placeholder": "​",
       "style": "IPY_MODEL_f0cc9ad10c3d4a63bd03716995531022",
       "value": "Loading checkpoint shards: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
