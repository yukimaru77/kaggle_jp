{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c305e9",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」に取り組んでいます。具体的には、大規模言語モデル（LLM）によって生成されたチャット応答の中から、ユーザーが好みそうな応答を予測するための機械学習モデルを構築しています。\n",
    "\n",
    "主な手法としては、Natural Language Processing (NLP)を用いたテキスト分析が行われており、以下のようなライブラリや技術が使用されています：\n",
    "\n",
    "- **NumPy**や**Pandas**：基本的なデータ処理を行うために用いられます。\n",
    "- **NLTK**：テキストをトークン化したり、品詞タグ付け、頻度分布の計算などに使用されます。\n",
    "- **TextStat**：可読性スコアの計算に利用されており、Flesch-KincaidグレードやGunning-Fogインデックスなど多様な指標を提供します。\n",
    "- **TextBlob**：テキストの感情分析を実行します。\n",
    "- **SpaCy**：テキスト処理（トークン化など）に使われ、受動態文のカウント等も行います。\n",
    "- **scikit-learn**：Gradient BoostingやXGBoost、LightGBM、CatBoostなどの強化学習アルゴリズムを使用してモデルを訓練し、性能評価には対数損失（log loss）が採用されています。\n",
    "- **Optuna**：ハイパーパラメータの最適化に利用されており、異なるモデルタイプ（XGBClassifier, LGBMClassifier, CatBoostClassifier）に対して最適なパラメータを選定します。\n",
    "- **Concurrent Futures**：テキスト統計を並列処理するために使用され、計算効率が向上しています。\n",
    "\n",
    "具体的な流れとしては、まずトレーニングデータとテストデータを読み込み、各テキストに対して可読性スコアや感情スコア、文の統計を計算し、特徴量を生成します。次に、これらの特徴量を用いてモデルを訓練し、最終的にテストデータに対する予測を行い、結果をCSVファイルとして保存します。\n",
    "\n",
    "全体的には、ユーザーの好みを正確に予測するための多様なテキスト分析手法と機械学習アルゴリズムを組み合わせたアプローチが強調されています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e92c307",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookの内容に関連する専門用語の簡単な解説です。特に初心者がつまずきやすい用語や、このコンペティション特有のドメイン知識に焦点を当てています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **可読性スコア (Readability Scores)**:\n",
    "   - テキストがどれだけ容易に理解できるかを定量化する指標。一般的には、英語の文章に対してどの年齢層の読者が理解可能かを示すために使用される。例として、Flesch-KincaidグレードやGunning-Fogインデックスがある。\n",
    "\n",
    "2. **Flesch-Kincaidグレード (Flesch-Kincaid Grade)**:\n",
    "   - 英語の文章の難易度を示す指標で、読者が理解するのに必要な学年を示す。数値が高いほど、文章が難しくなる。\n",
    "\n",
    "3. **Gunning-Fogインデックス**:\n",
    "   - テキストの可読性を測る指標で、文章中の難しい単語の割合と文の長さを考慮して、理解に必要な年数を示す。\n",
    "\n",
    "4. **SMOGインデックス (SMOG Index)**:\n",
    "   - ショート文の可読性を測定するための指数で、特に公共の場や教育のために作成されたもので、難解な単語の数に基づいて計算される。\n",
    "\n",
    "5. **自動可読性インデックス (Automated Readability Index)**:\n",
    "   - テキストの難易度を測定するための指標で、単語数と文の長さから計算される。数値が高いと難易度が高くなる。\n",
    "\n",
    "6. **Coleman-Liau Index**:\n",
    "   - テキストの可読性を示す指標で、文字数に基づいており、特に単純な計算で可読性を測定する方式を採用している。\n",
    "\n",
    "7. **名詞句 (Noun Phrases)**:\n",
    "   - 名詞とその修飾語から成る構造。文章中で主要な意味を構成する要素であり、その数を解析することでテキストの構造を理解できる。\n",
    "\n",
    "8. **感情極性 (Sentiment Polarity)**:\n",
    "   - テキストが持つ感情の方向性。一般的に、ポジティブ、ネガティブ、ニュートラルのどれかに分類される。テキストの感情的なトーンを評価する際に使われる。\n",
    "\n",
    "9. **受動態 (Passive Voice)**:\n",
    "   - 文の構造の一つで、行為によって影響を受ける側（目的語）が主語となる形式。例えば、「彼によって書かれた手紙」は受動態となる。\n",
    "\n",
    "10. **POS (Part of Speech) タグ**:\n",
    "    - 単語に対する品詞（名詞、動詞、形容詞など）のラベル。自然言語処理において、文の構造を理解するために重要な役割を果たす。\n",
    "\n",
    "11. **並列処理 (Parallel Processing)**:\n",
    "    - 複数のプロセスを同時に実行する方法。データ処理にかかる時間を短縮するために用いられる。\n",
    "\n",
    "12. **Optuna**:\n",
    "    - ハイパーパラメータ最適化のためのフレームワーク。経済的に効率的に最適なモデルのパラメータを探索することができる。\n",
    "\n",
    "13. **ログ損失 (Log Loss)**:\n",
    "    - モデルの予測性能を評価するための指標。予測確率と実際のラベルとの違いを計測し、数値が小さいほど良いモデルとされる。\n",
    "\n",
    "これらの用語は、Jupyter Notebookの内容に特有のものであり、理解することで機械学習・深層学習の解析やモデルの構築に役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:08.3611Z",
     "iopub.status.busy": "2024-07-10T18:14:08.360659Z",
     "iopub.status.idle": "2024-07-10T18:14:08.929677Z",
     "shell.execute_reply": "2024-07-10T18:14:08.928456Z",
     "shell.execute_reply.started": "2024-07-10T18:14:08.361064Z"
    }
   },
   "outputs": [],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これは、kaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、以下のいくつかの便利なパッケージを読み込むことができます\n",
    "\n",
    "import numpy as np # 線形代数\n",
    "import pandas as pd # データ処理、CSVファイルの入出力（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の \"../input/\" ディレクトリにあります\n",
    "# 例えば、これを実行すると（実行ボタンをクリックするかShift+Enterを押す）、入力ディレクトリ内のファイルがすべてリストされます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# 現在のディレクトリ(/kaggle/working/)には最大20GBまで書き込むことができ、バージョンを作成する際に出力として保存されます\n",
    "# 一時ファイルは/kaggle/temp/に書き込むことができますが、現在のセッションの外では保存されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:10.223858Z",
     "iopub.status.busy": "2024-07-10T18:14:10.223246Z",
     "iopub.status.idle": "2024-07-10T18:14:46.242631Z",
     "shell.execute_reply": "2024-07-10T18:14:46.241363Z",
     "shell.execute_reply.started": "2024-07-10T18:14:10.223819Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/Pyphen-0.9.3-py2.py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:14:46.245461Z",
     "iopub.status.busy": "2024-07-10T18:14:46.245087Z",
     "iopub.status.idle": "2024-07-10T18:15:21.470406Z",
     "shell.execute_reply": "2024-07-10T18:15:21.469016Z",
     "shell.execute_reply.started": "2024-07-10T18:14:46.245428Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:15:21.472389Z",
     "iopub.status.busy": "2024-07-10T18:15:21.472024Z",
     "iopub.status.idle": "2024-07-10T18:15:56.372185Z",
     "shell.execute_reply": "2024-07-10T18:15:56.370713Z",
     "shell.execute_reply.started": "2024-07-10T18:15:21.472355Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl')\n",
    "!pip install '/kaggle/input/textstat-pypi/textstat-0.7.0-py3-none-any.whl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:15:56.376712Z",
     "iopub.status.busy": "2024-07-10T18:15:56.376166Z",
     "iopub.status.idle": "2024-07-10T18:16:05.593946Z",
     "shell.execute_reply": "2024-07-10T18:16:05.592679Z",
     "shell.execute_reply.started": "2024-07-10T18:15:56.376663Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import textstat\n",
    "from textblob import TextBlob\n",
    "import spacy\n",
    "import concurrent.futures\n",
    "import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "# nltk.download('punkt')  # NLTKのpunktモデルをダウンロードします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:44.314554Z",
     "iopub.status.busy": "2024-07-10T18:19:44.314074Z",
     "iopub.status.idle": "2024-07-10T18:19:44.333118Z",
     "shell.execute_reply": "2024-07-10T18:19:44.331702Z",
     "shell.execute_reply.started": "2024-07-10T18:19:44.31452Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_readability_scores(text):\n",
    "    # この関数は、さまざまな可読性スコアを計算します\n",
    "    return {\n",
    "        \"flesch_kincaid_grade\": textstat.flesch_kincaid_grade(text),  # Flesch-Kincaid グレードを計算\n",
    "        \"gunning_fog\": textstat.gunning_fog(text),  # Gunning-Fog インデックスを計算\n",
    "        \"smog_index\": textstat.smog_index(text),  # SMOGインデックスを計算\n",
    "        \"ari\": textstat.automated_readability_index(text),  # 自動可読性インデックスを計算\n",
    "        \"coleman_liau_index\": textstat.coleman_liau_index(text)  # Coleman-Liau インデックスを計算\n",
    "    }\n",
    "\n",
    "def count_noun_phrases(text):\n",
    "    blob = TextBlob(text)  # TextBlobオブジェクトを作成\n",
    "    return len(blob.noun_phrases)  # 名詞句の数を返す\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)  # TextBlobオブジェクトを作成\n",
    "    return blob.sentiment.polarity  # テキストの感情極性を返す\n",
    "\n",
    "def count_passive_voice(text):\n",
    "    doc = nlp(text)  # SpaCyを使用してテキストを処理\n",
    "    return sum(1 for token in doc if token.dep_ == 'auxpass')  # 受動態の文の数をカウント\n",
    "\n",
    "def pos_tag_frequencies(text):\n",
    "    words = word_tokenize(text)  # テキストを単語にトークン化\n",
    "    tags = nltk.pos_tag(words)  # 各単語に品詞タグを付与\n",
    "    freq_dist = nltk.FreqDist(tag for (word, tag) in tags)  # 品詞の頻度分布を計算\n",
    "    # 一貫した辞書形式で頻度を格納することを保証\n",
    "    return {tag: freq for tag, freq in freq_dist.items()}\n",
    "\n",
    "def text_statistics(text):\n",
    "    stats = calculate_readability_scores(text)  # 可読性スコアの計算\n",
    "    stats.update({\n",
    "        \"word_count\": len(word_tokenize(text)),  # 単語数を計算\n",
    "        \"char_count\": len(text),  # 文字数を計算\n",
    "        \"sentence_count\": len(sent_tokenize(text)),  # 文数を計算\n",
    "        \"avg_word_length\": sum(len(word) for word in word_tokenize(text)) / len(word_tokenize(text)),  # 平均単語長を計算\n",
    "        \"avg_sentence_length\": sum(len(sent) for sent in sent_tokenize(text)) / len(sent_tokenize(text)),  # 平均文長を計算\n",
    "        \"lexical_diversity\": len(set(word_tokenize(text))) / len(word_tokenize(text)),  # 語彙の多様性を計算\n",
    "        \"noun_phrases_count\": count_noun_phrases(text),  # 名詞句の数を計算\n",
    "        \"sentiment\": analyze_sentiment(text),  # 感情分析を実行\n",
    "        \"passive_voice_count\": count_passive_voice(text),  # 受動態のカウントを実行\n",
    "    })\n",
    "    # POSタグの頻度を主な統計辞書にマージ\n",
    "    pos_tags = pos_tag_frequencies(text)\n",
    "    for tag, count in pos_tags.items():\n",
    "        stats[f'pos_tag_{tag}'] = count  # 各品詞の頻度を辞書に追加\n",
    "    return stats\n",
    "\n",
    "def parallel_apply(df, column):\n",
    "    # NaN値をドロップしてエラーを回避\n",
    "    texts = df[column].dropna()  # NaNを除外したテキストのリストを作成\n",
    "\n",
    "    # ProcessPoolExecutorを使用して並列に関数を適用\n",
    "    with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        results = list(executor.map(text_statistics, texts))  # 並列処理でテキスト統計を計算\n",
    "\n",
    "    # 辞書のリストをDataFrameに変換\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # 欠損POSタグを0で埋め、データ型を適切に変換する処理を自動的に行う\n",
    "    results_df.fillna(0, inplace=True)  # NaNを0で埋める\n",
    "    for col in results_df.columns:\n",
    "        if results_df[col].dtype == float:\n",
    "            results_df[col] = results_df[col].astype(int)  # float型の列をint型に変換\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:47.314726Z",
     "iopub.status.busy": "2024-07-10T18:19:47.314284Z",
     "iopub.status.idle": "2024-07-10T18:19:49.521817Z",
     "shell.execute_reply": "2024-07-10T18:19:49.52068Z",
     "shell.execute_reply.started": "2024-07-10T18:19:47.314695Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/train.csv')  # トレーニングデータを読み込む\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')  # テストデータを読み込む\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')  # 提出サンプルを読み込む\n",
    "print('データがインポートされました')  # データインポート完了のメッセージ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:51.505083Z",
     "iopub.status.busy": "2024-07-10T18:19:51.504656Z",
     "iopub.status.idle": "2024-07-10T18:19:51.512762Z",
     "shell.execute_reply": "2024-07-10T18:19:51.511538Z",
     "shell.execute_reply.started": "2024-07-10T18:19:51.50505Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape  # トレーニングデータの形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T11:21:50.392346Z",
     "iopub.status.busy": "2024-07-10T11:21:50.391912Z",
     "iopub.status.idle": "2024-07-10T11:21:50.398948Z",
     "shell.execute_reply": "2024-07-10T11:21:50.397465Z",
     "shell.execute_reply.started": "2024-07-10T11:21:50.392314Z"
    }
   },
   "outputs": [],
   "source": [
    "# def parallel_apply(df, column):\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         results = list(executor.map(text_statistics, df[column].dropna()))  # NaNを処理するためにdropnaを使用\n",
    "#     return pd.DataFrame(results)  # DataFrameを返す関数（コメントアウト）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:19:57.96877Z",
     "iopub.status.busy": "2024-07-10T18:19:57.968198Z",
     "iopub.status.idle": "2024-07-10T18:20:17.15232Z",
     "shell.execute_reply": "2024-07-10T18:20:17.150766Z",
     "shell.execute_reply.started": "2024-07-10T18:19:57.968726Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'prompt'および'response'列に対してparallel_applyを適用\n",
    "nlp = spacy.load('en_core_web_sm')  # SpaCyの英語モデルをロード\n",
    "prompt_stats_df = parallel_apply(train, 'prompt')  # プロンプトの統計を計算\n",
    "response_a_stats_df = parallel_apply(train, 'response_a')  # レスポンスAの統計を計算\n",
    "response_b_stats_df = parallel_apply(train, 'response_b')  # レスポンスBの統計を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:27.584464Z",
     "iopub.status.busy": "2024-07-10T18:20:27.583673Z",
     "iopub.status.idle": "2024-07-10T18:20:27.686498Z",
     "shell.execute_reply": "2024-07-10T18:20:27.685326Z",
     "shell.execute_reply.started": "2024-07-10T18:20:27.584421Z"
    }
   },
   "outputs": [],
   "source": [
    "train = train.join(prompt_stats_df.add_suffix('_prompt'))  # プロンプトの統計をトレーニングデータに結合\n",
    "train = train.join(response_a_stats_df.add_suffix('_response_a'))  # レスポンスAの統計をトレーニングデータに結合\n",
    "train = train.join(response_b_stats_df.add_suffix('_response_b'))  # レスポンスBの統計をトレーニングデータに結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:49.736783Z",
     "iopub.status.busy": "2024-07-10T18:20:49.73633Z",
     "iopub.status.idle": "2024-07-10T18:20:49.744679Z",
     "shell.execute_reply": "2024-07-10T18:20:49.7434Z",
     "shell.execute_reply.started": "2024-07-10T18:20:49.736746Z"
    }
   },
   "outputs": [],
   "source": [
    "train.shape  # 結合後のトレーニングデータの形状を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-10T18:20:30.29828Z",
     "iopub.status.busy": "2024-07-10T18:20:30.297834Z",
     "iopub.status.idle": "2024-07-10T18:20:30.325713Z",
     "shell.execute_reply": "2024-07-10T18:20:30.324552Z",
     "shell.execute_reply.started": "2024-07-10T18:20:30.298248Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()  # トレーニングデータの最初の数行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:02:58.054824Z",
     "iopub.status.busy": "2024-07-08T12:02:58.054395Z",
     "iopub.status.idle": "2024-07-08T12:02:58.477477Z",
     "shell.execute_reply": "2024-07-08T12:02:58.476116Z",
     "shell.execute_reply.started": "2024-07-08T12:02:58.05479Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import time  # 時間計測のためのモジュールをインポート\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# ターゲットを単一の列に変換し、カテゴリーベースにします\n",
    "train['winner'] = (train['winner_model_a'] * 1 + train['winner_model_b'] * 2 + train['winner_tie'] * 3).astype(int)\n",
    "\n",
    "# 特徴量とターゲットの定義\n",
    "columns_to_remove = {'id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', \n",
    "                     'winner_model_a', 'winner_model_b', 'winner_tie', 'winner'}\n",
    "\n",
    "features = [col for col in train.columns if col not in columns_to_remove]  # 残す特徴量をリストアップ\n",
    "\n",
    "X = train[features]  # 特徴量データ\n",
    "y = train['winner'] - 1  # ターゲットデータ（0から始まるインデックスに変換）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:04:40.502718Z",
     "iopub.status.busy": "2024-07-08T12:04:40.501238Z",
     "iopub.status.idle": "2024-07-08T12:06:05.549672Z",
     "shell.execute_reply": "2024-07-08T12:06:05.548464Z",
     "shell.execute_reply.started": "2024-07-08T12:04:40.502676Z"
    }
   },
   "outputs": [],
   "source": [
    "# 最適化関数の定義\n",
    "def objective(trial):\n",
    "    # トライアル内でのデータ分割\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # 最適化するモデルとハイパーパラメータの定義\n",
    "    model_type = trial.suggest_categorical('model_type', ['XGBClassifier', 'LGBMClassifier', 'CatBoostClassifier'])\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 500)  # 決定木の数を指定\n",
    "    max_depth = trial.suggest_int('max_depth', 2, 10)  # 木の深さを指定\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-4, 0.1)  # 学習率を指定\n",
    "\n",
    "    if model_type == 'XGBClassifier':\n",
    "        model = XGBClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "    elif model_type == 'LGBMClassifier':\n",
    "        model = LGBMClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, random_state=42)\n",
    "    elif model_type == 'CatBoostClassifier':\n",
    "        model = CatBoostClassifier(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate, verbose=0, random_state=42)\n",
    "\n",
    "    # モデルの訓練と評価\n",
    "    model.fit(X_train, y_train)  # モデルを訓練\n",
    "    y_val_pred = model.predict_proba(X_val)  # バリデーションデータで予測\n",
    "    return log_loss(y_val, y_val_pred)  # ログ損失を返す\n",
    "\n",
    "# Optuna最適化の実行\n",
    "study = optuna.create_study(direction='minimize')  # 最小化方向でスタディを作成\n",
    "study.optimize(objective, n_trials=5)  # トライアルを実行\n",
    "\n",
    "print('最良のトライアル:', study.best_trial.params)  # 最良のパラメータを表示\n",
    "\n",
    "# フルデータで最良モデルを訓練\n",
    "best_params = study.best_trial.params  # 最良のパラメータを取得\n",
    "model_type = best_params.pop('model_type')  # モデルタイプを取得し、辞書から削除\n",
    "\n",
    "if model_type == 'XGBClassifier':\n",
    "    final_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "elif model_type == 'LGBMClassifier':\n",
    "    final_model = LGBMClassifier(**best_params, random_state=42)\n",
    "elif model_type == 'CatBoostClassifier':\n",
    "    final_model = CatBoostClassifier(**best_params, verbose=0, random_state=42)\n",
    "\n",
    "final_model.fit(X, y)  # フルデータセットで訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:10:55.670111Z",
     "iopub.status.busy": "2024-07-08T12:10:55.669593Z",
     "iopub.status.idle": "2024-07-08T12:10:55.681442Z",
     "shell.execute_reply": "2024-07-08T12:10:55.680161Z",
     "shell.execute_reply.started": "2024-07-08T12:10:55.670072Z"
    }
   },
   "outputs": [],
   "source": [
    "final_model  # 最終モデルを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:16:41.428065Z",
     "iopub.status.busy": "2024-07-08T12:16:41.42756Z",
     "iopub.status.idle": "2024-07-08T12:16:42.661732Z",
     "shell.execute_reply": "2024-07-08T12:16:42.660111Z",
     "shell.execute_reply.started": "2024-07-08T12:16:41.42803Z"
    }
   },
   "outputs": [],
   "source": [
    "# 'prompt'および'response'列に対してparallel_applyを再度適用\n",
    "prompt_stats_df_test = parallel_apply(test, 'prompt')  # テストデータのプロンプト統計を計算\n",
    "response_a_stats_df_test = parallel_apply(test, 'response_a')  # テストデータのレスポンスA統計を計算\n",
    "response_b_stats_df_test = parallel_apply(test, 'response_b')  # テストデータのレスポンスB統計を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:17:18.052752Z",
     "iopub.status.busy": "2024-07-08T12:17:18.052149Z",
     "iopub.status.idle": "2024-07-08T12:17:18.072001Z",
     "shell.execute_reply": "2024-07-08T12:17:18.07058Z",
     "shell.execute_reply.started": "2024-07-08T12:17:18.052709Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test.join(prompt_stats_df_test.add_suffix('_prompt'))  # プロンプトの統計をテストデータに結合\n",
    "test = test.join(response_a_stats_df_test.add_suffix('_response_a'))  # レスポンスAの統計をテストデータに結合\n",
    "test = test.join(response_b_stats_df_test.add_suffix('_response_b'))  # レスポンスBの統計をテストデータに結合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:12.279293Z",
     "iopub.status.busy": "2024-07-08T12:19:12.278703Z",
     "iopub.status.idle": "2024-07-08T12:19:12.312519Z",
     "shell.execute_reply": "2024-07-08T12:19:12.311113Z",
     "shell.execute_reply.started": "2024-07-08T12:19:12.279252Z"
    }
   },
   "outputs": [],
   "source": [
    "test = test[features]  # テストデータから特徴量のみ抽出\n",
    "test  # テストデータを表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:20.608873Z",
     "iopub.status.busy": "2024-07-08T12:19:20.608382Z",
     "iopub.status.idle": "2024-07-08T12:19:20.645067Z",
     "shell.execute_reply": "2024-07-08T12:19:20.643825Z",
     "shell.execute_reply.started": "2024-07-08T12:19:20.608837Z"
    }
   },
   "outputs": [],
   "source": [
    "train.head()  # トレーニングデータの最初の数行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:29.014605Z",
     "iopub.status.busy": "2024-07-08T12:19:29.01409Z",
     "iopub.status.idle": "2024-07-08T12:19:29.026851Z",
     "shell.execute_reply": "2024-07-08T12:19:29.025562Z",
     "shell.execute_reply.started": "2024-07-08T12:19:29.014565Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = final_model.predict_proba(test)  # テストデータに対する予測確率を計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:19:35.206668Z",
     "iopub.status.busy": "2024-07-08T12:19:35.205839Z",
     "iopub.status.idle": "2024-07-08T12:19:35.218775Z",
     "shell.execute_reply": "2024-07-08T12:19:35.217583Z",
     "shell.execute_reply.started": "2024-07-08T12:19:35.206626Z"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions  # テストデータの予測確率を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:22:54.02283Z",
     "iopub.status.busy": "2024-07-08T12:22:54.021496Z",
     "iopub.status.idle": "2024-07-08T12:22:54.032338Z",
     "shell.execute_reply": "2024-07-08T12:22:54.031145Z",
     "shell.execute_reply.started": "2024-07-08T12:22:54.022787Z"
    }
   },
   "outputs": [],
   "source": [
    "test_raw = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv', usecols=['id'])  # テストデータのIDを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-08T12:23:00.262804Z",
     "iopub.status.busy": "2024-07-08T12:23:00.261927Z",
     "iopub.status.idle": "2024-07-08T12:23:00.27939Z",
     "shell.execute_reply": "2024-07-08T12:23:00.278202Z",
     "shell.execute_reply.started": "2024-07-08T12:23:00.262753Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出ファイルの準備\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_raw['id'],  # ID列\n",
    "    'winner_model_a': test_predictions[:, 0],  # モデルAの勝者予測\n",
    "    'winner_model_b': test_predictions[:, 1],  # モデルBの勝者予測\n",
    "    'winner_tie': test_predictions[:, 2]  # 引き分けの勝者予測\n",
    "})\n",
    "\n",
    "submission.head()  # 提出ファイルの最初の数行を表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('/kaggle/working/submission.csv', index=False)  # 提出ファイルをCSV形式で保存"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 1332972,
     "sourceId": 2220985,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
