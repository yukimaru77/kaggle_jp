{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde80b2d",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "以下は、指定されたJupyter Notebookの要約です。\n",
    "\n",
    "---\n",
    "\n",
    "## Jupyter Notebook の要約\n",
    "\n",
    "このJupyter Notebookは、「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」に参加し、ユーザーの応答に対する好みを予測するためのモデルを構築するために設計されています。主な対象は、チャットボットの応答がユーザーによって好まれるかどうかを判断することです。\n",
    "\n",
    "### 取組み内容\n",
    "1. **データ準備**:\n",
    "   - `pandas`と`os`ライブラリを利用して、Kaggleの入力ディレクトリからデータファイルをリストアップし、読み込む準備を行います。\n",
    "   - データセットはCSV形式で提供されており、`datasets`ライブラリを使用してこれを読み込みます。\n",
    "\n",
    "2. **ハードウェアの確認**:\n",
    "   - `TensorFlow`を用いて利用可能なGPUデバイスの存在を確認し、計算リソースが確保されているかどうかをチェックします。\n",
    "\n",
    "3. **ライブラリのインストール**:\n",
    "   - `transformers`, `datasets`, `accelerate`, 及び `bitsandbytes`といったライブラリをインストールし、必要な外部依存関係を整えます。\n",
    "\n",
    "4. **モデルの設定**:\n",
    "   - `AutoModelForCausalLM`を使って、特定の因果言語モデルを事前学習済みの状態でロードします。\n",
    "   - `BitsAndBytesConfig`を配置し、モデルを4ビット精度で読み込み、パフォーマンスを最適化します。\n",
    "\n",
    "### 使用ライブラリ\n",
    "- `numpy`: 数値計算\n",
    "- `pandas`: データ処理\n",
    "- `os`: ファイルシステム操作\n",
    "- `TensorFlow`: ディープラーニング\n",
    "- `transformers`: 事前学習済みモデルとトークナイザの利用\n",
    "- `datasets`: データセットの読み込み\n",
    "- `torch`: PyTorchライブラリ（後のモデル動作に使用）\n",
    "\n",
    "### 解決手法\n",
    "本ノートブックでは、データの読み込みやGPUの確認に加え、チャットボットの応答の評価に有用な言語モデルを準備することを目的としています。これにより、人間の好みを予測するためのモデルの訓練や評価を行うための基盤が構築されています。\n",
    "\n",
    "--- \n",
    "\n",
    "この要約は、ノートブックの目的や手法、使用するライブラリに焦点を当てています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3620008e",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、Jupyter Notebook内で初学者がつまずきそうな専門用語の簡単な解説をまとめます。特に、マイナーなものや実務での経験が少ない場合に理解が難しい用語を中心にしています。\n",
    "\n",
    "### 専門用語の解説\n",
    "\n",
    "1. **kaggle/python Dockerイメージ**:\n",
    "   - Kaggleが提供する環境でPythonとそれに必要なライブラリがセットアップされたコンテナ。データサイエンスや機械学習の実験ごとに再現性のある環境を提供するために使用されます。\n",
    "\n",
    "2. **`pd.read_csv`**:\n",
    "   - Pandasライブラリの関数で、CSV形式のファイルを読み込んでデータフレームオブジェクトに変換するために使います。データ処理において非常に一般的な操作ですが、ファイルのパスやデリミタのオプションを設定することの重要性を理解していないとつまづくことがあります。\n",
    "\n",
    "3. **`os.walk`**:\n",
    "   - Pythonのosモジュールの関数で、指定したディレクトリ以下の全ファイルとサブディレクトリを走査します。ファイルシステムの操作に関する知識が乏しいと理解が難しい場合があります。\n",
    "\n",
    "4. **`tf.test.gpu_device_name()`**:\n",
    "   - TensorFlowで現在の環境で使用可能なGPUデバイスの名前を取得するための関数。この関数は主にハードウェアの確認に使われ、GPUを用いた学習が可能かどうかを判別するための重要な前処理です。\n",
    "\n",
    "5. **`BitsAndBytesConfig`**:\n",
    "   - モデルの量子化設定を行うためのクラス。特に、低ビット数でモデルを扱うことでメモリや計算資源の消費を抑えながらも、高いパフォーマンスを保つことが目的です。量子化や低精度計算に慣れていない初学者にとっては理解が難しい場合があります。\n",
    "\n",
    "6. **`load_in_4bit` と `bnb_4bit_quant_type`**:\n",
    "   - モデルを4ビットの精度で読み込む設定や、その量子化のタイプを指定するオプション。こうした精度の設定は、モデルのストレージや計算効率に影響を与えますが、初学者にはビットや量子化の概念自体が馴染みが薄いかもしれません。\n",
    "\n",
    "7. **ダブル量子化 (Double Quantization)**:\n",
    "   - 量子化をさらなる精度向上のために行う手法。通常の量子化は誤差を持つが、ダブル量子化はその過程を二重にすることで精度を向上させることができるという考え方。これが理解できていないと、モデルの性能向上がどのように実現されるかが分かりにくいかもしれません。\n",
    "\n",
    "8. **因果言語モデル (Causal Language Model)**:\n",
    "   - 過去の情報に基づいて次の単語を予測するタイプの言語モデル。対話型AIや文章生成のタスクでよく使われますが、リカレントニューラルネットワーク(RNN)や自己回帰モデルの理解が必要です。\n",
    "\n",
    "これらの用語は、特に実際に手を動かしながら学んでいる段階の初学者にとって、しばしば触れることがないか、あまりに専門的であるために理解が難しい場合があります。理解を深めるためには、関連する文献や記事を参照することが有効です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-06-29T06:46:49.165625Z",
     "iopub.status.busy": "2024-06-29T06:46:49.164975Z",
     "iopub.status.idle": "2024-06-29T06:46:50.463811Z",
     "shell.execute_reply": "2024-06-29T06:46:50.462757Z",
     "shell.execute_reply.started": "2024-06-29T06:46:49.165589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/config.json\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00002-of-00002.bin\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.json\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer_config.json\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model.bin.index.json\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/pytorch_model-00001-of-00002.bin\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/special_tokens_map.json\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/.gitattributes\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/tokenizer.model\n",
      "/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1/generation_config.json\n",
      "/kaggle/input/lmsys-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/train.csv\n",
      "/kaggle/input/lmsys-chatbot-arena/test.csv\n"
     ]
    }
   ],
   "source": [
    "# このPython 3環境には、多くの便利な分析ライブラリがインストールされています\n",
    "# これは、kaggle/python Dockerイメージによって定義されています: https://github.com/kaggle/docker-python\n",
    "# 例えば、ここでは便利なパッケージをいくつか読み込む方法を示します\n",
    "\n",
    "import numpy as np # 線形代数を行うためのライブラリ\n",
    "import pandas as pd # データ処理、CSVファイルの入出力のためのライブラリ（例: pd.read_csv）\n",
    "\n",
    "# 入力データファイルは読み取り専用の\"../input/\"ディレクトリにあります\n",
    "# 例えば、これを実行することで（クリックするかShift+Enterを押すことで）入力ディレクトリ内のすべてのファイルをリストアップできます\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'): # '/kaggle/input'ディレクトリ内を走査します\n",
    "    for filename in filenames: # 各ファイル名をループします\n",
    "        print(os.path.join(dirname, filename)) # 各ファイルのフルパスを出力します\n",
    "\n",
    "# 現在のディレクトリ（/kaggle/working/）に最大20GBまで書き込むことができ、これらは「すべて保存して実行する」を使用してバージョンを作成する際に出力として保持されます\n",
    "# 一時ファイルは/kaggle/temp/に書き込むことができますが、現在のセッションの外では保存されません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T06:46:57.939278Z",
     "iopub.status.busy": "2024-06-29T06:46:57.937902Z",
     "iopub.status.idle": "2024-06-29T06:47:09.143559Z",
     "shell.execute_reply": "2024-06-29T06:47:09.142511Z",
     "shell.execute_reply.started": "2024-06-29T06:46:57.939235Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 06:47:00.055021: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-29 06:47:00.055199: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-29 06:47:00.234087: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "GPU available (YESS!!!!)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # TensorFlowライブラリをインポートします\n",
    "\n",
    "device_name = tf.test.gpu_device_name() # 使用可能なGPUデバイスの名前を取得します\n",
    "\n",
    "if \"GPU\" not in device_name: # もしデバイス名に\"GPU\"が含まれていない場合\n",
    "    print(\"GPUデバイスが見つかりません\") # GPUが見つからなかったことを表示します\n",
    "    \n",
    "print('見つかったGPU: {}'.format(device_name)) # 見つかったGPUデバイスの名前を表示します\n",
    "\n",
    "# GPUが利用可能かどうかをチェックし、結果を表示します\n",
    "print(\"GPU\", \"利用可能です (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"利用できません :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T06:47:44.111327Z",
     "iopub.status.busy": "2024-06-29T06:47:44.11012Z",
     "iopub.status.idle": "2024-06-29T06:48:13.080824Z",
     "shell.execute_reply": "2024-06-29T06:48:13.078995Z",
     "shell.execute_reply.started": "2024-06-29T06:47:44.111291Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.30.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate # Transformers、datasets、accelerateライブラリをインストールします\n",
    "!pip install -q -U bitsandbytes # bitsandbytesライブラリを最新バージョンにアップグレードしてインストールします（出力を抑制します）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T06:43:27.729437Z",
     "iopub.status.busy": "2024-06-29T06:43:27.72902Z",
     "iopub.status.idle": "2024-06-29T06:43:29.558672Z",
     "shell.execute_reply": "2024-06-29T06:43:29.557793Z",
     "shell.execute_reply.started": "2024-06-29T06:43:27.729398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae194cdfe014726841e24c0a943d875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset # datasetsライブラリからload_dataset関数をインポートします\n",
    "\n",
    "# 'path/to/dataset.csv' を実際のデータセットファイルのパスに置き換えてください\n",
    "dataset = load_dataset('csv', data_files='/kaggle/input/lmsys-chatbot-arena/test.csv') # CSVファイルからデータセットを読み込みます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T06:43:34.389475Z",
     "iopub.status.busy": "2024-06-29T06:43:34.388611Z",
     "iopub.status.idle": "2024-06-29T06:43:54.021111Z",
     "shell.execute_reply": "2024-06-29T06:43:54.020094Z",
     "shell.execute_reply.started": "2024-06-29T06:43:34.389441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-29 06:43:41.391615: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-29 06:43:41.391719: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-29 06:43:41.565725: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, pipeline # transformersライブラリから必要なクラスや関数をインポートします\n",
    "import torch # PyTorchライブラリをインポートします\n",
    "\n",
    "# BitsAndBytesConfigクラスを使用して、モデルの設定を行います\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, # 4ビット精度でモデルをロードする設定\n",
    "    bnb_4bit_quant_type=\"nf4\", # 4ビット量子化のタイプを指定します\n",
    "    bnb_4bit_use_double_quant=True, # ダブル量子化を使用するかどうかを指定します\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-29T06:43:54.023441Z",
     "iopub.status.busy": "2024-06-29T06:43:54.022751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3916cc9582744f5b1d5113bcfcc9686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, Trainer, TrainingArguments # transformersライブラリからモデル、トレーナー、トレーニング引数をインポートします\n",
    "\n",
    "model_name = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\" # 使用するモデルのパスを指定します\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name) # 指定したパスから事前学習済みの因果言語モデルをロードします"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
