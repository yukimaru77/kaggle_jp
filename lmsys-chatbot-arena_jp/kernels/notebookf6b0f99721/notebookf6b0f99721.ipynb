{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f370f244",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、LMSYS - Chatbot Arenaにおける人間による好みの予測に関するコンペティションに取り組んでいます。主な目的は、チャットボットの応答に対するユーザーの好みを予測し、どちらのモデルが勝者であるかを判断することです。\n",
    "\n",
    "ノートブックでは、以下の手法やライブラリが使用されています：\n",
    "\n",
    "1. **データの取り込みと前処理**：\n",
    "   - `pandas`を使って訓練データを読み込み、`winner`列を作成するためのカスタム関数`get_winner`を定義しています。この関数は、各行の応答がどちらのモデルによって勝たれたのかを確認します。\n",
    "\n",
    "2. **データの可視化**：\n",
    "   - `seaborn`と`matplotlib`を用いて、`winner`列の分布や応答の文字数の相関を可視化しています。\n",
    "\n",
    "3. **特徴量エンジニアリング**：\n",
    "   - モデルAとモデルBのそれぞれの応答の長さを新たな特徴量として追加し、これをモデルの学習に使用します。\n",
    "\n",
    "4. **モデルの学習**：\n",
    "   - `scikit-learn`の`MultiOutputClassifier`と`RandomForestClassifier`を用いて、応答の長さを特徴量としてモデルを訓練し、予測を行っています。\n",
    "\n",
    "5. **評価と予測**：\n",
    "   - 検証データに対する予測結果を得て、`log_loss`を利用してモデルの性能を評価しています。\n",
    "\n",
    "6. **テストデータに対する予測**：\n",
    "   - テストセットを読み込み、事前に定義した特徴量エンジニアリングの手順を適用し、最終的な予測結果を生成して`submission.csv`形式で提出用ファイルを作成しています。\n",
    "\n",
    "全体として、ノートブックは人間の好みを予測するために、ランダムフォレスト分類器を中心とした機械学習手法と特徴量加工を駆使しており、特に応答の長さに着目した解析を行っている点が特徴です。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badccace",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下は、Jupyter Notebookにおける専門用語の解説です。特に初心者や実務経験の少ない方にとって、マイナーまたは特有の知識が必要となる用語に焦点を当てています。\n",
    "\n",
    "1. **特徴量エンジニアリング**: データから有用な情報を抽出し、モデルに適した形に変換するプロセスを指します。このノートブックでは、応答の長さを特徴量として追加することが特徴量エンジニアリングの一例です。\n",
    "\n",
    "2. **相関行列**: 複数の変数間における相関関係を示す行列です。この行列を使用することで、それぞれの特徴量が他の特徴量とどの程度関連しているかを視覚的に理解できます。\n",
    "\n",
    "3. **ワンホットエンコーディング**: カテゴリカルデータを機械学習モデルが扱える数値形式に変換する手法です。各カテゴリを二進数のベクトルで表現し、特定のカテゴリのみが1となり、他が0となるようにします。このノートブックでは、'winner'変数をワンホットエンコーディングしています。\n",
    "\n",
    "4. **MultiOutputClassifier**: Scikit-learnライブラリの一部で、複数のターゲット変数を持つ分類問題に対応できるラッパークラスです。複数の分類器を同時に使用し、それぞれのターゲット変数に対して予測を行います。このノートブックでは、RandomForestClassifierを用いています。\n",
    "\n",
    "5. **predict_proba**: モデルの予測メソッドの一つで、クラスごとの予測確率を提供します。例えば、特定の応答がモデルAまたはモデルBの勝者である確率を得るために使用されます。\n",
    "\n",
    "6. **ログ損失 (Log Loss)**: モデルの予測の品質を評価するための損失関数です。実際のクラスラベルと予測確率の間の不一致を測定し、低いほど良いモデルを示します。このコンペティションでは、モデルの性能評価に使われています。\n",
    "\n",
    "7. **データフレーム (DataFrame)**: Pandasライブラリのデータ構造の一つで、表形式のデータを扱うことができます。行と列を持ち、複数の異なるデータ型を格納することが可能です。このノートブック内でのデータ操作は、全てPandasのDataFrameを通じて行われています。\n",
    "\n",
    "8. **テストセット**: モデルの精度を評価するために持ち出されるデータのことです。トレーニング (学習) セットとは異なり、モデルの訓練には使用されず、主に性能評価のために使用されます。\n",
    "\n",
    "これらの用語は、機械学習や深層学習の初心者が理解するのに役立つ基本的な概念であり、特にこのノートブックのコンテキストに関連しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-10T13:01:14.69594Z",
     "iopub.status.busy": "2024-07-10T13:01:14.695461Z",
     "iopub.status.idle": "2024-07-10T13:01:52.683479Z",
     "shell.execute_reply": "2024-07-10T13:01:52.682096Z",
     "shell.execute_reply.started": "2024-07-10T13:01:14.695903Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "# データセットを読み込む\n",
    "train_df = pd.read_csv('/kaggle/input/my-files/train.csv')\n",
    "\n",
    "# 列名を確認する\n",
    "print(train_df.columns)\n",
    "\n",
    "# 'winner' 列が正しく作成されているか確認する\n",
    "def get_winner(row):\n",
    "    # モデルAが勝者の場合\n",
    "    if row['winner_model_a'] == 1:\n",
    "        return 'a'\n",
    "    # モデルBが勝者の場合\n",
    "    elif row['winner_model_b'] == 1:\n",
    "        return 'b'\n",
    "    # 引き分けの場合\n",
    "    else:\n",
    "        return 'tie'\n",
    "\n",
    "# 'winner' 列を新たに作成する\n",
    "train_df['winner'] = train_df.apply(get_winner, axis=1)\n",
    "\n",
    "# 'winner' 列が作成されたことを確認するため最初の数行を表示\n",
    "print(train_df.head())\n",
    "\n",
    "# DataFrameに'winner'列が存在するか確認する\n",
    "print('winner' in train_df.columns)\n",
    "\n",
    "# 'winner' 変数の分布を可視化する\n",
    "sns.countplot(data=train_df, x='winner')\n",
    "plt.title(\"勝者の分布\")\n",
    "plt.xlabel(\"勝者\")\n",
    "plt.ylabel(\"カウント\")\n",
    "plt.show()\n",
    "\n",
    "# 特徴量エンジニアリング: 各応答の長さを特徴量として追加\n",
    "train_df['response_a_length'] = train_df['response_a'].apply(len)\n",
    "train_df['response_b_length'] = train_df['response_b'].apply(len)\n",
    "\n",
    "# 相関行列を表示する\n",
    "correlation_matrix = train_df[['response_a_length', 'response_b_length']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title(\"相関行列\")\n",
    "plt.show()\n",
    "\n",
    "# モデルの学習のためにデータを準備\n",
    "X = train_df[['response_a_length', 'response_b_length']]\n",
    "y = train_df['winner']\n",
    "\n",
    "# 目的変数をワンホットエンコーディングする\n",
    "y = pd.get_dummies(y)\n",
    "\n",
    "# データを学習用と検証用に分割する\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# モデルを初期化して学習する\n",
    "model = MultiOutputClassifier(RandomForestClassifier())\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 予測を行う\n",
    "y_pred = model.predict_proba(X_val)\n",
    "\n",
    "# 配列のリストを単一の配列に変換する\n",
    "y_pred = np.array([pred[:, 1] for pred in y_pred]).T\n",
    "\n",
    "# モデルを評価する\n",
    "loss = log_loss(y_val, y_pred)\n",
    "print(f'ログ損失: {loss}')\n",
    "\n",
    "# 提出ファイルを準備する\n",
    "# テストセットを読み込む\n",
    "test_df = pd.read_csv('/kaggle/input/my-files/test.csv')\n",
    "\n",
    "# テストセットに対して特徴量エンジニアリングの手順を追加\n",
    "test_df['response_a_length'] = test_df['response_a'].apply(len)\n",
    "test_df['response_b_length'] = test_df['response_b'].apply(len)\n",
    "\n",
    "# テストセットで予測を行う\n",
    "test_pred = model.predict_proba(test_df[['response_a_length', 'response_b_length']])\n",
    "\n",
    "# 配列のリストを単一の配列に変換する\n",
    "test_pred = np.array([pred[:, 1] for pred in test_pred]).T\n",
    "\n",
    "# 提出用に予測結果をフォーマットする\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'winner_model_a': test_pred[:, 0],\n",
    "    'winner_model_b': test_pred[:, 1],\n",
    "    'winner_tie': test_pred[:, 2]\n",
    "})\n",
    "\n",
    "# 提出ファイルを保存する\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5366538,
     "sourceId": 8922294,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 187668059,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
