{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e021158c",
   "metadata": {},
   "source": [
    "# 要約 \n",
    "このJupyter Notebookは、Kaggleの「LMSYS - Chatbot Arena 人間による好み予測チャレンジ」に参加するために設計されており、2つの異なる言語モデルの応答の好ましさを予測する問題に取り組んでいます。\n",
    "\n",
    "## 問題へのアプローチ\n",
    "Notebookでは、CatBoostを用いて、チャットボットの応答の優劣を予測するモデルを構築します。このモデルにより、2つの異なるチャットボットの応答の中で、どちらがユーザーによって好まれるかを確率として出力します。データセットには、与えられたプロンプトに対してモデルが生成した複数の応答と、それに対するユーザーの選好が含まれています。\n",
    "\n",
    "## 使用されている手法とライブラリ\n",
    "1. **ライブラリ**:\n",
    "   - **bitsandbytes**および**transformers**: 大規模言語モデルを効率的に扱うためのライブラリとして使用されています。\n",
    "   - **CatBoost**: 決定木を基にした機械学習アルゴリズムであり、特にカテゴリカルデータに強いモデルを構築します。\n",
    "   - **PyTorch**: 深層学習モデルやテンソル操作を行うためのフレームワークです。\n",
    "   - **Pandas**および**NumPy**: データ操作や数値計算に使用されます。\n",
    "\n",
    "2. **主な手順**:\n",
    "   - 必要なライブラリのインストールとインポート。\n",
    "   - 訓練データの読み込みと埋め込み特徴の取得。\n",
    "   - ターゲット変数の整備と訓練データとテストデータの分割。\n",
    "   - CatBoostClassifierのモデルをロードし、予測を行う準備。\n",
    "   - Gemmaモデルの初期化とトークナイザーの設定。\n",
    "   - テストデータの整形およびトークン化を行い、モデルに入力するための形式に変換。\n",
    "   - スレッドを使用して埋め込みを計算し、最終的にCatBoostモデルを使って予測確率を取得。\n",
    "   - 提出用のCSVファイルを生成するために、予測結果をサンプルデータフレームに設定し保存。\n",
    "\n",
    "このNotebookは、最終的に提出用ファイル「submission.csv」を生成し、コンペティションで使用する予測確率を出力します。この一連の処理を通じて、2つのチャットボットの応答に対して、ユーザーの好みを予測するモデルを効果的に構築しています。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5047032e",
   "metadata": {},
   "source": [
    "# 用語概説 \n",
    "以下に、jupyter notebookの内容をもとに、機械学習・深層学習の初心者がつまずきそうな専門用語の解説を列挙します。\n",
    "\n",
    "1. **bitsandbytes**:\n",
    "   - 深層学習モデルの量子化や圧縮に特化したライブラリ。メモリ使用量を削減し、計算を高速化することができる。特に大規模なモデルを扱う際に役立つ。\n",
    "\n",
    "2. **トークナイザー**:\n",
    "   - テキストデータをモデルが理解できる形（トークン）に変換するためのツール。単語やサブワードに分割し、内部的なIDに変換する。\n",
    "\n",
    "3. **埋め込み（embedding）**:\n",
    "   - データ（通常はテキスト）を連続的な数値ベクトルに変換する手法。これにより、データのセマンティックな関係が反映される。例えば、単語をベクトル空間にマッピングし、意味的に類似した単語が近くに配置される。\n",
    "\n",
    "4. **CatBoost**:\n",
    "   - 決定木に基づく勾配ブースティングアルゴリズム。特にカテゴリカルデータを扱うのに強く、高速で効果的なモデルを構築できる。デフォルトでオーバーフィッティングを避けるように設計されている。\n",
    "\n",
    "5. **ガーベジコレクション（Garbage Collection）**:\n",
    "   - メモリ管理の一種で、不要になったオブジェクトを自動的に検出し、メモリを解放するプロセス。特に大きなデータやモデルを扱う際にメモリ不足を防ぐために重要。\n",
    "\n",
    "6. **注意マスク（Attention Mask）**:\n",
    "   - ニューラルネットワークが入力データ中のどの部分を「見る」べきかを示すマスク。パディング（無視されるべき部分）を避け、モデルが有効な情報のみを処理することができる。\n",
    "\n",
    "7. **スレッド（Thread）**:\n",
    "   - プログラムが同時に実行できるプロセスの単位。スレッドを使用して、異なる処理を同時並行で行うことで、計算の効率を上げることができる。\n",
    "\n",
    "8. **量子化（Quantization）**:\n",
    "   - モデルの重みやデータを減少させる手法で、小さいビット数（例えば16ビットや4ビット）に変換することで、メモリ使用量と計算コストを削減する。これにより、モデルを軽量化し、特にGPUの性能を最大限に引き出すことができる。\n",
    "\n",
    "9. **自動混合精度（autocast）**:\n",
    "   - 計算の精度を動的に調整する技術。モデルの計算をフロート16（半精度）やフロート32（単精度）の間で切り替え、高速かつメモリ効率を改善する。\n",
    "\n",
    "10. **トンネル効果（Truncation）**:\n",
    "    - 入力が指定された最大長を超えた場合に、その超過部分を切り捨てる処理。通常、モデルが処理できる最大のトークン数に制限をかけるために行う。\n",
    "\n",
    "これらの用語は、ノートブックに特有の文脈や実務経験に基づいたものであり、初心者が理解する上で役立つでしょう。\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:55:50.628675Z",
     "iopub.status.busy": "2024-07-20T15:55:50.628382Z",
     "iopub.status.idle": "2024-07-20T15:56:17.87735Z",
     "shell.execute_reply": "2024-07-20T15:56:17.876038Z",
     "shell.execute_reply.started": "2024-07-20T15:55:50.628646Z"
    }
   },
   "outputs": [],
   "source": [
    "# bitsandbytesライブラリをインストールします。\n",
    "# --no-indexオプションは、PyPIリポジトリを使用せず、指定したファイルシステムのリンクからのみインストールします。\n",
    "!pip install -q -U bitsandbytes --no-index --find-links ../input/libs-install\n",
    "\n",
    "# transformersライブラリをインストールします。\n",
    "# 同様に、--no-indexオプションを使用して、指定したリンクからのみインストールします。\n",
    "!pip install -q -U transformers --no-index --find-links ../input/libs-install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:56:27.053843Z",
     "iopub.status.busy": "2024-07-20T15:56:27.053454Z",
     "iopub.status.idle": "2024-07-20T15:56:30.488833Z",
     "shell.execute_reply": "2024-07-20T15:56:30.487809Z",
     "shell.execute_reply.started": "2024-07-20T15:56:27.053806Z"
    }
   },
   "outputs": [],
   "source": [
    "# 必要なライブラリをインポートします。\n",
    "import os  # OSに関連する機能を提供するライブラリ\n",
    "import gc  # ガーベジコレクタ（不要なオブジェクトをメモリから削除するためのライブラリ）\n",
    "import re  # 正規表現を使用するためのライブラリ\n",
    "from time import time  # 時間に関する機能を提供するライブラリ\n",
    "\n",
    "import torch  # PyTorchライブラリ\n",
    "import transformers  # Hugging Faceのtransformersライブラリ\n",
    "import sklearn  # 機械学習のためのライブラリ\n",
    "import random  # ランダムな数値を生成するためのライブラリ\n",
    "import numpy as np  # 数値計算を行うためのライブラリ（NumPy）\n",
    "import pandas as pd  # データ分析を行うためのライブラリ（Pandas）\n",
    "import matplotlib.pyplot as plt  # グラフ描画を行うためのライブラリ\n",
    "\n",
    "# モデルとトークナイザーをインポートします。\n",
    "from transformers import Gemma2ForCausalLM, GemmaTokenizer, BitsAndBytesConfig\n",
    "\n",
    "import time  # 再度timeライブラリをインポート（必要ない場合は削除可能）\n",
    "from catboost import CatBoostClassifier, Pool  # CatBoostライブラリをインポート（決定木による分類器）\n",
    "from sklearn.model_selection import train_test_split  # データを訓練セットとテストセットに分割する機能\n",
    "from sklearn.metrics import accuracy_score, log_loss  # モデルの評価指標を計算するための機能\n",
    "\n",
    "from torch.cuda.amp import autocast  # 自動混合精度を使用するための機能をインポート\n",
    "from threading import Thread  # スレッドの管理を行うためのライブラリ\n",
    "\n",
    "# CUDAのメモリアイデアを有効にする設定\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "# GPUが使用可能か確認し、使用できない場合はメッセージを表示します。\n",
    "if (not torch.cuda.is_available()):\n",
    "    print(\"Sorry - GPU required!\")  # GPUが必要であることを知らせるメッセージを表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:56:38.21034Z",
     "iopub.status.busy": "2024-07-20T15:56:38.209404Z",
     "iopub.status.idle": "2024-07-20T15:56:45.353822Z",
     "shell.execute_reply": "2024-07-20T15:56:45.352979Z",
     "shell.execute_reply.started": "2024-07-20T15:56:38.210303Z"
    }
   },
   "outputs": [],
   "source": [
    "# 訓練データフレームをCSVファイルから読み込みます。\n",
    "train_df = pd.read_csv('/kaggle/input/embedding/train_embed.csv')\n",
    "\n",
    "# 訓練データの埋め込み（特徴量）をNumpy配列として読み込みます。\n",
    "train_embed = np.load('/kaggle/input/embedding/gemma2_train_embed.npy')\n",
    "\n",
    "# 各行のラベルを設定します。\n",
    "# winner_model_a, winner_model_b, winner_tie の中で最大の値を持つ列を見つけ、その列のインデックスをラベルとして使用します。\n",
    "train_df.loc[:, 'label'] = np.argmax(train_df[['winner_model_a', 'winner_model_b', 'winner_tie']].values, axis=1)  # どのモデルが勝つかを示すラベルを作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T16:04:14.675515Z",
     "iopub.status.busy": "2024-07-20T16:04:14.67469Z",
     "iopub.status.idle": "2024-07-20T16:04:14.825208Z",
     "shell.execute_reply": "2024-07-20T16:04:14.824135Z",
     "shell.execute_reply.started": "2024-07-20T16:04:14.675478Z"
    }
   },
   "outputs": [],
   "source": [
    "# ターゲット変数の列名を定義します。\n",
    "Targets = ['winner_model_a', 'winner_model_b', 'winner_tie']\n",
    "\n",
    "# 予測対象のラベルを取得します。\n",
    "y = train_df['label'].values\n",
    "\n",
    "# 訓練データとテストデータに分割します。\n",
    "# train_test_split関数を使用して、インデックスを訓練用とテスト用に分けます。\n",
    "train_idx, test_idx = train_test_split(train_df.index, test_size=0.1, random_state=42, stratify=y)\n",
    "\n",
    "# 訓練データとテストデータの特徴量とラベルを設定します。\n",
    "X_train, y_train = train_embed[train_idx], train_df.iloc[train_idx]['label'].values  # 訓練データ\n",
    "X_test, y_test = train_embed[test_idx], train_df.iloc[test_idx]['label'].values  # テストデータ\n",
    "\n",
    "# 訓練データとテストデータの形状を出力します。\n",
    "print(X_train.shape, y_train.shape)  # 訓練データの形状を出力\n",
    "print(X_test.shape, y_test.shape)      # テストデータの形状を出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:56:48.004951Z",
     "iopub.status.busy": "2024-07-20T15:56:48.004578Z",
     "iopub.status.idle": "2024-07-20T15:56:48.03876Z",
     "shell.execute_reply": "2024-07-20T15:56:48.037854Z",
     "shell.execute_reply.started": "2024-07-20T15:56:48.004921Z"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostClassifierのモデルを初期化します。\n",
    "model_cb = CatBoostClassifier()\n",
    "\n",
    "# 保存されたCatBoostモデルを読み込みます。\n",
    "# 指定されたパスからモデルをロードします。\n",
    "model_cb.load_model('/kaggle/input/catboost-mike/catboost.cbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:56:49.887004Z",
     "iopub.status.busy": "2024-07-20T15:56:49.886015Z",
     "iopub.status.idle": "2024-07-20T15:56:49.893266Z",
     "shell.execute_reply": "2024-07-20T15:56:49.892301Z",
     "shell.execute_reply.started": "2024-07-20T15:56:49.886956Z"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostモデルの情報を表示します。\n",
    "# これにより、モデルの構造やパラメータ、トレーニング状況などの詳細を確認することができます。\n",
    "model_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:56:51.256772Z",
     "iopub.status.busy": "2024-07-20T15:56:51.256391Z",
     "iopub.status.idle": "2024-07-20T15:57:42.262798Z",
     "shell.execute_reply": "2024-07-20T15:57:42.261799Z",
     "shell.execute_reply.started": "2024-07-20T15:56:51.256742Z"
    }
   },
   "outputs": [],
   "source": [
    "# モデルのパスと設定を定義します。\n",
    "MODEL_PATH = '/kaggle/input/gemma-2-9b-hf'  # Gemmaモデルの保存先パス\n",
    "MAX_LENGTH = 1024  # モデルが処理する最大のシーケンス長\n",
    "BATCH_SIZE = 2  # バッチサイズ\n",
    "\n",
    "# 使用するGPUデバイスを指定します。\n",
    "device0 = torch.device('cuda:0')  # 1つ目のGPUデバイス\n",
    "device1 = torch.device('cuda:1')  # 2つ目のGPUデバイス\n",
    "\n",
    "# トークナイザーをモデルからロードします。\n",
    "tokenizer = GemmaTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "# 量子化の設定を定義します。\n",
    "bnb_config_4bit = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # 4ビットモードで読み込みます。\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # 計算精度としてfloat16を使用します。\n",
    "    bnb_4bit_use_double_quant=False)  # 二重量子化を使用しない設定\n",
    "\n",
    "# 1つ目のGPUデバイスにモデルをロードします。\n",
    "model_0 = Gemma2ForCausalLM.from_pretrained(MODEL_PATH,\n",
    "                                        revision=\"float16\",  # float16バージョンを使用\n",
    "                                        device_map='cuda:0',  # GPUデバイス0にマッピング\n",
    "                                        quantization_config=bnb_config_4bit)        \n",
    "\n",
    "# 2つ目のGPUデバイスにモデルをロードします。\n",
    "model_1 = Gemma2ForCausalLM.from_pretrained(MODEL_PATH,\n",
    "                                        revision=\"float16\",  # float16バージョンを使用\n",
    "                                        device_map='cuda:1',  # GPUデバイス1にマッピング\n",
    "                                        quantization_config=bnb_config_4bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:58:36.584863Z",
     "iopub.status.busy": "2024-07-20T15:58:36.584451Z",
     "iopub.status.idle": "2024-07-20T15:58:36.601027Z",
     "shell.execute_reply": "2024-07-20T15:58:36.599962Z",
     "shell.execute_reply.started": "2024-07-20T15:58:36.584831Z"
    }
   },
   "outputs": [],
   "source": [
    "# 入力文字列を処理する関数を定義します。\n",
    "def process(input_str):\n",
    "    # 文字列の先頭と末尾のブラケットを削除します。\n",
    "    stripped_str = input_str.strip('[]')\n",
    "    # カンマで区切られた文をリストに分割し、前後の空白を削除します。\n",
    "    sentences = [s.strip('\"') for s in stripped_str.split('\",\"')]\n",
    "    # 文が存在する場合は最後の文を返し、存在しない場合は空文字を返します。\n",
    "    return sentences[-1] if sentences else ''\n",
    "\n",
    "# テストデータをCSVファイルから読み込みます。\n",
    "test = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/test.csv')\n",
    "\n",
    "# 'prompt', 'response_a', 'response_b' 列に対してprocess関数を適用します。\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process)\n",
    "\n",
    "# テキスト列を構成します。モデルの応答を整理した形式です。\n",
    "test['text'] = '<start_of_turn>User prompt: ' + test['prompt'] +  '\\n\\nModel A :\\n' + test['response_a'] +'\\n\\n----\\n\\nModel B:\\n'  + test['response_b'] + '<end_of_turn><eos>'\n",
    "\n",
    "# 最初のテキストを出力します。\n",
    "print(test['text'][0])  # 生成された最初のテキストの形式を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:58:39.903906Z",
     "iopub.status.busy": "2024-07-20T15:58:39.90304Z",
     "iopub.status.idle": "2024-07-20T15:58:39.948433Z",
     "shell.execute_reply": "2024-07-20T15:58:39.947544Z",
     "shell.execute_reply.started": "2024-07-20T15:58:39.903875Z"
    }
   },
   "outputs": [],
   "source": [
    "# トークナイザーを使用してテキストをトークン化します。\n",
    "tokens = tokenizer(test['text'].tolist(),\n",
    "                   padding='max_length',  # 最大長にパディングを行います。\n",
    "                   max_length=MAX_LENGTH,  # 定義した最大長を適用します。\n",
    "                   truncation=True,  # 長さが超過する場合は切り捨てます。\n",
    "                   return_tensors='pt')  # PyTorchテンソルとして返します。\n",
    "\n",
    "# テキストデータをDataFrameに変換します。\n",
    "data = pd.DataFrame()\n",
    "# トークンの入力IDと注意マスクをリストとしてDataFrameに追加します。\n",
    "data['INPUT_IDS'] = [tensor.tolist() for tensor in tokens['input_ids']]\n",
    "data['ATTENTION_MASKS'] = [tensor.tolist() for tensor in tokens['attention_mask']]\n",
    "\n",
    "# 最初の2行を表示します。\n",
    "data[:2]  # データの最初の2行を表示して内容を確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:58:42.255269Z",
     "iopub.status.busy": "2024-07-20T15:58:42.254534Z",
     "iopub.status.idle": "2024-07-20T15:58:42.264111Z",
     "shell.execute_reply": "2024-07-20T15:58:42.263201Z",
     "shell.execute_reply.started": "2024-07-20T15:58:42.255234Z"
    }
   },
   "outputs": [],
   "source": [
    "# 埋め込みを取得する関数を定義します。\n",
    "def get_embeddings(df, model, device, batch_size=BATCH_SIZE):  \n",
    "    # INPUT_IDSとATTENTION_MASKSをテンソルに変換します。\n",
    "    input_ids = torch.tensor(df['INPUT_IDS'].values.tolist(), dtype=torch.long)\n",
    "    attention_mask = torch.tensor(df['ATTENTION_MASKS'].values.tolist(), dtype=torch.long)\n",
    "\n",
    "    embed_list = []  # 埋め込みのリストを初期化します。\n",
    "\n",
    "    # バッチごとに処理を行います。\n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))  # 最後のバッチのインデックスを設定\n",
    "        batch_input_ids = input_ids[start_idx:end_idx].to(device)  # バッチの入力IDをデバイスに転送\n",
    "        batch_attention_mask = attention_mask[start_idx:end_idx].to(device)  # バッチの注意マスクをデバイスに転送\n",
    "        \n",
    "        # ガーベジコレクションを実施し、メモリをクリアします。\n",
    "        gc.collect() \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # 勾配計算を行わずにモデルを通して埋め込みを取得します。\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask, output_hidden_states=True)\n",
    "            embed = outputs.hidden_states[-1]  # 最後の隠れ層の出力を取得\n",
    "            embed_mean = torch.mean(embed, dim=1).cpu()  # 平均プールを行い、CPUに戻します。\n",
    "            embed_list.append(embed_mean)  # 得られた埋め込みをリストに追加\n",
    "            \n",
    "            torch.cuda.empty_cache()  # 再度メモリをクリア\n",
    "        \n",
    "    # リストの埋め込みを1つのテンソルに結合して返します。\n",
    "    embeddings = torch.cat(embed_list, dim=0)\n",
    "    return embeddings  # 取得した埋め込みを返します。\n",
    "\n",
    "# 埋め込みを計算し結果を保存する関数を定義します。\n",
    "def compute_embed(df, model, device, results, index):\n",
    "    results[index] = get_embeddings(df, model, device)  # 指定されたインデックスに埋め込み結果を格納します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:58:45.72353Z",
     "iopub.status.busy": "2024-07-20T15:58:45.72315Z",
     "iopub.status.idle": "2024-07-20T15:59:00.986464Z",
     "shell.execute_reply": "2024-07-20T15:59:00.985477Z",
     "shell.execute_reply.started": "2024-07-20T15:58:45.723499Z"
    }
   },
   "outputs": [],
   "source": [
    "# 処理開始時刻を記録します。\n",
    "st = time.time()\n",
    "\n",
    "# データのサンプル数を取得します。\n",
    "N_SAMPLES = len(data)\n",
    "half = round(N_SAMPLES / 2)  # データを2つのサブセットに分けるためのインデックスを計算\n",
    "sub1 = data.iloc[0:half].copy()  # 最初の半分のデータをコピー\n",
    "sub2 = data.iloc[half:N_SAMPLES].copy()  # 残りの半分のデータをコピー\n",
    "\n",
    "# 結果を格納する辞書を初期化します。\n",
    "results = {}\n",
    "\n",
    "# それぞれのスレッドを作成し、compute_embed関数を呼び出します。\n",
    "t0 = Thread(target=compute_embed, args=(sub1, model_0, device0, results, 0))  # スレッド0\n",
    "t1 = Thread(target=compute_embed, args=(sub2, model_1, device1, results, 1))  # スレッド1\n",
    "\n",
    "# スレッドを開始します。\n",
    "t0.start()\n",
    "t1.start()\n",
    "\n",
    "# 両方のスレッドが完了するのを待ちます。\n",
    "t0.join()\n",
    "t1.join()\n",
    "\n",
    "# 処理の完了時刻を表示します。\n",
    "print(f\"Processing complete. Total time: {time.time() - st:.2f} seconds\")  # 処理にかかった合計時間を表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:59:28.51597Z",
     "iopub.status.busy": "2024-07-20T15:59:28.51497Z",
     "iopub.status.idle": "2024-07-20T15:59:28.522786Z",
     "shell.execute_reply": "2024-07-20T15:59:28.521713Z",
     "shell.execute_reply.started": "2024-07-20T15:59:28.515935Z"
    }
   },
   "outputs": [],
   "source": [
    "# 結果の埋め込みを結合します。\n",
    "# 先ほどのスレッドで計算した埋め込みを1つのテンソルにまとめます。\n",
    "test_embeddings = torch.cat([results[0], results[1]], dim=0)\n",
    "\n",
    "# 結合した埋め込みの形状を出力します。\n",
    "test_embeddings.shape  # テンソルの形状を表示して、埋め込みのサイズを確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ガーベジコレクションを実行して、不要なオブジェクトをメモリから削除します。\n",
    "gc.collect()\n",
    "\n",
    "# 使用し終わったモデルを削除します。\n",
    "del model_1  # モデル1を削除\n",
    "del model_0  # モデル0を削除\n",
    "\n",
    "# GPUメモリをクリアします。\n",
    "torch.cuda.empty_cache()  # 不要なメモリを解放します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T15:59:34.530916Z",
     "iopub.status.busy": "2024-07-20T15:59:34.530054Z",
     "iopub.status.idle": "2024-07-20T15:59:34.642592Z",
     "shell.execute_reply": "2024-07-20T15:59:34.641713Z",
     "shell.execute_reply.started": "2024-07-20T15:59:34.530884Z"
    }
   },
   "outputs": [],
   "source": [
    "# CatBoostモデルを使用して予測確率を計算します。\n",
    "# テストデータの埋め込みに対して、モデルが各クラスが選ばれる確率を予測します。\n",
    "preds = model_cb.predict_proba(test_embeddings.numpy())\n",
    "\n",
    "# 予測結果を表示します。\n",
    "preds  # 各モデルの応答が選ばれる確率の配列を出力します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T16:04:20.252748Z",
     "iopub.status.busy": "2024-07-20T16:04:20.252401Z",
     "iopub.status.idle": "2024-07-20T16:04:20.269829Z",
     "shell.execute_reply": "2024-07-20T16:04:20.268956Z",
     "shell.execute_reply.started": "2024-07-20T16:04:20.252723Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用サンプルファイルをCSVから読み込みます。\n",
    "sample_sub = pd.read_csv('/kaggle/input/lmsys-chatbot-arena/sample_submission.csv')\n",
    "\n",
    "# 予測結果をサンプル提出用データフレームに設定します。\n",
    "sample_sub[Targets] = preds  # 予測確率をターゲット列に代入します。\n",
    "\n",
    "# サンプル提出用データを表示します。\n",
    "display(sample_sub)  # 最終的な提出用データフレームを画面に表示します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-20T16:04:21.652541Z",
     "iopub.status.busy": "2024-07-20T16:04:21.65216Z",
     "iopub.status.idle": "2024-07-20T16:04:21.662648Z",
     "shell.execute_reply": "2024-07-20T16:04:21.661766Z",
     "shell.execute_reply.started": "2024-07-20T16:04:21.652511Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提出用データフレームをCSVファイルとして保存します。\n",
    "sample_sub.to_csv('submission.csv', index=False)  # インデックスなしで'submission.csv'という名前で保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8346466,
     "sourceId": 66631,
     "sourceType": "competition"
    },
    {
     "datasetId": 5299906,
     "sourceId": 8811121,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5410481,
     "sourceId": 8984506,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5419932,
     "sourceId": 8998271,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 148861315,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 186671053,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
